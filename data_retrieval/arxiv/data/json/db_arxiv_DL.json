[{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2014.6210", 
    "link": "http://arxiv.org/pdf/cs/9811020v1", 
    "title": "Digitizing Legacy Documents: A Knowledge-Base Preservation Project", 
    "arxiv-id": "cs/9811020v1", 
    "author": "Sara Tompson", 
    "publish": "1998-11-11T22:12:18Z", 
    "summary": "This paper addresses the issue of making legacy information (that material\nheld in paper format only) electronically searchable and retrievable. We used\nproprietary software and commercial hardware to create a process for scanning,\ncataloging, archiving and electronically disseminating full-text documents.\nThis process is relatively easy to implement and reasonably affordable."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2014.6210", 
    "link": "http://arxiv.org/pdf/cs/9812009v1", 
    "title": "Vocal Access to a Newspaper Archive: Design Issues and Preliminary   Investigation", 
    "arxiv-id": "cs/9812009v1", 
    "author": "Fabio Crestani", 
    "publish": "1998-12-10T13:49:57Z", 
    "summary": "This paper presents the design and the current prototype implementation of an\ninteractive vocal Information Retrieval system that can be used to access\narticles of a large newspaper archive using a telephone. The results of\npreliminary investigation into the feasibility of such a system are also\npresented."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2014.6210", 
    "link": "http://arxiv.org/pdf/cs/9812016v1", 
    "title": "Making the most of electronic journals", 
    "arxiv-id": "cs/9812016v1", 
    "author": "Wendy Hall", 
    "publish": "1998-12-14T18:24:14Z", 
    "summary": "As most electronic journals available today have been derived from print\noriginals, print journals have become a vital element in the broad development\nof electronic journals publishing. Further dependence on the print publishing\nmodel, however, will be a constraint on the continuing development of\ne-journals, and a series of conflicts are likely to arise. Making the most of\ne-journals requires that a distinctive new publishing model is developed. We\nconsider some of the issues that will be fundamental in this new model,\nstarting with user motivations and some reported publisher experiences, both of\nwhich suggest a broadening desire for comprehensive linked archives. This leads\nin turn to questions about the impact of rights assignment by authors, in\nparticular the common practice of giving exlusive rights to publishers for\nindividual works. Some non-prescriptive solutions are suggested, and four steps\ntowards optimum e-journals are proposed."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2014.6210", 
    "link": "http://arxiv.org/pdf/cs/9812020v1", 
    "title": "The Computing Research Repository: Promoting the Rapid Dissemination and   Archiving of Computer Science Research", 
    "arxiv-id": "cs/9812020v1", 
    "author": "Carl Lagoze", 
    "publish": "1998-12-22T11:49:29Z", 
    "summary": "We describe the Computing Research Repository (CoRR), a new electronic\narchive for rapid dissemination and archiving of computer science research\nresults. CoRR was initiated in September 1998 through the cooperation of ACM,\nLANL (Los Alamos National Laboratory) e-Print archive, and NCSTRL (Networked\nComputer Science Technical Research Library. Through its implementation of the\nDienst protocol, CoRR combines the open and extensible architecture of NCSTRL\nwith the reliable access and well-established management practices of the LANL\nXXX e-Print repository. This architecture will allow integration with other\ne-Print archives and provides a foundation for a future broad-based scholarly\ndigital library. We describe the decisions that were made in creating CoRR, the\narchitecture of the CoRR/NCSTRL interoperation, and issues that have arisen\nduring the operation of CoRR."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2014.6210", 
    "link": "http://arxiv.org/pdf/cs/9901009v1", 
    "title": "Competition and cooperation: Libraries and publishers in the transition   to electronic scholarly journals", 
    "arxiv-id": "cs/9901009v1", 
    "author": "Andrew Odlyzko", 
    "publish": "1999-01-20T13:01:09Z", 
    "summary": "The conversion of scholarly journals to digital format is proceeding rapidly,\nespecially for those from large commercial and learned society publishers. This\nconversion offers the best hope for survival for such publishers. The infamous\n\"journal crisis\" is more of a library cost crisis than a publisher pricing\nproblem, with internal library costs much higher than the amount spent on\npurchasing books and journals. Therefore publishers may be able to retain or\neven increase their revenues and profits, while at the same time providing a\nsuperior service. To do this, they will have to take over many of the function\nof libraries, and they can do that only in the digital domain. This paper\nexamines publishers' strategies, how they are likely to evolve, and how they\nwill affect libraries."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2014.6210", 
    "link": "http://arxiv.org/pdf/cs/9902003v1", 
    "title": "MyLibrary: A Model for Implementing a User-centered, Customizable   Interface to a Library's Collection of Information Resources", 
    "arxiv-id": "cs/9902003v1", 
    "author": "Eric Lease Morgan", 
    "publish": "1999-02-02T13:41:56Z", 
    "summary": "The paper describes an extensible model for implementing a user-centered,\ncustomizable interface to a library's collection of information resources. This\nmodel, called MyLibrary, integrates the principles of librarianship\n(collection, organization, dissemination, and evaluation) with globally\nnetworked computing resources creating a dynamic, customer-driven front-end to\nany library's set of materials. The model supports a framework for libraries to\nprovide enhanced access to local and remote sets of data, information, and\nknowledge. At the same, the model does not overwhelm its users with too much\ninformation because the users control exactly how much information is displayed\nto them at any given time. The model is active and not passive; direct human\ninteraction, computer mediated guidance and communication technologies, as well\nas current awareness services all play indispensable roles in this system."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2014.6210", 
    "link": "http://arxiv.org/pdf/cs/9902004v1", 
    "title": "The Alex Catalogue, A Collection of Digital Texts with Automatic Methods   for Acquisition and Cataloging, User-Defined Typography, Cross-searching of   Indexed Content, and a Sense of Community", 
    "arxiv-id": "cs/9902004v1", 
    "author": "Eric Lease Morgan", 
    "publish": "1999-02-02T14:14:42Z", 
    "summary": "This paper describes the Alex Catalogue of Electronic Texts, the only\nInternet-accessible collection of digital documents allowing the user to 1)\ndynamically create customized, typographically readable documents on demand, 2)\nsearch the content of one or more documents from the collection simultaneously,\n3) create sets of documents from the collection for review and annotation, and\n4) publish these sets of annotated documents in turn fostering a sense of\ncommunity around the Catalogue. More than a just a collection of links that\nwill break over time, Alex is an archive of electronic texts providing\nunprecedented access to its content and features allowing it to meet the needs\nof a wide variety of users and settings. Furthermore, the process of\nmaintaining the Catalogue is streamlined with tools for automatic acquisition\nand cataloging making it possible to sustain the service with a minimum of\npersonnel."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2014.6210", 
    "link": "http://arxiv.org/pdf/cs/9902007v1", 
    "title": "KEA: Practical Automatic Keyphrase Extraction", 
    "arxiv-id": "cs/9902007v1", 
    "author": "Craig G. Nevill-Manning", 
    "publish": "1999-02-05T03:15:45Z", 
    "summary": "Keyphrases provide semantic metadata that summarize and characterize\ndocuments. This paper describes Kea, an algorithm for automatically extracting\nkeyphrases from text. Kea identifies candidate keyphrases using lexical\nmethods, calculates feature values for each candidate, and uses a\nmachine-learning algorithm to predict which candidates are good keyphrases. The\nmachine learning scheme first builds a prediction model using training\ndocuments with known keyphrases, and then uses the model to find keyphrases in\nnew documents. We use a large test corpus to evaluate Kea's effectiveness in\nterms of how many author-assigned keyphrases are correctly identified. The\nsystem is simple, robust, and publicly available."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2014.6210", 
    "link": "http://arxiv.org/pdf/cs/9902009v1", 
    "title": "Quality of OCR for Degraded Text Images", 
    "arxiv-id": "cs/9902009v1", 
    "author": "Kathleen Crumpton", 
    "publish": "1999-02-05T20:52:05Z", 
    "summary": "Commercial OCR packages work best with high-quality scanned images. They\noften produce poor results when the image is degraded, either because the\noriginal itself was poor quality, or because of excessive photocopying. The\nability to predict the word failure rate of OCR from a statistical analysis of\nthe image can help in making decisions in the trade-off between the success\nrate of OCR and the cost of human correction of errors. This paper describes an\ninvestigation of OCR of degraded text images using a standard OCR engine (Adobe\nCapture). The documents were selected from those in the archive at Los Alamos\nNational Laboratory. By introducing noise in a controlled manner into perfect\ndocuments, we show how the quality of OCR can be predicted from the nature of\nthe noise. The preliminary results show that a simple noise model can give good\nprediction of the number of OCR errors."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2014.6210", 
    "link": "http://arxiv.org/pdf/cs/9902011v1", 
    "title": "Content-Based Book Recommending Using Learning for Text Categorization", 
    "arxiv-id": "cs/9902011v1", 
    "author": "Loriene Roy", 
    "publish": "1999-02-07T20:03:20Z", 
    "summary": "Recommender systems improve access to relevant products and information by\nmaking personalized suggestions based on previous examples of a user's likes\nand dislikes. Most existing recommender systems use social filtering methods\nthat base recommendations on other users' preferences. By contrast,\ncontent-based methods use information about an item itself to make suggestions.\nThis approach has the advantage of being able to recommended previously unrated\nitems to users with unique interests and to provide explanations for its\nrecommendations. We describe a content-based book recommending system that\nutilizes information extraction and a machine-learning algorithm for text\ncategorization. Initial experimental results demonstrate that this approach can\nproduce accurate recommendations."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2014.6210", 
    "link": "http://arxiv.org/pdf/cs/9902012v1", 
    "title": "Digital Library Technology for Locating and Accessing Scientific Data", 
    "arxiv-id": "cs/9902012v1", 
    "author": "Damien Guillaume", 
    "publish": "1999-02-07T20:06:01Z", 
    "summary": "In this paper we describe our efforts to bring scientific data into the\ndigital library. This has required extension of the standard WWW, and also the\nextension of metadata standards far beyond the Dublin Core. Our system\ndemonstrates this technology for real scientific data from astronomy."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2014.6210", 
    "link": "http://arxiv.org/pdf/cs/9902013v1", 
    "title": "Use and usability in a digital library search system", 
    "arxiv-id": "cs/9902013v1", 
    "author": "Jianxin Zhao", 
    "publish": "1999-02-08T23:08:11Z", 
    "summary": "Digital libraries must reach out to users from all walks of life, serving\ninformation needs at all levels. To do this, they must attain high standards of\nusability over an extremely broad audience. This paper details the evolution of\none important digital library component as it has grown in functionality and\nusefulness over several years of use by a live, unrestricted community. Central\nto its evolution have been user studies, analysis of use patterns, and\nformative usability evaluation. We extrapolate that all three components are\nnecessary in the production of successful digital library systems."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2014.6210", 
    "link": "http://arxiv.org/pdf/cs/9902016v1", 
    "title": "Multimedia Description Framework (MDF) for Content Description of   Audio/Video Documents", 
    "arxiv-id": "cs/9902016v1", 
    "author": "Ye Jian", 
    "publish": "1999-02-09T02:17:19Z", 
    "summary": "MPEG is undertaking a new initiative to standardize content description of\naudio and video data/documents. When it is finalized in 2001, MPEG-7 is\nexpected to provide standardized description schemes for concise and\nunambiguous content description of data/documents of complex media types.\nMeanwhile, other meta-data or description schemes, such as Dublin Core, XML,\netc., are becoming popular in different application domains. In this paper, we\npropose the Multimedia Description Framework (MDF), which is designated to\naccommodate multiple description (meta-data) schemes, both MPEG-7 and\nnon-MPEG-7, into integrated architecture. We will use examples to show how MDF\ndescription makes use of combined strength of different description schemes to\nenhance its expression power and flexibility. We conclude the paper with\ndiscussion of using MDF description of a movie video to search/retrieve\nrequired scene clips from the movie, on the MDF prototype system we have\nimplemented."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2014.6210", 
    "link": "http://arxiv.org/pdf/cs/9902020v1", 
    "title": "Using Query Mediators for Distributed Searching in Federated Digital   Libraries", 
    "arxiv-id": "cs/9902020v1", 
    "author": "Carl Lagoze", 
    "publish": "1999-02-09T05:18:56Z", 
    "summary": "We describe an architecture and investigate the characteristics of\ndistributed searching in federated digital libraries. We introduce the notion\nof a query mediator as a digital library service responsible for selecting\namong available search engines, routing queries to those search engines, and\naggregating results. We examine operational data from the NCSTRL distributed\ndigital library that reveals a number of characteristics of distributed\nresource discovery. These include availability and response time of indexers\nand the distinction between the query mediator view of these characteristics\nand the indexer view."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2014.6210", 
    "link": "http://arxiv.org/pdf/cs/9902022v1", 
    "title": "Semi-Automatic Indexing of Multilingual Documents", 
    "arxiv-id": "cs/9902022v1", 
    "author": "Edberto Ferneda", 
    "publish": "1999-02-11T00:19:25Z", 
    "summary": "With the growing significance of digital libraries and the Internet, more and\nmore electronic texts become accessible to a wide and geographically disperse\npublic. This requires adequate tools to facilitate indexing, storage, and\nretrieval of documents written in different languages. We present a method for\nsemi-automatic indexing of electronic documents and construction of a\nmultilingual thesaurus, which can be used for query formulation and information\nretrieval. We use special dictionaries and user interaction in order to solve\nambiguities and find adequate canonical terms in the language and adequate\nabstract language-independent terms. The abstract thesaurus is updated\nincrementally by new indexed documents and is used to search document\nconcerning terms in a query to the document base."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2014.6210", 
    "link": "http://arxiv.org/pdf/cs/9902023v1", 
    "title": "A New Ranking Principle for Multimedia Information Retrieval", 
    "arxiv-id": "cs/9902023v1", 
    "author": "Peter Schauble", 
    "publish": "1999-02-11T12:33:12Z", 
    "summary": "A theoretic framework for multimedia information retrieval is introduced\nwhich guarantees optimal retrieval effectiveness. In particular, a Ranking\nPrinciple for Distributed Multimedia-Documents (RPDM) is described together\nwith an algorithm that satisfies this principle. Finally, the RPDM is shown to\nbe a generalization of the Probability Ranking principle (PRP) which guarantees\noptimal retrieval effectiveness in the case of text document retrieval. The PRP\njustifies theoretically the relevance ranking adopted by modern search engines.\nIn contrast to the classical PRP, the new RPDM takes into account transmission\nand inspection time, and most importantly, aspectual recall rather than simple\nrecall."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2014.6210", 
    "link": "http://arxiv.org/pdf/cs/0009004v1", 
    "title": "A usage based analysis of CoRR", 
    "arxiv-id": "cs/0009004v1", 
    "author": "Stevan Harnad", 
    "publish": "2000-09-13T13:02:04Z", 
    "summary": "Based on an empirical analysis of author usage of CoRR, and of its\npredecessor in the Los Alamos eprint archives, it is shown that CoRR has not\nyet been able to match the early growth of the Los Alamos physics archives.\nSome of the reasons are implicit in Halpern's paper, and we explore them\nfurther here. In particular we refer to the need to promote CoRR more\neffectively for its intended community - computer scientists in universities,\nindustrial research labs and in government. We take up some points of detail on\nthis new world of open archiving concerning central versus distributed\nself-archiving, publication, the restructuring of the journal publishers'\nniche, peer review and copyright."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2014.6210", 
    "link": "http://arxiv.org/pdf/cs/0101027v1", 
    "title": "Open Archives Initiative protocol development and implementation at   arXiv", 
    "arxiv-id": "cs/0101027v1", 
    "author": "Simeon Warner", 
    "publish": "2001-01-26T00:05:04Z", 
    "summary": "I outline the involvement of the Los Alamos e-print archive (arXiv) within\nthe Open Archives Initiative (OAI) and describe the implementation of the data\nprovider side of the OAI protocol v1.0. I highlight the ways in which we map\nthe existing structure of arXiv onto elements of the protocol."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2014.6210", 
    "link": "http://arxiv.org/pdf/cs/0106057v1", 
    "title": "Exposing and harvesting metadata using the OAI metadata harvesting   protocol: A tutorial", 
    "arxiv-id": "cs/0106057v1", 
    "author": "Simeon Warner", 
    "publish": "2001-06-28T23:08:20Z", 
    "summary": "In this article I outline the ideas behind the Open Archives Initiative\nmetadata harvesting protocol (OAIMH), and attempt to clarify some common\nmisconceptions. I then consider how the OAIMH protocol can be used to expose\nand harvest metadata. Perl code examples are given as practical illustration."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2014.6210", 
    "link": "http://arxiv.org/pdf/cs/0112017v1", 
    "title": "Using Structural Metadata to Localize Experience of Digital Content", 
    "arxiv-id": "cs/0112017v1", 
    "author": "Naomi Dushay", 
    "publish": "2001-12-14T18:55:11Z", 
    "summary": "With the increasing technical sophistication of both information consumers\nand providers, there is increasing demand for more meaningful experiences of\ndigital information. We present a framework that separates digital object\nexperience, or rendering, from digital object storage and manipulation, so the\nrendering can be tailored to particular communities of users. Our framework\nalso accommodates extensible digital object behaviors and interoperability. The\ntwo key components of our approach are 1) exposing structural metadata\nassociated with digital objects -- metadata about the labeled access points\nwithin a digital object and 2) information intermediaries called context\nbrokers that match structural characteristics of digital objects with\nmechanisms that produce behaviors. These context brokers allow for localized\nrendering of digital information stored externally."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2014.6210", 
    "link": "http://arxiv.org/pdf/cs/0201025v1", 
    "title": "Core Services in the Architecture of the National Digital Library for   Science Education (NSDL)", 
    "arxiv-id": "cs/0201025v1", 
    "author": "Tom Kalt", 
    "publish": "2002-01-29T17:51:15Z", 
    "summary": "We describe the core components of the architecture for the (NSDL) National\nScience, Mathematics, Engineering, and Technology Education Digital Library.\nOver time the NSDL will include heterogeneous users, content, and services. To\naccommodate this, a design for a technical and organization infrastructure has\nbeen formulated based on the notion of a spectrum of interoperability. This\npaper describes the first phase of the interoperability infrastructure\nincluding the metadata repository, search and discovery services, rights\nmanagement services, and user interface portal facilities."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2014.6210", 
    "link": "http://arxiv.org/pdf/cs/0201027v1", 
    "title": "Components of an NSDL Architecture: Technical Scope and Functional Model", 
    "arxiv-id": "cs/0201027v1", 
    "author": "Greg Janee", 
    "publish": "2002-01-30T01:14:35Z", 
    "summary": "We describe work leading toward specification of a technical architecture for\nthe National Science, Mathematics, Engineering, and Technology Education\nDigital Library (NSDL). This includes a technical scope and a functional model,\nwith some elaboration on the particularly rich set of library services that\nNSDL is expected eventually to encompass."
},{
    "category": "cs.DL", 
    "doi": "10.1117/12.461524", 
    "link": "http://arxiv.org/pdf/cs/0208012v1", 
    "title": "Online Scientific Data Curation, Publication, and Archiving", 
    "arxiv-id": "cs/0208012v1", 
    "author": "Jan vandenBerg", 
    "publish": "2002-08-07T22:42:31Z", 
    "summary": "Science projects are data publishers. The scale and complexity of current and\nfuture science data changes the nature of the publication process. Publication\nis becoming a major project component. At a minimum, a project must preserve\nthe ephemeral data it gathers. Derived data can be reconstructed from metadata,\nbut metadata is ephemeral. Longer term, a project should expect some archive to\npreserve the data. We observe that pub-lished scientific data needs to be\navailable forever ? this gives rise to the data pyramid of versions and to data\ninflation where the derived data volumes explode. As an example, this article\ndescribes the Sloan Digital Sky Survey (SDSS) strategies for data publication,\ndata access, curation, and preservation."
},{
    "category": "cs.DL", 
    "doi": "10.1117/12.461524", 
    "link": "http://arxiv.org/pdf/cs/0208039v1", 
    "title": "A Virtual Library of Technical Publications", 
    "arxiv-id": "cs/0208039v1", 
    "author": "Stephen Wolbers", 
    "publish": "2002-08-23T19:14:32Z", 
    "summary": "Through a collaborative effort, the Fermilab Information Resources Department\nand Computing Division have created a \"virtual library\" of technical\npublications that provides public access to electronic full-text documents.\nThis paper will discuss the vision, planning and milestones of the project, as\nwell as the hardware, software and interdepartmental cooperation components."
},{
    "category": "cs.DL", 
    "doi": "10.1117/12.461524", 
    "link": "http://arxiv.org/pdf/cs/0210029v1", 
    "title": "Integration and interoperability accessing electronic information   resources in science and technology: the proposal of Brazilian Digital   Library", 
    "arxiv-id": "cs/0210029v1", 
    "author": "Luis Fernando Sayao", 
    "publish": "2002-10-29T23:02:21Z", 
    "summary": "This paper describes technological and methodological options to achieve\ninteroperability in accessing electronic information resources, available in\nInternet, in the scope of Brazilian Digital Library in Science and Technology\nProject - BDL, developed by Brazilian Institute for Scientific and Technical\nInformation - IBICT. It stresses the impact of the Web in the publishing and\ncommunication processes in science and technology and also in the information\nsystems and libraries. The work points out the two major objectives of the BDL\nProject: facilitates electronic publishing of different full text materials\nsuch as theses, journal articles, conference papers,grey literature - by\nBrazilian scientific community, so amplifying their nationally and\ninternationally visibility; and achieving, through a unified gateway, thus\navoiding a user to navigate and query across different information resources\nindividually. The work explains technological options and standards that will\nassure interoperability in this context."
},{
    "category": "cs.DL", 
    "doi": "10.1108/07378830310479794", 
    "link": "http://arxiv.org/pdf/cs/0307008v1", 
    "title": "Eprints and the Open Archives Initiative", 
    "arxiv-id": "cs/0307008v1", 
    "author": "Simeon Warner", 
    "publish": "2003-07-04T03:33:49Z", 
    "summary": "The Open Archives Initiative (OAI) was created as a practical way to promote\ninteroperability between eprint repositories. Although the scope of the OAI has\nbeen broadened, eprint repositories still represent a significant fraction of\nOAI data providers. In this article I present a brief survey of OAI eprint\nrepositories, and of services using metadata harvested from eprint repositories\nusing the OAI protocol for metadata harvesting (OAI-PMH). I then discuss\nseveral situations where metadata harvesting may be used to further improve the\nutility of eprint archives as a component of the scholarly communication\ninfrastructure."
},{
    "category": "cs.DL", 
    "doi": "10.1108/07378830310479794", 
    "link": "http://arxiv.org/pdf/cs/0307049v1", 
    "title": "Limit groups and groups acting freely on $\\bbR^n$-trees", 
    "arxiv-id": "cs/0307049v1", 
    "author": "Vincent Guirardel", 
    "publish": "2003-07-21T14:31:57Z", 
    "summary": "We give a simple proof of the finite presentation of Sela's limit groups by\nusing free actions on $\\bbR^n$-trees. We first prove that Sela's limit groups\ndo have a free action on an $\\bbR^n$-tree. We then prove that a finitely\ngenerated group having a free action on an $\\bbR^n$-tree can be obtained from\nfree abelian groups and surface groups by a finite sequence of free products\nand amalgamations over cyclic groups. As a corollary, such a group is finitely\npresented, has a finite classifying space, its abelian subgroups are finitely\ngenerated and contains only finitely many conjugacy classes of non-cyclic\nmaximal abelian subgroups."
},{
    "category": "cs.DL", 
    "doi": "10.1108/07378830310479794", 
    "link": "http://arxiv.org/pdf/cs/0401028v1", 
    "title": "Automated Resolution of Noisy Bibliographic References", 
    "arxiv-id": "cs/0401028v1", 
    "author": "Steven S. Murray", 
    "publish": "2004-01-27T10:09:54Z", 
    "summary": "We describe a system used by the NASA Astrophysics Data System to identify\nbibliographic references obtained from scanned article pages by OCR methods\nwith records in a bibliographic database. We analyze the process generating the\nnoisy references and conclude that the three-step procedure of correcting the\nOCR results, parsing the corrected string and matching it against the database\nprovides unsatisfactory results. Instead, we propose a method that allows a\ncontrolled merging of correction, parsing and matching, inspired by dependency\ngrammars. We also report on the effectiveness of various heuristics that we\nhave employed to improve recall."
},{
    "category": "cs.DL", 
    "doi": "10.1108/07378830310479794", 
    "link": "http://arxiv.org/pdf/cs/0401029v1", 
    "title": "Dynamic Linking of Smart Digital Objects Based on User Navigation   Patterns", 
    "arxiv-id": "cs/0401029v1", 
    "author": "Michael L. Nelson", 
    "publish": "2004-01-28T00:45:53Z", 
    "summary": "We discuss a methodology to dynamically generate links among digital objects\nby means of an unsupervised learning mechanism which analyzes user link\ntraversal patterns. We performed an experiment with a test bed of 150 complex\ndata objects, referred to as buckets. Each bucket manages its own content,\nprovides methods to interact with users and individually maintains a set of\nlinks to other buckets. We demonstrate that buckets were capable of dynamically\nadjusting their links to other buckets according to user link selections,\nthereby generating a meaningful network of bucket relations. Our results\nindicate such adaptive networks of linked buckets approximate the collective\nlink preferences of a community of user"
},{
    "category": "cs.DL", 
    "doi": "10.1108/07378830310479794", 
    "link": "http://arxiv.org/pdf/cs/0411077v1", 
    "title": "Transparent Format Migration of Preserved Web Content", 
    "arxiv-id": "cs/0411077v1", 
    "author": "Seth Morabito", 
    "publish": "2004-11-22T00:35:30Z", 
    "summary": "The LOCKSS digital preservation system collects content by crawling the web\nand preserves it in the format supplied by the publisher. Eventually, browsers\nwill no longer understand that format. A process called format migration\nconverts it to a newer format that the browsers do understand. The LOCKSS\nprogram has designed and tested an initial implementation of format migration\nfor Web content that is transparent to readers, building on the content\nnegotiation capabilities of HTTP."
},{
    "category": "cs.DL", 
    "doi": "10.1108/07378830310479794", 
    "link": "http://arxiv.org/pdf/cs/0411078v1", 
    "title": "Notes On The Design Of An Internet Adversary", 
    "arxiv-id": "cs/0411078v1", 
    "author": "Mary Baker", 
    "publish": "2004-11-22T00:22:23Z", 
    "summary": "The design of the defenses Internet systems can deploy against attack,\nespecially adaptive and resilient defenses, must start from a realistic model\nof the threat. This requires an assessment of the capabilities of the\nadversary. The design typically evolves through a process of simulating both\nthe system and the adversary. This requires the design and implementation of a\nsimulated adversary based on the capability assessment. Consensus on the\ncapabilities of a suitable adversary is not evident. Part of the recent\nredesign of the protocol used by peers in the LOCKSS digital preservation\nsystem included a conservative assessment of the adversary's capabilities. We\npresent our assessment and the implications we drew from it as a step towards a\nreusable adversary specification."
},{
    "category": "cs.DL", 
    "doi": "10.1108/07378830310479794", 
    "link": "http://arxiv.org/pdf/cs/0411091v2", 
    "title": "Principles for Digital Preservation", 
    "arxiv-id": "cs/0411091v2", 
    "author": "H. M. Gladney", 
    "publish": "2004-11-24T20:54:43Z", 
    "summary": "The immense investments in creating and disseminating digitally represented\ninformation have not been accompanied by commensurate effort to ensure the\nlongevity of information of permanent interest. Asserted difficulties with\nlong-term digital preservation prove to be largely underestimation of what\ntechnology can provide. We show how to clarify prominent misunderstandings and\nsketch a 'Trustworthy Digital Object (TDO)' method that solves all the\npublished technical challenges."
},{
    "category": "cs.DL", 
    "doi": "10.1108/07378830310479794", 
    "link": "http://arxiv.org/pdf/cs/0411092v1", 
    "title": "Trustworthy 100-Year Digital Objects: Durable Encoding for When It's Too   Late to Ask", 
    "arxiv-id": "cs/0411092v1", 
    "author": "R. A. Lorie", 
    "publish": "2004-11-24T21:26:13Z", 
    "summary": "How can an author store digital information so that it will be reliably\nuseful, even years later when he is no longer available to answer questions?\nMethods that might work are not good enough; what is preserved today should be\nreliably useful whenever someone wants it. Prior proposals fail because they\nconfound saved data with irrelevant details of today's information\ntechnology--details that are difficult to define, extract, and save completely\nand accurately.\n  We use a virtual machine to represent and eventually to render any data\nwhatsoever. We focus on a case of intermediate difficulty--an executable\nprocedure--and identify a variant for every other data type. This solution\nmight be more elaborate than needed to render some text, image, audio, or video\ndata. Simple data can be preserved as representations using well-known\nstandards. We sketch practical methods for files ranging from simple structures\nto those containing computer programs, treating simple cases here and deferring\ncomplex cases for future work. Enough of the complete solution is known to\nenable practical aggressive preservation programs today."
},{
    "category": "cs.DL", 
    "doi": "10.1108/07378830310479794", 
    "link": "http://arxiv.org/pdf/cs/0412001v1", 
    "title": "EURYDICE : A platform for unified access to documents", 
    "arxiv-id": "cs/0412001v1", 
    "author": "Catherine Allauzun", 
    "publish": "2004-12-01T13:14:51Z", 
    "summary": "In this paper we present Eurydice, a platform dedicated to provide a unified\ngateway to documents. Its basic functionalities about collecting documents have\nbeen designed based on a long experience about the management of scientific\ndocumentation among large and demanding academic communities such as IMAG and\nINRIA. Besides the basic problem of accessing documents - which was of course\nthe original and main motivation of the project - a great effort has been\ndedicated to the development of management functionalities which could help\ninstitutions to control, analyse the current situation about the use of the\ndocumentation, and finally to set a better ground for a documentation policy.\nFinally a great emphasis - and corresponding technical investment - has been\nput on the protection of property and reproduction rights both from the users'\nintitution side and from the editors' side."
},{
    "category": "cs.DL", 
    "doi": "10.1108/07378830310479794", 
    "link": "http://arxiv.org/pdf/cs/0501080v2", 
    "title": "An Information Network Overlay Architecture for the NSDL", 
    "arxiv-id": "cs/0501080v2", 
    "author": "Eddie Shin", 
    "publish": "2005-01-27T19:49:11Z", 
    "summary": "We describe the underlying data model and implementation of a new\narchitecture for the National Science Digital Library (NSDL) by the Core\nIntegration Team (CI). The architecture is based on the notion of an\ninformation network overlay. This network, implemented as a graph of digital\nobjects in a Fedora repository, allows the representation of multiple\ninformation entities and their relationships. The architecture provides the\nframework for contextualization and reuse of resources, which we argue is\nessential for the utility of the NSDL as a tool for teaching and learning."
},{
    "category": "cs.DL", 
    "doi": "10.1108/07378830310479794", 
    "link": "http://arxiv.org/pdf/cs/0501083v1", 
    "title": "Orchestrating Metadata Enhancement Services: Introducing Lenny", 
    "arxiv-id": "cs/0501083v1", 
    "author": "Gordon Paynter", 
    "publish": "2005-01-28T18:44:23Z", 
    "summary": "Harvested metadata often suffers from uneven quality to the point that\nutility is compromised. Although some aggregators have developed methods for\nevaluating and repairing specific metadata problems, it has been unclear how\nthese methods might be scaled into services that can be used within an\nautomated production environment. The National Science Digital Library (NSDL),\nas part of its work with INFOMINE, has developed a model of ser-vice\ninteraction that enables loosely-coupled third party services to provide\nmetadata enhancements to a central repository, with interactions orchestrated\nby a centralized software application."
},{
    "category": "cs.DL", 
    "doi": "10.1108/07378830310479794", 
    "link": "http://arxiv.org/pdf/cs/0502028v1", 
    "title": "aDORe: a modular, standards-based Digital Object Repository", 
    "arxiv-id": "cs/0502028v1", 
    "author": "Thorsten Schwander", 
    "publish": "2005-02-04T22:09:14Z", 
    "summary": "This paper describes the aDORe repository architecture, designed and\nimplemented for ingesting, storing, and accessing a vast collection of Digital\nObjects at the Research Library of the Los Alamos National Laboratory. The\naDORe architecture is highly modular and standards-based. In the architecture,\nthe MPEG-21 Digital Item Declaration Language is used as the XML-based format\nto represent Digital Objects that can consist of multiple datastreams as Open\nArchival Information System Archival Information Packages (OAIS AIPs).Through\nan ingestion process, these OAIS AIPs are stored in a multitude of autonomous\nrepositories. A Repository Index keeps track of the creation and location of\nall the autonomous repositories, whereas an Identifier Locator registers in\nwhich autonomous repository a given Digital Object or OAIS AIP resides. A\nfront-end to the complete environment, the OAI-PMH Federator, is introduced for\nrequesting OAIS Dissemination Information Packages (OAIS DIPs). These OAIS DIPs\ncan be the stored OAIS AIPs themselves, or transformations thereof. This\nfront-end allows OAI-PMH harvesters to recurrently and selectively collect\nbatches of OAIS DIPs from aDORe, and hence to create multiple, parallel\nservices using the collected objects. Another front-end, the OpenURL Resolver,\nis introduced for requesting OAIS Result Sets. An OAIS Result Set is a\ndissemination of an individual Digital Object or of its constituent\ndatastreams. Both front-ends make use of an MPEG-21 Digital Item Processing\nEngine to apply services to OAIS AIPs, Digital Objects, or constituent\ndatastreams that were specified in a dissemination request."
},{
    "category": "cs.DL", 
    "doi": "10.1108/07378830310479794", 
    "link": "http://arxiv.org/pdf/cs/0502056v2", 
    "title": "Co-Authorship Networks in the Digital Library Research Community", 
    "arxiv-id": "cs/0502056v2", 
    "author": "Herbert Van de Sompel", 
    "publish": "2005-02-12T00:08:57Z", 
    "summary": "The field of digital libraries (DLs) coalesced in 1994: the first digital\nlibrary conferences were held that year, awareness of the World Wide Web was\naccelerating, and the National Science Foundation awarded $24 Million (U.S.)\nfor the Digital Library Initiative (DLI). In this paper we examine the state of\nthe DL domain after a decade of activity by applying social network analysis to\nthe co-authorship network of the past ACM, IEEE, and joint ACM/IEEE digital\nlibrary conferences. We base our analysis on a common binary undirectional\nnetwork model to represent the co-authorship network, and from it we extract\nseveral established network measures. We also introduce a weighted directional\nnetwork model to represent the co-authorship network, for which we define\n$AuthorRank$ as an indicator of the impact of an individual author in the\nnetwork. The results are validated against conference program committee members\nin the same period. The results show clear advantages of PageRank and\nAuthorRank over degree, closeness and betweenness centrality metrics. We also\ninvestigate the amount and nature of international participation in Joint\nConference on Digital Libraries (JCDL)."
},{
    "category": "cs.DL", 
    "doi": "10.1108/07378830310479794", 
    "link": "http://arxiv.org/pdf/cs/0503007v1", 
    "title": "Toward alternative metrics of journal impact: A comparison of download   and citation data", 
    "arxiv-id": "cs/0503007v1", 
    "author": "Rick Luce", 
    "publish": "2005-03-03T05:14:47Z", 
    "summary": "We generated networks of journal relationships from citation and download\ndata, and determined journal impact rankings from these networks using a set of\nsocial network centrality metrics. The resulting journal impact rankings were\ncompared to the ISI IF. Results indicate that, although social network metrics\nand ISI IF rankings deviate moderately for citation-based journal networks,\nthey differ considerably for journal networks derived from download data. We\nbelieve the results represent a unique aspect of general journal impact that is\nnot captured by the ISI IF. These results furthermore raise questions regarding\nthe validity of the ISI IF as the sole assessment of journal impact, and\nsuggest the possibility of devising impact metrics based on usage information\nin general."
},{
    "category": "cs.DL", 
    "doi": "10.1108/07378830310479794", 
    "link": "http://arxiv.org/pdf/cs/0503016v2", 
    "title": "File-based storage of Digital Objects and constituent datastreams:   XMLtapes and Internet Archive ARC files", 
    "arxiv-id": "cs/0503016v2", 
    "author": "Herbert Van de Sompel", 
    "publish": "2005-03-07T23:17:23Z", 
    "summary": "This paper introduces the write-once/read-many XMLtape/ARC storage approach\nfor Digital Objects and their constituent datastreams. The approach combines\ntwo interconnected file-based storage mechanisms that are made accessible in a\nprotocol-based manner. First, XML-based representations of multiple Digital\nObjects are concatenated into a single file named an XMLtape. An XMLtape is a\nvalid XML file; its format definition is independent of the choice of the\nXML-based complex object format by which Digital Objects are represented. The\ncreation of indexes for both the identifier and the creation datetime of the\nXML-based representation of the Digital Objects facilitates OAI-PMH-based\naccess to Digital Objects stored in an XMLtape. Second, ARC files, as\nintroduced by the Internet Archive, are used to contain the constituent\ndatastreams of the Digital Objects in a concatenated manner. An index for the\nidentifier of the datastream facilitates OpenURL-based access to an ARC file.\nThe interconnection between XMLtapes and ARC files is provided by conveying the\nidentifiers of ARC files associated with an XMLtape as administrative\ninformation in the XMLtape, and by including OpenURL references to constituent\ndatastreams of a Digital Object in the XML-based representation of that Digital\nObject."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ipm.2005.03.010", 
    "link": "http://arxiv.org/pdf/cs/0503029v1", 
    "title": "The Effect of Use and Access on Citations", 
    "arxiv-id": "cs/0503029v1", 
    "author": "Stephen S. Murray", 
    "publish": "2005-03-14T16:44:37Z", 
    "summary": "It has been shown (S. Lawrence, 2001, Nature, 411, 521) that journal articles\nwhich have been posted without charge on the internet are more heavily cited\nthan those which have not been. Using data from the NASA Astrophysics Data\nSystem (ads.harvard.edu) and from the ArXiv e-print archive at Cornell\nUniversity (arXiv.org) we examine the causes of this effect."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ipm.2005.03.010", 
    "link": "http://arxiv.org/pdf/cs/0503069v1", 
    "title": "mod_oai: An Apache Module for Metadata Harvesting", 
    "arxiv-id": "cs/0503069v1", 
    "author": "Nathan McFarland", 
    "publish": "2005-03-24T14:38:26Z", 
    "summary": "We describe mod_oai, an Apache 2.0 module that implements the Open Archives\nInitiative Protocol for Metadata Harvesting (OAI-PMH). OAIPMH is the de facto\nstandard for metadata exchange in digital libraries and allows repositories to\nexpose their contents in a structured, application-neutral format with\nsemantics optimized for accurate incremental harvesting. Current\nimplementations of OAI-PMH are either separate applications that access an\nexisting repository, or are built-in to repository software packages. mod_oai\nis different in that it optimizes harvesting web content by building OAI-PMH\ncapability into the Apache server. We discuss the implications of adding\nharvesting capability to an Apache server and describe our initial experimental\nresults accessing a departmental web site using both web crawling and OAIPMH\nharvesting techniques."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ipm.2005.03.010", 
    "link": "http://arxiv.org/pdf/cs/0506010v1", 
    "title": "The OAI Data-Provider Registration and Validation Service", 
    "arxiv-id": "cs/0506010v1", 
    "author": "Simeon Warner", 
    "publish": "2005-06-03T17:15:04Z", 
    "summary": "I present a summary of recent use of the Open Archives Initiative (OAI)\nregistration and validation services for data-providers. The registration\nservice has seen a steady stream of registrations since its launch in 2002, and\nthere are now over 220 registered repositories. I examine the validation logs\nto produce a breakdown of reasons why repositories fail validation. This\nbreakdown highlights some common problems and will be used to guide work to\nimprove the validation service."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ipm.2005.03.010", 
    "link": "http://arxiv.org/pdf/cs/0506046v1", 
    "title": "Dictionaries merger for text expansion in question answering", 
    "arxiv-id": "cs/0506046v1", 
    "author": "Bernard Jacquemin", 
    "publish": "2005-06-12T16:36:47Z", 
    "summary": "This paper presents an original way to add new data in a reference dictionary\nfrom several other lexical resources, without loosing any consistence. This\noperation is carried in order to get lexical information classified by the\nsense of the entry. This classification makes it possible to enrich utterances\n(in QA: the queries) following the meaning, and to reduce noise. An analysis of\nthe experienced problems shows the interest of this method, and insists on the\npoints that have to be tackled."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ipm.2005.03.010", 
    "link": "http://arxiv.org/pdf/cs/0506049v1", 
    "title": "Exploitation de dictionnaires \u00e9lectroniques pour la   d\u00e9sambigu\u00efsation s\u00e9mantique lexicale", 
    "arxiv-id": "cs/0506049v1", 
    "author": "Fr\u00e9d\u00e9rique Segond", 
    "publish": "2005-06-12T16:48:33Z", 
    "summary": "This paper presents a lexical disambiguation system, initially developed for\nEnglish and now adapted to French. This system associates a word with its\nmeaning in a given context using electronic dictionaries as semantically\nannotated corpora in order to extract semantic disambiguation rules. We\ndescribe the rule extraction and application process as well as the evaluation\nof the system. The results for French give us insight information on some\npossible improvments of the nature and content of lexical resources adapted for\ndisambiguation in this framework."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ipm.2005.03.010", 
    "link": "http://arxiv.org/pdf/cs/0509018v2", 
    "title": "Requirements for Digital Preservation Systems: A Bottom-Up Approach", 
    "arxiv-id": "cs/0509018v2", 
    "author": "Seth Morabito", 
    "publish": "2005-09-06T19:26:08Z", 
    "summary": "The field of digital preservation is being defined by a set of standards\ndeveloped top-down, starting with an abstract reference model (OAIS) and\ngradually adding more specific detail. Systems claiming conformance to these\nstandards are entering production use. Work is underway to certify that systems\nconform to requirements derived from OAIS.\n  We complement these requirements derived top-down by presenting an alternate,\nbottom-up view of the field. The fundamental goal of these systems is to ensure\nthat the information they contain remains accessible for the long term. We\ndevelop a parallel set of requirements based on observations of how existing\nsystems handle this task, and on an analysis of the threats to achieving the\ngoal. On this basis we suggest disclosures that systems should provide as to\nhow they satisfy their goals."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ipm.2005.03.010", 
    "link": "http://arxiv.org/pdf/cs/0509084v1", 
    "title": "Representing Digital Assets for Long-Term Preservation using MPEG-21 DID", 
    "arxiv-id": "cs/0509084v1", 
    "author": "Herbert Van de Sompel", 
    "publish": "2005-09-27T19:05:39Z", 
    "summary": "Various efforts aimed at representing digital assets have emerged from\nseveral communities over the last years, including the Metadata Encoding and\nTransmission Standard (METS), the IMS Content Packaging (IMS-CP) XML Binding\nand the XML Formatted Data Units (XFDU). The MPEG-21 Digital Item Declaration\n(MPEG-21 DID) is another approach that can be used for the representation of\ndigital assets in XML. This paper will explore the potential of the MPEG-21 DID\nin a Digital Preservation context, by looking at the core building blocks of\nthe OAIS Information Model and the way in which they map to the MPEG-21 DID\nabstract model and the MPEG-21 DIDL XML syntax."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ipm.2005.03.010", 
    "link": "http://arxiv.org/pdf/cs/0509090v1", 
    "title": "Access Interfaces for Open Archival Information Systems based on the   OAI-PMH and the OpenURL Framework for Context-Sensitive Services", 
    "arxiv-id": "cs/0509090v1", 
    "author": "Herbert Van de Sompel", 
    "publish": "2005-09-28T14:57:38Z", 
    "summary": "In recent years, a variety of digital repository and archival systems have\nbeen developed and adopted. All of these systems aim at hosting a variety of\ncompound digital assets and at providing tools for storing, managing and\naccessing those assets. This paper will focus on the definition of common and\nstandardized access interfaces that could be deployed across such diverse\ndigital respository and archival systems. The proposed interfaces are based on\nthe two formal specifications that have recently emerged from the Digital\nLibrary community: The Open Archive Initiative Protocol for Metadata Harvesting\n(OAI-PMH) and the NISO OpenURL Framework for Context-Sensitive Services\n(OpenURL Standard). As will be described, the former allows for the retrieval\nof batches of XML-based representations of digital assets, while the latter\nfacilitates the retrieval of disseminations of a specific digital asset or of\none or more of its constituents. The core properties of the proposed interfaces\nare explained in terms of the Reference Model for an Open Archival Information\nSystem (OAIS)."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ipm.2005.03.010", 
    "link": "http://arxiv.org/pdf/cs/0511077v1", 
    "title": "The Availability and Persistence of Web References in D-Lib Magazine", 
    "arxiv-id": "cs/0511077v1", 
    "author": "Johan Bollen", 
    "publish": "2005-11-21T15:56:17Z", 
    "summary": "We explore the availability and persistence of URLs cited in articles\npublished in D-Lib Magazine. We extracted 4387 unique URLs referenced in 453\narticles published from July 1995 to August 2004. The availability was checked\nthree times a week for 25 weeks from September 2004 to February 2005. We found\nthat approximately 28% of those URLs failed to resolve initially, and 30%\nfailed to resolve at the last check. A majority of the unresolved URLs were due\nto 404 (page not found) and 500 (internal server error) errors. The content\npointed to by the URLs was relatively stable; only 16% of the content\nregistered more than a 1 KB change during the testing period. We explore\npossible factors which may cause a URL to fail by examining its age, path\ndepth, top-level domain and file extension. Based on the data collected, we\nfound the half-life of a URL referenced in a D-Lib Magazine article is\napproximately 10 years. We also found that URLs were more likely to be\nunavailable if they pointed to resources in the .net, .edu or country-specific\ntop-level domain, used non-standard ports (i.e., not port 80), or pointed to\nresources with uncommon or deprecated extensions (e.g., .shtml, .ps, .txt)."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ipm.2005.03.010", 
    "link": "http://arxiv.org/pdf/cs/0512068v1", 
    "title": "Dynamic Web File Format Transformations with Grace", 
    "arxiv-id": "cs/0512068v1", 
    "author": "Michael L. Nelson", 
    "publish": "2005-12-16T17:21:57Z", 
    "summary": "Web accessible content stored in obscure, unpopular or obsolete formats\nrepresents a significant problem for digital preservation. The file formats\nthat encode web content represent the implicit and explicit choices of web site\nmaintainers at a particular point in time. Older file formats that have fallen\nout of favor are obviously a problem, but so are new file formats that have not\nyet been fully supported by browsers. Often browsers use plug-in software for\ndisplaying old and new formats, but plug-ins can be difficult to find, install\nand replicate across all environments that one may use. We introduce Grace, an\nhttp proxy server that transparently converts browser-incompatible and obsolete\nweb content into web content that a browser is able to display without the use\nof plug-ins. Grace is configurable on a per user basis and can be expanded to\nprovide an array of conversion services. We illustrate how the Grace prototype\ntransforms several image formats (XBM, PNG with various alpha channels, and\nJPEG 2000) so they are viewable in Internet Explorer."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ipm.2005.03.010", 
    "link": "http://arxiv.org/pdf/cs/0601125v1", 
    "title": "Metadata aggregation and \"automated digital libraries\": A retrospective   on the NSDL experience", 
    "arxiv-id": "cs/0601125v1", 
    "author": "John Saylor", 
    "publish": "2006-01-30T12:26:53Z", 
    "summary": "Over three years ago, the Core Integration team of the National Science\nDigital Library (NSDL) implemented a digital library based on metadata\naggregation using Dublin Core and OAI-PMH. The initial expectation was that\nsuch low-barrier technologies would be relatively easy to automate and\nadminister. While this architectural choice permitted rapid deployment of a\nproduction NSDL, our three years of experience have contradicted our original\nexpectations of easy automation and low people cost. We have learned that\nalleged \"low-barrier\" standards are often harder to deploy than expected. In\nthis paper we report on this experience and comment on the general cost, the\nfunctionality, and the ultimate effectiveness of this architecture."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ipm.2005.03.010", 
    "link": "http://arxiv.org/pdf/cs/0602059v1", 
    "title": "D2D: Digital Archive to MPEG-21 DIDL", 
    "arxiv-id": "cs/0602059v1", 
    "author": "Michael L. Nelson", 
    "publish": "2006-02-15T22:18:38Z", 
    "summary": "Digital Archive to MPEG-21 DIDL (D2D) analyzes the contents of the digital\narchive and produces an MPEG-21 Digital Item Declaration Language (DIDL)\nencapsulating the analysis results. DIDL is an extensible XML-based language\nthat aggregates resources and the metadata. We provide a brief report on\nseveral analysis techniques applied on the digital archive by the D2D and\nprovide an evaluation of its run-time performance."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ipm.2005.03.010", 
    "link": "http://arxiv.org/pdf/cs/0603024v1", 
    "title": "Representing Contextualized Information in the NSDL", 
    "arxiv-id": "cs/0603024v1", 
    "author": "Chris Wilper", 
    "publish": "2006-03-07T15:50:22Z", 
    "summary": "The NSDL (National Science Digital Library) is funded by the National Science\nFoundation to advance science and match education. The inital product was a\nmetadata-based digital library providing search and access to distributed\nresources. Our recent work recognizes the importance of context - relations,\nmetadata, annotations - for the pedagogical value of a digital library. This\nnew architecture uses Fedora, a tool for representing complex content, data,\nmetadata, web-based services, and semantic relationships, as the basis of an\ninformation network overlay (INO). The INO provides an extensible knowl-edge\nbase for an expanding suite of digital library services."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ipm.2005.03.010", 
    "link": "http://arxiv.org/pdf/cs/0605022v1", 
    "title": "Toward a Collection-based Metadata Maintenance Model", 
    "arxiv-id": "cs/0605022v1", 
    "author": "Jim LeBlanc", 
    "publish": "2006-05-05T18:16:22Z", 
    "summary": "In this paper, the authors identify key entities and relationships in the\noperational management of metadata catalogs that describe digital collections,\nand they draft a data model to support the administration of metadata\nmaintenance for collections. Further, they consider this proposed model in\nlight of other data schemes to which it relates and discuss the implications of\nthe model for library metadata maintenance operations."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ipm.2005.03.010", 
    "link": "http://arxiv.org/pdf/cs/0605111v1", 
    "title": "A Metadata Registry from Vocabularies UP: The NSDL Registry Project", 
    "arxiv-id": "cs/0605111v1", 
    "author": "Ryan Laundry", 
    "publish": "2006-05-24T16:51:43Z", 
    "summary": "The NSDL Metadata Registry is designed to provide humans and machines with\nthe means to discover, create, access and manage metadata schemes, schemas,\napplication profiles, crosswalks and concept mappings. This paper describes the\ngeneral goals and architecture of the NSDL Metadata Registry as well as issues\nencountered during the first year of the project's implementation."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ipm.2005.03.010", 
    "link": "http://arxiv.org/pdf/cs/0605113v1", 
    "title": "An Architecture for the Aggregation and Analysis of Scholarly Usage Data", 
    "arxiv-id": "cs/0605113v1", 
    "author": "Herbert Van de Sompel", 
    "publish": "2006-05-24T18:06:49Z", 
    "summary": "Although recording of usage data is common in scholarly information services,\nits exploitation for the creation of value-added services remains limited due\nto concerns regarding, among others, user privacy, data validity, and the lack\nof accepted standards for the representation, sharing and aggregation of usage\ndata. This paper presents a technical, standards-based architecture for sharing\nusage information, which we have designed and implemented. In this\narchitecture, OpenURL-compliant linking servers aggregate usage information of\na specific user community as it navigates the distributed information\nenvironment that it has access to. This usage information is made OAI-PMH\nharvestable so that usage information exposed by many linking servers can be\naggregated to facilitate the creation of value-added services with a reach\nbeyond that of a single community or a single information service. This paper\nalso discusses issues that were encountered when implementing the proposed\napproach, and it presents preliminary results obtained from analyzing a usage\ndata set containing about 3,500,000 requests aggregated by a federation of\nlinking servers at the California State University system over a 20 month\nperiod."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ipm.2005.03.010", 
    "link": "http://arxiv.org/pdf/cs/0606008v2", 
    "title": "Repository Replication Using NNTP and SMTP", 
    "arxiv-id": "cs/0606008v2", 
    "author": "Michael L. Nelson", 
    "publish": "2006-06-01T17:45:36Z", 
    "summary": "We present the results of a feasibility study using shared, existing,\nnetwork-accessible infrastructure for repository replication. We investigate\nhow dissemination of repository contents can be ``piggybacked'' on top of\nexisting email and Usenet traffic. Long-term persistence of the replicated\nrepository may be achieved thanks to current policies and procedures which\nensure that mail messages and news posts are retrievable for evidentiary and\nother legal purposes for many years after the creation date. While the\npreservation issues of migration and emulation are not addressed with this\napproach, it does provide a simple method of refreshing content with unknown\npartners."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ipm.2005.03.010", 
    "link": "http://arxiv.org/pdf/cs/0606079v2", 
    "title": "Ten-Year Cross-Disciplinary Comparison of the Growth of Open Access and   How it Increases Research Citation Impact", 
    "arxiv-id": "cs/0606079v2", 
    "author": "Y. Gingras", 
    "publish": "2006-06-18T19:51:18Z", 
    "summary": "Lawrence (2001)found computer science articles that were openly accessible\n(OA) on the Web were cited more. We replicated this in physics. We tested\n1,307,038 articles published across 12 years (1992-2003) in 10 disciplines\n(Biology, Psychology, Sociology, Health, Political Science, Economics,\nEducation, Law, Business, Management). A robot trawls the Web for full-texts\nusing reference metadata ISI citation data (signal detectability d'=2.45; bias\n= 0.52). Percentage OA (relative to total OA + NOA) articles varies from 5%-16%\n(depending on discipline, year and country) and is slowly climbing annually\n(correlation r=.76, sample size N=12, probability p < 0.005). Comparing OA and\nNOA articles in the same journal/year, OA articles have consistently more\ncitations, the advantage varying from 36%-172% by discipline and year.\nComparing articles within six citation ranges (0, 1, 2-3, 4-7, 8-15, 16+\ncitations), the annual percentage of OA articles is growing significantly\nfaster than NOA within every citation range (r > .90, N=12, p < .0005) and the\neffect is greater with the more highly cited articles (r = .98, N=6, p < .005).\nCausality cannot be determined from these data, but our prior finding of a\nsimilar pattern in physics, where percent OA is much higher (and even\napproaches 100% in some subfields), makes it unlikely that the OA citation\nadvantage is merely or mostly a self-selection bias (for making only one's\nbetter articles OA). Further research will analyze the effect's timing, causal\ncomponents and relation to other variables."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ipm.2005.03.010", 
    "link": "http://arxiv.org/pdf/cs/0607066v1", 
    "title": "Generalized h-index for Disclosing Latent Facts in Citation Networks", 
    "arxiv-id": "cs/0607066v1", 
    "author": "Yannis Manolopoulos", 
    "publish": "2006-07-13T15:47:25Z", 
    "summary": "What is the value of a scientist and its impact upon the scientific thinking?\nHow can we measure the prestige of a journal or of a conference? The evaluation\nof the scientific work of a scientist and the estimation of the quality of a\njournal or conference has long attracted significant interest, due to the\nbenefits from obtaining an unbiased and fair criterion. Although it appears to\nbe simple, defining a quality metric is not an easy task. To overcome the\ndisadvantages of the present metrics used for ranking scientists and journals,\nJ.E. Hirsch proposed a pioneering metric, the now famous h-index. In this\narticle, we demonstrate several inefficiencies of this index and develop a pair\nof generalizations and effective variants of it to deal with scientist ranking\nand with publication forum ranking. The new citation indices are able to\ndisclose trendsetters in scientific research, as well as researchers that\nconstantly shape their field with their influential work, no matter how old\nthey are. We exhibit the effectiveness and the benefits of the new indices to\nunfold the full potential of the h-index, with extensive experimental results\nobtained from DBLP, a widely known on-line digital library."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ipm.2005.03.010", 
    "link": "http://arxiv.org/pdf/cs/0608052v10", 
    "title": "GDF - A general dataformat for biosignals", 
    "arxiv-id": "cs/0608052v10", 
    "author": "Alois Schl\u00f6gl", 
    "publish": "2006-08-11T15:13:34Z", 
    "summary": "Biomedical signals are stored in many different data formats. Most formats\nhave been developed for a specific purpose of a specialized community for ECG\nresearch, EEG analysis, sleep research, etc. So far none of the existing\nformats can be considered a general purpose data format for biomedical signals.\nIn order to solve this problem and to unify the various needs of the various\nbiomedical signal processing fields, the so-called \"General Data Format for\nbiomedical signals\" (GDF) is developed. This GDF format is fully described and\nspecified. Software for reading and writing GDF data is implemented in\nOctave/Matlab and C/C++ and provided through BioSig - an free and open source\nsoftware library for biomedical signal processing. BioSig privides also\nconverters from various data formats to GDF, and a viewing and scoring\nsoftware."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s00799-007-0016-7", 
    "link": "http://arxiv.org/pdf/cs/0610031v1", 
    "title": "Pathways: Augmenting interoperability across scholarly repositories", 
    "arxiv-id": "cs/0610031v1", 
    "author": "Herbert Van de Sompel", 
    "publish": "2006-10-05T19:55:09Z", 
    "summary": "In the emerging eScience environment, repositories of papers, datasets,\nsoftware, etc., should be the foundation of a global and natively-digital\nscholarly communications system. The current infrastructure falls far short of\nthis goal. Cross-repository interoperability must be augmented to support the\nmany workflows and value-chains involved in scholarly communication. This will\nnot be achieved through the promotion of single repository architecture or\ncontent representation, but instead requires an interoperability framework to\nconnect the many heterogeneous systems that will exist.\n  We present a simple data model and service architecture that augments\nrepository interoperability to enable scholarly value-chains to be implemented.\nWe describe an experiment that demonstrates how the proposed infrastructure can\nbe deployed to implement the workflow involved in the creation of an overlay\njournal over several different repository systems (Fedora, aDORe, DSpace and\narXiv)."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s00799-007-0016-7", 
    "link": "http://arxiv.org/pdf/cs/0610056v1", 
    "title": "Constructing experimental indicators for Open Access documents", 
    "arxiv-id": "cs/0610056v1", 
    "author": "Philipp Mayr", 
    "publish": "2006-10-11T07:10:52Z", 
    "summary": "The ongoing paradigm change in the scholarly publication system ('science is\nturning to e-science') makes it necessary to construct alternative evaluation\ncriteria/metrics which appropriately take into account the unique\ncharacteristics of electronic publications and other research output in digital\nformats. Today, major parts of scholarly Open Access (OA) publications and the\nself-archiving area are not well covered in the traditional citation and\nindexing databases. The growing share and importance of freely accessible\nresearch output demands new approaches/metrics for measuring and for evaluating\nof these new types of scientific publications. In this paper we propose a\nsimple quantitative method which establishes indicators by measuring the\naccess/download pattern of OA documents and other web entities of a single web\nserver. The experimental indicators (search engine, backlink and direct access\nindicator) are constructed based on standard local web usage data. This new\ntype of web-based indicator is developed to model the specific demand for\nbetter study/evaluation of the accessibility, visibility and interlinking of\nopen accessible documents. We conclude that e-science will need new stable\ne-indicators."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s00799-007-0016-7", 
    "link": "http://arxiv.org/pdf/cs/0610154v2", 
    "title": "Usage Impact Factor: the effects of sample characteristics on   usage-based impact metrics", 
    "arxiv-id": "cs/0610154v2", 
    "author": "Herbert Van de Sompel", 
    "publish": "2006-10-26T16:39:53Z", 
    "summary": "There exist ample demonstrations that indicators of scholarly impact\nanalogous to the citation-based ISI Impact Factor can be derived from usage\ndata. However, contrary to the ISI IF which is based on citation data generated\nby the global community of scholarly authors, so far usage can only be\npractically recorded at a local level leading to community-specific assessments\nof scholarly impact that are difficult to generalize to the global scholarly\ncommunity. We define a journal Usage Impact Factor which mimics the definition\nof the Thomson Scientific's ISI Impact Factor. Usage Impact Factor rankings are\ncalculated on the basis of a large-scale usage data set recorded for the\nCalifornia State University system from 2003 to 2005. The resulting journal\nrankings are then compared to Thomson Scientific's ISI Impact Factor which is\nused as a baseline indicator of general impact. Our results indicate that\nimpact as derived from California State University usage reflects the\nparticular scientific and demographic characteristics of its communities."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s00799-007-0016-7", 
    "link": "http://arxiv.org/pdf/cs/0611005v1", 
    "title": "Protocols for Scholarly Communication", 
    "arxiv-id": "cs/0611005v1", 
    "author": "Joanne Yeomans", 
    "publish": "2006-11-01T18:59:57Z", 
    "summary": "CERN, the European Organization for Nuclear Research, has operated an\ninstitutional preprint repository for more than 10 years. The repository\ncontains over 850,000 records of which more than 450,000 are full-text OA\npreprints, mostly in the field of particle physics, and it is integrated with\nthe library's holdings of books, conference proceedings, journals and other\ngrey literature. In order to encourage effective propagation and open access to\nscholarly material, CERN is implementing a range of innovative library services\ninto its document repository: automatic keywording, reference extraction,\ncollaborative management tools and bibliometric tools. Some of these services,\nsuch as user reviewing and automatic metadata extraction, could make up an\ninteresting testbed for future publishing solutions and certainly provide an\nexciting environment for e-science possibilities. The future protocol for\nscientific communication should naturally guide authors towards OA publication\nand CERN wants to help reach a full open access publishing environment for the\nparticle physics community and the related sciences in the next few years."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s00799-007-0016-7", 
    "link": "http://arxiv.org/pdf/cs/0611036v1", 
    "title": "Intra-site Level Cultural Heritage Documentation: Combination of Survey,   Modeling and Imagery Data in a Web Information System", 
    "arxiv-id": "cs/0611036v1", 
    "author": "Jean-Pierre Perrin", 
    "publish": "2006-11-08T17:35:52Z", 
    "summary": "Cultural heritage documentation induces the use of computerized techniques to\nmanage and preserve the information produced. Geographical information systems\nhave proved their potentialities in this scope, but they are not always adapted\nfor the management of features at the scale of a particular archaeological\nsite. Moreover, computer applications in archaeology are often technology\ndriven and software constrained. Thus, we propose a tool that tries to avoid\nthese difficulties. We are developing an information system that works over the\nInternet and that is joined with a web site. Aims are to assist the work of\narchaeological sites managers and to be a documentation tool about these sites,\ndedicated to everyone. We devote therefore our system both to the professionals\nwho are in charge of the site, and to the general public who visits it or who\nwants to have information on it. The system permits to do exploratory analyses\nof the data, especially at spatial and temporal levels. We propose to record\nmetadata about the archaeological features in XML and to access these features\nthrough interactive 2D and 3D representations, and through queries systems\n(keywords and images). The 2D images, photos, or vectors are generated in SVG,\nwhile 3D models are generated in X3D. Archaeological features are also\nautomatically integrated in a MySQL database. The web site is an exchange\nplatform with the information system and is written in PHP. Our first\napplication case is the medieval castle of Vianden, Luxembourg."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20616", 
    "link": "http://arxiv.org/pdf/cs/0701074v1", 
    "title": "On the robustness of the h-index", 
    "arxiv-id": "cs/0701074v1", 
    "author": "Jerome K Vanclay", 
    "publish": "2007-01-11T00:48:45Z", 
    "summary": "The h-index (Hirsch, 2005) is robust, remaining relatively unaffected by\nerrors in the long tails of the citations-rank distribution, such as\ntypographic errors that short-change frequently-cited papers and create bogus\nadditional records. This robustness, and the ease with which h-indices can be\nverified, support the use of a Hirsch-type index over alternatives such as the\njournal impact factor. These merits of the h-index apply to both individuals\nand to journals."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20616", 
    "link": "http://arxiv.org/pdf/cs/0702103v1", 
    "title": "Exploring the academic invisible web", 
    "arxiv-id": "cs/0702103v1", 
    "author": "Philipp Mayr", 
    "publish": "2007-02-18T20:56:34Z", 
    "summary": "Purpose: To provide a critical review of Bergman's 2001 study on the Deep\nWeb. In addition, we bring a new concept into the discussion, the Academic\nInvisible Web (AIW). We define the Academic Invisible Web as consisting of all\ndatabases and collections relevant to academia but not searchable by the\ngeneral-purpose internet search engines. Indexing this part of the Invisible\nWeb is central to scientific search engines. We provide an overview of\napproaches followed thus far. Design/methodology/approach: Discussion of\nmeasures and calculations, estimation based on informetric laws. Literature\nreview on approaches for uncovering information from the Invisible Web.\nFindings: Bergman's size estimate of the Invisible Web is highly questionable.\nWe demonstrate some major errors in the conceptual design of the Bergman paper.\nA new (raw) size estimate is given. Research limitations/implications: The\nprecision of our estimate is limited due to a small sample size and lack of\nreliable data. Practical implications: We can show that no single library alone\nwill be able to index the Academic Invisible Web. We suggest collaboration to\naccomplish this task. Originality/value: Provides library managers and those\ninterested in developing academic search engines with data on the size and\nattributes of the Academic Invisible Web."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20616", 
    "link": "http://arxiv.org/pdf/cs/0703043v1", 
    "title": "A Comparison of On-Line Computer Science Citation Databases", 
    "arxiv-id": "cs/0703043v1", 
    "author": "C. Lee Giles", 
    "publish": "2007-03-09T16:00:55Z", 
    "summary": "This paper examines the difference and similarities between the two on-line\ncomputer science citation databases DBLP and CiteSeer. The database entries in\nDBLP are inserted manually while the CiteSeer entries are obtained autonomously\nvia a crawl of the Web and automatic processing of user submissions. CiteSeer's\nautonomous citation database can be considered a form of self-selected on-line\nsurvey. It is important to understand the limitations of such databases,\nparticularly when citation information is used to assess the performance of\nauthors, institutions and funding bodies.\n  We show that the CiteSeer database contains considerably fewer single author\npapers. This bias can be modeled by an exponential process with intuitive\nexplanation. The model permits us to predict that the DBLP database covers\napproximately 24% of the entire literature of Computer Science. CiteSeer is\nalso biased against low-cited papers.\n  Despite their difference, both databases exhibit similar and significantly\ndifferent citation distributions compared with previous analysis of the Physics\ncommunity. In both databases, we also observe that the number of authors per\npaper has been increasing over time."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20616", 
    "link": "http://arxiv.org/pdf/0705.3466v1", 
    "title": "Open Access Publishing in Particle Physics: A Brief Introduction for the   non-Expert", 
    "arxiv-id": "0705.3466v1", 
    "author": "Travis C. Brooks", 
    "publish": "2007-05-23T20:28:47Z", 
    "summary": "Open Access to particle physics literature does not sound particularly new or\nexciting, since particle physicists have been reading preprints for decades,\nand arXiv.org for 15 years. However new movements in Europe are attempting to\nmake the peer-reviewed literature of the field fully Open Access. This is not a\nnew movement, nor is it restricted to this field. However, given the field's\nhistory of preprints and eprints, it is well suited to a change to a fully Open\nAccess publishing model. Data shows that 90% of HEP published literature is\nfreely available online, meaning that HEP libraries have little need for\nexpensive journal subscriptions. As libraries begin to cancel journal\nsubscriptions, the peer review process will lose its primary source of funding.\nOpen Access publishing models can potentially address this issue. European\nphysicists and funding agencies are proposing a consortium, SCOAP3, that might\nsolve many of the objections to traditional Open Access publishing models in\nParticle Physics. These proposed changes should be viewed as a starting point\nfor a serious look at the field's publication model, and are at least worthy of\nattention, if not adoption."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20616", 
    "link": "http://arxiv.org/pdf/0706.0306v1", 
    "title": "Submission of content to a digital object repository using a   configurable workflow system", 
    "arxiv-id": "0706.0306v1", 
    "author": "Johannes Mueller", 
    "publish": "2007-06-03T19:37:41Z", 
    "summary": "The prototype of a workflow system for the submission of content to a digital\nobject repository is here presented. It is based entirely on open-source\nstandard components and features a service-oriented architecture. The front-end\nconsists of Java Business Process Management (jBPM), Java Server Faces (JSF),\nand Java Server Pages (JSP). A Fedora Repository and a mySQL data base\nmanagement system serve as a back-end. The communication between front-end and\nback-end uses a SOAP minimal binding stub. We describe the design principles\nand the construction of the prototype and discuss the possibilities and\nlimitations of work ow creation by administrators. The code of the prototype is\nopen-source and can be retrieved in the project escipub at\nhttp://sourceforge.net"
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20616", 
    "link": "http://arxiv.org/pdf/0707.2886v1", 
    "title": "OA@MPS - a colourful view", 
    "arxiv-id": "0707.2886v1", 
    "author": "Laurent Romary", 
    "publish": "2007-07-19T12:30:42Z", 
    "summary": "The open access agenda of the Max Planck Society, initiator of the Berlin\nDeclaration, envisions the support of both the green way and the golden way to\nopen access. For the implementation of the green way the Max Planck Society\nthrough its newly established unit (Max Planck Digital Library) follows the\nidea of providing a centralized technical platform for publications and a local\nsupport for editorial issues. With regard to the golden way, the Max Planck\nSociety fosters the development of open access publication models and\nexperiments new publishing concepts like the Living Reviews journals."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2008.07.002", 
    "link": "http://arxiv.org/pdf/0712.1916v4", 
    "title": "Ranking forestry journals using the h-index", 
    "arxiv-id": "0712.1916v4", 
    "author": "Jerome K. Vanclay", 
    "publish": "2007-12-12T12:09:55Z", 
    "summary": "An expert ranking of forestry journals was compared with journal impact\nfactors and h-indices computed from the ISI Web of Science and internet-based\ndata. Citations reported by Google Scholar appear to offer the most efficient\nway to rank all journals objectively, in a manner consistent with other\nindicators. This h-index exhibited a high correlation with the journal impact\nfactor (r=0.92), but is not confined to journals selected by any particular\ncommercial provider. A ranking of 180 forestry journals is presented, on the\nbasis of this index."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2008.07.002", 
    "link": "http://arxiv.org/pdf/0712.2449v1", 
    "title": "Reducing semantic complexity in distributed Digital Libraries: treatment   of term vagueness and document re-ranking", 
    "arxiv-id": "0712.2449v1", 
    "author": "Vivien Petras", 
    "publish": "2007-12-14T21:24:26Z", 
    "summary": "The purpose of the paper is to propose models to reduce the semantic\ncomplexity in heterogeneous DLs. The aim is to introduce value-added services\n(treatment of term vagueness and document re-ranking) that gain a certain\nquality in DLs if they are combined with heterogeneity components established\nin the project \"Competence Center Modeling and Treatment of Semantic\nHeterogeneity\". Empirical observations show that freely formulated user terms\nand terms from controlled vocabularies are often not the same or match just by\ncoincidence. Therefore, a value-added service will be developed which rephrases\nthe natural language searcher terms into suggestions from the controlled\nvocabulary, the Search Term Recommender (STR). Two methods, which are derived\nfrom scientometrics and network analysis, will be implemented with the\nobjective to re-rank result sets by the following structural properties: the\nranking of the results by core journals (so-called Bradfordizing) and ranking\nby centrality of authors in co-authorship networks."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2008.07.002", 
    "link": "http://arxiv.org/pdf/0802.0745v1", 
    "title": "Knowledge management by wikis", 
    "arxiv-id": "0802.0745v1", 
    "author": "Sander Spek", 
    "publish": "2008-02-06T08:01:48Z", 
    "summary": "Wikis provide a new way of collaboration and knowledge sharing. Wikis are\nsoftware that allows users to work collectively on a web-based knowledge base.\nWikis are characterised by a sense of anarchism, collaboration, connectivity,\norganic development and self-healing, and they rely on trust. We list several\nconcerns about applying wikis in professional organisation. After these\nconcerns are met, wikis can provide a progessive, new knowledge sharing and\ncollaboration tool."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2008.07.002", 
    "link": "http://arxiv.org/pdf/0803.1500v1", 
    "title": "NCore: Architecture and Implementation of a Flexible, Collaborative   Digital Library", 
    "arxiv-id": "0803.1500v1", 
    "author": "Ellen J. Cramer", 
    "publish": "2008-03-10T21:06:31Z", 
    "summary": "NCore is an open source architecture and software platform for creating\nflexible, collaborative digital libraries. NCore was developed by the National\nScience Digital Library (NSDL) project, and it serves as the central technical\ninfrastructure for NSDL. NCore consists of a central Fedora-based digital\nrepository, a specific data model, an API, and a set of backend services and\nfrontend tools that create a new model for collaborative, contributory digital\nlibraries. This paper describes NCore, presents and analyzes its architecture,\ntools and services; and reports on the experience of NSDL in building and\noperating a major digital library on it over the past year and the experience\nof the Digital Library for Earth Systems Education in porting their existing\ndigital library and tools to the NCore platform."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2008.07.002", 
    "link": "http://arxiv.org/pdf/0803.4511v1", 
    "title": "The aDORe Federation Architecture", 
    "arxiv-id": "0803.4511v1", 
    "author": "Patrick Hochstenbach", 
    "publish": "2008-03-31T18:02:57Z", 
    "summary": "The need to federate repositories emerges in two distinctive scenarios. In\none scenario, scalability-related problems in the operation of a repository\nreach a point beyond which continued service requires parallelization and hence\nfederation of the repository infrastructure. In the other scenario, multiple\ndistributed repositories manage collections of interest to certain communities\nor applications, and federation is an approach to present a unified perspective\nacross these repositories. The high-level, 3-Tier aDORe federation architecture\ncan be used as a guideline to federate repositories in both cases. This paper\ndescribes the architecture, consisting of core interfaces for federated\nrepositories in Tier-1, two shared infrastructure components in Tier-2, and a\nsingle-point of access to the federation in Tier-3. The paper also illustrates\ntwo large-scale deployments of the aDORe federation architecture: the aDORe\nArchive repository (over 100,000,000 digital objects) at the Los Alamos\nNational Laboratory and the Ghent University Image Repository federation\n(multiple terabytes of image files)."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20944", 
    "link": "http://arxiv.org/pdf/0804.2701v2", 
    "title": "Information Resources in High-Energy Physics: Surveying the Present   Landscape and Charting the Future Course", 
    "arxiv-id": "0804.2701v2", 
    "author": "Travis C. Brooks", 
    "publish": "2008-04-16T23:01:51Z", 
    "summary": "Access to previous results is of paramount importance in the scientific\nprocess. Recent progress in information management focuses on building\ne-infrastructures for the optimization of the research workflow, through both\npolicy-driven and user-pulled dynamics. For decades, High-Energy Physics (HEP)\nhas pioneered innovative solutions in the field of information management and\ndissemination. In light of a transforming information environment, it is\nimportant to assess the current usage of information resources by researchers\nand HEP provides a unique test-bed for this assessment. A survey of about 10%\nof practitioners in the field reveals usage trends and information needs.\nCommunity-based services, such as the pioneering arXiv and SPIRES systems,\nlargely answer the need of the scientists, with a limited but increasing\nfraction of younger users relying on Google. Commercial services offered by\npublishers or database vendors are essentially unused in the field. The survey\noffers an insight into the most important features that users require to\noptimize their research workflow. These results inform the future evolution of\ninformation management in HEP and, as these researchers are traditionally\n``early adopters'' of innovation in scholarly communication, can inspire\ndevelopments of disciplinary repositories serving other communities."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20944", 
    "link": "http://arxiv.org/pdf/0804.3791v1", 
    "title": "Towards Usage-based Impact Metrics: - First Results from the MESUR   Project", 
    "arxiv-id": "0804.3791v1", 
    "author": "Marko A. Rodriguez", 
    "publish": "2008-04-23T19:23:44Z", 
    "summary": "Scholarly usage data holds the potential to be used as a tool to study the\ndynamics of scholarship in real time, and to form the basis for the definition\nof novel metrics of scholarly impact. However, the formal groundwork to\nreliably and validly exploit usage data is lacking, and the exact nature,\nmeaning and applicability of usage-based metrics is poorly understood. The\nMESUR project funded by the Andrew W. Mellon Foundation constitutes a\nsystematic effort to define, validate and cross-validate a range of usage-based\nmetrics of scholarly impact. MESUR has collected nearly 1 billion usage events\nas well as all associated bibliographic and citation data from significant\npublishers, aggregators and institutional consortia to construct a large-scale\nusage data reference set. This paper describes some major challenges related to\naggregating and processing usage data, and discusses preliminary results\nobtained from analyzing the MESUR reference data set. The results confirm the\nintrinsic value of scholarly usage data, and support the feasibility of\nreliable and valid usage-based metrics of scholarly impact."
},{
    "category": "cs.DL", 
    "doi": "10.3233/ISU-2008-0570", 
    "link": "http://arxiv.org/pdf/0805.2739v1", 
    "title": "Innovation in Scholarly Communication: Vision and Projects from   High-Energy Physics", 
    "arxiv-id": "0805.2739v1", 
    "author": "Salvatore Mele", 
    "publish": "2008-05-18T17:38:14Z", 
    "summary": "Having always been at the forefront of information management and open\naccess, High-Energy Physics (HEP) proves to be an ideal test-bed for\ninnovations in scholarly communication including new information and\ncommunication technologies. Three selected topics of scholarly communication in\nHigh-Energy Physics are presented here: A new open access business model,\nSCOAP3, a world-wide sponsoring consortium for peer-reviewed HEP literature;\nthe design, development and deployment of an e-infrastructure for information\nmanagement; and the emerging debate on long-term preservation, re-use and\n(open) access to HEP data."
},{
    "category": "cs.DL", 
    "doi": "10.3233/ISU-2008-0570", 
    "link": "http://arxiv.org/pdf/0808.2246v1", 
    "title": "Comparing human and automatic thesaurus mapping approaches in the   agricultural domain", 
    "arxiv-id": "0808.2246v1", 
    "author": "Philipp Mayr", 
    "publish": "2008-08-16T10:10:21Z", 
    "summary": "Knowledge organization systems (KOS), like thesauri and other controlled\nvocabularies, are used to provide subject access to information systems across\nthe web. Due to the heterogeneity of these systems, mapping between\nvocabularies becomes crucial for retrieving relevant information. However,\nmapping thesauri is a laborious task, and thus big efforts are being made to\nautomate the mapping process. This paper examines two mapping approaches\ninvolving the agricultural thesaurus AGROVOC, one machine-created and one human\ncreated. We are addressing the basic question \"What are the pros and cons of\nhuman and automatic mapping and how can they complement each other?\" By\npointing out the difficulties in specific cases or groups of cases and grouping\nthe sample into simple and difficult types of mappings, we show the limitations\nof current automatic methods and come up with some basic recommendations on\nwhat approach to use when."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20965", 
    "link": "http://arxiv.org/pdf/0808.2428v3", 
    "title": "Author-choice open access publishing in the biological and medical   literature: a citation analysis", 
    "arxiv-id": "0808.2428v3", 
    "author": "Philip M. Davis", 
    "publish": "2008-08-18T17:02:59Z", 
    "summary": "In this article, we analyze the citations to articles published in 11\nbiological and medical journals from 2003 to 2007 that employ author-choice\nopen access models. Controlling for known explanatory predictors of citations,\nonly 2 of the 11 journals show positive and significant open access effects.\nAnalyzing all journals together, we report a small but significant increase in\narticle citations of 17%. In addition, there is strong evidence to suggest that\nthe open access advantage is declining by about 7% per year, from 32% in 2004\nto 11% in 2007."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20965", 
    "link": "http://arxiv.org/pdf/0809.2851v2", 
    "title": "Correlation of Expert and Search Engine Rankings", 
    "arxiv-id": "0809.2851v2", 
    "author": "Manoranjan Magudamudi", 
    "publish": "2008-09-17T04:27:14Z", 
    "summary": "In previous research it has been shown that link-based web page metrics can\nbe used to predict experts' assessment of quality. We are interested in a\nrelated question: do expert rankings of real-world entities correlate with\nsearch engine rankings of corresponding web resources? For example, each year\nUS News & World Report publishes a list of (among others) top 50 graduate\nbusiness schools. Does their expert ranking correlate with the search engine\nranking of the URLs of those business schools? To answer this question we\nconducted 9 experiments using 8 expert rankings on a range of academic,\nathletic, financial and popular culture topics. We compared the expert rankings\nwith the rankings in Google, Live Search (formerly MSN) and Yahoo (with list\nlengths of 10, 25, and 50). In 57 search engine vs. expert comparisons, only 1\nstrong and 4 moderate correlations were statistically significant. In 42\ninter-search engine comparisons, only 2 strong and 4 moderate correlations were\nstatistically significant. The correlations appeared to decrease with the size\nof the lists: the 3 strong correlations were for lists of 10, the 8 moderate\ncorrelations were for lists of 25, and no correlations were found for lists of\n50."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20965", 
    "link": "http://arxiv.org/pdf/0811.0573v1", 
    "title": "A Web-Based Resource Model for eScience: Object Reuse & Exchange", 
    "arxiv-id": "0811.0573v1", 
    "author": "Pete Johnston", 
    "publish": "2008-11-04T19:07:36Z", 
    "summary": "Work in the Open Archives Initiative - Object Reuse and Exchange (OAI-ORE)\nfocuses on an important aspect of infrastructure for eScience: the\nspecification of the data model and a suite of implementation standards to\nidentify and describe compound objects. These are objects that aggregate\nmultiple sources of content including text, images, data, visualization tools,\nand the like. These aggregations are an essential product of eScience, and will\nbecome increasingly common in the age of data-driven scholarship. The OAI-ORE\nspecifications conform to the core concepts of the Web architecture and the\nsemantic Web, ensuring that applications that use them will integrate well into\nthe general Web environment."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20965", 
    "link": "http://arxiv.org/pdf/0811.3137v1", 
    "title": "Collecting and Preserving Videogames and Their Related Materials: A   Review of Current Practice, Game-Related Archives and Research Projects", 
    "arxiv-id": "0811.3137v1", 
    "author": "Caitlin Murray", 
    "publish": "2008-11-19T15:36:13Z", 
    "summary": "This paper reviews the major methods and theories regarding the preservation\nof new media artifacts such as videogames, and argues for the importance of\ncollecting and coming to a better understanding of videogame artifacts of\ncreation, which will help build a more detailed understanding of the essential\nqualities of these culturally significant artifacts. We will also review the\nmajor videogame collections in the United States, Europe and Japan to give an\nidea of the current state of videogame archives, and argue for a fuller, more\ncomprehensive coverage of these materials in institutional repositories."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20965", 
    "link": "http://arxiv.org/pdf/0812.0262v1", 
    "title": "An evaluation of Bradfordizing effects", 
    "arxiv-id": "0812.0262v1", 
    "author": "Philipp Mayr", 
    "publish": "2008-12-01T10:44:25Z", 
    "summary": "The purpose of this paper is to apply and evaluate the bibliometric method\nBradfordizing for information retrieval (IR) experiments. Bradfordizing is used\nfor generating core document sets for subject-specific questions and to reorder\nresult sets from distributed searches. The method will be applied and tested in\na controlled scenario of scientific literature databases from social and\npolitical sciences, economics, psychology and medical science (SOLIS, SoLit,\nUSB Koeln Opac, CSA Sociological Abstracts, World Affairs Online, Psyndex and\nMedline) and 164 standardized topics. An evaluation of the method and its\neffects is carried out in two laboratory-based information retrieval\nexperiments (CLEF and KoMoHe) using a controlled document corpus and human\nrelevance assessments. The results show that Bradfordizing is a very robust\nmethod for re-ranking the main document types (journal articles and monographs)\nin today's digital libraries (DL). The IR tests show that relevance\ndistributions after re-ranking improve at a significant level if articles in\nthe core are compared with articles in the succeeding zones. The items in the\ncore are significantly more often assessed as relevant, than items in zone 2\n(z2) or zone 3 (z3). The improvements between the zones are statistically\nsignificant based on the Wilcoxon signed-rank test and the paired T-Test."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20965", 
    "link": "http://arxiv.org/pdf/0812.3563v2", 
    "title": "Questions & Answers for TEI Newcomers", 
    "arxiv-id": "0812.3563v2", 
    "author": "Laurent Romary", 
    "publish": "2008-12-18T15:51:17Z", 
    "summary": "This paper provides an introduction to the Text Encoding Initia-tive (TEI),\nfocused at bringing in newcomers who have to deal with a digital document\nproject and are looking at the capacity that the TEI environment may have to\nfulfil his needs. To this end, we avoid a strictly technical presentation of\nthe TEI and concentrate on the actual issues that such projects face, with\nparallel made on the situation within two institutions. While a quick\nwalkthrough the TEI technical framework is provided, the papers ends up by\nshowing the essential role of the community in the actual technical\ncontributions that are being brought to the TEI."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20965", 
    "link": "http://arxiv.org/pdf/0902.0755v1", 
    "title": "A Simple Extraction Procedure for Bibliographical Author Field", 
    "arxiv-id": "0902.0755v1", 
    "author": "Pere Constans", 
    "publish": "2009-02-04T17:36:41Z", 
    "summary": "A procedure for bibliographic author metadata extraction from scholarly texts\nis presented. The author segments are identified based on capitalization and\nline break patterns. Two main author layout templates, which can retrieve from\na varied set of title pages, are provided. Additionally, several disambiguating\nrules are described."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20965", 
    "link": "http://arxiv.org/pdf/0905.4610v1", 
    "title": "Indexing Research Papers in Open Access Databases", 
    "arxiv-id": "0905.4610v1", 
    "author": "Alexandra-Emilia Fortis", 
    "publish": "2009-05-28T11:06:19Z", 
    "summary": "This paper synthesizes the actions performed in order to transform a classic\nscientific research journal - 'Annals. Computer Science Series' - available\nonly in printed form until 2008, into a modern e-journal with free access to\nthe full text of the articles. For achieving this goal, the research papers\nhave been included in various article databases, portals and library catalogs\nwhich offered a high visibility to the journal."
},{
    "category": "cs.DL", 
    "doi": "10.1504/IJKWI.2011.045165", 
    "link": "http://arxiv.org/pdf/0905.4717v3", 
    "title": "Reengineering PDF-Based Documents Targeting Complex Software   Specifications", 
    "arxiv-id": "0905.4717v3", 
    "author": "Timothy C. Lethbridge", 
    "publish": "2009-05-28T19:23:21Z", 
    "summary": "This article aims at reengineering of PDF-based complex documents, where\nspecifications of the Object Management Group (OMG) are our initial targets.\nOur motivation is that such specifications are dense and intricate to use, and\ntend to have complicated structures. Our objective is therefore to create an\napproach that allows us to reengineer PDF-based documents, and to illustrate\nhow to make more usable versions of electronic documents (such as\nspecifications, technical books, etc) so that end users to have a better\nexperience with them. The first step was to extract the logical structure of\nthe document in a meaningful XML format for subsequent processing. Our initial\nassumption was that, many key concepts of a document are expressed in this\nstructure. In the next phase, we created a multilayer hypertext version of the\ndocument to facilitate browsing and navigating. Although we initially focused\non OMG software specifications, we chose a general approach for different\nphases of our work including format conversions, logical structure extraction,\ntext extraction, multilayer hypertext generation, and concept exploration. As a\nconsequence, we can process other complex documents to achieve our goals."
},{
    "category": "cs.DL", 
    "doi": "10.1504/IJKWI.2011.045165", 
    "link": "http://arxiv.org/pdf/0906.0867v1", 
    "title": "PDF/A standard for long term archiving", 
    "arxiv-id": "0906.0867v1", 
    "author": "Ramona Vasilescu", 
    "publish": "2009-06-04T09:56:14Z", 
    "summary": "PDF/A is defined by ISO 19005-1 as a file format based on PDF format. The\nstandard provides a mechanism for representing electronic documents in a way\nthat preserves their visual appearance over time, independent of the tools and\nsystems used for creating or storing the files."
},{
    "category": "cs.DL", 
    "doi": "10.1504/IJKWI.2011.045165", 
    "link": "http://arxiv.org/pdf/0906.1053v1", 
    "title": "Report on the current state of the French DMLs", 
    "arxiv-id": "0906.1053v1", 
    "author": "Thierry Bouche", 
    "publish": "2009-06-05T08:10:30Z", 
    "summary": "This is a survey of the existing digital collections of French mathematical\nliterature, run by non-profit organizations. This includes research monographs,\nserials, proceedings, Ph. D. theses, collected works, books and personal\nwebsites."
},{
    "category": "cs.DL", 
    "doi": "10.1504/IJKWI.2011.045165", 
    "link": "http://arxiv.org/pdf/0906.2135v1", 
    "title": "Adding eScience Assets to the Data Web", 
    "arxiv-id": "0906.2135v1", 
    "author": "Pete Johnston", 
    "publish": "2009-06-11T15:33:37Z", 
    "summary": "Aggregations of Web resources are increasingly important in scholarship as it\nadopts new methods that are data-centric, collaborative, and networked-based.\nThe same notion of aggregations of resources is common to the mashed-up,\nsocially networked information environment of Web 2.0. We present a mechanism\nto identify and describe aggregations of Web resources that has resulted from\nthe Open Archives Initiative - Object Reuse and Exchange (OAI-ORE) project. The\nOAI-ORE specifications are based on the principles of the Architecture of the\nWorld Wide Web, the Semantic Web, and the Linked Data effort. Therefore, their\nincorporation into the cyberinfrastructure that supports eScholarship will\nensure the integration of the products of scholarly research into the Data Web."
},{
    "category": "cs.DL", 
    "doi": "10.1504/IJKWI.2011.045165", 
    "link": "http://arxiv.org/pdf/0906.5418v2", 
    "title": "Citing and Reading Behaviours in High-Energy Physics. How a Community   Stopped Worrying about Journals and Learned to Love Repositories", 
    "arxiv-id": "0906.5418v2", 
    "author": "Travis Brooks", 
    "publish": "2009-06-30T16:45:04Z", 
    "summary": "Contemporary scholarly discourse follows many alternative routes in addition\nto the three-century old tradition of publication in peer-reviewed journals.\nThe field of High- Energy Physics (HEP) has explored alternative communication\nstrategies for decades, initially via the mass mailing of paper copies of\npreliminary manuscripts, then via the inception of the first online\nrepositories and digital libraries.\n  This field is uniquely placed to answer recurrent questions raised by the\ncurrent trends in scholarly communication: is there an advantage for scientists\nto make their work available through repositories, often in preliminary form?\nIs there an advantage to publishing in Open Access journals? Do scientists\nstill read journals or do they use digital repositories?\n  The analysis of citation data demonstrates that free and immediate online\ndissemination of preprints creates an immense citation advantage in HEP,\nwhereas publication in Open Access journals presents no discernible advantage.\nIn addition, the analysis of clickstreams in the leading digital library of the\nfield shows that HEP scientists seldom read journals, preferring preprints\ninstead."
},{
    "category": "cs.DL", 
    "doi": "10.1504/IJKWI.2011.045165", 
    "link": "http://arxiv.org/pdf/0907.3154v1", 
    "title": "COMMENTARY ON: Citing and Reading Behavours in High-Energy Physics   (arXiv:0906.5418)", 
    "arxiv-id": "0907.3154v1", 
    "author": "Stevan Harnad", 
    "publish": "2009-07-17T20:29:11Z", 
    "summary": "Evidence confirming that OA increases impact will not be sufficient to induce\nenough researchers to provide OA; only mandates from their institutions and\nfunders can ensure that. HEP researchers continue to submit their papers to\npeer-reviewed journals, as they always did, depositing both their unrefereed\npreprints and their refereed postprints. None of that has changed. In fields\nlike HEP and astrophysics, the journal affordability/accessibility problem is\nnot as great as in many other fields, where it the HEP Early Access impact\nadvantage translates into the OA impact advantage itself. Almost no one has\never argued that Gold OA provides a greater OA advantage than Green OA. The OA\nadvantage is the OA advantage, whether Green or Gold."
},{
    "category": "cs.DL", 
    "doi": "10.1504/IJKWI.2011.045165", 
    "link": "http://arxiv.org/pdf/0907.3826v1", 
    "title": "Experimental DML over digital repositories in Japan", 
    "arxiv-id": "0907.3826v1", 
    "author": "Shunsuke Naruse", 
    "publish": "2009-07-22T12:40:35Z", 
    "summary": "In this paper the authors show an overview of Virtual Digital Mathematics\nLibrary in Japan (DML-JP), contents of which consist of metadata harvested from\ninstitutional repositories in Japan and digital repositories in the world.\nDML-JP is, in a sense, a subject specific repository which collaborate with\nvarious digital repositories. Beyond portal website, DML-JP provides\nsubject-specific metadata through OAI-ORE. By the schema it is enabled that\ndigital repositories can load the rich metadata which were added by\nmathematicians."
},{
    "category": "cs.DL", 
    "doi": "10.1504/IJKWI.2011.045165", 
    "link": "http://arxiv.org/pdf/0910.2626v1", 
    "title": "On challenges and opportunities of designing integrated IT platforms for   supporting knowledge works in organizations", 
    "arxiv-id": "0910.2626v1", 
    "author": "Arijit Laha", 
    "publish": "2009-10-14T13:55:57Z", 
    "summary": "Designing and implementing comprehensive IT-based support environments for KM\nin organizations is fraught with many problems. Solving them requires intimate\nknowledge about the information usage in knowledge works and the scopes of\ntechnology intervention. In this paper, the Task-oriented Organizational\nKnowledge Management or TOKM, a design theory for building integrated IT\nplatforms for supporting organizational KM, is proposed. TOKM brings together\ntwo apparently mutually exclusive practices of building KM systems, the\ntask-based approach and the generic or universalistic approach. In developing\nthe design, the information requirements of knowledge workers in light of an\ninformation usage model of knowledge works is studied. Then the model is\nextended to study possibilities of more advanced IT support and formulate them\nin form of a set of meta-requirements. Following the IS design theory paradigm,\na set of artifacts are hypothesized to meet the requirements. Finally, a design\nmethod, as a possible approach of building an IT-based integrated platform, the\nKnowledge Work Support Platform (KWSP) to realize the artifacts in order to\nmeet the requirements, is outlined. The KWSP is a powerful platform for\nbuilding and maintaining a number of task-type specific Knowledge Work Support\nSystems (KWSS) on a common sharable platform. Each KWSS, for the task-type\nsupported by it, can be easily designed to provide extensive and sophisticated\nsupport to individual as well as group of knowledge workers in performing their\nrespective knowledge work instances"
},{
    "category": "cs.DL", 
    "doi": "10.1504/IJKWI.2011.045165", 
    "link": "http://arxiv.org/pdf/0910.2632v1", 
    "title": "Communication scientifique : Pour le meilleur et pour le PEER", 
    "arxiv-id": "0910.2632v1", 
    "author": "Laurent Romary", 
    "publish": "2009-10-14T14:28:28Z", 
    "summary": "This paper provides an overview (in French) of the European PEER project,\nfocusing on its origins, the actual objectives and the technical deployment."
},{
    "category": "cs.DL", 
    "doi": "10.1504/IJKWI.2011.045165", 
    "link": "http://arxiv.org/pdf/0910.2638v1", 
    "title": "On building Information Warehouses", 
    "arxiv-id": "0910.2638v1", 
    "author": "Arijit Laha", 
    "publish": "2009-10-14T14:59:42Z", 
    "summary": "One of the most important goals of information management (IM) is supporting\nthe knowledge workers in performing their works. In this paper we examine\nissues of relevance, linkage and provenance of information, as accessed and\nused by the knowledge workers. These are usually not adequately addressed in\nmost of the IT based solutions for IM. Here we propose a non-conventional\napproach for building information systems for supporting the knowledge workers\nwhich addresses these issues. The approach leads to the ideas of building\nInformation Warehouses (IW) and Knowledge work Support Systems (KwSS). Such\nsystems can open up potential for building innovative applications of\nsignificant impact, including those capable of helping organizations in\nimplementing processes for double-loop learning."
},{
    "category": "cs.DL", 
    "doi": "10.1504/IJKWI.2011.045165", 
    "link": "http://arxiv.org/pdf/0910.3152v1", 
    "title": "Towards a Semantic Preservation System", 
    "arxiv-id": "0910.3152v1", 
    "author": "Jim Myers", 
    "publish": "2009-10-16T16:22:12Z", 
    "summary": "Preserving access to file content requires preserving not just bits but also\nmeaningful logical structures. The ongoing development of the Data Format\nDescription Language (DFDL) is a completely general standard that addresses\nthis need. The Defuddle parser is a generic parser that can use DFDL-style\nformat descriptions to extract logical structures from ASCII or binary files\nwritten in those formats. DFDL and Defuddle provide a preservation capability\nthat has minimal format-specific software and cleanly separates issues related\nto bits, formats, and logical content. Such a system has the potential to\ngreatly reduce overall system development and maintenance costs as well as the\nper-file-format costs for long term preservation."
},{
    "category": "cs.DL", 
    "doi": "10.1504/IJKWI.2011.045165", 
    "link": "http://arxiv.org/pdf/0911.1807v2", 
    "title": "Big Macs and Eigenfactor Scores: Don't Let Correlation Coefficients Fool   You", 
    "arxiv-id": "0911.1807v2", 
    "author": "Carl Bergstrom", 
    "publish": "2009-11-10T00:44:12Z", 
    "summary": "The Eigenfactor Metrics provide an alternative way of evaluating scholarly\njournals based on an iterative ranking procedure analogous to Google's PageRank\nalgorithm. These metrics have recently been adopted by Thomson-Reuters and are\nlisted alongside the Impact Factor in the Journal Citation Reports. But do\nthese metrics differ sufficiently so as to be a useful addition to the\nbibliometric toolbox? Davis (2008) has argued otherwise, based on his finding\nof a 0.95 correlation coefficient between Eigenfactor score and Total Citations\nfor a sample of journals in the field of medicine. This conclusion is mistaken;\nhere we illustrate the basic statistical fallacy to which Davis succumbed. We\nprovide a complete analysis of the 2006 Journal Citation Reports and\ndemonstrate that there are statistically and economically significant\ndifferences between the information provided by the Eigenfactor Metrics and\nthat provided by Impact Factor and Total Citations."
},{
    "category": "cs.DL", 
    "doi": "10.1504/IJKWI.2011.045165", 
    "link": "http://arxiv.org/pdf/0912.2032v1", 
    "title": "Institutional Repository saber.ula.ve: A testimonial perspective", 
    "arxiv-id": "0912.2032v1", 
    "author": "R. Torrens", 
    "publish": "2009-12-10T19:55:09Z", 
    "summary": "In this paper, we describe our decade-long experience of building and\noperating one of the most active Institutional Repository in the world:\nwww.saber.ula.ve <http://www.saber.ula.ve> (University of the Andes,\nMerida-Venezuela). In order to share our experience with other institutions, we\nfirstly explain the steps we followed to preserve and disseminate the\nscientific production of the University of Los Andes' researchers. We then\npresent some recent quantitative results about our repository activities and we\noutline some methodological guidelines that could be applied in order to\nreplicate similar experiences. These guidelines list the ingredients or\nbuilding blocks as well as the processes followed for developing and\nmaintaining the services of an Institutional Repository. These include\ntechnological infrastructure; institutional policies on preservation,\npublication and dissemination of knowledge; recommendations on incentives for\nopen access publication; the process of selection, testing and adaptation of\ntechnological tools; the planning and organization of services, and the\ndissemination and support within the scientific community that will eventually\nlead to the adoption of the ideas that lie behind the open access movement. We\nsummarize the results obtained regarding the acceptance, adoption and use of\nthe technological tools used for the publication of our institution's\nintellectual production, and we present the main obstacles encountered on the\nway."
},{
    "category": "cs.DL", 
    "doi": "10.1504/IJKWI.2011.045165", 
    "link": "http://arxiv.org/pdf/1001.1199v1", 
    "title": "New ways of scientific publishing and accessing human knowledge inspired   by transdisciplinary approaches", 
    "arxiv-id": "1001.1199v1", 
    "author": "B. Y Majlis", 
    "publish": "2010-01-08T04:55:49Z", 
    "summary": "Inspired by interdisciplinary work touching biology and microtribology, the\nauthors propose a new, dynamic way of publishing research results, the\nestablishment of a tree of knowledge and the localisation of scientific\narticles on this tree. 'Technomimetics' is proposed as a new method of\nknowledge management in science and technology: it shall help find and organise\ninformation in an era of over-information. Such ways of presenting and managing\nresearch results would be accessible by people with different kinds of\nbackgrounds and levels of education, and allow for full use of the ever-\nincreasing number of scientific and technical publications. This approach would\ndramatically change and revolutionize the way we are doing science, and\ncontribute to overcoming the three gaps between the world of ideas, inventors,\ninnovators and investors as introduced by Gebeshuber, Gruber and Drack in 2009\nfor accelerated scientific and technological breakthroughs to improve the human\ncondition. Inspiration for the development of above methods was the fact that -\ngenerally - tribologists and biologists do not see many overlaps of their\nprofessions. However, both deal with materials, structures and processes.\nTribology is omnipresent in biology and many biological systems have impressive\ntribological properties. Tribologists can therefore get valuable input and\ninspiration from living systems. The aim of biomimetics is knowledge transfer\nfrom biology to technology and successful biomimetics in tribology needs\ncollaboration between biologists and tribologists. Literature search shows that\nthe number of papers regarding biotribology is steadily increasing. However, at\nthe moment, most scientific papers of the other respective field are hard to\naccess and hard to understand, in terms of concepts and specific wording."
},{
    "category": "cs.DL", 
    "doi": "10.1504/IJKWI.2011.045165", 
    "link": "http://arxiv.org/pdf/1001.3663v1", 
    "title": "Collaboration in an Open Data eScience: A Case Study of Sloan Digital   Sky Survey", 
    "arxiv-id": "1001.3663v1", 
    "author": "Chaomei Chen", 
    "publish": "2010-01-20T20:23:06Z", 
    "summary": "Current science and technology has produced more and more publically\naccessible scientific data. However, little is known about how the open data\ntrend impacts a scientific community, specifically in terms of its\ncollaboration behaviors. This paper aims to enhance our understanding of the\ndynamics of scientific collaboration in the open data eScience environment via\na case study of co-author networks of an active and highly cited open data\nproject, called Sloan Digital Sky Survey. We visualized the co-authoring\nnetworks and measured their properties over time at three levels: author,\ninstitution, and country levels. We compared these measurements to a random\nnetwork model and also compared results across the three levels. The study\nfound that 1) the collaboration networks of the SDSS community transformed from\nrandom networks to small-world networks; 2) the number of author-level\ncollaboration instances has not changed much over time, while the number of\ncollaboration instances at the other two levels has increased over time; 3)\npairwise institutional collaboration become common in recent years. The open\ndata trend may have both positive and negative impacts on scientific\ncollaboration."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11786-010-0029-2", 
    "link": "http://arxiv.org/pdf/1001.4023v1", 
    "title": "Digital Mathematics Libraries: The Good, the Bad, the Ugly", 
    "arxiv-id": "1001.4023v1", 
    "author": "Thierry Bouche", 
    "publish": "2010-01-22T15:26:51Z", 
    "summary": "The idea of a World digital mathematics library (DML) has been around since\nthe turn of the 21th century. We feel that it is time to make it a reality,\nstarting in a modest way from successful bricks that have already been built,\nbut with an ambitious goal in mind. After a brief historical overview of\npublishing mathematics, an estimate of the size and a characterisation of the\nbulk of documents to be included in the DML, we turn to proposing a model for a\nReference Digital Mathematics Library--a network of institutions where the\ndigital documents would be physically archived. This pattern based rather on\nthe bottom-up strategy seems to be more practicable and consistent with the\ndigital nature of the DML. After describing the model we summarise what can and\nshould be done in order to accomplish the vision. The current state of some of\nthe local libraries that could contribute to the global views are described\nwith more details."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11786-010-0029-2", 
    "link": "http://arxiv.org/pdf/1001.4274v2", 
    "title": "ONER: Tool for Organization Named Entity Recognition from Affiliation   Strings in PubMed Abstracts", 
    "arxiv-id": "1001.4274v2", 
    "author": "Graciela Gonzalez", 
    "publish": "2010-01-24T20:28:13Z", 
    "summary": "Automatically extracting organization names from the affiliation sentences of\narticles related to biomedicine is of great interest to the pharmaceutical\nmarketing industry, health care funding agencies and public health officials.\nIt will also be useful for other scientists in normalizing author names,\nautomatically creating citations, indexing articles and identifying potential\nresources or collaborators. Today there are more than 18 million articles\nrelated to biomedical research indexed in PubMed, and information derived from\nthem could be used effectively to save the great amount of time and resources\nspent by government agencies in understanding the scientific landscape,\nincluding key opinion leaders and centers of excellence. Our process for\nextracting organization names involves multi-layered rule matching with\nmultiple dictionaries. The system achieves 99.6% f-measure in extracting\norganization names."
},{
    "category": "cs.DL", 
    "doi": "10.1109/BIBMW.2009.5332108", 
    "link": "http://arxiv.org/pdf/1001.4276v2", 
    "title": "Towards Automatic Extraction of Social Networks of Organizations in   PubMed Abstracts", 
    "arxiv-id": "1001.4276v2", 
    "author": "Graciela Gonzalez", 
    "publish": "2010-01-24T20:31:14Z", 
    "summary": "Social Network Analysis (SNA) of organizations can attract great interest\nfrom government agencies and scientists for its ability to boost translational\nresearch and accelerate the process of converting research to care. For SNA of\na particular disease area, we need to identify the key research groups in that\narea by mining the affiliation information from PubMed. This not only involves\nrecognizing the organization names in the affiliation string, but also\nresolving ambiguities to identify the article with a unique organization. We\npresent here a process of normalization that involves clustering based on local\nsequence alignment metrics and local learning based on finding connected\ncomponents. We demonstrate the application of the method by analyzing\norganizations involved in angiogenensis treatment, and demonstrating the\nutility of the results for researchers in the pharmaceutical and biotechnology\nindustries or national funding agencies."
},{
    "category": "cs.DL", 
    "doi": "10.1109/BIBMW.2009.5332108", 
    "link": "http://arxiv.org/pdf/1001.5018v1", 
    "title": "The Citation Field of Evolutionary Economics", 
    "arxiv-id": "1001.5018v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2010-01-27T20:31:53Z", 
    "summary": "Evolutionary economics has developed into an academic field of its own,\ninstitutionalized around, amongst others, the Journal of Evolutionary Economics\n(JEE). This paper analyzes the way and extent to which evolutionary economics\nhas become an interdisciplinary journal, as its aim was: a journal that is\nindispensable in the exchange of expert knowledge on topics and using\napproaches that relate naturally with it. Analyzing citation data for the\nrelevant academic field for the Journal of Evolutionary Economics, we use\ninsights from scientometrics and social network analysis to find that, indeed,\nthe JEE is a central player in this interdisciplinary field aiming mostly at\nunderstanding technological and regional dynamics. It does not, however, link\nfirmly with the natural sciences (including biology) nor to management\nsciences, entrepreneurship, and organization studies. Another journal that\ncould be perceived to have evolutionary acumen, the Journal of Economic Issues,\ndoes relate to heterodox economics journals and is relatively more involved in\ndiscussing issues of firm and industry organization. The JEE seems most keen to\ndevelop theoretical insights."
},{
    "category": "cs.DL", 
    "doi": "10.1109/BIBMW.2009.5332108", 
    "link": "http://arxiv.org/pdf/1002.3074v1", 
    "title": "Open Access Mandates and the \"Fair Dealing\" Button", 
    "arxiv-id": "1002.3074v1", 
    "author": "Stevan Harnad", 
    "publish": "2010-02-16T12:52:46Z", 
    "summary": "We describe the \"Fair Dealing Button,\" a feature designed for authors who\nhave deposited their papers in an Open Access Institutional Repository but have\ndeposited them as \"Closed Access\" (meaning only the metadata are visible and\nretrievable, not the full eprint) rather than Open Access. The Button allows\nindividual users to request and authors to provide a single eprint via\nsemi-automated email. The purpose of the Button is to tide over research usage\nneeds during any publisher embargo on Open Access and, more importantly, to\nmake it possible for institutions to adopt the\n\"Immediate-Deposit/Optional-Access\" Mandate, without exceptions or opt-outs,\ninstead of a mandate that allows delayed deposit or deposit waivers, depending\non publisher permissions or embargoes (or no mandate at all). This is only\n\"Almost-Open Access,\" but in facilitating exception-free immediate-deposit\nmandates it will accelerate the advent of universal Open Access."
},{
    "category": "cs.DL", 
    "doi": "10.1109/BIBMW.2009.5332108", 
    "link": "http://arxiv.org/pdf/1003.1345v1", 
    "title": "Author Identifiers in Scholarly Repositories", 
    "arxiv-id": "1003.1345v1", 
    "author": "Simeon Warner", 
    "publish": "2010-03-06T01:37:01Z", 
    "summary": "Bibliometric and usage-based analyses and tools highlight the value of\ninformation about scholarship contained within the network of authors, articles\nand usage data. Less progress has been made on populating and using the author\nside of this network than the article side, in part because of the difficulty\nof unambiguously identifying authors. I briefly review a sample of author\nidentifier schemes, and consider use in scholarly repositories. I then describe\npreliminary work at arXiv to implement public author identifiers, services\nbased on them, and plans to make this information useful beyond the boundaries\nof arXiv."
},{
    "category": "cs.DL", 
    "doi": "10.1109/BIBMW.2009.5332108", 
    "link": "http://arxiv.org/pdf/1003.2643v2", 
    "title": "Making Web Annotations Persistent over Time", 
    "arxiv-id": "1003.2643v2", 
    "author": "Herbert Van de Sompel", 
    "publish": "2010-03-12T21:36:18Z", 
    "summary": "As Digital Libraries (DL) become more aligned with the web architecture,\ntheir functional components need to be fundamentally rethought in terms of URIs\nand HTTP. Annotation, a core scholarly activity enabled by many DL solutions,\nexhibits a clearly unacceptable characteristic when existing models are applied\nto the web: due to the representations of web resources changing over time, an\nannotation made about a web resource today may no longer be relevant to the\nrepresentation that is served from that same resource tomorrow. We assume the\nexistence of archived versions of resources, and combine the temporal features\nof the emerging Open Annotation data model with the capability offered by the\nMemento framework that allows seamless navigation from the URI of a resource to\narchived versions of that resource, and arrive at a solution that provides\nguarantees regarding the persistence of web annotations over time. More\nspecifically, we provide theoretical solutions and proof-of-concept\nexperimental evaluations for two problems: reconstructing an existing\nannotation so that the correct archived version is displayed for all resources\ninvolved in the annotation, and retrieving all annotations that involve a given\narchived version of a web resource."
},{
    "category": "cs.DL", 
    "doi": "10.1109/BIBMW.2009.5332108", 
    "link": "http://arxiv.org/pdf/1003.4187v1", 
    "title": "Comparing Repository Types - Challenges and barriers for subject-based   repositories, research repositories, national repository systems and   institutional repositories in serving scholarly communication", 
    "arxiv-id": "1003.4187v1", 
    "author": "Laurent Romary", 
    "publish": "2010-03-22T15:11:47Z", 
    "summary": "After two decades of repository development, some conclusions may be drawn as\nto which type of repository and what kind of service best supports digital\nscholarly communication, and thus the production of new knowledge. Four types\nof publication repository may be distinguished, namely the subject-based\nrepository, research repository, national repository system and institutional\nrepository. Two important shifts in the role of repositories may be noted. With\nregard to content, a well-defined and high quality corpus is essential. This\nimplies that repository services are likely to be most successful when\nconstructed with the user and reader uppermost in mind. With regard to service,\nhigh value to specific scholarly communities is essential. This implies that\nrepositories are likely to be most useful to scholars when they offer dedicated\nservices supporting the production of new knowledge. Along these lines,\nchallenges and barriers to repository development may be identified in three\nkey dimensions: a) identification and deposit of content; b) access and use of\nservices; and c) preservation of content and sustainability of service. An\nindicative comparison of challenges and barriers in some major world regions\nsuch as Europe, North America and East Asia plus Australia is offered in\nconclusion."
},{
    "category": "cs.DL", 
    "doi": "10.1109/BIBMW.2009.5332108", 
    "link": "http://arxiv.org/pdf/1004.3351v1", 
    "title": "Citing for High Impact", 
    "arxiv-id": "1004.3351v1", 
    "author": "Daniel A. McFarland", 
    "publish": "2010-04-20T06:10:04Z", 
    "summary": "The question of citation behavior has always intrigued scientists from\nvarious disciplines. While general citation patterns have been widely studied\nin the literature we develop the notion of citation projection graphs by\ninvestigating the citations among the publications that a given paper cites. We\ninvestigate how patterns of citations vary between various scientific\ndisciplines and how such patterns reflect the scientific impact of the paper.\nWe find that idiosyncratic citation patterns are characteristic for low impact\npapers; while narrow, discipline-focused citation patterns are common for\nmedium impact papers. Our results show that crossing-community, or bridging\ncitation patters are high risk and high reward since such patterns are\ncharacteristic for both low and high impact papers. Last, we observe that\nrecently citation networks are trending toward more bridging and\ninterdisciplinary forms."
},{
    "category": "cs.DL", 
    "doi": "10.1109/BIBMW.2009.5332108", 
    "link": "http://arxiv.org/pdf/1004.4296v1", 
    "title": "Analysis of Graphs for Digital Preservation Suitability", 
    "arxiv-id": "1004.4296v1", 
    "author": "Michael L. Nelson", 
    "publish": "2010-04-24T17:47:30Z", 
    "summary": "We investigate the use of autonomically created small-world graphs as a\nframework for the long term storage of digital objects on the Web in a\npotentially hostile environment. We attack the classic Erdos - Renyi random,\nBarab'asi and Albert power law, Watts - Strogatz small world and our\nUnsupervised Small-World (USW) graphs using different attacker strategies and\nreport their respective robustness. Using different attacker profiles, we\nconstruct a game where the attacker is allowed to use a strategy of his choice\nto remove a percentage of each graph's elements. The graph is then allowed to\nrepair some portion of its self. We report on the number of alternating attack\nand repair turns until either the graph is disconnected, or the game exceeds\nthe number of permitted turns. Based on our analysis, an attack strategy that\nfocuses on removing the vertices with the highest betweenness value is most\nadvantageous to the attacker. Power law graphs can become disconnected with the\nremoval of a single edge; random graphs with the removal of as few as 1% of\ntheir vertices, small-world graphs with the removal of 14% vertices, and USW\nwith the removal of 17% vertices. Watts - Strogatz small-world graphs are more\nrobust and resilient than random or power law graphs. USW graphs are more\nrobust and resilient than small world graphs. A graph of USW connected web\nobjects (WOs) filled with data could outlive the individuals and institutions\nthat created the data in an environment where WOs are lost due to random\nfailures or directed attacks."
},{
    "category": "cs.DL", 
    "doi": "10.1109/BIBMW.2009.5332108", 
    "link": "http://arxiv.org/pdf/1004.5165v1", 
    "title": "Notations Around the World: Census and Exploitation", 
    "arxiv-id": "1004.5165v1", 
    "author": "Paul Libbrecht", 
    "publish": "2010-04-28T23:58:17Z", 
    "summary": "Mathematical notations around the world are diverse. Not as much as requiring\ncomputing machines' makers to adapt to each culture, but as much as to\ndisorient a person landing on a web-page with a text in mathematics. In order\nto understand better this diversity, we are building a census of notations: it\nshould allow any content creator or mathematician to grasp which mathematical\nnotation is used in which language and culture. The census is built\ncollaboratively, collected in pages with a given semantic and presenting\nobservations of the widespread notations being used in existing materials by a\ngraphical extract. We contend that our approach should dissipate the fallacies\nfound here and there about the notations in \"other cultures\" so that a better\nunderstanding of the cultures can be realized. The exploitation of the census\nin the math-bridge project is also presented: this project aims at taking\nlearners \"where they are in their math-knowledge\" and bring them to a level\nready to start engineering studies. The census serves as definitive reference\nfor the transformation elements that generate the rendering of formul{\\ae} in\nweb-browsers."
},{
    "category": "cs.DL", 
    "doi": "10.1109/BIBMW.2009.5332108", 
    "link": "http://arxiv.org/pdf/1005.0839v1", 
    "title": "Comparing Repository Types - Challenges and barriers for subject-based   repositories, research repositories, national repository systems and   institutional repositories in serving scholarly communication", 
    "arxiv-id": "1005.0839v1", 
    "author": "Laurent Romary", 
    "publish": "2010-05-05T19:59:46Z", 
    "summary": "After two decades of repository development, some conclusions may be drawn as\nto which type of repository and what kind of service best supports digital\nscholarly communication, and thus the production of new knowledge. Four types\nof publication repository may be distinguished, namely the subject-based\nrepository, research repository, national repository system and institutional\nrepository. Two important shifts in the role of repositories may be noted. With\nregard to content, a well-defined and high quality corpus is essential. This\nimplies that repository services are likely to be most successful when\nconstructed with the user and reader uppermost in mind. With regard to service,\nhigh value to specific scholarly communities is essential. This implies that\nrepositories are likely to be most useful to scholars when they offer dedicated\nservices supporting the production of new knowledge. Along these lines,\nchallenges and barriers to repository development may be identified in three\nkey dimensions: a) identification and deposit of content; b) access and use of\nservices; and c) preservation of content and sustainability of service. An\nindicative comparison of challenges and barriers in some major world regions\nsuch as Europe, North America and East Asia plus Australia is offered in\nconclusion."
},{
    "category": "cs.DL", 
    "doi": "10.1109/BIBMW.2009.5332108", 
    "link": "http://arxiv.org/pdf/1005.0950v1", 
    "title": "On Duplication in Mathematical Repositories", 
    "arxiv-id": "1005.0950v1", 
    "author": "Christoph Schwarzweller", 
    "publish": "2010-05-06T09:46:21Z", 
    "summary": "Building a repository of proof-checked mathematical knowledge is without any\ndoubt a lot of work, and besides the actual formalization process there also is\nthe task of maintaining the repository. Thus it seems obvious to keep a\nrepsoitory as small as possible, in particular each piece of mathematical\nknowledge should be formalized only once. In this paper, however, we claim that\nit might be reasonable or even necessary to duplicate knowledge in a\nmathematical repository. We analyze different situations and reasons for doing\nso and provide a number of examples supporting our thesis."
},{
    "category": "cs.DL", 
    "doi": "10.1109/BIBMW.2009.5332108", 
    "link": "http://arxiv.org/pdf/1005.4008v1", 
    "title": "An Ontology-based Context Aware System for Selective Dissemination of   Information in a Digital Library", 
    "arxiv-id": "1005.4008v1", 
    "author": "Juan P. Mart\u00ednez", 
    "publish": "2010-05-21T17:08:03Z", 
    "summary": "Users of Institutional Repositories and Digital Libraries are known by their\nneeds for very specific information about one or more subjects. To characterize\nusers profiles and offer them new documents and resources is one of the main\nchallenges of today's libraries. In this paper, a Selective Dissemination of\nInformation service is described, which proposes an Ontology-based Context\nAware system for identifying user's context (research subjects, work team,\nareas of interest). This system enables librarians to broaden users profiles\nbeyond the information that users have introduced by hand (such as institution,\nage and language). The system requires a context retrieval layer to capture\nuser information and behavior, and an inference engine to support context\ninference from many information sources (selected documents and users'\nqueries)."
},{
    "category": "cs.DL", 
    "doi": "10.1109/BIBMW.2009.5332108", 
    "link": "http://arxiv.org/pdf/1005.4026v1", 
    "title": "Dissertations Repository System Using Context Module", 
    "arxiv-id": "1005.4026v1", 
    "author": "Yahya Al-Nabhani", 
    "publish": "2010-05-21T17:43:28Z", 
    "summary": "Without a doubt, the electronic learning makes education quite flexible.\nNowadays, all organizations and institutions are trying to avoid Monotony and\nthe delay and inertia. As well the universities should be improving their\nsystems continually to achieve success. Whereas, the students need to access\nthe dissertations in the library. In this paper we will present Dissertations\nRepository System Using Context Module to allow the students to benefit the\ndissertations which is in the library flexibly."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-642-14128-7_38", 
    "link": "http://arxiv.org/pdf/1005.4552v1", 
    "title": "A Wiki for Mizar: Motivation, Considerations, and Initial Prototype", 
    "arxiv-id": "1005.4552v1", 
    "author": "Herman Geuvers", 
    "publish": "2010-05-25T12:42:29Z", 
    "summary": "Formal mathematics has so far not taken full advantage of ideas from\ncollaborative tools such as wikis and distributed version control systems\n(DVCS). We argue that the field could profit from such tools, serving both\nnewcomers and experts alike. We describe a preliminary system for such\ncollaborative development based on the Git DVCS. We focus, initially, on the\nMizar system and its library of formalized mathematics."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-642-14128-7_38", 
    "link": "http://arxiv.org/pdf/1006.1993v1", 
    "title": "Rozw\u00f3j bibliotek cyfrowych i repozytori\u00f3w elektronicznych na Dolnym   Slasku w latach 2004-2008 / Development of Digital Libraries and Electronic   Repositories in Lower Silesia in Years 2004-2008", 
    "arxiv-id": "1006.1993v1", 
    "author": "Piotr Rossa", 
    "publish": "2010-06-10T10:25:52Z", 
    "summary": "In following elaboration were presented digital libraries and electronic\nrepositories operating in Lower Silesia region (of Poland) in years 2004-2008.\nGeneral description of character and size of their collections was presented,\nas well as standards and methods of digital collections management and\njuridical aspects of this management. Potential of usage of digital collections\nin regional scientific researches was described.\n  -----\n  W referacie przedstawiono biblioteki cyfrowe i repozytoria elektroniczne\nfunkcjonujace na Dolnym Slasku w latach 2004-2008. Scharakteryzowano og\\'olnie\nich zawarto\\'s\\'c i wielko\\'s\\'c, zaprezentowano standardy i systemy\nzarzadzania kolekcjami cyfrowymi oraz om\\'owiono uwarunkowania prawne\ntowarzyszace zarzadzaniu zasobami cyfrowymi. Wskazano mo\\.zliwo\\'sci\nwykorzystania kolekcji cyfrowych w badaniach naukowych realizowanych w\nregionie."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-642-14128-7_38", 
    "link": "http://arxiv.org/pdf/1006.4547v1", 
    "title": "New Quantitative Study for Dissertations Repository System", 
    "arxiv-id": "1006.4547v1", 
    "author": "A. A. Zaidan", 
    "publish": "2010-06-23T15:05:47Z", 
    "summary": "In the age of technology, the information communication technology becomes\nvery important especially in education field. Students must be allowed to learn\nanytime, anywhere and at their own place. The facility of library in the\nuniversity should be developed. In this paper we are going to present new\nQuantitative Study for Dissertations Repository System and also recommend\nfuture application of the approach."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-642-14128-7_38", 
    "link": "http://arxiv.org/pdf/1009.1466v1", 
    "title": "The Development of the Journal Environment of Leonardo", 
    "arxiv-id": "1009.1466v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2010-09-08T07:36:55Z", 
    "summary": "We present animations based on the aggregated journal-journal citations of\nLeonardo during the period 1974-2008. Leonardo is mainly cited by journals\noutside the arts domain for cultural reasons, for example, in neuropsychology\nand physics. Articles in Leonardo itself cite a large number of journals, but\nwith a focus on the arts. Animations at this level of aggregation enable us to\nshow the history of the journal from a network perspective."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2010.12.001", 
    "link": "http://arxiv.org/pdf/1009.3359v3", 
    "title": "An evaluation of the Australian Research Council's journal ranking", 
    "arxiv-id": "1009.3359v3", 
    "author": "Jerome K. Vanclay", 
    "publish": "2010-09-17T08:14:27Z", 
    "summary": "As part of its program of 'Excellence in Research for Australia' (ERA), the\nAustralian Research Council ranked journals into four categories (A*, A, B, C)\nin preparation for their performance evaluation of Australian universities. The\nranking is important because it likely to have a major impact on publication\nchoices and research dissemination in Australia. The ranking is problematic\nbecause it is evident that some disciplines have been treated very differently\nthan others. This paper reveals weaknesses in the ERA journal ranking and\nhighlights the poor correlation between ERA rankings and other acknowledged\nmetrics of journal standing. It highlights the need for a reasonable\nrepresentation of journals ranked as A* in each scientific discipline."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2010.12.001", 
    "link": "http://arxiv.org/pdf/1010.0506v1", 
    "title": "First results of the SOAP project. Open access publishing in 2010", 
    "arxiv-id": "1010.0506v1", 
    "author": "Wim van der Stelt", 
    "publish": "2010-10-04T08:40:16Z", 
    "summary": "The SOAP (Study of Open Access Publishing) project has compiled data on the\npresent offer for open access publishing in online peer-reviewed journals.\nStarting from the Directory of Open Access Journals, several sources of data\nare considered, including inspection of journal web site and direct inquiries\nwithin the publishing industry. Several results are derived and discussed,\ntogether with their correlations: the number of open access journals and\narticles; their subject area; the starting date of open access journals; the\nsize and business models of open access publishers; the licensing models; the\npresence of an impact factor; the uptake of hybrid open access."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2010.12.001", 
    "link": "http://arxiv.org/pdf/1010.5935v1", 
    "title": "Editing Knowledge in Large Mathematical Corpora. A case study with   Semantic LaTeX (sTeX)", 
    "arxiv-id": "1010.5935v1", 
    "author": "Constantin Jucovschi", 
    "publish": "2010-10-28T12:13:41Z", 
    "summary": "Before we can get the whole potential of employing computers in the process\nof managing mathematical `knowledge', we have to convert informal knowledge\ninto machine-oriented representations. How exactly to support this process so\nthat it becomes as effortless as possible is one of the main unsolved problems\nof Mathematical Knowledge Management.\n  Two independent projects in formalization of mathematical content showed that\nmany of the time consuming tasks could be significantly reduced if adequate\ntool support were available. It was also established that similar tasks are\ntypical for object oriented languages and that they are to a large extent\nsolved by Integrated Development Environments (IDE).\n  This thesis starts by analyzing the opportunities where formalization process\ncan benefit from software support. A list of research questions is compiled\nalong with a set of software requirements which are then used for developing a\nnew IDE for the semantic \\TeX{} (\\stex{}) format. The result of the current\nresearch is that, indeed, IDEs can be very useful in the process of\nformalization and presents a set of best practices for implementing such IDEs."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2010.12.001", 
    "link": "http://arxiv.org/pdf/1011.4879v1", 
    "title": "Analysis of Generalized Impact Factor and Indices of Journals", 
    "arxiv-id": "1011.4879v1", 
    "author": "Ash Mohammad Abbas", 
    "publish": "2010-11-22T17:25:45Z", 
    "summary": "Analyzing the relationships among the parameters for quantifying the quality\nof research published in journals is a challenging task. In this paper, we\nanalyze the relationships between impact factor, h-index, and g-index of a\njournal. To keep our analysis simple and easy to understand, we consider a\ngeneralized version of the impact factor where there is no time window. In the\nabsence of the time window, the impact factor converges to the number of\ncitations received per paper. This is not only justified for the impact factor,\nit simplifies the analysis of h-index and g-index as well because addition of a\ntime window in the form of years complicates the computation of indices too. We\nderive the expressions for the relationships among impact factor, h-index, and\ng-index and validate them using a given set of publication-citation data."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2010.12.001", 
    "link": "http://arxiv.org/pdf/1012.0160v1", 
    "title": "A Joint Initiative to Support the Semantic Interoperability within the   GIIDA Project", 
    "arxiv-id": "1012.0160v1", 
    "author": "Riccardo Albertoni", 
    "publish": "2010-12-01T11:15:23Z", 
    "summary": "The GIIDA project aims to develop a digital infrastructure for the spatial\ninformation within CNR. It is foreseen to use semantic-oriented technologies to\nease information modeling and connecting, according to international standards\nlike the ISO/IEC 11179. Complex information management systems, like GIIDA,\nwill take benefit from the use of terminological tools like thesauri that make\navailable a reference lexicon for the indexing and retrieval of information.\nWithin GIIDA the goal is to make available the EARTh thesaurus (Environmental\nApplications Reference Thesaurus), developed by the CNR-IIA-EKOLab. A web-based\nsoftware, developed by the CNR-Water Research Institute (IRSA) was implemented\nto allow consultation and utilization of thesaurus through the web. This\nservice is a useful tool to ensure interoperability between thesaurus and other\nsystems of the indexing, with, the idea of cooperating to develop a\ncomprehensive system of knowledge organization, that could be defined\nintegrated, open, multi-functional and multilingual. Currently the system is\navailable in multiple languages mode (Italian - English) and navigation can be\ndone in the following ways: Alphabetical, Hierarchical and for Themes. A full\nsearch allows to find any term by searching for the whole term or a part of it\nand as well as allows to filter the results by themes. Within a collaborative\ninitiative with the CNR-Institute of Applied Mathematics and Information\nTechnology (IMATI) a SKOS (Simple Knowledge Organization System) version of\nEARTh was developed. This will ensure the possibility to support the use of the\nthesaurus within the framework of the Semantic Web in order to be used in\ndecentralized metadata applications"
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2010.12.001", 
    "link": "http://arxiv.org/pdf/1012.0359v1", 
    "title": "Fractional counting of citations in research evaluation: An option for   cross- and interdisciplinary assessments", 
    "arxiv-id": "1012.0359v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2010-12-02T01:23:23Z", 
    "summary": "In the case of the scientometric evaluation of multi- or interdisciplinary\nunits one risks to compare apples with oranges: each paper has to assessed in\ncomparison to an appropriate reference set. We suggest that the set of citing\npapers first can be considered as the relevant representation of the field of\nimpact. In order to normalize for differences in citation behavior among\nfields, citations can be fractionally counted proportionately to the length of\nthe reference lists in the citing papers. This new method enables us to compare\namong units with different disciplinary affiliations at the paper level and\nalso to assess the statistical significance of differences among sets.\nTwenty-seven departments of the Tsinghua University in Beijing are thus\ncompared. Among them, the Department of Chinese Language and Linguistics is\nupgraded from the 19th to the second position in the ranking. The overall\nimpact of 19 of the 27 departments is not significantly different at the 5%\nlevel when thus normalized for different citation potentials."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2010.12.001", 
    "link": "http://arxiv.org/pdf/1012.1638v1", 
    "title": "Ontology and Knowledge Management System on Epilepsy and Epileptic   Seizures", 
    "arxiv-id": "1012.1638v1", 
    "author": "Ant\u00f3nio Dourado", 
    "publish": "2010-12-07T23:20:15Z", 
    "summary": "A Knowledge Management System developed for supporting creation, capture,\nstorage and dissemination of information about Epilepsy and Epileptic Seizures\nis presented. We present an Ontology on Epilepsy and a Web-based prototype that\ntogether create the KMS."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2010.12.001", 
    "link": "http://arxiv.org/pdf/1012.1652v1", 
    "title": "Import of ENZYME data into the ConceptWiki and its representation as RDF", 
    "arxiv-id": "1012.1652v1", 
    "author": "Christine Chichester", 
    "publish": "2010-12-08T00:31:10Z", 
    "summary": "Solutions to the classic problems of dealing with heterogeneous data and\nmaking entire collections interoperable while ensuring that any annotation,\nwhich includes the recognition-and-reward system of scientific publishing, need\nto fit into a seamless beginning to end to attract large numbers of end users.\nThe latest trend in Web applications encourages highly interactive Web sites\nwith rich user interfaces featuring content integrated from various sources\naround the Web. The obvious potential of RDF, SPARQL, and OWL to provide\nflexible data modeling, easier data integration, and networked data access may\nbe the answer to the classic problems. Using Semantic Web technologies we have\ncreated a Web application, the ConceptWiki, as an end-to-end solution for\ncreating browserbased readwrite triples using RDF, which focus on data\nintegration and ease of use for the end user. Here we will demonstrate the\nintegration of a biological data source, the ENZYME database, into the\nConceptWiki and it's representation in RDF."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2010.12.001", 
    "link": "http://arxiv.org/pdf/1012.2019v1", 
    "title": "Comparative Analysis of Existing Methods and Algorithms for Automatic   Assignment of Reviewers to Papers", 
    "arxiv-id": "1012.2019v1", 
    "author": "Boris Rachev", 
    "publish": "2010-12-09T14:44:08Z", 
    "summary": "The article focuses on the importance of the automatic assignment of\nreviewers to papers for increasing the assignment accuracy therefore the\nquality of the scientific event itself. It discusses the main aspects that\ninfluence the assignment accuracy, performs a detailed analysis of the methods\nof describing papers and reviewers' competences used by the existing conference\nmanagement systems and suggests some improvements in the way the similarity\nfactors are calculated."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2010.12.001", 
    "link": "http://arxiv.org/pdf/1012.4862v1", 
    "title": "Applying centrality measures to impact analysis: A coauthorship network   analysis", 
    "arxiv-id": "1012.4862v1", 
    "author": "Ying Ding", 
    "publish": "2010-12-22T02:37:41Z", 
    "summary": "Many studies on coauthorship networks focus on network topology and network\nstatistical mechanics. This article takes a different approach by studying\nmicro-level network properties, with the aim to apply centrality measures to\nimpact analysis. Using coauthorship data from 16 journals in the field of\nlibrary and information science (LIS) with a time span of twenty years\n(1988-2007), we construct an evolving coauthorship network and calculate four\ncentrality measures (closeness, betweenness, degree and PageRank) for authors\nin this network. We find out that the four centrality measures are\nsignificantly correlated with citation counts. We also discuss the usability of\ncentrality measures in author ranking, and suggest that centrality measures can\nbe useful indicators for impact analysis."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2010.12.001", 
    "link": "http://arxiv.org/pdf/1012.4870v1", 
    "title": "Discovering author impact: A PageRank perspective", 
    "arxiv-id": "1012.4870v1", 
    "author": "Ying Ding", 
    "publish": "2010-12-22T03:05:20Z", 
    "summary": "This article provides an alternative perspective for measuring author impact\nby applying PageRank algorithm to a coauthorship network. A weighted PageRank\nalgorithm considering citation and coauthorship network topology is proposed.\nWe test this algorithm under different damping factors by evaluating author\nimpact in the informetrics research community. In addition, we also compare\nthis weighted PageRank with the h-index, citation, and program committee (PC)\nmembership of the International Society for Scientometrics and Informetrics\n(ISSI) conferences. Findings show that this weighted PageRank algorithm\nprovides reliable results in measuring author impact."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2010.12.001", 
    "link": "http://arxiv.org/pdf/1012.4871v1", 
    "title": "Popular and/or Prestigious? Measures of Scholarly Esteem", 
    "arxiv-id": "1012.4871v1", 
    "author": "Blaise Cronin", 
    "publish": "2010-12-22T03:19:22Z", 
    "summary": "Citation analysis does not generally take the quality of citations into\naccount: all citations are weighted equally irrespective of source. However, a\nscholar may be highly cited but not highly regarded: popularity and prestige\nare not identical measures of esteem. In this study we define popularity as the\nnumber of times an author is cited and prestige as the number of times an\nauthor is cited by highly cited papers. Information Retrieval (IR) is the test\nfield. We compare the 40 leading researchers in terms of their popularity and\nprestige over time. Some authors are ranked high on prestige but not on\npopularity, while others are ranked high on popularity but not on prestige. We\nalso relate measures of popularity and prestige to date of Ph.D. award, number\nof key publications, organizational affiliation, receipt of prizes/honors, and\ngender."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2010.12.001", 
    "link": "http://arxiv.org/pdf/1012.4872v1", 
    "title": "PageRank for ranking authors in co-citation networks", 
    "arxiv-id": "1012.4872v1", 
    "author": "James Caverlee", 
    "publish": "2010-12-22T03:26:00Z", 
    "summary": "Google's PageRank has created a new synergy to information retrieval for a\nbetter ranking of Web pages. It ranks documents depending on the topology of\nthe graphs and the weights of the nodes. PageRank has significantly advanced\nthe field of information retrieval and keeps Google ahead of competitors in the\nsearch engine market. It has been deployed in bibliometrics to evaluate\nresearch impact, yet few of these studies focus on the important impact of the\ndamping factor (d) for ranking purposes. This paper studies how varied damping\nfactors in the PageRank algorithm can provide additional insight into the\nranking of authors in an author co-citation network. Furthermore, we propose\nweighted PageRank algorithms. We select 108 most highly cited authors in the\ninformation retrieval (IR) area from the 1970s to 2008 to form the author\nco-citation network. We calculate the ranks of these 108 authors based on\nPageRank with damping factor ranging from 0.05 to 0.95. In order to test the\nrelationship between these different measures, we compare PageRank and weighted\nPageRank results with the citation ranking, h-index, and centrality measures.\nWe found that in our author co-citation network, citation rank is highly\ncorrelated with PageRank's with different damping factors and also with\ndifferent PageRank algorithms; citation rank and PageRank are not significantly\ncorrelated with centrality measures; and h-index is not significantly\ncorrelated with centrality measures."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2010.12.001", 
    "link": "http://arxiv.org/pdf/1012.4876v1", 
    "title": "Weighted citation: An indicator of an article's prestige", 
    "arxiv-id": "1012.4876v1", 
    "author": "Ying Ding", 
    "publish": "2010-12-22T03:39:03Z", 
    "summary": "We propose using the technique of weighted citation to measure an article's\nprestige. The technique allocates a different weight to each reference by\ntaking into account the impact of citing journals and citation time intervals.\nWeighted citation captures prestige, whereas citation counts capture\npopularity. We compare the value variances for popularity and prestige for\narticles published in the Journal of the American Society for Information\nScience and Technology from 1998 to 2007, and find that the majority have\ncomparable status."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-642-15464-5_24", 
    "link": "http://arxiv.org/pdf/1012.5396v1", 
    "title": "Analysis of Computer Science Communities Based on DBLP", 
    "arxiv-id": "1012.5396v1", 
    "author": "Cailing Dong", 
    "publish": "2010-12-24T13:18:05Z", 
    "summary": "It is popular nowadays to bring techniques from bibliometrics and\nscientometrics into the world of digital libraries to analyze the collaboration\npatterns and explore mechanisms which underlie community development. In this\npaper we use the DBLP data to investigate the author's scientific career and\nprovide an in-depth exploration of some of the computer science communities. We\ncompare them in terms of productivity, population stability and collaboration\ntrends.Besides we use these features to compare the sets of topranked\nconferences with their lower ranked counterparts."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-642-15464-5_24", 
    "link": "http://arxiv.org/pdf/1012.5477v1", 
    "title": "Generalized Linear Weights for Sharing Credits Among Multiple Authors", 
    "arxiv-id": "1012.5477v1", 
    "author": "Ash Mohammad Abbas", 
    "publish": "2010-12-25T14:04:00Z", 
    "summary": "Assignment of weights to multiple authors of a paper is a challenging task\ndue to its dependence on the conventions that may be different among different\nfields of research and research groups. In this paper, we describe a scheme for\nassignment of weights to multiple authors of a paper. In our scheme, weights\nare assigned in a linearly decreasing/increasing fashion depending upon the\nweight decrement/increment parameter. We call our scheme Arithmetic: Type-2\nscheme as the weights follow an arithmetic series. We analyze the proposed\nweight assignment scheme and compare it with the existing schemes such as\nequal, arithmetic, geometric, and harmonic. We argue that the a positional\nweight assignment scheme, called arithmetic scheme, which we refer to\nArithmetic: Type-1 in this paper, and the equal weight assignment scheme can be\ntreated as special cases of the proposed Arithmetic: Type-2 scheme."
},{
    "category": "cs.DL", 
    "doi": "10.3989/redc.2013.1.876", 
    "link": "http://arxiv.org/pdf/1101.2711v1", 
    "title": "A Proposal to Classify Latinamerican Scientific Journals using Citation   Indicators: Case Study in Colombia", 
    "arxiv-id": "1101.2711v1", 
    "author": "Alberto Acosta", 
    "publish": "2011-01-14T03:16:58Z", 
    "summary": "Colombian scientific journals are poorly represented in international digital\nlibraries; however, through Google Scholar (GS) it is possible to determine\ntheir use by the community. Between the years of 2003 and 2007 a classification\nof 185 Colombian journals indexed in the Colombian National Bibliographical\nIndex (IBNP) was performed using the information provided by GS, basing\ncategorization on size indicators, indexation and citation. The indicators were\nanalyzed by grouping the journals in two general areas: sciences and social\nsciences. In each area, the indicators provided by the digital libraries\nScopus, Redalyc and Scielo were compared. Additionally, the indicators provided\nby IBNP journals categories (A1, A2, B and C) were also compared. The sciences\nand social sciences had a similar pattern in their indicators. The existence of\npositive correlations was established between some indicators and they\npredicted that the number of citations per journal in GS and the h index\ndepends on its visibility in GS and Scopus. We put forward that the current\nIBNP categories (A1, A2, B or C) faintly reflect the use of journals by the\ncommunity and we propose a classification based on the h index as an infometric\nindicator, which reflects not only its visibility in Google Scholar, but also\nits inclusion in certain international digital libraries, particularly Scopus.\nOur results may be applied to the creation of public policies regarding science\nand technology in Colombia and in developing countries."
},{
    "category": "cs.DL", 
    "doi": "10.3989/redc.2013.1.876", 
    "link": "http://arxiv.org/pdf/1101.4750v1", 
    "title": "Fractional counting of citations in research evaluation: A cross- and   interdisciplinary assessment of the Tsinghua University in Beijing", 
    "arxiv-id": "1101.4750v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2011-01-25T09:13:15Z", 
    "summary": "In the case of the scientometric evaluation of multi- or interdisciplinary\nunits one risks to compare apples with oranges: each paper has to be assessed\nin comparison to an appropriate reference set. We suggest that the set of\nciting papers can be considered as the relevant representation of the field of\nimpact. In order to normalize for differences in citation behavior among\nfields, citations can be fractionally counted proportionately to the length of\nthe reference lists in the citing papers. This new method enables us to compare\namong units with different disciplinary affiliations at the paper level and\nalso to assess the statistical significance of differences among sets.\nTwenty-seven departments of the Tsinghua University in Beijing are thus\ncompared. Among them, the Department of Chinese Language and Linguistics is\nupgraded from the 19th to the second position in the ranking. The overall\nimpact of 19 of the 27 departments is not significantly different at the 5%\nlevel when thus normalized for different citation potentials."
},{
    "category": "cs.DL", 
    "doi": "10.3989/redc.2013.1.876", 
    "link": "http://arxiv.org/pdf/1101.5260v2", 
    "title": "Highlights from the SOAP project survey. What Scientists Think about   Open Access Publishing", 
    "arxiv-id": "1101.5260v2", 
    "author": "Wim van der Stelt", 
    "publish": "2011-01-27T11:49:17Z", 
    "summary": "The SOAP (Study of Open Access Publishing) project has run a large-scale\nsurvey of the attitudes of researchers on, and the experiences with, open\naccess publishing. Around forty thousands answers were collected across\ndisciplines and around the world, showing an overwhelming support for the idea\nof open access, while highlighting funding and (perceived) quality as the main\nbarriers to publishing in open access journals. This article serves as an\nintroduction to the survey and presents this and other highlights from a\npreliminary analysis of the survey responses. To allow a maximal re-use of the\ninformation collected by this survey, the data are hereby released under a CC0\nwaiver, so to allow libraries, publishers, funding agencies and academics to\nfurther analyse risks and opportunities, drivers and barriers, in the\ntransition to open access publishing."
},{
    "category": "cs.DL", 
    "doi": "10.3989/redc.2013.1.876", 
    "link": "http://arxiv.org/pdf/1101.5833v1", 
    "title": "The Documents and Assets Created During the Video Game Production   Process", 
    "arxiv-id": "1101.5833v1", 
    "author": "Katy Daiger", 
    "publish": "2011-01-30T23:32:46Z", 
    "summary": "The purpose of this paper is to take that first step in helping archivists\nunderstand the video game industry by examining the documents and assets\ncreated by game companies. This paper is intended as a survey of the records\ngenerated during video game production, and an overview of why and how those\nrecords are created. It is not intended to be a statement on archiving best\npractices, but rather a tool for archivists to use when assessing and\nprocessing video game collections. It is an overview of how a video game is\nmade and the paper trail left behind that an archivist might encounter."
},{
    "category": "cs.DL", 
    "doi": "10.3989/redc.2013.1.876", 
    "link": "http://arxiv.org/pdf/1102.1760v1", 
    "title": "Applying weighted PageRank to author citation networks", 
    "arxiv-id": "1102.1760v1", 
    "author": "Ying Ding", 
    "publish": "2011-02-09T01:46:22Z", 
    "summary": "This paper aims to identify whether different weighted PageRank algorithms\ncan be applied to author citation networks to measure the popularity and\nprestige of a scholar from a citation perspective. Information Retrieval (IR)\nwas selected as a test field and data from 1956-2008 were collected from Web of\nScience (WOS). Weighted PageRank with citation and publication as weighted\nvectors were calculated on author citation networks. The results indicate that\nboth popularity rank and prestige rank were highly correlated with the weighted\nPageRank. Principal Component Analysis (PCA) was conducted to detect\nrelationships among these different measures. For capturing prize winners\nwithin the IR field, prestige rank outperformed all the other measures."
},{
    "category": "cs.DL", 
    "doi": "10.3989/redc.2013.1.876", 
    "link": "http://arxiv.org/pdf/1102.3047v1", 
    "title": "Publish or Patent: Bibliometric evidence for empirical trade-offs in   national funding strategies", 
    "arxiv-id": "1102.3047v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2011-02-15T12:27:59Z", 
    "summary": "Multivariate linear regression models suggest a trade-off in allocations of\nnational R&D investments. Government funding, and spending in the higher\neducation sector, seem to encourage publications, whereas other components such\nas industrial funding, and spending in the business sector, encourage\npatenting. Our results help explain why the US trails the EU in publications,\nbecause of its focus on industrial funding - some 70% of its total R&D\ninvestment. Conversely, it also helps explain why the EU trails the US in\npatenting. Government funding is indicated as a negative incentive to\nhigh-quality patenting. The models here can also be used to predict an output\nindicator for a country, once the appropriate input indicator is known. This\nusually is done within a dataset for a single year, but the process can be\nextended to predict outputs a few years into the future, if reasonable\nforecasts can be made of the input indicators. We provide new forecasts about\nthe further relationships of the US, the EU-27, and the PRC in the case of\npublishing. Models for individual countries may be more successful, however,\nthan regression models whose parameters are averaged over a set of countries."
},{
    "category": "cs.DL", 
    "doi": "10.3989/redc.2013.1.876", 
    "link": "http://arxiv.org/pdf/1102.3523v1", 
    "title": "PaperBricks: An Alternative to Complete-Story Peer Reviewing", 
    "arxiv-id": "1102.3523v1", 
    "author": "Jens Dittrich", 
    "publish": "2011-02-17T08:32:39Z", 
    "summary": "The peer review system as used in several computer science communities has\nseveral flaws including long review times, overloaded reviewers, as well as\nfostering of niche topics. These flaws decrease quality, lower impact, slowdown\nthe innovation process, and lead to frustration of authors, readers, and\nreviewers. In order to fix this, we propose a new peer review system termed\npaper bricks. Paper bricks has several advantages over the existing system\nincluding shorter publications, better competition for new ideas, as well as an\naccelerated innovation process. Furthermore, paper bricks may be implemented\nwith minimal change to the existing peer review systems."
},{
    "category": "cs.DL", 
    "doi": "10.3989/redc.2013.1.876", 
    "link": "http://arxiv.org/pdf/1102.3862v2", 
    "title": "The detection of \"hot regions\" in the geography of science: A   visualization approach by using density maps", 
    "arxiv-id": "1102.3862v2", 
    "author": "Ludo Waltman", 
    "publish": "2011-02-18T15:52:23Z", 
    "summary": "Spatial scientometrics has attracted a lot of attention in the very recent\npast. The visualization methods (density maps) presented in this paper allow\nfor an analysis revealing regions of excellence around the world using computer\nprograms that are freely available. Based on Scopus and Web of Science data,\nfield-specific and field-overlapping scientific excellence can be identified in\nbroader regions (worldwide or for a specific continent) where high quality\npapers (highly cited papers or papers published in Nature or Science) were\npublished. We used a geographic information system to produce our density maps.\nWe also briefly discuss the use of Google Earth."
},{
    "category": "cs.DL", 
    "doi": "10.3989/redc.2013.1.876", 
    "link": "http://arxiv.org/pdf/1102.4078v2", 
    "title": "An Analytical Model for Service Profile Based Service Quality of an   Institutional eLibrary", 
    "arxiv-id": "1102.4078v2", 
    "author": "Ash Mohammad Abbas", 
    "publish": "2011-02-20T16:02:33Z", 
    "summary": "Devising a scheme for evaluating the service quality of an institutional\nelectronic library is a difficult and challenging task. The challenge comes\nfrom the fact that the services provided by an institutional electronic library\ndepend upon the contents requested by the users and the contents housed by the\nlibrary. Different types of users might be interested in different types of\ncontents. In this paper, we propose a technique for evaluating the service\nquality of an institutional electronic library. Our scheme is based on the\nservice profiles of contents requested by the users at the server side which is\nhosted at the library. Further, we propose models to analyze the service\nquality of an electronic library. For analyzing the service quality, we present\ntwo analytical models. The first one is based on the number of days by which\nthe item to be served by the library is delayed and the penalty points per day\nfor the duration for which the item is delayed. The second model is based on\nthe credits earned by the library if the item is served in a timely fashion,\nand the penalties, thereof, if the item is delayed. These models may help in\nevaluating the service quality of an electronic library and taking the\ncorrective measures to improve it."
},{
    "category": "cs.DL", 
    "doi": "10.3989/redc.2013.1.876", 
    "link": "http://arxiv.org/pdf/1103.1977v1", 
    "title": "Development of Computer Science Disciplines - A Social Network Analysis   Approach", 
    "arxiv-id": "1103.1977v1", 
    "author": "Matthias Jarke", 
    "publish": "2011-03-10T09:51:19Z", 
    "summary": "In contrast to many other scientific disciplines, computer science considers\nconference publications. Conferences have the advantage of providing fast\npublication of papers and of bringing researchers together to present and\ndiscuss the paper with peers. Previous work on knowledge mapping focused on the\nmap of all sciences or a particular domain based on ISI published JCR (Journal\nCitation Report). Although this data covers most of important journals, it\nlacks computer science conference and workshop proceedings. That results in an\nimprecise and incomplete analysis of the computer science knowledge. This paper\npresents an analysis on the computer science knowledge network constructed from\nall types of publications, aiming at providing a complete view of computer\nscience research. Based on the combination of two important digital libraries\n(DBLP and CiteSeerX), we study the knowledge network created at\njournal/conference level using citation linkage, to identify the development of\nsub-disciplines. We investigate the collaborative and citation behavior of\njournals/conferences by analyzing the properties of their co-authorship and\ncitation subgraphs. The paper draws several important conclusions. First,\nconferences constitute social structures that shape the computer science\nknowledge. Second, computer science is becoming more interdisciplinary. Third,\nexperts are the key success factor for sustainability of journals/conferences."
},{
    "category": "cs.DL", 
    "doi": "10.3989/redc.2013.1.876", 
    "link": "http://arxiv.org/pdf/1103.2848v1", 
    "title": "Polynomial Weights or Generalized Geometric Weights: Yet Another Scheme   for Assigning Credits to Multiple Authors", 
    "arxiv-id": "1103.2848v1", 
    "author": "Ash Mohammad Abbas", 
    "publish": "2011-03-15T06:06:46Z", 
    "summary": "Devising a weight assignment policy for assigning credits to multiple authors\nof a manuscript is a challenging task. In this paper, we present a scheme for\nassigning credits to multiple authors that we call a polynomial weight\nassignment scheme. We compare our scheme with other schemes proposed in the\nliterature."
},{
    "category": "cs.DL", 
    "doi": "10.3989/redc.2013.1.876", 
    "link": "http://arxiv.org/pdf/1103.3648v2", 
    "title": "Globalisation of science in kilometres", 
    "arxiv-id": "1103.3648v2", 
    "author": "Nees Jan van Eck", 
    "publish": "2011-03-18T15:13:29Z", 
    "summary": "The ongoing globalisation of science has undisputedly a major impact on how\nand where scientific research is being conducted nowadays. Yet, the big picture\nremains blurred. It is largely unknown where this process is heading, and at\nwhich rate. Which countries are leading or lagging? Many of its key features\nare difficult if not impossible to capture in measurements and comparative\nstatistics. Our empirical study measures the extent and growth of scientific\nglobalisation in terms of physical distances between co-authoring researchers.\nOur analysis, drawing on 21 million research publications across all countries\nand fields of science, reveals that contemporary science has globalised at a\nfairly steady rate during recent decades. The average collaboration distance\nper publication has increased from 334 kilometres in 1980 to 1553 in 2009.\nDespite significant differences in globalisation rates across countries and\nfields of science, we observe a pervasive process in motion, moving towards a\ntruly interconnected global science system."
},{
    "category": "cs.DL", 
    "doi": "10.3989/redc.2013.1.876", 
    "link": "http://arxiv.org/pdf/1103.4218v1", 
    "title": "Universal Metadata Standard", 
    "arxiv-id": "1103.4218v1", 
    "author": "Andrej Poleev", 
    "publish": "2011-03-22T07:20:03Z", 
    "summary": "The creation of a next generation internet (semantic web) is impossible\nwithout attributes, allowing the semantic association of documents and their\nintegration into information context. To achieve these goals, the Universal\nMetadata Standard (ums) may be an ultimative tool, which could serve as a basis\nfor documentography, and is functionally required for interpretation of\ndocuments by the automatic operating systems."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0033699", 
    "link": "http://arxiv.org/pdf/1103.5045v1", 
    "title": "Bounds and Inequalities Relating h-Index, g-Index, e-Index and   Generalized Impact Factor", 
    "arxiv-id": "1103.5045v1", 
    "author": "Ash Mohammad Abbas", 
    "publish": "2011-03-25T17:47:40Z", 
    "summary": "Finding relationships among different indices such as h-index, g-index,\ne-index, and generalized impact factor is a challenging task. In this paper, we\ndescribe some bounds and inequalities relating h-index, g-index, e-index, and\ngeneralized impact factor. We derive the bounds and inequalities relating these\nindexing parameters from their basic definitions and without assuming any\ncontinuous model to be followed by any of them."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0033699", 
    "link": "http://arxiv.org/pdf/1103.5162v1", 
    "title": "Progress of concepts and processes in library information system:   towards Library 2.0", 
    "arxiv-id": "1103.5162v1", 
    "author": "Sahbi Sidhom", 
    "publish": "2011-03-26T20:36:35Z", 
    "summary": "The main principle of the Library 2.0 is in the fact that the information has\nto be spread from the library to the user and viceversa, to allow fast and\npermanent adaptation of the library services. Within the framework of the\nimplementation of the \"Departmental Plan of the Public Services Reading\" by the\n\"General Council of Moselle\", the division of the public reading develops a\ndepartmental portal as main vector of the information with various users'\nprofile. The context of this research work takes a part of a Master degree\ntraining Diploma in STI-Economic Intelligence (Nancy2 University), combining\nfacets of R&D in a professional context at the \"Conseil G\\'en\\'eral de la\nMoselle\" in France."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0033699", 
    "link": "http://arxiv.org/pdf/1105.2392v1", 
    "title": "Workflows for the Management of Change in Science, Technologies,   Engineering and Mathematics", 
    "arxiv-id": "1105.2392v1", 
    "author": "Vyacheslav Zholudev", 
    "publish": "2011-05-12T07:31:08Z", 
    "summary": "Mathematical knowledge is a central component in science, engineering, and\ntechnology (documentation). Most of it is represented informally, and -- in\ncontrast to published research mathematics -- subject to continual change.\nUnfortunately, machine support for change management has either been very\ncoarse grained and thus barely useful, or restricted to formal languages, where\nautomation is possible. In this paper, we report on an effort to extend change\nmanagement to collections of semi-formal documents which flexibly intermix\nmathematical formulas and natural language and to integrate it into a semantic\npublishing system for mathematical knowledge. We validate the long-standing\nassumption that the semantic annotations in these flexiformal documents that\ndrive the machine-supported interaction with documents can support semantic\nimpact analyses at the same time. But in contrast to the fully formal setting,\nwhere adaptations of impacted documents can be automated to some degree, the\nflexiformal setting requires much more user interaction and thus a much tighter\nintegration into document management workflows."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0033699", 
    "link": "http://arxiv.org/pdf/1105.2925v1", 
    "title": "Interactive Overlays: A New Method for Generating Global Journal Maps   from Web-of-Science Data", 
    "arxiv-id": "1105.2925v1", 
    "author": "Ismael Rafols", 
    "publish": "2011-05-15T06:19:13Z", 
    "summary": "Recent advances in methods and techniques enable us to develop an interactive\noverlay to the global map of science based on aggregated citation relations\namong the 9,162 journals contained in the Science Citation Index and Social\nScience Citation Index 2009 combined. The resulting mapping is provided by\nVOSViewer. We first discuss the pros and cons of the various options: cited\nversus citing, multidimensional scaling versus spring-embedded algorithms,\nVOSViewer versus Gephi, and the various clustering algorithms and similarity\ncriteria. Our approach focuses on the positions of journals in the\nmultidimensional space spanned by the aggregated journal-journal citations. A\nnumber of choices can be left to the user, but we provide default options\nreflecting our preferences. Some examples are also provided; for example, the\npotential of using this technique to assess the interdisciplinarity of\norganizations and/or document sets."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0033699", 
    "link": "http://arxiv.org/pdf/1105.3212v1", 
    "title": "A recursive field-normalized bibliometric performance indicator: An   application to the field of library and information science", 
    "arxiv-id": "1105.3212v1", 
    "author": "Nees Jan van Eck", 
    "publish": "2011-05-16T20:25:08Z", 
    "summary": "Two commonly used ideas in the development of citation-based research\nperformance indicators are the idea of normalizing citation counts based on a\nfield classification scheme and the idea of recursive citation weighing (like\nin PageRank-inspired indicators). We combine these two ideas in a single\nindicator, referred to as the recursive mean normalized citation score\nindicator, and we study the validity of this indicator. Our empirical analysis\nshows that the proposed indicator is highly sensitive to the field\nclassification scheme that is used. The indicator also has a strong tendency to\nreinforce biases caused by the classification scheme. Based on these\nobservations, we advise against the use of indicators in which the idea of\nnormalization based on a field classification scheme and the idea of recursive\ncitation weighing are combined."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0033699", 
    "link": "http://arxiv.org/pdf/1105.3287v1", 
    "title": "Scholarly Communication", 
    "arxiv-id": "1105.3287v1", 
    "author": "Laurent Romary", 
    "publish": "2011-05-17T07:06:14Z", 
    "summary": "The chapter tackles the role of scholarly publication in the research process\n(quality, preservation) and looks at the consequences of new information\ntechnologies in the organization of the scholarly communication ecology. It\nwill then show how new technologies have had an impact on the scholarly\ncommunication process and made it depart from the traditional publishing\nenvironment. Developments will address new editorial processes, dissemination\nof new content and services, as well as the development of publication\narchives. This last aspect will be covered on all levels (open access,\nscientific, technical and legal aspects). A view on the possible evolutions of\nthe scientific publishing environment will be provided."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0033699", 
    "link": "http://arxiv.org/pdf/1105.3459v1", 
    "title": "Analyzing the Persistence of Referenced Web Resources with Memento", 
    "arxiv-id": "1105.3459v1", 
    "author": "Herbert Van de Sompel", 
    "publish": "2011-05-17T19:21:46Z", 
    "summary": "In this paper we present the results of a study into the persistence and\navailability of web resources referenced from papers in scholarly repositories.\nTwo repositories with different characteristics, arXiv and the UNT digital\nlibrary, are studied to determine if the nature of the repository, or of its\ncontent, has a bearing on the availability of the web resources cited by that\ncontent. Memento makes it possible to automate discovery of archived resources\nand to consider the time between the publication of the research and the\narchiving of the referenced URLs. This automation allows us to process more\nthan 160000 URLs, the largest known such study, and the repository metadata\nallows consideration of the results by discipline. The results are startling:\n45% (66096) of the URLs referenced from arXiv still exist, but are not\npreserved for future generations, and 28% of resources referenced by UNT papers\nhave been lost. Moving forwards, we provide some initial recommendations,\nincluding that repositories should publish URL lists extracted from papers that\ncould be used as seeds for web archiving systems."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0033699", 
    "link": "http://arxiv.org/pdf/1105.4736v1", 
    "title": "Mapping excellence in the geography of science: An approach based on   Scopus data", 
    "arxiv-id": "1105.4736v1", 
    "author": "Christoph Ettl", 
    "publish": "2011-05-24T11:54:36Z", 
    "summary": "As research becomes an ever more globalized activity, there is growing\ninterest in national and international comparisons of standards and quality in\ndifferent countries and regions. A sign for this trend is the increasing\ninterest in rankings of universities according to their research performance,\nboth inside but also outside the scientific environment. New methods presented\nin this paper, enable us to map centers of excellence around the world using\nprograms that are freely available. Based on Scopus data, field-specific\nexcellence can be identified and agglomerated in regions and cities where\nrecently highly-cited papers were published. Differences in performance rates\ncan be visualized on the map using colors and sizes of the marks."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0033699", 
    "link": "http://arxiv.org/pdf/1105.5832v1", 
    "title": "Revealing digital documents. Concealed structures in data", 
    "arxiv-id": "1105.5832v1", 
    "author": "Jakob Vo\u00df", 
    "publish": "2011-05-29T21:49:34Z", 
    "summary": "This short paper gives an introduction to a research project to analyze how\ndigital documents are structured and described. Using a phenomenological\napproach, this research will reveal common patterns that are used in data,\nindependent from the particular technology in which the data is available. The\nability to identify these patterns, on different levels of description, is\nimportant for several applications in digital libraries. A better understanding\nof data structuring will not only help to better capture singular\ncharacteristics of data by metadata, but will also recover intended structures\nof digital objects, beyond long term preservation."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0033699", 
    "link": "http://arxiv.org/pdf/1106.2649v3", 
    "title": "Viewpoint: Journals for Certification, Conferences for Rapid   Dissemination", 
    "arxiv-id": "1106.2649v3", 
    "author": "David C. Parkes", 
    "publish": "2011-06-14T09:37:39Z", 
    "summary": "The publication culture in Computer Science is different from that of all\nother disciplines. Whereas other disciplines focus on journal publication, the\nstandard practice in CS has been to publish in a conference and then\n(sometimes) publish a journal version of the conference paper. We discuss the\nrole of journal publication in CS.\n  Indeed, it is through publication in selective, leading conferences that the\nquality of CS research is typically assessed."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0033699", 
    "link": "http://arxiv.org/pdf/1106.4176v1", 
    "title": "Similarity-based Browsing over Linked Open Data", 
    "arxiv-id": "1106.4176v1", 
    "author": "Yannis Tzitzikas", 
    "publish": "2011-06-21T11:39:11Z", 
    "summary": "An increasing amount of data is published on the Web according to the Linked\nOpen Data (LOD) principles. End users would like to browse these data in a\nflexible manner. In this paper we focus on similarity-based browsing and we\nintroduce a novel method for computing the similarity between two entities of a\ngiven RDF/S graph. The distinctive characteristics of the proposed metric is\nthat it is generic (it can be used to compare nodes of any kind), it takes into\naccount the neighborhoods of the nodes, and it is configurable (with respect to\nthe accuracy vs computational complexity tradeoff). We demonstrate the behavior\nof the metric using examples from an application over LOD. Finally, we\ngeneralize and elaborate on implementation approaches harmonized with the\ndistributed nature of LOD which can be used for computing the most similar\nentities using neighborhood-based similarity metrics."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0033699", 
    "link": "http://arxiv.org/pdf/1106.5178v1", 
    "title": "The Open Annotation Collaboration (OAC) Model", 
    "arxiv-id": "1106.5178v1", 
    "author": "Herbert van de Sompel", 
    "publish": "2011-06-25T22:55:17Z", 
    "summary": "Annotations allow users to associate additional information with existing\nresources. Using proprietary and closed systems on the Web, users are already\nable to annotate multimedia resources such as images, audio and video. So far,\nhowever, this information is almost always kept locked up and inaccessible to\nthe Web of Data. We believe that an important step to take is the integration\nof multimedia annotations and the Linked Data principles. This should allow\nclients to easily publish and consume, thus exchange annotations about\nresources via common Web standards. We first present the current status of the\nOpen Annotation Collaboration, an international initiative that is currently\nworking on annotation interoperability specifications based on best practices\nfrom the Linked Data effort. Then we present two use cases and early prototypes\nthat make use of the proposed annotation model and present lessons learned and\ndiscuss yet open technical issues."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0033699", 
    "link": "http://arxiv.org/pdf/1106.5651v2", 
    "title": "Hyperincursive Cogitata and Incursive Cogitantes: Scholarly Discourse as   a Strongly Anticipatory System", 
    "arxiv-id": "1106.5651v2", 
    "author": "Loet Leydesdorff", 
    "publish": "2011-06-28T12:56:19Z", 
    "summary": "Strongly anticipatory systems-that is, systems which use models of themselves\nfor their further development-and which additionally may be able to run\nhyperincursive routines-that is, develop only with reference to their future\nstates-cannot exist in res extensa, but can only be envisaged in res cogitans.\nOne needs incursive routines in cogitantes to instantiate these systems. Unlike\nhistorical systems (with recursion), these hyper-incursive routines generate\nredundancies by opening horizons of other possible states. Thus, intentional\nsystems can enrich our perceptions of the cases that have happened to occur.\nThe perspective of hindsight codified at the above-individual level enables us\nfurthermore to intervene technologically. The theory and computation of\nanticipatory systems have made these loops between supra-individual\nhyper-incursion, individual incursion (in instantiation), and historical\nrecursion accessible for modeling and empirical investigation."
},{
    "category": "cs.DL", 
    "doi": "10.2902/1725-0463.2011.06.art10", 
    "link": "http://arxiv.org/pdf/1107.1676v1", 
    "title": "A multilingual/multicultural semantic-based approach to improve Data   Sharing in an SDI for Nature Conservation", 
    "arxiv-id": "1107.1676v1", 
    "author": "Riccardo Albertoni", 
    "publish": "2011-07-08T16:50:38Z", 
    "summary": "The paper proposes an approach to transcend multicultural and multilingual\nbarriers in the use and reuse of geographical data at the European level. The\napproach aims at sharing scientific terms in the field of nature conservation\nwith the goal of assisting different user communities with metadata compilation\nand information discovery. A multi-thesauri solution is proposed, based on a\nCommon Thesaurus Framework for Nature Conservation, where different well-known\nKnowledge Organization Systems are assembled and shared. It has been designed\naccording to semantic web and W3C recommendations employing SKOS standard\nmodels and Linked Data to publish the thesauri as a whole in\nmachine-understandable format. The outcome is a powerful framework satisfying\nthe requirements of modularity and openness for further thesaurus extension and\nupdating, interlinking among thesauri, and exploitability from other systems.\nThe paper supports the employment of Linked Data to deal with terminologies in\ncomplex domains such as nature conservation and it proposes a hands-on recipe\nto publish thesauri in the framework."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-642-22673-1_11", 
    "link": "http://arxiv.org/pdf/1107.3209v1", 
    "title": "Large Formal Wikis: Issues and Solutions", 
    "arxiv-id": "1107.3209v1", 
    "author": "Josef Urban", 
    "publish": "2011-07-16T08:46:47Z", 
    "summary": "We present several steps towards large formal mathematical wikis. The Coq\nproof assistant together with the CoRN repository are added to the pool of\nsystems handled by the general wiki system described in\n\\cite{DBLP:conf/aisc/UrbanARG10}. A smart re-verification scheme for the large\nformal libraries in the wiki is suggested for Mizar/MML and Coq/CoRN, based on\nrecently developed precise tracking of mathematical dependencies. We propose to\nuse features of state-of-the-art filesystems to allow real-time cloning and\nsandboxing of the entire libraries, allowing also to extend the wiki to a true\nmulti-user collaborative area. A number of related issues are discussed."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-642-22673-1_11", 
    "link": "http://arxiv.org/pdf/1108.4041v2", 
    "title": "Extracting, Transforming and Archiving Scientific Data", 
    "arxiv-id": "1108.4041v2", 
    "author": "Andre Vellino", 
    "publish": "2011-08-19T20:16:02Z", 
    "summary": "It is becoming common to archive research datasets that are not only large\nbut also numerous. In addition, their corresponding metadata and the software\nrequired to analyse or display them need to be archived. Yet the manual\ncuration of research data can be difficult and expensive, particularly in very\nlarge digital repositories, hence the importance of models and tools for\nautomating digital curation tasks. The automation of these tasks faces three\nmajor challenges: (1) research data and data sources are highly heterogeneous,\n(2) future research needs are difficult to anticipate, (3) data is hard to\nindex. To address these problems, we propose the Extract, Transform and Archive\n(ETA) model for managing and mechanizing the curation of research data.\nSpecifically, we propose a scalable strategy for addressing the research-data\nproblem, ranging from the extraction of legacy data to its long-term storage.\nWe review some existing solutions and propose novel avenues of research."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2011.08.003", 
    "link": "http://arxiv.org/pdf/1108.4828v1", 
    "title": "Publication patterns of award-winning forest scientists and implications   for the ERA journal ranking", 
    "arxiv-id": "1108.4828v1", 
    "author": "Jerome K Vanclay", 
    "publish": "2011-08-24T12:49:04Z", 
    "summary": "Publication patterns of 79 forest scientists awarded major international\nforestry prizes during 1990-2010 were compared with the journal classification\nand ranking promoted as part of the 'Excellence in Research for Australia'\n(ERA) by the Australian Research Council. The data revealed that these\nscientists exhibited an elite publication performance during the decade before\nand two decades following their first major award. An analysis of their 1703\narticles in 431 journals revealed substantial differences between the journal\nchoices of these elite scientists and the ERA classification and ranking of\njournals. Implications from these findings are that additional\ncross-classifications should be added for many journals, and there should be an\nadjustment to the ranking of several journals relevant to the ERA Field of\nResearch classified as 0705 Forestry Sciences."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2011.08.003", 
    "link": "http://arxiv.org/pdf/1110.2305v3", 
    "title": "The new Excellence Indicator in the World Report of the SCImago   Institutions Rankings 2011", 
    "arxiv-id": "1110.2305v3", 
    "author": "Loet Leydesdorff", 
    "publish": "2011-10-11T08:53:00Z", 
    "summary": "The new excellence indicator in the World Report of the SCImago Institutions\nRankings (SIR) makes it possible to test differences in the ranking in terms of\nstatistical significance. For example, at the 17th position of these rankings,\nUCLA has an output of 37,994 papers with an excellence indicator of 28.9.\nStanford University follows at the 19th position with 37,885 papers and 29.1\nexcellence, and z = - 0.607. The difference between these two institution thus\nis not statistically significant. We provide a calculator at\nhttp://www.leydesdorff.net/scimago11/scimago11.xls in which one can fill out\nthis test for any two institutions and also for each institution on whether its\nscore is significantly above or below expectation (assuming that 10% of the\npapers are for stochastic reasons in the top-10% set)."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2011.08.003", 
    "link": "http://arxiv.org/pdf/1110.2396v1", 
    "title": "Semantic Technology to Exploit Digital Content Exposed as Linked Data", 
    "arxiv-id": "1110.2396v1", 
    "author": "Monica De Martino", 
    "publish": "2011-10-11T15:20:15Z", 
    "summary": "The paper illustrates the research result of the application of semantic\ntechnology to ease the use and reuse of digital contents exposed as Linked Data\non the web. It focuses on the specific issue of explorative research for the\nresource selection: a context dependent semantic similarity assessment is\nproposed in order to compare datasets annotated through terminologies exposed\nas Linked Data (e.g. habitats, species). Semantic similarity is shown as a\nbuilding block technology to sift linked data resources. From semantic\nsimilarity application, we derived a set of recommendations underlying open\nissues in scaling the similarity assessment up to the Web of Data."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2011.08.003", 
    "link": "http://arxiv.org/pdf/1110.2400v1", 
    "title": "The CHRONIOUS Ontology-Driven Search Tool: Enabling Access to Focused   and Up-to-Date Healthcare Literature", 
    "arxiv-id": "1110.2400v1", 
    "author": "Michael Lawo", 
    "publish": "2011-10-11T15:33:21Z", 
    "summary": "This paper presents an advanced search engine prototype for bibliography\nretrieval developed within the CHRONIOUS European IP project of the seventh\nFramework Program (FP7). This search engine is specifically targeted to\nclinicians and healthcare practitioners searching for documents related to\nChronic Obstructive Pulmonary Disease (COPD) and Chronic Kidney Disease (CKD).\nTo this aim, the presented tool exploits two pathology-specific ontologies that\nallow focused document indexing and retrieval. These ontologies have been\ndeveloped on the top of the Middle Layer Ontology for Clinical Care (MLOCC),\nwhich provides a link with the Basic Formal Ontology, a foundational ontology\nused in the Open Biological and Biomedical Ontologies (OBO) Foundry. In\naddition link with the terms of the MeSH (Medical Subject Heading) thesaurus\nhas been provided to guarantee the coverage with the general certified medical\nterms and multilingual capabilities."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2011.08.003", 
    "link": "http://arxiv.org/pdf/1110.2646v1", 
    "title": "Notas metodol\u00f3gicas para cubrir la etapa de documentar una   investigaci\u00f3n", 
    "arxiv-id": "1110.2646v1", 
    "author": "Jose Texier", 
    "publish": "2011-10-12T13:03:44Z", 
    "summary": "The search process of scientific articles (papers) and review articles\n(reviews) is one of the pillars of the scientific world, and is performed by\npeople in the research as well as for people who want to keep abreast specific\ntopics. Scopus (there are other databases) or Google Scholar are proposed\noptions to find articles, but is recommended by Scopus its extensive database\nand its versatility in the search options it offers. This paper proposes is a\nplan that allows a systematic search and keep the items in an orderly,\nconsistent and coherent within own repository for cataloging and consultation,\nwhich will serve for many tasks to establish the state of the art of a topic,\nstaff training in an area and/or writing articles, among others."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2011.08.003", 
    "link": "http://arxiv.org/pdf/1110.3687v1", 
    "title": "Evaluating the SharedCanvas Manuscript Data Model in CATCHPlus", 
    "arxiv-id": "1110.3687v1", 
    "author": "Herbert Van de Sompel", 
    "publish": "2011-10-17T14:55:48Z", 
    "summary": "In this paper, we present the SharedCanvas model for describing the layout of\nculturally important, hand-written objects such as medieval manuscripts, which\nis intended to be used as a common input format to presentation interfaces. The\nmodel is evaluated using two collections from CATCHPlus not consulted during\nthe design phase, each with their own complex requirements, in order to\ndetermine if further development is required or if the model is ready for\ngeneral usage. The model is applied to the new collections, revealing several\nnew areas of concern for user interface production and discovery of the\nconstituent resources. However, the fundamental information modelling aspects\nof SharedCanvas and the underlying Open Annotation Collaboration ontology are\ndemonstrated to be sufficient to cover the challenging new requirements. The\ndistributed, Linked Open Data approach is validated as an important methodology\nto seamlessly allow simultaneous interaction with multiple repositories, and at\nthe same time to facilitate both scholarly commentary and crowd-sourcing of the\nproduction of transcriptions."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2011.08.003", 
    "link": "http://arxiv.org/pdf/1110.5419v1", 
    "title": "Knowledge Organization Research in the last two decades: 1988-2008", 
    "arxiv-id": "1110.5419v1", 
    "author": "Eric Sanjuan", 
    "publish": "2011-10-25T06:17:59Z", 
    "summary": "We apply an automatic topic mapping system to records of publications in\nknowledge organization published between 1988-2008. The data was collected from\njournals publishing articles in the KO field from Web of Science database\n(WoS). The results showed that while topics in the first decade (1988-1997)\nwere more traditional, the second decade (1998-2008) was marked by a more\ntechnological orientation and by the appearance of more specialized topics\ndriven by the pervasiveness of the Web environment."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2011.08.003", 
    "link": "http://arxiv.org/pdf/1110.6519v1", 
    "title": "Un modello di struttura dinamica per ebook scolastici", 
    "arxiv-id": "1110.6519v1", 
    "author": "Maria Vincelli", 
    "publish": "2011-10-29T10:44:30Z", 
    "summary": "This article proposes a model of e-books for schools based on a graph in\nwhich nodes represent individual subjects of a teaching program to a the\nrelatively low granularity, which facilitates their aggregation and\nre-usability, and edges represent prerequisites between subjects (and, indeed,\nbetween nodes). On this graph we will develop a series of simple algorithms\nthat allow both teachers and students to assemble an interactive and\npersonalized ebook that, respecting the prerequisites, it will be significant\nfrom the point of methodological and stylistic sense. Therefore, teachers and\nstudents do not have available a set of unrelated units neither a limited set a\nfew pre-packaged learning paths, as it is typical of some solutions on the Web,\nbut rather will have a network of topics that can be serialized in a\ncombinatorial vast number of alternatives, and therefore can create as many\ncustom ebook, but guaranteed from the point of view of the scientific\nperspective."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2011.08.003", 
    "link": "http://arxiv.org/pdf/1111.0735v1", 
    "title": "Using Automated Dependency Analysis To Generate Representation   Information", 
    "arxiv-id": "1111.0735v1", 
    "author": "Andrew N. Jackson", 
    "publish": "2011-11-03T06:26:29Z", 
    "summary": "To preserve access to digital content, we must preserve the representation\ninformation that captures the intended interpretation of the data. In\nparticular, we must be able to capture performance dependency requirements,\ni.e. to identify the other resources that are required in order for the\nintended interpretation to be constructed successfully. Critically, we must\nidentify the digital objects that are only referenced in the source data, but\nare embedded in the performance, such as fonts. This paper describes a new\ntechnique for analysing the dynamic dependencies of digital media, focussing on\nanalysing the process that underlies the performance, rather than parsing and\ndeconstructing the source data. This allows the results of format-specific\ncharacterisation tools to be verified independently, and facilitates the\ngeneration of representation information for any digital media format, even\nwhen no suitable characterisation tool exists."
},{
    "category": "cs.DL", 
    "doi": "10.5120/4083-5888", 
    "link": "http://arxiv.org/pdf/1111.6934v1", 
    "title": "Architecture of a Conference Management System Providing Advanced Paper   Assignment Features", 
    "arxiv-id": "1111.6934v1", 
    "author": "Yordan Kalmukov", 
    "publish": "2011-11-29T19:07:24Z", 
    "summary": "This paper proposes an architecture and assignment management model of a\nconference management system that performs a precise and accurate automatic\nassignment of reviewers to papers. The system relies on taxonomy of keywords to\ndescribe papers and reviewers' competences. The implied hierarchical structure\nof the taxonomy provides important additional information - the semantic\nrelationships between the separate keywords. It allows similarity measures to\ntake into account not only the number of exactly matching keywords between a\npaper and a reviewer, but in case of non-matching ones to calculate how\nsemantically close they are. Reviewers are allowed to bid on the papers they\nwould like to (or not like to) review and to explicitly state conflicts of\ninterest (CoI) with papers. An automatic CoI detection is checking for\nadditional conflicts based on institutional affiliation, co-authorship (within\nthe local database) and previous co-authorship in the past (within the major\nbibliographic indexes and digital libraries). The algorithm for automatic\nassignment takes into account all - selected keywords, reviewers' bids and\nconflicts of interest and tries to find the most accurate assignment while\nmaintaining load balancing among reviewers."
},{
    "category": "cs.DL", 
    "doi": "10.5120/4083-5888", 
    "link": "http://arxiv.org/pdf/1112.1681v1", 
    "title": "A literature review: What exactly should we preserve? How scholars   address this question and where is the gap", 
    "arxiv-id": "1112.1681v1", 
    "author": "Jyue Tyan Low", 
    "publish": "2011-12-07T20:24:35Z", 
    "summary": "This review addresses the question of what exactly should we preserve, and\nhow the digital preservation community and scholars address this question. The\npaper first introduces the much-abused-term \"significant properties,\" before\nrevealing how some scholars are of the opinion that characteristics of digital\nobjects to be preserved (i.e., significant properties) can be identified and\nshould be expressed formally, while others are not of that opinion. The digital\npreservation community's attempt to expound on the general characteristics of\ndigital objects and significant properties will then be discussed. Finally, the\nreview shows that while there may be ways to identify the technical makeup or\ngeneral characteristics of a digital object, there is currently no formal and\nobjective methodology to help stakeholders identify and decide what the\nsignificant properties of the objects are. This review thus helps open\nquestions and generates a formative recommendation based on expert opinion that\nexpressing an object's functions in an explicit and formal way (using didactic\nguides from the archives community) could be the solution to help stakeholders\ndecide what characteristics/ elements exactly we should preserve."
},{
    "category": "cs.DL", 
    "doi": "10.5120/4083-5888", 
    "link": "http://arxiv.org/pdf/1112.2619v1", 
    "title": "Towards a Reference Model for Open Access and Knowledge Sharing, Lessons   from Systems Research", 
    "arxiv-id": "1112.2619v1", 
    "author": "Paola Di Maio", 
    "publish": "2011-12-09T19:38:35Z", 
    "summary": "The Open Access Movement has been striving to grant universal unrestricted\naccess to the knowledge and data outputs of publicly funded research.\nleveraging the real time, virtually cost free publishing opportunities offered\nby the internet and the web. However, evidence suggests that in the systems\nengineering domain open access policies are not widely adopted. This paper\npresents the rationale, methodology and results of an evidence based inquiry\nthat investigates the dichotomy between policy and practice in Open Access (OA)\nof systems engineering research in the UK, explores entangled dimensions of the\nproblem space from a socio-technical perspective, and issues a set of\nrecommendations, including a reference model outline for knowledge sharing in\nsystems research"
},{
    "category": "cs.DL", 
    "doi": "10.5120/4083-5888", 
    "link": "http://arxiv.org/pdf/1112.4019v1", 
    "title": "Legal Resources Information System for Information Agencies of   Specialized Libraries", 
    "arxiv-id": "1112.4019v1", 
    "author": "Phuc V. Nguyen", 
    "publish": "2011-12-17T03:48:36Z", 
    "summary": "In recent years, the rapid development of information technology and\ncommunication has a strong impact to industry information - the library. The\nmission of the industry when in fact the great social place to see the library\nas knowledge management. Vietnam is in the process of building the rule of law\nsocialist orientation and improves the legal system. So in the current\ndevelopment process, the law library plays an important role in the retention,\ndissemination and provision of legal information service of legislative,\nexecutive and judiciary, particularly especially research, teaching and\nlearning of law school. But the response of the legal information library\ninformation agencies remains limited compared to the increasing demand of\nusers."
},{
    "category": "cs.DL", 
    "doi": "10.5120/4083-5888", 
    "link": "http://arxiv.org/pdf/1112.6090v1", 
    "title": "Multi-Connected Ontologies", 
    "arxiv-id": "1112.6090v1", 
    "author": "Damla Karagozlu", 
    "publish": "2011-12-28T10:23:16Z", 
    "summary": "Ontologies have been used for the purpose of bringing system and consistency\nto subject and knowledge areas. We present a criticism of the present\nmathematical structure of ontologies and indicate that they are not sufficient\nin their present form to represent the many different valid expressions of a\nsubject knowledge domain. We propose an alternative structure for ontologies\nbased on a richer multi connected complex network which contains the present\nontology structure as a projection. We demonstrate how this new multi connected\nontology should be represented as an asymmetric probability matrix."
},{
    "category": "cs.DL", 
    "doi": "10.5120/4083-5888", 
    "link": "http://arxiv.org/pdf/1201.0385v2", 
    "title": "Information Carriers and Identification of Information Objects: An   Ontological Approach", 
    "arxiv-id": "1201.0385v2", 
    "author": "Yannis Tzitzikas", 
    "publish": "2012-01-01T21:04:46Z", 
    "summary": "Even though library and archival practice, as well as Digital Preservation,\nhave a long tradition in identifying information objects, the question of their\nprecise identity under change of carrier or migration is still a riddle to\nscience. The objective of this paper is to provide criteria for the unique\nidentification of some important kinds of information objects, independent from\nthe kind of carrier or specific encoding. Our approach is based on the idea\nthat the substance of some kinds of information objects can completely be\ndescribed in terms of discrete arrangements of finite numbers of known kinds of\nsymbols, such as those implied by style guides for scientific journal\nsubmissions. Our theory is also useful for selecting or describing what has to\nbe preserved. This is a fundamental problem since curators and archivists would\nlike to formally record the decisions of what has to be preserved over time and\nto decide (or verify) whether a migration (transformation) preserves the\nintended information content. Furthermore, it is important for reasoning about\nthe authenticity of digital objects, as well as for reducing the cost of\ndigital preservation."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-012-0618-8", 
    "link": "http://arxiv.org/pdf/1201.3068v1", 
    "title": "Metrics to evaluate research performance in academic institutions: A   critique of ERA 2010 as applied in forestry and the indirect H2 index as a   possible alternative", 
    "arxiv-id": "1201.3068v1", 
    "author": "Lutz Bornmann", 
    "publish": "2012-01-15T08:38:28Z", 
    "summary": "Excellence for Research in Australia (ERA) is an attempt by the Australian\nResearch Council to rate Australian universities on a 5-point scale within 180\nFields of Research using metrics and peer evaluation by an evaluation\ncommittee. Some of the bibliometric data contributing to this ranking suffer\nstatistical issues associated with skewed distributions. Other data are\nstandardised year-by-year, placing undue emphasis on the most recent\npublications which may not yet have reliable citation patterns. The\nbibliometric data offered to the evaluation committees is extensive, but lacks\neffective syntheses such as the h-index and its variants. The indirect H2 index\nis objective, can be computed automatically and efficiently, is resistant to\nmanipulation, and a good indicator of impact to assist the ERA evaluation\ncommittees and to similar evaluations internationally."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-011-0561-0", 
    "link": "http://arxiv.org/pdf/1201.3076v1", 
    "title": "Impact Factor: outdated artefact or stepping-stone to journal   certification?", 
    "arxiv-id": "1201.3076v1", 
    "author": "Jerome K. Vanclay", 
    "publish": "2012-01-15T10:15:27Z", 
    "summary": "A review of Garfield's journal impact factor and its specific implementation\nas the Thomson Reuters Impact Factor reveals several weaknesses in this\ncommonly-used indicator of journal standing. Key limitations include the\nmismatch between citing and cited documents, the deceptive display of three\ndecimals that belies the real precision, and the absence of confidence\nintervals. These are minor issues that are easily amended and should be\ncorrected, but more substantive improvements are needed. There are indications\nthat the scientific community seeks and needs better certification of journal\nprocedures to improve the quality of published science. Comprehensive\ncertification of editorial and review procedures could help ensure adequate\nprocedures to detect duplicate and fraudulent submissions."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-011-0561-0", 
    "link": "http://arxiv.org/pdf/1201.4574v4", 
    "title": "Technologie et pratiques bibliographiques associ\u00e9es \u00e0 l'\u00e9criture   scientifique en milieu universitaire", 
    "arxiv-id": "1201.4574v4", 
    "author": "G\u00e9rald Kembellec", 
    "publish": "2012-01-22T16:58:27Z", 
    "summary": "Observe and understand users of the Scientific and Technical Information, is\npreparing to offer them appropriate services. This exploratory study provides\nanswers about the uses in the humanities, social sciences as well as technical\nsciences. We also observe those who assist teachers in their scientific\nresearch: librarians. Then we outline considerations and recommendations to\nspecify functionalities of an efficient e-Linrary."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-011-0561-0", 
    "link": "http://arxiv.org/pdf/1201.4638v2", 
    "title": "Alternatives to the Journal Impact Factor: I3 and the Top-10% (or   Top-25%?) of the Most-Highly Cited Papers", 
    "arxiv-id": "1201.4638v2", 
    "author": "Loet Leydesdorff", 
    "publish": "2012-01-23T07:33:37Z", 
    "summary": "Journal Impact Factors (IFs) can be considered historically as the first\nattempt to normalize citation distributions by using averages over two years.\nHowever, it has been recognized that citation distributions vary among fields\nof science and that one needs to normalize for this. Furthermore, the mean-or\nany central-tendency statistics-is not a good representation of the citation\ndistribution because these distributions are skewed. Important steps have been\ntaken to solve these two problems during the last few years. First, one can\nnormalize at the article level using the citing audience as the reference set.\nSecond, one can use non-parametric statistics for testing the significance of\ndifferences among ratings. A proportion of most-highly cited papers (the\ntop-10% or top-quartile) on the basis of fractional counting of the citations\nmay provide an alternative to the current IF. This indicator is intuitively\nsimple, allows for statistical testing, and accords with the state of the art."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-011-0561-0", 
    "link": "http://arxiv.org/pdf/1201.4639v2", 
    "title": "A further step forward in measuring journals' scientific prestige: The   SJR2 indicator", 
    "arxiv-id": "1201.4639v2", 
    "author": "Felix Moya-Anegon", 
    "publish": "2012-01-23T07:39:03Z", 
    "summary": "A new size-independent indicator of scientific journal prestige, the SJR2\nindicator, is proposed. This indicator takes into account not only the prestige\nof the citing scientific journal but also its closeness to the cited journal\nusing the cosine of the angle between the vectors of the two journals'\ncocitation profiles. To eliminate the size effect, the accumulated prestige is\ndivided by the fraction of the journal's citable documents, thus eliminating\nthe decreasing tendency of this type of indicator and giving meaning to the\nscores. Its method of computation is described, and the results of its\nimplementation on the Scopus 2008 dataset is compared with those of an ad hoc\nJournal Impact Factor, JIF(3y), and SNIP, the comparison being made both\noverall and within specific scientific areas. All three, the SJR2 indicator,\nthe SNIP indicator and the JIF distributions, were found to fit well to a\nlogarithmic law. Although the three metrics were strongly correlated, there\nwere major changes in rank. In addition, the SJR2 was distributed more\nequalized than the JIF by Subject Area and almost as equalized as the SNIP, and\nbetter than both at the lower level of Specific Subject Areas. The\nincorporation of the cosine increased the values of the flows of prestige\nbetween thematically close journals."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-011-0561-0", 
    "link": "http://arxiv.org/pdf/1201.5681v1", 
    "title": "T2Ku: Building a Semantic Wiki of Mathematics", 
    "arxiv-id": "1201.5681v1", 
    "author": "Minqi Pan", 
    "publish": "2012-01-27T00:22:57Z", 
    "summary": "We introduce T2Ku, an open source project that aims at building a semantic\nwiki of mathematics featuring automated reasoning(AR) techniques. We want to\nutilize AR techniques in a way that truly helps mathematical researchers solve\nproblems in the real world, instead of building another ambitious yet useless\nsystem. By setting this as our objective, we exploit pragmatic design decisions\nthat have proven feasible in other projects, while still employs a loosely\ncoupled architecture to allow better inference programs to be integrated in the\nfuture. In this paper, we state the motivations and examine state-of-the-art\nsystems, why we are not satisfied with those systems and how we are going to\nimprove. We then describe our architecture and the way we implemented the\nsystem. We present examples showing how to use its facilities. T2Ku is an\non-going project. We conclude this paper by summarizing the development\nprogress and encouraging the reader to join the project."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-011-0561-0", 
    "link": "http://arxiv.org/pdf/1202.0567v1", 
    "title": "ProofFlow: Flow Diagrams for Proofs", 
    "arxiv-id": "1202.0567v1", 
    "author": "Steven A. Kieffer", 
    "publish": "2012-02-02T21:42:33Z", 
    "summary": "We present a light formalism for proofs that encodes their inferential\nstructure, along with a system that transforms these representations into\nflow-chart diagrams. Such diagrams should improve the comprehensibility of\nproofs. We discuss language syntax, diagram semantics, and our goal of building\na repository of diagrammatic representations of proofs from canonical\nmathematical literature. The repository will be available online in the form of\na wiki at proofflow.org, where the flow chart drawing software will be\ndeployable through the wiki editor. We also consider the possibility of a\nsemantic tagging of the assertions in a proof, to permit data mining."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-011-0561-0", 
    "link": "http://arxiv.org/pdf/1202.2638v4", 
    "title": "Scienceography: the study of how science is written", 
    "arxiv-id": "1202.2638v4", 
    "author": "Jinyun Yan", 
    "publish": "2012-02-13T06:38:14Z", 
    "summary": "Scientific literature has itself been the subject of much scientific study,\nfor a variety of reasons: understanding how results are communicated, how ideas\nspread, and assessing the influence of areas or individuals. However, most\nprior work has focused on extracting and analyzing citation and stylistic\npatterns. In this work, we introduce the notion of 'scienceography', which\nfocuses on the writing of science. We provide a first large scale study using\ndata derived from the arXiv e-print repository. Crucially, our data includes\nthe \"source code\" of scientific papers-the LaTEX source-which enables us to\nstudy features not present in the \"final product\", such as the tools used and\nprivate comments between authors. Our study identifies broad patterns and\ntrends in two example areas-computer science and mathematics-as well as\nhighlighting key differences in the way that science is written in these\nfields. Finally, we outline future directions to extend the new topic of\nscienceography."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22976", 
    "link": "http://arxiv.org/pdf/1202.3119v3", 
    "title": "Scientific impact evaluation and the effect of self-citations:   mitigating the bias by discounting h-index", 
    "arxiv-id": "1202.3119v3", 
    "author": "Alfonso E. Romero", 
    "publish": "2012-02-14T19:46:51Z", 
    "summary": "In this paper, we propose a measure to assess scientific impact that\ndiscounts self-citations and does not require any prior knowledge on the their\ndistribution among publications. This index can be applied to both researchers\nand journals. In particular, we show that it fills the gap of h-index and\nsimilar measures that do not take into account the effect of self-citations for\nauthors or journals impact evaluation. The paper provides with two real-world\nexamples: in the former, we evaluate the research impact of the most productive\nscholars in Computer Science (according to DBLP); in the latter, we revisit the\nimpact of the journals ranked in the 'Computer Science Applications' section of\nSCImago. We observe how self-citations, in many cases, affect the rankings\nobtained according to different measures (including h-index and ch-index), and\nshow how the proposed measure mitigates this effect."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22976", 
    "link": "http://arxiv.org/pdf/1202.3941v1", 
    "title": "The Leiden Ranking 2011/2012: Data collection, indicators, and   interpretation", 
    "arxiv-id": "1202.3941v1", 
    "author": "Paul Wouters", 
    "publish": "2012-02-17T15:56:15Z", 
    "summary": "The Leiden Ranking 2011/2012 is a ranking of universities based on\nbibliometric indicators of publication output, citation impact, and scientific\ncollaboration. The ranking includes 500 major universities from 41 different\ncountries. This paper provides an extensive discussion of the Leiden Ranking\n2011/2012. The ranking is compared with other global university rankings, in\nparticular the Academic Ranking of World Universities (commonly known as the\nShanghai Ranking) and the Times Higher Education World University Rankings.\nAlso, a detailed description is offered of the data collection methodology of\nthe Leiden Ranking 2011/2012 and of the indicators used in the ranking. Various\ninnovations in the Leiden Ranking 2011/2012 are presented. These innovations\ninclude (1) an indicator based on counting a university's highly cited\npublications, (2) indicators based on fractional rather than full counting of\ncollaborative publications, (3) the possibility of excluding non-English\nlanguage publications, and (4) the use of stability intervals. Finally, some\ncomments are made on the interpretation of the ranking, and a number of\nlimitations of the ranking are pointed out."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22976", 
    "link": "http://arxiv.org/pdf/1202.4133v2", 
    "title": "McCall's Area Transformation versus the Integrated Impact Indicator (I3)", 
    "arxiv-id": "1202.4133v2", 
    "author": "Loet Leydesdorff", 
    "publish": "2012-02-19T07:34:35Z", 
    "summary": "In a study entitled \"Skewed Citation Distributions and Bias Factors:\nSolutions to two core problems with the journal impact factor,\" Mutz & Daniel\n(2012) propose (i) McCall's (1922) Area Transformation of the skewed citation\ndistribution so that this data can be considered as normally distributed (Krus\n& Kennedy, 1977), and (ii) to control for different document types as a\nco-variate (Rubin, 1977). This approach provides an alternative to Leydesdorff\n& Bornmann's (2011) Integrated Impact Indicator (I3). As the authors note, the\ntwo approaches are akin.\n  Can something be said about the relative quality of the two approaches? To\nthat end, I replicated the study of Mutz & Daniel for the 11 journals in the\nSubject Category \"mathematical psychology,\" but using additionally I3 on the\nbasis of continuous quantiles (Leydesdorff & Bornmann, in press) and its\nvariant PR6 based on the six percentile rank classes distinguished by Bornmann\n& Mutz (2011) as follows: the top-1%, 95-99%, 90-95%, 75-90%, 50-75%, and\nbottom-50%."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22976", 
    "link": "http://arxiv.org/pdf/1202.6354v1", 
    "title": "Open Annotations on Multimedia Web Resources", 
    "arxiv-id": "1202.6354v1", 
    "author": "Herbert van de Sompel", 
    "publish": "2012-02-28T20:46:54Z", 
    "summary": "Many Web portals allow users to associate additional information with\nexisting multimedia resources such as images, audio, and video. However, these\nportals are usually closed systems and user-generated annotations are almost\nalways kept locked up and remain inaccessible to the Web of Data. We believe\nthat an important step to take is the integration of multimedia annotations and\nthe Linked Data principles. We present the current state of the Open Annotation\nModel, explain our design rationale, and describe how the model can represent\nuser annotations on multimedia Web resources. Applying this model in Web\nportals and devices, which support user annotations, should allow clients to\neasily publish and consume, thus exchange annotations on multimedia Web\nresources via common Web standards."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22976", 
    "link": "http://arxiv.org/pdf/1203.0532v1", 
    "title": "A new methodology for constructing a publication-level classification   system of science", 
    "arxiv-id": "1203.0532v1", 
    "author": "Nees Jan van Eck", 
    "publish": "2012-03-02T17:45:42Z", 
    "summary": "Classifying journals or publications into research areas is an essential\nelement of many bibliometric analyses. Classification usually takes place at\nthe level of journals, where the Web of Science subject categories are the most\npopular classification system. However, journal-level classification systems\nhave two important limitations: They offer only a limited amount of detail, and\nthey have difficulties with multidisciplinary journals. To avoid these\nlimitations, we introduce a new methodology for constructing classification\nsystems at the level of individual publications. In the proposed methodology,\npublications are clustered into research areas based on citation relations. The\nmethodology is able to deal with very large numbers of publications. We present\nan application in which a classification system is produced that includes\nalmost ten million publications. Based on an extensive analysis of this\nclassification system, we discuss the strengths and the limitations of the\nproposed methodology. Important strengths are the transparency and relative\nsimplicity of the methodology and its fairly modest computing and memory\nrequirements. The main limitation of the methodology is its exclusive reliance\non direct citation relations between publications. The accuracy of the\nmethodology can probably be increased by also taking into account other types\nof relations, for instance based on bibliographic coupling."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22976", 
    "link": "http://arxiv.org/pdf/1203.1006v2", 
    "title": "Bibliometric Perspectives on Medical Innovation using the Medical   Subject Headings (MeSH) of PubMed", 
    "arxiv-id": "1203.1006v2", 
    "author": "Ismael Rafols", 
    "publish": "2012-03-05T18:58:41Z", 
    "summary": "Multiple perspectives on the nonlinear processes of medical innovations can\nbe distinguished and combined using the Medical Subject Headings (MeSH) of the\nMedline database. Focusing on three main branches-\"diseases,\" \"drugs and\nchemicals,\" and \"techniques and equipment\"-we use base maps and overlay\ntechniques to investigate the translations and interactions and thus to gain a\nbibliometric perspective on the dynamics of medical innovations. To this end,\nwe first analyze the Medline database, the MeSH index tree, and the various\noptions for a static mapping from different perspectives and at different\nlevels of aggregation. Following a specific innovation (RNA interference) over\ntime, the notion of a trajectory which leaves a signature in the database is\nelaborated. Can the detailed index terms describing the dynamics of research be\nused to predict the diffusion dynamics of research results? Possibilities are\nspecified for further integration between the Medline database, on the one\nhand, and the Science Citation Index and Scopus (containing citation\ninformation), on the other."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22976", 
    "link": "http://arxiv.org/pdf/1203.3611v1", 
    "title": "Literature-based knowledge discovery: the state of the art", 
    "arxiv-id": "1203.3611v1", 
    "author": "Hui Fu", 
    "publish": "2012-03-16T03:33:06Z", 
    "summary": "Literature-based knowledge discovery method was introduced by Dr. Swanson in\n1986. He hypothesized a connection between Raynaud's phenomenon and dietary\nfish oil, the field of literature-based discovery (LBD) was born from then on.\nDuring the subsequent two decades, LBD's research attracts some scientists\nincluding information science, computer science, and biomedical science, etc..\nIt has been a part of knowledge discovery and text mining. This paper\nsummarizes the development of recent years about LBD and presents two parts,\nmethodology research and applied research. Lastly, some problems are pointed as\nfuture research directions."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22976", 
    "link": "http://arxiv.org/pdf/1203.4135v1", 
    "title": "Metadata Management in Scientific Computing", 
    "arxiv-id": "1203.4135v1", 
    "author": "Eric L. Seidel", 
    "publish": "2012-03-19T15:35:36Z", 
    "summary": "Complex scientific codes and the datasets they generate are in need of a\nsophisticated categorization environment that allows the community to store,\nsearch, and enhance metadata in an open, dynamic system. Currently, data is\noften presented in a read-only format, distilled and curated by a select group\nof researchers. We envision a more open and dynamic system, where authors can\npublish their data in a writeable format, allowing users to annotate the\ndatasets with their own comments and data. This would enable the scientific\ncommunity to collaborate on a higher level than before, where researchers could\nfor example annotate a published dataset with their citations.\n  Such a system would require a complete set of permissions to ensure that any\nindividual's data cannot be altered by others unless they specifically allow\nit. For this reason datasets and codes are generally presented read-only, to\nprotect the author's data; however, this also prevents the type of social\nrevolutions that the private sector has seen with Facebook and Twitter.\n  In this paper, we present an alternative method of publishing codes and\ndatasets, based on Fluidinfo, which is an openly writeable and social metadata\nengine. We will use the specific example of the Einstein Toolkit, a shared\nscientific code built using the Cactus Framework, to illustrate how the code's\nmetadata may be published in writeable form via Fluidinfo."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22976", 
    "link": "http://arxiv.org/pdf/1203.4194v1", 
    "title": "Research collaboration and the expanding science grid: Measuring   globalization processes worldwide", 
    "arxiv-id": "1203.4194v1", 
    "author": "Nees Jan van Eck", 
    "publish": "2012-03-19T18:23:29Z", 
    "summary": "This paper applies a new model and analytical tool to measure and study\ncontemporary globalization processes in collaborative science - a world in\nwhich scientists, scholars, technicians and engineers interact within a 'grid'\nof interconnected research sites and collaboration networks. The building\nblocks of our metrics are the cities where scientific research is conducted, as\nmentioned in author addresses on research publications. The unit of analysis is\nthe geographical distance between those cities. In our macro-level trend\nanalysis, covering the years 2000-2010, we observe that research collaboration\ndistances have been increasing, while the share of collaborative contacts with\nforeign cities has leveled off. Collaboration distances and growth rates differ\nsignificantly between countries and between fields of science. The application\nof a distance metrics to compare and track these processes opens avenues for\nfurther studies, both at the meso-level and at the micro-level, into how\nresearch collaboration patterns and trends are driving and shaping the\nconnectivity fabric of world science."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22976", 
    "link": "http://arxiv.org/pdf/1203.4725v2", 
    "title": "Citation Analysis with Medical Subject Headings (MeSH) using the Web of   Knowledge: A new routine", 
    "arxiv-id": "1203.4725v2", 
    "author": "Tobias Opthof", 
    "publish": "2012-03-21T12:56:26Z", 
    "summary": "Citation analysis of documents retrieved from the Medline database (at the\nWeb of Knowledge) has been possible only on a case-by-case basis. A technique\nis here developed for citation analysis in batch mode using both Medical\nSubject Headings (MeSH) at the Web of Knowledge and the Science Citation Index\nat the Web of Science. This freeware routine is applied to the case of \"Brugada\nSyndrome,\" a specific disease and field of research (since 1992). The journals\ncontaining these publications, for example, are attributed to Web-of-Science\nCategories other than \"Cardiac and Cardiovascular Systems\"), perhaps because of\nthe possibility of genetic testing for this syndrome in the clinic. With this\nroutine, all the instruments available for citation analysis can now be used on\nthe basis of MeSH terms. Other options for crossing between Medline, WoS, and\nScopus are also reviewed."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22976", 
    "link": "http://arxiv.org/pdf/1203.4745v1", 
    "title": "Altmetrics in the wild: Using social media to explore scholarly impact", 
    "arxiv-id": "1203.4745v1", 
    "author": "Bradley M. Hemminger", 
    "publish": "2012-03-20T19:46:25Z", 
    "summary": "In growing numbers, scholars are integrating social media tools like blogs,\nTwitter, and Mendeley into their professional communications. The online,\npublic nature of these tools exposes and reifies scholarly processes once\nhidden and ephemeral. Metrics based on this activities could inform broader,\nfaster measures of impact, complementing traditional citation metrics. This\nstudy explores the properties of these social media-based metrics or\n\"altmetrics\", sampling 24,331 articles published by the Public Library of\nScience.\n  We find that that different indicators vary greatly in activity. Around 5% of\nsampled articles are cited in Wikipedia, while close to 80% have been included\nin at least one Mendeley library. There is, however, an encouraging diversity;\na quarter of articles have nonzero data from five or more different sources.\nCorrelation and factor analysis suggest citation and altmetrics indicators\ntrack related but distinct impacts, with neither able to describe the complete\npicture of scholarly use alone. There are moderate correlations between\nMendeley and Web of Science citation, but many altmetric indicators seem to\nmeasure impact mostly orthogonal to citation. Articles cluster in ways that\nsuggest five different impact \"flavors\", capturing impacts of different types\non different audiences; for instance, some articles may be heavily read and\nsaved by scholars but seldom cited. Together, these findings encourage more\nresearch into altmetrics as complements to traditional citation measures."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22976", 
    "link": "http://arxiv.org/pdf/1203.5689v1", 
    "title": "Building Custom Term Suggestion Web Services with OAI-Harvested Open   Data", 
    "arxiv-id": "1203.5689v1", 
    "author": "Wilko van Hoek", 
    "publish": "2012-03-26T14:45:45Z", 
    "summary": "The problem that the same information need can be expressed in a variety of\nways is especially true for scientific literature. Each scientific discipline\nhas its own domain-specific language and vocabulary. This language is coded\ninto documentary tools like thesauri or classifications that are used to\ndocument and describe scientific documents. When we think of information\nretrieval as \"fundamentally a linguistic process\" (Blair, 2003) users have to\nbe aware of the most relevant search terms - which are the controlled thesauri\nterms the documents are described with. This can be achieved with so-called\nsearch-term-recommenders (STR) that map free search terms of a lay user to\ncontrolled vocabulary terms which can then be used as a term suggestion or to\ndo an automatic query expansion (Hienert, Schaer, Schaible, & Mayr, 2011).\nState-of-the-art repository software systems like DSpace or EPrints already\noffer some kind of term suggestion features in search or input forms but these\nimplementations only work as simple auto completion mechanisms that don't\nincorporate any kind of semantic mapping. Such software systems would gain a\nlot in terms of usability and data consistency if tools like the proposed\ndomain-specific STRs would be freely available. We aim to implement a rich\ntoolbox of web services (like the mentioned domain-specific STRs) to support\nusers and providers of online Digital Library (DL) or repository systems."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22976", 
    "link": "http://arxiv.org/pdf/1205.0003v1", 
    "title": "Indices to Quantify the Ranking of Arabic Journals and Research Output", 
    "arxiv-id": "1205.0003v1", 
    "author": "Mahmoud Abdel-Aty", 
    "publish": "2012-04-30T16:22:17Z", 
    "summary": "I propose two simple indices to classify journals, published in Arabic\nlanguage, and different researchers. These indices depend upon the known impact\nfactor and h-index. The new indices give an easy way to judge the rank of any\njournal (output of any researcher) without looking for other journals (output\nof other researchers)."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22976", 
    "link": "http://arxiv.org/pdf/1205.0668v2", 
    "title": "How Can Journal Impact Factors be Normalized across Fields of Science?   An Assessment in terms of Percentile Ranks and Fractional Counts", 
    "arxiv-id": "1205.0668v2", 
    "author": "Lutz Bornmann", 
    "publish": "2012-05-03T10:12:57Z", 
    "summary": "Using the CD-ROM version of the Science Citation Index 2010 (N = 3,705\njournals), we study the (combined) effects of (i) fractional counting on the\nimpact factor (IF) and (ii) transformation of the skewed citation distributions\ninto a distribution of 100 percentiles and six percentile rank classes (top-1%,\ntop-5%, etc.). Do these approaches lead to field-normalized impact measures for\njournals? In addition to the two-year IF (IF2), we consider the five-year IF\n(IF5), the respective numerators of these IFs, and the number of Total Cites,\ncounted both as integers and fractionally. These various indicators are tested\nagainst the hypothesis that the classification of journals into 11 broad fields\nby PatentBoard/National Science Foundation provides statistically significant\nbetween-field effects. Using fractional counting the between-field variance is\nreduced by 91.7% in the case of IF5, and by 79.2% in the case of IF2. However,\nthe differences in citation counts are not significantly affected by fractional\ncounting. These results accord with previous studies, but the longer citation\nwindow of a fractionally counted IF5 can lead to significant improvement in the\nnormalization across fields."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22976", 
    "link": "http://arxiv.org/pdf/1205.1419v1", 
    "title": "An Integrated Impact Indicator (I3): A New Definition of \"Impact\" with   Policy Relevance", 
    "arxiv-id": "1205.1419v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2012-05-07T14:58:20Z", 
    "summary": "Allocation of research funding, as well as promotion and tenure decisions,\nare increasingly made using indicators and impact factors drawn from citations\nto published work. A debate among scientometricians about proper normalization\nof citation counts has resolved with the creation of an Integrated Impact\nIndicator (I3) that solves a number of problems found among previously used\nindicators. The I3 applies non-parametric statistics using percentiles,\nallowing highly-cited papers to be weighted more than less-cited ones. It\nfurther allows unbundling of venues (i.e., journals or databases) at the\narticle level. Measures at the article level can be re-aggregated in terms of\nunits of evaluation. At the venue level, the I3 creates a properly weighted\nalternative to the journal impact factor. I3 has the added advantage of\nenabling and quantifying classifications such as the six percentile rank\nclasses used by the National Science Board's Science & Engineering Indicators."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22976", 
    "link": "http://arxiv.org/pdf/1205.2555v2", 
    "title": "Public Data Integration with WebSmatch", 
    "arxiv-id": "1205.2555v2", 
    "author": "Z. Bellahsene", 
    "publish": "2012-05-11T15:24:09Z", 
    "summary": "Integrating open data sources can yield high value information but raises\nmajor problems in terms of metadata extraction, data source integration and\nvisualization of integrated data. In this paper, we describe WebSmatch, a\nflexible environment for Web data integration, based on a real, end-to-end data\nintegration scenario over public data from Data Publica. WebSmatch supports the\nfull process of importing, refining and integrating data sources and uses third\nparty tools for high quality visualization. We use a typical scenario of public\ndata integration which involves problems not solved by currents tools: poorly\nstructured input data sources (XLS files) and rich visualization of integrated\ndata."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22976", 
    "link": "http://arxiv.org/pdf/1206.0570v1", 
    "title": "Automatic Generation of OWL Ontology from XML Data Source", 
    "arxiv-id": "1206.0570v1", 
    "author": "AbdelWahab Ahmed", 
    "publish": "2012-06-04T09:55:33Z", 
    "summary": "The eXtensible Markup Language (XML) can be used as data exchange format in\ndifferent domains. It allows different parties to exchange data by providing\ncommon understanding of the basic concepts in the domain. XML covers the\nsyntactic level, but lacks support for reasoning. Ontology can provide a\nsemantic representation of domain knowledge which supports efficient reasoning\nand expressive power. One of the most popular ontology languages is the Web\nOntology Language (OWL). It can represent domain knowledge using classes,\nproperties, axioms and instances for the use in a distributed environment such\nas the World Wide Web. This paper presents a new method for automatic\ngeneration of OWL ontology from XML data sources."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22976", 
    "link": "http://arxiv.org/pdf/1206.1833v1", 
    "title": "CyberChair: A Web-Based Groupware Application to Facilitate the Paper   Reviewing Process", 
    "arxiv-id": "1206.1833v1", 
    "author": "Richard van de Stadt", 
    "publish": "2012-06-08T18:19:01Z", 
    "summary": "In this paper we describe CyberChair, a web-based groupware application that\nsupports the review process for technical contributions to conferences.\nCyberChair deals with most administrative tasks that are involved in the review\nprocess, such as storing author information, abstracts, (camera-ready) papers\nand reviews. It generates several overviews based on the reviews which support\nthe Program Committee (PC) in selecting the best papers. CyberChair points out\nconflicting reviews and offers the reviewers means to easily communicate to\nsolve these conflicts. In his paper Identify the Champion, O. Nierstrasz\ndescribes this review process in terms of a pattern language. CyberChair\nsupports PCs by using these patterns in its implementation."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22976", 
    "link": "http://arxiv.org/pdf/1206.3664v1", 
    "title": "Green and Gold Open Access Percentages and Growth, by Discipline", 
    "arxiv-id": "1206.3664v1", 
    "author": "Stevan Harnad", 
    "publish": "2012-06-16T13:21:04Z", 
    "summary": "Most refereed journal articles today are published in subscription journals,\naccessible only to subscribing institutions, hence losing considerable research\nimpact. Making articles freely accessible online (\"Open Access,\" OA) maximizes\ntheir impact. Articles can be made OA in two ways: by self-archiving them on\nthe web (\"Green OA\") or by publishing them in OA journals (\"Gold OA\"). We\ncompared the percent and growth rate of Green and Gold OA for 14 disciplines in\ntwo random samples of 1300 articles per discipline out of the 12,500 journals\nindexed by Thomson-Reuters-ISI using a robot that trawled the web for OA\nfull-texts. We sampled in 2009 and 2011 for publication year ranges 1998-2006\nand 2005-2010, respectively. Green OA (21.4%) exceeds Gold OA (2.4%) in\nproportion and growth rate in all but the biomedical disciplines, probably\nbecause it can be provided for all journals articles and does not require\npaying extra Gold OA publication fees. The spontaneous overall OA growth rate\nis still very slow (about 1% per year). If institutions make Green OA\nself-archiving mandatory, however, it triples percent Green OA as well as\naccelerating its growth rate."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22976", 
    "link": "http://arxiv.org/pdf/1206.3747v2", 
    "title": "Statistics for the Dynamic Analysis of Scientometric Data: The evolution   of the sciences in terms of trajectories and regimes", 
    "arxiv-id": "1206.3747v2", 
    "author": "Loet Leydesdorff", 
    "publish": "2012-06-17T11:51:13Z", 
    "summary": "The gap in statistics between multi-variate and time-series analysis can be\nbridged by using entropy statistics and recent developments in\nmulti-dimensional scaling. For explaining the evolution of the sciences as\nnon-linear dynamics, the configurations among variables can be important in\naddition to the statistics of individual variables and trend lines. Animations\nenable us to combine multiple perspectives (based on configurations of\nvariables) and to visualize path-dependencies in terms of trajectories and\nregimes. Path-dependent transitions and systems formation can be tested using\nentropy statistics."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22976", 
    "link": "http://arxiv.org/pdf/1206.4863v1", 
    "title": "An empirical analysis of the use of alphabetical authorship in   scientific publishing", 
    "arxiv-id": "1206.4863v1", 
    "author": "Ludo Waltman", 
    "publish": "2012-06-21T13:09:01Z", 
    "summary": "There are different ways in which the authors of a scientific publication can\ndetermine the order in which their names are listed. Sometimes author names are\nsimply listed alphabetically. In other cases, authorship order is determined\nbased on the contribution authors have made to a publication.\nContribution-based authorship can facilitate proper credit assignment, for\ninstance by giving most credits to the first author. In the case of\nalphabetical authorship, nothing can be inferred about the relative\ncontribution made by the different authors of a publication. In this paper, we\npresent an empirical analysis of the use of alphabetical authorship in\nscientific publishing. Our analysis covers all fields of science. We find that\nthe use of alphabetical authorship is declining over time. In 2011, the authors\nof less than 4% of all publications intentionally chose to list their names\nalphabetically. The use of alphabetical authorship is most common in\nmathematics, economics (including finance), and high energy physics. Also, the\nuse of alphabetical authorship is relatively more common in the case of\npublications with either a small or a large number of authors."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22976", 
    "link": "http://arxiv.org/pdf/1206.5048v1", 
    "title": "The Planetary Project: Towards eMath3.0", 
    "arxiv-id": "1206.5048v1", 
    "author": "Michael Kohlhase", 
    "publish": "2012-06-22T03:44:46Z", 
    "summary": "The Planetary project develops a general framework - the Planetary system -\nfor social semantic portals that support users in interacting with STEM\n(Science/Technology/Engineering/Mathematics) documents. Developed from an\ninitial attempt to replace the aging portal of PlanetMath.org with a mashup of\nexisting MKM technologies, the Planetary system is now in a state, where it can\nserve as a basis for various eMath3.0 portals, ranging from eLearning systems\nover scientific archives to semantic help systems."
},{
    "category": "cs.DL", 
    "doi": "10.3390/fi4041004", 
    "link": "http://arxiv.org/pdf/1206.5135v1", 
    "title": "Three Steps to Heaven: Semantic Publishing in a Real World Workflow", 
    "arxiv-id": "1206.5135v1", 
    "author": "Robert Stevens", 
    "publish": "2012-06-22T12:56:58Z", 
    "summary": "Semantic publishing offers the promise of computable papers, enriched\nvisualisation and a realisation of the linked data ideal. In reality, however,\nthe publication process contrives to prevent richer semantics while culminating\nin a `lumpen' PDF. In this paper, we discuss a web-first approach to\npublication, and describe a three-tiered approach which integrates with the\nexisting authoring tooling. Critically, although it adds limited semantics, it\ndoes provide value to all the participants in the process: the author, the\nreader and the machine."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-012-0884-5", 
    "link": "http://arxiv.org/pdf/1208.1349v2", 
    "title": "Tracing scientist's research trends realtimely", 
    "arxiv-id": "1208.1349v2", 
    "author": "Shenmeng Xu", 
    "publish": "2012-08-07T07:08:21Z", 
    "summary": "In this research, we propose a method to trace scientists' research trends\nrealtimely. By monitoring the downloads of scientific articles in the journal\nof Scientometrics for 744 hours, namely one month, we investigate the download\nstatistics. Then we aggregate the keywords in these downloaded research papers,\nand analyze the trends of article downloading and keyword downloading.\nFurthermore, taking both the download of keywords and articles into\nconsideration, we design a method to detect the emerging research trends. We\nfind that in scientometrics field, social media, new indices to quantify\nscientific productivity (g-index), webometrics, semantic, text mining, open\naccess are emerging fields that scientometrics researchers are focusing on."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-012-0884-5", 
    "link": "http://arxiv.org/pdf/1208.4566v2", 
    "title": "Scientometrics", 
    "arxiv-id": "1208.4566v2", 
    "author": "Sta\u0161a Milojevi\u0107", 
    "publish": "2012-08-22T17:37:57Z", 
    "summary": "The paper provides an overview of the field of scientometrics, that is: the\nstudy of science, technology, and innovation from a quantitative perspective.\nWe cover major historical milestones in the development of this specialism from\nthe 1960s to today and discuss its relationship with the sociology of\nscientific knowledge, the library and information sciences, and science policy\nissues such as indicator development. The disciplinary organization of\nscientometrics is analyzed both conceptually and empirically, using a map of\njournals cited in the core journal of the field, entitled Scientometrics. A\nstate-of-the-art review of five major research threads is provided: (1) the\nmeasurement of impact; (2) the delineation of reference sets; (3) theories of\ncitation; (4) mapping science; and (5) the policy and management contexts of\nindicator developments."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-012-0884-5", 
    "link": "http://arxiv.org/pdf/1208.6122v2", 
    "title": "Source normalized indicators of citation impact: An overview of   different approaches and an empirical comparison", 
    "arxiv-id": "1208.6122v2", 
    "author": "Nees Jan van Eck", 
    "publish": "2012-08-30T10:02:34Z", 
    "summary": "Different scientific fields have different citation practices. Citation-based\nbibliometric indicators need to normalize for such differences between fields\nin order to allow for meaningful between-field comparisons of citation impact.\nTraditionally, normalization for field differences has usually been done based\non a field classification system. In this approach, each publication belongs to\none or more fields and the citation impact of a publication is calculated\nrelative to the other publications in the same field. Recently, the idea of\nsource normalization was introduced, which offers an alternative approach to\nnormalize for field differences. In this approach, normalization is done by\nlooking at the referencing behavior of citing publications or citing journals.\nIn this paper, we provide an overview of a number of source normalization\napproaches and we empirically compare these approaches with a traditional\nnormalization approach based on a field classification system. We also pay\nattention to the issue of the selection of the journals to be included in a\nnormalization for field differences. Our analysis indicates a number of\nproblems of the traditional classification-system-based normalization approach,\nsuggesting that source normalization approaches may yield more accurate\nresults."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-012-0884-5", 
    "link": "http://arxiv.org/pdf/1209.0036v1", 
    "title": "Supporting Structured Browsing for Full-Text Scientific Research Reports", 
    "arxiv-id": "1209.0036v1", 
    "author": "Robert B. Allen", 
    "publish": "2012-08-31T23:54:30Z", 
    "summary": "Scientific research is highly structured and some of that structure is\nreflected in research reports. Traditional scientific research reports are\nyielding to interactive documents which expose their internal structure and are\nrichly linked to other materials. In these changes, there are opportunities to\ntake advantage of the structure in scientific research reports which previously\nhave not been systematically captured. Thus, we explore ways of capturing more\nof the structure of research in reports about the research and we use that\nstructure to support the development of a new generation of document browsers\nwhich include novel interaction widgets. We apply the browsers incorporating\nthe conceptual modeling framework to full-text research reports from the Public\nLibrary of Science (PLoS). In addition, we describe the application of\nmodel-oriented constructs to facilitating highly interlinked digital libraries."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-012-0884-5", 
    "link": "http://arxiv.org/pdf/1209.0785v1", 
    "title": "Some modifications to the SNIP journal impact indicator", 
    "arxiv-id": "1209.0785v1", 
    "author": "Martijn S. Visser", 
    "publish": "2012-09-04T20:04:08Z", 
    "summary": "The SNIP (source normalized impact per paper) indicator is an indicator of\nthe citation impact of scientific journals. The indicator, introduced by Henk\nMoed in 2010, is included in Elsevier's Scopus database. The SNIP indicator\nuses a source normalized approach to correct for differences in citation\npractices between scientific fields. The strength of this approach is that it\ndoes not require a field classification system in which the boundaries of\nfields are explicitly defined. In this paper, a number of modifications that\nwill be made to the SNIP indicator are explained, and the advantages of the\nresulting revised SNIP indicator are pointed out. It is argued that the\noriginal SNIP indicator has some counterintuitive properties, and it is shown\nmathematically that the revised SNIP indicator does not have these properties.\nEmpirically, the differences between the original SNIP indicator and the\nrevised one turn out to be relatively small, although some systematic\ndifferences can be observed. Relations with other source normalized indicators\nproposed in the literature are discussed as well."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-012-0884-5", 
    "link": "http://arxiv.org/pdf/1209.2664v1", 
    "title": "A Plan For Curating \"Obsolete Data or Resources\"", 
    "arxiv-id": "1209.2664v1", 
    "author": "Michael L. Nelson", 
    "publish": "2012-09-12T16:54:45Z", 
    "summary": "Our cultural discourse is increasingly carried in the web. With the initial\nemergence of the web many years ago, there was a period where conventional\nmediums (e.g., music, movies, books, scholarly publications) were primary and\nthe web was a supplementary channel. This has now changed, where the web is\noften the primary channel, and other publishing mechanisms, if present at all,\nsupplement the web. Unfortunately, the technology for publishing information on\nthe web always outstrips our technology for preservation. My concern is less\nthat we will lose data of known importance (e.g., scientific data, census\ndata), but rather that we will lose data that we do not yet know is important.\nIn this paper I review some of the issues and, where appropriate, proposed\nsolutions for increasing the archivability of the web."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-012-0884-5", 
    "link": "http://arxiv.org/pdf/1209.2807v1", 
    "title": "True Peer Review", 
    "arxiv-id": "1209.2807v1", 
    "author": "Amit K. Chopra", 
    "publish": "2012-09-13T08:04:59Z", 
    "summary": "In computer science, conferences and journals conduct peer review in order to\ndecide what to publish. Many have pointed out the inherent weaknesses in peer\nreview, including those of bias, quality, and accountability. Many have\nsuggested and adopted refinements of peer review, for instance, double blind\npeer review with author rebuttals.\n  In this essay, I argue that peer review as currently practiced conflates the\nsensible idea of getting comments on a paper with the irrevocably-flawed one\nthat we either accept or reject the paper, which I term gatekeeping. If we look\nat the two separately, then it is clear that the ills associated with current\npeer review systems are not due to the practice of getting comments, but due to\nthe practice of gatekeeping.\n  True peer review constitutes my proposal for replacing existing peer review\nsystems. It embraces the idea of open debate on the merits of a paper; however,\nit rejects unequivocally the exercise of gatekeeping. True peer review offers\nall the benefits of current peer review systems but has none of its weaknesses.\nTrue peer review will lead to a truly engaged community of researchers and\ntherefore better science."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-012-0861-z", 
    "link": "http://arxiv.org/pdf/1209.3406v2", 
    "title": "Information Metrics (iMetrics): A Research Specialty with a   Socio-Cognitive Identity?", 
    "arxiv-id": "1209.3406v2", 
    "author": "Loet Leydesdorff", 
    "publish": "2012-09-15T13:36:38Z", 
    "summary": "\"Bibliometrics\", \"scientometrics\", \"informetrics\", and \"webometrics\" can all\nbe considered as manifestations of a single research area with similar\nobjectives and methods, which we call \"information metrics\" or iMetrics. This\nstudy explores the cognitive and social distinctness of iMetrics with respect\nto the general information science (IS), focusing on a core of researchers,\nshared vocabulary and literature/knowledge base. Our analysis investigates the\nsimilarities and differences between four document sets. The document sets are\ndrawn from three core journals for iMetrics research (Scientometrics, Journal\nof the American Society for Information Science and Technology, and Journal of\nInformetrics). We split JASIST into document sets containing iMetrics and\ngeneral IS articles. The volume of publications in this representation of the\nspecialty has increased rapidly during the last decade. A core of researchers\nthat predominantly focus on iMetrics topics can thus be identified. This core\ngroup has developed a shared vocabulary as exhibited in high similarity of\ntitle words and one that shares a knowledge base. The research front of this\nfield moves faster than the research front of information science in general,\nbringing it closer to Price's dream."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-012-0861-z", 
    "link": "http://arxiv.org/pdf/1209.3608v1", 
    "title": "Age-sensitive bibliographic coupling with an application in the history   of science", 
    "arxiv-id": "1209.3608v1", 
    "author": "Sandor Soos", 
    "publish": "2012-09-17T09:36:16Z", 
    "summary": "In science mapping, bibliographic coupling (BC) has been a standard tool for\ndiscovering the cognitive structure of research areas, such as constituent\nsubareas, directions, schools of thought, or paradigms. Modelled as a set of\ndocuments, research areas are often sorted into document clusters via BC\nrepresenting a thematic unit each. In this paper we propose an alternative\nmethod called age-sensitive bibliographic coupling: the aim is to enable the\nstandard method to produce historically valid thematic units, that is, to yield\ndocument clusters that represent the historical development of the thematic\nstructure of the subject as well. As such, the method is expected to be\nespecially beneficial for investigations on science dynamics and the history of\nscience. We apply the method within a bibliometric study in the modern history\nof bioscience, addressing the development of a complex, interdisciplinary\ndiscourse called the Species Problem."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-012-0861-z", 
    "link": "http://arxiv.org/pdf/1209.5850v1", 
    "title": "TheSoz: A SKOS Representation of the Thesaurus for the Social Sciences", 
    "arxiv-id": "1209.5850v1", 
    "author": "Brigitte Mathiak", 
    "publish": "2012-09-26T07:32:55Z", 
    "summary": "The Thesaurus for the Social Sciences (TheSoz) is a Linked Dataset in SKOS\nformat, which serves as a crucial instrument for information retrieval based on\ne.g. document indexing or search term recommendation. Thesauri and similar\ncontrolled vocabularies build a linking bridge for other datasets from the\nLinked Open Data cloud - even between different domains. The information and\nknowledge, which is exposed by such links, can be processed by Semantic Web\napplications. In this article the conversion process of the TheSoz to SKOS is\ndescribed including the analysis of the original dataset and its structure, the\nmapping to adequate SKOS classes and properties, and the technical conversion.\nFurthermore mappings to other datasets and the appliance of the TheSoz are\npresented. Finally, limitations and modeling issues encountered during the\ncreation process are discussed."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0062395", 
    "link": "http://arxiv.org/pdf/1210.0442v2", 
    "title": "Citation analysis may severely underestimate the impact of clinical   research as compared to basic research", 
    "arxiv-id": "1210.0442v2", 
    "author": "Wilco C. Peul", 
    "publish": "2012-10-01T15:39:14Z", 
    "summary": "Background: Citation analysis has become an important tool for research\nperformance assessment in the medical sciences. However, different areas of\nmedical research may have considerably different citation practices, even\nwithin the same medical field. Because of this, it is unclear to what extent\ncitation-based bibliometric indicators allow for valid comparisons between\nresearch units active in different areas of medical research.\n  Methodology: A visualization methodology is introduced that reveals\ndifferences in citation practices between medical research areas. The\nmethodology extracts terms from the titles and abstracts of a large collection\nof publications and uses these terms to visualize the structure of a medical\nfield and to indicate how research areas within this field differ from each\nother in their average citation impact.\n  Results: Visualizations are provided for 32 medical fields, defined based on\njournal subject categories in the Web of Science database. The analysis focuses\non three fields. In each of these fields, there turn out to be large\ndifferences in citation practices between research areas. Low-impact research\nareas tend to focus on clinical intervention research, while high-impact\nresearch areas are often more oriented on basic and diagnostic research.\n  Conclusions: Popular bibliometric indicators, such as the h-index and the\nimpact factor, do not correct for differences in citation practices between\nmedical fields. These indicators therefore cannot be used to make accurate\nbetween-field comparisons. More sophisticated bibliometric indicators do\ncorrect for field differences but still fail to take into account within-field\nheterogeneity in citation practices. As a consequence, the citation impact of\nclinical intervention research may be substantially underestimated in\ncomparison with basic and diagnostic research."
},{
    "category": "cs.DL", 
    "doi": "10.1140/epjst/e2012-01692-1", 
    "link": "http://arxiv.org/pdf/1210.1480v1", 
    "title": "Theoretical And Technological Building Blocks For An Innovation   Accelerator", 
    "arxiv-id": "1210.1480v1", 
    "author": "Dirk Helbing", 
    "publish": "2012-10-04T15:08:28Z", 
    "summary": "The scientific system that we use today was devised centuries ago and is\ninadequate for our current ICT-based society: the peer review system encourages\nconservatism, journal publications are monolithic and slow, data is often not\navailable to other scientists, and the independent validation of results is\nlimited. Building on the Innovation Accelerator paper by Helbing and Balietti\n(2011) this paper takes the initial global vision and reviews the theoretical\nand technological building blocks that can be used for implementing an\ninnovation (in first place: science) accelerator platform driven by\nre-imagining the science system. The envisioned platform would rest on four\npillars: (i) Redesign the incentive scheme to reduce behavior such as\nconservatism, herding and hyping; (ii) Advance scientific publications by\nbreaking up the monolithic paper unit and introducing other building blocks\nsuch as data, tools, experiment workflows, resources; (iii) Use machine\nreadable semantics for publications, debate structures, provenance etc. in\norder to include the computer as a partner in the scientific process, and (iv)\nBuild an online platform for collaboration, including a network of trust and\nreputation among the different types of stakeholders in the scientific system:\nscientists, educators, funding agencies, policy makers, students and industrial\ninnovators among others. Any such improvements to the scientific system must\nsupport the entire scientific process (unlike current tools that chop up the\nscientific process into disconnected pieces), must facilitate and encourage\ncollaboration and interdisciplinarity (again unlike current tools), must\nfacilitate the inclusion of intelligent computing in the scientific process,\nmust facilitate not only the core scientific process, but also accommodate\nother stakeholders such science policy makers, industrial innovators, and the\ngeneral public."
},{
    "category": "cs.DL", 
    "doi": "10.1140/epjst/e2012-01692-1", 
    "link": "http://arxiv.org/pdf/1210.1714v1", 
    "title": "Formats over Time: Exploring UK Web History", 
    "arxiv-id": "1210.1714v1", 
    "author": "Andrew N. Jackson", 
    "publish": "2012-10-05T11:34:33Z", 
    "summary": "Is software obsolescence a significant risk? To explore this issue, we\nanalysed a corpus of over 2.5 billion resources corresponding to the UK Web\ndomain, as crawled between 1996 and 2010. Using the DROID and Apache Tika\nidentification tools, we examined each resource and captured the results as\nextended MIME types, embedding version, software and hardware identifiers\nalongside the format information. The combined results form a detailed temporal\nformat profile of the corpus, which we have made available as open data. We\npresent the results of our initial analysis of this dataset. We look at image,\nHTML and PDF resources in some detail, showing how the usage of different\nformats, versions and software implementations has changed over time.\nFurthermore, we show that software obsolescence is rare on the web and uncover\nevidence indicating that network effects act to stabilise formats against\nobsolescence."
},{
    "category": "cs.DL", 
    "doi": "10.1140/epjst/e2012-01692-1", 
    "link": "http://arxiv.org/pdf/1210.5224v2", 
    "title": "Use of Repositories and its Significance for Engineering Education / El   Uso de Repositorios y su Importancia para la Educaci\u00f3n en Ingenier\u00eda", 
    "arxiv-id": "1210.5224v2", 
    "author": "Ariel Lira", 
    "publish": "2012-10-18T19:08:35Z", 
    "summary": "Institutional repositories are deposits of different types of digital files\nfor access, disseminate and preserve them. This paper aims to explain the\nimportance of repositories in the academic field of engineering as a way to\ndemocratize knowledge by teachers, researchers and students to contribute to\nsocial and human development. These repositories, usually framed in the Open\nAccess Initiative, allow to ensure access free and open (unrestricted legal and\neconomic) to different sectors of society and, thus, can make use of the\nservices they offer. Finally, that repositories are evolving in the academic\nand scientific, and different disciplines of engineering should be prepared to\nprovide a range of services through these systems to society of today and\ntomorrow."
},{
    "category": "cs.DL", 
    "doi": "10.1140/epjst/e2012-01692-1", 
    "link": "http://arxiv.org/pdf/1210.6456v2", 
    "title": "Interactive Overlay Maps for US Patent (USPTO) Data Based on   International Patent Classifications (IPC)", 
    "arxiv-id": "1210.6456v2", 
    "author": "Ismael Rafols", 
    "publish": "2012-10-24T08:32:44Z", 
    "summary": "We report on the development of an interface to the US Patent and Trademark\nOffice (USPTO) that allows for the mapping of patent portfolios as overlays to\nbasemaps constructed from citation relations among all patents contained in\nthis database during the period 1976-2011. Both the interface and the data are\nin the public domain; the freeware programs VOSViewer and/or Pajek can be used\nfor the visualization. These basemaps and overlays can be generated at both the\n3-digit and 4-digit levels of the International Patent Classifications (IPC) of\nthe World Intellectual Property Organization (WIPO). The basemaps can provide a\nstable mental framework for analysts to follow developments over searches for\ndifferent years, which can be animated. The full flexibility of the advanced\nsearch engines of USPTO are available for generating sets of patents and/or\npatent applications which can thus be visualized and compared. This instrument\nallows for addressing questions about technological distance, diversity in\nportfolios, and animating the developments of both technologies and\ntechnological capacities of organizations over time."
},{
    "category": "cs.DL", 
    "doi": "10.1140/epjst/e2012-01692-1", 
    "link": "http://arxiv.org/pdf/1210.8174v2", 
    "title": "Testing the Finch Hypothesis on Green OA Mandate Ineffectiveness", 
    "arxiv-id": "1210.8174v2", 
    "author": "Stevan Harnad", 
    "publish": "2012-10-30T21:22:50Z", 
    "summary": "We have now tested the Finch Committee's Hypothesis that Green Open Access\nMandates are ineffective in generating deposits in institutional repositories.\nWith data from ROARMAP on institutional Green OA mandates and data from ROAR on\ninstitutional repositories, we show that deposit number and rate is\nsignificantly correlated with mandate strength (classified as 1-12): The\nstronger the mandate, the more the deposits. The strongest mandates generate\ndeposit rates of 70%+ within 2 years of adoption, compared to the un-mandated\ndeposit rate of 20%. The effect is already detectable at the national level,\nwhere the UK, which has the largest proportion of Green OA mandates, has a\nnational OA rate of 35%, compared to the global baseline of 25%. The conclusion\nis that, contrary to the Finch Hypothesis, Green Open Access Mandates do have a\nmajor effect, and the stronger the mandate, the stronger the effect (the Liege\nID/OA mandate, linked to research performance evaluation, being the strongest\nmandate model). RCUK (as well as all universities, research institutions and\nresearch funders worldwide) would be well advised to adopt the strongest Green\nOA mandates and to integrate institutional and funder mandates."
},{
    "category": "cs.DL", 
    "doi": "10.1140/epjst/e2012-01692-1", 
    "link": "http://arxiv.org/pdf/1211.2571v2", 
    "title": "Field-normalized Impact Factors: A Comparison of Rescaling versus   Fractionally Counted IFs", 
    "arxiv-id": "1211.2571v2", 
    "author": "Wouter de Nooy", 
    "publish": "2012-11-12T11:22:25Z", 
    "summary": "Two methods for comparing impact factors and citation rates across fields of\nscience are tested against each other using citations to the 3,705 journals in\nthe Science Citation Index 2010 (CD-Rom version of SCI) and the 13 field\ncategories used for the Science and Engineering Indicators of the US National\nScience Board. We compare (i) normalization by counting citations in proportion\nto the length of the reference list (1/N of references) with (ii) rescaling by\ndividing citation scores by the arithmetic mean of the citation rate of the\ncluster. Rescaling is analytical and therefore independent of the quality of\nthe attribution to the sets, whereas fractional counting provides an empirical\nstrategy for normalization among sets (by evaluating the between-group\nvariance). By the fairness test of Radicchi & Castellano (2012a), rescaling\noutperforms fractional counting of citations for reasons that we consider."
},{
    "category": "cs.DL", 
    "doi": "10.1140/epjst/e2012-01692-1", 
    "link": "http://arxiv.org/pdf/1211.2575v1", 
    "title": "A semantic cache for enhancing Web services communities activities:   Health care case study", 
    "arxiv-id": "1211.2575v1", 
    "author": "Jalel Akaichi", 
    "publish": "2012-11-12T11:24:34Z", 
    "summary": "Collective memories are strong support for enhancing the activities of\ncapitalization, management and dissemination inside a Web services community."
},{
    "category": "cs.DL", 
    "doi": "10.1140/epjst/e2012-01692-1", 
    "link": "http://arxiv.org/pdf/1211.5820v1", 
    "title": "A bird's-eye view of scientific trading: Dependency relations among   fields of science", 
    "arxiv-id": "1211.5820v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2012-11-25T23:22:05Z", 
    "summary": "We use a trading metaphor to study knowledge transfer in the sciences as well\nas the social sciences. The metaphor comprises four dimensions: (a) Discipline\nSelf-dependence, (b) Knowledge Exports/Imports, (c) Scientific Trading\nDynamics, and (d) Scientific Trading Impact. This framework is applied to a\ndataset of 221 Web of Science subject categories. We find that: (i) the\nScientific Trading Impact and Dynamics of Materials Science And Transportation\nScience have increased; (ii) Biomedical Disciplines, Physics, And Mathematics\nare significant knowledge exporters, as is Statistics & Probability; (iii) in\nthe social sciences, Economics, Business, Psychology, Management, And Sociology\nare important knowledge exporters; (iv) Discipline Self-dependence is\nassociated with specialized domains which have ties to professional practice\n(e.g., Law, Ophthalmology, Dentistry, Oral Surgery & Medicine, Psychology,\nPsychoanalysis, Veterinary Sciences, And Nursing)."
},{
    "category": "cs.DL", 
    "doi": "10.1140/epjst/e2012-01692-1", 
    "link": "http://arxiv.org/pdf/1212.0638v2", 
    "title": "Manipulating Google Scholar Citations and Google Scholar Metrics:   simple, easy and tempting", 
    "arxiv-id": "1212.0638v2", 
    "author": "Daniel Torres-Salinas", 
    "publish": "2012-12-04T08:30:13Z", 
    "summary": "The launch of Google Scholar Citations and Google Scholar Metrics may provoke\na revolution in the research evaluation field as it places within every\nresearchers reach tools that allow bibliometric measuring. In order to alert\nthe research community over how easily one can manipulate the data and\nbibliometric indicators offered by Google s products we present an experiment\nin which we manipulate the Google Citations profiles of a research group\nthrough the creation of false documents that cite their documents, and\nconsequently, the journals in which they have published modifying their H\nindex. For this purpose we created six documents authored by a faked author and\nwe uploaded them to a researcher s personal website under the University of\nGranadas domain. The result of the experiment meant an increase of 774\ncitations in 129 papers (six citations per paper) increasing the authors and\njournals H index. We analyse the malicious effect this type of practices can\ncause to Google Scholar Citations and Google Scholar Metrics. Finally, we\nconclude with several deliberations over the effects these malpractices may\nhave and the lack of control tools these tools offer"
},{
    "category": "cs.DL", 
    "doi": "10.1140/epjst/e2012-01692-1", 
    "link": "http://arxiv.org/pdf/1212.0823v3", 
    "title": "Interdisciplinarity at the Journal and Specialty Level: The changing   knowledge bases of the journal Cognitive Science", 
    "arxiv-id": "1212.0823v3", 
    "author": "Robert L. Goldstone", 
    "publish": "2012-12-04T19:02:40Z", 
    "summary": "Using the referencing patterns in articles in Cognitive Science over three\ndecades, we analyze the knowledge base of this literature in terms of its\nchanging disciplinary composition. Three periods are distinguished: (1)\nconstruction of the interdisciplinary space in the 1980s; (2) development of an\ninterdisciplinary orientation in the 1990s; (3) reintegration into \"cognitive\npsychology\" in the 2000s. The fluidity and fuzziness of the interdisciplinary\ndelineations in the different visualizations can be reduced and clarified using\nfactor analysis. We also explore newly available routines (\"CorText\") to\nanalyze this development in terms of \"tubes\" using an alluvial map, and compare\nthe results with an animation (using \"visone\"). The historical specificity of\nthis development can be compared with the development of \"artificial\nintelligence\" into an integrated specialty during this same period.\n\"Interdisciplinarity\" should be defined differently at the level of journals\nand of specialties."
},{
    "category": "cs.DL", 
    "doi": "10.1140/epjst/e2012-01692-1", 
    "link": "http://arxiv.org/pdf/1212.3677v1", 
    "title": "Discovering Links for Metadata Enrichment on Computer Science Papers", 
    "arxiv-id": "1212.3677v1", 
    "author": "Philipp Mayr", 
    "publish": "2012-12-15T12:09:57Z", 
    "summary": "At the very beginning of compiling a bibliography, usually only basic\ninformation, such as title, authors and publication date of an item are known.\nIn order to gather additional information about a specific item, one typically\nhas to search the library catalog or use a web search engine. This look-up\nprocedure implies a manual effort for every single item of a bibliography. In\nthis technical report we present a proof of concept which utilizes Linked Data\ntechnology for the simple enrichment of sparse metadata sets. This is done by\ndiscovering owl:sameAs links be- tween an initial set of computer science\npapers and resources from external data sources like DBLP, ACM and the Semantic\nWeb Conference Corpus. In this report, we demonstrate how the link discovery\ntool Silk is used to detect additional information and to enrich an initial set\nof records in the computer science domain. The pros and cons of silk as link\ndiscovery tool are summarized in the end."
},{
    "category": "cs.DL", 
    "doi": "10.5120/9629-4272", 
    "link": "http://arxiv.org/pdf/1212.4935v1", 
    "title": "A Study on the Open Source Digital Library Software's: Special Reference   to DSpace, EPrints and Greenstone", 
    "arxiv-id": "1212.4935v1", 
    "author": "Sumeer Gul", 
    "publish": "2012-12-20T06:44:42Z", 
    "summary": "The richness in knowledge has changed access methods for all stake holders in\nretrieving key knowledge and relevant information. This paper presents a study\nof three open source digital library management software used to assimilate and\ndisseminate information to world audience. The methodology followed involves\nonline survey and study of related software documentation and associated\ntechnical manuals."
},{
    "category": "cs.DL", 
    "doi": "10.5120/9629-4272", 
    "link": "http://arxiv.org/pdf/1212.5194v2", 
    "title": "International Scientific Migration and Collaboration Patterns Following   a Bibliometrics Line of Investigation", 
    "arxiv-id": "1212.5194v2", 
    "author": "Henk F. Moed", 
    "publish": "2012-12-20T19:14:26Z", 
    "summary": "A bibliometric approach is explored to tracking international scientific\nmigration, based on an analysis of the affiliation countries of authors\npublishing in peer reviewed journals indexed in Scopus. The paper introduces a\nmodel that relates base concepts in the study of migration to bibliometric\nconstructs, and discusses the potentialities and limitations of a bibliometric\napproach both with respect to data accuracy and interpretation. Synchronous and\nasynchronous analyses are presented for 10 rapidly growing countries and 7\nscientifically established countries. Rough error rates of the proposed\nindicators are estimated. It is concluded that the bibliometric approach is\npromising provided that its outcomes are interpreted with care, based on\ninsight into the limits and potentialities of the bibliometric approach, and\ncombined with complementary data, obtained, for instance, from researchers\nCurricula Vitae or survey or questionnaire based data. Error rates for units of\nassessment with indicator values based on sufficiently large numbers are\nestimated to be fairly below 10 per cent, but can be expected to vary\nsubstantially among countries of origin, especially between Asian countries and\nWestern countries."
},{
    "category": "cs.DL", 
    "doi": "10.1057/jors.2014.113", 
    "link": "http://arxiv.org/pdf/1212.6773v1", 
    "title": "Identifying Research Fields within Business and Management: A Journal   Cross-Citation Analysis", 
    "arxiv-id": "1212.6773v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2012-12-30T20:35:06Z", 
    "summary": "A discipline such as business and management (B&M) is very broad and has many\nfields within it, ranging from fairly scientific ones such as management\nscience or economics to softer ones such as information systems. There are at\nleast two reasons why it is important to identify these sub-fields accurately.\nFirstly, for the purpose of normalizing citation data as it is well known that\ncitation rates vary significantly between different disciplines. Secondly,\nbecause journal rankings and lists tend to split their classifications into\ndifferent subjects, for example the the Association of Business Schools (ABS)\nlist, which is a standard in the UK, has 22 different fields. Unfortunately, at\nthe moment these are created in an ad hoc manner with no underlying rigour. The\npurpose of this paper is to identify possible sub-fields in B&M rigorously\nbased on actual citation patterns. We have examined 450 journals in B&M which\nare included in the ISI Web of Science (WoS) and analysed the cross-citation\nrates between them enabling us to generate sets of coherent and consistent\nsub-fields that minimise the extent to which journals appear in several\ncategories. Implications and limitations of the analysis are discussed"
},{
    "category": "cs.DL", 
    "doi": "10.1057/jors.2014.113", 
    "link": "http://arxiv.org/pdf/1302.0608v1", 
    "title": "On the use of Biplot analysis for multivariate bibliometric and   scientific indicators", 
    "arxiv-id": "1302.0608v1", 
    "author": "Emilio Delgado L\u00f3pez-C\u00f3zar", 
    "publish": "2013-02-04T08:25:34Z", 
    "summary": "Bibliometric mapping and visualization techniques represent one of the main\npillars in the field of scientometrics. Traditionally, the main methodologies\nemployed for representing data are Multi-Dimensional Scaling, Principal\nComponent Analysis or Correspondence Analysis. In this paper we aim at\npresenting a visualization methodology known as Biplot analysis for\nrepresenting bibliometric and science and technology indicators. A Biplot is a\ngraphical representation of multivariate data, where the elements of a data\nmatrix are represented according to dots and vectors associated with the rows\nand columns of the matrix. In this paper we explore the possibilities of\napplying the Biplot analysis in the research policy area. More specifically we\nwill first describe and introduce the reader to this methodology and secondly,\nwe will analyze its strengths and weaknesses through three different study\ncases: countries, universities and scientific fields. For this, we use a Biplot\nanalysis known as JK-Biplot. Finally we compare the Biplot representation with\nother multivariate analysis techniques. We conclude that Biplot analysis could\nbe a useful technique in scientometrics when studying multivariate data and an\neasy-to-read tool for research decision makers."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.websem.2013.05.001", 
    "link": "http://arxiv.org/pdf/1302.1224v1", 
    "title": "Key Choices in the Design of Simple Knowledge Organization System (SKOS)", 
    "arxiv-id": "1302.1224v1", 
    "author": "Ed Summers", 
    "publish": "2013-02-05T22:21:52Z", 
    "summary": "Simple Knowledge Organization System (SKOS) provides a data model and\nvocabulary for expressing Knowledge Organization Systems (KOSs) such as\nthesauri and classification schemes in Semantic Web applications. This paper\npresents the main components of SKOS and their formal expression in Web\nOntology Language (OWL), providing an extensive account of the design decisions\ntaken by the Semantic Web Deployment (SWD) Working Group of the World Wide Web\nConsortium (W3C), which between 2006 and 2009 brought SKOS to the status of W3C\nRecommendation. The paper explains key design principles such as \"minimal\nontological commitment\" and systematically cites the requirements and issues\nthat influenced the design of SKOS components.\n  By reconstructing the discussion around alternative features and design\noptions and presenting the rationale for design decisions, the paper aims at\nproviding insight into how SKOS turned out as it did, and why. Assuming that\nSKOS, like any other successful technology, may eventually be subject to\nrevision and improvement, the critical account offered here may help future\neditors approach such a task with deeper understanding."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.websem.2013.05.001", 
    "link": "http://arxiv.org/pdf/1302.1848v2", 
    "title": "H Index of History journals published in Spain according to Google   Scholar Metrics (2007-2011)", 
    "arxiv-id": "1302.1848v2", 
    "author": "Manuel Ramirez Sanchez", 
    "publish": "2013-02-07T20:16:17Z", 
    "summary": "Google Scholar Metrics (GSM), which was recently launched in April 2012,\nfeatures new bibliometric systems for gauging scientific journals by counting\nthe number of citations obtained in Google Scholar. This way, it opens new\npossibilities for measuring journal impacts in the field of Humanities. The\npresent article intends to evaluate the scope of this tool through analysing\nGSM searches, from the 5th through 6th of December 2012, of History journals\npublished in Spain. In sum, 69 journals were identified, accounting for only\n24% of the History journals published in Spain. The ranges of H index values\nfor this field are so small that the ranking can no longer be said to show a\ndiscriminating potential. In the light of this, we would like to propose a\nchange in the way Google Scholar Metrics is designed so that it could also\naccommodate production and citation patterns in the particular field of\nHistory, and, in a broader scope, in the area of Humanities as well."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22735", 
    "link": "http://arxiv.org/pdf/1302.4053v1", 
    "title": "Mapping Academic Institutions According to Their Journal Publication   Profile: Spanish Universities as a Case Study", 
    "arxiv-id": "1302.4053v1", 
    "author": "Daniel Torres-Salinas", 
    "publish": "2013-02-17T10:37:09Z", 
    "summary": "We introduce a novel methodology for mapping academic institutions based on\ntheir journal publication profiles. We believe that journals in which\nresearchers from academic institutions publish their works can be considered as\nuseful identifiers for representing the relationships between these\ninstitutions and establishing comparisons. However, when academic journals are\nused for research output representation, distinctions must be introduced\nbetween them, based on their value as institution descriptors. This leads us to\nthe use of journal weights attached to the institution identifiers. Since a\njournal in which researchers from a large proportion of institutions published\ntheir papers may be a bad indicator of similarity between two academic\ninstitutions, it seems reasonable to weight it in accordance with how\nfrequently researchers from different institutions published their papers in\nthis journal. Cluster analysis can then be applied to group the academic\ninstitutions, and dendrograms can be provided to illustrate groups of\ninstitutions following agglomerative hierarchical clustering. In order to test\nthis methodology, we use a sample of Spanish universities as a case study. We\nfirst map the study sample according to an institution's overall research\noutput, then we use it for two scientific fields (Information and Communication\nTechnologies, as well as Medicine and Pharmacology) as a means to demonstrate\nhow our methodology can be applied, not only for analyzing institutions as a\nwhole, but also in different disciplinary contexts."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22735", 
    "link": "http://arxiv.org/pdf/1302.4591v4", 
    "title": "Linking Things on the Web: A Pragmatic Examination of Linked Data for   Libraries, Archives and Museums", 
    "arxiv-id": "1302.4591v4", 
    "author": "Dorothea Salo", 
    "publish": "2013-02-19T12:46:21Z", 
    "summary": "The Web publishing paradigm of Linked Data has been gaining traction in the\ncultural heritage sector: libraries, archives and museums. At first glance, the\nprinciples of Linked Data seem simple enough. However experienced Web\ndevelopers, designers and architects who attempt to put these ideas into\npractice often find themselves having to digest and understand debates about\nWeb architecture, the semantic web, artificial intelligence and the\nphilosophical nature of identity. In this paper I will discuss some of the\nreasons why Linked Data is of interest to the cultural heritage community, what\nsome of the pain points are for deploying it, and characterize some pragmatic\nways for cultural heritage organizations to realize the goals of Linked Data\nwith examples from the Web we have today."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22735", 
    "link": "http://arxiv.org/pdf/1302.4864v1", 
    "title": "Technology Transfer and the End of the Bayh-Dole Effect: Patents as an   Analytical Lens on University-Industry-Government Relations", 
    "arxiv-id": "1302.4864v1", 
    "author": "Martin Meyer", 
    "publish": "2013-02-20T10:30:29Z", 
    "summary": "Three periods can be distinguished in university patenting at the U.S. Patent\nand Trade Office (USPTO) since the Bayh-Dole Act of 1980: (1) a first period of\nexponential increase in university patenting till 1995 (filing date) or 1999\n(issuing date); (2) a period of relative decline since 1999; and (3) in most\nrecent years -- since 2008 -- a linear increase in university patenting. We\nargue that this last period is driven by specific non-US universities (e.g.,\nTokyo University and Chinese universities) patenting increasingly in the U.S.A.\nas the most competitive market for high-tech patents."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22735", 
    "link": "http://arxiv.org/pdf/1302.7274v2", 
    "title": "A measure for the impact of research", 
    "arxiv-id": "1302.7274v2", 
    "author": "Alejandro M. Arag\u00f3n", 
    "publish": "2013-02-28T18:20:53Z", 
    "summary": "The last few years have seen the proliferation of measures that quantify the\nscientific output of researches. Yet, these measures focus on productivity,\nthus fostering the \"publish or perish\" paradigm. This article proposes a\nmeasure that aims at quantifying the impact of research de-emphasizing\nproductivity, thus providing scientists an alternative, conceivably fairer,\nevaluation of their work. Emphasis is placed on the scientist rather than on\nquantities that can grow unbounded. The measure, defined initially for\nmanuscripts, is then extended to researchers and institutions."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22735", 
    "link": "http://arxiv.org/pdf/1303.3875v1", 
    "title": "F1000 recommendations as a new data source for research evaluation: A   comparison with citations", 
    "arxiv-id": "1303.3875v1", 
    "author": "Rodrigo Costas", 
    "publish": "2013-03-15T19:33:34Z", 
    "summary": "F1000 is a post-publication peer review service for biological and medical\nresearch. F1000 aims to recommend important publications in the biomedical\nliterature, and from this perspective F1000 could be an interesting tool for\nresearch evaluation. By linking the complete database of F1000 recommendations\nto the Web of Science bibliographic database, we are able to make a\ncomprehensive comparison between F1000 recommendations and citations. We find\nthat about 2% of the publications in the biomedical literature receive at least\none F1000 recommendation. Recommended publications on average receive 1.30\nrecommendations, and over 90% of the recommendations are given within half a\nyear after a publication has appeared. There turns out to be a clear\ncorrelation between F1000 recommendations and citations. However, the\ncorrelation is relatively weak, at least weaker than the correlation between\njournal impact and citations. More research is needed to identify the main\nreasons for differences between recommendations and citations in assessing the\nimpact of publications."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22735", 
    "link": "http://arxiv.org/pdf/1303.4366v2", 
    "title": "Group-Based Trajectory Modeling of Citations in Scholarly Literature:   Dynamic Qualities of \"Transient\" and \"Sticky Knowledge Claims\"", 
    "arxiv-id": "1303.4366v2", 
    "author": "Loet Leydesdorff", 
    "publish": "2013-03-18T19:13:44Z", 
    "summary": "Group-based Trajectory Modeling (GBTM) is applied to the citation curves of\narticles in six journals and to all citable items in a single field of science\n(Virology, 24 journals), in order to distinguish among the developmental\ntrajectories in subpopulations. Can highly-cited citation patterns be\ndistinguished in an early phase as \"fast-breaking\" papers? Can \"late bloomers\"\nor \"sleeping beauties\" be identified? Most interesting, we find differences\nbetween \"sticky knowledge claims\" that continue to be cited more than ten years\nafter publication, and \"transient knowledge claims\" that show a decay pattern\nafter reaching a peak within a few years. Only papers following the trajectory\nof a \"sticky knowledge claim\" can be expected to have a sustained impact. These\nfindings raise questions about indicators of \"excellence\" that use aggregated\ncitation rates after two or three years (e.g., impact factors). Because\naggregated citation curves can also be composites of the two patterns,\n5th-order polynomials (with four bending points) are needed to capture citation\ncurves precisely. For the journals under study, the most frequently cited\ngroups were furthermore much smaller than ten percent. Although GBTM has proved\na useful method for investigating differences among citation trajectories, the\nmethodology does not enable us to define a percentage of highly-cited papers\ninductively across different fields and journals. Using multinomial logistic\nregression, we conclude that predictor variables such as journal names, number\nof authors, etc., do not affect the stickiness of knowledge claims in terms of\ncitations, but only the levels of aggregated citations (that are\nfield-specific)."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.23631", 
    "link": "http://arxiv.org/pdf/1303.4672v5", 
    "title": "Strategic Intelligence on Emerging Technologies: Scientometric Overlay   Mapping", 
    "arxiv-id": "1303.4672v5", 
    "author": "Loet Leydesdorff", 
    "publish": "2013-03-19T17:44:58Z", 
    "summary": "This paper examines the use of scientometric overlay mapping as a tool of\n'strategic intelligence' to aid the governance of emerging technologies. We\ndevelop an integrative synthesis of different overlay mapping techniques and\nassociated perspectives on technological emergence across the geographical,\nsocial, and cognitive spaces. To do so, we longitudinally analyse (with\npublication and patent data) three case-studies of emerging technologies in the\nmedical domain. These are: RNA interference (RNAi), Human Papilloma Virus (HPV)\ntesting technologies for cervical cancer, and Thiopurine Methyltransferase\n(TPMT) genetic testing. Given the flexibility (i.e. adaptability to different\nsources of data) and granularity (i.e. applicability across multiple levels of\ndata aggregation) of overlay mapping techniques, we argue that these techniques\ncan favour the integration and comparison of results from different contexts\nand cases, thus potentially functioning as platform for a 'distributed'\nstrategic intelligence for analysts and decision-makers."
},{
    "category": "cs.DL", 
    "doi": "10.1177/0266382108098866", 
    "link": "http://arxiv.org/pdf/1303.4788v1", 
    "title": "Business information through Spain's Chambers of Commerce: meeting   business needs", 
    "arxiv-id": "1303.4788v1", 
    "author": "Pedro Hipola", 
    "publish": "2013-03-19T23:21:59Z", 
    "summary": "From different public and private instances, mechanisms have been set in\naction that allow for companies to obtain information in order to make\ndecisions with a stronger foundation. This article is focused on the\ndescription of an entire information system for the business world, developed\nin the realm of the Chambers of Commerce of Spain, which have given rise to the\ncreation of an authentic network of inter-chamber information.\n  In Spain, the obligatory membership of businesses to the Chambers of Commerce\nin their geographic areas, and therefore the compulsory payment of member\nquotas, has traditionally generated some polemics, above all because many firms\nhave not perceived a material usefulness of the services offered by these\nChambers.\n  Notwithstanding, the 85 Chambers currently existing in Spain, as well as the\norganism that coordinates them -the Upper Council or Consejo Superior de\nCamaras de Comercio- and the company created expressly to commercialize\ninformational services online, Camerdata, have developed genuinely informative\ntools that cover a good part of the informational demands that a business might\nclaim, described here."
},{
    "category": "cs.DL", 
    "doi": "10.1177/0266382108098866", 
    "link": "http://arxiv.org/pdf/1303.4905v2", 
    "title": "Web Maps and Their Algebra", 
    "arxiv-id": "1303.4905v2", 
    "author": "Giuseppe Pirr\u00f3", 
    "publish": "2013-03-20T11:15:10Z", 
    "summary": "A map is an abstract visual representation of a region, taken from a given\nspace, usually designed for final human consumption. Traditional cartography\nfocuses on the mapping of Euclidean spaces by using some distance metric. In\nthis paper we aim at mapping the Web space by leveraging its relational nature.\nWe introduce a general mathematical framework for maps and an algebra and\ndiscuss the feasibility of maps suitable for interpretation not only by humans\nbut also by machines."
},{
    "category": "cs.DL", 
    "doi": "10.1087/20130206", 
    "link": "http://arxiv.org/pdf/1303.5870v1", 
    "title": "Ranking journals: Could Google Scholar Metrics be an alternative to   Journal Citation Reports and Scimago Journal Rank?", 
    "arxiv-id": "1303.5870v1", 
    "author": "Alvaro Cabezas-Clavijo", 
    "publish": "2013-03-23T17:44:50Z", 
    "summary": "The launch of Google Scholar Metrics as a tool for assessing scientific\njournals may be serious competition for Thomson Reuters Journal Citation\nReports, and for Scopus powered Scimago Journal Rank. A review of these\nbibliometric journal evaluation products is performed. We compare their main\ncharacteristics from different approaches: coverage, indexing policies, search\nand visualization, bibliometric indicators, results analysis options, economic\ncost and differences in their ranking of journals. Despite its shortcomings,\nGoogle Scholar Metrics is a helpful tool for authors and editors in identifying\ncore journals. As an increasingly useful tool for ranking scientific journals,\nit may also challenge established journals products"
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2013.06.006", 
    "link": "http://arxiv.org/pdf/1308.0749v1", 
    "title": "Accuracy of simple, initials-based methods for author name   disambiguation", 
    "arxiv-id": "1308.0749v1", 
    "author": "Sta\u0161a Milojevi\u0107", 
    "publish": "2013-08-03T21:52:12Z", 
    "summary": "There are a number of solutions that perform unsupervised name disambiguation\nbased on the similarity of bibliographic records or common co-authorship\npatterns. Whether the use of these advanced methods, which are often difficult\nto implement, is warranted depends on whether the accuracy of the most basic\ndisambiguation methods, which only use the author's last name and initials, is\nsufficient for a particular purpose. We derive realistic estimates for the\naccuracy of simple, initials-based methods using simulated bibliographic\ndatasets in which the true identities of authors are known. Based on the\nsimulations in five diverse disciplines we find that the first initial method\nalready correctly identifies 97% of authors. An alternative simple method,\nwhich takes all initials into account, is typically two times less accurate,\nexcept in certain datasets that can be identified by applying a simple\ncriterion. Finally, we introduce a new name-based method that combines the\nfeatures of first initial and all initials methods by implicitly taking into\naccount the last name frequency and the size of the dataset. This hybrid method\nreduces the fraction of incorrectly identified authors by 10-30% over the first\ninitial method."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2013.06.006", 
    "link": "http://arxiv.org/pdf/1308.1838v1", 
    "title": "Tweeting biomedicine: an analysis of tweets and citations in the   biomedical literature", 
    "arxiv-id": "1308.1838v1", 
    "author": "Vincent Larivi\u00e8re", 
    "publish": "2013-08-08T13:09:13Z", 
    "summary": "Data collected by social media platforms have recently been introduced as a\nnew source for indicators to help measure the impact of scholarly research in\nways that are complementary to traditional citation-based indicators. Data\ngenerated from social media activities related to scholarly content can be used\nto reflect broad types of impact. This paper aims to provide systematic\nevidence regarding how often Twitter is used to diffuse journal articles in the\nbiomedical and life sciences. The analysis is based on a set of 1.4 million\ndocuments covered by both PubMed and Web of Science (WoS) and published between\n2010 and 2012. The number of tweets containing links to these documents was\nanalyzed to evaluate the degree to which certain journals, disciplines, and\nspecialties were represented on Twitter. It is shown that, with less than 10%\nof PubMed articles mentioned on Twitter, its uptake is low in general. The\nrelationship between tweets and WoS citations was examined for each document at\nthe level of journals and specialties. The results show that tweeting behavior\nvaries between journals and specialties and correlations between tweets and\ncitations are low, implying that impact metrics based on tweets are different\nfrom those based on citations. A framework utilizing the coverage of articles\nand the correlation between Twitter mentions and citations is proposed to\nfacilitate the evaluation of novel social-media based metrics and to shed light\non the question in how far the number of tweets is a valid metric to measure\nresearch impact."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2013.06.006", 
    "link": "http://arxiv.org/pdf/1308.5395v1", 
    "title": "Toward an Interactive Directory for Norfolk, Nebraska: 1899-1900", 
    "arxiv-id": "1308.5395v1", 
    "author": "Robert B. Allen", 
    "publish": "2013-08-25T10:40:34Z", 
    "summary": "We describe steps toward an interactive directory for the town of Norfolk,\nNebraska for the years 1899 and 1900. This directory would extend the\ntraditional city directory by including a wider range of entities being\ndescribed, much richer information about the entities mentioned and linkages to\nmentions of the entities in material such as digitized historical newspapers.\nSuch a directory would be useful to readers who browse the historical\nnewspapers by providing structured summaries of the entities mentioned. We\ndescribe the occurrence of entities in two years of the Norfolk Weekly News,\nfocusing on several individuals to better understand the types of information\nwhich can be gleaned from historical newspapers and other historical materials.\nWe also describe a prototype program which coordinates information about\nentities from the traditional city directories, the federal census, and from\nnewspapers. We discuss the structured coding for these entities, noting that\nricher coding would increasingly include descriptions of events and scenarios.\nWe propose that rich content about individuals and communities could eventually\nbe modeled with agents and woven into historical narratives."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2013.06.006", 
    "link": "http://arxiv.org/pdf/1309.0277v1", 
    "title": "Categorizing Influential Authors Using Penalty Areas", 
    "arxiv-id": "1309.0277v1", 
    "author": "Yannis Manolopoulos", 
    "publish": "2013-09-01T23:35:52Z", 
    "summary": "The concept of h-index has been proposed to easily assess a researcher's\nperformance with a single two-dimensional number. However, by using only this\nsingle number, we lose significant information about the distribution of the\nnumber of citations per article of an author's publication list. Two authors\nwith the same h-index may have totally different distributions of the number of\ncitations per article. One may have a very long \"tail\" in the citation curve,\ni.e. he may have published a great number of articles, which did not receive\nrelatively many citations. Another researcher may have a short tail, i.e.\nalmost all his publications got a relatively large number of citations. In this\narticle, we study an author's citation curve and we define some areas appearing\nin this curve. These areas are used to further evaluate authors' research\nperformance from quantitative and qualitative point of view. We call these\nareas as \"penalty\" ones, since the greater they are, the more an author's\nperformance is penalized. Moreover, we use these areas to establish new metrics\naiming at categorizing researchers in two distinct categories: \"influential\"\nones vs. \"mass producers\"."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2013.06.006", 
    "link": "http://arxiv.org/pdf/1309.1066v1", 
    "title": "Statistiques et visibilit\u00e9 des biblioth\u00e8ques num\u00e9riques : quelles   strat\u00e9gies de diffusion ?", 
    "arxiv-id": "1309.1066v1", 
    "author": "Ga\u00ebtan Tr\u00f6ger", 
    "publish": "2013-09-04T15:12:25Z", 
    "summary": "We compared statistics of major digital libraries and we tried to see if\nthere is a relationship between the volume of digital libraries and online\nvisibility of each digitized document. Finally, we analyzed the consequences of\nthe diffusion strategies of French digital libraries. The statistics were\nobtained by survey, gray literature, alexa.com, and Google Trends."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2013.06.006", 
    "link": "http://arxiv.org/pdf/1309.2409v1", 
    "title": "Letter to the editor: Against the Resilience of Rejected Manuscripts", 
    "arxiv-id": "1309.2409v1", 
    "author": "Emilio Delgado L\u00f3pez-C\u00f3zar", 
    "publish": "2013-09-10T08:28:12Z", 
    "summary": "In this letter we propose the development of guidelines by the main editors\nassociations as well as protocols within online journal management systems for\nkeeping track of rejected manuscripts that are resubmitted as well as for the\ninterchange of referees reports between journals."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2013.06.006", 
    "link": "http://arxiv.org/pdf/1309.2413v1", 
    "title": "The Google Scholar Experiment: how to index false papers and manipulate   bibliometric indicators", 
    "arxiv-id": "1309.2413v1", 
    "author": "Daniel Torres-Salinas", 
    "publish": "2013-09-10T08:33:57Z", 
    "summary": "Google Scholar has been well received by the research community. Its promises\nof free, universal and easy access to scientific literature as well as the\nperception that it covers better than other traditional multidisciplinary\ndatabases the areas of the Social Sciences and the Humanities have contributed\nto the quick expansion of Google Scholar Citations and Google Scholar Metrics:\ntwo new bibliometric products that offer citation data at the individual level\nand at journal level. In this paper we show the results of a experiment\nundertaken to analyze Google Scholar's capacity to detect citation counting\nmanipulation. For this, six documents were uploaded to an institutional web\ndomain authored by a false researcher and referencing all the publications of\nthe members of the EC3 research group at the University of Granada. The\ndetection of Google Scholar of these papers outburst the citations included in\nthe Google Scholar Citations profiles of the authors. We discuss the effects of\nsuch outburst and how it could affect the future development of such products\nnot only at individual level but also at journal level, especially if Google\nScholar persists with its lack of transparency."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2013.06.006", 
    "link": "http://arxiv.org/pdf/1309.2434v3", 
    "title": "Just Google It - Digital Research Practices of Humanities Scholars", 
    "arxiv-id": "1309.2434v3", 
    "author": "Stef Scagliola", 
    "publish": "2013-09-10T09:52:44Z", 
    "summary": "The transition from analogue to digital archives and the recent explosion of\nonline content offers researchers novel ways of engaging with data. The crucial\nquestion for ensuring a balance between the supply and demand-side of data, is\nwhether this trend connects to existing scholarly practices and to the average\nsearch skills of researchers. To gain insight into this process we conducted a\nsurvey among nearly three hundred (N= 288) humanities scholars in the\nNetherlands and Belgium with the aim of finding answers to the following\nquestions: 1) To what extent are digital databases and archives used? 2) What\nare the preferences in search functionalities 3) Are there differences in\nsearch strategies between novices and experts of information retrieval? Our\nresults show that while scholars actively engage in research online they mainly\nsearch for text and images. General search systems such as Google and JSTOR are\npredominant, while large-scale collections such as Europeana are rarely\nconsulted. Searching with keywords is the dominant search strategy and advanced\nsearch options are rarely used. When comparing novice and more experienced\nsearchers, the first tend to have a more narrow selection of search engines,\nand mostly use keywords. Our overall findings indicate that Google is the key\nplayer among available search engines. This dominant use illustrates the\nparadoxical attitude of scholars toward Google: while provenance and context\nare deemed key academic requirements, the workings of the Google algorithm\nremain unclear. We conclude that Google introduces a black box into digital\nscholarly practices, indicating scholars will become increasingly dependent on\nsuch black boxed algorithms. This calls for a reconsideration of the academic\nprinciples of provenance and context."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0071416", 
    "link": "http://arxiv.org/pdf/1309.2486v1", 
    "title": "Entitymetrics: Measuring the Impact of Entities", 
    "arxiv-id": "1309.2486v1", 
    "author": "Tamy Chambers", 
    "publish": "2013-09-10T12:45:47Z", 
    "summary": "This paper proposes entitymetrics to measure the impact of knowledge units.\nEntitymetrics highlight the importance of entities embedded in scientific\nliterature for further knowledge discovery. In this paper, we use Metformin, a\ndrug for diabetes, as an example to form an entity-entity citation network\nbased on literature related to Metformin. We then calculate the network\nfeatures and compare the centrality ranks of biological entities with results\nfrom Comparative Toxicogenomics Database (CTD). The comparison demonstrates the\nusefulness of entitymetrics to detect most of the outstanding interactions\nmanually curated in CTD."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0071416", 
    "link": "http://arxiv.org/pdf/1309.2546v1", 
    "title": "Finding knowledge paths among scientific disciplines", 
    "arxiv-id": "1309.2546v1", 
    "author": "Erjia Yan", 
    "publish": "2013-09-10T15:23:01Z", 
    "summary": "This paper discovers patterns of knowledge dissemination among scientific\ndisciplines. While the transfer of knowledge is largely unobservable, citations\nfrom one discipline to another have been proven to be an effective proxy to\nstudy disciplinary knowledge flow. This study constructs a knowledge flow\nnetwork in that a node represents a Journal Citation Report subject category\nand a link denotes the citations from one subject category to another. Using\nthe concept of shortest path, several quantitative measurements are proposed\nand applied to a knowledge flow network. Based on an examination of subject\ncategories in Journal Citation Report, this paper finds that social science\ndomains tend to be more self-contained and thus it is more difficult for\nknowledge from other domains to flow into them; at the same time, knowledge\nfrom science domains, such as biomedicine-, chemistry-, and physics-related\ndomains can access and be accessed by other domains more easily. This paper\nalso finds that social science domains are more disunified than science\ndomains, as three fifths of the knowledge paths from one social science domain\nto another need at least one science domain to serve as an intermediate. This\npaper contributes to discussions on disciplinarity and interdisciplinarity by\nproviding empirical analysis."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0071416", 
    "link": "http://arxiv.org/pdf/1309.4008v1", 
    "title": "Profiling Web Archive Coverage for Top-Level Domain and Content Language", 
    "arxiv-id": "1309.4008v1", 
    "author": "Herbert Van de Sompel", 
    "publish": "2013-09-16T15:39:35Z", 
    "summary": "The Memento aggregator currently polls every known public web archive when\nserving a request for an archived web page, even though some web archives focus\non only specific domains and ignore the others. Similar to query routing in\ndistributed search, we investigate the impact on aggregated Memento TimeMaps\n(lists of when and where a web page was archived) by only sending queries to\narchives likely to hold the archived page. We profile twelve public web\narchives using data from a variety of sources (the web, archives' access logs,\nand full-text queries to archives) and discover that only sending queries to\nthe top three web archives (i.e., a 75% reduction in the number of queries) for\nany request produces the full TimeMaps on 84% of the cases."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0071416", 
    "link": "http://arxiv.org/pdf/1309.4016v1", 
    "title": "Who and What Links to the Internet Archive", 
    "arxiv-id": "1309.4016v1", 
    "author": "Michael L. Nelson", 
    "publish": "2013-09-16T16:01:37Z", 
    "summary": "The Internet Archive's (IA) Wayback Machine is the largest and oldest public\nweb archive and has become a significant repository of our recent history and\ncultural heritage. Despite its importance, there has been little research about\nhow it is discovered and used. Based on web access logs, we analyze what users\nare looking for, why they come to IA, where they come from, and how pages link\nto IA. We find that users request English pages the most, followed by the\nEuropean languages. Most human users come to web archives because they do not\nfind the requested pages on the live web. About 65% of the requested archived\npages no longer exist on the live web. We find that more than 82% of human\nsessions connect to the Wayback Machine via referrals from other web sites,\nwhile only 15% of robots have referrers. Most of the links (86%) from websites\nare to individual archived pages at specific points in time, and of those 83%\nno longer exist on the live web."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0071416", 
    "link": "http://arxiv.org/pdf/1309.4932v1", 
    "title": "Developing a Robust Migration Workflow for Preserving and Curating   Hand-held Media", 
    "arxiv-id": "1309.4932v1", 
    "author": "Akiko Kimura", 
    "publish": "2013-09-19T11:10:13Z", 
    "summary": "Many memory institutions hold large collections of hand-held media, which can\ncomprise hundreds of terabytes of data spread over many thousands of\ndata-carriers. Many of these carriers are at risk of significant physical\ndegradation over time, depending on their composition. Unfortunately, handling\nthem manually is enormously time consuming and so a full and frequent\nevaluation of their condition is extremely expensive. It is, therefore,\nimportant to develop scalable processes for stabilizing them onto backed-up\nonline storage where they can be subject to highquality digital preservation\nmanagement. This goes hand in hand with the need to establish efficient,\nstandardized ways of recording metadata and to deal with defective\ndata-carriers. This paper discusses processing approaches, workflows, technical\nset-up, software solutions and touches on staffing needs for the stabilization\nprocess. We have experimented with different disk copying robots, defined our\nmetadata, and addressed storage issues to scale stabilization to the vast\nquantities of digital objects on hand-held data-carriers that need to be\npreserved. Working closely with the content curators, we have been able to\nbuild a robust data migration workflow and have stabilized over 16 terabytes of\ndata in a scalable and economical manner."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0071416", 
    "link": "http://arxiv.org/pdf/1309.5256v1", 
    "title": "Author Name Co-Mention Analysis: Testing a Poor Man's Author Co-Citation   Analysis Method", 
    "arxiv-id": "1309.5256v1", 
    "author": "Arnim Bleier", 
    "publish": "2013-09-20T12:54:17Z", 
    "summary": "As a social science information service for the German language countries, we\ndocument research projects, publications, and data in relevant fields. At the\nsame time, we aim to provide well-founded bibliometric studies of these fields.\nPerforming a citation analysis on an area of the German social sciences is,\nhowever, a serious challenge given the low and likely significantly biased\ncoverage of these fields in the standard citation databases. Citations, and\nespecially author citations, play a highly significant role in that literature,\nhowever. In this work in progress, we report preliminary methods and results\nfor an author name co-mention analysis of a large fragment of a particularly\ninteresting corpus of German sociology: a quarter century's worth of the\nfull-text proceedings of the Deutsche Gesellschaft fuer Soziologie (DGS), which\ncelebrated its 100th anniversary meeting in 2012. Results are encouraging for\nthis poor cousin of author co-citation analysis, but considerable refinements,\nespecially of the underlying computational infrastructure for full-text\nanalysis, appear advisable for full-scale deployment of this method."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2467696.2467718", 
    "link": "http://arxiv.org/pdf/1309.5503v1", 
    "title": "Evaluating Sliding and Sticky Target Policies by Measuring Temporal   Drift in Acyclic Walks Through a Web Archive", 
    "arxiv-id": "1309.5503v1", 
    "author": "Michael L. Nelson", 
    "publish": "2013-09-21T17:27:04Z", 
    "summary": "When a user views an archived page using the archive's user interface (UI),\nthe user selects a datetime to view from a list. The archived web page, if\navailable, is then displayed. From this display, the web archive UI attempts to\nsimulate the web browsing experience by smoothly transitioning between archived\npages. During this process, the target datetime changes with each link\nfollowed; drifting away from the datetime originally selected. When browsing\nsparsely-archived pages, this nearly-silent drift can be many years in just a\nfew clicks. We conducted 200,000 acyclic walks of archived pages, following up\nto 50 links per walk, comparing the results of two target datetime policies.\nThe Sliding Target policy allows the target datetime to change as it does in\narchive UIs such as the Internet Archive's Wayback Machine. The Sticky Target\npolicy, represented by the Memento API, keeps the target datetime the same\nthroughout the walk. We found that the Sliding Target policy drift increases\nwith the number of walk steps, number of domains visited, and choice (number of\nlinks available). However, the Sticky Target policy controls temporal drift,\nholding it to less than 30 days on average regardless of walk length or number\nof domains visited. The Sticky Target policy shows some increase as choice\nincreases, but this may be caused by other factors. We conclude that based on\nwalk length, the Sticky Target policy generally produces at least 30 days less\ndrift than the Sliding Target policy."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1143-0", 
    "link": "http://arxiv.org/pdf/1309.7099v1", 
    "title": "On the Internal Dynamics of the Shanghai Ranking", 
    "arxiv-id": "1309.7099v1", 
    "author": "Lawrence Cram", 
    "publish": "2013-09-27T01:47:37Z", 
    "summary": "The Academic Ranking of World Universities (ARWU) published by researchers at\nShanghai Jiao Tong University has become a major source of information for\nuniversity administrators, country officials, students and the public at large.\nRecent discoveries regarding its internal dynamics allow the inversion of\npublished ARWU indicator scores to reconstruct raw scores for five hundred\nworld class universities. This paper explores raw scores in the ARWU and in\nother contests to contrast the dynamics of rank-driven and score-driven tables,\nand to explain why the ARWU ranking is a score-driven procedure. We show that\nthe ARWU indicators constitute sub-scales of a single factor accounting for\nresearch performance, and provide an account of the system of gains and\nnon-linearities used by ARWU. The paper discusses the non-linearities selected\nby ARWU, concluding that they are designed to represent the regressive\ncharacter of indicators measuring research performance. We propose that the\nutility and usability of the ARWU could be greatly improved by replacing the\nunwanted dynamical effects of the annual re-scaling based on raw scores of the\nbest performers."
},{
    "category": "cs.DL", 
    "doi": "10.1109/BigData.2013.6691762", 
    "link": "http://arxiv.org/pdf/1309.7949v1", 
    "title": "Bibliometric-enhanced Retrieval Models for Big Scholarly Information   Systems", 
    "arxiv-id": "1309.7949v1", 
    "author": "Peter Mutschke", 
    "publish": "2013-09-30T18:32:14Z", 
    "summary": "Bibliometric techniques are not yet widely used to enhance retrieval\nprocesses in digital libraries, although they offer value-added effects for\nusers. In this paper we will explore how statistical modelling of scholarship,\nsuch as Bradfordizing or network analysis of coauthorship network, can improve\nretrieval services for specific communities, as well as for large, cross-domain\nlarge collections. This paper aims to raise awareness of the missing link\nbetween information retrieval (IR) and bibliometrics / scientometrics and to\ncreate a common ground for the incorporation of bibliometric-enhanced services\ninto retrieval at the digital library interface."
},{
    "category": "cs.DL", 
    "doi": "10.1109/BigData.2013.6691762", 
    "link": "http://arxiv.org/pdf/1311.3034v1", 
    "title": "Contribution of Information and Communication Technology (ICT) in   Country'S H-Index", 
    "arxiv-id": "1311.3034v1", 
    "author": "Nader Ale Ebrahim", 
    "publish": "2013-11-13T07:27:42Z", 
    "summary": "The aim of this study is to examine the effect of Information and\nCommunication Technology (ICT) development on country's scientific ranking as\nmeasured by H-index. Moreover, this study applies ICT development sub-indices\nincluding ICT Use, ICT Access and ICT skill to find the distinct effect of\nthese sub-indices on country's H-index. To this purpose, required data for the\npanel of 14 Middle East countries over the period 1995 to 2009 is collected.\nFindings of the current study show that ICT development increases the H-index\nof the sample countries. The results also indicate that ICT Use and ICT Skill\nsub-indices positively contribute to higher H-index but the effect of ICT\naccess on country's H-index is not clear."
},{
    "category": "cs.DL", 
    "doi": "10.1109/BigData.2013.6691762", 
    "link": "http://arxiv.org/pdf/1402.0928v3", 
    "title": "A Framework for Evaluation of Composite Memento Temporal Coherence", 
    "arxiv-id": "1402.0928v3", 
    "author": "Herbert Van de Sompel", 
    "publish": "2014-02-05T03:50:33Z", 
    "summary": "Most archived HTML pages embed other web resources, such as images and\nstylesheets. Playback of the archived web pages typically provides only the\ncapture date (or Memento-Datetime) of the root resource and not the\nMemento-Datetime of the embedded resources. In the course of our research, we\nhave discovered that the Memento-Datetime of embedded resources can be up to\nseveral years in the future or past, relative to the Memento-Datetime of the\nembedding root resource. We introduce a framework for assessing temporal\ncoherence between a root resource and its embedded resource depending on\nMemento-Datetime, Last-Modified datetime, and entity body."
},{
    "category": "cs.DL", 
    "doi": "10.1109/BigData.2013.6691762", 
    "link": "http://arxiv.org/pdf/1402.2003v2", 
    "title": "A New Approach to Reporting Archaeological Surveys: Connecting Rough   Cilicia, Visible Past and Open Context through loose coupling and 3d codes", 
    "arxiv-id": "1402.2003v2", 
    "author": "Eric C. Kansa", 
    "publish": "2014-02-09T23:09:21Z", 
    "summary": "The project presents the strategy adopted by the Rough Cilicia Archaeological\nSurvey team for publishing its primary data and reports via three potentially\ntransformative strategies for digital humanities: Loose coupling of digital\ndata curation and publishing platforms. In loosely coupled systems, components\nshare only a limited set of simple assumptions, which enables systems to evolve\ndynamically. Collaborative creation of map based narrative content. Connecting\nprint scholarship (book, reports, article) to online resources via\ntwo-dimensional barcodes (2D codes) that can be printed on paper and can call\nup hyperlinks when scanned with a Smartphone. The three strategies are made\npossible by loosely coupling two autonomous services: Visible Past, dedicated\nto web collaboration and digital-print publishing and Open Context, which is a\ngeo-historical data archiving and publishing service. The Rough Cilicia\nArchaeological Survey, Visible Past, and Open Context work together to\nillustrate a new genre of scholarship, which combine qualitative narratives and\nquantitative representations of space and social phenomena. The project\nprovides tools for collaborative creation of rich scholarly narratives that are\nspatially located and for connecting print publications to the digital realm.\nThe project is a case study for utilizing the three new strategies for creating\nand publishing spatial humanities scholarship more broadly for ancient\nhistorians."
},{
    "category": "cs.DL", 
    "doi": "10.1108/LHT-12-20112-0135", 
    "link": "http://arxiv.org/pdf/1402.2019v1", 
    "title": "Authoris: a tool for authority control in the semantic web", 
    "arxiv-id": "1402.2019v1", 
    "author": "Pedro Hipola", 
    "publish": "2014-02-10T02:33:03Z", 
    "summary": "Purpose: The purpose of this paper is to propose a tool that generates\nauthority files to be integrated with linked data by means of learning rules.\nAUTHORIS is software developed to enhance authority control and information\nexchange among bibliographic and non-bibliographic entities.\n  Design / methodology / approach: The article analyzes different methods\npreviously developed for authority control as well as IFLA and ALA standards\nfor managing bibliographic records. Semantic Web technologies are also\nevaluated. AUTHORIS relies on Drupal and incorporates the protocols of Dublin\nCore, SIOC, SKOS and FOAF. The tool has also taken into account the\nobsolescence of MARC and its substitution by FRBR and RDA. Its effectiveness\nwas evaluated applying a learning test proposed by RDA. Over 80 percent of the\nactions were carried out correctly.\n  Findings: The use of learning rules and the facilities of linked data make it\neasier for information organizations to reutilize products for authority\ncontrol and distribute them in a fair and efficient manner.\n  Research limitations / implications: The ISAD-G records were the ones\npresenting most errors. EAD was found to be second in the number of errors\nproduced. The rest of the formats --MARC 21, Dublin Core, FRAD, RDF, OWL, XBRL\nand FOAF-- showed fewer than 20 errors in total.\n  Practical implications: AUTHORIS offers institutions the means of sharing\ndata with a high level of stability, helping to detect records that are\nduplicated and contributing to lexical disambiguation and data enrichment.\n  Originality / value: The software combines the facilities of linked data, the\npotency of the algorithms for converting bibliographic data, and the precision\nof learning rules."
},{
    "category": "cs.DL", 
    "doi": "10.1108/LHT-12-20112-0135", 
    "link": "http://arxiv.org/pdf/1402.3418v1", 
    "title": "Scientific works citation analysis", 
    "arxiv-id": "1402.3418v1", 
    "author": "Alexander S. Kholodov", 
    "publish": "2014-02-14T10:19:55Z", 
    "summary": "Several questions of scientometrics parameters organization are considered.\nTwo new indices for scientific works citation analysis are proposed. They\nprovide more detailed and reliable scientific significance assessment of\nindividual authors and scientific groups basing on the publication activity"
},{
    "category": "cs.DL", 
    "doi": "10.1108/LHT-12-20112-0135", 
    "link": "http://arxiv.org/pdf/1402.3913v1", 
    "title": "Analysis of Personalized Information Service System for Digital   Libraries", 
    "arxiv-id": "1402.3913v1", 
    "author": "Yue Hu", 
    "publish": "2014-02-17T07:17:56Z", 
    "summary": "Along with the rapid development of digital library, digital library of the\nthird generation, taking the main characteristics of the personalized service,\nhas already become the mainstream today. This article first analyzes the\nconcept and characteristics of digital library, then elaborates the\ninevitability of personalized service as well as the necessity of its\ndevelopment and based on the Propose of establishing interested knowledge-base,\nenumerates several ways of personalized service, at last according to\nindividualized service, this paper proposes the model of \"learningoriented\nindividual digital library\" and prospects the trends of digital library."
},{
    "category": "cs.DL", 
    "doi": "10.1108/LHT-12-20112-0135", 
    "link": "http://arxiv.org/pdf/1402.6317v1", 
    "title": "Journal topic citation potential and between-field comparisons: The   topic normalized impact factor", 
    "arxiv-id": "1402.6317v1", 
    "author": "Rafael Suarez-Vega", 
    "publish": "2014-02-25T13:11:52Z", 
    "summary": "The journal impact factor is not comparable among fields of science and\nsocial science because of systematic differences in publication and citation\nbehaviour across disciplines. In this work, a source normalization of the\njournal impact factor is proposed. We use the aggregate impact factor of the\nciting journals as a measure of the citation potential in the journal topic,\nand we employ this citation potential in the normalization of the journal\nimpact factor to make it comparable between scientific fields. An empirical\napplication comparing some impact indicators with our topic normalized impact\nfactor in a set of 224 journals from four different fields shows that our\nnormalization, using the citation potential in the journal topic, reduces the\nbetween-group variance with respect to the within-group variance in a higher\nproportion than the rest of indicators analysed. The effect of journal\nself-citations over the normalization process is also studied."
},{
    "category": "cs.DL", 
    "doi": "10.1108/LHT-12-20112-0135", 
    "link": "http://arxiv.org/pdf/1404.0462v2", 
    "title": "The European Union, China, and the United States in the Top-1% and   Top-10% Layers of Most-Frequently-Cited Publications: Competition and   Collaborations", 
    "arxiv-id": "1404.0462v2", 
    "author": "Lutz Bornmann", 
    "publish": "2014-04-02T05:11:29Z", 
    "summary": "The percentages of shares of world publications of the European Union and its\nmember states, China, and the United States have been represented differently\nas a result of using different databases. An analytical variant of the\nWeb-of-Science (of Thomson Reuters) enables us to study the dynamics in the\nworld publication system in terms of the field-normalized top-1% and top-10%\nmost-frequently-cited publications. Comparing the EU28, USA, and China at the\nglobal level shows a top-level dynamics that is different from the analysis in\nterms of shares of publications: the United States remains far more productive\nin the top-1% of all papers; China drops out of the competition for elite\nstatus; and the EU28 increased its share among the top-cited papers from\n2000-2010. Some of the EU28 member states overtook the U.S. during this decade,\nbut a clear divide remains between EU15 (Western Europe) and the Accession\nCountries. Network analysis shows that internationally co-authored top-1%\npublications perform far above expectation and also above top-10% ones. In\n2005, China was embedded in this top-layer of internationally co-authored\npublications. These publications often involve more than a single European\nnation."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-014-1264-0", 
    "link": "http://arxiv.org/pdf/1404.1301v1", 
    "title": "How well developed are altmetrics? A cross-disciplinary analysis of the   presence of 'alternative metrics' in scientific publications", 
    "arxiv-id": "1404.1301v1", 
    "author": "Paul Wouters", 
    "publish": "2014-02-21T10:01:48Z", 
    "summary": "In this paper an analysis of the presence and possibilities of altmetrics for\nbibliometric and performance analysis is carried out. Using the web based tool\nImpact Story, we collected metrics for 20,000 random publications from the Web\nof Science. We studied both the presence and distribution of altmetrics in the\nset of publications, across fields, document types and over publication years,\nas well as the extent to which altmetrics correlate with citation indicators.\nThe main result of the study is that the altmetrics source that provides the\nmost metrics is Mendeley, with metrics on readerships for 62.6% of all the\npublications studied, other sources only provide marginal information. In terms\nof relation with citations, a moderate spearman correlation (r=0.49) has been\nfound between Mendeley readership counts and citation indicators. Other\npossibilities and limitations of these indicators are discussed and future\nresearch lines are outlined."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-014-1264-0", 
    "link": "http://arxiv.org/pdf/1404.2505v3", 
    "title": "Aggregated journal-journal citation relations in Scopus and   Web-of-Science matched and compared in terms of networks, maps, and   interactive overlays", 
    "arxiv-id": "1404.2505v3", 
    "author": "Wouter de Nooy", 
    "publish": "2014-04-09T14:47:57Z", 
    "summary": "We compare the network of aggregated journal-journal citation relations\nprovided by the Journal Citation Reports (JCR) 2012 of the Science and Social\nScience Citation Indexes (SCI and SSCI) with similar data based on Scopus 2012.\nFirst, global maps were developed for the two sets separately; sets of\ndocuments can then be compared using overlays to both maps. Using fuzzy-string\nmatching and ISSN numbers, we were able to match 10,524 journal names between\nthe two sets; that is, 96.4% of the 10,936 journals contained in JCR or 51.2%\nof the 20,554 journals covered by Scopus. Network analysis was then pursued on\nthe set of journals shared between the two databases and the two sets of unique\njournals. Citations among the shared journals are more comprehensively covered\nin JCR than Scopus, so the network in JCR is denser and more connected than in\nScopus. The ranking of shared journals in terms of indegree (that is, numbers\nof citing journals) or total citations is similar in both databases overall\n(Spearman's \\r{ho} > 0.97), but some individual journals rank very differently.\nJournals that are unique to Scopus seem to be less important--they are citing\nshared journals rather than being cited by them--but the humanities are covered\nbetter in Scopus than in JCR."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-014-1264-0", 
    "link": "http://arxiv.org/pdf/1404.3720v1", 
    "title": "The substantive and practical significance of citation impact   differences between institutions: Guidelines for the analysis of percentiles   using effect sizes and confidence intervals", 
    "arxiv-id": "1404.3720v1", 
    "author": "Lutz Bornmann", 
    "publish": "2014-04-12T09:34:22Z", 
    "summary": "In our chapter we address the statistical analysis of percentiles: How should\nthe citation impact of institutions be compared? In educational and\npsychological testing, percentiles are already used widely as a standard to\nevaluate an individual's test scores - intelligence tests for example - by\ncomparing them with the percentiles of a calibrated sample. Percentiles, or\npercentile rank classes, are also a very suitable method for bibliometrics to\nnormalize citations of publications in terms of the subject category and the\npublication year and, unlike the mean-based indicators (the relative citation\nrates), percentiles are scarcely affected by skewed distributions of citations.\nThe percentile of a certain publication provides information about the citation\nimpact this publication has achieved in comparison to other similar\npublications in the same subject category and publication year. Analyses of\npercentiles, however, have not always been presented in the most effective and\nmeaningful way. New APA guidelines (American Psychological Association, 2010)\nsuggest a lesser emphasis on significance tests and a greater emphasis on the\nsubstantive and practical significance of findings. Drawing on work by Cumming\n(2012) we show how examinations of effect sizes (e.g. Cohen's d statistic) and\nconfidence intervals can lead to a clear understanding of citation impact\ndifferences."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-014-1264-0", 
    "link": "http://arxiv.org/pdf/1404.3721v2", 
    "title": "BRICS countries and scientific excellence: A bibliometric analysis of   most frequently-cited papers", 
    "arxiv-id": "1404.3721v2", 
    "author": "Loet Leydesdorff", 
    "publish": "2014-04-14T15:51:38Z", 
    "summary": "The BRICS countries (Brazil, Russia, India, and China, and South Africa) are\nnoted for their increasing participation in science and technology. The\ngovernments of these countries have been boosting their investments in research\nand development to become part of the group of nations doing research at a\nworld-class level. This study investigates the development of the BRICS\ncountries in the domain of top-cited papers (top 10% and 1% most frequently\ncited papers) between 1990 and 2010. To assess the extent to which these\ncountries have become important players on the top level, we compare the BRICS\ncountries with the top-performing countries worldwide. As the analyses of the\n(annual) growth rates show, with the exception of Russia, the BRICS countries\nhave increased their output in terms of most frequently-cited papers at a\nhigher rate than the top-cited countries worldwide. In a further step of\nanalysis for this study, we generate co-authorship networks among authors of\nhighly cited papers for four time points to view changes in BRICS participation\n(1995, 2000, 2005, and 2010). Here, the results show that all BRICS countries\nsucceeded in becoming part of this network, whereby the Chinese collaboration\nactivities focus on the USA."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-319-08434-3_17", 
    "link": "http://arxiv.org/pdf/1404.6179v1", 
    "title": "Mathoid: Robust, Scalable, Fast and Accessible Math Rendering for   Wikipedia", 
    "arxiv-id": "1404.6179v1", 
    "author": "Gabriel Wicke", 
    "publish": "2014-04-24T16:55:51Z", 
    "summary": "Wikipedia is the first address for scientists who want to recap basic\nmathematical and physical laws and concepts. Today, formulae in those pages are\ndisplayed as Portable Network Graphics images. Those images do not integrate\nwell into the text, can not be edited after copying, are inaccessible to screen\nreaders for people with special needs, do not support line breaks for small\nscreens and do not scale for high resolution devices. Mathoid improves this\nsituation and converts formulae specified by Wikipedia editors in a TeX-like\ninput format to MathML, with Scalable Vector Graphics images as a fallback\nsolution."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-319-08434-3_17", 
    "link": "http://arxiv.org/pdf/1404.6476v2", 
    "title": "Math Indexer and Searcher Web Interface: Towards Fulfillment of   Mathematicians' Information Needs", 
    "arxiv-id": "1404.6476v2", 
    "author": "Michal R\u016f\u017ei\u010dka", 
    "publish": "2014-04-25T16:27:51Z", 
    "summary": "We are designing and developing a web user interface for digital mathematics\nlibraries called WebMIaS. It allows queries to be expressed by mathematicians\nthrough a faceted search interface. Users can combine standard textual\nautocompleted keywords with keywords in the form of mathematical formulae in\nLaTeX or MathML formats. Formulae are shown rendered by the web browser\non-the-fly for users' feedback. We describe WebMIaS design principles and our\nexperiences deploying in the European Digital Mathematics Library (EuDML). We\nfurther describe the issues addressed by formulae canonicalization and by\nextending the MIaS indexing engine with Content MathML support."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-319-08434-3_30", 
    "link": "http://arxiv.org/pdf/1404.6519v2", 
    "title": "Digital Repository of Mathematical Formulae", 
    "arxiv-id": "1404.6519v2", 
    "author": "Janelle C. Williams", 
    "publish": "2014-04-25T19:52:31Z", 
    "summary": "The purpose of the NIST Digital Repository of Mathematical Formulae (DRMF) is\nto create a digital compendium of mathematical formulae for orthogonal\npolynomials and special functions (OPSF) and of associated mathematical data.\nThe DRMF addresses needs of working mathematicians, physicists and engineers:\nproviding a platform for publication and interaction with OPSF formulae on the\nweb. Using MediaWiki extensions and other existing technology (such as software\nand macro collections developed for the NIST Digital Library of Mathematical\nFunctions), the DRMF acts as an interactive web domain for OPSF formulae.\nWhereas Wikipedia and other web authoring tools manifest notions or\ndescriptions as first class objects, the DRMF does that with mathematical\nformulae. See http://gw32.iu.xsede.org/index.php/Main_Page."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-319-08434-3_30", 
    "link": "http://arxiv.org/pdf/1404.6545v2", 
    "title": "Recent Developments in China-U.S. Cooperation in Science", 
    "arxiv-id": "1404.6545v2", 
    "author": "Lutz Bornmann", 
    "publish": "2014-04-25T20:29:59Z", 
    "summary": "China's remarkable gains in science over the past 25 years have been well\ndocumented (e.g., Jin and Rousseau, 2005a; Zhou and Leydesdorff, 2006; Shelton\n& Foland, 2009) but it is less well known that China and the United States have\nbecome each other's top collaborating country. Science and technology has been\na primary vehicle for growing the bilateral relationship between China and the\nUnited States since the opening of relations between the two countries in the\nlate 1970s. During the 2000s, the scientific relationship between China and the\nUnited States--as measured in coauthored papers--showed significant growth.\nChinese scientists claim first authorship much more frequently than U.S.\ncounterparts by the end of the decade. The sustained rate of increase of\ncollaboration with one other country is unprecedented on the U.S. side. Even\ngrowth in relations with eastern European nations does not match the growth in\nthe relationship between China and the United States. Both countries can\nbenefit from the relationship, but for the U.S., greater benefit would come\nfrom a more targeted strategy."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-319-08434-3_30", 
    "link": "http://arxiv.org/pdf/1404.6547v1", 
    "title": "E-books and Graphics with LaTeXML", 
    "arxiv-id": "1404.6547v1", 
    "author": "Silviu Oprea", 
    "publish": "2014-04-25T20:32:02Z", 
    "summary": "Marked by the highlights of native generation of EPUB E-books and TikZ\nsupport for creating SVG images, we present an annual report of LaTeXML\ndevelopment in 2013. LaTeXML provides a reimplementation of the $\\TeX$ parser,\ngeared towards preserving macro semantics; it supports an array of output\nformats, notably HTML5, EPUB, XHTML and its own $\\LaTeX$-near XML. Other\nhighlights include enhancing performance when used inside high-throughput\nbuild-systems, via incorporating a native ZIP archive workflow, as well as a\nsimplified installation procedure that now allows to deploy LaTeXML as a cloud\nservice. To this end, we also introduce an official plugin-based scheme for\npublishing new features that go beyond the core scope of LaTeXML, such as web\nservices or unconventional post-processors. The software suite has now migrated\nto GitHub and we welcome forks and patches from the wider FLOSS community."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-319-08434-3_30", 
    "link": "http://arxiv.org/pdf/1404.6548v1", 
    "title": "NNexus Reloaded", 
    "arxiv-id": "1404.6548v1", 
    "author": "Joseph Corneli", 
    "publish": "2014-04-25T20:32:21Z", 
    "summary": "Interlinking knowledge is one of the cornerstones of online collaboration.\nWhile wiki systems typically rely on links supplied by authors, in the early\n2000s the mathematics encyclopedia at PlanetMath.org introduced a feature that\nprovides automatic linking for previously defined concepts. The NNexus software\nsuite was developed to support the necessary subtasks of concept indexing,\nconcept discovery and link-annotation. In this paper, we describe our recent\nreimplementation and revisioning of the NNexus system."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-319-08434-3_30", 
    "link": "http://arxiv.org/pdf/1404.6549v1", 
    "title": "LaTeXML 2012 - A Year of LaTeXML", 
    "arxiv-id": "1404.6549v1", 
    "author": "Bruce R. Miller", 
    "publish": "2014-04-25T20:32:46Z", 
    "summary": "LaTeXML, a $\\TeX$ to XML converter, is being used in a wide range of MKM\napplications. In this paper, we present a progress report for the 2012 calendar\nyear. Noteworthy enhancements include: increased coverage such as Wikipedia\nsyntax; enhanced capabilities such as embeddable JavaScript and CSS resources\nand RDFa support; a web service for remote processing via web-sockets; along\nwith general accuracy and reliability improvements."
},{
    "category": "cs.DL", 
    "doi": "10.1108/OIR-07-2014-0169", 
    "link": "http://arxiv.org/pdf/1404.7045v3", 
    "title": "Empirical Evidences in Citation-Based Search Engines: Is Microsoft   Academic Search dead?", 
    "arxiv-id": "1404.7045v3", 
    "author": "Emilio Delgado Lopez-Cozar", 
    "publish": "2014-04-28T16:28:21Z", 
    "summary": "The goal of this working paper is to summarize the main empirical evidences\nprovided by the scientific community as regards the comparison between the two\nmain citation based academic search engines: Google Scholar and Microsoft\nAcademic Search, paying special attention to the following issues: coverage,\ncorrelations between journal rankings, and usage of these academic search\nengines. Additionally, selfelaborated data is offered, which are intended to\nprovide current evidence about the popularity of these tools on the Web, by\nmeasuring the number of rich files PDF, PPT and DOC in which these tools are\nmentioned, the amount of external links that both products receive, and the\nsearch queries frequency from Google Trends. The poor results obtained by MAS\nled us to an unexpected and unnoticed discovery: Microsoft Academic Search is\noutdated since 2013. Therefore, the second part of the working paper aims at\nadvancing some data demonstrating this lack of update. For this purpose we\ngathered the number of total records indexed by Microsoft Academic Search since\n2000. The data shows an abrupt drop in the number of documents indexed from\n2,346,228 in 2010 to 8,147 in 2013 and 802 in 2014. This decrease is offered\naccording to 15 thematic areas as well. In view of these problems it seems\nlogical not only that Microsoft Academic Searchwas poorly used to search for\narticles by academics and students, who mostly use Google or Google Scholar,\nbut virtually ignored by bibliometricians"
},{
    "category": "cs.DL", 
    "doi": "10.1108/OIR-07-2014-0169", 
    "link": "http://arxiv.org/pdf/1404.7447v1", 
    "title": "An Introduction to the Patstat Database with Example Queries", 
    "arxiv-id": "1404.7447v1", 
    "author": "Geert Boedt", 
    "publish": "2014-04-02T05:34:53Z", 
    "summary": "This paper provides an introduction to the Patstat patent database. It offers\nguided examples of ten popular queries that are relevant for research purposes\nand that cover the most important data tables. It is targeted at academic\nresearchers and practitioners willing to learn the basics of the database."
},{
    "category": "cs.DL", 
    "doi": "10.1108/OIR-07-2014-0169", 
    "link": "http://arxiv.org/pdf/1404.7753v4", 
    "title": "Aca 2.0: Questions and Answers", 
    "arxiv-id": "1404.7753v4", 
    "author": "Rob Jelier", 
    "publish": "2014-04-30T15:03:02Z", 
    "summary": "\"Academia 2.0\" is a proposal to organize scientific publishing around true\npeer-to-peer distributed dissemination channels and eliminate the traditional\nrole of the academic publisher. This model will be first presented at the 2014\nworkshop on Reproducible Research Methodologies and New Publication Models in\nComputer Engineering (TRUST'14) in the form of a high-level overview, so as to\nstimulate discussion and gather feedback on its merits and feasibility. This\nreport complements the 6-page introductory article presented at TRUST, by\ndetailing the review processes, some use scenarios and answering the reviewer's\ncomments in detail."
},{
    "category": "cs.DL", 
    "doi": "10.1108/OIR-07-2014-0169", 
    "link": "http://arxiv.org/pdf/1406.0216v1", 
    "title": "LODE: Linking Digital Humanities Content to the Web of Data", 
    "arxiv-id": "1406.0216v1", 
    "author": "Mathias Niepert", 
    "publish": "2014-06-01T23:37:39Z", 
    "summary": "Numerous digital humanities projects maintain their data collections in the\nform of text, images, and metadata. While data may be stored in many formats,\nfrom plain text to XML to relational databases, the use of the resource\ndescription framework (RDF) as a standardized representation has gained\nconsiderable traction during the last five years. Almost every digital\nhumanities meeting has at least one session concerned with the topic of digital\nhumanities, RDF, and linked data. While most existing work in linked data has\nfocused on improving algorithms for entity matching, the aim of the\nLinkedHumanities project is to build digital humanities tools that work \"out of\nthe box,\" enabling their use by humanities scholars, computer scientists,\nlibrarians, and information scientists alike. With this paper, we report on the\nLinked Open Data Enhancer (LODE) framework developed as part of the\nLinkedHumanities project. With LODE we support non-technical users to enrich a\nlocal RDF repository with high-quality data from the Linked Open Data cloud.\nLODE links and enhances the local RDF repository without compromising the\nquality of the data. In particular, LODE supports the user in the enhancement\nand linking process by providing intuitive user-interfaces and by suggesting\nhigh-quality linking candidates using tailored matching algorithms. We hope\nthat the LODE framework will be useful to digital humanities scholars\ncomplementing other digital humanities tools."
},{
    "category": "cs.DL", 
    "doi": "10.1108/OIR-07-2014-0169", 
    "link": "http://arxiv.org/pdf/1406.2793v1", 
    "title": "Towards a Frontier of Spatial Scientometric Studies", 
    "arxiv-id": "1406.2793v1", 
    "author": "Song Gao", 
    "publish": "2014-06-11T06:51:31Z", 
    "summary": "The research field of spatial scientometrics is dedicated to measuring and\nanalyzing science with spatial components (e.g., location, place, mapping).\nBecause of the dynamic nature of this field, researchers from multidisciplinary\ndomains constantly contribute qualitative, quantitative and computational\napproaches and technologies into scientometric analysis. This article aims to\ngiving a brief overview about this field by analyzing the publications in\n(spatial) scientometrics collected from the Scopus database and introduces\nrecent frontier researches which integrate advanced spatial analysis and\ngeovisualization with Semantic Web technologies."
},{
    "category": "cs.DL", 
    "doi": "10.1108/OIR-07-2014-0169", 
    "link": "http://arxiv.org/pdf/1406.2886v1", 
    "title": "The role of handbooks in knowledge creation and diffusion: A case of   science and technology studies", 
    "arxiv-id": "1406.2886v1", 
    "author": "Ying Ding", 
    "publish": "2014-06-11T12:36:07Z", 
    "summary": "Genre is considered to be an important element in scholarly communication and\nin the practice of scientific disciplines. However, scientometric studies have\ntypically focused on a single genre, the journal article. The goal of this\nstudy is to understand the role that handbooks play in knowledge creation and\ndiffusion and their relationship with the genre of journal articles,\nparticularly in highly interdisciplinary and emergent social science and\nhumanities disciplines. To shed light on these questions we focused on\nhandbooks and journal articles published over the last four decades belonging\nto the research area of Science and Technology Studies (STS), broadly defined.\nTo get a detailed picture we used the full-text of five handbooks (500,000\nwords) and a well-defined set of 11,700 STS articles. We confirmed the\nmethodological split of STS into qualitative and quantitative (scientometric)\napproaches. Even when the two traditions explore similar topics (e.g., science\nand gender) they approach them from different starting points. The change in\ncognitive foci in both handbooks and articles partially reflects the changing\ntrends in STS research, often driven by technology. Using text similarity\nmeasures we found that, in the case of STS, handbooks play no special role in\neither focusing the research efforts or marking their decline. In general, they\ndo not represent the summaries of research directions that have emerged since\nthe previous edition of the handbook."
},{
    "category": "cs.DL", 
    "doi": "10.1108/OIR-07-2014-0169", 
    "link": "http://arxiv.org/pdf/1406.3876v1", 
    "title": "Bringing Web Time Travel to MediaWiki: An Assessment of the Memento   MediaWiki Extension", 
    "arxiv-id": "1406.3876v1", 
    "author": "Herbert Van de Sompel", 
    "publish": "2014-06-16T01:01:54Z", 
    "summary": "We have implemented the Memento MediaWiki Extension Version 2.0, which brings\nthe Memento Protocol to MediaWiki, used by Wikipedia and the Wikimedia\nFoundation. Test results show that the extension has a negligible impact on\nperformance. Two 302 status code datetime negotiation patterns, as defined by\nMemento, have been examined for the extension: Pattern 1.1, which requires 2\nrequests, versus Pattern 2.1, which requires 3 requests. Our test results and\nmathematical review find that, contrary to intuition, Pattern 2.1 performs\nbetter than Pattern 1.1 due to idiosyncrasies in MediaWiki. In addition to\nimplementing Memento, Version 2.0 allows administrators to choose the optional\n200-style datetime negotiation Pattern 1.2 instead of Pattern 2.1. It also\npermits administrators the ability to have the Memento MediaWiki Extension\nreturn full HTTP 400 and 500 status codes rather than using standard MediaWiki\nerror pages. Finally, version 2.0 permits administrators to turn off\nrecommended Memento headers if desired. Seeing as much of our work focuses on\nproducing the correct revision of a wiki page in response to a user's datetime\ninput, we also examine the problem of finding the correct revisions of the\nembedded resources, including images, stylesheets, and JavaScript; identifying\nthe issues and discussing whether or not MediaWiki must be changed to support\nthis functionality."
},{
    "category": "cs.DL", 
    "doi": "10.1108/OIR-07-2014-0169", 
    "link": "http://arxiv.org/pdf/1406.4020v1", 
    "title": "Community-driven reviewing and validation of publications", 
    "arxiv-id": "1406.4020v1", 
    "author": "Christophe Dubach", 
    "publish": "2014-06-16T14:08:19Z", 
    "summary": "In this report, we share our practical experience on crowdsourcing evaluation\nof research artifacts and reviewing of publications since 2008. We also briefly\ndiscuss encountered problems including reproducibility of experimental results\nand possible solutions."
},{
    "category": "cs.DL", 
    "doi": "10.1108/OIR-07-2014-0169", 
    "link": "http://arxiv.org/pdf/1406.4161v4", 
    "title": "Matching MEDLINE/PubMed Data with Web of Science (WoS): A Routine in R   language", 
    "arxiv-id": "1406.4161v4", 
    "author": "Loet Leydesdorff", 
    "publish": "2014-06-16T20:27:50Z", 
    "summary": "We present a novel routine, namely medlineR, based on R-language, that\nenables the user to match data from MEDLINE/PubMed with records indexed in the\nISI Web of Science (WoS) database. The matching allows exploiting the rich and\ncontrolled vocabulary of Medical Subject Headings (MeSH) of MEDLINE/PubMed with\nadditional fields of WoS. The integration provides data (e.g. citation data,\nlist of cited reference, full list of the addresses of authors' host\norganisations, WoS subject categories) to perform a variety of scientometric\nanalyses. This brief communication describes medlineR, the methodology on which\nit relies, and the steps the user should follow to perform the matching across\nthe two databases. In order to specify the differences from Leydesdorff and\nOpthof (2013), we conclude the brief communication by testing the routine on\nthe case of the \"Burgada Syndrome\"."
},{
    "category": "cs.DL", 
    "doi": "10.1108/OIR-07-2014-0169", 
    "link": "http://arxiv.org/pdf/1406.4331v1", 
    "title": "The dark side of Open Access in Google and Google Scholar: the case of   Latin-American repositories", 
    "arxiv-id": "1406.4331v1", 
    "author": "Emilio Delgado Lopez-Cozar", 
    "publish": "2014-06-17T11:45:30Z", 
    "summary": "Since repositories are a key tool in making scholarly knowledge open access,\ndetermining their presence and impact on the Web is essential, particularly in\nGoogle (search engine par excellence) and Google Scholar (a tool increasingly\nused by researchers to search for academic information). The few studies\nconducted so far have been limited to very specific geographic areas (USA),\nwhich makes it necessary to find out what is happening in other regions that\nare not part of mainstream academia, and where repositories play a decisive\nrole in the visibility of scholarly production. The main objective of this\nstudy is to ascertain the presence and visibility of Latin American\nrepositories in Google and Google Scholar through the application of page count\nand visibility indicators. For a sample of 137 repositories, the results\nindicate that the indexing ratio is low in Google, and virtually nonexistent in\nGoogle Scholar; they also indicate a complete lack of correspondence between\nthe repository records and the data produced by these two search tools. These\nresults are mainly attributable to limitations arising from the use of\ndescription schemas that are incompatible with Google Scholar (repository\ndesign) and the reliability of web indicators (search engines). We conclude\nthat neither Google nor Google Scholar accurately represent the actual size of\nopen access content published by Latin American repositories; this may indicate\na non-indexed, hidden side to open access, which could be limiting the\ndissemination and consumption of open access scholarly literature."
},{
    "category": "cs.DL", 
    "doi": "10.1108/OIR-07-2014-0169", 
    "link": "http://arxiv.org/pdf/1406.5520v1", 
    "title": "The Multidimensional Assessment of Scholarly Research Impact", 
    "arxiv-id": "1406.5520v1", 
    "author": "Gali Halevi", 
    "publish": "2014-06-20T20:13:52Z", 
    "summary": "This article introduces the Multidimensional Research Assessment Matrix of\nscientific output. Its base notion holds that the choice of metrics to be\napplied in a research assessment process depends upon the unit of assessment,\nthe research dimension to be assessed, and the purposes and policy context of\nthe assessment. An indicator may by highly useful within one assessment\nprocess, but less so in another. For instance, publication counts are useful\ntools to help discriminating between those staff members who are research\nactive, and those who are not, but are of little value if active scientists are\nto be compared one another according to their research performance. This paper\ngives a systematic account of the potential usefulness and limitations of a set\nof 10 important metrics including altmetrics, applied at the level of\nindividual articles, individual researchers, research groups and institutions.\nIt presents a typology of research impact dimensions, and indicates which\nmetrics are the most appropriate to measure each dimension. It introduces the\nconcept of a meta-analysis of the units under assessment in which metrics are\nnot used as tools to evaluate individual units, but to reach policy inferences\nregarding the objectives and general setup of an assessment process."
},{
    "category": "cs.DL", 
    "doi": "10.3145/epi.2014.jul.03", 
    "link": "http://arxiv.org/pdf/1408.0135v1", 
    "title": "New data, new possibilities: Exploring the insides of Altmetric.com", 
    "arxiv-id": "1408.0135v1", 
    "author": "Rodrigo Costas", 
    "publish": "2014-08-01T11:27:47Z", 
    "summary": "This paper analyzes Altmetric.com, one of the most important altmetric data\nproviders currently used. We have analyzed a set of publications with DOI\nnumber indexed in the Web of Science during the period 2011-2013 and collected\ntheir data with the Altmetric API. 19% of the original set of papers was\nretrieved from Altmetric.com including some altmetric data. We identified 16\ndifferent social media sources from which Altmetric.com retrieves data. However\nfive of them cover 95.5% of the total set. Twitter (87.1%) and Mendeley (64.8%)\nhave the highest coverage. We conclude that Altmetric.com is a transparent,\nrich and accurate tool for altmetric data. Nevertheless, there are still\npotential limitations on its exhaustiveness as well as on the selection of\nsocial media sources that need further research."
},{
    "category": "cs.DL", 
    "doi": "10.3145/epi.2014.jul.03", 
    "link": "http://arxiv.org/pdf/1408.1713v1", 
    "title": "The Digital Public Library of America Ingestion Ecosystem: Lessons   Learned After One Year of Large-Scale Collaborative Metadata Aggregation", 
    "arxiv-id": "1408.1713v1", 
    "author": "Amy Rudersdorf", 
    "publish": "2014-08-07T21:10:09Z", 
    "summary": "The Digital Public Library of America (DPLA) aggregates metadata for cultural\nheritage materials from 20 direct partners, or Hubs, across the United States.\nWhile the initial build-out of the DPLA's infrastructure used a lightweight\ningestion system that was ultimately pushed into production, a year's\nexperience has allowed DPLA and its partners to identify limitations to that\nsystem, the quality and scalability of metadata remediation and enhancement\npossible, and areas for collaboration and leadership across the partnership.\nAlthough improved infrastructure is needed to support aggregation at this scale\nand complexity, ultimately DPLA needs to balance responsibilities across the\npartnership and establish a strong community that shares ownership of the\naggregation process."
},{
    "category": "cs.DL", 
    "doi": "10.1109/TVCG.2016.2598827", 
    "link": "http://arxiv.org/pdf/1408.3297v1", 
    "title": "Toward a deeper understanding of Visualization through keyword analysis", 
    "arxiv-id": "1408.3297v1", 
    "author": "Torsten M\u00f6ller", 
    "publish": "2014-08-13T07:21:04Z", 
    "summary": "We present the results of a comprehensive analysis of visualization paper\nkeywords supplied for 4366 papers submitted to five main visualization\nconferences. We describe main keywords, topic areas, and 10-year historic\ntrends from two datasets: (1) the standardized PCS taxonomy keywords in use for\npaper submissions for IEEE InfoVis, IEEE Vis-SciVis, IEEE VAST, EuroVis, and\nIEEE PacificVis since 2009 and (2) the author-chosen keywords for papers\npublished in the IEEE Visualization conference series (now called IEEE VIS)\nsince 2004. Our analysis of research topics in visualization can serve as a\nstarting point to (a) help create a common vocabulary to improve communication\namong different visualization sub-groups, (b) facilitate the process of\nunderstanding differences and commonalities of the various research sub-fields\nin visualization, (c) provide an understanding of emerging new research trends,\n(d) facilitate the crucial step of finding the right reviewers for research\nsubmissions, and (e) it can eventually lead to a comprehensive taxonomy of\nvisualization research. One additional tangible outcome of our work is an\napplication that allows visualization researchers to easily browse the 2600+\nkeywords used for IEEE VIS papers during the past 10 years, aiming at more\ninformed and, hence, more effective keyword selections for future visualization\npublications."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-014-1423-3", 
    "link": "http://arxiv.org/pdf/1408.5700v1", 
    "title": "A review of the characteristics of 108 author-level bibliometric   indicators", 
    "arxiv-id": "1408.5700v1", 
    "author": "Birger Larsen", 
    "publish": "2014-08-25T09:36:08Z", 
    "summary": "An increasing demand for bibliometric assessment of individuals has led to a\ngrowth of new bibliometric indicators as well as new variants or combinations\nof established ones. The aim of this review is to contribute with objective\nfacts about the usefulness of bibliometric indicators of the effects of\npublication activity at the individual level. This paper reviews 108 indicators\nthat can potentially be used to measure performance on the individual author\nlevel, and examines the complexity of their calculations in relation to what\nthey are supposed to reflect and ease of end-user application."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-014-1423-3", 
    "link": "http://arxiv.org/pdf/1408.5893v1", 
    "title": "On the causes of subject-specific citation rates in Web of Science", 
    "arxiv-id": "1408.5893v1", 
    "author": "Lutz Bornmann", 
    "publish": "2014-08-25T12:28:59Z", 
    "summary": "It is well known in bibliometrics that the average number of citations per\npaper differs greatly between the various disciplines. The differing citation\nculture (in particular the different average number of references per paper and\nthereby the different probability of being cited) is widely seen as the cause\nof this variation. Based on all Web of Science (WoS) records published in 1990,\n1995, 2000, 2005, and 2010 we demonstrate that almost all disciplines show\nsimilar numbers of references in the appendices of their papers. Our results\nsuggest that the average citation rate is far more influenced by the extent to\nwhich the papers (cited as references) are included in WoS as linked database\nrecords. For example, the comparatively low citation rates in the humanities\nare not at all the result of a lower average number of references per paper but\nare caused by the low fraction of linked references which refer to papers\npublished in the core journals covered by WoS."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-014-1423-3", 
    "link": "http://arxiv.org/pdf/1408.6438v1", 
    "title": "A Note on the Ranking of Saudi Arabian Universities based on   highlycited.com", 
    "arxiv-id": "1408.6438v1", 
    "author": "Eisa Alanazi", 
    "publish": "2014-08-25T00:45:19Z", 
    "summary": "Recently, Thomson Reuters has published its 2014 list of highly cited\nresearchers (HCRs)[1]. Initial studies over the list [2] suggested that some\nuniversities (for instance, King Abdulaziz University in Saudi Arabia) may have\nbeen manipulating its world ranking by contracting with highly cited\nresearchers. In this work, we analyse the ranking of other Saudi universities\nbased solely on the list. Our analysis suggests that other universities in\nSaudi Arabia do not follow the steps of King Abdulaziz University when it comes\nto contracting with HCRs."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.23421", 
    "link": "http://arxiv.org/pdf/1409.0129v1", 
    "title": "Costly Collaborations: The Impact of Scientific Fraud on Co-authors'   Careers", 
    "arxiv-id": "1409.0129v1", 
    "author": "Vincent Lariviere", 
    "publish": "2014-08-30T16:23:07Z", 
    "summary": "Over the last few years, several major scientific fraud cases have shocked\nthe scientific community. The number of retractions each year has also\nincreased tremendously, especially in the biomedical field, and scientific\nmisconduct accounts for approximately more than half of those retractions. It\nis assumed that co-authors of retracted papers are affected by their\ncolleagues' misconduct, and the aim of this study is to provide empirical\nevidence of the effect of retractions in biomedical research on co-authors'\nresearch careers. Using data from the Web of Science (WOS), we measured the\nproductivity, impact and collaboration of 1,123 co-authors of 293 retracted\narticles for a period of five years before and after the retraction. We found\nclear evidence that collaborators do suffer consequences of their colleagues'\nmisconduct, and that a retraction for fraud has higher consequences than a\nretraction for error. Our results also suggest that the extent of these\nconsequences is closely linked with the ranking of co-authors on the retracted\npaper, being felt most strongly by first authors, followed by the last authors,\nwhile the impact is less important for middle authors."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2014.12.003", 
    "link": "http://arxiv.org/pdf/1409.0348v2", 
    "title": "Visualization of Co-Readership Patterns from an Online Reference   Management System", 
    "arxiv-id": "1409.0348v2", 
    "author": "Stefanie Lindstaedt", 
    "publish": "2014-09-01T09:56:18Z", 
    "summary": "In this paper, we analyze the adequacy and applicability of readership\nstatistics recorded in social reference management systems for creating\nknowledge domain visualizations. First, we investigate the distribution of\nsubject areas in user libraries of educational technology researchers on\nMendeley. The results show that around 69% of the publications in an average\nuser library can be attributed to a single subject area. Then, we use\nco-readership patterns to map the field of educational technology. The\nresulting visualization prototype, based on the most read publications in this\nfield on Mendeley, reveals 13 topic areas of educational technology research.\nThe visualization is a recent representation of the field: 80% of the\npublications included were published within ten years of data collection. The\ncharacteristics of the readers, however, introduce certain biases to the\nvisualization. Knowledge domain visualizations based on readership statistics\nare therefore multifaceted and timely, but it is important that the\ncharacteristics of the underlying sample are made transparent."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2014.12.003", 
    "link": "http://arxiv.org/pdf/1409.0753v1", 
    "title": "How many citations are there in the Data Citation Index?", 
    "arxiv-id": "1409.0753v1", 
    "author": "Nicolas Robinson-Garc\u00eda", 
    "publish": "2014-09-02T15:24:34Z", 
    "summary": "Descriptive analysis on the citation distribution of the Thomson Reuters'\nData Citation Index by publication type and four broad areas: Science,\nEngineering & Technology, Humanities & Arts and Social Sciences."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2014.12.003", 
    "link": "http://arxiv.org/pdf/1409.1911v1", 
    "title": "Revealing Comparative Advantages in the Backbone of Science", 
    "arxiv-id": "1409.1911v1", 
    "author": "Marcelo Mendoza", 
    "publish": "2014-09-05T19:47:37Z", 
    "summary": "Mapping Science across countries is a challenging task in the field of\nScientometrics. A number of efforts trying to cope with this task has been\ndiscussed in the state of the art, addressing this challenge by processing\ncollections of scientific digital libraries and visualizing author-based\nmeasures (for instance, the h-index) or document-based measures (for instance,\nthe averaged number of citations per document). A major drawback of these\napproaches is related to the presence of bias. The bigger the country, the\nhigher the measure value. We explore the use of an econometric index to tackle\nthis limitation, known as the Revealed Comparative Advantage measure (RCA).\nUsing RCA, the diversity and ubiquity of each field of knowledge is mapped\nacross countries. Then, a RCA-based proximity function is explored to visualize\ncitation and h-index ubiquity. Science maps relating 27 knowledge areas and 237\ncountries are introduced using data crawled from Scimago that ranges from 1996\nto 2011. Our results shows that the proposal is feasible and can be extended to\nellaborate a global scientific production characterization."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2014.12.003", 
    "link": "http://arxiv.org/pdf/1409.2365v1", 
    "title": "Investigation of Partition Cells as a Structural Basis Suitable for   Assessments of Individual Scientists", 
    "arxiv-id": "1409.2365v1", 
    "author": "Nadine Rons", 
    "publish": "2014-09-08T14:34:06Z", 
    "summary": "Individual, excellent scientists have become increasingly important in the\nresearch funding landscape. Accurate bibliometric measures of an individual's\nperformance could help identify excellent scientists, but still present a\nchallenge. One crucial aspect in this respect is an adequate delineation of the\nsets of publications that determine the reference values to which a scientist's\npublication record and its citation impact should be compared. The structure of\npartition cells formed by intersecting fixed subject categories in a database\nhas been proposed to approximate a scientist's specialty more closely than can\nbe done with the broader subject categories. This paper investigates this cell\nstructure's suitability as an underlying basis for methodologies to assess\nindividual scientists, from two perspectives: (1) Proximity to the actual\nstructure of publication records of individual scientists: The distribution and\nconcentration of publications over the highly fragmented structure of partition\ncells are examined for a sample of ERC grantees; (2) Proximity to customary\nlevels of accuracy: Differences in commonly used reference values (mean\nexpected number of citations per publication, and threshold number of citations\nfor highly cited publications) between adjacent partition cells are compared to\ndifferences in two other dimensions: successive publication years and\nsuccessive citation window lengths. Findings from both perspectives are in\nsupport of partition cells rather than the larger subject categories as a\njournal based structure on which to construct and apply methodologies for the\nassessment of highly specialized publication records such as those of\nindividual scientists."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2014.12.003", 
    "link": "http://arxiv.org/pdf/1409.2863v2", 
    "title": "Usefulness of altmetrics for measuring the broader impact of research: A   case study using data from PLOS (altmetrics) and F1000Prime (paper tags)", 
    "arxiv-id": "1409.2863v2", 
    "author": "Lutz Bornmann", 
    "publish": "2014-09-09T08:05:37Z", 
    "summary": "Purpose: Whereas citation counts allow the measurement of the impact of\nresearch on research itself, an important role in the measurement of the impact\nof research on other parts of society is ascribed to altmetrics. The present\ncase study investigates the usefulness of altmetrics for measuring the broader\nimpact of research. Methods: This case study is essentially based on a dataset\nwith papers obtained from F1000. The dataset was augmented with altmetrics\n(such as Twitter counts) which were provided by PLOS (the Public Library of\nScience). In total, the case study covers a total of 1,082 papers. Findings:\nThe F1000 dataset contains tags on papers which were assigned intellectually by\nexperts and which can characterise a paper. The most interesting tag for\naltmetric research is \"good for teaching\". This tag is assigned to papers which\ncould be of interest to a wider circle of readers than the peers in a\nspecialist area. Particularly on Facebook and Twitter, one could expect papers\nwith this tag to be mentioned more often than those without this tag. With\nrespect to the \"good for teaching\" tag, the results from regression models were\nable to confirm these expectations: Papers with this tag show significantly\nhigher Facebook and Twitter counts than papers without this tag. This\nassociation could not be seen with Mendeley or Figshare counts (that is with\ncounts from platforms which are chiefly of interest in a scientific context).\nConclusions: The results of the current study indicate that Facebook and\nTwitter, but not Figshare or Mendeley, can provide indications of papers which\nare of interest to a broader circle of readers (and not only for the peers in a\nspecialist area), and seem therefore be useful for societal impact measurement."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2014.12.003", 
    "link": "http://arxiv.org/pdf/1409.3495v1", 
    "title": "The impact of a few: The effect of alternative formulas for recruiting   talent in a non-competitive system", 
    "arxiv-id": "1409.3495v1", 
    "author": "Clara Calero-Medina", 
    "publish": "2014-09-11T16:33:57Z", 
    "summary": "This paper analyzes the effect of the Catalan programme ICREA for the\nselection of talented researchers on the percentage of highly cited papers of\nCatalan universities"
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2014.12.003", 
    "link": "http://arxiv.org/pdf/1409.3920v1", 
    "title": "The 7 Habits of Highly Effective Research Communicators", 
    "arxiv-id": "1409.3920v1", 
    "author": "Anup Kumar Das", 
    "publish": "2014-09-13T07:08:21Z", 
    "summary": "The emergence of Web 2.0 and simultaneously Library 2.0 platforms has helped\nthe library and information professionals to outreach to new audiences beyond\ntheir physical boundaries. In a globalized society, information becomes very\nuseful resource for socio-economic empowerment of marginalized communities,\neconomic prosperity of common citizens, and knowledge enrichment of liberated\nminds. Scholarly information becomes both developmental and functional for\nresearchers working towards advancement of knowledge. We must recognize a relay\nof information flow and information ecology while pursuing scholarly research.\nPublished scholarly literatures we consult that help us in creation of new\nknowledge. Similarly, our published scholarly works should be outreached to\nfuture researchers for regeneration of next dimension of knowledge.\nFortunately, present day research communicators have many freely available\npersonalized digital tools to outreach to globalized research audiences having\nsimilar research interests. These tools and techniques, already adopted by many\nresearchers in different subject areas across the world, should be\nenthusiastically utilized by LIS researchers in South Asia for global\ndissemination of their scholarly research works. This newly found enthusiasm\nwill soon become integral part of the positive habits and cultural practices of\nresearch communicators in LIS domain."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2014.12.003", 
    "link": "http://arxiv.org/pdf/1409.4898v1", 
    "title": "The Generation of Large Networks from Web-of-Science Data", 
    "arxiv-id": "1409.4898v1", 
    "author": "Lutz Bornmann", 
    "publish": "2014-09-17T08:22:32Z", 
    "summary": "During the 1990s, one of us developed a series of freeware routines\n(http://www.leydesdorff.net/indicators) that enable the user to organize\ndownloads from the Web-of-Science (Thomson Reuters) into a relational database,\nand then to export matrices for further analysis in various formats (for\nexample, for co-author analysis). The basic format of the matrices displays\neach document as a case in a row that can be attributed different variables in\nthe columns. One limitation to this approach was hitherto that relational\ndatabases typically have an upper limit for the number of variables, such as\n256 or 1024. In this brief communication, we report on a way to circumvent this\nlimitation by using txt2Pajek.exe, available as freeware from\nhttp://www.pfeffer.at/txt2pajek/."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2014.10.001", 
    "link": "http://arxiv.org/pdf/1409.4899v1", 
    "title": "Is the new citation-rank approach P100' in bibliometrics really new?", 
    "arxiv-id": "1409.4899v1", 
    "author": "Michael Schreiber", 
    "publish": "2014-09-17T08:22:32Z", 
    "summary": "The percentile-based rating scale P100 describes the citation impact in terms\nof the distribution of unique citation values. This approach has recently been\nrefined by considering also the frequency of papers with the same citation\ncounts. Here I compare the resulting P100' with P100 for an empirical dataset\nand a simple fictitious model dataset. It is shown that P100' is not much\ndifferent from standard percentile-based ratings in terms of citation\nfrequencies. A new indicator P100'' is introduced."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2014.10.001", 
    "link": "http://arxiv.org/pdf/1409.6964v1", 
    "title": "Knowledge discovery via multidimensional science maps: the case of the   Species Problem", 
    "arxiv-id": "1409.6964v1", 
    "author": "Sandor Soos", 
    "publish": "2014-09-24T14:05:26Z", 
    "summary": "Science mapping (SM), the study of the organization and development of\nscience and technology, is a rapidly developing field within information\nscience. The volume of available data allows this methodology to empirically\naddress such issues as the historical development of topics, discourses, fields\nor the entire science system. Based on the pool of related methods, we are\nproposing an integration of various maps to obtain a novel kind of science map\nwe call multidimensional. The basic idea behind is to combine the most\ninformative relations available from various maps based on different\nbibliometric indicators, in order to produce a rich structrue for the study of\nknowledge dynamics, with special emphasis on causal-historical connections. As\na proof of concept, we deploy the proposed framework in an extensive case study\non a historical topic from the life sciences, namely, the debate on the species\nconcept in biosystematics."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2014.10.001", 
    "link": "http://arxiv.org/pdf/1501.01076v3", 
    "title": "The Effects of Research Level and Article Type on the Differences   between Citation Metrics and F1000 Recommendations", 
    "arxiv-id": "1501.01076v3", 
    "author": "Yishan Wu", 
    "publish": "2015-01-06T04:28:10Z", 
    "summary": "F1000 recommendations have been validated as a potential data source for\nresearch evaluation, but reasons for differences between F1000 Article Factor\n(FFa scores) and citations remain to be explored. By linking 28254 publications\nin F1000 to citations in Scopus, we investigated the effect of research level\nand article type on the internal consistency of assessments based on citations\nand FFa scores. It turns out that research level has little impact, while\narticle type has big effect on the differences. These two measures are\nsignificantly different for two groups: non-primary research or evidence-based\nresearch publications are more highly cited rather than highly recommended,\nhowever, translational research or transformative research publications are\nmore highly recommended by faculty members but gather relatively lower\ncitations. This can be expected because citation activities are usually\npracticed by academic authors while the potential for scientific revolutions\nand the suitability for clinical practice of an article should be investigated\nfrom the practitioners' points of view. We conclude with a policy relevant\nrecommendation that the application of bibliometric approaches in research\nevaluation procedures should include the proportion of three types of\npublications: evidence-based research, transformative research, and\ntranslational research. The latter two types are more suitable to be assessed\nthrough peer review."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2014.10.001", 
    "link": "http://arxiv.org/pdf/1501.02084v1", 
    "title": "Reviving the past: the growth of citations to old documents", 
    "arxiv-id": "1501.02084v1", 
    "author": "Emilio Delgado L\u00f3pez-C\u00f3zar", 
    "publish": "2015-01-09T09:46:37Z", 
    "summary": "In this Digest we review a recent study released by the Google Scholar team\non the apparently increasing fraction of citations to old articles from studies\npublished in the last 24 years (1990-2013). First, we describe the main\nfindings of their article. Secondly, we conduct an analogue study, using a\ndifferent data source as well as different measures which throw very similar\nresults, thus confirming the phenomenon. Lastly, we discuss the possible causes\nof this phenomenon."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2014.10.001", 
    "link": "http://arxiv.org/pdf/1501.03342v2", 
    "title": "Research Data Explored: Citations versus Altmetrics", 
    "arxiv-id": "1501.03342v2", 
    "author": "Juan Gorraiz", 
    "publish": "2015-01-14T13:42:59Z", 
    "summary": "The study explores the citedness of research data, its distribution over time\nand how it is related to the availability of a DOI (Digital Object Identifier)\nin Thomson Reuters' DCI (Data Citation Index). We investigate if cited research\ndata \"impact\" the (social) web, reflected by altmetrics scores, and if there is\nany relationship between the number of citations and the sum of altmetrics\nscores from various social media-platforms. Three tools are used to collect and\ncompare altmetrics scores, i.e. PlumX, ImpactStory, and Altmetric.com. In terms\nof coverage, PlumX is the most helpful altmetrics tool. While research data\nremain mostly uncited (about 85%), there has been a growing trend in citing\ndata sets published since 2007. Surprisingly, the percentage of the number of\ncited research data with a DOI in DCI has decreased in the last years. Only\nnine repositories account for research data with DOIs and two or more\ncitations. The number of cited research data with altmetrics scores is even\nlower (4 to 9%) but shows a higher coverage of research data from the last\ndecade. However, no correlation between the number of citations and the total\nnumber of altmetrics scores is observable. Certain data types (i.e. survey,\naggregate data, and sequence data) are more often cited and receive higher\naltmetrics scores."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2014.10.001", 
    "link": "http://arxiv.org/pdf/1501.04431v1", 
    "title": "Field-normalized citation impact indicators and the choice of an   appropriate counting method", 
    "arxiv-id": "1501.04431v1", 
    "author": "Nees Jan van Eck", 
    "publish": "2015-01-19T09:31:36Z", 
    "summary": "Bibliometric studies often rely on field-normalized citation impact\nindicators in order to make comparisons between scientific fields. We discuss\nthe connection between field normalization and the choice of a counting method\nfor handling publications with multiple co-authors. Our focus is on the choice\nbetween full counting and fractional counting. Based on an extensive\ntheoretical and empirical analysis, we argue that properly field-normalized\nresults cannot be obtained when full counting is used. Fractional counting does\nprovide results that are properly field normalized. We therefore recommend the\nuse of fractional counting in bibliometric studies that require field\nnormalization, especially in studies at the level of countries and research\norganizations. We also compare different variants of fractional counting. In\ngeneral, it seems best to use either the author-level or the address-level\nvariant of fractional counting."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2014.10.001", 
    "link": "http://arxiv.org/pdf/1501.05136v1", 
    "title": "Uma an\u00e1lise bibliom\u00e9trica do Congresso Nacional de Bibliotec\u00e1rios,   Arquivistas e Documentalistas (1985-2012)", 
    "arxiv-id": "1501.05136v1", 
    "author": "Mar\u00eda \u00c1mgeles Zuleta Garcia", 
    "publish": "2015-01-21T11:33:42Z", 
    "summary": "This article is the first bibliometric analysis of the 708 lectures published\nby The Librarians and Archivists National Congress between 1985 and 2012,\nhaving been developed markers for production, productivity, institutional\norigin and thematic analysis, in a quantitative, relational and diachronic\nperspective. Its results show a dynamic congress, essentially national and\nprofessional, with a strong majority of individual authorships, even with the\nrecent growth of the ratio of collaborations. In its thematic approach,\nemphasis is given to public services of information, with the greatest focus\nbeing on libraries, while still giving relevance to reflections on professional\nand academic training in the area of Information Sciences, and also following\nthe most recent technological developments."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2014.10.001", 
    "link": "http://arxiv.org/pdf/1501.05138v1", 
    "title": "Thematic Identification of 'Little Science': Trends in Portuguese IS&LS   Literature by Controlled Vocabulary and Co-Word Analysis", 
    "arxiv-id": "1501.05138v1", 
    "author": "Mar\u00eda \u00c1ngeles Zulueta Garcia", 
    "publish": "2015-01-21T11:38:29Z", 
    "summary": "This study presents an overview of IS&LS thematic trends in Portugal between\n2001 and 2012. The results were obtained by means of an analysis, using\nexpeditious qualitative and quantitative techniques, of the bibliographic\nrecords of proceedings papers identified during this period. These records were\nprocessed using two techniques: a manual subject classification and an\nautomated co-word analysis of the Author-Assigned Keywords. From this we\ndesigned cluster and co-occurrence maps, using the VOSviewer and the Pajek\nsoftware packages. The results indicated an accentuated dynamism in the\nthematic evolution of this documental corpus, apart from revealing a\nsignificant difference among the themes transmitted in nationally and\ninternationally visible production."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1501.05462v3", 
    "title": "A Review of Theory and Practice in Scientometrics", 
    "arxiv-id": "1501.05462v3", 
    "author": "Loet Leydesdorff", 
    "publish": "2015-01-22T11:28:03Z", 
    "summary": "Scientometrics is the study of the quantitative aspects of the process of\nscience as a communication system. It is centrally, but not only, concerned\nwith the analysis of citations in the academic literature. In recent years it\nhas come to play a major role in the measurement and evaluation of research\nperformance. In this review we consider: the historical development of\nscientometrics, sources of citation data, citation metrics and the \"laws\" of\nscientometrics, normalisation, journal impact factors and other journal\nmetrics, visualising and mapping science, evaluation and policy, and future\ndevelopments."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1501.06285v2", 
    "title": "Analyzing data citation practices using the Data Citation Index", 
    "arxiv-id": "1501.06285v2", 
    "author": "Daniel Torres-Salinas", 
    "publish": "2015-01-26T08:36:18Z", 
    "summary": "We present an analysis of data citation practices based on the Data Citation\nIndex from Thomson Reuters. This database launched in 2012 aims to link data\nsets and data studies with citations received from the other citation indexes.\nThe DCI harvests citations to research data from papers indexed in the Web of\nScience. It relies on the information provided by the data repository as data\ncitation practices are inconsistent or inexistent in many cases. The findings\nof this study show that data citation practices are far from common in most\nresearch fields. Some differences have been reported on the way researchers\ncite data: while in the areas of Science and Engineering and Technology data\nsets were the most cited, in Social Sciences and Arts and Humanities data\nstudies play a greater role. A total of 88.1 percent of the records have\nreceived no citation, but some repositories show very low uncitedness rates.\nAlthough data citation practices are rare in most fields, they have expanded in\ndisciplines such as crystallography and genomics. We conclude by emphasizing\nthe role that the DCI could play in encouraging the consistent, standardized\ncitation of research data; a role that would enhance their value as a means of\nfollowing the research process from data collection to publication."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1104.2925v1", 
    "title": "SharedCanvas: A Collaborative Model for Medieval Manuscript Layout   Dissemination", 
    "arxiv-id": "1104.2925v1", 
    "author": "Herbert Van de Sompel", 
    "publish": "2011-04-14T20:46:33Z", 
    "summary": "In this paper we present a model based on the principles of Linked Data that\ncan be used to describe the interrelationships of images, texts and other\nresources to facilitate the interoperability of repositories of medieval\nmanuscripts or other culturally important handwritten documents. The model is\ndesigned from a set of requirements derived from the real world use cases of\nsome of the largest digitized medieval content holders, and instantiations of\nthe model are intended as the input to collection-independent page turning and\nscholarly presentation interfaces. A canvas painting paradigm, such as in PDF\nand SVG, was selected based on the lack of a one to one correlation between\nimage and page, and to fulfill complex requirements such as when the full text\nof a page is known, but only fragments of the physical object remain. The model\nis implemented using technologies such as OAI-ORE Aggregations and OAC\nAnnotations, as the fundamental building blocks of emerging Linked Digital\nLibraries. The model and implementation are evaluated through prototypes of\nboth content providing and consuming applications. Although the system was\ndesigned from requirements drawn from the medieval manuscript domain, it is\napplicable to any layout-oriented presentation of images of text."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1104.4601v2", 
    "title": "ChemXSeer Digital Library Gaussian Search", 
    "arxiv-id": "1104.4601v2", 
    "author": "Karl T. Mueller", 
    "publish": "2011-04-24T02:19:49Z", 
    "summary": "We report on the Gaussian file search system designed as part of the\nChemXSeer digital library. Gaussian files are produced by the Gaussian software\n[4], a software package used for calculating molecular electronic structure and\nproperties. The output files are semi-structured, allowing relatively easy\naccess to the Gaussian attributes and metadata. Our system is currently capable\nof searching Gaussian documents using a boolean combination of atoms (chemical\nelements) and attributes. We have also implemented a faceted browsing feature\non three important Gaussian attribute types - Basis Set, Job Type and Method\nUsed. The faceted browsing feature enables a user to view and process a\nsmaller, filtered subset of documents."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1109.0680v1", 
    "title": "Beyond the Boundaries of Open, Closed and Pirate Archives: Lessons from   a Hybrid Approach", 
    "arxiv-id": "1109.0680v1", 
    "author": "Petros Stefaneas", 
    "publish": "2011-09-04T07:07:04Z", 
    "summary": "The creation of open archives i.e. archives where access is regulated by open\nlicensing models (content, source, data), should be seen as part of a broader\nsocio-economic phenomenon that finds legal expression in specific\norganizational and technical formats.This paper examines the origins and main\ncharacteristics of the open archives phenomenon. We investigate the extent to\nwhich different models of production of economic or social value can be\nexpressed in different forms of licensing in the context of open archives.\nThrough this process, we assess the extent to which the digital archive is\nmoving towards providing access that is deeper (meaning, that offers more\naccess rights) and wider (in the sense that most of the information given is in\nopen content licensing) or face a gradual stratification and polarization of\nthe content. Such stratification entails the emergence of two types of content:\ncontent to which access is extremely limited and content to which access\nremains completely open. This differentiation between classes of content is the\nresult of multiple factors: from purely legislative, administrative and\ncontractual restrictions (e.g. data protection and confidentiality\nrestrictions) to information economics (e.g. peer production) or social\n(minimum universal access).\n  We claim that with respect to the access management model, most of the\ncurrent archiving processes include elements of openness. Usually, this is the\nresult of economic necessity expressed in licensing instruments or\norganisational arrangements. The viability and the socio-economic importance of\nthe digital archives also contributes to the use of open archiving practices.\nIn such a context, although pure forms of open digital archives may remain an\nideal, the reality of hybrid open digital archives is a necessity."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1109.1173v1", 
    "title": "Which cities' paper output and citation impact are above expectation in   information science? Some improvements of our previous mapping approaches", 
    "arxiv-id": "1109.1173v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2011-09-06T13:21:33Z", 
    "summary": "Bornmann and Leydesdorff (in press) proposed methods based on Web-of-Science\ndata to identify field-specific excellence in cities where highly-cited papers\nwere published more frequently than can be expected. Top performers in output\nare cities in which authors are located who publish a number of highly-cited\npapers that is statistically significantly higher than can be expected for\nthese cities. Using papers published between 1989 and 2009 in information\nscience improvements to the methods of Bornmann and Leydesdorff (in press) are\npresented and an alternative mapping approach based on the indicator I3 is\nintroduced here. The I3 indicator was introduced by Leydesdorff and Bornmann\n(in press)."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1109.2058v1", 
    "title": "Text mining and visualization using VOSviewer", 
    "arxiv-id": "1109.2058v1", 
    "author": "Ludo Waltman", 
    "publish": "2011-09-09T16:16:22Z", 
    "summary": "VOSviewer is a computer program for creating, visualizing, and exploring\nbibliometric maps of science. In this report, the new text mining functionality\nof VOSviewer is presented. A number of examples are given of applications in\nwhich VOSviewer is used for analyzing large amounts of text data."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1109.2306v2", 
    "title": "An Evaluation of Impacts in \"Nanoscience & nanotechnology:\" Steps   towards standards for citation analysis", 
    "arxiv-id": "1109.2306v2", 
    "author": "Loet Leydesdorff", 
    "publish": "2011-09-11T11:22:01Z", 
    "summary": "One is inclined to conceptualize impact in terms of citations per\npublication, and thus as an average. However, citation distributions are\nskewed, and the average has the disadvantage that the number of publications is\nused in the denominator. Using hundred percentiles, one can integrate the\nnormalized citation curve and develop an indicator that can be compared across\ndocument sets because percentile ranks are defined at the article level. I\napply this indicator to the set of 58 journals in the ISI Subject Category of\n\"Nanoscience & nanotechnology,\" and rank journals, countries, cities, and\ninstitutes using non-parametric statistics. The significance levels of results\ncan thus be indicated. The results are first compared with the ISI-Impact\nFactors, but this Integrated Impact Indicator (I3) can be used with any set\ndownloaded from the (Social) Science Citation Index. The software is made\npublicly available at the Internet. Visualization techniques are also specified\nfor evaluation by positioning institutes on Google Map overlays."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1204.3717v3", 
    "title": "Edited Volumes, Monographs, and Book Chapters in the Book Citation Index   (BKCI) and Science Citation Index (SCI, SoSCI, A&HCI)", 
    "arxiv-id": "1204.3717v3", 
    "author": "Ulrike Felt", 
    "publish": "2012-04-17T07:25:15Z", 
    "summary": "In 2011, Thomson-Reuters introduced the Book Citation Index (BKCI) as part of\nthe Science Citation Index (SCI). The interface of the Web of Science version 5\nenables users to search for both \"Books\" and \"Book Chapters\" as new categories.\nBooks and book chapters, however, were always among the cited references, and\nbook chapters have been included in the database since 2005. We explore the two\ncategories with both BKCI and SCI, and in the sister social sciences (SoSCI)\nand the arts & humanities (A&HCI) databases. Book chapters in edited volumes\ncan be highly cited. Books contain many citing references but are relatively\nless cited. This may find its origin in the slower circulation of books than of\njournal articles. It is possible to distinguish between monographs and edited\nvolumes among the \"Books\" scientometrically. Monographs may be underrated in\nterms of citation impact or overrated using publication performance indicators\nbecause individual chapters are counted as contributions separately in terms of\narticles, reviews, and/or book chapters."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1207.6324v1", 
    "title": "A Revised Publication Model for ECML PKDD", 
    "arxiv-id": "1207.6324v1", 
    "author": "Filip Zelezny", 
    "publish": "2012-07-26T16:44:30Z", 
    "summary": "ECML PKDD is the main European conference on machine learning and data\nmining. Since its foundation it implemented the publication model common in\ncomputer science: there was one conference deadline; conference submissions\nwere reviewed by a program committee; papers were accepted with a low\nacceptance rate. Proceedings were published in several Springer Lecture Notes\nin Artificial (LNAI) volumes, while selected papers were invited to special\nissues of the Machine Learning and Data Mining and Knowledge Discovery\njournals. In recent years, this model has however come under stress. Problems\ninclude: reviews are of highly variable quality; the purpose of bringing the\ncommunity together is lost; reviewing workloads are high; the information\ncontent of conferences and journals decreases; there is confusion among\nscientists in interdisciplinary contexts. In this paper, we present a new\npublication model, which will be adopted for the ECML PKDD 2013 conference, and\naims to solve some of the problems of the traditional model. The key feature of\nthis model is the creation of a journal track, which is open to submissions all\nyear long and allows for revision cycles."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1207.7067v1", 
    "title": "Towards a Book Publishers Citation Reports. First approach using the   Book Citation Index", 
    "arxiv-id": "1207.7067v1", 
    "author": "Emilio Delgado Lopez-Cozar", 
    "publish": "2012-07-29T17:23:43Z", 
    "summary": "The absence of books and book chapters in the Web of Science Citation Indexes\n(SCI, SSCI and A&HCI) has always been considered an important flaw but the\nThomson Reuters 'Book Citation Index' database was finally available in October\nof 2010 indexing 29,618 books and 379,082 book chapters. The Book Citation\nIndex opens a new window of opportunities for analyzing these fields from a\nbibliometric point of view. The main objective of this article is to analyze\ndifferent impact indicators referred to the scientific publishers included in\nthe Book Citation Index for the Social Sciences and Humanities fields during\n2006-2011. This way we construct what we have called the 'Book Publishers\nCitation Reports'. For this, we present a total of 19 rankings according to the\ndifferent disciplines in Humanities & Arts and Social Sciences & Law with six\nindicators for scientific publishers"
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1301.0801v2", 
    "title": "International Collaboration in Science: The Global Map and the Network", 
    "arxiv-id": "1301.0801v2", 
    "author": "Jonathan Adams", 
    "publish": "2013-01-04T18:55:25Z", 
    "summary": "The network of international co-authorship relations has been dominated by\ncertain European nations and the USA, but this network is rapidly expanding at\nthe global level. Between 40 and 50 countries appear in the center of the\ninternational network in 2011, and almost all (201) nations are nowadays\ninvolved in international collaboration. In this brief communication, we\npresent both a global map with the functionality of a Google Map (zooming,\netc.) and network maps based on normalized relations. These maps reveal\ncomplementary aspects of the network. International collaboration in the\ngeneration of knowledge claims (that is, the context of discovery) changes the\nstructural layering of the sciences. Previously, validation was at the global\nlevel and discovery more dependent on local contexts. This changing\nrelationship between the geographical and intellectual dimensions of the\nsciences also has implications for national science policies."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1301.1013v2", 
    "title": "Interactive Overlays of Journals and the Measurement of   Interdisciplinarity on the basis of Aggregated Journal-Journal Citations", 
    "arxiv-id": "1301.1013v2", 
    "author": "Chaomei Chen", 
    "publish": "2013-01-06T15:34:00Z", 
    "summary": "Using \"Analyze Results\" at the Web of Science, one can directly generate\noverlays onto global journal maps of science. The maps are based on the 10,000+\njournals contained in the Journal Citation Reports (JCR) of the Science and\nSocial Science Citation Indices (2011). The disciplinary diversity of the\nretrieval is measured in terms of Rao-Stirling's \"quadratic entropy.\" Since\nthis indicator of interdisciplinarity is normalized between zero and one, the\ninterdisciplinarity can be compared among document sets and across years, cited\nor citing. The colors used for the overlays are based on Blondel et al.'s\n(2008) community-finding algorithms operating on the relations journals\nincluded in JCRs. The results can be exported from VOSViewer with different\noptions such as proportional labels, heat maps, or cluster density maps. The\nmaps can also be web-started and/or animated (e.g., using PowerPoint). The\n\"citing\" dimension of the aggregated journal-journal citation matrix was found\nto provide a more comprehensive description than the matrix based on the cited\narchive. The relations between local and global maps and their different\nfunctions in studying the sciences in terms of journal litteratures are further\ndiscussed: local and global maps are based on different assumptions and can be\nexpected to serve different purposes for the explanation."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1301.1563v1", 
    "title": "Academic Ranking with Web Mining and Axiomatic Analysis", 
    "arxiv-id": "1301.1563v1", 
    "author": "Ge Wang", 
    "publish": "2012-12-26T13:20:44Z", 
    "summary": "Academic ranking is a public topic, such as for universities, colleges, or\ndepartments, which has significant educational, administrative and social\neffects. Popular ranking systems include the US News & World Report (USNWR),\nthe Academic Ranking of World Universities (ARWU), and others. The most popular\nobservables for such ranking are academic publications and their citations.\nHowever, a rigorous, quantitative and thorough methodology has been missing for\nthis purpose. With modern web technology and axiomatic bibliometric analysis,\nhere we perform a feasibility study on Microsoft Academic Search metadata and\nobtain the first-of-its-kind ranking results for American departments of\ncomputer science. This approach can be extended for fully automatic intuitional\nand college ranking based on comprehensive data on Internet."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1301.4941v2", 
    "title": "A systematic empirical comparison of different approaches for   normalizing citation impact indicators", 
    "arxiv-id": "1301.4941v2", 
    "author": "Nees Jan van Eck", 
    "publish": "2013-01-21T18:04:31Z", 
    "summary": "We address the question how citation-based bibliometric indicators can best\nbe normalized to ensure fair comparisons between publications from different\nscientific fields and different years. In a systematic large-scale empirical\nanalysis, we compare a traditional normalization approach based on a field\nclassification system with three source normalization approaches. We pay\nspecial attention to the selection of the publications included in the\nanalysis. Publications in national scientific journals, popular scientific\nmagazines, and trade magazines are not included. Unlike earlier studies, we use\nalgorithmically constructed classification systems to evaluate the different\nnormalization approaches. Our analysis shows that a source normalization\napproach based on the recently introduced idea of fractional citation counting\ndoes not perform well. Two other source normalization approaches generally\noutperform the classification-system-based normalization approach that we\nstudy. Our analysis therefore offers considerable support for the use of\nsource-normalized bibliometric indicators."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1301.5375v1", 
    "title": "A Single Journal Study : Malaysian Journal of Computer Science", 
    "arxiv-id": "1301.5375v1", 
    "author": "N. B. Anuar", 
    "publish": "2013-01-23T01:40:30Z", 
    "summary": "Single journal studies are reviewed and measures used in the studies are\nhighlighted. The following quantitative measures are used to study 272 articles\npublished in Malaysian Journal of Computer Science, (1) the article\nproductivity of the journal from 1985 to 2007, (2) the observed and expected\nauthorship productivity tested using Lotka's Law of author productivity,\nidentification and listing of core authors; (3) the authorship, co-authorship\npattern by authors' country of origin and institutional affiliations; (4) the\nsubject areas of research; (5) the citation analysis of resources referenced as\nwell as the age and half-life of citations; the journals referenced and tested\nfor zonal distribution using Bradford's law of journal scattering; the extent\nof web citations; and (6) the citations received by articles published in MJCS\nand impact factor of the journal based on information obtained from Google\nScholar, the level of author and journal self-citation."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1301.5379v1", 
    "title": "Auditing scholarly journals published in Malaysia and assessing their   visibility", 
    "arxiv-id": "1301.5379v1", 
    "author": "A. P. Koh", 
    "publish": "2013-01-23T01:51:57Z", 
    "summary": "The problem with the identification of Malaysian scholarly journals lies in\nthe lack of a current and complete listing of journals published in Malaysia.\nAs a result, librarians are deprived of a tool that can be used for journal\nselection and identification of gaps in their serials collection. This study\ndescribes the audit carried out on scholarly journals, with the objectives (a)\nto trace and characterized scholarly journal titles published in Malaysia, and\n(b) to determine their visibility in international and national indexing\ndatabases. A total of 464 titles were traced and their yearly trends, publisher\nand publishing characteristics, bibliometrics and indexation in national,\ninternational and subject-based indexes were described."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1301.5380v1", 
    "title": "Publication productivity and citation analysis of the Medical Journal of   Malaysia: 2004 - 2008", 
    "arxiv-id": "1301.5380v1", 
    "author": "S. A. Sanni", 
    "publish": "2013-01-23T01:54:39Z", 
    "summary": "We analysed 580 articles (original articles only) published in Medical\nJournal of Malaysia between 2004 and 2008, the resources referenced by the\narticles and the citations and impact received. Our aim was to examine article\nand author productivity, the age of references used and impact of the journal.\nPublication data was obtained from MyAIS database and Google Scholar provided\nthe citation data. From the 580 articles analyzed, contributors mainly come\nfrom the hospitals, universities and clinics. Contributions from foreign\nauthors are low. The useful lives of references cited were between 3 to 11\nyears. ISI derived Impact factor for MJM ranged between 0.378 to 0.616. Journal\nself-citation is low. Out of the 580 sampled articles, 76.8% have been cited at\nleast once over the 5 years and the ratio of total publications to citations is\n1: 2.6."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1301.5383v1", 
    "title": "Measuring the influence of a journal using impact and diffusion factors", 
    "arxiv-id": "1301.5383v1", 
    "author": "A. N. Zainab", 
    "publish": "2013-01-23T02:03:19Z", 
    "summary": "Presents the result of the calculated IS! equivalent Impact Factor, Relative\nDiffusion Factor (RDF), and Journal Diffusion Factor (JDF) for articles\npublished in the Medical Journal of Malaysia (MJM) between the years 2004 and\n2008 in both their synchronous and diachronous versions. The publication data\nare collected from MyAis (Malaysian Abstracting & Indexing system) while the\ncitation data are collected from Google Scholar. The values of the synchronous\nJDF ranges from 0.057 - 0.14 while the diachronous JDF ranges from 0.46 - 1.98.\nThe high diachronous JDF is explained by a relatively high number of different\nciting journals against the number of publications. This implies that the\nresults of diachronous JDF is influenced by the numbers of publications and a\ngood comparison may be one of which the subject of analysis have similar number\nof publications and citations period. The yearly values of the synchronous RDF\nvary in the range of 0.66 - 1.00 while diachronous RDF ranges from 0.62 - 0.88.\nThe result shows that diachronous RDF is negatively correlated with the number\nof citations, resulting in a low RDF value for highly cited publication years.\nWhat this implies in practice is that the diffusion factors can be calculated\nfor every additional year at any journal level of analysis. This study\ndemonstrates that these indicators are valuable tools that help to show\ndevelopment of journals as it changes through time."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1301.5384v1", 
    "title": "International Contribution to Nipah Virus Research 1999-2010", 
    "arxiv-id": "1301.5384v1", 
    "author": "A. N. Zainab", 
    "publish": "2013-01-23T02:15:09Z", 
    "summary": "This study examines 462 papers on Nipah virus research published from 1999 to\n2010, identifying the active authors, institutions and citations received. Data\nwas extracted from SCI-Expanded database, (Web of Science) and analyzed using\ndescriptive figures and tables. The results show the growth of publication is\nincremental up to 2010 even though the average citations received is\ndecreasing. The ratio of authors to articles is 1330: 426. The active\ncontributing countries are USA (41.0%), Australia (19.3%), Malaysia (16.0%),\nEngland (6.5%) and France (5.6%). The productive authors are mainly affiliated\nto the Centre for Disease Control and Prevention, USA and Commonwealth\nScientific and Industrial Research Organization (CSIRO) in Australia and\nUniversity of Malaya Medical Centre, Malaysia. A total of 10572 citations were\nreceived and the ratio of articles to citation is 1: 24.8. Collaboration with\nthe bigger laboratories in USA and Australia is contributive to the sustained\ngrowth of published literature and to access diverse expertise."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1301.5385v1", 
    "title": "Collection security management at university libraries: assessment of   its implementation status", 
    "arxiv-id": "1301.5385v1", 
    "author": "A. N. Zainab", 
    "publish": "2013-01-23T02:23:02Z", 
    "summary": "This study examines the literature on library security and collection\nsecurity to identify factors to be considered to develop a collection security\nmanagement assessment instrument for university libraries. A \"house\" model was\nproposed consisting of five factors; collection security governance, operations\nand processes, people issues, physical and technical issues and the security\nculture in libraries. An assessment instrument listing items covering the five\nfactors was pilot tested on 61 samples comprising chief librarians, deputy\nlibrarians, departmental, sectional heads and professional staff working in\nfour university libraries in Nigeria. The level of security implementation is\nassessed on a scale of 1=not-implemented, 2=planning stage, 3=partial\nimplementation, 4=close to completion, and 5=full implementation. The\ninstrument was also tested for reliability. Reliability tests indicate that all\nfive factors are reliable with Cronbach's alpha values between 0.7 and 0.9,\nindicating that the instrument can be used for wider distribution to explore\nand assess the level of collection security implementation in university\nlibraries from a holistic perspective."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1301.5386v1", 
    "title": "Information systems security in special and public libraries: an   assessment of status", 
    "arxiv-id": "1301.5386v1", 
    "author": "A. N. Zainab", 
    "publish": "2013-01-23T02:35:03Z", 
    "summary": "Explores the use of an assessment instrument based on a model named library\ninformation systems security assessment model (LISSAM) to assess the 155 status\nin special and public libraries in Malaysia. The study aims to determine the\nimplementation status of technological and organizational components of the\nLISSAM model. An implementation index as well as a scoring tool is presented to\nassess the IS safeguarding measures in a library. Data used was based on\nquestionnaires distributed to a total of 50 individuals who are responsible for\nthe information systems (IS) or IT in the special and public libraries in\nMalaysia. Findings revealed that over 95% of libraries have high level of\ntechnological implementation but 54% were fair poorly on organizational\nmeasures, especially on lack of security procedures, administrative tools and\nawareness creation activities."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1301.5387v1", 
    "title": "Open Access repositories and journals for visibility: Implications for   Malaysian libraries", 
    "arxiv-id": "1301.5387v1", 
    "author": "A. N. Zainab", 
    "publish": "2013-01-23T02:36:55Z", 
    "summary": "This paper describes the growth of Open Access (OA) repositories and journals\nas reported by monitoring initiatives such as ROAR (Registry of Open Access\nRepositories), Open DOAR (Open Directory of Open Access Repositories), DOAJ\n(Directory of Open Access Journals), Directory of Web Ranking of World\nRepositories by the Cybermetrics Laboratory in Spain and published literature.\nThe performance of Malaysian OA repositories and journals is highlighted. The\nstrength of OA channels in increasing visibility and citations are evidenced by\nresearch findings. It is proposed that libraries champion OA initiatives by\nmaking university or institutional governance aware; encouraging institutional\njournal publishers to adopt OA platform; collaborating with research groups to\njumpstart OA institutional initiatives and to embed OA awareness into user and\nresearcher education programmes. By actively involved, libraries will be free\nof permission, licensing and archiving barriers usually imposed in traditional\npublishing situation."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1301.5392v1", 
    "title": "Internationalization of Malaysian Mathematical and Computer Science   Journal", 
    "arxiv-id": "1301.5392v1", 
    "author": "A. N. Zainab", 
    "publish": "2013-01-23T03:34:31Z", 
    "summary": "The internationalization characteristics of two Malaysian journals, Bulletin\nof the Malaysian Mathematical Sciences Society (indexed by ISI) and the\nMalaysian Journal of Computer Science (indexed by Inspec and Scopus) is\nobserved. All issues for the years 2000 to 2007 were looked at to obtain the\nfollowing information, (i) total articles published between 2000 and 2007; (ii)\nthe distribution of foreign and Malaysian authors publishing in the journals;\n(iii) the distribution of articles by country and (iv) the geographical\ndistribution of authors citing articles published in the journals. Citation to\narticles is derived from information given by Google scholar. The results\nindicate that both journals exhibit average internationalization\ncharacteristics as they are current in their publications but with between 19%\n-30% international composition of reviewers or editorials, publish between\n36%-79% of foreign articles and receive between 60%-70% of citations from\nforeign authors."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1301.5400v1", 
    "title": "The Pattern of E-Book Use amongst Undergraduates an Malaysia: A Case of   to Know is to Use", 
    "arxiv-id": "1301.5400v1", 
    "author": "A. N. Zainab", 
    "publish": "2013-01-23T04:16:16Z", 
    "summary": "This exploratory study focuses on identifying the usage pattern of e-books\nespecially on how, when, where and why undergraduates at the Faculty of\nComputer Science and Information Technology (FCSIT), University of Malaya (UM),\nKuala Lumpur use or do not use the e-books service provided by the University\nof Malaya library. A total of 206 (82%) useable questionnaires form the basis\nof analysis. The results indicate even though the students are heavy users of\nthe Internet, rate themselves as skilled in Internet use and have positive\nattitude towards the e-book service, the level of e-book use is still low\n(39%). The students become aware of the e-book service mainly while visiting\nthe University of Malaya Library Website, or are referred to it by their\nlecturers, friends or the librarians. About 70% rate positively on the e-book\nservice. Those who are users of e-books find e-books easy to use and their\nusages are mainly for writing assignment or project work. Most respondents\nprefer to use e-versions of textbooks and reference sources. Generally, both\nusers and non-users of e-books prefer to use the printed version of textbooks\nespecially if the text is continuously used. There are significant difference\nbetween the frequency of e-book use and gender; between past usage of e-book\nand preference for electronic textbooks and reference books. The possible\nfactors which may be related to e-book use are categorized into 4 groups and\npresented in a model, which comprises the ICT competencies of the students,\ntheir cognitive makeup, the degree of user access to the e-books and the\nfunctional or use factors."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1301.5782v1", 
    "title": "Association between quality of clinical practice guidelines and   citations given to their references", 
    "arxiv-id": "1301.5782v1", 
    "author": "Jens Peter Andersen", 
    "publish": "2013-01-24T13:54:24Z", 
    "summary": "It has been suggested that bibliometric analysis of different document types\nmay reveal new aspects of research performance. In medical research a number of\nstudy types play different roles in the research process and it has been shown,\nthat the evidence-level of study types is associated with varying citation\nrates. This study focuses on clinical practice guidelines, which are supposed\nto gather the highest evidence on a given topic to give the best possible\nrecommendation for practitioners. The quality of clinical practice guidelines,\nmeasured using the AGREE score, is compared to the citations given to the\nreferences used in these guidelines, as it is hypothesised, that better\nguidelines are based on higher cited references. AGREE scores are gathered from\nreviews of clinical practice guidelines on a number of diseases and treatments.\nTheir references are collected from Web of Science and citation counts are\nnormalised using the item-oriented z-score and the PPtop-10% indicators. A\npositive correlation between both citation indicators and the AGREE score of\nclinical practice guidelines is found. Some potential confounding factors are\nidentified. While confounding cannot be excluded, results indicate low\nlikelihood for the identified confounders. The results provide a new\nperspective to and application of citation analysis."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1301.6849v3", 
    "title": "Mutual Redundancies in Inter-human Communication Systems: Steps Towards   a Calculus of Processing Meaning", 
    "arxiv-id": "1301.6849v3", 
    "author": "Inga A. Ivanova", 
    "publish": "2013-01-29T07:26:24Z", 
    "summary": "The study of inter-human communication requires a more complex framework than\nShannon's (1948) mathematical theory of communication because \"information\" is\ndefined in the latter case as meaningless uncertainty. Assuming that meaning\ncannot be communicated, we extend Shannon's theory by defining mutual\nredundancy as a positional counterpart of the relational communication of\ninformation. Mutual redundancy indicates the surplus of meanings that can be\nprovided to the exchanges in reflexive communications. The information is\nredundant because based on \"pure sets,\" that is, without subtraction of mutual\ninformation in the overlaps. We show that in the three-dimensional case (e.g.,\nof a Triple Helix of university-industry-government relations), mutual\nredundancy is equal to mutual information (Rxyz = Txyz); but when the\ndimensionality is even, the sign is different. We generalize to the measurement\nin N dimensions and proceed to the interpretation. Using Luhmann's\nsocial-systems theory and/or Giddens' structuration theory, mutual redundancy\ncan be provided with an interpretation in the sociological case: different\nmeaning-processing structures code and decode with other algorithms. A surplus\nof (\"absent\") options can then be generated that add to the redundancy.\nLuhmann's \"functional (sub)systems\" of expectations or Giddens' \"rule-resource\nsets\" are positioned mutually, but coupled operationally in events or\n\"instantiated\" in actions. Shannon-type information is generated by the\nmediation, but the \"structures\" are (re-)positioned towards one another as sets\nof (potentially counterfactual) expectations. The structural differences among\nthe coding and decoding algorithms provide a source of additional options in\nreflexive and anticipatory communications."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1301.7443v1", 
    "title": "An OAI-PMH-based Web Service for the Generation of Co-Author Networks", 
    "arxiv-id": "1301.7443v1", 
    "author": "Peter Mutschke", 
    "publish": "2013-01-27T19:52:16Z", 
    "summary": "We will present a new component of our technical framework that was built to\nprovide a brought range of reusable web services for the enhancement of typical\nscientific retrieval processes. The proposed component computes betweenness of\nauthors in co-authorship networks extracted from publicly available metadata\nthat was harvested using OAI-PMH."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.ejor.2015.04.002", 
    "link": "http://arxiv.org/pdf/1304.2032v1", 
    "title": "Google Scholar and the h-index in biomedicine: the popularization of   bibliometric asessment", 
    "arxiv-id": "1304.2032v1", 
    "author": "Emilio Delgado Lopez-Cozar", 
    "publish": "2013-04-07T17:48:37Z", 
    "summary": "The aim of this paper is to review the features, benefits and limitations of\nthe new scientific evaluation products derived from Google Scholar; Google\nScholar Metrics and Google Scholar Citations, as well as the h-index which is\nthe standard bibliometric indicator adopted by these services. It also outlines\nthe potential of this new database as a source for studies in Biomedicine and\ncompares the h-index obtained by the most relevant journals and researchers in\nthe field of Intensive Care Medicine, by means of data extracted from Web of\nScience, Scopus and Google Scholar. Results show that, although average h-index\nvalues in Google Scholar are almost 30% higher than those obtained in Web of\nScience and about 15% higher than those collected by Scopus, there are no\nsubstantive changes in the rankings generated from either data source. Despite\nsome technical problems, it is concluded that Google Scholar is a valid tool\nfor researchers in Health Sciences, both for purposes of information retrieval\nand computation of bibliometric indicators"
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1000-1", 
    "link": "http://arxiv.org/pdf/1304.3924v1", 
    "title": "Best-in-class and Strategic Benchmarking of Scientific Subject   Categories of Web of Science in 2010", 
    "arxiv-id": "1304.3924v1", 
    "author": "Daniel Torres-Salinas", 
    "publish": "2013-04-14T16:52:41Z", 
    "summary": "Here we show a novel technique for comparing subject categories, where the\nprestige of academic journals in each category is represented statistically by\nan impact-factor histogram. For each subject category we compute the\nprobability of occurrence of scholarly journals with impact factor in different\nintervals. Here impact factor is measured with Thomson Reuters Impact Factor,\nEigenfactor Score, and Immediacy Index. Assuming the probabilities associated\nwith a pair of subject categories our objective is to measure the degree of\ndissimilarity between them. To do so, we use an axiomatic characterization for\npredicting dissimilarity between subject categories. The scientific subject\ncategories of Web of Science in 2010 were used to test the proposed approach\nfor benchmarking Cell Biology and Computer Science Information Systems with the\nrest as two case studies. The former is best-in-class benchmarking that\ninvolves studying the leading competitor category; the latter is strategic\nbenchmarking that involves observing how other scientific subject categories\ncompete."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1000-1", 
    "link": "http://arxiv.org/pdf/1304.5475v1", 
    "title": "Making Math Searchable in Wikipedia", 
    "arxiv-id": "1304.5475v1", 
    "author": "Moritz Schubotz", 
    "publish": "2013-04-19T16:48:46Z", 
    "summary": "Wikipedia, the world largest encyclopedia contains a lot of knowledge that is\nexpressed as formulae exclusively. Unfortunately, this knowledge is currently\nnot fully accessible by intelligent information retrieval systems. This immense\nbody of knowledge is hidden form value-added services, such as search. In this\npaper, we present our MathSearch implementation for Wikipedia that enables\nusers to perform a combined text and fully unlock the potential benefits."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1000-1", 
    "link": "http://arxiv.org/pdf/1304.5743v1", 
    "title": "Genericity versus expressivity - an exercise in semantic interoperable   research information systems for Web Science", 
    "arxiv-id": "1304.5743v1", 
    "author": "Andrea Scharnhorst", 
    "publish": "2013-04-21T14:41:23Z", 
    "summary": "The web does not only enable new forms of science, it also creates new\npossibilities to study science and new digital scholarship. This paper brings\ntogether multiple perspectives: from individual researchers seeking the best\noptions to display their activities and market their skills on the academic job\nmarket; to academic institutions, national funding agencies, and countries\nneeding to monitor the science system and account for public money spending. We\nalso address the research interests aimed at better understanding the\nself-organising and complex nature of the science system through researcher\ntracing, the identification of the emergence of new fields, and knowledge\ndiscovery using large-data mining and non-linear dynamics. In particular this\npaper draws attention to the need for standardisation and data interoperability\nin the area of research information as an indispensable pre-condition for any\nscience modelling. We discuss which levels of complexity are needed to provide\na globally, interoperable, and expressive data infrastructure for research\ninformation. With possible dynamic science model applications in mind, we\nintroduce the need for a \"middle-range\" level of complexity for data\nrepresentation and propose a conceptual model for research data based on a core\ninternational ontology with national and local extensions."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1000-1", 
    "link": "http://arxiv.org/pdf/1304.5753v2", 
    "title": "Mapping EINS -- An exercise in mapping the Network of Excellence in   Internet Science", 
    "arxiv-id": "1304.5753v2", 
    "author": "Andrea Scharnhorst", 
    "publish": "2013-04-21T15:28:39Z", 
    "summary": "This paper demonstrates the application of bibliometric mapping techniques in\nthe area of funded research networks. We discuss how science maps can be used\nto facilitate communication inside newly formed communities, but also to\naccount for their activities to funding agencies. We present the mapping of\nEINS as case -- an FP7 funded Network of Excellence. Finally, we discuss how\nthese techniques can be used to serve as knowledge maps for interdisciplinary\nworking experts."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1000-1", 
    "link": "http://arxiv.org/pdf/1304.6460v1", 
    "title": "Are elite journals declining?", 
    "arxiv-id": "1304.6460v1", 
    "author": "Yves Gingras", 
    "publish": "2013-04-24T01:16:04Z", 
    "summary": "Previous work indicates that over the past 20 years, the highest quality work\nhave been published in an increasingly diverse and larger group of journals. In\nthis paper we examine whether this diversification has also affected the\nhandful of elite journals that are traditionally considered to be the best. We\nexamine citation patterns over the past 40 years of 7 long-standing\ntraditionally elite journals and 6 journals that have been increasing in\nimportance over the past 20 years. To be among the top 5% or 1% cited papers,\npapers now need about twice as many citations as they did 40 years ago. Since\nthe late 1980s and early 1990s elite journals have been publishing a decreasing\nproportion of these top cited papers. This also applies to the two journals\nthat are typically considered as the top venues and often used as bibliometric\nindicators of \"excellence\", Science and Nature. On the other hand, several new\nand established journals are publishing an increasing proportion of most cited\npapers. These changes bring new challenges and opportunities for all parties.\nJournals can enact policies to increase or maintain their relative position in\nthe journal hierarchy. Researchers now have the option to publish in more\ndiverse venues knowing that their work can still reach the same audiences.\nFinally, evaluators and administrators need to know that although there will\nalways be a certain prestige associated with publishing in \"elite\" journals,\njournal hierarchies are in constant flux so inclusion of journals into this\ngroup is not permanent."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1000-1", 
    "link": "http://arxiv.org/pdf/1304.6709v1", 
    "title": "Designing the W3C Open Annotation Data Model", 
    "arxiv-id": "1304.6709v1", 
    "author": "Herbert Van de Sompel", 
    "publish": "2013-04-24T19:49:57Z", 
    "summary": "The Open Annotation Core Data Model specifies an interoperable framework for\ncreating associations between related resources, called annotations, using a\nmethodology that conforms to the Architecture of the World Wide Web. Open\nAnnotations can easily be shared between platforms, with sufficient richness of\nexpression to satisfy complex requirements while remaining simple enough to\nalso allow for the most common use cases, such as attaching a piece of text to\na single web resource. This paper presents the W3C Open Annotation Community\nGroup specification and the rationale behind the scoping and technical\ndecisions that were made. It also motivates interoperable Annotations via use\ncases, and provides a brief analysis of the advantages over previous\nspecifications."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1000-1", 
    "link": "http://arxiv.org/pdf/1304.6945v1", 
    "title": "A bibliometric index based on the complete list of cited publications", 
    "arxiv-id": "1304.6945v1", 
    "author": "Judit Bar-Ilan", 
    "publish": "2013-04-25T15:54:24Z", 
    "summary": "We propose a new index, the $j$-index, which is defined for an author as the\nsum of the square roots of the numbers of citations to each of the author's\npublications. The idea behind the $j$-index it to remedy a drawback of the\n$h$-index $-$ that the $h$-index does not take into account the full citation\nrecord of a researcher. The square root function is motivated by our desire to\navoid the possible bias that may occur with a simple sum when an author has\nseveral very highly cited papers. We compare the $j$-index to the $h$-index,\nthe $g$-index and the total citation count for three subject areas using\nseveral association measures.\n  Our results indicate that that the association between the $j$-index and the\nother indices varies according to the subject area. One explanation of this\nvariation may be due to the proportion of citations to publications of the\nresearcher that are in the $h$-core. The $j$-index is {\\em not} an $h$-index\nvariant, and as such is intended to complement rather than necessarily replace\nthe $h$-index and other bibliometric indicators, thus providing a more complete\npicture of a researcher's achievements."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1000-1", 
    "link": "http://arxiv.org/pdf/1304.7151v1", 
    "title": "Twenty-Five Shades of Greycite: Semantics for referencing and   preservation", 
    "arxiv-id": "1304.7151v1", 
    "author": "Lindsay Marshall", 
    "publish": "2013-04-26T13:03:01Z", 
    "summary": "Semantic publishing can enable richer documents with clearer, computationally\ninterpretable properties. For this vision to become reality, however, authors\nmust benefit from this process, so that they are incentivised to add these\nsemantics. Moreover, the publication process that generates final content must\nallow and enable this semantic content. Here we focus on author-led or \"grey\"\nliterature, which uses a convenient and simple publication pipeline. We\ndescribe how we have used metadata in articles to enable richer referencing of\nthese articles and how we have customised the addition of these semantics to\narticles. Finally, we describe how we use the same semantics to aid in digital\npreservation and non-repudiability of research articles."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1000-1", 
    "link": "http://arxiv.org/pdf/1304.7300v1", 
    "title": "Coverage and adoption of altmetrics sources in the bibliometric   community", 
    "arxiv-id": "1304.7300v1", 
    "author": "Jens Terliesner", 
    "publish": "2013-04-26T22:34:40Z", 
    "summary": "Altmetrics, indices based on social media platforms and tools, have recently\nemerged as alternative means of measuring scholarly impact. Such indices assume\nthat scholars in fact populate online social environments, and interact with\nscholarly products there. We tested this assumption by examining the use and\ncoverage of social media environments amongst a sample of bibliometricians. As\nexpected, coverage varied: 82% of articles published by sampled\nbibliometricians were included in Mendeley libraries, while only 28% were\nincluded in CiteULike. Mendeley bookmarking was moderately correlated (.45)\nwith Scopus citation. Over half of respondents asserted that social media tools\nwere affecting their professional lives, although uptake of online tools varied\nwidely. 68% of those surveyed had LinkedIn accounts, while Academia.edu,\nMendeley, and ResearchGate each claimed a fifth of respondents. Nearly half of\nthose responding had Twitter accounts, which they used both personally and\nprofessionally. Surveyed bibliometricians had mixed opinions on altmetrics'\npotential; 72% valued download counts, while a third saw potential in tracking\narticles' influence in blogs, Wikipedia, reference managers, and social media.\nAltogether, these findings suggest that some online tools are seeing\nsubstantial use by bibliometricians, and that they present a potentially\nvaluable source of impact data."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1167-5", 
    "link": "http://arxiv.org/pdf/1304.7653v3", 
    "title": "Usage History of Scientific Literature: Nature Metrics and Metrics of   Nature Publications", 
    "arxiv-id": "1304.7653v3", 
    "author": "Chunbo Zhang", 
    "publish": "2013-04-29T13:15:46Z", 
    "summary": "In this study, we analyze the dynamic usage history of Nature publications\nover time using Nature metrics data. We conduct analysis from two perspectives.\nOn the one hand, we examine how long it takes before the articles' downloads\nreach 50%/80% of the total; on the other hand, we compare the percentage of\ntotal downloads in 7 days, 30 days, and 100 days after publication. In general,\npapers are downloaded most frequently within a short time period right after\ntheir publication. And we find that compared with Non-Open Access papers,\nreaders' attention on Open Access publications are more enduring. Based on the\nusage data of a newly published paper, regression analysis could predict the\nfuture expected total usage counts."
},{
    "category": "cs.DL", 
    "doi": "10.5539/ass.v9n5p176", 
    "link": "http://arxiv.org/pdf/1305.0379v1", 
    "title": "Does Criticisms Overcome the Praises of Journal Impact Factor?", 
    "arxiv-id": "1305.0379v1", 
    "author": "Nader Ale Ebrahim", 
    "publish": "2013-05-02T09:27:11Z", 
    "summary": "Journal impact factor (IF) as a gauge of influence and impact of a particular\njournal comparing with other journals in the same area of research, reports the\nmean number of citations to the published articles in particular journal.\nAlthough, IF attracts more attention and being used more frequently than other\nmeasures, it has been subjected to criticisms, which overcome the advantages of\nIF. Critically, extensive use of IF may result in destroying editorial and\nresearchers behaviour, which could compromise the quality of scientific\narticles. Therefore, it is the time of the timeliness and importance of a new\ninvention of journal ranking techniques beyond the journal impact factor."
},{
    "category": "cs.DL", 
    "doi": "10.5539/ass.v9n5p176", 
    "link": "http://arxiv.org/pdf/1305.1216v2", 
    "title": "An insight into the importance of national university rankings in an   international context: The case of the I-UGR Rankings of Spanish universities", 
    "arxiv-id": "1305.1216v2", 
    "author": "Francisco Herrera", 
    "publish": "2013-05-06T14:49:44Z", 
    "summary": "The great importance international rankings have achieved in the research\npolicy arena warns against many threats consequence of the flaws and\nshortcomings these tools present. One of them has to do with the inability to\naccurately represent national university systems as their original purpose is\nonly to rank world-class universities. Another one has to do with the lack of\nrepresentativeness of universities' disciplinary profiles as they usually\nprovide a unique table. Although some rankings offer a great coverage and\nothers offer league tables by fields, no international ranking does both. In\norder to surpass such limitation from a research policy viewpoint, this paper\nanalyzes the possibility of using national rankings in order to complement\ninternational rankings. For this, we analyze the Spanish university system as a\nstudy case presenting the I-UGR Rankings for Spanish universities by fields and\nsubfields. Then, we compare their results with those obtained by the Shanghai\nRanking, the QS Ranking, the Leiden Ranking and the NTU Ranking, as they all\nhave basic common grounds which allow such comparison. We conclude that it is\nadvisable to use national rankings in order to complement international\nrankings, however we observe that this must be done with certain caution as\nthey differ on the methodology employed as well as on the construction of the\nfields."
},{
    "category": "cs.DL", 
    "doi": "10.5539/ass.v9n5p176", 
    "link": "http://arxiv.org/pdf/1305.1476v1", 
    "title": "ResourceSync: Leveraging Sitemaps for Resource Synchronization", 
    "arxiv-id": "1305.1476v1", 
    "author": "Herbert van de Sompel", 
    "publish": "2013-05-07T11:42:52Z", 
    "summary": "Many applications need up-to-date copies of collections of changing Web\nresources. Such synchronization is currently achieved using ad-hoc or\nproprietary solutions. We propose ResourceSync, a general Web resource\nsynchronization protocol that leverages XML Sitemaps. It provides a set of\ncapabilities that can be combined in a modular manner to meet local or\ncommunity requirements. We report on work to implement this protocol for\narXiv.org and also provide an experimental prototype for the English Wikipedia\nas well as a client API."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1168-4", 
    "link": "http://arxiv.org/pdf/1305.1483v2", 
    "title": "Analyzing the citation characteristics of books: edited books, book   series and types of publishers in the Book Citation Index", 
    "arxiv-id": "1305.1483v2", 
    "author": "Evaristo Jim\u00e9nez-Contreras", 
    "publish": "2013-05-07T12:16:26Z", 
    "summary": "This paper presents a first approach to analyzing the factors that determine\nthe citation characteristics of books. For this we use the Thomson Reuters'\nBook Citation Index, a novel multidisciplinary database launched in 2010 which\noffers bibliometric data of books. We analyze three possible factors which are\nconsidered to affect the citation impact of books: the presence of editors, the\ninclusion in series and the type of publisher. Also, we focus on highly cited\nbooks to see if these factors may affect them as well. We considered as highly\ncited books, those in the top 5% of the most highly cited ones of the database.\nWe define these three aspects and we present the results for four major\nscientific areas in order to identify field-based differences (Science,\nEngineering & Technology, Social Sciences and Arts & Humanities). Finally we\nconclude observing that differences were noted for edited books and types of\npublishers. Although books included in series showed higher impact in two\nareas."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1168-4", 
    "link": "http://arxiv.org/pdf/1305.1488v1", 
    "title": "Most borrowed is most cited? Library loan statistics as a proxy for   monograph selection in citation indexes", 
    "arxiv-id": "1305.1488v1", 
    "author": "Juan Gorraiz", 
    "publish": "2013-05-07T12:31:39Z", 
    "summary": "This study aims to analyse whether library loans statistics can be used as a\nmeasure of monograph use and as a selection criteria for inclusion in citation\nindexes. For this, we conducted an exploratory study based on loan data (1000\nmost borrowed monographs) from two non-Anglo-Saxon European university\nlibraries (Granada and Vienna) with strong social sciences and humanities\ncomponents. Loans to scientists only were also analysed at the University of\nVienna. Furthermore, citation counts for the 100 most borrowed scientific\nmonographs (SM) and textbooks or manuals (MTB) were retrieved from Web of\nScience and Google Scholar. The results show considerable similarities in both\nlibraries: the percentage of loans for books in national languages represents\nalmost 96 per cent of the total share and SM accounts only for 10 to 13 per\ncent. When considering loans to scientists only, the percentage of English\nbooks increases to 30 per cent, the percentage of SM loans also increases\n(approx 80 per cent). Furthermore, we found no significant correlations between\nloans and citations. Since loan statistics are currently insufficient for\nmeasuring the use of monographs, their suggested use as an applicable selection\ncriterion for book citation indexes is not yet feasible. Data improvement and\naggregation at different levels is a challenge for modern libraries in order to\nenable the exploitation of this invaluable information source for scientometric\npurposes."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1168-4", 
    "link": "http://arxiv.org/pdf/1305.3328v1", 
    "title": "Riding the crest of the altmetrics wave: How librarians can help prepare   faculty for the next generation of research impact metrics", 
    "arxiv-id": "1305.3328v1", 
    "author": "Jason Priem", 
    "publish": "2013-05-15T00:46:53Z", 
    "summary": "As scholars migrate into online spaces like Mendeley, blogs, Twitter, and\nmore, they leave new traces of once-invisible interactions like reading,\nsaving, discussing, and recommending. Observing these traces can inform new\nmetrics of scholarly influence and impact -- so-called \"altmetrics.\"\nStakeholders in academia are beginning to discuss how and where altmetrics can\nbe useful towards evaluating a researcher's academic contribution. As this\ninterest grows, libraries are in a unique position to help support an informed\ndialog on campus. We suggest that librarians can provide this support in three\nmain ways: informing emerging conversations with the latest research,\nsupporting experimentation with emerging altmetrics tools, and engaging in\nearly altmetrics education and outreach. We include examples and lists of\nresources to help librarians fill these roles."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1168-4", 
    "link": "http://arxiv.org/pdf/1305.3506v4", 
    "title": "Micropublications: a Semantic Model for Claims, Evidence, Arguments and   Annotations in Biomedical Communications", 
    "arxiv-id": "1305.3506v4", 
    "author": "Carole A. Goble", 
    "publish": "2013-05-15T14:51:33Z", 
    "summary": "The Micropublications semantic model for scientific claims, evidence,\nargumentation and annotation in biomedical publications, is a metadata model of\nscientific argumentation, designed to support several key requirements for\nexchange and value-addition of semantic metadata across the biomedical\npublications ecosystem.\n  Micropublications allow formalizing the argument structure of scientific\npublications so that (a) their internal structure is semantically clear and\ncomputable; (b) citation networks can be easily constructed across large\ncorpora; (c) statements can be formalized in multiple useful abstraction\nmodels; (d) statements in one work may cite statements in another,\nindividually; (e) support, similarity and challenge of assertions can be\nmodelled across corpora; (f) scientific assertions, particularly in review\narticles, may be transitively closed to supporting evidence and methods.\n  The model supports natural language statements; data; methods and materials\nspecifications; discussion and commentary; as well as challenge and\ndisagreement. A detailed analysis of nine use cases is provided, along with an\nimplementation in OWL 2 and SWRL, with several example instantiations in RDF."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1168-4", 
    "link": "http://arxiv.org/pdf/1305.4890v1", 
    "title": "Extending Sitemaps for ResourceSync", 
    "arxiv-id": "1305.4890v1", 
    "author": "Herbert Van de Sompel", 
    "publish": "2013-05-21T17:19:04Z", 
    "summary": "The documents used in the ResourceSync synchronization framework are based on\nthe widely adopted document format defined by the Sitemap protocol. In order to\naddress requirements of the framework, extensions to the Sitemap format were\nnecessary. This short paper describes the concerns we had about introducing\nsuch extensions, the tests we did to evaluate their validity, and aspects of\nthe framework to address them."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-642-39320-4_26", 
    "link": "http://arxiv.org/pdf/1305.5655v1", 
    "title": "Math-Net.Ru as a Digital Archive of the Russian Mathematical Knowledge   from the XIX Century to Today", 
    "arxiv-id": "1305.5655v1", 
    "author": "Alexey B. Zhizhchenko", 
    "publish": "2013-05-24T08:58:34Z", 
    "summary": "The main goal of the project Math-Net.Ru is to collect scientific\npublications in Russian and Soviet mathematics journals since their foundation\nto today and the authors of these publications into a single database and to\nprovide access to full-text articles for broad international mathematical\ncommunity. Leading Russian mathematics journals have been comprehensively\ndigitized dating back to the first volumes."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-642-39320-4_26", 
    "link": "http://arxiv.org/pdf/1305.6026v1", 
    "title": "New Index for Quantifying an Individual's Scientific Research Output", 
    "arxiv-id": "1305.6026v1", 
    "author": "Mahmoud Abdel-Aty", 
    "publish": "2013-05-26T14:12:43Z", 
    "summary": "Classifying researchers according to the quality of their published work\nrather than the quantity is a curtail issue. We attempt to introduce a new\nformula of the percentage range to be used for evaluating qualitatively the\nresearchers' production. The suggested equation depends on the number of the\nsingle-author published papers and their citations to be added as a new factor\nto the known h-index. These factors give an advantage and make a clear evidence\nof innovative authors and reduce the known h-index for authors who are gaining\ncitations by adding their names to multi-author papers. It is shown that\nvarious dimensions of ethical integrity and originality will be effective in\nthis new index. An important scenario arising from the analysis is shown in\nterms of examples. It refers to larger differences between the h- and the new\nindex which comes from the whole work and the one comes from the single-author\npapers only, is shown."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-642-39320-4_26", 
    "link": "http://arxiv.org/pdf/1305.6800v1", 
    "title": "Ovopub: Modular data publication with minimal provenance", 
    "arxiv-id": "1305.6800v1", 
    "author": "Michel Dumontier", 
    "publish": "2013-05-29T13:51:24Z", 
    "summary": "With the growth of the Semantic Web as a medium for creating, consuming,\nmashing up and republishing data, our ability to trace any statement(s) back to\ntheir origin is becoming ever more important. Several approaches have now been\nproposed to associate statements with provenance, with multiple applications in\ndata publication, attribution and argumentation. Here, we describe the ovopub,\na modular model for data publication that enables encapsulation, aggregation,\nintegrity checking, and selective-source query answering. We describe the\novopub RDF specification, key design patterns and their application in the\npublication and referral to data in the life sciences."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-642-40501-3_25", 
    "link": "http://arxiv.org/pdf/1306.2866v2", 
    "title": "Hierarchical structuring of Cultural Heritage objects within large   aggregations", 
    "arxiv-id": "1306.2866v2", 
    "author": "Titia van der Werf", 
    "publish": "2013-06-12T15:40:48Z", 
    "summary": "Huge amounts of cultural content have been digitised and are available\nthrough digital libraries and aggregators like Europeana.eu. However, it is not\neasy for a user to have an overall picture of what is available nor to find\nrelated objects. We propose a method for hier- archically structuring cultural\nobjects at different similarity levels. We describe a fast, scalable clustering\nalgorithm with an automated field selection method for finding semantic\nclusters. We report a qualitative evaluation on the cluster categories based on\nrecords from the UK and a quantitative one on the results from the complete\nEuropeana dataset."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-642-40501-3_25", 
    "link": "http://arxiv.org/pdf/1306.2869v2", 
    "title": "Achieving interoperability between the CARARE schema for monuments and   sites and the Europeana Data Model", 
    "arxiv-id": "1306.2869v2", 
    "author": "Stavros Angelis", 
    "publish": "2013-06-12T15:44:46Z", 
    "summary": "Mapping between different data models in a data aggregation context always\npresents significant interoperability challenges. In this paper, we describe\nthe challenges faced and solutions developed when mapping the CARARE schema\ndesigned for archaeological and architectural monuments and sites to the\nEuropeana Data Model (EDM), a model based on Linked Data principles, for the\npurpose of integrating more than two million metadata records from national\nmonument collections and databases across Europe into the Europeana digital\nlibrary."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-642-40501-3_25", 
    "link": "http://arxiv.org/pdf/1306.3261v1", 
    "title": "arXiv e-prints and the journal of record: An analysis of roles and   relationships", 
    "arxiv-id": "1306.3261v1", 
    "author": "Mike Thelwall", 
    "publish": "2013-06-13T21:30:54Z", 
    "summary": "Since its creation in 1991, arXiv has become central to the diffusion of\nresearch in a number of fields. Combining data from the entirety of arXiv and\nthe Web of Science (WoS), this paper investigates (a) the proportion of papers\nacross all disciplines that are on arXiv and the proportion of arXiv papers\nthat are in the WoS, (b) elapsed time between arXiv submission and journal\npublication, and (c) the aging characteristics and scientific impact of arXiv\ne-prints and their published version. It shows that the proportion of WoS\npapers found on arXiv varies across the specialties of physics and mathematics,\nand that only a few specialties make extensive use of the repository. Elapsed\ntime between arXiv submission and journal publication has shortened but remains\nlonger in mathematics than in physics. In physics, mathematics, as well as in\nastronomy and astrophysics, arXiv versions are cited more promptly and decay\nfaster than WoS papers. The arXiv versions of papers - both published and\nunpublished - have lower citation rates than published papers, although there\nis almost no difference in the impact of the arXiv versions of both published\nand unpublished papers."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-642-40501-3_25", 
    "link": "http://arxiv.org/pdf/1306.3771v2", 
    "title": "The revised SNIP indicator of Elsevier's Scopus", 
    "arxiv-id": "1306.3771v2", 
    "author": "Loet Leydesdorff", 
    "publish": "2013-06-17T08:42:23Z", 
    "summary": "The modified SNIP indicator of Elsevier, as recently explained by Waltman et\nal. (2013) in this journal, solves some of the problems which Leydesdorff &\nOpthof (2010 and 2011) indicated in relation to the original SNIP indicator\n(Moed, 2010 and 2011). The use of an arithmetic average, however, remains\nunfortunate in the case of scientometric distributions because these can be\nextremely skewed (Seglen, 1992 and 1997). The new indicator cannot (or hardly)\nbe reproduced independently when used for evaluation purposes, and remains in\nthis sense opaque from the perspective of evaluated units and scholars."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1113-6", 
    "link": "http://arxiv.org/pdf/1306.4223v2", 
    "title": "Growth in the number of references in engineering journal papers during   the 1972-2013 period", 
    "arxiv-id": "1306.4223v2", 
    "author": "Joaqu\u00edn Sevilla", 
    "publish": "2013-06-18T14:53:59Z", 
    "summary": "The number of references per paper, perhaps the best single index of a\njournal's scholarliness, has been studied in different disciplines and periods.\nIn this paper we present a four decade study of eight engineering journals. A\ndata set of over 70000 references was generated after automatic data gathering\nand manual inspection for errors. Results show a significant increase in the\nnumber of references per paper, the average rises from 8 in 1972 to 25 in 2013.\nThis growth presents an acceleration around the year 2000, consistent with a\nmuch easier access to search engines and documents produced by the\ngeneralization of the Internet."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1113-6", 
    "link": "http://arxiv.org/pdf/1306.4856v1", 
    "title": "The potential of preprints to accelerate scholarly communication - A   bibliometric analysis based on selected journals", 
    "arxiv-id": "1306.4856v1", 
    "author": "Valeria Aman", 
    "publish": "2013-06-20T12:49:48Z", 
    "summary": "This paper quantifies to which extent preprints in arXiv accelerate scholarly\ncommunication. The following subject fields were investigated up to the year\n2012: High Energy Physics (HEP), Mathematics, Astrophysics, Quantitative\nBiology, and Library and Information Science (LIS). Publication and citation\ndata was downloaded from Scopus and matched with corresponding preprints in\narXiv. Furthermore, the INSPIRE HEP database was used to retrieve citation data\nfor papers related to HEP. The bibliometric analysis deals with the growth in\nnumbers of articles published having a previous preprint in arXiv and the\npublication delay, which is defined as the chronological distance between the\ndeposit of a preprint in arXiv and its formal journal publication. Likewise,\nthe citation delay is analyzed, which describes the time it takes until the\nfirst citation of preprints, and articles, respectively. Total citation numbers\nare compared for sets of articles with a previous preprint and those without.\nThe results show that in all fields but biology a significant citation\nadvantage exists in terms of speed and citation rates for articles with a\nprevious preprint version on arXiv."
},{
    "category": "cs.DL", 
    "doi": "10.3989/redc.2014.1.1114", 
    "link": "http://arxiv.org/pdf/1306.6584v2", 
    "title": "An introduction to the coverage of the Data Citation Index   (Thomson-Reuters): disciplines, document types and repositories", 
    "arxiv-id": "1306.6584v2", 
    "author": "Enrique Fuente-Guti\u00e9rrez", 
    "publish": "2013-06-27T17:43:33Z", 
    "summary": "In the past years, the movement of data sharing has been enjoying great\npopularity. Within this context, Thomson Reuters launched at the end of 2012 a\nnew product inside the Web of Knowledge family: the Data Citation Index. The\naim of this tool is to enable discovery and access, from a single place, to\ndata from a variety of data repositories from different subject areas and from\naround the world. In this short note we present some preliminary results from\nthe analysis of the Data Citation Index. Specifically, we address the following\nissues: discipline coverage, data types present in the database, and\nrepositories that were included at the time of the study"
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0068258", 
    "link": "http://arxiv.org/pdf/1307.0110v1", 
    "title": "Reviewers' ratings and bibliometric indicators: hand in hand when   assessing over research proposals?", 
    "arxiv-id": "1307.0110v1", 
    "author": "Evaristo Jim\u00e9nez-Contreras", 
    "publish": "2013-06-29T14:38:12Z", 
    "summary": "The peer review system has been traditionally challenged due to its many\nlimitations especially for allocating funding. Bibliometric indicators may well\npresent themselves as a complement. Objective: We analyze the relationship\nbetween peers' ratings and bibliometric indicators for Spanish researchers in\nthe 2007 National R&D Plan for 23 research fields. We analyze peers' ratings\nfor 2333 applications. We also gathered principal investigators' research\noutput and impact and studied the differences between accepted and rejected\napplications. We used the Web of Science database and focused on the 2002-2006\nperiod. First, we analyzed the distribution of granted and rejected proposals\nconsidering a given set of bibliometric indicators to test if there are\nsignificant differences. Then, we applied a multiple logistic regression\nanalysis to determine if bibliometric indicators can explain by themselves the\nconcession of grant proposals. 63.4% of the applications were funded.\nBibliometric indicators for accepted proposals showed a better previous\nperformance than for those rejected; however the correlation between peer\nreview and bibliometric indicators is very heterogeneous among most areas. The\nlogistic regression analysis showed that the main bibliometric indicators that\nexplain the granting of research proposals in most cases are the output (number\nof published articles) and the number of papers published in journals that\nbelong to the first quartile ranking of the Journal Citations Report.\nBibliometric indicators predict the concession of grant proposals at least as\nwell as peer ratings. Social Sciences and Education are the only areas where no\nrelation was found, although this may be due to the limitations of the Web of\nScience's coverage. These findings encourage the use of bibliometric indicators\nas a complement to peer review in most of the analyzed areas."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0068258", 
    "link": "http://arxiv.org/pdf/1307.0667v2", 
    "title": "From P100 to P100_: Conception and improvement of a new citation-rank   approach in bibliometrics", 
    "arxiv-id": "1307.0667v2", 
    "author": "Ruediger Mutz", 
    "publish": "2013-07-02T10:24:45Z", 
    "summary": "Properties of a percentile-based rating scale needed in bibliometrics are\nformulated. Based on these properties, P100 was recently introduced as a new\ncitation-rank approach (Bornmann, Leydesdorff, & Wang, in press). In this\npaper, we conceptualize P100 and propose an improvement which we call P100_.\nAdvantages and disadvantages of citation-rank indicators are noted."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0068258", 
    "link": "http://arxiv.org/pdf/1307.3616v1", 
    "title": "The \"Academic Trace\" of the Performance Matrix: A Mathematical Synthesis   of the h-Index and the Integrated Impact Indicator (I3)", 
    "arxiv-id": "1307.3616v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2013-07-13T06:34:44Z", 
    "summary": "The h-index provides us with nine natural classes which can be written as a\nmatrix of three vectors. The three vectors are: X=(X1, X2, X3) indicate\npublication distribution in the h-core, the h-tail, and the uncited ones,\nrespectively; Y=(Y1, Y2, Y3) denote the citation distribution of the h-core,\nthe h-tail and the so-called \"excess\" citations (above the h-threshold),\nrespectively; and Z=(Z1, Z2, Z3)= (Y1-X1, Y2-X2, Y3-X3). The matrix V=(X,Y,Z)T\nconstructs a measure of academic performance, in which the nine numbers can all\nbe provided with meanings in different dimensions. The \"academic trace\" tr(V)\nof this matrix follows naturally, and contributes a unique indicator for total\nacademic achievements by summarizing and weighting the accumulation of\npublications and citations. This measure can also be used to combine the\nadvantages of the h-index and the Integrated Impact Indicator (I3) into a\nsingle number with a meaningful interpretation of the values. We illustrate the\nuse of tr(V) for the cases of two journal sets, two universities, and ourselves\nas two individual authors."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0068258", 
    "link": "http://arxiv.org/pdf/1307.4329v1", 
    "title": "H Index of scientific Nursing journals according to Google Scholar   Metrics (2007-2011)", 
    "arxiv-id": "1307.4329v1", 
    "author": "Emilio Delgado Lopez-Cozar", 
    "publish": "2013-07-16T16:19:47Z", 
    "summary": "The aim of this report is to present a ranking of Nursing journals covered in\nGoogle Scholar Metrics (GSM), a Google product launched in 2012 to assess the\nimpact of scientific journals from citation counts this receive on Google\nScholar. Google has chosen to include only those journals that have published\nat least 100 papers and have at least one citation in a period of five years\n(2007-2011). Journal rankings are sorted by languages (showing the 100 papers\nwith the greatest impact). This tool allows to sort by subject areas and\ndisciplines, but only in the case of journals in English. In this case, it only\nshows the 20 journals with the highest h index. This option is not available\nfor journals in the other nine languages present in Google (Chinese,\nPortuguese, German, Spanish, French, Korean, Japanese, Dutch and Italian).\n  Google Scholar Metrics doesnt currently allow to group and sort all journals\nbelonging to a scientific discipline. In the case of Nursing, in the ten\nlistings displayed by GSM we can only locate 34 journals. Therefore, in an\nattempt to overcome this limitation, we have used the diversity of search\nprocedures allowed by GSM to identify the greatest number of scientific\njournals of Nursing with h index calculated by this bibliometric tool.\nBibliographic searches were conducted between 10th and 30th May 2013.\n  The result is a ranking of 337 nursing journals sorted by the same h index,\nand mean as discriminating value. Journals are also grouped by quartiles."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0068258", 
    "link": "http://arxiv.org/pdf/1307.5685v1", 
    "title": "An Evaluation of Caching Policies for Memento TimeMaps", 
    "arxiv-id": "1307.5685v1", 
    "author": "Michael L. Nelson", 
    "publish": "2013-07-22T12:53:10Z", 
    "summary": "As defined by the Memento Framework, TimeMaps are ma-chine-readable lists of\ntime-specific copies -- called \"mementos\" -- of an archived original resource.\nIn theory, as an archive acquires additional mementos over time, a TimeMap\nshould be monotonically increasing. However, there are reasons why the number\nof mementos in a TimeMap would decrease, for example: archival redaction of\nsome or all of the mementos, archival restructuring, and transient errors on\nthe part of one or more archives. We study TimeMaps for 4,000 original\nresources over a three month period, note their change patterns, and develop a\ncaching algorithm for TimeMaps suitable for a reverse proxy in front of a\nMemento aggregator. We show that TimeMap cardinality is constant or\nmonotonically increasing for 80.2% of all TimeMap downloads observed in the\nobservation period. The goal of the caching algorithm is to exploit the ideally\nmonotonically increasing nature of TimeMaps and not cache responses with fewer\nmementos than the already cached TimeMap. This new caching algorithm uses\nconditional cache replacement and a Time To Live (TTL) value to ensure the user\nhas access to the most complete TimeMap available. Based on our empirical data,\na TTL of 15 days will minimize the number of mementos missed by users, and\nminimize the load on archives contributing to TimeMaps."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0068258", 
    "link": "http://arxiv.org/pdf/1307.6760v1", 
    "title": "Quantitative CV-based indicators for research quality, validated by peer   review", 
    "arxiv-id": "1307.6760v1", 
    "author": "Nadine Rons", 
    "publish": "2013-07-25T14:46:21Z", 
    "summary": "In a university, research assessments are organized at different policy\nlevels (faculties, research council) in different contexts (funding, council\nmembership, personnel evaluations). Each evaluation requires its own focus and\nmethodology. To conduct a coherent research policy however, data on which\ndifferent assessments are based should be well coordinated. A common set of\ncore indicators for any type of research assessment can provide a supportive\nand objectivating tool for evaluations at different institutional levels and at\nthe same time promote coherent decision-making. The same indicators can also\nform the basis for a 'light touch' monitoring instrument, signalling when and\nwhere a more thorough evaluation could be considered. This poster paper shows\nhow peer review results were used to validate a set of quantitative indicators\nfor research quality for a first series of disciplines. The indicators\ncorrespond to categories in the university's standard CV-format. Per\ndiscipline, specific indicators are identified corresponding to their own\npublication and funding characteristics. Also more globally valid indicators\nare identified after normalization for discipline-characteristic performance\nlevels. The method can be applied to any system where peer ratings and\nquantitative performance measures, both reliable and sufficiently detailed, can\nbe combined for the same entities."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0068258", 
    "link": "http://arxiv.org/pdf/1307.6765v1", 
    "title": "Composing a Publication List for Individual Researcher Assessment by   Merging Information from Different Sources", 
    "arxiv-id": "1307.6765v1", 
    "author": "Nadine Rons", 
    "publish": "2013-07-25T14:57:55Z", 
    "summary": "Citation and publication profiles are gaining importance for the evaluation\nof top researchers when it comes to the appropriation of funding for excellence\nprograms or career promotion judgments. Indicators like the Normalized Mean\nCitation Rate, the hindex or other distinguishing measures are increasingly\nused to picture the characteristics of individual scholars. Using bibliometric\ntechniques for individual assessment is known to be particularly delicate, as\nthe chance of errors being averaged away becomes smaller whereas a minor\nincompleteness can have a significant influence on the evaluation outcome. The\nquality of the data becomes as such crucial to the legitimacy of the methods\nused."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0068258", 
    "link": "http://arxiv.org/pdf/1307.6770v1", 
    "title": "Impact Vitality - A Measure for Excellent Scientists", 
    "arxiv-id": "1307.6770v1", 
    "author": "Lucy Amez", 
    "publish": "2013-07-25T15:04:43Z", 
    "summary": "In many countries and at European level, research policy increasingly focuses\non 'excellent' researchers. The concept of excellence however is complex and\nmultidimensional. For individual scholars it involves talents for innovative\nknowledge creation and successful transmission to peers, as well as management\ncapacities. Excellence is also a comparative concept, implying the ability to\nsurpass others [TIJSSEN, 2003]. Grants are in general awarded based on\nassessments by expert committees. While peer review is a widely accepted\npractice, it nevertheless is also subject to criticism. At higher aggregation\nlevels, peer assessments are often supported by quantitative measures. At\nindividual level, most of these measures are much less appropriate and there is\na need for new, dedicated indicators."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0068258", 
    "link": "http://arxiv.org/pdf/1307.6773v1", 
    "title": "Quality related publication categories in social sciences and   humanities, based on a university's peer review assessments", 
    "arxiv-id": "1307.6773v1", 
    "author": "Arlette De Bruyn", 
    "publish": "2013-07-25T15:10:14Z", 
    "summary": "Bibliometric analysis has firmly conquered its place as an instrument for\nevaluation and international comparison of performance levels. Consequently,\ndifferences in coverage by standard bibliometric databases installed a\ndichotomy between on the one hand the well covered 'exact' sciences, and on the\nother hand most of the social sciences and humanities with a more limited\ncoverage (Nederhof, 2006). Also the latter domains need to be able to soundly\ndemonstrate their level of performance and claim or legitimate funding\naccordingly. An important part of the output volume in social sciences appears\nas books, book chapters and national literature (Hicks, 2004). To proceed from\npublication data to performance measurement, quantitative publication counts\nneed to be combined with qualitative information, for example from peer\nassessment or validation (European Expert Group on Assessment of\nUniversity-Based Research, 2010), to identify those categories that represent\nresearch quality as perceived by peers. An accurate focus is crucial in order\nto stimulate, recognize and reward high quality achievements only. This paper\ndemonstrates how such a selection of publication categories can be based on\ncorrelations with peer judgments. It is also illustrated that the selection\nshould be sufficiently precise, to avoid subcategories negatively correlated\nwith peer judgments. The findings indicate that, also in social sciences and\nhumanities, publications in journals with an international referee system are\nthe most important category for evaluating quality. Book chapters with\ninternational referee system and contributions in international conference\nproceedings follow them."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0068258", 
    "link": "http://arxiv.org/pdf/1307.6778v1", 
    "title": "Output and citation impact of interdisciplinary networks: Experiences   from a dedicated funding program", 
    "arxiv-id": "1307.6778v1", 
    "author": "Nadine Rons", 
    "publish": "2013-07-25T15:14:50Z", 
    "summary": "In a context of ever more specialized scientists, interdisciplinarity\nreceives increasing attention as innovating ideas are often situated where the\ndisciplines meet. In many countries science policy makers installed dedicated\nfunding programs and policies. This induces a need for specific tools for their\nsupport. There is however not yet a generally accepted quantitative method or\nset of criteria to recognize and evaluate interdisciplinary research outputs\n(Tracking and evaluating interdisciplinary research: metrics and maps, 12th\nISSI Conference, 2009). Interdisciplinarity also takes on very different forms,\nas distinguished in overviews from the first codifications (Klein, 1990) to the\nlatest reference work (Frodeman et al., 2010). In the specific context of\nresearch measurement and evaluation, interdisciplinarity was discussed e.g. by\nRinia (2007) and Porter et al. (2006). This empirical study aims to contribute\nto the understanding and the measuring of interdisciplinary research at the\nmicro level, in the form of new synergies between disciplines. Investigation of\na specialized funding program shows how a new interdisciplinary synergy and its\ncitation impact are visible in co-publications and cocitations, and that these\nare important parameters for assessment. The results also demonstrate the\neffect of funding, which is clearly present after about three years."
},{
    "category": "cs.DL", 
    "doi": "10.1080/09737766.2011.10700900", 
    "link": "http://arxiv.org/pdf/1307.6784v2", 
    "title": "Interdisciplinary Research Collaborations: Evaluation of a Funding   Program", 
    "arxiv-id": "1307.6784v2", 
    "author": "Nadine Rons", 
    "publish": "2013-07-25T15:20:42Z", 
    "summary": "Innovative ideas are often situated where disciplines meet, and\nsocio-economic problems generally require contributions from several\ndisciplines. Ways to stimulate interdisciplinary research collaborations are\ntherefore an increasing point of attention for science policy. There is concern\nthat 'regular' funding programs, involving advice from disciplinary experts and\ndiscipline-bound viewpoints, may not adequately stimulate, select or evaluate\nthis kind of research. This has led to specific policies aimed at\ninterdisciplinary research in many countries. There is however at this moment\nno generally accepted method to adequately select and evaluate\ninterdisciplinary research. In the vast context of different forms of\ninterdisciplinarity, this paper aims to contribute to the debate on best\npractices to stimulate and support interdisciplinary research collaborations.\nIt describes the selection procedures and results of a university program\nsupporting networks formed 'bottom up', integrating expertise from different\ndisciplines. The program's recent evaluation indicates that it is successful in\nselecting and supporting the interdisciplinary synergies aimed for, responding\nto a need experienced in the field. The analysis further confirms that\npotential for interdisciplinary collaboration is present in all disciplines."
},{
    "category": "cs.DL", 
    "doi": "10.1080/09737766.2011.10700900", 
    "link": "http://arxiv.org/pdf/1307.6791v1", 
    "title": "Research Excellence Milestones of BRIC and N-11 Countries", 
    "arxiv-id": "1307.6791v1", 
    "author": "Nadine Rons", 
    "publish": "2013-07-25T15:26:45Z", 
    "summary": "While scientific performance is an important aspect of a stable and healthy\neconomy, measures for it have yet to gain their place in economic country\nprofiles. As useful indicators for this performance dimension, this paper\nintroduces the concept of milestones for research excellence, as points of\ntransition to higher-level contributions at the leading edge of science. The\nproposed milestones are based on two indicators associated with research\nexcellence, the impact vitality profile and the production of review type\npublications, both applied to a country's publications in the top journals\nNature and Science. The milestones are determined for two distinct groups of\nemerging market economies: the BRIC countries, which outperformed the relative\ngrowth expected at their identification in 2001, and the N-11 or Next Eleven\ncountries, identified in 2005 as potential candidates for a BRIC-like\nevolution. Results show how these two groups at different economic levels can\nbe clearly distinguished based on the research milestones, indicating a\npotential utility as parameters in an economic context."
},{
    "category": "cs.DL", 
    "doi": "10.1080/09737766.2011.10700900", 
    "link": "http://arxiv.org/pdf/1307.6792v1", 
    "title": "Characteristics of International versus Non-International Scientific   Publication Media in Team- and Author-Based Data", 
    "arxiv-id": "1307.6792v1", 
    "author": "Nadine Rons", 
    "publish": "2013-07-25T15:30:44Z", 
    "summary": "The enlarged coverage of the international publication and citation databases\nWeb of Science and Scopus towards local media in social sciences was a welcome\nresponse to an increased usage of these databases in evaluation and funding\nsystems. The mostly international journals available earlier were the basis for\nthe development of current standard bibliometric indicators. The same\nindicators may no longer measure exactly the same concepts when applied to\nnewly introduced or extended media categories, with possibly different\ncharacteristics than those of international journals. This paper investigates\ndifferences between media with and without international dimension in\npublication data at team and author level. The findings relate the\ninternational publication categories to research quality, important for\nvalidation of their usage in evaluation or funding models that aim to stimulate\nquality."
},{
    "category": "cs.DL", 
    "doi": "10.1080/09737766.2011.10700900", 
    "link": "http://arxiv.org/pdf/1307.6797v1", 
    "title": "Groups of Highly Cited Publications: Stability in Content with Citation   Window Length", 
    "arxiv-id": "1307.6797v1", 
    "author": "Nadine Rons", 
    "publish": "2013-07-25T15:39:41Z", 
    "summary": "The growing focus in research policy worldwide on top scientists makes it\nincreasingly important to define adequate supporting measures to help identify\nexcellent scientists. Highly cited publications have since long been associated\nto research excellence. At the same time, the analysis of the high-end of\ncitation distributions still is a challenging topic in evaluative\nbibliometrics. Evaluations typically require indicators that generate\nsufficiently stable results when applied to recent publication records of\nlimited size. Highly cited publications have been identified using two\ntechniques in particular: pre-set percentiles, and the parameter free\nCharacteristic Scores and Scales (CSS) (Gl\\\"anzel & Schubert, 1988). The\nstability required in assessments of relatively small publication records,\nconcerns size as well as content of groups of highly cited publications.\nInfluencing factors include domain delineation and citation window length.\nStability in size is evident for the pre-set percentiles, and has been\ndemonstrated for the CSS-methodology beyond an initial citation period of about\nthree years (Gl\\\"anzel, 2007). Stability in content is less straightforward,\nconsidering for instance that more highly cited publications can have a later\ncitation peak, as observed by Abt (1981) for astronomical papers. This paper\ninvestigates the stability in content of groups of highly cited publications,\ni.e. the extent to which individual publications enter and leave the group as\nthe citation window is enlarged."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2012.09.001", 
    "link": "http://arxiv.org/pdf/1307.6804v1", 
    "title": "Partition-based Field Normalization: An approach to highly specialized   publication records", 
    "arxiv-id": "1307.6804v1", 
    "author": "Nadine Rons", 
    "publish": "2013-07-25T16:22:21Z", 
    "summary": "Field normalized citation rates are well-established indicators for research\nperformance from the broadest aggregation levels such as countries, down to\ninstitutes and research teams. When applied to still more specialized\npublication sets at the level of individual scientists, also a more accurate\ndelimitation is required of the reference domain that provides the expectations\nto which a performance is compared. This necessity for sharper accuracy\nchallenges standard methodology based on predefined subject categories. This\npaper proposes a way to define a reference domain that is more strongly\ndelimited than in standard methodology, by building it up out of cells of the\npartition created by the pre-defined subject categories and their\nintersections. This partition approach can be applied to different existing\nfield normalization variants. The resulting reference domain lies between those\ngenerated by standard field normalization and journal normalization. Examples\nbased on fictive and real publication records illustrate how the potential\nimpact on results can exceed or be smaller than the effect of other currently\ndebated normalization variants, depending on the case studied. The proposed\nPartition-based Field Normalization is expected to offer advantages in\nparticular at the level of individual scientists and other very specific\npublication records, such as publication output from interdisciplinary\nresearch."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2012.09.001", 
    "link": "http://arxiv.org/pdf/1307.6941v1", 
    "title": "Google Scholar Metrics 2013: nothing new under the sun", 
    "arxiv-id": "1307.6941v1", 
    "author": "Emilio Delgado Lopez-Cozar", 
    "publish": "2013-07-26T07:20:44Z", 
    "summary": "Main characteristics of Google Scholar Metrics new version (july 2013) are\npresented. We outline the novelties and the weaknesses detected after a first\nanalysis. As main conclusion, we remark the lack of new functionalities with\nrespect to last editions, as the only modification is the update of the\ntimeframe (2008-2012). Hence, problems pointed out in our last reviews still\nremain active. Finally, it seems Google Scholar Metrics will be updated in a\nyearly basis"
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2012.09.001", 
    "link": "http://arxiv.org/pdf/1307.7031v1", 
    "title": "Reliability and Comparability of Peer Review Results", 
    "arxiv-id": "1307.7031v1", 
    "author": "Eric Spruyt", 
    "publish": "2013-07-26T13:38:13Z", 
    "summary": "In this paper peer review reliability is investigated based on peer ratings\nof research teams at two Belgian universities. It is found that outcomes can be\nsubstantially influenced by the different ways in which experts attribute\nratings. To increase reliability of peer ratings, procedures creating a uniform\nreference level should be envisaged. One should at least check for signs of low\nreliability, which can be obtained from an analysis of the outcomes of the peer\nevaluation itself. The peer review results are compared to outcomes from a\ncitation analysis of publications by the same teams, in subject fields well\ncovered by citation indexes. It is illustrated how, besides reliability,\ncomparability of results depends on the nature of the indicators, on the\nsubject area and on the intrinsic characteristics of the methods. The results\nfurther confirm what is currently considered as good practice: the presentation\nof results for not one but for a series of indicators."
},{
    "category": "cs.DL", 
    "doi": "10.3152/095820208X240208", 
    "link": "http://arxiv.org/pdf/1307.7033v1", 
    "title": "Research evaluation per discipline: a peer-review method and its   outcomes", 
    "arxiv-id": "1307.7033v1", 
    "author": "Jan Cornelis", 
    "publish": "2013-07-26T13:44:08Z", 
    "summary": "This paper describes the method for ex-post peer review evaluation per\nresearch discipline used at the Vrije Universiteit Brussel (VUB) and summarizes\nthe outcomes obtained from it. The method produces pertinent advice and\ntriggers responses - at the level of the individual researcher, the research\nteam and the university's research management - for the benefit of research\nquality, competitivity and visibility. Imposed reflection and contacts during\nand after the evaluation procedure modify the individual researcher's attitude,\nimprove the research teams' strategies and allow for the extraction of general\nrecommendations that are used as discipline-dependent guidelines in the\nuniversity's research management. The deep insights gained in the different\nresearch disciplines and the substantial data sets on their research, support\nthe university management in its policy decisions and in building policy\ninstruments. Moreover, the results are used as a basis for comparison with\nother assessments, leading to a better understanding of the possibilities and\nlimitations of different evaluation processes. The peer review method can be\napplied systematically in a pluri-annual cycle of research discipline\nevaluations to build up a complete overview, or it can be activated on an ad\nhoc basis for a particular discipline, based on demands from research teams or\non strategic or policy arguments."
},{
    "category": "cs.DL", 
    "doi": "10.3152/095820209X470563", 
    "link": "http://arxiv.org/pdf/1307.7035v1", 
    "title": "Impact vitality: an indicator based on citing publications in search of   excellent scientists", 
    "arxiv-id": "1307.7035v1", 
    "author": "Lucy Amez", 
    "publish": "2013-07-26T13:48:36Z", 
    "summary": "This paper contributes to the quest for an operational definition of\n'research excellence' and proposes a translation of the excellence concept into\na bibliometric indicator. Starting from a textual analysis of funding program\ncalls aimed at individual researchers and from the challenges for an indicator\nat this level in particular, a new type of indicator is proposed. The Impact\nVitality indicator [RONS & AMEZ, 2008] reflects the vitality of the impact of a\nresearcher's publication output, based on the change in volume over time of the\nciting publications. The introduced metric is shown to posses attractive\noperational characteristics and meets a number of criteria which are desirable\nwhen comparing individual researchers. The validity of one of the possible\nindicator variants is tested using a small dataset of applicants for a senior\nfull time Research Fellowship. Options for further research involve testing\nvarious indicator variants on larger samples linked to different kinds of\nevaluations."
},{
    "category": "cs.DL", 
    "doi": "10.3152/095820209X470563", 
    "link": "http://arxiv.org/pdf/1307.8067v1", 
    "title": "On the Change in Archivability of Websites Over Time", 
    "arxiv-id": "1307.8067v1", 
    "author": "Michael L. Nelson", 
    "publish": "2013-07-30T17:52:38Z", 
    "summary": "As web technologies evolve, web archivists work to keep up so that our\ndigital history is preserved. Recent advances in web technologies have\nintroduced client-side executed scripts that load data without a referential\nidentifier or that require user interaction (e.g., content loading when the\npage has scrolled). These advances have made automating methods for capturing\nweb pages more difficult. Because of the evolving schemes of publishing web\npages along with the progressive capability of web preservation tools, the\narchivability of pages on the web has varied over time. In this paper we show\nthat the archivability of a web page can be deduced from the type of page being\narchived, which aligns with that page's accessibility in respect to dynamic\ncontent. We show concrete examples of when these technologies were introduced\nby referencing mementos of pages that have persisted through a long evolution\nof available technologies. Identifying these reasons for the inability of these\nweb pages to be archived in the past in respect to accessibility serves as a\nguide for ensuring that content that has longevity is published using good\npractice methods that make it available for preservation."
},{
    "category": "cs.DL", 
    "doi": "10.3152/095820209X470563", 
    "link": "http://arxiv.org/pdf/1307.8239v1", 
    "title": "Detecting the historical roots of research fields by reference   publication year spectroscopy (RPYS)", 
    "arxiv-id": "1307.8239v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2013-07-31T07:38:30Z", 
    "summary": "We introduce the quantitative method named \"reference publication year\nspectroscopy\" (RPYS). With this method one can determine the historical roots\nof research fields and quantify their impact on current research. RPYS is based\non the analysis of the frequency with which references are cited in the\npublications of a specific research field in terms of the publication years of\nthese cited references. The origins show up in the form of more or less\npronounced peaks mostly caused by individual publications which are cited\nparticularly frequently. In this study, we use research on graphene and on\nsolar cells to illustrate how RPYS functions, and what results it can deliver."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2508497.2508500", 
    "link": "http://arxiv.org/pdf/1310.1968v1", 
    "title": "First Author Advantage: Citation Labeling in Research", 
    "arxiv-id": "1310.1968v1", 
    "author": "Jinyun Yan", 
    "publish": "2013-10-07T22:28:28Z", 
    "summary": "Citations among research papers, and the networks they form, are the primary\nobject of study in scientometrics. The act of making a citation reflects the\nciter's knowledge of the related literature, and of the work being cited. We\naim to gain insight into this process by studying citation keys: user-chosen\nlabels to identify a cited work. Our main observation is that the first listed\nauthor is disproportionately represented in such labels, implying a strong\nmental bias towards the first author."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-319-08425-1_22", 
    "link": "http://arxiv.org/pdf/1310.3370v2", 
    "title": "Talking With Scholars: Developing a Research Environment for Oral   History Collections", 
    "arxiv-id": "1310.3370v2", 
    "author": "Roeland Ordelman", 
    "publish": "2013-10-12T13:32:17Z", 
    "summary": "Scholars are yet to make optimal use of Oral History collections. For the\nuptake of digital research tools in the daily working practice of researchers,\npractices and conventions commonly adhered to in the subfields in the\nhumanities should be taken into account during development. To this end, in the\nOral History Today project a research tool for exploring Oral History\ncollections is developed in close collaboration with scholarly researchers.\nThis paper describes four stages of scholarly research and the first steps\nundertaken to incorporate requirements of these stages in a digital research\nenvironment."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijdkp.2013.3501", 
    "link": "http://arxiv.org/pdf/1310.4900v1", 
    "title": "GV-Index:Scientific Contribution Rating Index That Takes into Account   the Growth Degree of Research Area and Variance Values of the Publication   Year of Cited Paper", 
    "arxiv-id": "1310.4900v1", 
    "author": "Masayoshi Kawamura", 
    "publish": "2013-10-18T03:38:06Z", 
    "summary": "There are a wide variety of scientific contribution rating indices including\nthe impact factor and h-index. These are used for quantitative analyses on\nresearch papers published in the past, and therefore unable to incorporate in\nthe assessment the growth, or deterioration, of the research area: whether the\nresearch area of a particular paper is in decline or conversely in a growing\ntrend. Other hand, the use of the conventional rating indices may result in\nhigher rates for papers that are hardly referenced nowadays in other papers\nalthough frequently cited in the past. This study proposes a new type of\nscientific contribution ranking index, \"Growing Degree of Research Area and\nVariance Values Index (GV-Index)\". The GV-Index is computed by a principal\ncomponent analysis based on an estimated value obtained by PageRank Algorithm,\nwhich takes into account the growing degree of the research area and its\nvariance. We also propose visualization system of a scientist's network using\nthe GV-Index."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijdkp.2013.3506", 
    "link": "http://arxiv.org/pdf/1310.4904v1", 
    "title": "Dynamic Extraction of Key Paper from the Cluster Using Variance Values   of Cited Literature", 
    "arxiv-id": "1310.4904v1", 
    "author": "Akira Otsuki", 
    "publish": "2013-10-18T03:43:40Z", 
    "summary": "When looking into recent research trends in the field of academic landscape,\ncitation network analysis is common and automated clustering of many academic\npapers has been achieved by making good use of various techniques. However,\nspecifying the features of each area identified by automated clustering or\ndynamically extracted key papers in each research area has not yet been\nachieved. In this study, therefore, we propose a method for dynamically\nspecifying the key papers in each area identified by clustering. We will\ninvestigate variance values of the publication year of the cited literature and\ncalculate each cited paper's importance by applying the variance values to the\nPageRank algorithm."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijdkp.2013.3506", 
    "link": "http://arxiv.org/pdf/1310.4966v3", 
    "title": "Journal Maps, Interactive Overlays, and the Measurement of   Interdisciplinarity on the Basis of Scopus Data (1996-2012)", 
    "arxiv-id": "1310.4966v3", 
    "author": "Vicente P. Guerrero-Bote", 
    "publish": "2013-10-18T10:17:30Z", 
    "summary": "Using Scopus data, we construct a global map of science based on aggregated\njournal-journal citations from 1996-2012 (N of journals = 20,554). This base\nmap enables users to overlay downloads from Scopus interactively. Using a\nsingle year (e.g., 2012), results can be compared with mappings based on the\nJournal Citation Reports at the Web-of-Science (N = 10,936). The Scopus maps\nare more detailed at both the local and global levels because of their greater\ncoverage, including, for example, the arts and humanities. The base maps can be\ninteractively overlaid with journal distributions in sets downloaded from\nScopus, for example, for the purpose of portfolio analysis. Rao-Stirling\ndiversity can be used as a measure of interdisciplinarity in the sets under\nstudy. Maps at the global and the local level, however, can be very different\nbecause of the different levels of aggregation involved. Two journals, for\nexample, can both belong to the humanities in the global map, but participate\nin different specialty structures locally. The base map and interactive tools\nare available online (with instructions) at\nhttp://www.leydesdorff.net/scopus_ovl."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1001-0", 
    "link": "http://arxiv.org/pdf/1310.5812v1", 
    "title": "U.S. academic libraries: understanding their web presence and their   relationship with economic indicators", 
    "arxiv-id": "1310.5812v1", 
    "author": "John J. Regazzi", 
    "publish": "2013-10-22T06:49:53Z", 
    "summary": "The main goal of this research is to analyze the web structure and\nperformance of units and services belonging to U.S. academic libraries in order\nto check their suitability for webometric studies. Our objectives include\nstudying their possible correlation with economic data and assessing their use\nfor complementary evaluation purposes. We conducted a survey of library\nhomepages, institutional repositories, digital collections, and online catalogs\n(a total of 374 URLs) belonging to the 100 U.S. universities with the highest\ntotal expenditures in academic libraries according to data provided by the\nNational Center for Education Statistics (NCES). Several data points were taken\nand analyzed, including web variables (page count, external links, and visits)\nand economic variables (total expenditures, expenditures on printed and\nelectronic books, and physical visits). The results indicate that the variety\nof URL syntaxes is wide, diverse and complex, which produces a\nmisrepresentation of academic library web resources and reduces the accuracy of\nweb analysis. On the other hand, institutional and web data indicators are not\nhighly correlated. Better results are obtained by correlating total library\nexpenditures with URL mentions measured by Google (r= 0.546) and visits\nmeasured by Compete (r= 0.573), respectively. Because correlation values\nobtained are not highly significant, we estimate such correlations will\nincrease if users can avoid linkage problems (due to the complexity of URLs)\nand gain direct access to log files (for more accurate data about visits)."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.22912", 
    "link": "http://arxiv.org/pdf/1310.5814v1", 
    "title": "Aggregation of the web performance of internal university units as a   method of quantitative analysis of a university system: the case of Spain", 
    "arxiv-id": "1310.5814v1", 
    "author": "Enrique Ordu\u00f1a-Malea", 
    "publish": "2013-10-22T06:56:07Z", 
    "summary": "The aggregation of web performance (page count and visibility) of internal\nuniversity units could constitute a more precise indicator than the overall web\nperformance of the universities and, therefore, be of use in the design of\nuniversity web rankings. In order to test this hypothesis, a longitudinal\nanalysis of the internal units of the Spanish university system was conducted\nover the course of 2010. For the 13800 URLs identified, page count and\nvisibility was calculated using the Yahoo API. The internal values obtained\nwere aggregated by university and compared with the values obtained from the\nanalysis of the university general URLs. The results indicate that, although\nthe correlations between general and internal values are high, internal\nperformance is low in comparison to general performance, and that they give\nrise to different performance rankings. The conclusion is that the aggregation\nof unit performance is of limited use due to the low levels of internal\ndevelopment of the websites, and so its use is not recommended for the design\nof rankings. Despite this, the internal analysis enabled the detection of,\namongst other things, a low correlation between page count and visibility due\nto the widespread use of subdirectories and problems accessing certain content."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-012-0868-5", 
    "link": "http://arxiv.org/pdf/1310.5816v1", 
    "title": "Proposal for a multilevel university cybermetric analysis model", 
    "arxiv-id": "1310.5816v1", 
    "author": "Jos\u00e9-Antonio Ontalba-Ruip\u00e9rez", 
    "publish": "2013-10-22T07:03:02Z", 
    "summary": "University online seats have gradually become complex systems of dynamic\ninformation where all their institutions and services are linked and\npotentially accessible. These online seats now constitute a central node around\nwhich universities construct and document their main activities and services.\nThis information can be quantitative measured by cybermetric techniques in\norder to design university web rankings, taking the university as a global\nreference unit. However, previous research into web subunits shows that it is\npossible to carry out systemic web analyses, which open up the possibility of\ncarrying out studies which address university diversity, necessary for both\ndescribing the university in greater detail and for establishing comparable\nranking units. To address this issue, a multilevel university cybermetric\nanalysis model is proposed, based on parts (core and satellite), levels\n(institutional and external) and sublevels (contour and internal), providing a\ndeeper analysis of institutions. Finally the model is integrated into another\nwhich is independent of the technique used, and applied by analysing Harvard\nUniversity as an example of use."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1157-7", 
    "link": "http://arxiv.org/pdf/1310.5892v1", 
    "title": "What do university rankings by fields rank? Exploring discrepancies   between the organizational structure of universities and bibliometric   classifications", 
    "arxiv-id": "1310.5892v1", 
    "author": "Clara Calero-Medina", 
    "publish": "2013-10-22T12:33:32Z", 
    "summary": "University rankings by fields are usually based on the research output of\nuniversities. However, research managers and rankings consumers expect to see\nin such fields a reflection of the structure of their own organizational\ninstitution. In this study we address such misinterpretation by developing the\nresearch profile of the organizational units of two Spanish universities:\nUniversity of Granada and Pompeu Fabra University. We use two classification\nsystems, the subject categories offered by Thomson Scientific which are\ncommonly used on bibliometric studies, and the 37 disciplines displayed by the\nSpanish I-UGR Rankings which are constructed from an aggregation of the former.\nWe also describe in detail problems encountered when working with address data\nfrom a top down approach and we show differences between universities\nstructures derived from the interdisciplinary organizational forms of new\nmanagerialism at universities. We conclude by highlighting that rankings by\nfields should clearly state the methodology for the construction of such\nfields. We indicate that the construction of research profiles may be a good\nsolution for universities for finding out levels of discrepancy between\norganizational units and subject fields."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1157-7", 
    "link": "http://arxiv.org/pdf/1310.6162v1", 
    "title": "Google Scholar Metrics evolution: an analysis according to languages", 
    "arxiv-id": "1310.6162v1", 
    "author": "Emilio Delgado Lopez-Cozar", 
    "publish": "2013-10-23T09:30:11Z", 
    "summary": "In November 2012 the Google Scholar Metrics (GSM) journal rankings were\nupdated, making it possible to compare bibliometric indicators in the 10\nlanguages indexed and their stability with the April 2012 version. The h-index\nand h 5 median of 1000 journals were analysed, comparing their averages,\nmaximum and minimum values and the correlation coefficient within rankings. The\nbibliometric figures grew significantly. In just seven and a half months the h\nindex of the journals increased by 15% and the median h-index by 17%. This\ngrowth was observed for all the bibliometric indicators analysed and for\npractically every journal. However, we found significant differences in growth\nrates depending on the language in which the journal is published. Moreover,\nthe journal rankings seem to be stable between April and November, reinforcing\nthe credibility of the data held by Google Scholar and the reliability of the\nGSM journal rankings, despite the uncontrolled growth of Google Scholar. Based\non the findings of this study we suggest, firstly, that Google should upgrade\nits rankings at least semiannually and, secondly, that the results should be\ndisplayed in each ranking proportionally to the number of journals indexed by\nlanguage"
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1157-7", 
    "link": "http://arxiv.org/pdf/1310.7378v1", 
    "title": "H Index Communication Journals according to Google Scholar Metrics   (2008-2012)", 
    "arxiv-id": "1310.7378v1", 
    "author": "Emilio Delgado Lopez-Cozar", 
    "publish": "2013-10-28T11:19:11Z", 
    "summary": "The aim of this report is to present a ranking of Communication journals\ncovered in Google Scholar Metrics for the period 2008-2012. It corresponds to\nthe H Index update made last year for the period 2007-2011 (Delgado\nL\\'opez-C\\'ozar and Repiso 2013). Google Scholar Metrics doesnt currently allow\nto group and sort all journals belonging to a scientific discipline. In the\ncase of Communication, in the ten listings displayed by GSM we can only locate\n46 journals. Therefore, in an attempt to overcome this limitation, we have used\nthe diversity of search procedures allowed by GSM to identify the greatest\nnumber of scientific journals of Communication with H Index calculated by this\nbibliometric tool. The result is a ranking of 354 communication journals sorted\nby the same H Index, and mean as discriminating value. Journals are also\ngrouped by quartiles."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1157-7", 
    "link": "http://arxiv.org/pdf/1312.1258v1", 
    "title": "Flexible and Extensible Digital Object and Repository Architecture   (FEDORA)", 
    "arxiv-id": "1312.1258v1", 
    "author": "Carl Lagoze", 
    "publish": "2013-12-04T17:52:13Z", 
    "summary": "We describe a digital object and respository architecture for storing and\ndisseminating digital library content. The key features of the architecture\nare: (1) support for heterogeneous data types; (2) accommodation of new types\nas they emerge; (3) aggregation of mixed, possibly distributed, data into\ncomplex objects; (4) the ability to specify multiple content disseminations of\nthese objects; and (5) the ability to associate rights management schemes with\nthese disseminations. This architecture is being implemented in the context of\na broader research project to develop next-generation service modules for a\nlayered digital library architecture."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1157-7", 
    "link": "http://arxiv.org/pdf/1312.1260v1", 
    "title": "Policy-Carrying, Policy-Enforcing Digital Objects", 
    "arxiv-id": "1312.1260v1", 
    "author": "Carl Lagoze", 
    "publish": "2013-12-04T17:54:41Z", 
    "summary": "We describe the motivation for moving policy enforcement for access control\ndown to the digital object level. The reasons for this include handling of\nitem-specific behaviors, adapting to evolution of digital objects, and\npermitting objects to move among repositories and portable devices. We then\ndescribe our experiments that integrate the Fedora architecture for digital\nobjects and repositories and the PoET implementation of security automata to\neffect such objectcentric policy enforcement."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1157-7", 
    "link": "http://arxiv.org/pdf/1312.1385v1", 
    "title": "The Mellon Fedora Project: Digital Library Architecture Meets XML and   Web Services", 
    "arxiv-id": "1312.1385v1", 
    "author": "Thornton Staples", 
    "publish": "2013-12-04T23:40:13Z", 
    "summary": "The University of Virginia received a grant of $1,000,000 from the Andrew W.\nMellon Foundation to enable the Library, in collaboration with Cornell\nUniversity, to build a digital object repository system based on the Flexible\nExtensible Digital Object and Repository Architecture (Fedora). The new system\ndemonstrates how distributed digital library architecture can be deployed using\nweb-based technologies, including XML and Web services. The new system is\ndesigned to be a foundation upon which interoperable web-based digital\nlibraries can be built. Virginia and collaborating partners in the US and UK\nwill evaluate the system using a diverse set of digital collections. The\nsoftware will be made available to the public as an open-source release."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1157-7", 
    "link": "http://arxiv.org/pdf/1312.2791v1", 
    "title": "Coverage, field specialization and impact of scientific publishers   indexed in the 'Book Citation Index'", 
    "arxiv-id": "1312.2791v1", 
    "author": "Emilio Delgado L\u00f3pez-C\u00f3zar", 
    "publish": "2013-12-10T13:28:01Z", 
    "summary": "Purpose: The aim of this study is to analyze the disciplinary coverage of the\nThomson Reuters' Book Citation Index database focusing on publisher presence,\nimpact and specialization. Design/Methodology/approach: We conduct a\ndescriptive study in which we examine coverage by discipline, publisher\ndistribution by field and country of publication, and publisher impact. For\nthis the Thomson Reuters' Subject Categories were aggregated into 15\ndisciplines. Findings: 30% of the total share of this database belongs to the\nfields of Humanities and Social Sciences. Most of the disciplines are covered\nby very few publishers mainly from the UK and USA (75.05% of the books), in\nfact 33 publishers concentrate 90% of the whole share. Regarding publisher\nimpact, 80.5% of the books and chapters remained uncited. Two serious errors\nwere found in this database. Firstly, the Book Citation Index does not retrieve\nall citations for books and chapters. Secondly, book citations do not include\ncitations to their chapters. Research limitations/implications: The Book\nCitation Index is still underdeveloped and has serious limitations which call\ninto caution when using it for bibliometric purposes. Practical implications:\nThe results obtained from this study warn against the use of this database for\nbibliometric purposes, but opens a new window of opportunities for covering\nlong neglected areas such as Humanities and Social Sciences. The target\naudience of this study is librarians, bibliometricians, researchers, scientific\npublishers, prospective authors and evaluation agencies. Originality/Value:\nThere are currently no studies analyzing in depth the coverage of this novel\ndatabase which covers monographs."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1157-7", 
    "link": "http://arxiv.org/pdf/1312.5817v3", 
    "title": "Exploring Regional Development of Digital Humanities Research: A Case   Study for Taiwan", 
    "arxiv-id": "1312.5817v3", 
    "author": "Bi-Shin Hsueh", 
    "publish": "2013-12-20T06:09:15Z", 
    "summary": "This study analyzed references and source papers of the Proceedings of\n2009-2012 International Conference of Digital Archives and Digital Humanities\n(DADH), which was held annually in Taiwan. A total of 59 sources and 1,104\nreferences were investigated, based on descriptive analysis and subject\nanalysis of library practices on cataloguing. Preliminary results showed\nhistorical materials, events, bureaucracies, and people of Taiwan and China in\nthe Qing Dynasty were the major subjects in the tempo-spatial dimensions. The\nsubject-date figure depicted a long-low head and short-high tail curve, which\ndemonstrated both characteristics of research of humanities and application of\ntechnology in digital humanities. The dates of publication of the references\nspanned over 360 years, which shows a long time span in research materials. A\nmajority of the papers (61.41%) were single-authored, which is in line with the\ncommon research practice in the humanities. Books published by general\npublishers were the major type of references, and this was the same as that of\nestablished humanities research. The next step of this study will focus on the\ncomparison of characteristics of both sources and references of international\njournals with those reported in this article."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-013-1157-7", 
    "link": "http://arxiv.org/pdf/1401.0922v1", 
    "title": "A survey on the importance of visualization and social collaboration in   academic digital libraries", 
    "arxiv-id": "1401.0922v1", 
    "author": "Amir Akhavan", 
    "publish": "2014-01-05T18:22:49Z", 
    "summary": "From more than half a century ago indexing scientific articles has been\nstudied intensively to provide a more efficient data retrieval and to conserve\nresearchers invaluable time. In the last two decades with the emergence of the\nWorld Wide Web and the rapid growth in the number of scientific documents\nonline many academic databases and search engines were launched with almost\nsimilar structure in order to reduce the difficulty in finding, relating and\nsorting of the existing scientific documents published online. The dramatic\nincrease of the scientific documents in the last few years makes it necessary\nthat the retrieved information by the search engines be analyzed and more\norganized and interpretable representation be displayed to the users.\nInformation visualization is a great way for exploration of large and complex\ndata sets, therefore it can be a natural candidate for the purpose of\ngenerating more comprehensible search results for the citation and academic\ndatabases. In this survey the usage pattern of the participants and their\ndemands and ideas for the existence of other beneficial methods for literature\nreview has been questioned and the results are quantitatively analyzed."
},{
    "category": "cs.DL", 
    "doi": "10.1109/SOSE.2014.55", 
    "link": "http://arxiv.org/pdf/1401.1861v1", 
    "title": "Empirical Patterns in Google Scholar Citation Counts", 
    "arxiv-id": "1401.1861v1", 
    "author": "Jonathan P. Bowen", 
    "publish": "2014-01-08T23:49:44Z", 
    "summary": "Scholarly impact may be metricized using an author's total number of\ncitations as a stand-in for real worth, but this measure varies in\napplicability between disciplines. The detail of the number of citations per\npublication is nowadays mapped in much more detail on the Web, exposing certain\nempirical patterns. This paper explores those patterns, using the citation data\nfrom Google Scholar for a number of authors."
},{
    "category": "cs.DL", 
    "doi": "10.1109/SOSE.2014.55", 
    "link": "http://arxiv.org/pdf/1401.4307v2", 
    "title": "The Research Object Suite of Ontologies: Sharing and Exchanging Research   Data and Methods on the Open Web", 
    "arxiv-id": "1401.4307v2", 
    "author": "Carole Goble", 
    "publish": "2014-01-17T11:07:52Z", 
    "summary": "Research in life sciences is increasingly being conducted in a digital and\nonline environment. In particular, life scientists have been pioneers in\nembracing new computational tools to conduct their investigations. To support\nthe sharing of digital objects produced during such research investigations, we\nhave witnessed in the last few years the emergence of specialized repositories,\ne.g., DataVerse and FigShare. Such repositories provide users with the means to\nshare and publish datasets that were used or generated in research\ninvestigations. While these repositories have proven their usefulness,\ninterpreting and reusing evidence for most research results is a challenging\ntask. Additional contextual descriptions are needed to understand how those\nresults were generated and/or the circumstances under which they were\nconcluded. Because of this, scientists are calling for models that go beyond\nthe publication of datasets to systematically capture the life cycle of\nscientific investigations and provide a single entry point to access the\ninformation about the hypothesis investigated, the datasets used, the\nexperiments carried out, the results of the experiments, the people involved in\nthe research, etc. In this paper we present the Research Object (RO) suite of\nontologies, which provide a structured container to encapsulate research data\nand methods along with essential metadata descriptions. Research Objects are\nportable units that enable the sharing, preservation, interpretation and reuse\nof research investigation results. The ontologies we present have been designed\nin the light of requirements that we gathered from life scientists. They have\nbeen built upon existing popular vocabularies to facilitate interoperability.\nFurthermore, we have developed tools to support the creation and sharing of\nResearch Objects, thereby promoting and facilitating their adoption."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.23309", 
    "link": "http://arxiv.org/pdf/1401.4321v1", 
    "title": "Do altmetrics correlate with citations? Extensive comparison of   altmetric indicators with citations from a multidisciplinary perspective", 
    "arxiv-id": "1401.4321v1", 
    "author": "Paul Wouters", 
    "publish": "2014-01-17T12:35:08Z", 
    "summary": "An extensive analysis of the presence of different altmetric indicators\nprovided by Altmetric.com across scientific fields is presented, particularly\nfocusing on their relationship with citations. Our results confirm that the\npresence and density of social media altmetric counts are still very low and\nnot very frequent among scientific publications, with 15%-24% of the\npublications presenting some altmetric activity and concentrating in the most\nrecent publications, although their presence is increasing over time.\nPublications from the social sciences, humanities and the medical and life\nsciences show the highest presence of altmetrics, indicating their potential\nvalue and interest for these fields. The analysis of the relationships between\naltmetrics and citations confirms previous claims of positive correlations but\nrelatively weak, thus supporting the idea that altmetrics do not reflect the\nsame concept of impact as citations. Also, altmetric counts do not always\npresent a better filtering of highly cited publications than journal citation\nscores. Altmetrics scores (particularly mentions in blogs) are able to identify\nhighly cited publications with higher levels of precision than journal citation\nscores (JCS), but they have a lower level of recall. The value of altmetrics as\na complementary tool of citation analysis is highlighted, although more\nresearch is suggested to disentangle the potential meaning and value of\naltmetric indicators for research evaluation."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.23309", 
    "link": "http://arxiv.org/pdf/1401.5986v1", 
    "title": "How are excellent (highly cited) papers defined in bibliometrics? A   quantitative analysis of the literature", 
    "arxiv-id": "1401.5986v1", 
    "author": "Lutz Bornmann", 
    "publish": "2014-01-22T12:07:55Z", 
    "summary": "As the subject of research excellence has received increasing attention (in\nscience policy) over the last few decades, increasing numbers of bibliometric\nstudies have been published dealing with excellent papers. However, many\ndifferent methods have been used in these studies to identify excellent papers.\nThe present quantitative analysis of the literature has been carried out in\norder to acquire an overview of these methods and an indication of an \"average\"\nor \"most frequent\" bibliometric practice. The search in the Web of Science\nyielded 321 papers dealing with \"highly cited\", \"most cited\", \"top cited\" and\n\"most frequently cited\". Of the 321 papers, 16 could not be used in this study.\nIn around 80% of the papers analyzed in this study, a quantitative definition\nhas been provided with which to identify excellent papers. With definitions\nwhich relate to an absolute number, either a certain number of top cited papers\n(58%) or papers with a minimum number of citations are selected (17%). Around\n23% worked with percentile rank classes. Over these papers, there is an\narithmetic average of the top 7.6% (arithmetic average) or of the top 3%\n(median). The top 1% is used most frequently in the papers, followed by the top\n10%. With the thresholds presented in this study, in future, it will be\npossible to identify excellent papers based on an \"average\" or \"most frequent\"\npractice among bibliometricians."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.23309", 
    "link": "http://arxiv.org/pdf/1401.7547v1", 
    "title": "Web Based Reputation Index of Turkish Universities", 
    "arxiv-id": "1401.7547v1", 
    "author": "Sadi Evren Seker", 
    "publish": "2014-01-25T23:33:08Z", 
    "summary": "This paper attempts to develop an online reputation index of Turkish\nuniversities through their online impact and effectiveness. Using 16 different\nweb based parameters and employing normalization process of the results, we\nhave ranked websites of Turkish universities in terms of their web presence.\nThis index is first attempt to determine the tools of reputation of Turkish\nacademic websites and would be a basis for further studies to examine the\nrelation between reputation and the online effectiveness of the universities."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.23309", 
    "link": "http://arxiv.org/pdf/1403.2096v1", 
    "title": "Determinants of Patent Citations in Biotechnology: An Analysis of Patent   Influence Across the Industrial and Organizational Boundaries", 
    "arxiv-id": "1403.2096v1", 
    "author": "Vito Albino", 
    "publish": "2014-03-09T19:46:03Z", 
    "summary": "The present paper extends the literature investigating key drivers leading\ncertain patents to exert a stronger influence on the subsequent technological\ndevelopments (inventions) than other ones. We investigated six key\ndeterminants, as (i) the use of scientific knowledge, (ii) the breadth of the\ntechnological base, (iii) the existence of collaboration in patent development,\n(iv) the number of claims, (v) the scope, and (vi) the novelty, and how the\neffect of these determinants varies when patent influence - as measured by the\nnumber of forward citations the patent received - is distinguished as within\nand across the industrial and organizational boundaries. We conducted an\nempirical analysis on a sample of 5671 patents granted to 293 US biotechnology\nfirms from 1976 to 2003. Results reveal that the contribution of the\ndeterminants to patent influence differs across the domains that are identified\nby the industrial and organizational boundaries. Findings, for example, show\nthat the use of scientific knowledge negatively affects patent influence\noutside the biotechnology industry, while it positively contributes to make a\npatent more relevant for the assignee's subsequent technological developments.\nIn addition, the broader the scope of a patent the higher the number of\ncitations the patent receives from subsequent non-biotechnology patents. This\nrelationship is inverted-U shaped when considering the influence of a patent on\ninventions granted to other organizations than the patent's assignee. Finally,\nthe novelty of a patent is inverted-U related with the influence the patent\nexerts on the subsequent inventions granted across the industrial and\norganizational boundaries."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.23309", 
    "link": "http://arxiv.org/pdf/1403.7748v1", 
    "title": "The State of Technology for Digital Archiving", 
    "arxiv-id": "1403.7748v1", 
    "author": "Sandy Payette", 
    "publish": "2014-03-30T12:34:34Z", 
    "summary": "The Windsor Study Group on Digital Archiving was commissioned to recommend\nstrategies, policies, and technologies necessary for ensuring the integrity and\nlongevity of electronic publications. The goal of this work is to inform\ninstitutions of the challenges and opportunities faced by information stewards\nin fulfilling their mission of guaranteeing a permanent and authoritative\nscholarly record in the digital age. This white paper focuses specifically on\nthe technological dimensions of digital archiving. It provides an analysis of\nthe current state of technologies as well as a forecast of how digital archive\nsystems are likely to evolve over the next decade. The thesis of this white\npaper is that technology does not present a barrier to long term digital\narchiving, but instead presents an opportunity to harness the current and\nfuture power of these technologies to create the architectural underpinnings of\na comprehensive digital archiving strategy."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.23309", 
    "link": "http://arxiv.org/pdf/1405.2407v1", 
    "title": "The Past and the Future of Holocaust Research: From Disparate Sources to   an Integrated European Holocaust Research Infrastructure", 
    "arxiv-id": "1405.2407v1", 
    "author": "Veerle Vanden Daelen", 
    "publish": "2014-05-10T09:00:16Z", 
    "summary": "The European Holocaust Research Infrastructure (EHRI) has been set up by the\nEuropean Union to create a sustainable complex of services for researchers.\nEHRI will bring together information about dispersed collections, based on\ncurrently more than 20 partner organisations in 13 countries and many other\narchives. EHRI, which brings together historians, archivists and specialists in\ndigital humanities, strives to develop innovative on-line tools for finding,\nresearching and sharing knowledge about the Holocaust. While connecting\ninformation about Holocaust collections, it strives to create tools and\napproaches applicable to other digital archival projects. The paper describes\nits current progress and collaboration across the disciplines involved."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.23309", 
    "link": "http://arxiv.org/pdf/1405.6399v2", 
    "title": "Research at UNIS - The University Centre in Svalbard. A bibliometric   study", 
    "arxiv-id": "1405.6399v2", 
    "author": "Johannes Stegmann", 
    "publish": "2014-05-25T15:50:17Z", 
    "summary": "The scientific output 1994-2014 of the University Centre in Svalbard (UNIS)\nwas bibliometrically analysed. It was found that the majority of the papers\nhave been published as international cooperations and rank above world average.\nAnalysis of the content of the papers reveals that UNIS works and publishes in\na wide variety of scientific topics."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.23309", 
    "link": "http://arxiv.org/pdf/1405.6738v1", 
    "title": "Assessing Educational Research -- An Information Service for Monitoring   a Heterogeneous Research Field", 
    "arxiv-id": "1405.6738v1", 
    "author": "Marc Rittberger", 
    "publish": "2014-05-26T20:15:32Z", 
    "summary": "The paper presents a web prototype that visualises different characteristics\nof research projects in the heterogeneous domain of educational research. The\nconcept of the application derives from the project \"Monitoring Educational\nResearch\" (MoBi) that aims at identifying and implementing indicators that\nadequately describe structural properties and dynamics of the research field.\nThe prototype enables users to visualise data regarding different indicators,\ne.g. \"research activity\", \"funding\", \"qualification project\", \"disciplinary\narea\". Since the application is based on Semantic MediaWikitechnology it\nfurthermore provides an easily accessible opportunity to collaboratively work\non a database of research projects. Users can jointly and in a semantically\ncontrolled way enter metadata on research projects which are the basis for the\ncomputation and visualisation of indicators."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.23309", 
    "link": "http://arxiv.org/pdf/1407.0547v1", 
    "title": "Understanding Repository Growth at the University of North Texas: A Case   Study", 
    "arxiv-id": "1407.0547v1", 
    "author": "Lauren Ko", 
    "publish": "2014-07-02T12:55:49Z", 
    "summary": "Over the past decade the University of North Texas Libraries (UNTL) has\ndeveloped a sizable digital library infrastructure for use in carrying out its\ncore mission to the students, faculty, staff and associated communities of the\nuniversity. This repository of content offers countless research possibilities\nfor end users across the Internet when it is discovered and used in research,\nscholarship, entertainment, and lifelong learning. The characteristics of the\nrepository itself provide insight into the workings of a modern digital library\ninfrastructure, how it was created, how often it is updated, or how often it is\nmodified. In that vein, the authors created a dataset comprised of information\nextracted from the UNT Libraries' archival repository Coda and analyzed this\ndataset in order to demonstrate the value and insights that can be gained from\nsharing repository characteristics more broadly. This case study presents the\nfindings from an analysis of this dataset."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.23309", 
    "link": "http://arxiv.org/pdf/1407.2827v1", 
    "title": "Google Scholar Metrics 2014: a low cost bibliometric tool", 
    "arxiv-id": "1407.2827v1", 
    "author": "Emilio Delgado L\u00f3pez-C\u00f3zar", 
    "publish": "2014-07-10T15:28:23Z", 
    "summary": "We analyse the main features of the third edition of Google Scholar Metrics\n(GSM), released in June 2014, focusing on its more important changes,\nstrengths, and weaknesses. Additionally, we present some figures that outline\nthe dimensions of this new edition, and we compare them to those of previous\neditions. Principal among these figures are the number of visualized\npublications, publication types, languages, and the maximum and minimum\nh5-index and h5-median values by language, subject area, and subcategory. This\nnew edition is marked by continuity. There is nothing new other than the\nupdating of the time frame (2009-2013) and the removal of some redundant\nsubcategories (from 268 to 261) for English written publications. Google has\njust updated the data, which means that some of the errors discussed in\nprevious studies still persist. To sum up, GSM is a minimalist information\nproduct with few features, closed (it cannot be customized by the user), and\nsimple (navigating it only takes a few clicks). For these reasons, we consider\nit a 'low cost' bibliometric tool, and propose a list of features it should\nincorporate in order to stop being labeled as such. Notwithstanding the above,\nthis product presents a stability in its bibliometric indicators that supports\nits ability to measure and track the impact of scientific publications."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.23309", 
    "link": "http://arxiv.org/pdf/1407.2932v1", 
    "title": "h-index Research in Scientometrics: A Summary", 
    "arxiv-id": "1407.2932v1", 
    "author": "Lutz Bornmann", 
    "publish": "2014-07-10T11:33:21Z", 
    "summary": "A Letter to the Editor shortly summing up ten or so years of research into\nthe h-index."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.23309", 
    "link": "http://arxiv.org/pdf/1407.6239v2", 
    "title": "About the size of Google Scholar: playing the numbers", 
    "arxiv-id": "1407.6239v2", 
    "author": "Emilio Delgado L\u00f3pez-C\u00f3zar", 
    "publish": "2014-07-23T14:37:09Z", 
    "summary": "The emergence of academic search engines (Google Scholar and Microsoft\nAcademic Search essentially) has revived and increased the interest in the size\nof the academic web, since their aspiration is to index the entirety of current\nacademic knowledge. The search engine functionality and human search patterns\nlead us to believe, sometimes, that what you see in the search engine's results\npage is all that really exists. And, even when this is not true, we wonder\nwhich information is missing and why. The main objective of this working paper\nis to calculate the size of Google Scholar at present (May 2014). To do this,\nwe present, apply and discuss up to 4 empirical methods: Khabsa & Giles's\nmethod, an estimate based on empirical data, and estimates based on direct\nqueries and absurd queries. The results, despite providing disparate values,\nplace the estimated size of Google Scholar in about 160 million documents.\nHowever, the fact that all methods show great inconsistencies, limitations and\nuncertainties, makes us wonder why Google does not simply provide this\ninformation to the scientific community if the company really knows this\nfigure."
},{
    "category": "cs.DL", 
    "doi": "10.1515/itit-2014-1048", 
    "link": "http://arxiv.org/pdf/1410.0569v1", 
    "title": "Tweets vs. Mendeley readers: How do these two social media metrics   differ?", 
    "arxiv-id": "1410.0569v1", 
    "author": "Isabella Peters", 
    "publish": "2014-10-02T14:34:36Z", 
    "summary": "A set of 1.4 million biomedical papers was analyzed with regards to how often\narticles are mentioned on Twitter or saved by users on Mendeley. While Twitter\nis a microblogging platform used by a general audience to distribute\ninformation, Mendeley is a reference manager targeted at an academic user group\nto organize scholarly literature. Both platforms are used as sources for\nso-called altmetrics to measure a new kind of research impact. This analysis\nshows in how far they differ and compare to traditional citation impact metrics\nbased on a large set of PubMed papers."
},{
    "category": "cs.DL", 
    "doi": "10.1515/itit-2014-1048", 
    "link": "http://arxiv.org/pdf/1410.1625v1", 
    "title": "A macro level scientometric analysis of world tribology research output   (1998 - 2012)", 
    "arxiv-id": "1410.1625v1", 
    "author": "Lutz Bornmann", 
    "publish": "2014-10-07T06:48:14Z", 
    "summary": "Bibliographic records related to tribology research were extracted from\nSCOPUS and Web of Science databases for the period of 15 years from 1998 to\n2012. Macro-level scientometric indicators such as growth rate, share of\ninternational collaborative papers, citations per paper, and share of non-cited\npapers were employed. Further, the Gini coefficient and Simpson Index of\nDiversity were used. Two new relative indicators : Relative International\nCollaboration Rate (RICR) and Relative Growth Index (RGI) are proposed in this\nstudy. The performance of top countries contributing more than 1000 papers\nacross the study period was discussed. Contributions and share of continents\nand countries by income groups were examined. Further research contributions\nand citation impact of selected country groups such as the Developing Eight\nCountries (D8), the Association of Southeast Asian Nations (ASEAN), the Union\nof South American Nations (UNASUR) and the Emerging and Growth-Leading\nEconomies (EAGLEs) countries were analyzed. High levels of interdisciplinarity\nexist in tribology research. Inequality of distribution between countries is\nhighest for number of publications and citations. Asia outperforms the other\nworld regions and China contributes most of the papers (25%), while the United\nStates receives most of the citations (22%). 84% of total output was\ncontributed by the Asiatic region, Western Europe and North America together.\nPublications from these three world regions received 88% of total citations.\nAround 50% of global research output was contributed by China, the United\nStates and Japan."
},{
    "category": "cs.DL", 
    "doi": "10.1108/AJIM-09-2013-0081", 
    "link": "http://arxiv.org/pdf/1410.1740v1", 
    "title": "Astrophysicists on Twitter: An in-depth analysis of tweeting and   scientific publication behavior", 
    "arxiv-id": "1410.1740v1", 
    "author": "Vincent Larivi\u00e8re", 
    "publish": "2014-10-07T14:26:58Z", 
    "summary": "This paper analyzes the tweeting behavior of 37 astrophysicists on Twitter\nand compares their tweeting behavior with their publication behavior and\ncitation impact to show whether they tweet research-related topics or not.\nAstrophysicists on Twitter are selected to compare their tweets with their\npublications from Web of Science. Different user groups are identified based on\ntweeting and publication frequency. A moderate negative correlation (p=-0.390*)\nis found between the number of publications and tweets per day, while retweet\nand citation rates do not correlate. The similarity between tweets and\nabstracts is very low (cos=0.081). User groups show different tweeting behavior\nsuch as retweeting and including hashtags, usernames and URLs. The study is\nlimited in terms of the small set of astrophysicists. Results are not\nnecessarily representative of the entire astrophysicist community on Twitter\nand they most certainly do not apply to scientists in general. Future research\nshould apply the methods to a larger set of researchers and other scientific\ndisciplines. To a certain extent, this study helps to understand how\nresearchers use Twitter. The results hint at the fact that impact on Twitter\ncan neither be equated with nor replace traditional research impact metrics.\nHowever, tweets and other so-called altmetrics might be able to reflect other\nimpact of scientists such as public outreach and science communication. To the\nbest of our knowledge, this is the first in-depth study comparing researchers'\ntweeting activity and behavior with scientific publication output in terms of\nquantity, content and impact."
},{
    "category": "cs.DL", 
    "doi": "10.1108/AJIM-09-2013-0081", 
    "link": "http://arxiv.org/pdf/1410.2065v1", 
    "title": "An approach to the author citation potential: Measures of scientific   performance which are invariant across scientific fields", 
    "arxiv-id": "1410.2065v1", 
    "author": "Rafael Suarez-Vega", 
    "publish": "2014-10-08T11:28:04Z", 
    "summary": "The citation potential is a measure of the probability of being cited.\nObviously, it is different among fields of science, social science, and\nhumanities because of systematic differences in publication and citation\nbehaviour across disciplines. In the past, the citation potential was studied\nat journal level considering the average number of references in established\ngroups of journals (for example, the crown indicator is based on the journal\nsubject categories in the Web of Science database). In this paper, some\ncharacterizations of the author's scientific research through three different\nresearch dimensions are proposed: production (journal papers), impact (journal\ncitations), and reference (bibliographical sources). Then, we propose different\nmeasures of the citation potential for authors based on a proportion of these\ndimensions. An empirical application, in a set of 120 randomly selected highly\nproductive authors from the CSIC Research Centre (Spain) in four subject areas,\nshows that the ratio between production and impact dimensions is a normalized\nmeasure of the citation potential at the level of individual authors. Moreover,\nthis ratio reduces the between-group variance in relation to the within-group\nvariance in a higher proportion than the rest of the indicators analysed.\nFurthermore, it is consistent with the type of journal impact indicator used. A\npossible application of this result is in the selection and promotion process\nwithin interdisciplinary institutions, since it allows comparisons of authors\nbased on their particular scientific research."
},{
    "category": "cs.DL", 
    "doi": "10.1108/AJIM-09-2013-0081", 
    "link": "http://arxiv.org/pdf/1410.2217v1", 
    "title": "Rise of the Rest: The Growing Impact of Non-Elite Journals", 
    "arxiv-id": "1410.2217v1", 
    "author": "Namit Shetty", 
    "publish": "2014-10-08T18:57:23Z", 
    "summary": "In this paper, we examine the evolution of the impact of non-elite journals.\nWe attempt to answer two questions. First, what fraction of the top-cited\narticles are published in non-elite journals and how has this changed over\ntime. Second, what fraction of the total citations are to non-elite journals\nand how has this changed over time.\n  We studied citations to articles published in 1995-2013. We computed the 10\nmost-cited journals and the 1000 most-cited articles each year for all 261\nsubject categories in Scholar Metrics. We marked the 10 most-cited journals in\na category as the elite journals for the category and the rest as non-elite.\n  There are two conclusions from our study. First, the fraction of top-cited\narticles published in non-elite journals increased steadily over 1995-2013.\nWhile the elite journals still publish a substantial fraction of high-impact\narticles, many more authors of well-regarded papers in diverse research fields\nare choosing other venues.\n  The number of top-1000 papers published in non-elite journals for the\nrepresentative subject category went from 149 in 1995 to 245 in 2013, a growth\nof 64%. Looking at broad research areas, 4 out of 9 areas saw at least\none-third of the top-cited articles published in non-elite journals in 2013.\nFor 6 out of 9 areas, the fraction of top-cited papers published in non-elite\njournals for the representative subject category grew by 45% or more.\n  Second, now that finding and reading relevant articles in non-elite journals\nis about as easy as finding and reading articles in elite journals, researchers\nare increasingly building on and citing work published everywhere. Considering\ncitations to all articles, the percentage of citations to articles in non-elite\njournals went from 27% in 1995 to 47% in 2013. Six out of nine broad areas had\nat least 50% of citations going to articles published in non-elite journals in\n2013."
},{
    "category": "cs.DL", 
    "doi": "10.1108/AJIM-09-2013-0081", 
    "link": "http://arxiv.org/pdf/1410.2926v2", 
    "title": "Estimating Open Access Mandate Effectiveness: The MELIBEA Score", 
    "arxiv-id": "1410.2926v2", 
    "author": "Stevan Harnad", 
    "publish": "2014-10-10T23:26:46Z", 
    "summary": "MELIBEA is a Spanish database that uses a composite formula with eight\nweighted conditions to estimate the effectiveness of Open Access mandates\n(registered in ROARMAP). We analyzed 68 mandated institutions for publication\nyears 2011-2013 to determine how well the MELIBEA score and its individual\nconditions predict what percentage of published articles indexed by Web of\nKnowledge is deposited in each institution's OA repository, and when. We found\na small but significant positive correlation (0.18) between MELIBEA score and\ndeposit percentage. We also found that for three of the eight MELIBEA\nconditions (deposit timing, internal use, and opt-outs), one value of each was\nstrongly associated with deposit percentage or deposit latency (immediate\ndeposit required, deposit required for performance evaluation, unconditional\nopt-out allowed for the OA requirement but no opt-out for deposit requirement).\nWhen we updated the initial values and weights of the MELIBEA formula for\nmandate effectiveness to reflect the empirical association we had found, the\nscore's predictive power doubled (.36). There are not yet enough OA mandates to\ntest further mandate conditions that might contribute to mandate effectiveness,\nbut these findings already suggest that it would be useful for future mandates\nto adopt these three conditions so as to maximize their effectiveness, and\nthereby the growth of OA."
},{
    "category": "cs.DL", 
    "doi": "10.1108/AJIM-09-2013-0081", 
    "link": "http://arxiv.org/pdf/1410.2980v1", 
    "title": "Whole counting vs. whole-normalized counting: A country level   comparative study of internationally collaborated papers on Tribology", 
    "arxiv-id": "1410.2980v1", 
    "author": "P. Rajendran", 
    "publish": "2014-10-11T09:58:50Z", 
    "summary": "The purpose of this study is to compare the changing behavior of two counting\nmethods (whole counting and whole-normalized counting) and inflation rate at\ncountry level research productivity and impact. For this, publication data on\ntribology research published between 1998 and 2012 from SCOPUS has been used.\nOnly internationally collaborated papers are considered for comparison between\ntwo counting methods. The result of correlation tests shows that there is\nhighly correlation in all the four indicators between the two counting methods.\nHowever, the result of t-test shows that there is significant difference in the\nthree indicators (paper count, citation count and h-index) between the two\ncounting methods. This study concludes that whole-normalized counting\n(fractional) is the better choice for publication and citations counting at the\ncountry level assessment."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-014-1456-7", 
    "link": "http://arxiv.org/pdf/1410.3705v1", 
    "title": "Does A Paper Being Featured on The Cover of A Journal Guarantee More   Attention and Greater Impact?", 
    "arxiv-id": "1410.3705v1", 
    "author": "Wenli Mao", 
    "publish": "2014-10-14T14:24:57Z", 
    "summary": "Paper featured on the cover of a journal has more visibility in an issue\ncompared with other ordinary articles for both printed and electronic journal.\nDoes this kind of visibility guarantee more attention and greater impact of its\nassociated content than the non-cover papers? In this research, usage and\ncitation data of 60 issues of PLOS Biology from 2006 to 2010 are analyzed to\ncompare the attention and scholarly impact between cover and non-cover paper.\nOur empirical study confirms that, in most cases, the group difference between\ncover and non-cover paper is not significant for attention or impact. Cover\npaper is not the best one, nor at the upper level in one issue considering the\nattention or the citation impact. Having a paper featured on the cover of a\njournal may be a source of pride to researchers, many institutions and\nresearchers would even release news about it. However, a paper being featured\non the cover of a journal doesn't guarantee more attention and greater impact."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-014-1456-7", 
    "link": "http://arxiv.org/pdf/1410.4139v1", 
    "title": "Tweets as impact indicators: Examining the implications of automated bot   accounts on Twitter", 
    "arxiv-id": "1410.4139v1", 
    "author": "Vincent Larivi\u00e8re", 
    "publish": "2014-10-15T17:10:20Z", 
    "summary": "This brief communication presents preliminary findings on automated Twitter\naccounts distributing links to scientific papers deposited on the preprint\nrepository arXiv. It discusses the implication of the presence of such bots\nfrom the perspective of social media metrics (altmetrics), where mentions of\nscholarly documents on Twitter have been suggested as a means of measuring\nimpact that is both broader and timelier than citations. We present preliminary\nfindings that automated Twitter accounts create a considerable amount of tweets\nto scientific papers and that they behave differently than common social bots,\nwhich has critical implications for the use of raw tweet counts in research\nevaluation and assessment. We discuss some definitions of Twitter cyborgs and\nbots in scholarly communication and propose differentiating between different\nlevels of engagement from tweeting only bibliographic information to discussing\nor commenting on the content of a paper."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-014-1456-7", 
    "link": "http://arxiv.org/pdf/1410.4774v1", 
    "title": "Research status and trends in Operations Research and Management Science   (OR/MS) journals: A bibliometric analysis based on the Web of Science   database 2001-2012", 
    "arxiv-id": "1410.4774v1", 
    "author": "Rafael Suarez-Vega", 
    "publish": "2014-10-17T15:52:59Z", 
    "summary": "A bibliometric analysis to evaluate global scientific production in the\nsubject category of Operations Research and Management Science (OR/MS) from\n2001 to 2012 was applied. Data was based on the Web of Science (Science\nCitation Index) database compiled by Thomson Reuters. The results showed that\nthe OR/MS research has significantly increased over the past twelve years. The\nBradford core journals in the category were identified. The researchers paid\ngreat attention to networks, control, and simulation. Among the countries, USA\nattained a dominant position in global research in the field."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-014-1456-7", 
    "link": "http://arxiv.org/pdf/1410.7758v1", 
    "title": "Towards a Virtual Data Centre for Classics", 
    "arxiv-id": "1410.7758v1", 
    "author": "Mark Hedges", 
    "publish": "2014-10-28T19:25:52Z", 
    "summary": "The paper presents some of our work on integrating datasets in Classics. We\npresent the results of various projects we had in this domain. The conclusions\nfrom LaQuAT concerned limitations to the approach rather than solutions. The\nrelational model followed by OGSA-DAI was more effective for resources that\nconsist primarily of structured data (which we call data-centric) rather than\nfor largely unstructured text (which we call text-centric), which makes up a\nsignificant component of the datasets we were using. This approach was,\nmoreover, insufficiently flexible to deal with the semantic issues. The gMan\nproject, on the other hand, addressed these problems by virtualizing data\nresources using full-text indexes, which can then be used to provide different\nviews onto the collections and services that more closely match the sort of\ninformation organization and retrieval activities found in the humanities, in\nan environment that is more interactive, researcher-focused, and\nresearcher-driven."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-014-1456-7", 
    "link": "http://arxiv.org/pdf/1410.8464v4", 
    "title": "Does Google Scholar contain all highly cited documents (1950-2013)?", 
    "arxiv-id": "1410.8464v4", 
    "author": "Emilio Delgado L\u00f3pez-C\u00f3zar", 
    "publish": "2014-10-30T17:54:21Z", 
    "summary": "The study of highly cited documents on Google Scholar (GS) has never been\naddressed to date in a comprehensive manner. The objective of this work is to\nidentify the set of highly cited documents in Google Scholar and define their\ncore characteristics: their languages, their file format, or how many of them\ncan be accessed free of charge. We will also try to answer some additional\nquestions that hopefully shed some light about the use of GS as a tool for\nassessing scientific impact through citations. The decalogue of research\nquestions is shown below:\n  1. Which are the most cited documents in GS?\n  2. Which are the most cited document types in GS?\n  3. What languages are the most cited documents written in GS?\n  4. How many highly cited documents are freely accessible?\n  4.1 What file types are the most commonly used to store these highly cited\ndocuments?\n  4.2 Which are the main providers of these documents?\n  5. How many of the highly cited documents indexed by GS are also indexed by\nWoS?\n  6. Is there a correlation between the number of citations that these highly\ncited documents have received in GS and the number of citations they have\nreceived in WoS?\n  7. How many versions of these highly cited documents has GS detected?\n  8. Is there a correlation between the number of versions GS has detected for\nthese documents, and the number citations they have received?\n  9. Is there a correlation between the number of versions GS has detected for\nthese documents, and their position in the search engine result pages?\n  10. Is there some relation between the positions these documents occupy in\nthe search engine result pages, and the number of citations they have received?"
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-014-1456-7", 
    "link": "http://arxiv.org/pdf/1410.8544v1", 
    "title": "Team size matters: Collaboration and scientific impact since 1900", 
    "arxiv-id": "1410.8544v1", 
    "author": "Yves Gingras", 
    "publish": "2014-10-30T20:27:40Z", 
    "summary": "This paper provides the first historical analysis of the relationship between\ncollaboration and scientific impact, using three indicators of collaboration\n(number of authors, number of addresses, and number of countries) and including\narticles published between 1900 and 2011. The results demonstrate that an\nincrease in the number of authors leads to an increase in impact--from the\nbeginning of the last century onwards--and that this is not simply due to\nself-citations. A similar trend is also observed for the number of addresses\nand number of countries represented in the byline of an article. However, the\nconstant inflation of collaboration since 1900 has resulted in diminishing\ncitation returns: larger and more diverse (in terms of institutional and\ncountry affiliation) teams are necessary to realize higher impact. The paper\nconcludes with a discussion of the potential causes of the impact gain in\ncitations of collaborative papers."
},{
    "category": "cs.DL", 
    "doi": "10.1080/09737766.2016.1177940", 
    "link": "http://arxiv.org/pdf/1411.0100v1", 
    "title": "Study of Citation Networks in Tribology Research", 
    "arxiv-id": "1411.0100v1", 
    "author": "Subramaniam Shankar", 
    "publish": "2014-11-01T11:01:24Z", 
    "summary": "CitNetExplorer has been used to study the citation networks among the\nscientific publications on tribology during the 15 years period from 1998-2012.\nThree data sets from Web of Science have been analyzed: (1) Core publications\nof tribology research, (2) publications on nanotribology and (3) publications\nof Bharat Bhushan (a top-contributor to nanotribology research). Based on this\nstudy, some suggestions are made to improve the CitNetExplorer."
},{
    "category": "cs.DL", 
    "doi": "10.1080/09737766.2016.1177940", 
    "link": "http://arxiv.org/pdf/1411.0275v1", 
    "title": "On the Shoulders of Giants: The Growing Impact of Older Articles", 
    "arxiv-id": "1411.0275v1", 
    "author": "Namit Shetty", 
    "publish": "2014-11-02T16:53:52Z", 
    "summary": "In this paper, we examine the evolution of the impact of older scholarly\narticles. We attempt to answer four questions. First, how often are older\narticles cited and how has this changed over time. Second, how does the impact\nof older articles vary across different research fields. Third, is the change\nin the impact of older articles accelerating or slowing down. Fourth, are these\ntrends different for much older articles.\n  To answer these questions, we studied citations from articles published in\n1990-2013. We computed the fraction of citations to older articles from\narticles published each year as the measure of impact. We considered articles\nthat were published at least 10 years before the citing article as older\narticles. We computed these numbers for 261 subject categories and 9 broad\nareas of research. Finally, we repeated the computation for two other\ndefinitions of older articles, 15 years and older and 20 years and older.\n  There are three conclusions from our study. First, the impact of older\narticles has grown substantially over 1990-2013. In 2013, 36% of citations were\nto articles that are at least 10 years old; this fraction has grown 28% since\n1990. The fraction of older citations increased over 1990-2013 for 7 out of 9\nbroad areas and 231 out of 261 subject categories. Second, the increase over\nthe second half (2002-2013) was double the increase in the first half\n(1990-2001).\n  Third, the trend of a growing impact of older articles also holds for even\nolder articles. In 2013, 21% of citations were to articles >= 15 years old with\nan increase of 30% since 1990 and 13% of citations were to articles >= 20 years\nold with an increase of 36%.\n  Now that finding and reading relevant older articles is about as easy as\nfinding and reading recently published articles, significant advances aren't\ngetting lost on the shelves and are influencing work worldwide for years after."
},{
    "category": "cs.DL", 
    "doi": "10.1080/09737766.2016.1177940", 
    "link": "http://arxiv.org/pdf/1411.0906v3", 
    "title": "The \"Tournaments\" Metaphor in Citation Impact Studies: Power-Weakness   Ratios (PWR) as a Journal Indicator", 
    "arxiv-id": "1411.0906v3", 
    "author": "Lutz Bornmann", 
    "publish": "2014-11-04T13:40:21Z", 
    "summary": "Ramanujacharyulu's (1964) Power-Weakness Ratio (PWR) measures impact by\nrecursively multiplying the citation matrix by itself until convergence is\nreached in both the cited and citing dimensions; the quotient of these values\nis defined as PWR, whereby \"cited\" is considered as power and \"citing\" as\nweakness. Analytically, PWR is an attractive candidate for measuring journal\nimpact because of its symmetrical handling of the rows and columns in the\nasymmetrical citation matrix, its recursive algorithm, and its mathematical\nelegance. In this study, PWR is discussed and critically assessed in relation\nto other size-independent recursive metrics. A test using the set of 83\njournals in \"information and library science\" (according to the Web-of-Science\ncategorization) converged, but did not provide interpretable results. Further\ndecomposition of this set into homogeneous sub-graphs shows that--like most\nother journal indicators--PWR can perhaps be used within homogeneous sets, but\nnot across citation communities."
},{
    "category": "cs.DL", 
    "doi": "10.1080/09737766.2016.1177940", 
    "link": "http://arxiv.org/pdf/1411.0928v1", 
    "title": "Power-law distributions, the h-index, and Google Scholar (GS) citations:   a test of their relationship with economics Nobelists", 
    "arxiv-id": "1411.0928v1", 
    "author": "J. Sylvan Katz", 
    "publish": "2014-11-04T14:46:36Z", 
    "summary": "This paper presents proof that Google Scholar (GS) can construct documentary\nsets relevant for evaluating researchers' works. Nobelists in economics were\nthe researchers under analysis, and two types of tests of the GS cites to their\nworks were performed: distributional and semantic. Distributional tests found\nthat the GS cites to the laureates' works conformed to the power-law model with\nan asymptote or \"tail\" conterminous with their h-index demarcating their core\noeuvre, validating both GS and the h-index. Semantic tests revealed that their\nworks highest in GS cites were on topics for which they were awarded the prize."
},{
    "category": "cs.DL", 
    "doi": "10.1080/09737766.2016.1177940", 
    "link": "http://arxiv.org/pdf/1411.1361v2", 
    "title": "Bibliometric Indicators for Publishers: Data processing, indicators and   interpretation", 
    "arxiv-id": "1411.1361v2", 
    "author": "Daniel Torres-Salinas", 
    "publish": "2014-11-05T19:09:51Z", 
    "summary": "Here we describe the Bibliometric Indicators for Publishers Project, an\ninitiative undertaken by EC3Metrics SL for the analysis and development of\nindicators based on books and book chapters. Its goal is to study and analyze\nthe publication and citation patterns of books and book chapters considering\nacademic publishers as the unit of analysis. It aims at developing new\nmethodologies and indicators that can better capture and define the research\nimpact of publishers. It is an on-going project in which data sources and\nindicators are tested. We consider academic publishers as an analogy of\njournals, focusing on them as the unit of analysis. In this working paper we\npresent the http://bipublishers.es website where all findings derived from the\nproject are displayed. We describe the data retrieval and normalization process\nand we show the main results. A total 482,470 records have been retrieved and\nprocessed, identifying 342 publishers from which 254 have been analyzed. Then\nsix indicators have been calculated for each publisher for four fields and 38\ndisciplines and displayed."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2788993.2789850", 
    "link": "http://arxiv.org/pdf/1411.2180v2", 
    "title": "Public Domain Rank: Identifying Notable Individuals with the Wisdom of   the Crowd", 
    "arxiv-id": "1411.2180v2", 
    "author": "Allen B. Riddell", 
    "publish": "2014-11-09T00:40:31Z", 
    "summary": "Identifying literary, scientific, and technical works of enduring interest is\nchallenging. Few are able to name significant works across more than a handful\nof domains or languages. This paper introduces an automatic method for\nidentifying authors of notable works throughout history. Notability is defined\nusing the record of which works volunteers have made available in public domain\ndigital editions. A significant benefit of this bottom-up approach is that it\nalso provides a novel and reproducible index of notability for all individuals\nwith Wikipedia pages. The method promises to supplement the work of cultural\norganizations and institutions seeking to publicize the availability of notable\nworks and prioritize works for preservation and digitization."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2788993.2789850", 
    "link": "http://arxiv.org/pdf/1411.2749v2", 
    "title": "Publishing without Publishers: a Decentralized Approach to   Dissemination, Retrieval, and Archiving of Data", 
    "arxiv-id": "1411.2749v2", 
    "author": "Michel Dumontier", 
    "publish": "2014-11-11T10:09:15Z", 
    "summary": "Making available and archiving scientific results is for the most part still\nconsidered the task of classical publishing companies, despite the fact that\nclassical forms of publishing centered around printed narrative articles no\nlonger seem well-suited in the digital age. In particular, there exist\ncurrently no efficient, reliable, and agreed-upon methods for publishing\nscientific datasets, which have become increasingly important for science. Here\nwe propose to design scientific data publishing as a Web-based bottom-up\nprocess, without top-down control of central authorities such as publishing\ncompanies. Based on a novel combination of existing concepts and technologies,\nwe present a server network to decentrally store and archive data in the form\nof nanopublications, an RDF-based format to represent scientific data. We show\nhow this approach allows researchers to publish, retrieve, verify, and\nrecombine datasets of nanopublications in a reliable and trustworthy manner,\nand we argue that this architecture could be used for the Semantic Web in\ngeneral. Evaluation of the current small network shows that this system is\nefficient and reliable."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2788993.2789850", 
    "link": "http://arxiv.org/pdf/1411.6675v2", 
    "title": "From orphan works, a new role of libraries for the public domain and   public interest (Dalle opere orfane, un nuovo ruolo delle biblioteche per il   pubblico dominio e l'utilit\u00e0 sociale)", 
    "arxiv-id": "1411.6675v2", 
    "author": "Federico Leva", 
    "publish": "2014-11-24T22:36:58Z", 
    "summary": "Summarising the new orphan works law of Italy, we show how it makes the\npublic interest prevail and allows libraries and other beneficiaries to improve\ntheir services. We then argue that such services are part of their mission\ntowards the public domain and are a first step for its complete accomplishment,\nby the work of each and a reform of european copyright. Failing that, European\nculture will disappear.\n  --\n  Sintetizzando le nuove norme sulle opere orfane, mostriamo come esse\naffermino la prevalenza dell'interesse pubblico e consentano a biblioteche e\naltri enti beneficiari di migliorare i propri servizi. Sosteniamo quindi che\nquesti si inquadrano nella loro missione nei confronti del pubblico dominio e\nsono un primo passo per la sua completa realizzazione, mediante il lavoro di\nciascuno e la riforma del diritto d'autore europeo. In caso contrario, la\ncultura europea sparir\\`a."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.02.006", 
    "link": "http://arxiv.org/pdf/1412.4081v2", 
    "title": "Quantitative Analysis of the Italian National Scientific Qualification", 
    "arxiv-id": "1412.4081v2", 
    "author": "Moreno Marzolla", 
    "publish": "2014-12-12T18:42:30Z", 
    "summary": "The Italian National Scientific Qualification (ASN) was introduced in 2010 as\npart of a major reform of the national university system. Under the new\nregulation, the scientific qualification for a specific role (associate or full\nprofessor) and field of study is required to apply to a permanent professor\nposition. The ASN is peculiar since it makes use of bibliometric indicators\nwith associated thresholds as one of the parameters used to assess applicants.\nOverall, more than 59000 applications were submitted, and the results have been\nmade publicly available for a short period of time, including the values of the\nquantitative indicators for each applicant. The availability of this wealth of\ninformation provides an opportunity to draw a fairly detailed picture of a\nnation-wide evaluation exercise, and to study the impact of the bibliometric\nindicators on the qualification results. In this paper we provide a first\naccount of the Italian ASN from a quantitative point of view. We show that\nsignificant differences exist among scientific disciplines, in particular with\nrespect to the fraction of qualified applicants, that can not be easily\nexplained. Furthermore, we describe some issues related to the definition and\nuse of the bibliometric indicators and thresholds. Our analysis aims at drawing\nattention to potential problems that should be addressed by decision-makers in\nfuture ASN rounds."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.02.006", 
    "link": "http://arxiv.org/pdf/1412.7633v2", 
    "title": "Proceedings Scholar Metrics: H Index of proceedings on Computer Science,   Electrical & Electronic Engineering, and Communications according to Google   Scholar Metrics (2009-2013)", 
    "arxiv-id": "1412.7633v2", 
    "author": "Emilio Delgado Lopez-Cozar", 
    "publish": "2014-12-24T09:54:10Z", 
    "summary": "The objective of this report is to present a list of proceedings\n(conferences, workshops, symposia, meetings) in the areas of Computer Science,\nElectrical & Electronic Engineering, and Communications covered by Google\nScholar Metrics and ranked according to their h-index. Google Scholar Metrics\nonly displays publications that have published at least 100 papers and have\nreceived at least one citation in the last five years (2009-2013). The searches\nwere conducted between the 15th and 22nd of December, 2014. A total of 1208\nproceedings have been identified"
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.02.006", 
    "link": "http://arxiv.org/pdf/1412.8420v1", 
    "title": "Return on citation: a consistent metric to evaluate papers, journals and   researchers", 
    "arxiv-id": "1412.8420v1", 
    "author": "Tiancheng Li", 
    "publish": "2014-12-29T18:44:46Z", 
    "summary": "Evaluating and comparing the academic performance of a journal, a researcher\nor a single paper has long remained a critical, necessary but also\ncontroversial issue. Most of existing metrics invalidate comparison across\ndifferent fields of science or even between different types of papers in the\nsame field. This paper proposes a new metric, called return on citation (ROC),\nwhich is simply a citation ratio but applies to evaluating the paper, the\njournal and the researcher in a consistent way, allowing comparison across\ndifferent fields of science and between different types of papers and\ndiscouraging unnecessary and coercive/self-citation."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.02.006", 
    "link": "http://arxiv.org/pdf/1502.00229v2", 
    "title": "Can \"Hot Spots\" in the Sciences Be Mapped Using the Dynamics of   Aggregated Journal-Journal Citation Relations?", 
    "arxiv-id": "1502.00229v2", 
    "author": "Wouter de Nooy", 
    "publish": "2015-02-01T10:40:42Z", 
    "summary": "Using three years of the Journal Citation Reports (2011, 2012, and 2013),\nindicators of transitions in 2012 (between 2011 and 2013) are studied using\nmethodologies based on entropy statistics. Changes can be indicated at the\nlevel of journals using the margin totals of entropy production along the row\nor column vectors, but also at the level of links among journals by importing\nthe transition matrices into network analysis and visualization programs (and\nusing community-finding algorithms). Seventy-four journals are flagged in terms\nof discontinuous changes in their citations; but 3,114 journals are involved in\n\"hot\" links. Most of these links are embedded in a main component; 78 clusters\n(containing 172 journals) are flagged as potential \"hot spots\" emerging at the\nnetwork level. An additional finding is that PLoS ONE introduced a new\ncommunication dynamics into the database. The limitations of the methodology\nare elaborated using an example. The results of the study indicate where\ndevelopments in the citation dynamics can be considered as significantly\nunexpected. This can be used as heuristic information; but what a \"hot spot\" in\nterms of the entropy statistics of aggregated citation relations means\nsubstantively can be expected to vary from case to case."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.02.006", 
    "link": "http://arxiv.org/pdf/1502.00658v1", 
    "title": "Throwing Out the Baby with the Bathwater: The Undesirable Effects of   National Research Assessment Exercises on Research", 
    "arxiv-id": "1502.00658v1", 
    "author": "Leroy White", 
    "publish": "2015-02-02T21:51:59Z", 
    "summary": "The evaluation of the quality of research at a national level has become\nincreasingly common. The UK has been at the forefront of this trend having\nundertaken many assessments since 1986, the latest being the Research\nExcellence Framework in 2014. The argument of this paper is that, whatever the\nintended results in terms of evaluating and improving research, there have been\nmany, presumably unintended, results that are highly undesirable for research\nand the university community more generally. We situate our analysis using\nBourdieu's theory of cultural reproduction and then focus on the peculiarities\nof the 2008 RAE and the 2014 REF the rules of which allowed for, and indeed\nencouraged, significant game-playing on the part of striving universities. We\nconclude with practical recommendations to maintain the general intention of\nresearch assessment without the undesirable side-effects."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.02.006", 
    "link": "http://arxiv.org/pdf/1502.01329v2", 
    "title": "A proposal for regularly updated review/survey articles: \"Perpetual   Reviews\"", 
    "arxiv-id": "1502.01329v2", 
    "author": "Daniel M. Zuckerman", 
    "publish": "2015-02-03T17:16:42Z", 
    "summary": "We advocate the publication of review/survey articles that will be updated\nregularly, both in traditional journals and novel venues. We call these\n\"perpetual reviews.\" This idea naturally builds on the dissemination and\narchival capabilities present in the modern internet, and indeed perpetual\nreviews exist already in some forms. Perpetual review articles allow authors to\nmaintain over time the relevance of non-research scholarship that requires a\nsignificant investment of effort. Further, such reviews published in a purely\nelectronic format without space constraints can also permit more pedagogical\nscholarship and clearer treatment of technical issues that remain obscure in a\nbrief treatment."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.02.006", 
    "link": "http://arxiv.org/pdf/1502.03943v1", 
    "title": "Improving Access to Digitized Historical Newspapers with Text Mining,   Coordinated Models, and Formative User Interface Design", 
    "arxiv-id": "1502.03943v1", 
    "author": "Robert B. Allen", 
    "publish": "2015-02-13T11:12:55Z", 
    "summary": "Most tools for accessing digitized historical newspapers emphasize relatively\nsimple search; but, as increasing numbers of digitized historical newspapers\nand other historical resources become available we can consider much richer\nmodes of interaction with these collections. For instance, users might use\nexploratory search for looking at larger issues and events such as elections\nand campaigns or to get a sense of \"the texture of the city\" or \"what the city\nwas thinking\". To take full advantage of rich interface tools, the content of\nthe newspapers needs to be described systematically and accurately. Moreover,\ncollections of multiple newspapers need to be richly cross-indexed across\ntitles and even with historical resources beyond the newspapers."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.02.006", 
    "link": "http://arxiv.org/pdf/1502.04069v1", 
    "title": "Evaluating Open Access Paper Repository In Higher Education For Asean   Region", 
    "arxiv-id": "1502.04069v1", 
    "author": "Fikri Saleh", 
    "publish": "2015-02-13T17:52:36Z", 
    "summary": "Paper repository at higher education is a collection of scientific articles\ncreated by the academic society. This study took as many as 80 universities in\nthe Webometrics ranking of repositories in the Southeast Asia region. The tools\nused in this research is Google for number of web page and Google Scholar for\nnumber of document paper repository and Ahrefs for referring page, backlink and\nreffering domain. The result of this study, Eprints is the most widely used\ntools in higher education, as many as 37 higher educations (46,25%). Institut\nTeknologi Sepuluh November got the highest score in number of web page in\nGoogle (2.010.000), Bogor Agricultural University Scientific Repository got the\nhighest score for number of document paper (44.300). University of Sumatera\nUtara Repository got the highest score for reffering page (82588) and backlink\n(86421). Universiti Teknologi Malaysia Institutional Repository got the highest\nscore for reffering domain (532)."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.02.006", 
    "link": "http://arxiv.org/pdf/1502.04108v1", 
    "title": "Structured Descriptions of Roles, Activities,and Procedures in the Roman   Constitution", 
    "arxiv-id": "1502.04108v1", 
    "author": "Robert B. Allen", 
    "publish": "2015-02-13T20:29:21Z", 
    "summary": "A highly structured description of entities and events in histories can\nsupport flexible exploration of those histories by users and, ultimately,\nsupport richly-linked full-text digital libraries. Here, we apply the Basic\nFormal Ontology (BFO) to structure a passage about the Roman Constitution from\nGibbon's Decline and Fall of the Roman Empire. Specifically, we consider the\nspecification of Roles such as Consuls, Activities associated with those Roles,\nand Procedures for accomplishing those Activities."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.02.006", 
    "link": "http://arxiv.org/pdf/1502.04250v1", 
    "title": "Hyperlinks embedded in Twitter as a proxy for total external inlinks to   international university websites", 
    "arxiv-id": "1502.04250v1", 
    "author": "Emilio Delgado Lopez-Cozar", 
    "publish": "2015-02-14T21:50:57Z", 
    "summary": "This article analyzes Twitter as a potential alternative source of external\nlinks for use in webometric analysis because of its capacity to embed\nhyperlinks in different tweets. Given the limitations on searching Twitter's\npublic API, we decided to use the Topsy search engine as a source for compiling\ntweets. To this end, we took a global sample of 200 universities and compiled\nall the tweets with hyperlinks to any of these institutions. Further link data\nwas obtained from alternative sources (MajesticSEO and OpenSiteExplorer) in\norder to compare the results. Thereafter, various statistical tests were\nperformed to determine the correlation between the indicators and the ability\nto predict external links from the collected tweets. The results indicate a\nhigh volume of tweets, although they are skewed by the presence and performance\nof specific universities and countries. The data provided by Topsy correlated\nsignificantly with all link indicators, particularly with OpenSiteExplorer\n(r=0.769). Finally, prediction models do not provide optimum results because of\nhigh error rates, which fall slightly in nonlinear models applied to specific\nenvironments. We conclude that the use of Twitter (via Topsy) as a source of\nhyperlinks to universities produces promising results due to its high\ncorrelation with link indicators, though limited by policies and culture\nregarding use and presence in social networks."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.02.006", 
    "link": "http://arxiv.org/pdf/1502.05676v3", 
    "title": "Journal Portfolio Analysis for Countries, Cities, and Organizations:   Maps and Comparisons", 
    "arxiv-id": "1502.05676v3", 
    "author": "Daniele Rotolo", 
    "publish": "2015-02-19T19:41:11Z", 
    "summary": "Using Web-of-Science data, portfolio analysis in terms of journal coverage\ncan be projected on a base map for units of analysis such as countries, cities,\nuniversities, and firms. The units of analysis under study can be compared\nstatistically across the 10,000+ journals. The interdisciplinarity of the\nportfolios is measured using Rao-Stirling diversity or Zhang et al.'s (in\npress) improved measure 2D3. At the country level we find regional\ndifferentiation (e.g., Latin-American or Asian countries), but also a major\ndivide between advanced and less-developed countries. Israel and Israeli cities\noutperform other nations and cities in terms of diversity. Universities appear\nto be specifically related to firms when a number of these units are\nexploratively compared. The instrument is relatively simple and\nstraightforward, and one can generalize the application to any document set\nretrieved from WoS. Further instruction is provided online at\nhttp://www.leydesdorff.net/portfolio ."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.02.006", 
    "link": "http://arxiv.org/pdf/1502.05701v1", 
    "title": "Interpreting \"altmetrics\": viewing acts on social media through the lens   of citation and social theories", 
    "arxiv-id": "1502.05701v1", 
    "author": "Rodrigo Costas", 
    "publish": "2015-02-19T20:54:48Z", 
    "summary": "More than 30 years after Cronin's seminal paper on \"the need for a theory of\nciting\" (Cronin, 1981), the metrics community is once again in need of a new\ntheory, this time one for so-called \"altmetrics\". Altmetrics, short for\nalternative (to citation) metrics -- and as such a misnomer -- refers to a new\ngroup of metrics based (largely) on social media events relating to scholarly\ncommunication. As current definitions of altmetrics are shaped and limited by\nactive platforms, technical possibilities, and business models of aggregators\nsuch as Altmetric.com, ImpactStory, PLOS, and Plum Analytics, and as such\nconstantly changing, this work refrains from defining an umbrella term for\nthese very heterogeneous new metrics. Instead a framework is presented that\ndescribes acts leading to (online) events on which the metrics are based. These\nactivities occur in the context of social media, such as discussing on Twitter\nor saving to Mendeley, as well as downloading and citing. The framework groups\nvarious types of acts into three categories -- accessing, appraising, and\napplying -- and provides examples of actions that lead to visibility and\ntraceability online. To improve the understanding of the acts, which result in\nonline events from which metrics are collected, select citation and social\ntheories are used to interpret the phenomena being measured. Citation theories\nare used because the new metrics based on these events are supposed to replace\nor complement citations as indicators of impact. Social theories, on the other\nhand, are discussed because there is an inherent social aspect to the\nmeasurements."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.02.006", 
    "link": "http://arxiv.org/pdf/1502.06378v1", 
    "title": "Bibliometrics/Citation networks", 
    "arxiv-id": "1502.06378v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2015-02-23T10:40:42Z", 
    "summary": "In addition to shaping social networks, for example, in terms of\nco-authorship relations, scientific communications induce and reproduce\ncognitive structures. Scientific literature is intellectually organized in\nterms of disciplines and specialties; these structures are reproduced and\nnetworked reflexively by making references to the authors, concepts and texts\nembedded in these literatures. The concept of a cognitive structure was\nintroduced in social network analysis (SNA) in 1987 by David Krackhardt, but\nthe focus in SNA has hitherto been on cognition as a psychological attribute of\nhuman agency. In bibliometrics, and in science and technology studies (STS)\nmore generally, socio-cognitive structures refer to intellectual organization\nat the supra-individual level. This intellectual organization emerges and is\nreproduced by the collectives of authors who are organized not only in terms of\ninter-personal relations, but also more abstractly in terms of codes of\ncommunication that are field-specific. Citations can serve as indicators of\nthis codification process."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.02.006", 
    "link": "http://arxiv.org/pdf/1503.01298v2", 
    "title": "Research Data Explored II: the Anatomy and Reception of figshare", 
    "arxiv-id": "1503.01298v2", 
    "author": "Isabella Peters", 
    "publish": "2015-03-04T12:45:38Z", 
    "summary": "This is the second paper in a series of bibliometric studies of research\ndata. In this paper, we present an analysis of figshare, one of the largest\nmultidisciplinary repositories for research materials to date. We analysed the\nstructure of items archived in figshare, their usage, and their reception in\ntwo altmetrics sources (PlumX and ImpactStory). We found that figshare acts (1)\nas a personal repository for yet unpublished materials, (2) as a platform for\nnewly published research materials, and (3) as an archive for PLOS. Depending\non the function, we found different bibliometric characteristics. Items\narchived from PLOS tend to be coming from the natural sciences and are often\nunviewed and non-downloaded. Self-archived items, however, come from a variety\nof disciplines and exhibit some patterns of higher usage. In the altmetrics\nanalysis, we found that Twitter was the social media service where research\ndata gained most attention; generally, research data published in 2014 were\nmost popular across social media services. PlumX detects considerably more\nitems in social media and also finds higher altmetric scores than ImpactStory."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.02.006", 
    "link": "http://arxiv.org/pdf/1503.01380v2", 
    "title": "Journal rank in the Science and Technology domain: A lightweight   quantitative approach for evaluation", 
    "arxiv-id": "1503.01380v2", 
    "author": "Sidhant Gupta", 
    "publish": "2015-03-04T16:46:48Z", 
    "summary": "The evaluation of journals based on their influence is of interest for\nnumerous reasons. Various methods of computing a score have been proposed for\nmeasuring the scientific influence of scholarly journals. Typically the\ncomputation of any of these scores involves compiling the citation information\npertaining to the journal under consideration. This involves significant\noverhead since the article citation information of not only the journal under\nconsideration but also that of other journals for the recent few years need to\nbe stored. Our work is motivated by the idea of developing a computationally\nlightweight approach that does not require any data storage, yet yields a score\nwhich is useful for measuring the importance of journals. In this paper, a\nregression analysis based method is proposed to calculate Journal Influence\nScore. Proposed model is validated using historical data from the SCImago\nportal. The results show that the error is small between rankings obtained\nusing the proposed method and the SCImago Journal Rank, thus proving that the\nproposed approach is a feasible and effective method of calculating scientific\nimpact of journals."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.02.006", 
    "link": "http://arxiv.org/pdf/1503.01960v1", 
    "title": "Conferences vs. Journals: Throwing the baby out with the bath water?", 
    "arxiv-id": "1503.01960v1", 
    "author": "Claudio Gutierrez", 
    "publish": "2015-03-06T14:03:01Z", 
    "summary": "Criticism of the conference model should be put in context. Evidences suggest\nthat the essential features of this model have emerged as responses to\nchallenges posed by current trends of scientific research and the impact of the\nnew techno-economic paradigm, the age of Information and Communication\nTechnology. This context seems indispensable when discussing today's problems\nof scientific evaluation, in particular the Conference vs. Journal (CvJ)\ndebate. This debate, also, would benefit from systematic historical and\nsociological studies of these practices. In this note we briefly develop these\narguments."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2702613.2732781", 
    "link": "http://arxiv.org/pdf/1503.04358v1", 
    "title": "Ariadne's Thread - Interactive Navigation in a World of Networked   Information", 
    "arxiv-id": "1503.04358v1", 
    "author": "Gwenn Englebienne", 
    "publish": "2015-03-14T22:42:49Z", 
    "summary": "This work-in-progress paper introduces an interface for the interactive\nvisual exploration of the context of queries using the ArticleFirst database, a\nproduct of OCLC. We describe a workflow which allows the user to browse live\nentities associated with 65 million articles. In the on-line interface, each\nquery leads to a specific network representation of the most prevailing\nentities: topics (words), authors, journals and Dewey decimal classes linked to\nthe set of terms in the query. This network represents the context of a query.\nEach of the network nodes is clickable: by clicking through, a user traverses a\nlarge space of articles along dimensions of authors, journals, Dewey classes\nand words simultaneously. We present different use cases of such an interface.\nThis paper provides a link between the quest for maps of science and on-going\ndebates in HCI about the use of interactive information visualisation to\nempower users in their search."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2702613.2732781", 
    "link": "http://arxiv.org/pdf/1503.05096v1", 
    "title": "Exploring Coverage and Distribution of Identifiers on the Scholarly Web", 
    "arxiv-id": "1503.05096v1", 
    "author": "Elisabeth Lex", 
    "publish": "2015-03-17T15:37:24Z", 
    "summary": "In a scientific publishing environment that is increasingly moving online,\nidentifiers of scholarly work are gaining in importance. In this paper, we\nanalysed identifier distribution and coverage of articles from the discipline\nof quantitative biology using arXiv, Mendeley and CrossRef as data sources. The\nresults show that when retrieving arXiv articles from Mendeley, we were able to\nfind more papers using the DOI than the arXiv ID. This indicates that DOI may\nbe a better identifier with respect to findability. We also find that coverage\nof articles on Mendeley decreases in the most recent years, whereas the\ncoverage of DOIs does not decrease in the same order of magnitude. This hints\nat the fact that there is a certain time lag involved, before articles are\ncovered in crowd-sourced services on the scholarly web."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2702613.2732781", 
    "link": "http://arxiv.org/pdf/1503.05443v2", 
    "title": "Can we track the geography of surnames based on bibliographic data?", 
    "arxiv-id": "1503.05443v2", 
    "author": "Rodrigo Costas", 
    "publish": "2015-03-18T15:06:42Z", 
    "summary": "In this paper we explore the possibility of using bibliographic databases for\ntracking the geographic origin of surnames. Surnames are used as a proxy to\ndetermine the ethnic, genetic or geographic origin of individuals in many\nfields such as Genetics or Demography; however they could also be used for\nbibliometric purposes such as the analysis of scientific migration flows. Here\nwe present two relevant methodologies for determining the most probable country\nto which a surname could be assigned. The first methodology assigns surnames\nbased on the most common country that can be assigned to a surname and the\nKullback-Liebler divergence measure. The second method uses the Gini Index to\nevaluate the assignment of surnames to countries. We test both methodologies\nwith control groups and conclude that, despite needing further analysis on its\nvalidity; these methodologies already show promising results."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2702613.2732781", 
    "link": "http://arxiv.org/pdf/1503.05881v1", 
    "title": "ADS 2.0: new architecture, API and services", 
    "arxiv-id": "1503.05881v1", 
    "author": "Vladimir Sudilovsky", 
    "publish": "2015-03-19T18:54:03Z", 
    "summary": "The ADS platform is undergoing the biggest rewrite of its 20-year history.\nWhile several components have been added to its architecture over the past\ncouple of years, this talk will concentrate on the underpinnings of ADS's\nsearch layer and its API. To illustrate the design of the components in the new\nsystem, we will show how the new ADS user interface is built exclusively on top\nof the API using RESTful web services. Taking one step further, we will discuss\nhow we plan to expose the treasure trove of information hosted by ADS (10\nmillion records and fulltext for much of the Astronomy and Physics refereed\nliterature) to partners interested in using this API. This will provide you\n(and your intelligent applications) with access to ADS's underlying data to\nenable the extraction of new knowledge and the ingestion of these results back\ninto the ADS. Using this framework, researchers could run controlled\nexperiments with content extraction, machine learning, natural language\nprocessing, etc. In this talk, we will discuss what is already implemented,\nwhat will be available soon, and where we are going next."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2702613.2732781", 
    "link": "http://arxiv.org/pdf/1503.06268v1", 
    "title": "On the categorization of scientific citation profiles in computer   sciences", 
    "arxiv-id": "1503.06268v1", 
    "author": "Animesh Mukherjee", 
    "publish": "2015-03-21T06:03:44Z", 
    "summary": "A common consensus in the literature is that the citation profile of\npublished articles in general follows a universal pattern - an initial growth\nin the number of citations within the first two to three years after\npublication followed by a steady peak of one to two years and then a final\ndecline over the rest of the lifetime of the article. This observation has long\nbeen the underlying heuristic in determining major bibliometric factors such as\nthe quality of a publication, the growth of scientific communities, impact\nfactor of publication venues etc. In this paper, we gather and analyze a\nmassive dataset of scientific papers from the computer science domain and\nnotice that the citation count of the articles over the years follows a\nremarkably diverse set of patterns - a profile with an initial peak (PeakInit),\nwith distinct multiple peaks (PeakMul), with a peak late in time (PeakLate),\nthat is monotonically decreasing (MonDec), that is monotonically increasing\n(MonIncr) and that can not be categorized into any of the above (Oth). We\nconduct a thorough experiment to investigate several important characteristics\nof these categories such as how individual categories attract citations, how\nthe categorization is influenced by the year and the venue of publication of\npapers, how each category is affected by self-citations, the stability of the\ncategories over time, and how much each of these categories contribute to the\ncore of the network. Further, we show that the traditional preferential\nattachment models fail to explain these citation profiles. Therefore, we\npropose a novel dynamic growth model that takes both the preferential\nattachment and the aging factor into account in order to replicate the\nreal-world behavior of various citation profiles. We believe that this paper\nopens the scope for a serious re-investigation of the existing bibliometric\nindices for scientific research."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2702613.2732781", 
    "link": "http://arxiv.org/pdf/1503.06683v1", 
    "title": "Extending search facilities via bibliometric-enhanced stratagems", 
    "arxiv-id": "1503.06683v1", 
    "author": "Philipp Mayr", 
    "publish": "2015-03-23T15:22:20Z", 
    "summary": "The paper introduces simple bibliometric-enhanced search facilities which are\nderived from the famous stratagems by Bates. Moves, tactics and stratagems are\nrevisited from a Digital Library perspective. The potential of extended\nversions of \"journal run\" or \"citation search\" for interactive information\nretrieval is outlined. The authors elaborate on the future implementation and\nevaluation of new bibliometric-enhanced search services."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2702613.2732781", 
    "link": "http://arxiv.org/pdf/1503.07496v1", 
    "title": "P-score: A Publication-based Metric for Academic Productivity", 
    "arxiv-id": "1503.07496v1", 
    "author": "Nivio Ziviani", 
    "publish": "2015-03-11T17:04:37Z", 
    "summary": "In this work we propose a metric to assess academic productivity based on\npublication outputs. We are interested in knowing how well a research group in\nan area of knowledge is doing relatively to a pre-selected set of reference\ngroups, where each group is composed by academics or researchers. To assess\nacademic productivity we propose a new metric, which we call P-score. Our\nmetric P-score assigns weights to venues using only the publication patterns of\nselected reference groups. This implies that P-score does not depend on\ncitation data and thus, that it is simpler to compute particularly in contexts\nin which citation data is not easily available. Also, preliminary experiments\nsuggest that P-score preserves strong correlation with citation-based metrics."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2702613.2732781", 
    "link": "http://arxiv.org/pdf/1503.08944v3", 
    "title": "The Normalization of Occurrence and Co-occurrence Matrices in   Bibliometrics using Cosine Similarities and Ochiai Coefficients", 
    "arxiv-id": "1503.08944v3", 
    "author": "Loet Leydesdorff", 
    "publish": "2015-03-31T07:53:31Z", 
    "summary": "We prove that Ochiai similarity of the co-occurrence matrix is equal to\ncosine similarity in the underlying occurrence matrix. Neither the cosine nor\nthe Pearson correlation should be used for the normalization of co-occurrence\nmatrices because the similarity is then normalized twice, and therefore\nover-estimated; the Ochiai coefficient can be used instead. Results are shown\nusing a small matrix (5 cases, 4 variables) for didactic reasons, and also\nAhlgren et al.'s (2003) co-occurrence matrix of 24 authors in library and\ninformation sciences. The over-estimation is shown numerically and will be\nillustrated using multidimensional scaling and cluster dendograms. If the\noccurrence matrix is not available (such as in internet research or author\nco-citation analysis) using Ochiai for the normalization is preferable to using\nthe cosine."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.06.005", 
    "link": "http://arxiv.org/pdf/1503.09156v1", 
    "title": "Predicting the long-term citation impact of recent publications", 
    "arxiv-id": "1503.09156v1", 
    "author": "Ludo Waltman", 
    "publish": "2015-03-31T18:36:42Z", 
    "summary": "A fundamental problem in citation analysis is the prediction of the long-term\ncitation impact of recent publications. We propose a model to predict a\nprobability distribution for the future number of citations of a publication.\nTwo predictors are used: The impact factor of the journal in which a\npublication has appeared and the number of citations a publication has received\none year after its appearance. The proposed model is based on quantile\nregression. We employ the model to predict the future number of citations of a\nlarge set of publications in the field of physics. Our analysis shows that both\npredictors (i.e., impact factor and early citations) contribute to the accurate\nprediction of long-term citation impact. We also analytically study the\nbehavior of the quantile regression coefficients for high quantiles of the\ndistribution of citations. This is done by linking the quantile regression\napproach to a quantile estimation technique from extreme value theory. Our work\nprovides insight into the influence of the impact factor and early citations on\nthe long-term citation impact of a publication, and it takes a step toward a\nmethodology that can be used to assess research institutions based on their\nmost recently published work."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.06.005", 
    "link": "http://arxiv.org/pdf/1504.01027v1", 
    "title": "Mapeamento Sistematico", 
    "arxiv-id": "1504.01027v1", 
    "author": "Marco Santos", 
    "publish": "2015-04-04T17:14:33Z", 
    "summary": "A systematic mapping is a way to identify, evaluate and interpret all\nrelevant research available to a matter of particular research. One of the\nreasons for conducting systematic reviews is that it summarizes the existing\nevidence regarding treatment or technology [Kitchenham, 2004]."
},{
    "category": "cs.DL", 
    "doi": "10.1108/AJIM-03-2015-0047", 
    "link": "http://arxiv.org/pdf/1504.01877v2", 
    "title": "Social media in scholarly communication", 
    "arxiv-id": "1504.01877v2", 
    "author": "Vincent Larivi\u00e8re", 
    "publish": "2015-04-08T09:26:22Z", 
    "summary": "Social media metrics - commonly coined as \"altmetrics\" - have been heralded\nas great democratizers of science, providing broader and timelier indicators of\nimpact than citations. These metrics come from a range of sources, including\nTwitter, blogs, social reference managers, post-publication peer review, and\nother social media platforms. Social media metrics have begun to be used as\nindicators of scientific impact, yet the theoretical foundation, empirical\nvalidity, and extent of use of platforms underlying these metrics lack thorough\ntreatment in the literature. This editorial provides an overview of terminology\nand definitions of altmetrics and summarizes current research regarding social\nmedia use in academia, social media metrics as well as data reliability and\nvalidity. The papers of the special issue are introduced."
},{
    "category": "cs.DL", 
    "doi": "10.1108/AJIM-03-2015-0047", 
    "link": "http://arxiv.org/pdf/1504.02261v1", 
    "title": "Open Access Policy: Numbers, Analysis, Effectiveness", 
    "arxiv-id": "1504.02261v1", 
    "author": "S. Harnad", 
    "publish": "2015-04-09T11:16:34Z", 
    "summary": "The PASTEUR4OA project analyses what makes an Open Access (OA) policy\neffective. The total number of institutional or funder OA policies worldwide is\nnow 663 (March 2015), over half of them mandatory. ROARMAP, the policy\nregistry, has been rebuilt to record more policy detail and provide more\nextensive search functionality. Deposit rates were measured for articles in\ninstitutions' repositories and compared to the total number of WoS-indexed\narticles published from those institutions. Average deposit rate was over four\ntimes as high for institutions with a mandatory policy. Six positive\ncorrelations were found between deposit rates and (1) Must-Deposit; (2)\nCannot-Waive-Deposit; (3) Deposit-Linked-to-Research-Evaluation; (4)\nCannot-Waive-Rights-Retention; (5) Must-Make-Deposit-OA (after allowable\nembargo) and (6) Can-Waive-OA. For deposit latency, there is a positive\ncorrelation between earlier deposit and (7) Must-Deposit-Immediately as well as\nwith (4) Cannot-Waive-Rights-Retention and with mandate age. There are not yet\nenough OA policies to test whether still further policy conditions would\ncontribute to mandate effectiveness but the present findings already suggest\nthat it would be useful for current and future OA policies to adopt the seven\npositive conditions so as to accelerate and maximise the growth of OA."
},{
    "category": "cs.DL", 
    "doi": "10.1108/AJIM-03-2015-0047", 
    "link": "http://arxiv.org/pdf/1504.02576v1", 
    "title": "Highly-cited papers in Library and Information Science (LIS): Authors,   institutions, and network structures", 
    "arxiv-id": "1504.02576v1", 
    "author": "Lutz Bornmann", 
    "publish": "2015-04-10T08:00:29Z", 
    "summary": "As a follow-up to the highly-cited authors list published by Thomson Reuters\nin June 2014, we analyze the top-1% most frequently cited papers published\nbetween 2002 and 2012 included in the Web of Science (WoS) subject category\n\"Information Science & Library Science.\" 798 authors contributed to 305 top-1%\npublications; these authors were employed at 275 institutions. The authors at\nHarvard University contributed the largest number of papers, when the addresses\nare whole-number counted. However, Leiden University leads the ranking, if\nfractional counting is used.\n  Twenty-three of the 798 authors were also listed as most highly-cited authors\nby Thomson Reuters in June 2014 (http://highlycited.com/). Twelve of these 23\nauthors were involved in publishing four or more of the 305 papers under study.\nAnalysis of co-authorship relations among the 798 highly-cited scientists shows\nthat co-authorships are based on common interests in a specific topic. Three\ntopics were important between 2002 and 2012: (1) collection and exploitation of\ninformation in clinical practices, (2) the use of internet in public\ncommunication and commerce, and (3) scientometrics."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.01.003", 
    "link": "http://arxiv.org/pdf/1504.03115v2", 
    "title": "Bibliometric author evaluation through linear regression on the coauthor   network", 
    "arxiv-id": "1504.03115v2", 
    "author": "Rasmus A. X. Persson", 
    "publish": "2015-04-13T10:10:19Z", 
    "summary": "The rising trend of coauthored academic works obscures the credit assignment\nthat is the basis for decisions of funding and career advancements. In this\npaper, a simple model based on the assumption of an unvarying \"author ability\"\nis introduced. With this assumption, the weight of author contributions to a\nbody of coauthored work can be statistically estimated. The method is tested on\na set of some more than five-hundred authors in a coauthor network from the\nCiteSeerX database. The ranking obtained agrees fairly well with that given by\ntotal fractional citation counts for an author, but noticeable differences\nexist."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.01.003", 
    "link": "http://arxiv.org/pdf/1504.04478v2", 
    "title": "Evaluating the Quality of RDF Data Sets on Common Vocabularies in the   Social, Behavioral, and Economic Sciences", 
    "arxiv-id": "1504.04478v2", 
    "author": "Kai Eckert", 
    "publish": "2015-04-17T10:42:09Z", 
    "summary": "From 2012 to 2015 together with other Linked Data community members and\nexperts from the social, behavioral, and economic sciences (SBE), we developed\ndiverse vocabularies to represent SBE metadata and tabular data in RDF. The\nDDI-RDF Discovery Vocabulary (DDI-RDF) is designed to support the\ndissemination, management, and reuse of unit-record data, i.e., data about\nindividuals, households, and businesses, collected in form of responses to\nstudies and archived for research purposes. The RDF Data Cube Vocabulary (QB)\nis a W3C recommendation for expressing data cubes, i.e. multi-dimensional\naggregate data and its metadata. Physical Data Description (PHDD) is a\nvocabulary to model data in rectangular format, i.e., tabular data. The data\ncould either be represented in records with character-separated values (CSV) or\nfixed length. The Simple Knowledge Organization System (SKOS) is a vocabulary\nto build knowledge organization systems such as thesauri, classification\nschemes, and taxonomies. XKOS is a SKOS extension to describe formal\nstatistical classifications.\n  To ensure high quality of and trust in both metadata and data, their\nrepresentation in RDF must satisfy certain criteria - specified in terms of RDF\nconstraints. In this paper, we evaluate the data quality of 15,694 data sets\n(4.26 billion triples) of research data for the social, behavioral, and\neconomic sciences obtained from 33 SPARQL endpoints. We checked 115 constraints\non three different and representative SBE vocabularies (DDI-RDF, QB, and SKOS)\nby means of the RDF Validator, a validation environment which is available at\nhttp://purl.org/net/rdfval-demo."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.01.003", 
    "link": "http://arxiv.org/pdf/1504.04479v3", 
    "title": "Constraints to Validate RDF Data Quality on Common Vocabularies in the   Social, Behavioral, and Economic Sciences", 
    "arxiv-id": "1504.04479v3", 
    "author": "Kai Eckert", 
    "publish": "2015-04-17T10:43:44Z", 
    "summary": "To ensure high quality of and trust in both metadata and data, their\nrepresentation in RDF must satisfy certain criteria - specified in terms of RDF\nconstraints. From 2012 to 2015 together with other Linked Data community\nmembers and experts from the social, behavioral, and economic sciences (SBE),\nwe developed diverse vocabularies to represent SBE metadata and rectangular\ndata in RDF.\n  The DDI-RDF Discovery Vocabulary (DDI-RDF) is designed to support the\ndissemination, management, and reuse of unit-record data, i.e., data about\nindividuals, households, and businesses, collected in form of responses to\nstudies and archived for research purposes. The RDF Data Cube Vocabulary (QB)\nis a W3C recommendation for expressing data cubes, i.e. multi-dimensional\naggregate data and its metadata. Physical Data Description (PHDD) is a\nvocabulary to model data in rectangular format, i.e., tabular data. The data\ncould either be represented in records with character-separated values (CSV) or\nfixed length. The Simple Knowledge Organization System (SKOS) is a vocabulary\nto build knowledge organization systems such as thesauri, classification\nschemes, and taxonomies. XKOS is a SKOS extension to describe formal\nstatistical classifications.\n  In this paper, we describe RDF constraints to validate metadata on\nunit-record data (DDI-RDF), aggregated data (QB), thesauri (SKOS), and\nstatistical classifications (XKOS) and to validate tabular data (PHDD) - all of\nthem represented in RDF. We classified these constraints according to the\nseverity of occurring constraint violations. This technical report is updated\ncontinuously as modifying, adding, and deleting constraints remains ongoing\nwork."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.01.003", 
    "link": "http://arxiv.org/pdf/1504.05816v1", 
    "title": "A new generation of science overlay maps with an application to the   history of biosystematics", 
    "arxiv-id": "1504.05816v1", 
    "author": "Sandor Soos", 
    "publish": "2015-04-22T14:17:38Z", 
    "summary": "The paper proposes a text-mining based analytical framework aiming at the\ncognitive organization of complex scientific discourses. The approach is based\non models recently developed in science mapping, being a generalization of the\nso-called Science Overlay Mapping methodology, referred to as Topic Overlay\nMapping (TOM). It is shown that via applications of TOM in visualization,\ndocument clustering, time series analysis etc. the in-depth exploration and\neven the measurement of cognitive complexity and its dynamics is feasible for\nscientific domains. As a use case, an empirical study is presented into the\ndiscovery of a long-standing complex, interdisciplinary discourse, the debate\non the species concept in biosystematics."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.01.003", 
    "link": "http://arxiv.org/pdf/1504.05840v2", 
    "title": "The Dynamics of Triads in Aggregated Journal-Journal Citation Relations:   Specialty Developments at the Above-Journal Level", 
    "arxiv-id": "1504.05840v2", 
    "author": "Loet Leydesdorff", 
    "publish": "2015-04-22T14:58:47Z", 
    "summary": "Dyads of journals related by citations can agglomerate into specialties\nthrough the mechanism of triadic closure. Using the Journal Citation Reports\n2011, 2012, and 2013, we analyze triad formation as indicators of integration\n(specialty growth) and disintegration (restructuring). The strongest\nintegration is found among the large journals that report on studies in\ndifferent scientific specialties, such as PLoS ONE, Nature Communications,\nNature, and Science. This tendency towards large-scale integration has not yet\nstabilized. Using the Islands algorithm, we also distinguish 51 local maxima of\nintegration. We zoom into the cited articles that carry the integration for:\n(i) a new development within high-energy physics and (ii) an emerging interface\nbetween the journals Applied Mathematical Modeling and the International\nJournal of Advanced Manufacturing Technology. In the first case, integration is\nbrought about by a specific communication reaching across specialty boundaries,\nwhereas in the second, the dyad of journals indicates an emerging interface\nbetween specialties. These results suggest that integration picks up\nsubstantive developments at the specialty level. An advantage of the bottom-up\nmethod is that no ex ante classification of journals is assumed in the dynamic\nanalysis."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.01.003", 
    "link": "http://arxiv.org/pdf/1504.07479v2", 
    "title": "Cited Half-Life of the Journal Literature", 
    "arxiv-id": "1504.07479v2", 
    "author": "Angela Cochran", 
    "publish": "2015-04-28T14:03:27Z", 
    "summary": "Analyzing 13,455 journals listed in the Journal Citation Report (Thomson\nReuters) from 1997 through 2013, we report that the mean cited half-life of the\nscholarly literature is 6.5 years and growing at a rate of 0.13 years per\nannum. Focusing on a subset of journals (N=4,937) for which we have a\ncontinuous series of half-life observations, 209 of 229 (91%) subject\ncategories experienced increasing cited half-lives. Contrary to the overall\ntrend, engineering and chemistry journals experienced declining cited\nhalf-lives. Last, as journals attracted more citations, a larger proportion of\nthem were directed toward older papers. The trend to cite older papers is not\nfully explained by technology (digital publishing, search and retrieval, etc.),\nbut may be the result of a structural shift to fund incremental and applied\nresearch over fundamental science."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.01.003", 
    "link": "http://arxiv.org/pdf/1505.00796v1", 
    "title": "When is an article actually published? An analysis of online   availability, publication, and indexation dates", 
    "arxiv-id": "1505.00796v1", 
    "author": "Rodrigo Costas", 
    "publish": "2015-05-04T20:07:47Z", 
    "summary": "With the acceleration of scholarly communication in the digital era, the\npublication year is no longer a sufficient level of time aggregation for\nbibliometric and social media indicators. Papers are increasingly cited before\nthey have been officially published in a journal issue and mentioned on Twitter\nwithin days of online availability. In order to find a suitable proxy for the\nday of online publication allowing for the computation of more accurate\nbenchmarks and fine-grained citation and social media event windows, various\ndates are compared for a set of 58,896 papers published by Nature Publishing\nGroup, PLOS, Springer and Wiley-Blackwell in 2012. Dates include the online\ndate provided by the publishers, the month of the journal issue, the Web of\nScience indexing date, the date of the first tweet mentioning the paper as well\nas the Altmetric.com publication and first-seen dates. Comparing these dates,\nthe analysis reveals that large differences exist between publishers, leading\nto the conclusion that more transparency and standardization is needed in the\nreporting of publication dates. The date on which the fixed journal article\n(Version of Record) is first made available on the publisher's website is\nproposed as a consistent definition of the online date."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.01.003", 
    "link": "http://arxiv.org/pdf/1505.01074v2", 
    "title": "The BiPublishers ranking: Main results and methodological problems when   constructing rankings of academic publishers", 
    "arxiv-id": "1505.01074v2", 
    "author": "Enrique de la Fuente", 
    "publish": "2015-05-05T16:40:33Z", 
    "summary": "We present the results of the Bibliometric Indicators for Publishers project\n(also known as BiPublishers). This project represents the first attempt to\nsystematically develop bibliometric publisher rankings. The data for this\nproject was derived from the Book Citation Index, and the study time period was\n2009-2013. We have developed 42 rankings: 4 for by fields and 38 by\ndisciplines. We display six indicators by publisher divided into three types:\noutput, impact and publisher's profile. The aim is to capture different\ncharacteristics of the research performance of publishers. 254 publishers were\nprocessed and classified according to publisher type: commercial publishers and\nuniversity presses. We present the main publishers by fields. Then, we discuss\nthe main challenges presented when developing this type of tools. The\nBiPublishers ranking is an on-going project which aims to develop and explore\nnew data sources and indicators to better capture and define the research\nimpact of publishers."
},{
    "category": "cs.DL", 
    "doi": "10.6084/m9.figshare.1400482", 
    "link": "http://arxiv.org/pdf/1505.01342v1", 
    "title": "Analyzing readerships of International Iranian publications in Mendeley:   an altmetrics study", 
    "arxiv-id": "1505.01342v1", 
    "author": "Zohreh Zahedi", 
    "publish": "2015-05-06T12:38:35Z", 
    "summary": "In this study, the presence and distribution of both Mendeley readerships and\nWeb of Science citations for the publications published in the 43 Iranian\ninternational journals indexed in Journal Citation Reports have been\ninvestigated. The aim was to determine the impact, visibility and use of the\npublications published by the Iranian international journals in Mendeley\ncompared to their citation impact; furthermore, to explore if there is any\nrelation between these two impact indicators (Mendeley readership counts and\nWoS citation counts) for these publications. The DOIs of the 1,884 publications\nused to extract the readerships data from Mendeley REST API in February 2014\nand citations data until end of 2013 calculated using CWTS in-house WoS\ndatabase. SPSS (version 21) used to analyze the relationship between the\nreaderships and citations for those publications. The Mendeley usage\ndistribution both at the publication level (across publications years, fields\nand document types) and at the user level (across users disciplines, academic\nstatus and countries) have been investigated. These information will help to\nunderstand the visibility and usage vs citation pattern and impact of Iranian\nscientific outputs."
},{
    "category": "cs.DL", 
    "doi": "10.1108/AJIM-12-2014-0180", 
    "link": "http://arxiv.org/pdf/1505.01515v1", 
    "title": "Differences in Personal and Professional Tweets of Scholars", 
    "arxiv-id": "1505.01515v1", 
    "author": "Timothy D. Bowman", 
    "publish": "2015-05-06T20:44:47Z", 
    "summary": "Purpose: This study shows that there were differences in the use of Twitter\nby professors at universities in the Association of American Universities\n(AAU). Affordance use differed between the personal and professional tweets of\nprofessors. Framing behaviors were described that could impact the\ninterpretation of tweets by audience members. Design/methodology/approach: A\nthree phase research design was used that included surveys of professors,\ncategorization of tweets by Amazon's Mechanical Turk workers (i.e., turkers),\nand categorization of tweets by active professors on Twitter. Findings: There\nwere significant differences found between professors that reported having a\nTwitter account, significant differences found between types of Twitter\naccounts (personal, professional, or both), and significant differences in the\naffordances used in personal and professional tweets. Framing behaviors were\ndescribed that may assist altmetric researchers in distinguishing between\npersonal and professional tweets. Research limitations/implications (if\napplicable): The study is limited by the sample population, survey instrument,\nlow survey response rate, and low Cohen's kappa. Practical implications (if\napplicable): An overview of various affordances found in Twitter is provided\nand a novel use of Amazon's Mechanical Turk for the categorization of tweets is\ndescribed that can be applied to future altmetric studies. Originality/value:\nThis work utilizes a socio-technical framework integrating social and\npsychological theories to interpret results from the tweeting behavior of\nprofessors and the interpretation of tweets by workers in Amazon's Mechanical\nTurk."
},{
    "category": "cs.DL", 
    "doi": "10.1108/AJIM-12-2014-0180", 
    "link": "http://arxiv.org/pdf/1505.03671v1", 
    "title": "Informetric Analyses of Knowledge Organization Systems (KOSs)", 
    "arxiv-id": "1505.03671v1", 
    "author": "Wolfgang G. Stock", 
    "publish": "2015-05-14T10:26:04Z", 
    "summary": "A knowledge organization system (KOS) is made up of concepts and semantic\nrelations between the concepts which represent a knowledge domain\nterminologically. We distinguish between five approaches to KOSs:\nnomenclatures, classification systems, thesauri, ontologies and, as a\nborderline case of KOSs, folksonomies. The research question of this paper is:\nHow can we informetrically analyze the effectiveness of KOSs? Quantitative\ninformetric measures and indicators allow for the description, for comparative\nanalyses as well as for evaluation of KOSs and their quality. We describe the\nstate of the art of KOS evaluation. Most of the evaluation studies found in the\nliterature are about ontologies. We introduce measures of the structure of KOSs\n(e.g., groundedness, tangledness, fan-out factor, or granularity) and\nindicators of KOS quality (completeness, consistency, overlap, and use)."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.09.003", 
    "link": "http://arxiv.org/pdf/1505.04565v1", 
    "title": "A critical cluster analysis of 44 indicators of author-level performance", 
    "arxiv-id": "1505.04565v1", 
    "author": "Lorna Wildgaard", 
    "publish": "2015-05-18T09:18:06Z", 
    "summary": "This paper explores the relationship between author-level bibliometric\nindicators and the researchers the \"measure\", exemplified across five academic\nseniorities and four disciplines. Using cluster methodology, the disciplinary\nand seniority appropriateness of author-level indicators is examined.\nPublication and citation data for 741 researchers across Astronomy,\nEnvironmental Science, Philosophy and Public Health was collected in Web of\nScience (WoS). Forty-four indicators of individual performance were computed\nusing the data. A two-step cluster analysis using IBM SPSS version 22 was\nperformed, followed by a risk analysis and ordinal logistic regression to\nexplore cluster membership. Indicator scores were contextualized using the\nindividual researcher's curriculum vitae. Four different clusters based on\nindicator scores ranked researchers as low, middle, high and extremely high\nperformers. The results show that different indicators were appropriate in\ndemarcating ranked performance in different disciplines. In Astronomy the h2\nindicator, sum pp top prop in Environmental Science, Q2 in Philosophy and\ne-index in Public Health. The regression and odds analysis showed individual\nlevel indicator scores were primarily dependent on the number of years since\nthe researcher's first publication registered in WoS, number of publications\nand number of citations. Seniority classification was secondary therefore no\nseniority appropriate indicators were confidently identified. Cluster\nmethodology proved useful in identifying disciplinary appropriate indicators\nproviding the preliminary data preparation was thorough but needed to be\nsupplemented by other analyses to validate the results. A general disconnection\nbetween the performance of the researcher on their curriculum vitae and the\nperformance of the researcher based on bibliometric indicators was observed."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.09.003", 
    "link": "http://arxiv.org/pdf/1505.06007v1", 
    "title": "Scientometrics and Science Studies: From Words and Co-Words to   Information and Probabilistic Entropy", 
    "arxiv-id": "1505.06007v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2015-05-22T09:42:37Z", 
    "summary": "The tension between qualitative theorizing and quantitative methods is\npervasive in the social sciences, and poses a constant challenge to empirical\nresearch. But in science studies as an interdisciplinary specialty, there are\nadditional reasons why a more reflexive consciousness of the differences among\nthe relevant disciplines is necessary. How can qualitative insights from the\nhistory of ideas and the sociology of science be combined with the quantitative\nperspective? By using the example of the lexical and semantic value of word\noccurrences, the issue of qualitatively different meanings of the same\nphenomena is discussed as a methodological problem. Nine criteria for methods\nwhich are needed for the development of science studies as an integrated\nenterprise can then be specified. Information calculus is suggested as a method\nwhich can comply with these criteria."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.09.003", 
    "link": "http://arxiv.org/pdf/1505.08138v1", 
    "title": "Chinese Interpreting Studies: Genesis of a Discipline", 
    "arxiv-id": "1505.08138v1", 
    "author": "Ziyun Xu", 
    "publish": "2014-12-24T20:15:24Z", 
    "summary": "The growth of Chinese Interpreting Studies (CIS) has been robust over the\npast two decades; this is reflected in the total number of research papers\nproduced. This paper takes a scientometric approach to assessing the\nproduction, themes and theoretical influences of those papers over time. The\nmost productive authors, universities, and regions, as well as patterns of\nresearch collaboration, were analyzed to gain a deeper understanding of the CIS\nlandscape. This study reveals that the general culture of the discipline\nremained constant throughout the period, none of its theoretical influences or\ntopics having gained significantly in popularity. However, certain limitations\nin the way research is conducted (lack of collaboration, inadequate academic\npolicies, etc.) hinder its potential for future growth."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.09.003", 
    "link": "http://arxiv.org/pdf/1506.02783v1", 
    "title": "Weighted Impact Factor (WIF) for assessing the quality of scientific   journals", 
    "arxiv-id": "1506.02783v1", 
    "author": "Nigar Ismayilova", 
    "publish": "2015-06-09T05:29:51Z", 
    "summary": "Nowadays impact factor is the significant indicator for journal evaluation.\nIn impact factor calculation is used number of all citations to journal,\nregardless of the prestige of cited journals, however, scientific units (paper,\nresearcher, journal or scientific organization) cited by journals with high\nimpact factor or researchers with high Hirsch index are more important than\nobjects cited by journals without impact factor or unknown researcher. In this\npaper was offered weighted impact factor for getting more accurate rankings for\njournals, which consider not only quantity of citations, but also quality of\nciting journals. Correlation coefficients among different indicators for\njournal evaluation: impact factors by Thomson Scientific, weighted impact\nfactors offered by different researchers, average and medians of all citing\njournals impact factors and 5-year impact factors were analysed."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-015-1614-6", 
    "link": "http://arxiv.org/pdf/1506.03009v1", 
    "title": "Methods for estimating the size of Google Scholar", 
    "arxiv-id": "1506.03009v1", 
    "author": "Emilio Delgado Lopez-Cozar", 
    "publish": "2015-06-09T17:19:23Z", 
    "summary": "The emergence of academic search engines (mainly Google Scholar and Microsoft\nAcademic Search) that aspire to index the entirety of current academic\nknowledge has revived and increased interest in the size of the academic web.\nThe main objective of this paper is to propose various methods to estimate the\ncurrent size (number of indexed documents) of Google Scholar (May 2014) and to\ndetermine its validity, precision and reliability. To do this, we present,\napply and discuss three empirical methods: an external estimate based on\nempirical studies of Google Scholar coverage, and two internal estimate methods\nbased on direct, empty and absurd queries, respectively. The results, despite\nproviding disparate values, place the estimated size of Google Scholar at\naround 160 to 165 million documents. However, all the methods show considerable\nlimitations and uncertainties due to inconsistencies in the Google Scholar\nsearch functionalities."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-015-1596-4", 
    "link": "http://arxiv.org/pdf/1506.03012v1", 
    "title": "Revealing the online network between University and Industry: The case   of Turkey", 
    "arxiv-id": "1506.03012v1", 
    "author": "Selenay Aytac", 
    "publish": "2015-06-09T17:24:01Z", 
    "summary": "The present paper attempts to explore the relationship between the Turkish\nacademic and industry systems by mapping the relationships under web\nindicators. We used the top 100 Turkish universities and the top 10 Turkish\ncompanies in 10 industrial sectors in order to observe the performance of web\nimpact indicators. Total page count metric is obtained through Google Turkey\nand the pure link metrics have been gathered from Open Site Explorer. The\nindicators obtained both for web presence and web visibility indicated that\nthere are significant differences between the group of academic institutions\nand those related to companies within the web space of Turkey. However, this\ncurrent study is exploratory and should be replicated with a larger sample of\nboth Turkish universities and companies in each sector. Likewise, a\nlongitudinal study rather than sectional would eliminate or smooth fluctuations\nof web data (especially URL mentions) as a more adequate understanding of the\nrelations between Turkish institutions, and their web impact, is reached."
},{
    "category": "cs.DL", 
    "doi": "10.1108/OIR-11-2014-0282", 
    "link": "http://arxiv.org/pdf/1506.03027v1", 
    "title": "Disclosing the network structure of private companies on the web: the   case of Spanish IBEX 35 share index", 
    "arxiv-id": "1506.03027v1", 
    "author": "Nuria Lloret-Romero", 
    "publish": "2015-06-09T18:19:11Z", 
    "summary": "It is common for an international company to have different brands, products\nor services, information for investors, a corporate blog, affiliates, branches\nin different countries, etc. If all these contents appear as independent\nadditional web domains (AWD), the company should be represented on the web by\nall these web domains, since many of these AWDs may acquire remarkable\nperformance that could mask or distort the real web performance of the company,\naffecting therefore on the understanding of web metrics. The main objective of\nthis study is to determine the amount, type, web impact and topology of the\nadditional web domains in commercial companies in order to get a better\nunderstanding on their complete web impact and structure. The set of companies\nbelonging to the Spanish IBEX-35 stock index has been analyzed as testing\nbench. We proceeded to identify and categorize all AWDs belonging to these\ncompanies, and to apply both web impact (web presence and visibility) and\nnetwork metrics. The results show that AWDs get a high web presence but\nrelatively low web visibility, due to certain opacity or less dissemination of\nsome AWDs, favoring its isolation. This is verified by the low network density\nvalues obtained, that occur because AWDs are strongly connected with the\ncorporate domain (although asymmetrically), but very weakly linked each other.\nAlthough the processes of AWDs creation and categorization are complex (web\npolicy seems not to be driven by a defined or conscious plan), their influence\non the web performance of IBEX 35companies is meaningful. This research\nmeasures the AWDs influence on companies under webometric terms for the first\ntime."
},{
    "category": "cs.DL", 
    "doi": "10.1108/OIR-11-2014-0282", 
    "link": "http://arxiv.org/pdf/1506.06279v1", 
    "title": "Avoiding Spoilers in Fan Wikis of Episodic Fiction", 
    "arxiv-id": "1506.06279v1", 
    "author": "Michael L. Nelson", 
    "publish": "2015-06-20T18:45:12Z", 
    "summary": "A variety of fan-based wikis about episodic fiction (e.g., television shows,\nnovels, movies) exist on the World Wide Web. These wikis provide a wealth of\ninformation about complex stories, but if readers are behind in their viewing\nthey run the risk of encountering \"spoilers\" -- information that gives away key\nplot points before the intended time of the show's writers. Enterprising\nreaders might browse the wiki in a web archive so as to view the page prior to\na specific episode date and thereby avoid spoilers. Unfortunately, due to how\nweb archives choose the \"best\" page, it is still possible to see spoilers\n(especially in sparse archives).\n  In this paper we discuss how to use Memento to avoid spoilers. Memento uses\nTimeGates to determine which best archived page to give back to the user,\ncurrently using a minimum distance heuristic. We quantify how this heuristic is\ninadequate for avoiding spoilers, analyzing data collected from fan wikis and\nthe Internet Archive. We create an algorithm for calculating the probability of\nencountering a spoiler in a given wiki article. We conduct an experiment with\n16 wiki sites for popular television shows. We find that 38% of those pages are\nunavailable in the Internet Archive. We find that when accessing fan wiki pages\nin the Internet Archive there is as much as a 66% chance of encountering a\nspoiler. Using sample access logs from the Internet Archive, we find that 19%\nof actual requests to the Wayback Machine for wikia.com pages ended in\nspoilers. We suggest the use of a different minimum distance heuristic,\nminpast, for wikis, using the desired datetime as an upper bound."
},{
    "category": "cs.DL", 
    "doi": "10.1108/OIR-11-2014-0282", 
    "link": "http://arxiv.org/pdf/1506.06879v1", 
    "title": "A Probe into Causes of Non-citation Based on Survey Data", 
    "arxiv-id": "1506.06879v1", 
    "author": "Yishan Wu", 
    "publish": "2015-06-23T07:04:11Z", 
    "summary": "Empirical analysis results about the possible causes leading to non-citation\nmay help increase the potential of researchers' work to be cited and editorial\nstaffs of journals to identify contributions with potential high quality. In\nthis study, we conduct a survey on the possible causes leading to citation or\nnon-citation based on a questionnaire. We then perform a statistical analysis\nto identify the major causes leading to non-citation in combination with the\nanalysis on the data collected through the survey. Most respondents to our\nquestionnaire identified eight major causes that facilitate easy citation of\none's papers, such as research hotspots and novel topics of content, longer\nintervals after publication, research topics similar to my work, high quality\nof content, reasonable self-citation, highlighted title, prestigious authors,\nacademic tastes and interests similar to mine.They also pointed out that the\nvast difference between their current and former research directions as the\nprimary reason for their previously uncited papers. They feel that text that\nincludes notes, comments, and letters to editors are rarely cited, and the same\nis true for too short or too lengthy papers. In comparison, it is easier for\nreviews, articles, or papers of intermediate length to be cited."
},{
    "category": "cs.DL", 
    "doi": "10.1108/OIR-11-2014-0282", 
    "link": "http://arxiv.org/pdf/1507.00154v1", 
    "title": "Influence of study type on Twitter activity for medical research papers", 
    "arxiv-id": "1507.00154v1", 
    "author": "Stefanie Haustein", 
    "publish": "2015-07-01T08:58:08Z", 
    "summary": "Twitter has been identified as one of the most popular and promising\naltmetrics data sources, as it possibly reflects a broader use of research\narticles by the general public. Several factors, such as document age,\nscientific discipline, number of authors and document type, have been shown to\naffect the number of tweets received by scientific documents. The particular\nmeaning of tweets mentioning scholarly papers is, however, not entirely\nunderstood and their validity as impact indicators debatable. This study\ncontributes to the understanding of factors influencing Twitter popularity of\nmedical papers investigating differences between medical study types. 162,830\ndocuments indexed in Embase to a medical study type have been analysed for the\nstudy type specific tweet frequency. Meta-analyses, systematic reviews and\nclinical trials were found to be tweeted substantially more frequently than\nother study types, while all basic research received less attention than the\naverage. The findings correspond well with clinical evidence hierarchies. It is\nsuggested that interest from laymen and patients may be a factor in the\nobserved effects."
},{
    "category": "cs.DL", 
    "doi": "10.1108/OIR-11-2014-0282", 
    "link": "http://arxiv.org/pdf/1507.00524v1", 
    "title": "Strategies for Parallel Markup", 
    "arxiv-id": "1507.00524v1", 
    "author": "Bruce R. Miller", 
    "publish": "2015-07-02T11:11:18Z", 
    "summary": "Cross-referenced parallel markup for mathematics allows the combination of\nboth presentation and content representations while associating the components\nof each. Interesting applications are enabled by such an arrangement, such as\ninteraction with parts of the presentation to manipulate and querying the\ncorresponding content, and enhanced search indexing. Although the idea of such\nmarkup is hardly new, effective techniques for creating and manipulating it are\nmore difficult than it appears. Since the structures and tokens in the two\nformats often do not correspond one-to-one, decisions and heuristics must be\ndeveloped to determine in which way each component refers to and is referred to\nby components of the other representation. Conversion between fine and coarse\ngrained parallel markup complicates ID assignments. In this paper, we will\ndescribe the techniques developed for \\LaTeXML, a \\TeX/\\LaTeX to XML converter,\nto create cross-referenced parallel MathML. While we do not yet consider\n\\LaTeXML's content MathML to be useful, the current effort is a step towards\nthat continuing goal."
},{
    "category": "cs.DL", 
    "doi": "10.1108/OIR-11-2014-0282", 
    "link": "http://arxiv.org/pdf/1507.01328v1", 
    "title": "Altmetrics (Chapter from Beyond Bibliometrics: Harnessing   Multidimensional Indicators of Scholarly Impact)", 
    "arxiv-id": "1507.01328v1", 
    "author": "Jason Priem", 
    "publish": "2015-07-06T05:08:25Z", 
    "summary": "This chapter discusses altmetrics (short for \"alternative metrics\"), an\napproach to uncovering previously-invisible traces of scholarly impact by\nobserving activity in online tools and systems. I argue that citations, while\nuseful, miss many important kinds of impacts, and that the increasing scholarly\nuse of online tools like Mendeley, Twitter, and blogs may allow us to measure\nthese hidden impacts. Next, I define altmetrics and discuss research on\naltmetric sources--both research mapping the growth of these sources, and\nscientometric research measuring activity on them. Following a discussion of\nthe potential uses of altmetrics, I consider the limitations of altmetrics and\nrecommend areas ripe for future research."
},{
    "category": "cs.DL", 
    "doi": "10.1108/OIR-11-2014-0282", 
    "link": "http://arxiv.org/pdf/1507.01967v1", 
    "title": "Adapting sentiment analysis for tweets linking to scientific papers", 
    "arxiv-id": "1507.01967v1", 
    "author": "Stefanie Haustein", 
    "publish": "2015-07-07T21:00:32Z", 
    "summary": "In the context of altmetrics, tweets have been discussed as potential\nindicators of immediate and broader societal impact of scientific documents.\nHowever, it is not yet clear to what extent Twitter captures actual research\nimpact. A small case study (Thelwall et al., 2013b) suggests that tweets to\njournal articles neither comment on nor express any sentiments towards the\npublication, which suggests that tweets merely disseminate bibliographic\ninformation, often even automatically. This study analyses the sentiments of\ntweets for a large representative set of scientific papers by specifically\nadapting different methods to academic articles distributed on Twitter. Results\nwill help to improve the understanding of Twitter's role in scholarly\ncommunication and the meaning of tweets as impact metrics."
},{
    "category": "cs.DL", 
    "doi": "10.1108/OIR-11-2014-0282", 
    "link": "http://arxiv.org/pdf/1507.02093v1", 
    "title": "Do Mendeley readership counts help to filter highly cited WoS   publications better than average citation impact of journals (JCS)?", 
    "arxiv-id": "1507.02093v1", 
    "author": "Paul Wouters", 
    "publish": "2015-07-08T10:48:42Z", 
    "summary": "In this study, the academic status of users of scientific publications in\nMendeley is explored in order to analyse the usage pattern of Mendeley users in\nterms of subject fields, citation and readership impact. The main focus of this\nstudy is on studying the filtering capacity of Mendeley readership counts\ncompared to journal citation scores in detecting highly cited WoS publications.\nMain finding suggests a faster reception of Mendeley readerships as compared to\ncitations across 5 major field of science. The higher correlations of\nscientific users with citations indicate the similarity between reading and\ncitation behaviour among these users. It is confirmed that Mendeley readership\ncounts filter highly cited publications (PPtop 10%) better than journal\ncitation scores in all subject fields and by most of user types. This result\nreinforces the potential role that Mendeley readerships could play for\ninforming scientific and alternative impacts."
},{
    "category": "cs.DL", 
    "doi": "10.1108/OIR-11-2014-0282", 
    "link": "http://arxiv.org/pdf/1507.02095v1", 
    "title": "How well developed are Altmetrics? Cross-disciplinary analysis of the   presence of alternative metrics in scientific publications?", 
    "arxiv-id": "1507.02095v1", 
    "author": "Paul Wouters", 
    "publish": "2015-07-08T11:04:34Z", 
    "summary": "In this paper an analysis of the presence and possibilities of altmetrics for\nbibliometric and performance analysis is carried out. Using the web based tool\nImpact Story, we have collected metrics for 20,000 random publications from the\nWeb of Science. We studied the presence and frequency of altmetrics in the set\nof publications, across fields, document types and also through the years. The\nmain result of the study is that less than 50% of the publications have some\nkind of altmetrics. The source that provides most metrics is Mendeley, with\nmetrics on readerships for around 37% of all the publications studied. Other\nsources only provide marginal information. Possibilities and limitations of\nthese indicators are discussed and future research lines are outlined. We also\nassessed the accuracy of the data retrieved through Impact Story by focusing on\nthe analysis of the accuracy of data from Mendeley; in a follow up study, the\naccuracy and validity of other data sources not included here will be assessed."
},{
    "category": "cs.DL", 
    "doi": "10.1108/OIR-11-2014-0282", 
    "link": "http://arxiv.org/pdf/1507.02099v3", 
    "title": "A review of the literature on citation impact indicators", 
    "arxiv-id": "1507.02099v3", 
    "author": "Ludo Waltman", 
    "publish": "2015-07-08T11:21:58Z", 
    "summary": "Citation impact indicators nowadays play an important role in research\nevaluation, and consequently these indicators have received a lot of attention\nin the bibliometric and scientometric literature. This paper provides an\nin-depth review of the literature on citation impact indicators. First, an\noverview is given of the literature on bibliographic databases that can be used\nto calculate citation impact indicators (Web of Science, Scopus, and Google\nScholar). Next, selected topics in the literature on citation impact indicators\nare reviewed in detail. The first topic is the selection of publications and\ncitations to be included in the calculation of citation impact indicators. The\nsecond topic is the normalization of citation impact indicators, in particular\nnormalization for field differences. Counting methods for dealing with\nco-authored publications are the third topic, and citation impact indicators\nfor journals are the last topic. The paper concludes by offering some\nrecommendations for future research."
},{
    "category": "cs.DL", 
    "doi": "10.1108/OIR-11-2014-0282", 
    "link": "http://arxiv.org/pdf/1507.03314v1", 
    "title": "Evaluation of the citation matching algorithms of CWTS and iFQ in   comparison to Web of Science", 
    "arxiv-id": "1507.03314v1", 
    "author": "Nees Jan van Eck", 
    "publish": "2015-07-13T02:57:11Z", 
    "summary": "The results of bibliometric studies provided by bibliometric research groups,\ne.g. the Centre for Science and Technology Studies (CWTS) and the Institute for\nResearch Information and Quality Assurance (iFQ), are often used in the process\nof research assessment. Their databases use Web of Science (WoS) citation data,\nwhich they match according to their own matching algorithms - in the case of\nCWTS for standard usage in their studies and in the case of iFQ on an\nexperimental basis. Since the problem of non-matched citations in WoS persists\nbecause of inaccuracies in the references or inaccuracies introduced in the\ndata extraction process, it is important to ascertain how well these\ninaccuracies are rectified in these citation matching algorithms. This paper\nevaluates the algorithms of CWTS and iFQ in comparison to WoS in a quantitative\nand a qualitative analysis. The analysis builds upon the methodology and the\nmanually verified corpus of a previous study. The algorithm of CWTS performs\nbest, closely followed by that of iFQ. The WoS algorithm still performs quite\nwell (F1 score: 96.41 percent), but shows deficits in matching references\ncontaining inaccuracies. An additional problem is posed by incorrectly provided\ncited reference information in source articles by WoS."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.01.009", 
    "link": "http://arxiv.org/pdf/1507.04720v2", 
    "title": "Assessing evaluation procedures for individual researchers: the case of   the Italian National Scientific Qualification", 
    "arxiv-id": "1507.04720v2", 
    "author": "Moreno Marzolla", 
    "publish": "2015-07-16T19:31:25Z", 
    "summary": "The Italian National Scientific Qualification (ASN) was introduced as a\nprerequisite for applying for tenured associate or full professor positions at\nstate-recognized universities. The ASN is meant to attest that an individual\nhas reached a suitable level of scientific maturity to apply for professorship\npositions. A five member panel, appointed for each scientific discipline, is in\ncharge of evaluating applicants by means of quantitative indicators of impact\nand productivity, and through an assessment of their research profile. Many\nconcerns were raised on the appropriateness of the evaluation criteria, and in\nparticular on the use of bibliometrics for the evaluation of individual\nresearchers. Additional concerns were related to the perceived poor quality of\nthe final evaluation reports. In this paper we assess the ASN in terms of\nappropriateness of the applied methodology, and the quality of the feedback\nprovided to the applicants. We argue that the ASN is not fully compliant with\nthe best practices for the use of bibliometric indicators for the evaluation of\nindividual researchers; moreover, the quality of final reports varies\nconsiderably across the panels, suggesting that measures should be put in place\nto prevent sloppy practices in future ASN rounds."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.01.009", 
    "link": "http://arxiv.org/pdf/1507.06369v1", 
    "title": "Authorship Patterns in Computer Science Research in the Philippines", 
    "arxiv-id": "1507.06369v1", 
    "author": "Jaderick P. Pabico", 
    "publish": "2015-07-23T01:30:54Z", 
    "summary": "We studied patterns of authorship in computer science~(CS) research in the\nPhilippines by using data mining and graph theory techniques on archives of\nscientific papers presented in the Philippine Computer Science Congresses from\n2000 to 2010 involving 326~papers written by 605~authors. We inferred from\nthese archives various graphs namely, a paper--author bipartite graph, a\nco-authorship graph, and two mixing graphs. Our results show that the\nscientific articles by Filipino computer scientists were generated at a rate of\n33~papers per year, while the papers were written by an average of 2.64~authors\n(maximum=13). The frequency distribution of the number of authors per paper\nfollows a power-law with a power of $\\varphi=-2.04$ ($R^2=0.71$). The number of\nFilipino CS researchers increases at an annual rate of 60~new scientists. The\nresearchers have written an average of 1.42~papers (maximum=20) and have\ncollaborated with 3.70~other computer scientists (maximum=54). The frequency\ndistribution of the number of papers per author follows a power law with\n$\\varphi=-1.88$ ($R^2=0.83$). This distribution closely agrees with Lotka's\n{\\em law of scientific productivity} having $\\varphi\\approx -2$. The number of\nco-authors per author also follows a power-law with $\\varphi=-1.65$\n($R^2=0.80$). These results suggest that most CS~papers in the country were\nwritten by scientists who prefer to work alone or at most in small groups.\nThese also suggest that few papers were written by scientists who were involved\nin large collaboration efforts. The productivity of the Philippines' CS\nresearchers, as measured by their number of papers, is positively correlated\nwith their participation in collaborative research efforts, as measured by\ntheir number of co-authors (Pearson $r=0.7425$)."
},{
    "category": "cs.DL", 
    "doi": "10.1080/00987913.2015.1031317", 
    "link": "http://arxiv.org/pdf/1508.04347v1", 
    "title": "SFX Miscellaneous Free Ejournals Target: Usage Survey among the SFX   Community", 
    "arxiv-id": "1508.04347v1", 
    "author": "Mark Needleman", 
    "publish": "2015-08-18T15:20:39Z", 
    "summary": "The number of free or open access articles is increasing rapidly, and their\nretrieval with library indexes and OpenURL link resolvers has been a challenge.\nIn June 2014, the SFX MISCELLANEOUS FREE EJOURNALS target contained more than\n24,000 portfolios of all kinds. The SFX Knowledge Base Advisory Board (KBAB)\ncarried out an international survey to get an overview of the usage of this\ntarget by the SFX community and to precisely identify what could be done to\nimprove it. The target is widely used among the community. However, many\nrespondents complained about three major problems: (a) incorrect links, (b)\nfull texts actually not free, and (c) incorrect or missing thresholds (years\nand volumes information)."
},{
    "category": "cs.DL", 
    "doi": "10.1080/00987913.2015.1031317", 
    "link": "http://arxiv.org/pdf/1508.04977v1", 
    "title": "nanopub-java: A Java Library for Nanopublications", 
    "arxiv-id": "1508.04977v1", 
    "author": "Tobias Kuhn", 
    "publish": "2015-08-20T13:32:20Z", 
    "summary": "The concept of nanopublications was first proposed about six years ago, but\nit lacked openly available implementations. The library presented here is the\nfirst one that has become an official implementation of the nanopublication\ncommunity. Its core features are stable, but it also contains unofficial and\nexperimental extensions: for publishing to a decentralized server network, for\ndefining sets of nanopublications with indexes, for informal assertions, and\nfor digitally signing nanopublications. Most of the features of the library can\nalso be accessed via an online validator interface."
},{
    "category": "cs.DL", 
    "doi": "10.1080/00987913.2015.1031317", 
    "link": "http://arxiv.org/pdf/1508.06206v1", 
    "title": "Semantic Publishing Challenge - Assessing the Quality of Scientific   Output by Information Extraction and Interlinking", 
    "arxiv-id": "1508.06206v1", 
    "author": "Sahar Vahdati", 
    "publish": "2015-08-25T16:17:24Z", 
    "summary": "The Semantic Publishing Challenge series aims at investigating novel\napproaches for improving scholarly publishing using Linked Data technology. In\n2014 we had bootstrapped this effort with a focus on extracting information\nfrom non-semantic publications - computer science workshop proceedings volumes\nand their papers - to assess their quality. The objective of this second\nedition was to improve information extraction but also to interlink the 2014\ndataset with related ones in the LOD Cloud, thus paving the way for\nsophisticated end-user services."
},{
    "category": "cs.DL", 
    "doi": "10.3145/epi.2015.sep.17", 
    "link": "http://arxiv.org/pdf/1508.07480v1", 
    "title": "Studies and analysis of reference management software: a literature   review", 
    "arxiv-id": "1508.07480v1", 
    "author": "Piedad Garrido-Picazo", 
    "publish": "2015-08-29T17:26:54Z", 
    "summary": "Reference management software is a well-known tool for scientific research\nwork. Since the 1980s, it has been the subject of reviews and evaluations in\nlibrary and information science literature. This paper presents a systematic\nreview of published studies that evaluate reference management software with a\ncomparative approach. The objective is to identify the types, models, and\nevaluation criteria that authors have adopted, in order to determine whether\nthe methods used provide adequate methodological rigor and useful contributions\nto the field of study."
},{
    "category": "cs.DL", 
    "doi": "10.3145/epi.2015.sep.17", 
    "link": "http://arxiv.org/pdf/1509.04184v1", 
    "title": "Emerging trends on the topic of Information Technology in the field of   Educational Sciences: a bibliometric exploration", 
    "arxiv-id": "1509.04184v1", 
    "author": "C. L. Gonz\u00e1lez-Valiente", 
    "publish": "2015-09-14T16:19:02Z", 
    "summary": "The paper presents a bibliometric analysis on the topic of Information\nTechnology (IT) in the field of Educational Sciences, aimed at envisioning the\nresearch emerging trends. The ERIC data base is used as a consultation source;\nthe results were subjected to productivity by authors, journals, and term\nco-occurrence analysis indicators for the period 2009-2013. The productivity of\nComputers & Education, and Turkish Online Journal of Educational\nTechnology-TOJET, as well as the preceding authors from Canada, have been\nemphasized. The more used terms are the following: Information technology,\nforeign countries, educational technology, technology integration, and student\nattitudes. Researches performed here seem to have a largely qualitative\ncharacter, highlighting computers and internet as the mostly explored\ntechnological objects. The largest subject matter trend refers to the\nintegration of IT in the higher education learning context, and its incidence\nover the teaching methods."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2015.7402", 
    "link": "http://arxiv.org/pdf/1509.04218v1", 
    "title": "Collaborative Bibliographic System for Review/Survey Articles", 
    "arxiv-id": "1509.04218v1", 
    "author": "Mznah Al-Rodhaan", 
    "publish": "2015-09-14T17:35:33Z", 
    "summary": "This paper proposes a Bibliographic system intends to exchange bibliographic\ninformation of survey/review articles by relying on Web service technology. It\nallows researchers and university students to interact with system via single\nservice using platform-independent standard named Web service to add, search\nand retrieve bibliographic information of review articles in various science\nand technology fields and build-up a dedicated database for these articles in\neach science and technology field. Additionally, different implementation\nscenarios of the proposed system are presented and described, and rich features\nthat offered by such system are studied and described. However, this paper\nexplains the proposed system using computing area due to the existence of\ndetailed taxonomy of this area, which allows defining the system, their\nfunctionalities and features provided. However, the proposed system is not only\nconfined to computing area, it can support any other science and technology\narea without any need to modify this system."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2015.7402", 
    "link": "http://arxiv.org/pdf/1509.04515v1", 
    "title": "Improvements in Google Scholar Citations are for the summer: creating an   institutional affiliation link feature", 
    "arxiv-id": "1509.04515v1", 
    "author": "Emilio Delgado L\u00f3pez-C\u00f3zar", 
    "publish": "2015-09-15T12:22:07Z", 
    "summary": "This report describes the feature introduced by Google to provide\nstandardized access to institutional affiliations within Google Scholar\nCitations. First, this new tool is described, pointing out its main\ncharacteristics and functioning. Next, the coverage and precision of the tool\nare evaluated. Two special cases (Google Inc. and Spanish Universities) are\nbriefly treated with the purpose of illustrating some aspects about the\naccuracy of the tool for the task of gathering authors within their appropriate\ninstitution. Finally, some inconsistencies, errors and malfunctioning are\nidentified, categorized and described. The report finishes by providing some\nsuggestions to improve the feature. The general conclusion is that the\nstandardized institutional affiliation link provided by Google Scholar\nCitations, despite working pretty well for a large number of institutions\n(especially Anglo-Saxon universities) still has a number of shortcomings and\npitfalls which need to be addressed in order to make this authority control\ntool fully useful worldwide, both for searching purposes and for metric tasks"
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2015.7402", 
    "link": "http://arxiv.org/pdf/1509.06184v1", 
    "title": "More Precise Methods for National Research Citation Impact Comparisons", 
    "arxiv-id": "1509.06184v1", 
    "author": "Mike Thelwall", 
    "publish": "2015-09-21T10:57:49Z", 
    "summary": "Governments sometimes need to analyse sets of research papers within a field\nin order to monitor progress, assess the effect of recent policy changes, or\nidentify areas of excellence. They may compare the average citation impacts of\nthe papers by dividing them by the world average for the field and year. Since\ncitation data is highly skewed, however, simple averages may be too imprecise\nto robustly identify differences within, rather than across, fields. In\nresponse, this article introduces two new methods to identify national\ndifferences in average citation impact, one based on linear modelling for\nnormalised data and the other using the geometric mean. Results from a sample\nof 26 Scopus fields between 2009-2015 show that geometric means are the most\nprecise and so are recommended for smaller sample sizes, such as for individual\nfields. The regression method has the advantage of distinguishing between\nnational contributions to internationally collaborative articles, but has\nsubstantially wider confidence intervals than the geometric mean, undermining\nits value for any except the largest sample sizes."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0123537", 
    "link": "http://arxiv.org/pdf/1509.06836v1", 
    "title": "A Framework to Explore the Knowledge Structure of Multidisciplinary   Research Fields", 
    "arxiv-id": "1509.06836v1", 
    "author": "Louise A. Baur", 
    "publish": "2015-09-23T03:33:42Z", 
    "summary": "Understanding emerging areas of a multidisciplinary research field is crucial\nfor researchers,policymakers and other stakeholders. For them a knowledge\nstructure based on longitudinal bibliographic data can be an effective\ninstrument. But with the vast amount of available online information it is\noften hard to understand the knowledge structure for data. In this paper, we\npresent a novel approach for retrieving online bibliographic data and propose a\nframework for exploring knowledge structure. We also present several\nlongitudinal analyses to interpret and visualize the last 20 years of published\nobesity research data."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0123537", 
    "link": "http://arxiv.org/pdf/1509.07157v1", 
    "title": "Analysis of the impact of studies published by Internext - Revista   Eletr\u00f4nica de Neg\u00f3cios Internacionais", 
    "arxiv-id": "1509.07157v1", 
    "author": "C. L. Gonz\u00e1lez-Valiente", 
    "publish": "2015-09-23T20:53:34Z", 
    "summary": "This paper presents a citation analysis of Internext-Review of International\nBusiness to detect the impact caused by papers published for the period\n2006-2013. The Publish or Perish (PoP) software is used, which retrieves\narticles and citations from Google Scholar database. As part of the applied\nindicators are: the distribution of authors by articles, citations per year,\ncitation vs. self-citation, journal's citable vs. non citable documents,\njournal's cited vs. uncited documents, co-word analysis, and H Index. A total\nof 131 articles were obtained for 153 citations made until June, 2014. Most\narticles present multiple authorship. It is also detected an ascending line in\nthe citation. The Journal has very low levels of self-citation, showing that\nmost citing sources are Brazilian journals. The most cited articles have been\npublished in the early years (2006-2008); whose main topics are related with\nthe internationalization theory and strategy, the transaction analysis, and the\ncorporate governance. The Internext' H Index is 6 and the G Index is 9."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0123537", 
    "link": "http://arxiv.org/pdf/1509.08798v2", 
    "title": "Replicability and the public/private divide", 
    "arxiv-id": "1509.08798v2", 
    "author": "Lutz Bornmann", 
    "publish": "2015-09-26T07:20:19Z", 
    "summary": "In a recent letter, Carlos Vilchez-Roman criticizes Bornmann et al. (2015)\nfor using data which cannot be reproduced without access to an in-house version\nof the Web-of-Science (WoS) at the Max Planck Digital Libraries (MPDL, Munich).\nWe agree with the norm of replicability and therefore returned to our data. Is\nthe problem only a practical one of automation or does the in-house processing\nadd analytical value to the data? Is the newly emerging situation in any sense\ndifferent from a further professionalization of the field? In our opinion, a\npolitical economy of science indicators has in the meantime emerged with a\ncompetitive dynamic that affects the intellectual organization of the field."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0123537", 
    "link": "http://arxiv.org/pdf/1510.00322v1", 
    "title": "Sustainability: Scholarly Repository as an Enterprise", 
    "arxiv-id": "1510.00322v1", 
    "author": "Oya Y. Rieger", 
    "publish": "2015-10-01T17:25:25Z", 
    "summary": "The expanding need for an open information sharing infrastructure to promote\nscholarly communication led to the pioneering establishment of arXiv.org, now\nmaintained by the Cornell University Library. To be sustainable, the repository\nrequires careful, long term planning for services, management and funding. The\nlibrary is developing a sustainability model for arXiv.org, based on voluntary\ncontributions and the ongoing participation and support of 200 libraries and\nresearch laboratories around the world. The sustainability initiative is based\non a membership model and builds on arXiv's technical, service, financial and\npolicy infrastructure. Five principles for sustainability drive development,\nstarting with deep integration into the scholarly community. Also key are a\nclearly defined mandate and governance structure, a stable yet innovative\ntechnology platform, systematic creation of content policies and strong\nbusiness planning strategies. Repositories like arXiv must consider usability\nand life cycle alongside values and trends in scholarly communication. To\nendure, they must also support and enhance their service by securing and\nmanaging resources and demonstrating responsible stewardship."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0123537", 
    "link": "http://arxiv.org/pdf/1510.01871v1", 
    "title": "Does Quantity Make a Difference? The importance of publishing many   papers", 
    "arxiv-id": "1510.01871v1", 
    "author": "Ulf Sandstrom", 
    "publish": "2015-10-07T09:39:50Z", 
    "summary": "Do highly productive researchers have significantly higher probability to\nproduce top cited papers? Or does the increased productivity in science only\nresult in a sea of irrelevant papers as a perverse effect of competition and\nthe increased use of indicators for research evaluation and accountability\nfocus? We use a Swedish author disambiguated data set consisting of 48,000\nresearchers and their WoS-publications during the period of 2008 2011 with\ncitations until 2014 to investigate the relation between productivity and\nproduction of highly cited papers. As the analysis shows, quantity does make a\ndifference."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0123537", 
    "link": "http://arxiv.org/pdf/1510.02453v2", 
    "title": "Regional and Global Science: Latin American and Caribbean publications   in the SciELO Citation Index and the Web of Science", 
    "arxiv-id": "1510.02453v2", 
    "author": "Loet Leydesdorff", 
    "publish": "2015-10-08T19:29:35Z", 
    "summary": "We compare the visibility of Latin American and Caribbean (LAC) publications\nin the Core Collection indexes of the Web of Science (WoS)--Science Citation\nIndex Expanded, Social Sciences Citation Index, and Arts & Humanities Citation\nIndex--and the SciELO Citation Index (SciELO CI) which was integrated into the\nlarger WoS platform in 2014. The purpose of this comparison is to contribute to\nour understanding of the communication of scientific knowledge produced in\nLatin America and the Caribbean, and to provide some reflections on the\npotential benefits of the articulation of regional indexing exercises into WoS\nfor a better understanding of geographic and disciplinary contributions. How is\nthe regional level of SciELO CI related to the global range of WoS? In WoS, LAC\nauthors are integrated at the global level in international networks, while\nSciELO has provided a platform for interactions among LAC researchers. The\narticulation of SciELO into WoS may improve the international visibility of the\nregional journals, but at the cost of independent journal inclusion criteria."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0123537", 
    "link": "http://arxiv.org/pdf/1510.03648v1", 
    "title": "An indicator of journal impact that is based on calculating a journal's   percentage of highly cited publications", 
    "arxiv-id": "1510.03648v1", 
    "author": "Pablo Dorta-Gonzalez", 
    "publish": "2015-10-13T12:38:10Z", 
    "summary": "The two most used citation impact indicators in the assessment of scientific\njournals are, nowadays, the impact factor and the h-index. However, both\nindicators are not field normalized (vary heavily depending on the scientific\ncategory) which makes them incomparable between categories. Furthermore, the\nimpact factor is not robust to the presence of articles with a large number of\ncitations, while the h-index depends on the journal size. These limitations are\nvery important when comparing journals of different sizes and categories. An\nalternative citation impact indicator is the percentage of highly cited\narticles in a journal. This measure is field normalized (comparable between\nscientific categories), independent of the journal size and also robust to the\npresence of articles with a high number of citations. This paper empirically\ncompares this indicator with the impact factor and the h-index, considering\ndifferent time windows and citation percentiles (levels of citation for\nconsidering an article as highly cited compared to others in the same year and\ncategory)."
},{
    "category": "cs.DL", 
    "doi": "10.1109/KSE.2015.76", 
    "link": "http://arxiv.org/pdf/1510.04422v1", 
    "title": "A Potential Approach to Overcome Data Limitation in Scientific   Publication Recommendation", 
    "arxiv-id": "1510.04422v1", 
    "author": "Kiem Hoang", 
    "publish": "2015-10-15T07:13:50Z", 
    "summary": "Data are essential for the experiments of relevant scientific publication\nrecommendation methods but it is difficult to build ground truth data. A\nnaturally promising solution is using publications that are referenced by\nresearchers to build their ground truth data. Unfortunately, this approach has\nnot been explored in the literature, so its applicability is still a gap in our\nknowledge. In this research, we systematically study this approach by\ntheoretical and empirical analyses. In general, the results show that this\napproach is reasonable and has many advantages. However, the empirical analysis\nshows both positive and negative results. We conclude that, in some situations,\nthis is a useful alternative approach toward overcoming data limitation. Based\non this approach, we build and publish a dataset in computer science domain to\nhelp advancing other researches."
},{
    "category": "cs.DL", 
    "doi": "10.1109/KSE.2015.76", 
    "link": "http://arxiv.org/pdf/1510.05128v1", 
    "title": "Comprehensive indicator comparisons intelligible to non-experts: The   case of two SNIP versions", 
    "arxiv-id": "1510.05128v1", 
    "author": "Henk F. Moed", 
    "publish": "2015-10-17T14:06:52Z", 
    "summary": "A framework is proposed for comparing different types of bibliometric\nindicators, introducing the notion of an Indicator Comparison Report. It\nprovides a comprehensive overview of the main differences and similarities of\nindicators. The comparison shows both the strong points and the limitations of\neach of the indicators at stake, rather than over-promoting one indicator and\nignoring the benefits of alternative constructs. It focuses on base notions,\nassumptions, and application contexts, which makes it more intelligible to\nnon-experts. As an illustration, a comparison report is presented for the\noriginal and the modified SNIP (Source Normalized Impact per Paper) indicator\nof journal citation impact."
},{
    "category": "cs.DL", 
    "doi": "10.1109/KSE.2015.76", 
    "link": "http://arxiv.org/pdf/1510.05129v1", 
    "title": "On full text download and citation distributions in scientific-scholarly   journals", 
    "arxiv-id": "1510.05129v1", 
    "author": "Gali Halevi", 
    "publish": "2015-10-17T14:16:31Z", 
    "summary": "A statistical analysis of full text downloads of articles in Elseviers\nScienceDirect covering all disciplines reveals large differences in download\nfrequencies, their skewness, and their correlation with Scopus-based citation\ncounts, between disciplines, journals, and document types. Download counts tend\nto be two orders of magnitude higher and less skewedly distributed than\ncitations. A mathematical model based on the sum of two exponentials does not\nadequately capture monthly download counts. The degree of correlation at the\narticle level within a journal is similar to that at the journal level in the\ndiscipline covered by that journal, suggesting that the differences between\njournals are to a large extent discipline specific. Despite the fact that in\nall study journals download and citation counts per article positively\ncorrelate, little overlap may exist between the set of articles appearing in\nthe top of the citation distribution and that with the most frequently\ndownloaded ones. Usage and citation leaks, bulk downloading, differences\nbetween reader and author populations in a subject field, the type of document\nor its content, differences in obsolescence patterns between downloads and\ncitations, different functions of reading and citing in the research process,\nall provide possible explanations of differences between download and citation\ndistributions."
},{
    "category": "cs.DL", 
    "doi": "10.1109/KSE.2015.76", 
    "link": "http://arxiv.org/pdf/1510.05131v1", 
    "title": "Altmetrics as traces of the computerization of the research process", 
    "arxiv-id": "1510.05131v1", 
    "author": "Henk F. Moed", 
    "publish": "2015-10-17T14:36:18Z", 
    "summary": "I propose a broad, multi-dimensional conception of altmetrics, namely as\ntraces of the computerization of the research process. Computerization should\nbe conceived in its broadest sense, including all recent developments in ICT\nand software, taking place in society as a whole. I distinguish four aspects of\nthe research process: the collection of research data and development of\nresearch methods; scientific information processing; communication and\norganization; and, last but not least, research assessment. I will argue that\nin each aspect, computerization plays a key role, and metrics are being\ndeveloped to describe this process. I propose to label the total collection of\nsuch metrics as Altmetrics. I seek to provide a theoretical foundation of\naltmetrics, based on notions developed by Michael Nielsen in his monograph\nReinventing Discovery: The New Era of Networked Science. Altmetrics can be\nconceived as tools for the practical realization of the ethos of science and\nscholarship in a computerized or digital age."
},{
    "category": "cs.DL", 
    "doi": "10.1109/KSE.2015.76", 
    "link": "http://arxiv.org/pdf/1510.05266v1", 
    "title": "The Scaling Relationship between Citation-Based Performance and   Scientific Collaboration in Natural Sciences", 
    "arxiv-id": "1510.05266v1", 
    "author": "J. Sylvan Katz", 
    "publish": "2015-10-18T15:48:41Z", 
    "summary": "The aim of this paper is to extend our knowledge about the power-law\nrelationship between citation-based performance and collaboration patterns for\npapers of the Natural Sciences domain. We analyzed 829,924 articles that\nreceived 16,490,346 citations. The number of articles published through\ncollaboration account for 89%. The citation-based performance and collaboration\npatterns exhibit a power-law correlation with a scaling exponent of 1.20,\nSD=0.07. We found that the Matthew effect is stronger for collaborated papers\nthan for single-authored. This means that the citations to a field research\nareas articles increase 2.30 times each time it doubles the number of\ncollaborative papers. The scaling exponent for the power-law relationship for\nsingle-authored papers was 0.85, SD=0.11. The citations to a field research\narea single-authored articles increase 1.89 times each time the research area\ndoubles the number of non-collaborative papers."
},{
    "category": "cs.DL", 
    "doi": "10.1109/KSE.2015.76", 
    "link": "http://arxiv.org/pdf/1510.06802v1", 
    "title": "Prominent but Less Productive: The Impact of Interdisciplinarity on   Scientists' Research", 
    "arxiv-id": "1510.06802v1", 
    "author": "Taryn Stanko", 
    "publish": "2015-10-23T01:49:50Z", 
    "summary": "Inter-disciplinary research (IDR) is being promoted by federal agencies and\nuniversities nationwide because it presumably spurs transformative, innovative\nscience. In this paper we bring empirical data to assess whether IDR is indeed\nbeneficial, and whether costs accompany potential benefits."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.05.006", 
    "link": "http://arxiv.org/pdf/1510.08867v1", 
    "title": "The influence of time and discipline on the magnitude of correlations   between citation counts and quality scores", 
    "arxiv-id": "1510.08867v1", 
    "author": "Ruth Fairclough", 
    "publish": "2015-10-29T20:08:05Z", 
    "summary": "Although various citation-based indicators are commonly used to help research\nevaluations, there are ongoing controversies about their value. In response,\nthey are often correlated with quality ratings or with other quantitative\nindicators in order to partly assess their validity. When correlations are\ncalculated for sets of publications from multiple disciplines or years,\nhowever, the magnitude of the correlation coefficient may be reduced, masking\nthe strength of the underlying correlation. In response, this article uses\nsimulations to systematically investigate the extent to which mixing years or\ndisciplines reduces correlations. The results show that mixing two sets of\narticles with different correlation strengths can reduce the correlation for\nthe combined set to substantially below the average of the two. Moreover, even\nmixing two sets of articles with the same correlation strength but different\nmean citation counts can substantially reduce the correlation for the combined\nset. The extent of the reduction in correlation also depends upon whether the\narticles assessed have been pre-selected for being high quality and whether the\nrelationship between the quality ratings and citation counts is linear or\nexponential. The results underline the importance of using homogeneous data\nsets but also help to interpret correlation coefficients when this is\nimpossible."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.02.004", 
    "link": "http://arxiv.org/pdf/1510.08874v1", 
    "title": "Geometric journal impact factors correcting for individual highly cited   articles", 
    "arxiv-id": "1510.08874v1", 
    "author": "Ruth Fairclough", 
    "publish": "2015-10-29T20:13:04Z", 
    "summary": "Journal impact factors (JIFs) are widely used and promoted but have important\nlimitations. In particular, JIFs can be unduly influenced by individual highly\ncited articles and hence are inherently unstable. A logical way to reduce the\nimpact of individual high citation counts is to use the geometric mean rather\nthan the standard mean in JIF calculations. Based upon journal rankings\n2004-2014 in 50 sub-categories within 5 broad categories, this study shows that\njournal rankings based on JIF variants tend to be more stable over time if the\ngeometric mean is used rather than the standard mean. The same is true for JIF\nvariants using Mendeley reader counts instead of citation counts. Thus,\nalthough the difference is not large, the geometric mean is recommended instead\nof the arithmetic mean for future JIF calculations. In addition, Mendeley\nreadership-based JIF variants are as stable as those using Scopus citations,\nconfirming the value of Mendeley readership as an academic impact indicator."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2014.09.011", 
    "link": "http://arxiv.org/pdf/1510.08877v1", 
    "title": "Regression for citation data: An evaluation of different methods", 
    "arxiv-id": "1510.08877v1", 
    "author": "Paul Wilson", 
    "publish": "2015-10-29T20:17:11Z", 
    "summary": "Citations are increasingly used for research evaluations. It is therefore\nimportant to identify factors affecting citation scores that are unrelated to\nscholarly quality or usefulness so that these can be taken into account.\nRegression is the most powerful statistical technique to identify these factors\nand hence it is important to identify the best regression strategy for citation\ndata. Citation counts tend to follow a discrete lognormal distribution and, in\nthe absence of alternatives, have been investigated with negative binomial\nregression. Using simulated discrete lognormal data (continuous lognormal data\nrounded to the nearest integer) this article shows that a better strategy is to\nadd one to the citations, take their log and then use the general linear\n(ordinary least squares) model for regression (e.g., multiple linear\nregression, ANOVA), or to use the generalised linear model without the log.\nReasonable results can also be obtained if all the zero citations are\ndiscarded, the log is taken of the remaining citation counts and then the\ngeneral linear model is used, or if the generalised linear model is used with\nthe continuous lognormal distribution. Similar approaches are recommended for\naltmetric data, if it proves to be lognormally distributed."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2014.08.001", 
    "link": "http://arxiv.org/pdf/1510.08881v1", 
    "title": "Distributions for cited articles from individual subjects and years", 
    "arxiv-id": "1510.08881v1", 
    "author": "Paul Wilson", 
    "publish": "2015-10-29T20:20:48Z", 
    "summary": "The citations to a set of academic articles are typically unevenly shared,\nwith many articles attracting few citations and few attracting many. It is\nimportant to know more precisely how citations are distributed in order to help\nstatistical analyses of citations, especially for sets of articles from a\nsingle discipline and a small range of years, as normally used for research\nevaluation. This article fits discrete versions of the power law, the lognormal\ndistribution and the hooked power law to 20 different Scopus categories, using\ncitations to articles published in 2004 and ignoring uncited articles. The\nresults show that, despite its popularity, the power law is not a suitable\nmodel for collections of articles from a single subject and year, even for the\npurpose of estimating the slope of the tail of the citation data. Both the\nhooked power law and the lognormal distributions fit best for some subjects but\nneither is a universal optimal choice and parameter estimates for both seem to\nbe unreliable. Hence only the hooked power law and discrete lognormal\ndistributions should be considered for subject-and-year-based citation analysis\nin future and parameter estimates should always be interpreted cautiously."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.08.003", 
    "link": "http://arxiv.org/pdf/1510.08884v1", 
    "title": "National research impact indicators from Mendeley readers", 
    "arxiv-id": "1510.08884v1", 
    "author": "M. Thelwall", 
    "publish": "2015-10-29T20:23:19Z", 
    "summary": "National research impact indicators derived from citation counts are used by\ngovernments to help assess their national research performance and to identify\nthe effect of funding or policy changes. Citation counts lag research by\nseveral years, however, and so their information is somewhat out of date. Some\nof this lag can be avoided by using readership counts from the social reference\nsharing site Mendeley because these accumulate more quickly than citations.\nThis article introduces a method to calculate national research impact\nindicators from Mendeley, using citation counts from older time periods to\npartially compensate for international biases in Mendeley readership. A\nrefinement to accommodate recent national changes in Mendeley uptake makes\nlittle difference, despite being theoretically more accurate. The Mendeley\npatterns using the methods broadly reflect the results from similar\ncalculations with citations and seem to reflect impact trends about a year\nearlier. Nevertheless, the reasons for the differences between the indicators\nfrom the two data sources are unclear."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.08.003", 
    "link": "http://arxiv.org/pdf/1511.00735v2", 
    "title": "Large-Scale Analysis of the Accuracy of the Journal Classification   Systems of Web of Science and Scopus", 
    "arxiv-id": "1511.00735v2", 
    "author": "Ludo Waltman", 
    "publish": "2015-11-02T22:55:50Z", 
    "summary": "Journal classification systems play an important role in bibliometric\nanalyses. The two most important bibliographic databases, Web of Science and\nScopus, each provide a journal classification system. However, no study has\nsystematically investigated the accuracy of these classification systems. To\nexamine and compare the accuracy of journal classification systems, we define\ntwo criteria on the basis of direct citation relations between journals and\ncategories. We use Criterion I to select journals that have weak connections\nwith their assigned categories, and we use Criterion II to identify journals\nthat are not assigned to categories with which they have strong connections. If\na journal satisfies either of the two criteria, we conclude that its assignment\nto categories may be questionable. Accordingly, we identify all journals with\nquestionable classifications in Web of Science and Scopus. Furthermore, we\nperform a more in-depth analysis for the field of Library and Information\nScience to assess whether our proposed criteria are appropriate and whether\nthey yield meaningful results. It turns out that according to our\ncitation-based criteria Web of Science performs significantly better than\nScopus in terms of the accuracy of its journal classification system."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.08.003", 
    "link": "http://arxiv.org/pdf/1511.03020v2", 
    "title": "Co-word Maps and Topic Modeling: A Comparison Using Small and   Medium-Sized Corpora (n < 1000)", 
    "arxiv-id": "1511.03020v2", 
    "author": "Adina Nerghes", 
    "publish": "2015-11-10T08:43:43Z", 
    "summary": "Induced by \"big data,\" \"topic modeling\" has become an attractive alternative\nto mapping co-words in terms of co-occurrences and co-absences using network\ntechniques. Does topic modeling provide an alternative for co-word mapping in\nresearch practices using moderately sized document collections? We return to\nthe word/document matrix using first a single text with a strong argument (\"The\nLeiden Manifesto\") and then upscale to a sample of moderate size (n = 687) to\nstudy the pros and cons of the two approaches in terms of the resulting\npossibilities for making semantic maps that can serve an argument. The results\nfrom co-word mapping (using two different routines) versus topic modeling are\nsignificantly uncorrelated. Whereas components in the co-word maps can easily\nbe designated, the topic models provide sets of words that are very differently\norganized. In these samples, the topic models seem to reveal similarities other\nthan semantic ones (e.g., linguistic ones). In other words, topic modeling does\nnot replace co-word mapping in small and medium-sized sets; but the paper\nleaves open the possibility that topic modeling would work well for the\nsemantic mapping of large sets."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.08.003", 
    "link": "http://arxiv.org/pdf/1511.04275v2", 
    "title": "An Index for SSRN Downloads", 
    "arxiv-id": "1511.04275v2", 
    "author": "Zura Kakushadze", 
    "publish": "2015-11-13T13:29:23Z", 
    "summary": "We propose a new index to quantify SSRN downloads. Unlike the SSRN downloads\nrank, which is based on the total number of an author's SSRN downloads, our\nindex also reflects the author's productivity by taking into account the\ndownload numbers for the papers. Our index is inspired by - but is not the same\nas - Hirsch's h-index for citations, which cannot be directly applied to SSRN\ndownloads. We analyze data for about 30,000 authors and 367,000 papers. We find\na simple empirical formula for the SSRN author rank via a Gaussian function of\nthe log of the number of downloads."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.08.003", 
    "link": "http://arxiv.org/pdf/1511.05078v2", 
    "title": "Which type of citation analysis generates the most accurate taxonomy of   scientific and technical knowledge?", 
    "arxiv-id": "1511.05078v2", 
    "author": "Kevin W. Boyack", 
    "publish": "2015-11-16T18:35:22Z", 
    "summary": "In 1965, Derek de Solla Price foresaw the day when a citation-based taxonomy\nof science and technology would be delineated and correspondingly used for\nscience policy. A taxonomy needs to be comprehensive and accurate if it is to\nbe useful for policy making, especially now that policy makers are utilizing\ncitation-based indicators to evaluate people, institutions and laboratories.\nDetermining the accuracy of a taxonomy, however, remains a challenge. Previous\nwork on the accuracy of partition solutions is sparse, and the results of those\nstudies, while useful, have not been definitive. In this study we compare the\naccuracies of topic-level taxonomies based on the clustering of documents using\ndirect citation, bibliographic coupling, and co-citation. Using a set of new\ngold standards - articles with at least 100 references - we find that direct\ncitation is better at concentrating references than either bibliographic\ncoupling or co-citation. Using the assumption that higher concentrations of\nreferences denote more accurate clusters, direct citation thus provides a more\naccurate representation of the taxonomy of scientific and technical knowledge\nthan either bibliographic coupling or co-citation. We also find that\ndiscipline-level taxonomies based on journal schema are highly inaccurate\ncompared to topic-level taxonomies, and recommend against their use."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.08.003", 
    "link": "http://arxiv.org/pdf/1511.05808v1", 
    "title": "Using Search Engine Technology to Improve Library Catalogs", 
    "arxiv-id": "1511.05808v1", 
    "author": "Dirk Lewandowski", 
    "publish": "2015-11-18T14:38:45Z", 
    "summary": "This chapter outlines how search engine technology can be used in online\npublic access library catalogs (OPACs) to help improve users experiences, to\nidentify users intentions, and to indicate how it can be applied in the library\ncontext, along with how sophisticated ranking criteria can be applied to the\nonline library catalog. A review of the literature and current OPAC\ndevelopments form the basis of recommendations on how to improve OPACs.\nFindings were that the major shortcomings of current OPACs are that they are\nnot sufficiently user-centered and that their results presentations lack\nsophistication. Further, these shortcomings are not addressed in current 2.0\ndevelopments. It is argued that OPAC development should be made search-centered\nbefore additional features are applied. While the recommendations on ranking\nfunctionality and the use of user intentions are only conceptual and not yet\napplied to a library catalogue, practitioners will find recommendations for\ndeveloping better OPACs in this chapter. In short, readers will find a\nsystematic view on how the search engines strengths can be applied to improving\nlibraries online catalogs."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.08.003", 
    "link": "http://arxiv.org/pdf/1511.05809v1", 
    "title": "Google Scholar as a tool for discovering journal articles in library and   information science", 
    "arxiv-id": "1511.05809v1", 
    "author": "Dirk Lewandowski", 
    "publish": "2015-11-18T14:41:21Z", 
    "summary": "Purpose: The purpose of this paper is to measure the coverage of Google\nScholar for the Library and Information Science (LIS) journal literature as\nidentified by a list of core LIS journals from a study by Schloegl and\nPetschnig (2005).\n  Methods: We checked every article from 35 major LIS journals from the years\n2004 to 2006 for availability in Google Scholar (GS). We also collected\ninformation on the type of availability-i.e., whether a certain article was\navailable as a PDF for a fee, as a free PDF, or as a preprint.\n  Results: We found that only some journals are completely indexed by Google\nScholar, that the ratio of versions available depends on the type of publisher,\nand that availability varies a lot from journal to journal. Google Scholar\ncannot substitute for abstracting and indexing services in that it does not\ncover the complete literature of the field. However, it can be used in many\ncases to easily find available full texts of articles already found using\nanother tool.\n  Originality/value: This study differs from other Google Scholar coverage\nstudies in that it takes into account not only whether an article is indexed in\nGS at all, but also the type of availability."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.11.007", 
    "link": "http://arxiv.org/pdf/1511.07182v1", 
    "title": "National, disciplinary and temporal variations in the extent to which   articles with more authors have more impact: Evidence from a geometric field   normalised citation indicator", 
    "arxiv-id": "1511.07182v1", 
    "author": "Pardeep Sud", 
    "publish": "2015-11-23T11:32:54Z", 
    "summary": "The importance of collaboration in research is widely accepted, as is the\nfact that articles with more authors tend to be more cited. Nevertheless,\nalthough previous studies have investigated whether the apparent advantage of\ncollaboration varies by country, discipline, and number of co-authors, this\nstudy introduces a more fine-grained method to identify differences: the\ngeometric Mean Normalized Citation Score (gMNCS). Based on comparisons between\ndisciplines, years and countries for two million journal articles, the average\ncitation impact of articles increases with the number of authors, even when\ninternational collaboration is excluded. This apparent advantage of\ncollaboration varies substantially by discipline and country and changes a\nlittle over time. Against the trend, however, in Russia solo articles have more\nimpact. Across the four broad disciplines examined, collaboration had by far\nthe strongest association with impact in the arts and humanities. Although\ninternational comparisons are limited by the availability of systematic data\nfor author country affiliations, the new indicator is the most precise yet and\ncan give statistical evidence rather than estimates."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.23729", 
    "link": "http://arxiv.org/pdf/1511.08088v5", 
    "title": "Relative Citation Ratio (RCR): An empirical attempt to study a new   field-normalized bibliometric indicator", 
    "arxiv-id": "1511.08088v5", 
    "author": "Robin Haunschild", 
    "publish": "2015-11-25T15:24:48Z", 
    "summary": "Hutchins, Yuan, M., and Santangelo (2015) proposed the Relative Citation\nRatio (RCR) as a new field-normalized impact indicator. This study investigates\nthe RCR by correlating it on the level of single publications with established\nfield-normalized indicators and assessments of the publications by peers. We\nfind that the RCR correlates highly with established field-normalized\nindicators, but the correlation between RCR and peer assessments is only low to\nmedium."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-015-1765-5", 
    "link": "http://arxiv.org/pdf/1511.08096v1", 
    "title": "The Journal Coverage of Web of Science and Scopus: a Comparative   Analysis", 
    "arxiv-id": "1511.08096v1", 
    "author": "Adele Paul-Hus", 
    "publish": "2015-11-25T15:46:48Z", 
    "summary": "Bibliometric methods are used in multiple fields for a variety of purposes,\nnamely for research evaluation. Most bibliometric analyses have in common their\ndata sources: Thomson Reuters' Web of Science (WoS) and Elsevier's Scopus. This\nresearch compares the journal coverage of both databases in terms of fields,\ncountries and languages, using Ulrich's extensive periodical directory as a\nbase for comparison. Results indicate that the use of either WoS or Scopus for\nresearch evaluation may introduces biases that favor Natural Sciences and\nEngineering as well as Biomedical Research to the detriment of Social Sciences\nand Arts and Humanities. Similarly, English-language journals are\noverrepresented to the detriment of other languages. While both databases share\nthese biases, their coverage differs substantially. As a consequence, the\nresults of bibliometric analyses may vary depending on the database used."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-015-1765-5", 
    "link": "http://arxiv.org/pdf/1512.00127v1", 
    "title": "The cost of reading research. A study of Computer Science publication   venues", 
    "arxiv-id": "1512.00127v1", 
    "author": "Wei Ding", 
    "publish": "2015-12-01T03:09:55Z", 
    "summary": "What does the cost of academic publishing look like to the common researcher\ntoday? Our goal is to convey the current state of academic publishing,\nspecifically in regards to the field of computer science and provide analysis\nand data to be used as a basis for future studies. We will focus on author and\nreader costs as they are the primary points of interaction within the\npublishing world. In this work, we restrict our focus to only computer science\nin order to make the data collection more feasible (the authors are computer\nscientists) and hope future work can analyze and collect data across all\nacademic fields."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-015-1765-5", 
    "link": "http://arxiv.org/pdf/1512.01388v1", 
    "title": "Identifying potential breakthrough publications using refined citation   analyses: Three related explorative approaches", 
    "arxiv-id": "1512.01388v1", 
    "author": "Rodrigo Costas", 
    "publish": "2015-12-04T12:33:07Z", 
    "summary": "The article presents three advanced citation-based methods used to detect\npotential breakthrough papers among very highly cited papers. We approach the\ndetection of such papers from three different perspectives in order to provide\ndifferent typologies of breakthrough papers. In all three cases we use the\nclassification of scientific publications developed at CWTS based on direct\ncitation relationships. This classification establishes clusters of papers at\nthree levels of aggregation. Papers are clustered based on their similar\ncitation orientations and it is assumed that they are focused on similar\nresearch interests. We use the clustering as the context for detecting\npotential breakthrough papers. We utilize the Characteristics Scores and Scales\n(CSS) approach to partition citation distributions and implement a specific\nfiltering algorithm to sort out potential highly-cited followers, papers not\nconsidered breakthroughs in themselves. After invoking thresholds and\nfiltering, three methods are explored: A very exclusive one where only the\nhighest cited paper in a micro-cluster is considered as a potential\nbreakthrough paper (M1); as well as two conceptually different methods, one\nthat detects potential breakthrough papers among the two percent highest cited\npapers according to CSS (M2a), and finally a more restrictive version where, in\naddition to the CSS two percent filter, knowledge diffusion is also taken in as\nan extra parameter (M2b). The advance citation-based methods are explored and\nevaluated using specifically validated publication sets linked to different\nDanish funding instruments including centres of excellence."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.12.001", 
    "link": "http://arxiv.org/pdf/1512.01688v1", 
    "title": "The precision of the arithmetic mean, geometric mean and percentiles for   citation data: An experimental simulation modelling approach", 
    "arxiv-id": "1512.01688v1", 
    "author": "Mike Thelwall", 
    "publish": "2015-12-05T17:12:06Z", 
    "summary": "When comparing the citation impact of nations, departments or other groups of\nresearchers within individual fields, three approaches have been proposed:\narithmetic means, geometric means, and percentage in the top X%. This article\ncompares the precision of these statistics using 97 trillion experimentally\nsimulated citation counts from 6875 sets of different parameters (although all\nhaving the same scale parameter) based upon the discretised lognormal\ndistribution with limits from 1000 repetitions for each parameter set. The\nresults show that the geometric mean is the most precise, closely followed by\nthe percentage of a country's articles in the top 50% most cited articles for a\nfield, year and document type. Thus the geometric mean citation count is\nrecommended for future citation-based comparisons between nations. The\npercentage of a country's articles in the top 1% most cited is a particularly\nimprecise indicator and is not recommended for international comparisons based\non individual fields. Moreover, whereas standard confidence interval formulae\nfor the geometric mean appear to be accurate, confidence interval formulae are\nless accurate and consistent for percentile indicators. These recommendations\nassume that the scale parameters of the samples are the same but the choice of\nindicator is complex and partly conceptual if they are not."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.12.001", 
    "link": "http://arxiv.org/pdf/1512.02898v2", 
    "title": "Well-Stratified Linked Data for Well-Behaved Data Citation", 
    "arxiv-id": "1512.02898v2", 
    "author": "Marco Peressotti", 
    "publish": "2015-12-09T15:30:15Z", 
    "summary": "In this paper we analyse the functional requirements of linked data citation\nand identify a minimal set of operations and primitives needed to realize such\ntask. Citing linked data implies solving a series of data provenance issues and\nfinding a way to identify data subsets. Those two tasks can be handled defining\na simple type system inside data and verifying it with a type checker, which is\nsignificantly less complex than interpreting reified RDF statements and can be\nimplemented in a non data invasive way. Finally we suggest that data citation\nshould be handled outside of the data, possibly with an ad-hoc language."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.12.001", 
    "link": "http://arxiv.org/pdf/1512.04214v1", 
    "title": "The Globalization of Academic Entrepreneurship? The Recent Growth   (2009-2014) in University Patenting Decomposed", 
    "arxiv-id": "1512.04214v1", 
    "author": "Duncan Kushnir", 
    "publish": "2015-12-14T08:14:24Z", 
    "summary": "The contribution of academia to US patents has become increasingly global.\nFollowing a pause, with a relatively flat rate, from 1998 to 2008, the\nlong-term trend of university patenting rising as a share of all patenting has\nresumed, driven by the internationalization of academic entrepreneurship and\nthe persistence of US university technology transfer. We disaggregate this\nrecent growth in university patenting at the US Patent and Trademark\nOrganization (USPTO) in terms of nations and patent classes. Foreign patenting\nin the US has almost doubled during the period 2009-2014, mainly due to\npatenting by universities in Taiwan, Korea, China, and Japan. These nations\ncompete with the US in terms of patent portfolios, whereas most European\ncountries--with the exception of the UK--have more specific portfolios, mainly\nin the bio-medical fields. In the case of China, Tsinghua University holds 63%\nof the university patents in USPTO, followed by King Fahd University with 55.2%\nof the national portfolio."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.12.001", 
    "link": "http://arxiv.org/pdf/1512.04250v1", 
    "title": "A Highly Literate Approach to Ontology Building", 
    "arxiv-id": "1512.04250v1", 
    "author": "Jennifer Warrendar", 
    "publish": "2015-12-14T10:43:52Z", 
    "summary": "Ontologies present an attractive technology for describing bio-medicine,\nbecause they can be shared, and have rich computational properties. However,\nthey lack the rich expressivity of English and fit poorly with the current\nscientific \"publish or perish\" model. While, there have been attempts to\ncombine free text and ontologies, most of these perform \\textit{post-hoc}\nannotation of text. In this paper, we introduce our new environment which\nborrows from literate programming, to allow an author to co-develop both text\nand ontological description. We are currently using this environment to\ndocument the Karyotype Ontology which allows rich descriptions of the\nchromosomal complement in humans. We explore some of the advantages and\ndifficulties of this form of ontology development."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.12.001", 
    "link": "http://arxiv.org/pdf/1512.05382v1", 
    "title": "Why scientific publications should be anonymous", 
    "arxiv-id": "1512.05382v1", 
    "author": "Paul H. P. Hanel", 
    "publish": "2015-12-16T21:39:55Z", 
    "summary": "Numerous studies have revealed biases within the scientific communication\nsystem and across all scientific fields. For example, already prominent\nresearchers receive disproportional credit compared to their (almost) equally\nqualified colleagues -- because of their prominence. However, none of those\nstudies has offered a solution as to how to decrease the incidence of these\nbiases. In this paper I argue that by publishing anonymously, we can decrease\nthe incidence of inaccurate heuristics in the current scientific communication\nsystem. Specific suggestions are made as to how to implement the changes."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.12.001", 
    "link": "http://arxiv.org/pdf/1512.05741v2", 
    "title": "A new methodology for comparing Google Scholar and Scopus", 
    "arxiv-id": "1512.05741v2", 
    "author": "Gali Halevi", 
    "publish": "2015-12-17T19:47:54Z", 
    "summary": "A new methodology is proposed for comparing Google Scholar (GS) with other\ncitation indexes. It focuses on the coverage and citation impact of sources,\nindexing speed, and data quality, including the effect of duplicate citation\ncounts. The method compares GS with Elsevier's Scopus, and is applied to a\nlimited set of articles published in 12 journals from six subject fields, so\nthat its findings cannot be generalized to all journals or fields. The study is\nexploratory, and hypothesis generating rather than hypothesis-testing. It\nconfirms findings on source coverage and citation impact obtained in earlier\nstudies. The ratio of GS over Scopus citation varies across subject fields\nbetween 1.0 and 4.0, while Open Access journals in the sample show higher\nratios than their non-OA counterparts. The linear correlation between GS and\nScopus citation counts at the article level is high: Pearson's R is in the\nrange of 0.8-0.9. A median Scopus indexing delay of two months compared to GS\nis largely though not exclusively due to missing cited references in articles\nin press in Scopus. The effect of double citation counts in GS due to multiple\ncitations with identical or substantially similar meta-data occurs in less than\n2 per cent of cases. Pros and cons of article-based and what is termed as\nconcept-based citation indexes are discussed."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.12.001", 
    "link": "http://arxiv.org/pdf/1512.06195v1", 
    "title": "Quantifying Orphaned Annotations in Hypothes.is", 
    "arxiv-id": "1512.06195v1", 
    "author": "Michele C. Weigle", 
    "publish": "2015-12-19T05:57:32Z", 
    "summary": "Web annotation has been receiving increased attention recently with the\norganization of the Open Annotation Collaboration and new tools for open\nannotation, such as Hypothes.is. We investigate the prevalence of orphaned\nannotations, where neither the live Web page nor an archived copy of the Web\npage contains the text that had previously been annotated in the Hypothes.is\nannotation system (containing 20,953 highlighted text annotations). We found\nthat about 22% of highlighted text annotations can no longer be attached to\ntheir live Web pages. Unfortunately, only about 12% of these annotations can be\nreattached using the holdings of current public web archives, leaving the\nremaining 88% of these annotations orphaned. For those annotations that are\nstill attached, 53% are in danger of becoming orphans if the live Web page\nchanges. This points to the need for archiving the target of an annotation at\nthe time the annotation is created."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.12.001", 
    "link": "http://arxiv.org/pdf/1512.07069v1", 
    "title": "Using HistCite software to identify significant articles in subject   searches of the Web of Science", 
    "arxiv-id": "1512.07069v1", 
    "author": "Enrique Wulff Barreiro", 
    "publish": "2015-12-22T13:07:20Z", 
    "summary": "HistCite TM is a large-scale computer tool for mapping science. Its power of\nvisualization combines the production of historiographs on the basis of the\nanalysis of co-citations of documents, with the use of bibliometrics specific\nindicators. The objective of this article is, to present the advantages of the\nnew bibliometrics configuration of HistCite TM (2004) when identifying\narticles. The analysis of the histograms that produces HistCite TM , in terms\nof cumulative advantage and aging of the citations. And the comparative study\nof the results of HistCite TM , in its indicators of amplitude and recognition.\nAlso is examined its treatment of the sampling problems, by formalizing the\nKendall method of estimating the robust standard deviation."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.12.001", 
    "link": "http://arxiv.org/pdf/1512.07193v1", 
    "title": "Comparison of full-text versus metadata searching in an institutional   repository: Case study of the UNT Scholarly Works", 
    "arxiv-id": "1512.07193v1", 
    "author": "Daniel Alemneh", 
    "publish": "2015-12-22T18:33:44Z", 
    "summary": "Authors in the library science field disagree about the importance of using\ncostly resources to create local metadata records, particularly for scholarly\nmaterials that have full-text search alternatives. At the University of North\nTexas (UNT) Libraries, we decided to test this concept by answering the\nquestion: What percentage of search terms retrieved results based on full-text\nversus metadata values for items in the UNT Scholarly Works institutional\nrepository? The analysis matched search query logs to indexes of the metadata\nrecords and full text of the items in the collection. Results show the\ndistribution of item discoveries that were based on metadata exclusively, on\nfull text exclusively, and on the combination of both. This paper describes in\ndetail the methods and findings of this study."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.respol.2015.12.004", 
    "link": "http://arxiv.org/pdf/1512.07250v2", 
    "title": "A Triple Helix Model of Medical Innovation: Supply, Demand, and   Technological Capabilities in terms of Medical Subject Headings", 
    "arxiv-id": "1512.07250v2", 
    "author": "Loet Leydesdorff", 
    "publish": "2015-12-22T20:58:25Z", 
    "summary": "We develop a model of innovation that enables us to trace the interplay among\nthree key dimensions of the innovation process: (i) demand of and (ii) supply\nfor innovation, and (iii) technological capabilities available to generate\ninnovation in the forms of products, processes, and services. Building on\ntriple helix research, we use entropy statistics to elaborate an indicator of\nmutual information among these dimensions that can provide indication of\nreduction of uncertainty. To do so, we focus on the medical context, where\nuncertainty poses significant challenges to the governance of innovation. We\nuse the Medical Subject Headings (MeSH) of MEDLINE/PubMed to identify\npublications classified within the categories \"Diseases\" (C), \"Drugs and\nChemicals\" (D), \"Analytic, Diagnostic, and Therapeutic Techniques and\nEquipment\" (E) and use these as knowledge representations of demand, supply,\nand technological capabilities, respectively. Three case-studies of medical\nresearch areas are used as representative 'entry perspectives' of the medical\ninnovation process. These are: (i) human papilloma virus, (ii) RNA\ninterference, and (iii) magnetic resonance imaging. We find statistically\nsignificant periods of synergy among demand, supply, and technological\ncapabilities (C-D-E) that point to three-dimensional interactions as a\nfundamental perspective for the understanding and governance of the uncertainty\nassociated with medical innovation. Among the pairwise configurations in these\ncontexts, the demand-technological capabilities (C-E) provided the strongest\nlink, followed by the supply-demand (D-C) and the supply-technological\ncapabilities (D-E) channels."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.respol.2015.12.004", 
    "link": "http://arxiv.org/pdf/1512.08395v1", 
    "title": "Biblioth\u00e8ques num\u00e9riques et gamification : panorama et \u00e9tat de   l'art", 
    "arxiv-id": "1512.08395v1", 
    "author": "Imad Saleh", 
    "publish": "2015-12-28T12:59:17Z", 
    "summary": "This article presents an overview of the main gamification projects for\ndigital libraries, either for tagging or OCR correction. This overview is\nfollowed by a state of the art with functionalities, motivations, sociology of\ncontributors and the scope of gamification compared to the serious games and\nexplicit crowdsourcing. Finally a comparison of results between explicit\ncrowdsourcing and gamification is proposed.\n  [English Title: Digital libraries and gamification: overview and state of the\nart]"
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.respol.2015.12.004", 
    "link": "http://arxiv.org/pdf/1512.09070v1", 
    "title": "Repositories with Direct Representation", 
    "arxiv-id": "1512.09070v1", 
    "author": "Robert Burnell Allen", 
    "publish": "2015-12-30T19:27:15Z", 
    "summary": "A new generation of digital repositories could be based on direct\nrepresentation of the contents with rich semantics and models rather than be\ncollections of documents. The contents of such repositories would be highly\nstructured which should help users to focus on meaningful relationships of the\ncontents. These repositories would implement earlier proposals for\nmodel-oriented information organization by extending current work on ontologies\nto cover state changes, instances, and scenarios. They could also apply other\napproaches such as object-oriented design and frame semantics. In addition to\nsemantics, the representation needs to allow for discourse and repository\nknowledge-support services and policies. For instance, the knowledge base would\nneed to be systematically updated as new findings and theories reshape it."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-016-1877-6", 
    "link": "http://arxiv.org/pdf/1601.00141v2", 
    "title": "Detecting the historical roots of tribology research: a bibliometric   analysis", 
    "arxiv-id": "1601.00141v2", 
    "author": "Govindaraju Kannan", 
    "publish": "2016-01-02T05:43:25Z", 
    "summary": "In this study, the historical roots of tribology are investigated using a\nnewly developed scientometric method called Referenced Publication Years\nSpectroscopy. The study is based on cited references in tribology research\npublications. The Science Citation Index Expanded is used as data source. The\nresults show that RPYS has the potential to identify the important publications\n: Most of the publications which have been identified in this study as highly\ncited (referenced) publications are landmark publications in the field of\ntribology."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.23713", 
    "link": "http://arxiv.org/pdf/1601.00245v1", 
    "title": "Funding acknowledgment analysis:Queries and Caveats", 
    "arxiv-id": "1601.00245v1", 
    "author": "Weishu Liu", 
    "publish": "2016-01-03T05:00:30Z", 
    "summary": "Thomson Reuters' Web of Science (WoS) began systematically collecting\nacknowledgment information in August 2008. Since then, bibliometric analysis of\nfunding acknowledgment (FA) has been growing and has aroused intense interest\nand attention from both academia and policy makers. Examining the distribution\nof FA by citation index database, by language, and by acknowledgment type, we\nnoted coverage limitations and potential biases in each analysis. We argue that\nin spite of its great value, bibliometric analysis of FA should be used with\ncaution."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.23713", 
    "link": "http://arxiv.org/pdf/1601.00288v1", 
    "title": "Identification of long-term concept-symbols among citations: Can   documents be clustered in terms of common intellectual histories?", 
    "arxiv-id": "1601.00288v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2016-01-03T12:52:27Z", 
    "summary": "\"Citation classics\" are not only highly cited, but also cited during several\ndecades. We test whether the peaks in the spectrograms generated by Reference\nPublication Years Spectroscopy (RPYS) indicate such long-term impact by\ncomparing across RPYS for subsequent time intervals. Multi-RPYS enables us to\ndistinguish between short-term citation peaks at the research front that decay\nwithin ten years versus historically constitutive (long-term) citations that\nfunction as concept symbols (Small, 1978). Using these constitutive citations,\none is able to cluster document sets (e.g., journals) in terms of\nintellectually shared histories. We test this premise by clustering 40 journals\nin the Web of Science Category of Information and Library Science using\nmulti-RPYS. It follows that RPYS can not only be used for retrieving roots of\nsets under study (cited), but also for algorithmic historiography of the citing\nsets. Significant references are historically rooted symbols among other\ncitations that function as currency."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.12.007", 
    "link": "http://arxiv.org/pdf/1601.00473v1", 
    "title": "The discretised lognormal and hooked power law distributions for   complete citation data: Best options for modelling and regression", 
    "arxiv-id": "1601.00473v1", 
    "author": "Mike Thelwall", 
    "publish": "2016-01-04T12:16:09Z", 
    "summary": "Identifying the statistical distribution that best fits citation data is\nimportant to allow robust and powerful quantitative analyses. Whilst previous\nstudies have suggested that both the hooked power law and discretised lognormal\ndistributions fit better than the power law and negative binomial\ndistributions, no comparisons so far have covered all articles within a\ndiscipline, including those that are uncited. Based on an analysis of 26\ndifferent Scopus subject areas in seven different years, this article reports\ncomparisons of the discretised lognormal and the hooked power law with citation\ndata, adding 1 to citation counts in order to include zeros. The hooked power\nlaw fits better in two thirds of the subject/year combinations tested for\njournal articles that are at least three years old, including most medical,\nlife and natural sciences, and for virtually all subject areas for younger\narticles. Conversely, the discretised lognormal tends to fit best for arts,\nhumanities, social science and engineering fields. The difference between the\nfits of the distributions is mostly small, however, and so either could\nreasonably be used for modelling citation data. For regression analyses,\nhowever, the best option is to use ordinary least squares regression applied to\nthe natural logarithm of citation counts plus one, especially for sets of\nyounger articles, because of the increased precision of the parameters."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.12.007", 
    "link": "http://arxiv.org/pdf/1601.01199v2", 
    "title": "Introducing CitedReferencesExplorer (CRExplorer): A program for   Reference Publication Year Spectroscopy with Cited References Standardization", 
    "arxiv-id": "1601.01199v2", 
    "author": "Lutz Bornmann", 
    "publish": "2016-01-06T14:56:59Z", 
    "summary": "We introduce a new tool - the CitedReferencesExplorer (CRExplorer,\nwww.crexplorer.net) - which can be used to disambiguate and analyze the cited\nreferences (CRs) of a publication set downloaded from the Web of Science (WoS).\nThe tool is especially suitable to identify those publications which have been\nfrequently cited by the researchers in a field and thereby to study for example\nthe historical roots of a research field or topic. CRExplorer simplifies the\nidentification of key publications by enabling the user to work with both a\ngraph for identifying most frequently cited reference publication years (RPYs)\nand the list of references for the RPYs which have been most frequently cited.\nA further focus of the program is on the standardization of CRs. It is a\nserious problem in bibliometrics that there are several variants of the same CR\nin the WoS. In this study, CRExplorer is used to study the CRs of all papers\npublished in the Journal of Informetrics. The analyses focus on the most\nimportant papers published between 1980 and 1990."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.12.007", 
    "link": "http://arxiv.org/pdf/1601.02927v1", 
    "title": "Opening Scholarly Communication in Social Sciences: Supporting Open Peer   Review with Fidus Writer", 
    "arxiv-id": "1601.02927v1", 
    "author": "Christoph Lange", 
    "publish": "2016-01-12T15:58:40Z", 
    "summary": "Our system will initially provide readers, authors and reviewers with an\nalternative, thus having the potential to gain wider acceptance and gradually\nreplace the old, incoherent publication process of our journals and of others\nin related fields. It will make journals more \"open\" (in terms of reusability)\nthat are open access already, and it has the potential to serve as an incentive\nfor turning \"closed\" journals into open access ones. In this poster paper we\nwill present the framework of the OSCOSS system and highlight the reviewer use\ncase."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.12.007", 
    "link": "http://arxiv.org/pdf/1601.04950v1", 
    "title": "Lotka's Inverse Square Law of Scientific Productivity: Its Methods and   Statistics", 
    "arxiv-id": "1601.04950v1", 
    "author": "Lawrence J. Smolinsky", 
    "publish": "2016-01-19T15:24:22Z", 
    "summary": "This brief communication analyzes the statistics and methods Lotka used to\nderive his inverse square law of scientific productivity from the standpoint of\nmodern theory. It finds that he violated the norms of this theory by extremely\ntruncating his data on the right. It also proves that Lotka himself played an\nimportant role in establishing the commonly used method of identifying\npower-law behavior by the R^2 fit to a regression line on a log-log plot that\nmodern theory considers unreliable by basing the derivation of his law on this\nvery method."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.12.007", 
    "link": "http://arxiv.org/pdf/1601.05142v1", 
    "title": "Adapting the Hypercube Model to Archive Deferred Representations and   Their Descendants", 
    "arxiv-id": "1601.05142v1", 
    "author": "Michael L. Nelson", 
    "publish": "2016-01-20T00:48:39Z", 
    "summary": "The web is today's primary publication medium, making web archiving an\nimportant activity for historical and analytical purposes. Web pages are\nincreasingly interactive, resulting in pages that are increasingly difficult to\narchive. Client-side technologies (e.g., JavaScript) enable interactions that\ncan potentially change the client-side state of a representation. We refer to\nrepresentations that load embedded resources via JavaScript as deferred\nrepresentations. It is difficult to archive all of the resources in deferred\nrepresentations and the result is archives with web pages that are either\nincomplete or that erroneously load embedded resources from the live web.\n  We propose a method of discovering and crawling deferred representations and\ntheir descendants (representation states that are only reachable through\nclient-side events). We adapt the Dincturk et al. Hypercube model to construct\na model for archiving descendants, and we measure the number of descendants and\nrequisite embedded resources discovered in a proof-of-concept crawl. Our\napproach identified an average of 38.5 descendants per seed URI crawled, 70.9%\nof which are reached through an onclick event. This approach also added 15.6\ntimes more embedded resources than Heritrix to the crawl frontier, but at a\nrate that was 38.9 times slower than simply using Heritrix. We show that our\ndataset has two levels of descendants. We conclude with proposed crawl policies\nand an analysis of the storage requirements for archiving descendants."
},{
    "category": "cs.DL", 
    "doi": "10.5281/zenodo.45402", 
    "link": "http://arxiv.org/pdf/1601.08049v2", 
    "title": "Individual Bibliometric Assessment @ University of Vienna: From Numbers   to Multidimensional Profiles", 
    "arxiv-id": "1601.08049v2", 
    "author": "Christian Gumpenberger", 
    "publish": "2016-01-29T10:54:56Z", 
    "summary": "This paper shows how bibliometric assessment can be implemented at individual\nlevel. This has been successfully done at the University of Vienna carried out\nby the Bibliometrics and Publication Strategies Department of the Vienna\nUniversity Library. According to the department's philosophy, bibliometrics is\nnot only a helpful evaluation instrument in order to complement the peer review\nsystem. It is also meant as a compass for researchers in the \"publish or\nperish\" dilemma in order to increase general visibility and to optimize\npublication strategies. The individual assessment comprises of an interview\nwith the researcher under evaluation, the elaboration of a bibliometric report\nof the researcher's publication output, the discussion and validation of the\nobtained results with the researcher under evaluation as well as further\noptional analyses. The produced bibliometric reports are provided to the\nresearchers themselves and inform them about the quantitative aspects of their\nresearch output. They also serve as a basis for further discussion concerning\ntheir publication strategies. These reports are eventually intended for\ninformed peer review practices, and are therefore forwarded to the quality\nassurance and the rector's office and finally sent to the peers. The most\nimportant feature of the generated bibliometric report is its multidimensional\nand individual character. It relies on a variety of basic indicators and\nfurther control parameters in order to foster comprehensibility. Researchers,\nadministrative staff and peers alike have confirmed the usefulness of this\nbibliometric approach. An increasing demand is noticeable. In total, 33\nbibliometric reports have been delivered so far. Moreover, similar reports have\nalso been produced for the bibliometric assessment of two faculties with great\nsuccess."
},{
    "category": "cs.DL", 
    "doi": "10.5281/zenodo.45402", 
    "link": "http://arxiv.org/pdf/1602.00234v3", 
    "title": "Computer-Assisted Processing of Intertextuality in Ancient Languages", 
    "arxiv-id": "1602.00234v3", 
    "author": "Charlotte Tupman", 
    "publish": "2016-01-31T11:59:02Z", 
    "summary": "The production of digital critical editions of texts using TEI is now a\nwidely-adopted procedure within digital humanities. The work described in this\npaper extends this approach to the publication of gnomologia (anthologies of\nwise sayings), which formed a widespread literary genre in many cultures of the\nmedieval Mediterranean. These texts are challenging because they were rarely\ncopied straightforwardly; rather, sayings were selected, reorganised, modified\nor re-attributed between manuscripts, resulting in a highly interconnected\ncorpus for which a standard approach to digital publication is insufficient.\nFocusing on Greek and Arabic collections, we address this challenge using\nsemantic web techniques to create an ecosystem of texts, relationships and\nannotations, and consider a new model - organic, collaborative, interconnected,\nand open-ended - of what constitutes an edition. This semantic web-based\napproach allows scholars to add their own materials and annotations to the\nnetwork of information and to explore the conceptual networks that arise from\nthese interconnected sayings."
},{
    "category": "cs.DL", 
    "doi": "10.5281/zenodo.45402", 
    "link": "http://arxiv.org/pdf/1602.00242v1", 
    "title": "Technical Report: Representing SES Cases Using Ontology", 
    "arxiv-id": "1602.00242v1", 
    "author": "Miao Chen", 
    "publish": "2016-01-31T13:09:12Z", 
    "summary": "Socio-ecological System (SES) research studies the interaction between\nenvironment, users, and governance of environment resources. Data produced\nduring the research cycle can be both long-tail (e.g. heterogeneous) and\nlongitudinal data. For example, the IFRI (International Forestry Resources and\nInstitutions) data set contains studies carried out over a period of 20 years.\nGiven the complexity of a SES system, case studies that are accumulated over\ntime and from different sites (e.g. site visit cases) are highly valuable in\nthe understanding of new SES system behavior for instance. We, as a group of\ninformatics researchers collaborating with personnel from the Workshop in\nPolitical Theory and Policy Analysis at Indiana University, are developing\ninformatics approaches to facilitating SES scholars' research.\n  Here we focus on presenting our work on representing SES cases using\nontology. An ontology for the SES field can help organize concepts in the\nfield, describe resources such as data and publications using a shared\nvocabulary, and also facilitate data use and query for researchers. We develop\na core SES ontology, which contains core concepts and resources in the field\nand can be used to describe actual concept and resource instances, and also a\ntool for contributing instances by drawing graphs, called Cmap2SES."
},{
    "category": "cs.DL", 
    "doi": "10.5281/zenodo.45402", 
    "link": "http://arxiv.org/pdf/1602.01904v1", 
    "title": "On the Discovery of Success Trajectories of Authors", 
    "arxiv-id": "1602.01904v1", 
    "author": "Subrata Nandi", 
    "publish": "2016-02-05T01:08:43Z", 
    "summary": "Understanding the qualitative patterns of research endeavor of scientific\nauthors in terms of publication count and their impact (citation) is important\nin order to quantify success trajectories. Here, we examine the career profile\nof authors in computer science and physics domains and discover at least six\ndifferent success trajectories in terms of normalized citation count in\nlongitudinal scale. Initial observations of individual trajectories lead us to\ncharacterize the authors in each category. We further leverage this trajectory\ninformation to build a two-stage stratification model to predict future success\nof an author at the early stage of her career. Our model outperforms the\nbaseline with an average improvement of 15.68% for both the datasets."
},{
    "category": "cs.DL", 
    "doi": "10.5281/zenodo.45402", 
    "link": "http://arxiv.org/pdf/1602.01950v2", 
    "title": "RPYS i/o: A web-based tool for the historiography and visualization of   citation classics, sleeping beauties, and research fronts", 
    "arxiv-id": "1602.01950v2", 
    "author": "Loet Leydesdorff", 
    "publish": "2016-02-05T08:10:56Z", 
    "summary": "Reference Publication Year Spectroscopy (RPYS) and Multi-RPYS provide\nalgorithmic approaches to reconstructing the intellectual histories of\nscientific fields. With this brief communication, we describe a technical\nadvancement for developing research historiographies by introducing RPYS i/o,\nan online tool for performing standard RPYS and Multi-RPYS analyses\ninteractively (at http://comins.leydesdorff.net/). The tool enables users to\nexplore seminal works underlying a research field and to plot the influence of\nthese seminal works over time. This suite of visualizations offers the\npotential to analyze and visualize the myriad of temporal dynamics of\nscientific influence, such as citation classics, sleeping beauties, and the\ndynamics of research fronts. We demonstrate the features of the tool by\nanalyzing--as an example--the references in documents published in the journal\nPhilosophy of Science."
},{
    "category": "cs.DL", 
    "doi": "10.5281/zenodo.45402", 
    "link": "http://arxiv.org/pdf/1602.02412v1", 
    "title": "The counting house: measuring those who count. Presence of   Bibliometrics, Scientometrics, Informetrics, Webometrics and Altmetrics in   the Google Scholar Citations, ResearcherID, ResearchGate, Mendeley & Twitter", 
    "arxiv-id": "1602.02412v1", 
    "author": "Emilio Delgado Lopez-Cozar", 
    "publish": "2016-02-07T19:14:35Z", 
    "summary": "Following in the footsteps of the model of scientific communication, which\nhas recently gone through a metamorphosis (from the Gutenberg galaxy to the Web\ngalaxy), a change in the model and methods of scientific evaluation is also\ntaking place. A set of new scientific tools are now providing a variety of\nindicators which measure all actions and interactions among scientists in the\ndigital space, making new aspects of scientific communication emerge. In this\nwork we present a method for capturing the structure of an entire scientific\ncommunity (the Bibliometrics, Scientometrics, Informetrics, Webometrics, and\nAltmetrics community) and the main agents that are part of it (scientists,\ndocuments, and sources) through the lens of Google Scholar Citations.\n  Additionally, we compare these author portraits to the ones offered by other\nprofile or social platforms currently used by academics (ResearcherID,\nResearchGate, Mendeley, and Twitter), in order to test their degree of use,\ncompleteness, reliability, and the validity of the information they provide. A\nsample of 814 authors (researchers in Bibliometrics with a public profile\ncreated in Google Scholar Citations was subsequently searched in the other\nplatforms, collecting the main indicators computed by each of them. The data\ncollection was carried out on September, 2015. The Spearman correlation was\napplied to these indicators (a total of 31) , and a Principal Component\nAnalysis was carried out in order to reveal the relationships among metrics and\nplatforms as well as the possible existence of metric clusters"
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0160393", 
    "link": "http://arxiv.org/pdf/1602.03834v2", 
    "title": "Climate Change Research in View of Bibliometrics", 
    "arxiv-id": "1602.03834v2", 
    "author": "Werner Marx", 
    "publish": "2016-02-11T19:20:28Z", 
    "summary": "This bibliometric study of a large publication set dealing with research on\nclimate change aims at mapping the relevant literature from a bibliometric\nperspective and presents a multitude of quantitative data: (1) The growth of\nthe overall publication output as well as (2) of some major subfields, (3) the\ncontributing journals and countries as well as their citation impact, and (4) a\ntitle word analysis aiming to illustrate the time evolution and relative\nimportance of specific research topics. The study is based on 222,060 papers\npublished between 1980 and 2014. The total number of papers shows a strong\nincrease with a doubling every 5-6 years. Continental biomass related research\nis the major subfield, closely followed by climate modeling. Research dealing\nwith adaptation, mitigation, risks, and vulnerability of global warming is\ncomparatively small, but their share of papers increased exponentially since\n2005. Research on vulnerability and on adaptation published the largest\nproportion of very important papers. Research on climate change is\nquantitatively dominated by the USA, followed by the UK, Germany, and Canada.\nThe citation-based indicators exhibit consistently that the UK has produced the\nlargest proportion of high impact papers compared to the other countries\n(having published more than 10,000 papers). The title word analysis shows that\nthe term climate change comes forward with time. Furthermore, the term impact\narises and points to research dealing with the various effects of climate\nchange. Finally, the term model and related terms prominently appear\nindependent of time, indicating the high relevance of climate modeling."
},{
    "category": "cs.DL", 
    "doi": "10.1093/reseval/rvw003", 
    "link": "http://arxiv.org/pdf/1602.04049v2", 
    "title": "Tracking the performance of an R&D programme in the Biomedical Sciences", 
    "arxiv-id": "1602.04049v2", 
    "author": "Evaristo Jim\u00e9nez-Contreras", 
    "publish": "2016-02-12T13:29:29Z", 
    "summary": "This paper aims at offering an evaluation framework of an Research and\nDevelopment programme in the Biomedical Sciences. It showcases the Spanish\nBiomedical Research Networking Centres initiative (CIBER) as an example of the\neffect of research policy management on performance. For this it focuses on\nthree specific aspects: its role on the national research output in the\nbiomedical sciences, its effect on promoting translational research through\ninternal collaboration between research groups, and the perception of\nresearchers on the programme as defined by their inclusion of their CIBER\ncentres in the address field. Research output derived from this programme\nrepresents around 25 per cent of the country's publications in the biomedical\nfields. After analysing a seven year period, the programme has enhanced\ncollaborations between its members, but they do not seem to be sufficiently\nstrong. With regard to the credit given to the initiative, 54.5 per cent of the\npublications mentioned this programme in their address, however an increase on\nthe share of papers mention it is observed two years after it was launched. We\nsuggest that by finding the point in which the share of mentions stabilises may\nbe a good strategy to identify the complete fulfilment of these types of\nResearch and Development policies."
},{
    "category": "cs.DL", 
    "doi": "10.1093/reseval/rvw003", 
    "link": "http://arxiv.org/pdf/1602.04701v2", 
    "title": "Iran's scientific dominance and the emergence of South-East Asian   countries as scientific collaborators in the Persian Gulf Region", 
    "arxiv-id": "1602.04701v2", 
    "author": "Henk F. Moed", 
    "publish": "2016-02-15T15:04:32Z", 
    "summary": "A longitudinal bibliometric analysis of publications indexed in Thomson\nReuters' Incites and Elsevier's Scopus, and published from Persian Gulf States\nand neighbouring Middle East countries, shows clear effects of major political\nevents during the past 35 years. Predictions made in 2006 by the US diplomat\nRichard N. Haass on political changes in the Middle East have come true in the\nGulf States' national scientific research systems, to the extent that Iran has\nbecome in 2015 by far the leading country in the Persian Gulf, and South-East\nAsian countries including China, Malaysia and South Korea have become major\nscientific collaborators, displacing the USA and other large Western countries.\nBut collaborations patterns among Persian Gulf States show no apparent\nrelationship with differences in Islam denominations."
},{
    "category": "cs.DL", 
    "doi": "10.1093/reseval/rvw003", 
    "link": "http://arxiv.org/pdf/1602.06223v2", 
    "title": "Rules of Acquisition for Mementos and Their Content", 
    "arxiv-id": "1602.06223v2", 
    "author": "Harihar Shankar", 
    "publish": "2016-02-19T17:07:24Z", 
    "summary": "Text extraction from web pages has many applications, including web crawling\noptimization and document clustering. Though much has been written about the\nacquisition of content from live web pages, content acquisition of archived web\npages, known as mementos, remains a relatively new enterprise. In the course of\nconducting a study with almost 700,000 web pages, we encountered issues\nacquiring mementos and extracting text from them. The acquisition of memento\ncontent via HTTP is expected to be a relatively painless exercise, but we have\nfound cases to the contrary. We also find that the parsing of HTML, already\nknown to be problematic, can be more complex when one attempts to extract the\ntext of mementos across many web archives, due to issues involving different\nmemento presentation behaviors, as well as the age of the HTML in their\nmementos. For the benefit of others acquiring mementos across many web\narchives, we document those experiences here."
},{
    "category": "cs.DL", 
    "doi": "10.1093/reseval/rvw007", 
    "link": "http://arxiv.org/pdf/1602.07396v1", 
    "title": "Concentration of research funding leads to decreasing marginal returns", 
    "arxiv-id": "1602.07396v1", 
    "author": "Vincent Lariviere", 
    "publish": "2016-02-24T04:37:19Z", 
    "summary": "In most countries, basic research is supported by research councils that\nselect, after peer review, the individuals or teams that are to receive\nfunding. Unfortunately, the number of grants these research councils can\nallocate is not infinite and, in most cases, a minority of the researchers\nreceive the majority of the funds. However, evidence as to whether this is an\noptimal way of distributing available funds is mixed. The purpose of this study\nis to measure the relation between the amount of funding provided to 12,720\nresearchers in Quebec over a fifteen year period (1998-2012) and their\nscientific output and impact from 2000 to 2013. Our results show that both in\nterms of the quantity of papers produced and of their scientific impact, the\nconcentration of research funding in the hands of a so-called \"elite\" of\nresearchers generally produces diminishing marginal returns. Also, we find that\nthe most funded researchers do not stand out in terms of output and scientific\nimpact."
},{
    "category": "cs.DL", 
    "doi": "10.1093/reseval/rvw007", 
    "link": "http://arxiv.org/pdf/1602.09102v1", 
    "title": "Persistent URIs Must Be Used To Be Persistent", 
    "arxiv-id": "1602.09102v1", 
    "author": "Shawn M. Jones", 
    "publish": "2016-02-29T19:03:23Z", 
    "summary": "We quantify the extent to which references to papers in scholarly literature\nuse persistent HTTP URIs that leverage the Digital Object Identifier\ninfrastructure. We find a significant number of references that do not,\nspeculate why authors would use brittle URIs when persistent ones are\navailable, and propose an approach to alleviate the problem."
},{
    "category": "cs.DL", 
    "doi": "10.1093/reseval/rvw007", 
    "link": "http://arxiv.org/pdf/1603.01207v1", 
    "title": "From manuscript catalogues to a handbook of Syriac literature: Modeling   an infrastructure for Syriaca.org", 
    "arxiv-id": "1603.01207v1", 
    "author": "Daniel L. Schwartz", 
    "publish": "2016-03-03T18:14:52Z", 
    "summary": "Despite increasing interest in Syriac studies and growing digital\navailability of Syriac texts, there is currently no up-to-date infrastructure\nfor discovering, identifying, classifying, and referencing works of Syriac\nliterature. The standard reference work (Baumstark's Geschichte) is over ninety\nyears old, and the perhaps 20,000 Syriac manuscripts extant worldwide can be\naccessed only through disparate catalogues and databases. The present article\nproposes a tentative data model for Syriaca.org's New Handbook of Syriac\nLiterature, an open-access digital publication that will serve as both an\nauthority file for Syriac works and a guide to accessing their manuscript\nrepresentations, editions, and translations. The authors hope that by\npublishing a draft data model they can receive feedback and incorporate\nsuggestions into the next stage of the project."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-016-1910-9", 
    "link": "http://arxiv.org/pdf/1603.04939v1", 
    "title": "Grand challenges in altmetrics: heterogeneity, data quality and   dependencies", 
    "arxiv-id": "1603.04939v1", 
    "author": "Stefanie Haustein", 
    "publish": "2016-03-16T02:02:15Z", 
    "summary": "As uptake among researchers is constantly increasing, social media are\nfinding their way into scholarly communication and, under the umbrella term\naltmetrics, were introduced to research evaluation. Fueled by technological\npossibilities and an increasing demand to demonstrate impact beyond the\nscientific community, altmetrics received great attention as potential\ndemocratizers of the scientific reward system and indicators of societal\nimpact. This paper focuses on current challenges of altmetrics. Heterogeneity,\ndata quality and particular dependencies are identified as the three major\nissues and discussed in detail with a particular emphasis on past developments\nin bibliometrics. The heterogeneity of altmetrics mirrors the diversity of the\ntypes of underlying acts, most of which take place on social media platforms.\nThis heterogeneity has made it difficult to establish a common definition or\nconceptual framework. Data quality issues become apparent in the lack of\naccuracy, consistency and replicability of various altmetrics, which is largely\naffected by the dynamic nature of social media events. It is further\nhighlighted that altmetrics are shaped by technical possibilities and depend\nparticularly on the availability of APIs and DOIs, are strongly dependent on\ndata providers and aggregators, and potentially influenced by technical\naffordances of underlying platforms."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-016-1910-9", 
    "link": "http://arxiv.org/pdf/1603.05078v1", 
    "title": "Are the discretised lognormal and hooked power law distributions   plausible for citation data?", 
    "arxiv-id": "1603.05078v1", 
    "author": "Mike Thelwall", 
    "publish": "2016-03-16T13:04:59Z", 
    "summary": "There is no agreement over which statistical distribution is most appropriate\nfor modelling citation count data. This is important because if one\ndistribution is accepted then the relative merits of different citation-based\nindicators, such as percentiles, arithmetic means and geometric means, can be\nmore fully assessed. In response, this article investigates the plausibility of\nthe discretised lognormal and hooked power law distributions for modelling the\nfull range of citation counts, with an offset of 1. The citation counts from 23\nScopus subcategories were fitted to hooked power law and discretised lognormal\ndistributions but both distributions failed a Kolmogorov-Smirnov goodness of\nfit test in over three quarters of cases. The discretised lognormal\ndistribution also seems to have the wrong shape for citation distributions,\nwith too few zeros and not enough medium values for all subjects. The cause of\npoor fits could be the impurity of the subject subcategories or the presence of\ninterdisciplinary research. Although it is possible to test for subject\nsubcategory purity indirectly through a goodness of fit test in theory with\nlarge enough sample sizes, it is probably not possible in practice. Hence it\nseems difficult to get conclusive evidence about the theoretically most\nappropriate statistical distribution."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-016-1910-9", 
    "link": "http://arxiv.org/pdf/1603.05212v1", 
    "title": "Analysis of the Cuban journal Bibliotecas: Anales de Investigacion", 
    "arxiv-id": "1603.05212v1", 
    "author": "M. P. Linares Herrera", 
    "publish": "2016-03-16T18:37:38Z", 
    "summary": "The objective of this article is to describe the academic impact, the\neditorial process quality, and the editorial and visibility strategies of\nBibliotecas. Anales de Investigacion (BAI), a scientific Cuban journal edited\nby National Library of Cuba Jose Marti. The academic impact is determined\nthrough a citation analysis, which considers Google Scholar database as\nreference source. The bibliometric indicators applied are: citation per year,\ncitation vs. self-citation, citable journals vs. non-citable documents, Hirsch\nIndex, and impact factor. The editorial process quality and the visibility\nstrategies are determined through a self-evaluation which takes into account\nthe SciELO, Scopus, CLASE, Redalyc, Latindex, Dialnet, and ERIH PLUS\nmethodologies. The results reveal an ascending citation line that highlights\nciting journals from the field of Library and Information Science, Medicine and\nHealth Sciences, and Education. Aspects related content and format have\nnegatively influenced on editorial process quality. Some strategies are\nproposed to improve scientific visibility through the inclusion in databases,\ndirectories, and social and academic networks. In general, this study\ncontributes to the editorial decision taking, an issue that could augment the\nimpact and scientific visibility of BAI."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-016-1910-9", 
    "link": "http://arxiv.org/pdf/1603.08452v3", 
    "title": "Citations: Indicators of Quality? The Impact Fallacy", 
    "arxiv-id": "1603.08452v3", 
    "author": "Sta\u0161a Milojevi\u0107", 
    "publish": "2016-03-28T17:37:20Z", 
    "summary": "We argue that citation is a composed indicator: short-term citations can be\nconsidered as currency at the research front, whereas long-term citations can\ncontribute to the codification of knowledge claims into concept symbols.\nKnowledge claims at the research front are more likely to be transitory and are\ntherefore problematic as indicators of quality. Citation impact studies focus\non short-term citation, and therefore tend to measure not epistemic quality,\nbut involvement in current discourses in which contributions are positioned by\nreferencing. We explore this argument using three case studies: (1) citations\nof the journal Soziale Welt as an example of a venue that tends not to publish\npapers at a research front, unlike, for example, JACS; (2) Robert Merton as a\nconcept symbol across theories of citation; and (3) the Multi-RPYS\n(\"Multi-Referenced Publication Year Spectroscopy\") of the journals\nScientometrics, Gene, and Soziale Welt. We show empirically that the\nmeasurement of \"quality\" in terms of citations can further be qualified:\nshort-term citation currency at the research front can be distinguished from\nlonger-term processes of incorporation and codification of knowledge claims\ninto bodies of knowledge. The recently introduced Multi-RPYS can be used to\ndistinguish between short-term and long-term impacts."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-016-1917-2", 
    "link": "http://arxiv.org/pdf/1603.09111v1", 
    "title": "Back to the past: on the shoulders of an academic search engine giant", 
    "arxiv-id": "1603.09111v1", 
    "author": "Emilio Delgado Lopez-Cozar", 
    "publish": "2016-03-30T10:25:16Z", 
    "summary": "A study released by the Google Scholar team found an apparently increasing\nfraction of citations to old articles from studies published in the last 24\nyears (1990-2013). To demonstrate this finding we conducted a complementary\nstudy using a different data source (Journal Citation Reports), metric\n(aggregate cited half-life), time spam (2003-2013), and set of categories (53\nSocial Science subject categories and 167 Science subject categories). Although\nthe results obtained confirm and reinforce the previous findings, the possible\ncauses of this phenomenon keep unclear. We finally hypothesize that first page\nresults syndrome in conjunction with the fact that Google Scholar favours the\nmost cited documents are suggesting the growing trend of citing old documents\nis partly caused by Google Scholar."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-016-1917-2", 
    "link": "http://arxiv.org/pdf/1604.02716v4", 
    "title": "Construction of a Pragmatic Base Line for Journal Classifications and   Maps Based on Aggregated Journal-Journal Citation Relations", 
    "arxiv-id": "1604.02716v4", 
    "author": "Ping Zhou", 
    "publish": "2016-04-10T17:40:20Z", 
    "summary": "A number of journal classification systems have been developed in\nbibliometrics since the launch of the Citation Indices by the Institute of\nScientific Information (ISI) in the 1960s. These systems are used to normalize\ncitation counts with respect to field-specific citation patterns. The best\nknown system is the so-called \"Web-of-Science Subject Categories\" (WCs). In\nother systems papers are classified by algorithmic solutions. Using the Journal\nCitation Reports 2014 of the Science Citation Index and the Social Science\nCitation Index (n of journals = 11,149), we examine options for developing a\nnew system based on journal classifications into subject categories using\naggregated journal-journal citation data. Combining routines in VOSviewer and\nPajek, a tree-like classification is developed. At each level one can generate\na map of science for all the journals subsumed under a category. Nine major\nfields are distinguished at the top level. Further decomposition of the social\nsciences is pursued for the sake of example with a focus on journals in\ninformation science (LIS) and science studies (STS). The new classification\nsystem improves on alternative options by avoiding the problem of randomness in\neach run that has made algorithmic solutions hitherto irreproducible.\nLimitations of the new system are discussed (e.g. the classification of\nmulti-disciplinary journals). The system's usefulness for field-normalization\nin bibliometrics should be explored in future studies."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-016-1917-2", 
    "link": "http://arxiv.org/pdf/1604.04705v1", 
    "title": "Referenced Publication Year Spectroscopy (RPYS) and Algorithmic   Historiography: The Bibliometric Reconstruction of Andr\u00e1s Schubert's   \u0152uvre", 
    "arxiv-id": "1604.04705v1", 
    "author": "Andreas Thor", 
    "publish": "2016-04-16T07:25:58Z", 
    "summary": "Referenced Publication Year Spectroscopy (RPYS) was recently introduced as a\nmethod to analyze the historical roots of research fields and groups or\ninstitutions. RPYS maps the distribution of the publication years of the cited\nreferences in a document set. In this study, we apply this methodology to the\n{\\oe}uvre of an individual researcher on the occasion of a Festschrift for\nAndr\\'as Schubert's 70th birthday. We discuss the different options of RPYS in\nrelation to one another (e.g. Multi-RPYS), and in relation to the longer-term\nresearch program of algorithmic historiography (e.g., HistCite) based on\nSchubert's publications (n=172) and cited references therein as a bibliographic\ndomain in scientometrics. Main path analysis and Multi-RPYS of the citation\nnetwork are used to show the changes and continuities in Schubert's\nintellectual career. Diachronic and static decomposition of a document set can\nlead to different results, while the analytically distinguishable lines of\nresearch may overlap and interact over time, and intermittent."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-016-1953-y", 
    "link": "http://arxiv.org/pdf/1604.04780v1", 
    "title": "Characterization, description, and considerations for the use of funding   acknowledgement data in Web of Science", 
    "arxiv-id": "1604.04780v1", 
    "author": "Rodrigo Costas", 
    "publish": "2016-04-16T18:04:00Z", 
    "summary": "Funding acknowledgements found in scientific publications have been used to\nstudy the impact of funding on research since the 1970s. However, no broad\nscale indexation of that paratextual element was done until 2008, when Thomson\nReuters Web of Science started to add funding acknowledgement information to\nits bibliographic records. As this new information provides a new dimension to\nbibliometric data that can be systematically exploited, it is important to\nunderstand the characteristics of these data and the underlying implications\nfor their use. This paper analyses the presence and distribution of funding\nacknowledgement data covered in Web of Science. Our results show that prior to\n2009 funding acknowledgements coverage is extremely low and therefore not\nreliable. Since 2008, funding information has been collected mainly for\npublications indexed in the Science Citation Index Expanded (SCIE); more\nrecently (2015), inclusion of funding texts for publications indexed in the\nSocial Science Citation Index (SSCI) has been implemented. Arts & Humanities\nCitation Index (AHCI) content is not indexed for funding acknowledgement data.\nMoreover, English-language publications are the most reliably covered. Finally,\nnot all types of documents are equally covered for funding information\nindexation and only articles and reviews show consistent coverage. The\ncharacterization of the funding acknowledgement information collected by\nThomson Reuters can therefore help understand the possibilities offered by the\ndata but also their limitations."
},{
    "category": "cs.DL", 
    "doi": "10.1002/jasist.23737", 
    "link": "http://arxiv.org/pdf/1604.04896v1", 
    "title": "Funding Data from Publication Acknowledgements: Coverage, Uses and   Limitations", 
    "arxiv-id": "1604.04896v1", 
    "author": "Michael M. Hopkins", 
    "publish": "2016-04-17T16:45:07Z", 
    "summary": "This article contributes to the development of methods for analysing research\nfunding systems by exploring the robustness and comparability of emerging\napproaches to generate funding landscapes useful for policy making. We use a\nnovel dataset of manually extracted and coded data on the funding\nacknowledgements of 7,510 publications representing UK cancer research in the\nyear 2011 and compare these 'reference data' with funding data provided by Web\nof Science (WoS) and MEDLINE/PubMed. Findings show high recall (about 93%) of\nWoS funding data. By contrast, MEDLINE/PubMed data retrieved less than half of\nthe UK cancer publications acknowledging at least one funder. Conversely, both\ndatabases have high precision (+90%): i.e. few cases of publications with no\nacknowledgement to funders are identified as having funding data. Nonetheless,\nfunders acknowledged in UK cancer publications were not correctly listed by\nMEDLINE/PubMed and WoS in about 75% and 32% of the cases, respectively.\n'Reference data' on the UK cancer research funding system are then used as a\ncase-study to demonstrate the utility of funding data for strategic\nintelligence applications (e.g. mapping of funding landscape, comparison of\nfunders' research portfolios)."
},{
    "category": "cs.DL", 
    "doi": "10.1002/jasist.23737", 
    "link": "http://arxiv.org/pdf/1604.05363v1", 
    "title": "Comparing Published Scientific Journal Articles to Their Pre-print   Versions", 
    "arxiv-id": "1604.05363v1", 
    "author": "Todd Grappone", 
    "publish": "2016-04-18T22:06:20Z", 
    "summary": "Academic publishers claim that they add value to scholarly communications by\ncoordinating reviews and contributing and enhancing text during publication.\nThese contributions come at a considerable cost: U.S. academic libraries paid\n$1.7 billion for serial subscriptions in 2008 alone. Library budgets, in\ncontrast, are flat and not able to keep pace with serial price inflation. We\nhave investigated the publishers' value proposition by conducting a comparative\nstudy of pre-print papers and their final published counterparts. This\ncomparison had two working assumptions: 1) if the publishers' argument is\nvalid, the text of a pre-print paper should vary measurably from its\ncorresponding final published version, and 2) by applying standard similarity\nmeasures, we should be able to detect and quantify such differences. Our\nanalysis revealed that the text contents of the scientific papers generally\nchanged very little from their pre-print to final published versions. These\nfindings contribute empirical indicators to discussions of the added value of\ncommercial publishers and therefore should influence libraries' economic\ndecisions regarding access to scholarly publications."
},{
    "category": "cs.DL", 
    "doi": "10.1002/jasist.23737", 
    "link": "http://arxiv.org/pdf/1604.06053v1", 
    "title": "Decomposition and Analysis of Technological domains for better   understanding of Technological Structure", 
    "arxiv-id": "1604.06053v1", 
    "author": "Christopher L. Magee", 
    "publish": "2016-04-19T07:04:13Z", 
    "summary": "Patents represent one of the most complete sources of information related to\ntechnological change. This paper presents three months of research on U.S.\npatents in the field of patent analysis. The methodology consists of using\nsearch terms to locate the most representative international and US patent\nclasses and determines the overlap of those classes to arrive at the final set\nof patents and using the prediction model developed by Benson and Magee to\ncalculate the technological improvement rate for the technological domains. My\nresearch focused on the Biochemical Pharmacology technological area and\nselecting relevant patents for technological domains and sub-domains within\nthis area. The goal is to better understand structure of technology domain and\nunderstand how fast the domains and their sub-domains progress. The method I\nused is developed by Benson and Magee which is called the Classification\nOverlap Method1, it provides a reliable and largely automated way to break the\npatent database into understandable technological domains where progress can be\nmeasured."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.04.014", 
    "link": "http://arxiv.org/pdf/1604.06246v1", 
    "title": "Are there too many uncited articles? Zero inflated variants of the   discretised lognormal and hooked power law distributions", 
    "arxiv-id": "1604.06246v1", 
    "author": "Mike Thelwall", 
    "publish": "2016-04-21T10:29:28Z", 
    "summary": "Although statistical models fit many citation data sets reasonably well with\nthe best fitting models being the hooked power law and discretised lognormal\ndistribution, the fits are rarely close. One possible reason is that there\nmight be more uncited articles than would be predicted by any model if some\narticles are inherently uncitable. Using data from 23 different Scopus\ncategories, this article tests the assumption that removing a proportion of\nuncited articles from a citation dataset allows statistical distributions to\nhave much closer fits. It also introduces two new models, zero inflated\ndiscretised lognormal distribution and the zero inflated hooked power law\ndistribution and algorithms to fit them. In all 23 cases, the zero inflated\nversion of the discretised lognormal distribution was an improvement on the\nstandard version and in 15 out of 23 cases the zero inflated version of the\nhooked power law was an improvement on the standard version. Without zero\ninflation the discretised lognormal models fit the data better than the hooked\npower law distribution 6 out of 23 times and with it, the discretised lognormal\nmodels fit the data better than the hooked power law distribution 9 out of 23\ntimes. Apparently uncitable articles seem to occur due to the presence of\nacademic-related magazines in Scopus categories. In conclusion, future citation\nanalysis and research indicators should take into account uncitable articles,\nand the best fitting distribution for sets of citation counts from a single\nsubject and year is either the zero inflated discretised lognormal or zero\ninflated hooked power law."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.04.014", 
    "link": "http://arxiv.org/pdf/1604.06685v2", 
    "title": "Evaluating Journal Quality: A Review of Journal Citation Indicators and   Ranking in Business and Management", 
    "arxiv-id": "1604.06685v2", 
    "author": "Liying Yang", 
    "publish": "2016-04-22T14:40:52Z", 
    "summary": "Evaluating the quality of academic journal is becoming increasing important\nwithin the context of research performance evaluation. Traditionally, journals\nhave been ranked by peer review lists such as that of the Association of\nBusiness Schools (UK) or though their journal impact factor (JIF). However,\nseveral new indicators have been developed, such as the h-index, SJR, SNIP and\nthe Eigenfactor which take into account different factors and therefore have\ntheir own particular biases. In this paper we evaluate these metrics both\ntheoretically and also through an empirical study of a large set of business\nand management journals. We show that even though the indicators appear highly\ncorrelated in fact they lead to large differences in journal rankings. We\ncontextualize our results in terms of the UK's large scale research assessment\nexercise (the RAE/REF) and particularly the ABS journal ranking list. We\nconclude that no one indicator is superior but that the h-index (which includes\nthe productivity of a journal) and SNIP (which aims to normalize for field\neffects) may be the most effective at the moment."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.04.014", 
    "link": "http://arxiv.org/pdf/1604.07997v2", 
    "title": "Knowledge Ratings in MetaboLights", 
    "arxiv-id": "1604.07997v2", 
    "author": "Francisco M. Couto", 
    "publish": "2016-04-27T09:47:38Z", 
    "summary": "This technical report presents an evaluation of the ontology annotations in\nthe metadata of a subset of entries of MetaboLights, a database for\nMetabolomics experiments and derived information. The work includes a manual\nanalysis of the entries and a comprehensive qualitative evaluation of their\nannotations, together with the evaluation guide and its rationale, that was\ndefined and followed. The approach was also implemented as a software script\nthat given a MetaboLights entry returns a quantitative evaluation of the\nquality of its annotations (available on request)."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.04.014", 
    "link": "http://arxiv.org/pdf/1605.01188v3", 
    "title": "Enhancing semantic expressivity in the cultural heritage domain:   exposing the Zeri Photo Archive as Linked Open Data", 
    "arxiv-id": "1605.01188v3", 
    "author": "Fabio Vitali", 
    "publish": "2016-05-04T09:09:34Z", 
    "summary": "Describing cultural heritage objects from the perspective of Linked Open Data\n(LOD) is not a trivial task. The process often requires not only choosing\npertinent ontologies, but also developing new models that preserve the most\ninformation and express the semantic power of cultural heritage data. Indeed,\ndata managed in archives, libraries and museums are complex objects themselves,\nwhich require a deep reflection on even non-conventional conceptual models.\nStarting from these considerations, this paper describes a research project: to\nexpose the vastness of one of the most important collections of European\ncultural heritage, the Zeri Photo Archive, as Linked Open Data. We describe\nhere the steps we undertook to this end: firstly, we developed two ad hoc\nontologies for describing all the issues not completely covered by existent\nmodels (the F Entry and the OA Entry Ontology); then we mapped into RDF the\ndescriptive elements used in the current Zeri Photo Archive catalog, converting\ninto CIDOC-CRM and into the two new aforementioned models the source data based\non the Italian content standards Scheda F (Photography Entry, in English) and\nScheda OA (Work of Art Entry, in English); and finally, we created an RDF\ndataset of the output of the mapping that could show a result capable of\ndemonstrating the complexity of our scenario."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.04.014", 
    "link": "http://arxiv.org/pdf/1605.01821v1", 
    "title": "ScientoBASE: A Framework and Model for Computing Scholastic Indicators   of non-local influence of Journals via Native Data Acquisition algorithms", 
    "arxiv-id": "1605.01821v1", 
    "author": "B. S. Daya Sagar", 
    "publish": "2016-05-06T04:52:18Z", 
    "summary": "Defining and measuring internationality as a function of influence diffusion\nof scientific journals is an open problem. There exists no metric to rank\njournals based on the extent or scale of internationality. Measuring\ninternationality is qualitative, vague, open to interpretation and is limited\nby vested interests. With the tremendous increase in the number of journals in\nvarious fields and the unflinching desire of academics across the globe to\npublish in \"international\" journals, it has become an absolute necessity to\nevaluate, rank and categorize journals based on internationality. Authors, in\nthe current work have defined internationality as a measure of influence that\ntranscends across geographic boundaries. There are concerns raised by the\nauthors about unethical practices reflected in the process of journal\npublication whereby scholarly influence of a select few are artificially\nboosted, primarily by resorting to editorial maneuvres. To counter the impact\nof such tactics, authors have come up with a new method that defines and\nmeasures internationality by eliminating such local effects when computing the\ninfluence of journals. A new metric, Non-Local Influence Quotient(NLIQ) is\nproposed as one such parameter for internationality computation along with\nanother novel metric, Other-Citation Quotient as the complement of the ratio of\nself-citation and total citation. In addition, SNIP and International\nCollaboration Ratio are used as two other parameters."
},{
    "category": "cs.DL", 
    "doi": "10.1186/s12967-014-0227-9", 
    "link": "http://arxiv.org/pdf/1605.02041v1", 
    "title": "Mapping knowledge translation and innovation processes in Cancer Drug   Development: the case of liposomal doxorubicin", 
    "arxiv-id": "1605.02041v1", 
    "author": "Victor-M Castano", 
    "publish": "2016-04-12T05:55:21Z", 
    "summary": "We explored how the knowledge translation and innovation processes are\nstructured when they result in innovations, as in the case of liposomal\ndoxorubicin research. In order to map the processes, a literature network\nanalysis was made through Cytoscape and semantic analysis was performed by\nGOPubmed which is based in the controlled vocabularies MeSH (Medical Subject\nHeadings) and GO (Gene Ontology). We found clusters related to different stages\nof the technological development (invention, innovation and imitation) and the\nknowledge translation process (preclinical, translational and clinical\nresearch), and we were able to map the historic emergence of Doxil as a\nparadigmatic nanodrug. This research could be a powerful methodological tool\nfor decision-making and innovation management in drug delivery research."
},{
    "category": "cs.DL", 
    "doi": "10.1186/s12967-014-0227-9", 
    "link": "http://arxiv.org/pdf/1605.02132v1", 
    "title": "End-to-end evaluation of research organizations", 
    "arxiv-id": "1605.02132v1", 
    "author": "Gangan Prathap", 
    "publish": "2016-05-07T02:18:11Z", 
    "summary": "End-to-end research evaluation needs to separate out the bibliometric part of\nthe chain from the econometric part. We first introduce the role of\nsize-dependent and size-independent indicators in the bibliometric part of the\nevaluation chain. We show that performance can then be evaluated at various\nlevels, namely a zeroth-order, a first-order or even a second-order. To\ncomplete the evaluation chain, we take up the econometric part where efficiency\nof the research production process is represented in terms of output and\noutcome productivities. Both size-dependent and size-independent terms play a\ncrucial role to combine quantity and quality (impact) in a meaningful way.\nOutput or outcome at the bibliometric level can be measured using zeroth, first\nor second-order composite indicators, and the productivity terms follow\naccordingly using the input to output or outcome factors."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.12.008", 
    "link": "http://arxiv.org/pdf/1605.02378v1", 
    "title": "The elephant in the room: The problem of quantifying productivity in   evaluative scientometrics", 
    "arxiv-id": "1605.02378v1", 
    "author": "Paul Wouters", 
    "publish": "2016-05-08T22:48:00Z", 
    "summary": "In a critical and provocative paper, Abramo and D'Angelo claim that commonly\nused scientometric indicators such as the mean normalized citation score (MNCS)\nare completely inappropriate as indicators of scientific performance. Abramo\nand D'Angelo argue that scientific performance should be quantified using\nindicators that take into account the productivity of a research unit. We\nprovide a response to Abramo and D'Angelo, indicating where we believe they\nraise important issues, but also pointing out where we believe their claims to\nbe too extreme."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.12.008", 
    "link": "http://arxiv.org/pdf/1605.03593v1", 
    "title": "The Normalization of Co-authorship Networks in the Bibliometric   Evaluation: The Government Stimulation Programs of China and Korea", 
    "arxiv-id": "1605.03593v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2016-05-11T20:00:35Z", 
    "summary": "Using co-authored publications between China and Korea in Web of Science\n(WoS) during the one-year period of 2014, we evaluate the government\nstimulation program for collaboration between China and Korea. In particular,\nwe apply dual approaches, full integer vs. fractional counting, to\ncollaborative publications in order to better examine both the patterns and\ncontents of Sino-Korean collaboration networks in terms of individual countries\nand institutions. We first conduct a semi-automatic network analysis of\nSino-Korean publications based on the full-integer counting method, and then\ncompare our categorization with contextual rankings using the fractional\ntechnique; routines for fractional counting of WoS data are made available at\nhttp://www.leydesdorff.net/software/fraction . Increasing international\ncollaboration leads paradoxically to lower numbers of publications and\ncitations using fractional counting for performance measurement. However,\ninteger counting is not an appropriate measure for the evaluation of the\nstimulation of collaborations. Both integer and fractional analytics can be\nused to identify important countries and institutions, but with other research\nquestions."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2910896.2925448", 
    "link": "http://arxiv.org/pdf/1605.04180v2", 
    "title": "Semantometrics: Towards Fulltext-based Research Evaluation", 
    "arxiv-id": "1605.04180v2", 
    "author": "Petr Knoth", 
    "publish": "2016-05-13T13:55:42Z", 
    "summary": "Over the recent years, there has been a growing interest in developing new\nresearch evaluation methods that could go beyond the traditional citation-based\nmetrics. This interest is motivated on one side by the wider availability or\neven emergence of new information evidencing research performance, such as\narticle downloads, views and Twitter mentions, and on the other side by the\ncontinued frustrations and problems surrounding the application of purely\ncitation-based metrics to evaluate research performance in practice.\nSemantometrics are a new class of research evaluation metrics which build on\nthe premise that full-text is needed to assess the value of a publication. This\npaper reports on the analysis carried out with the aim to investigate the\nproperties of the semantometric contribution measure, which uses semantic\nsimilarity of publications to estimate research contribution, and provides a\ncomparative study of the contribution measure with traditional bibliometric\nmeasures based on citation counting."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2910896.2925448", 
    "link": "http://arxiv.org/pdf/1605.06154v1", 
    "title": "Web Infrastructure to Support e-Journal Preservation (and More)", 
    "arxiv-id": "1605.06154v1", 
    "author": "Michael L. Nelson", 
    "publish": "2016-05-19T21:44:01Z", 
    "summary": "E-journal preservation systems have to ingest millions of articles each year.\nIngest, especially of the \"long tail\" of journals from small publishers, is the\nlargest element of their cost. Cost is the major reason that archives contain\nless than half the content they should. Automation is essential to minimize\nthese costs. This paper examines the potential for automation beyond the status\nquo based on the API provided by CrossRef, ANSI/NISO Z39.99 ResourceSync, and\nthe provision of typed links in publishers' HTTP response headers. These\nchanges would not merely assist e-journal preservation and other cross-venue\nscholarly applications, but would help remedy the gap that research has\nrevealed between DOIs' potential and actual benefits."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-016-2194-9", 
    "link": "http://arxiv.org/pdf/1605.08185v2", 
    "title": "Ruling Out Static Latent Homophily in Citation Networks", 
    "arxiv-id": "1605.08185v2", 
    "author": "Gustaf Nelhans", 
    "publish": "2016-05-26T08:07:47Z", 
    "summary": "Citation and coauthor networks offer an insight into the dynamics of\nscientific progress. We can also view them as representations of a causal\nstructure, a logical process captured in a graph. From a causal perspective, we\ncan ask questions such as whether authors form groups primarily due to their\nprior shared interest, or if their favourite topics are 'contagious' and spread\nthrough co-authorship. Such networks have been widely studied by the artificial\nintelligence community, and recently a connection has been made to nonlocal\ncorrelations produced by entangled particles in quantum physics -- the impact\nof latent hidden variables can be analyzed by the same algebraic geometric\nmethodology that relies on a sequence of semidefinite programming (SDP)\nrelaxations. Following this trail, we treat our sample coauthor network as a\ncausal graph and, using SDP relaxations, rule out latent homophily as a\nmanifestation of prior shared interest leading to the observed patternedness.\nBy introducing algebraic geometry to citation studies, we add a new tool to\nexisting methods for the analysis of content-related social influences."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-016-2194-9", 
    "link": "http://arxiv.org/pdf/1605.08888v1", 
    "title": "Models Coupling Urban Growth and Transportation Network Growth : An   Algorithmic Systematic Review Approach", 
    "arxiv-id": "1605.08888v1", 
    "author": "Juste Raimbault", 
    "publish": "2016-05-28T12:55:49Z", 
    "summary": "A broad bibliographical study suggests a scarcity of quantitative models of\nsimulation integrating both network and urban growth. This absence may be due\nto diverging interests of concerned disciplines, resulting in a lack of\ncommunication. We propose to proceed to an algorithmic systematic review to\ngive quantitative elements of answer to this question. A formal iterative\nalgorithm to retrieve corpuses of references from initial keywords, based on\ntext-mining, is developed and implemented. We study its convergence properties\nand do a sensitivity analysis. We then apply it on queries representative of\nthe specific question, for which results tend to confirm the assumption of\ndisciplines compartmentalisation."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-016-2194-9", 
    "link": "http://arxiv.org/pdf/1606.00153v1", 
    "title": "SSH & the City. A Network Approach for Tracing the Societal Contribution   of the Social Sciences and Humanities for Local Development", 
    "arxiv-id": "1606.00153v1", 
    "author": "Ismael Rafols", 
    "publish": "2016-06-01T07:50:45Z", 
    "summary": "Current evaluation frameworks in research policy were designed to address: 1)\nlife and natural sciences, 2) global research communities, and; 3) scientific\nimpact. This is problematic, as they do not adapt well to SSH scholarship, to\nlocal interests, or to consider broader societal impacts. This paper discusses\nthree different evaluation frameworks and proposes a methodology to\noperationalize them and capture societal interactions between social sciences\nand humanities (SSH) researchers and their local context. Here we propose a\nnetwork approach for identifying societal contributions in local contexts. The\ngoal of this approach is not to develop indicators for benchmarking, but to map\ninteractions for strategic assessment. The absolute 'value' or 'weight' of the\ninteractions cannot be captured, but we hope the method can identify the hot\nspots where they are taking place."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-016-2194-9", 
    "link": "http://arxiv.org/pdf/1606.00155v1", 
    "title": "Tracing scientific mobility of Early Career Researchers in Spain and The   Netherlands through their publications", 
    "arxiv-id": "1606.00155v1", 
    "author": "Rodrigo Costas", 
    "publish": "2016-06-01T08:03:07Z", 
    "summary": "International scientific mobility is acknowledged to be a key mechanism for\nthe diffusion of knowledge, particularly tacit or 'sticky' knowledge that\ncannot be transferred without geographical proximity and personal contact, for\nthe incorporation of young researchers into elite transnational scientific\nnetworks, and for accessing additional resources or infrastructures that are\nessential to the research process but located in other places. The inadequacy\nand lack of appropriate data to assess the phenomenon of researcher mobility\nhas been repeatedly pointed out by scholars and policy makers. This paper\npresents an exploratory analysis of different typologies of researchers\naccording to their traceable mobility using scientific publications covered in\nthe Web of Science (WoS). We compare two populations of researchers, of the\nsame 'scientific age', based in Spain and The Netherlands. We observe\ndifferences in the degree of mobility of Spain and Netherlands based\nresearchers. Factors associated with the different institutional conditions\ncharacterizing the two national systems need to be taken into account. First,\nthe Spanish and Dutch university and research systems are different in many\nways. Second, there may be very different institutional incentives for mobility\nin the two systems. More sophisticated bibliometric analyses and comparisons\nwith different 'generations' of researchers, possibly combined with qualitative\ninvestigation, will be required to better understand the role and function of\nnational institutional context in both research mobility and research careers."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.12.009", 
    "link": "http://arxiv.org/pdf/1606.00193v1", 
    "title": "Not dead, just resting: The practical value of per publication citation   indicators", 
    "arxiv-id": "1606.00193v1", 
    "author": "Mike Thelwall", 
    "publish": "2016-06-01T09:43:36Z", 
    "summary": "In the final analysis citation-based indicators are inferior to effective\npeer review and even peer review is flawed. It is impossible to accurately\nmeasure the value or impact of scientific research and a key task of\nscientometricians should be to produce figures for policy makers and others\nthat are as informative as it is practical to make them and to ensure that\nusers are fully aware of their limitations. Although the Abramo and D'Angelo\n(2016) suggestions make a lot of theoretical sense and so are a goal that is\nworth aiming for, it is unrealistic in practice to advocate their universal use\nin the contexts discussed above. This is because the indicators would still\nhave flaws in addition to the generic limitations of citation-based indicators\nand would still be inadequate for replacing peer review. Thus, the expense of\nthe data gathering does not always justify the value in practice of the extra\naccuracy. In the longer term, the restructuring of education needed in order to\nget the homogeneity necessary for genuinely comparable statistics would be too\nexpensive and probably damaging to the research mission, in addition to being\nout of proportion to the likely value of any citation-based indicator."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.12.009", 
    "link": "http://arxiv.org/pdf/1606.00232v1", 
    "title": "Can we use altmetrics at the institutional level? A case study analysing   the coverage by research areas of four Spanish universities", 
    "arxiv-id": "1606.00232v1", 
    "author": "Evaristo Jim\u00e9nez-Contreras", 
    "publish": "2016-06-01T11:26:19Z", 
    "summary": "Social media based indicators or altmetrics have been under scrutiny for the\nlast seven years. Their promise as alternative metrics for measuring scholarly\nimpact is still far from becoming a reality. Up to now, most studies have\nfocused on the understanding of the nature and relation of altmetric indicators\nwith citation data. Few papers have analysed research profiles based on\naltmetric data. Most of these have related to researcher profiles and the\nexpansion of these tools among researchers. This paper aims at exploring the\ncoverage of the Altmetric.com database and its potential use in order to show\nuniversities' research profiles in relationship with other databases. We\nanalyse a sample of four different Spanish universities.First, we observe a low\ncoverage of altmetric indicators with only 36 percent of all documents\nretrieved from the Web of Science having an 'altmetric' score. Second, we\nobserve that for the four universities analysed, the area of Science shows\nhigher 'altmetric' scores that the rest of the research areas. Finally,\nconsidering the low coverage of altmetric data at the institutional level, it\ncould be interesting for research policy makers to consider the development of\nguidelines and best practices guides to ensure that researchers disseminate\nadequately their research findings through social media."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.12.009", 
    "link": "http://arxiv.org/pdf/1606.00240v1", 
    "title": "Using network centrality measures to improve national journal   classification lists", 
    "arxiv-id": "1606.00240v1", 
    "author": "Daniel Torres-Salinas", 
    "publish": "2016-06-01T11:45:02Z", 
    "summary": "In countries like Denmark and Spain classified journal lists are now being\nproduced and used in the calculation of nationwide performance indicators. As a\nresult, Danish and Spanish scholars are advised to contribute to journals of\nhigh 'authority' (as in the former) or those within a high class (as in the\nlatter). This can create a few problems. The aim of this paper is to analyse\nthe potential use of network centrality measures to identify possible\nmismatches of journal categories. It analysis the Danish National Authority\nList and the Spanish CIRC Classification. Based on a sample of Library and\nInformation Science publications, it analyses centrality measures that can\nassess on the importance of journals to given fields, correcting mismatches in\nthese classifications. We conclude by emphasising the use of these measures to\nbetter calibrate journal classifications as we observe a general bias in these\nlists towards older journals. Centrality measures can allow to identify\nperiphery-to-core journals' transitions."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.12.009", 
    "link": "http://arxiv.org/pdf/1606.03857v1", 
    "title": "Evaluating Co-Authorship Networks in Author Name Disambiguation for   Common Names", 
    "arxiv-id": "1606.03857v1", 
    "author": "Philipp Mayr", 
    "publish": "2016-06-13T08:38:01Z", 
    "summary": "With the increasing size of digital libraries it has become a challenge to\nidentify author names correctly. The situation becomes more critical when\ndifferent persons share the same name (homonym problem) or when the names of\nauthors are presented in several different ways (synonym problem). This paper\nfocuses on homonym names in the computer science bibliography DBLP. The goal of\nthis study is to evaluate a method which uses co-authorship networks and\nanalyze the effect of common names on it. For this purpose we clustered the\npublications of authors with the same name and measured the effectiveness of\nthe method against a gold standard of manually assigned DBLP records. The\nresults show that despite the good performance of implemented method for most\nnames, we should optimize for common names. Hence community detection was\nemployed to optimize the method. Results prove that the applied method improves\nthe performance for these names."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2015.12.009", 
    "link": "http://arxiv.org/pdf/1606.05157v2", 
    "title": "Automatic quality evaluation and (semi-) automatic improvement of OCR   models for historical printings", 
    "arxiv-id": "1606.05157v2", 
    "author": "K. U. Schulz", 
    "publish": "2016-06-16T12:15:14Z", 
    "summary": "Good OCR results for historical printings rely on the availability of\nrecognition models trained on diplomatic transcriptions as ground truth, which\nis both a scarce resource and time-consuming to generate. Instead of having to\ntrain a separate model for each historical typeface, we propose a strategy to\nstart from models trained on a combined set of available transcriptions in a\nvariety of fonts. These \\emph{mixed models} result in character accuracy rates\nover 90\\% on a test set of printings from the same period of time, but without\nany representation in the training data, demonstrating the possibility to\novercome the typography barrier by generalizing from a few typefaces to a\nlarger set of (similar) fonts in use over a period of time. The output of these\nmixed models is then used as a baseline to be further improved by both fully\nautomatic methods and semi-automatic methods involving a minimal amount of\nmanual transcriptions. In order to evaluate the recognition quality of each\nmodel in a series of models generated during the training process in the\nabsence of any ground truth, we introduce two readily observable quantities\nthat correlate well with true accuracy. These quantities are \\emph{mean\ncharacter confidence C} (as given by the OCR engine OCRopus) and \\emph{mean\ntoken lexicality L} (a distance measure of OCR tokens from modern wordforms\ntaking historical spelling patterns into account, which can be calculated for\nany OCR engine). Whereas the fully automatic method is able to improve upon the\nresult of a mixed model by only 1-2 percentage points, already 100-200\nhand-corrected lines lead to much better OCR results with character error rates\nof only a few percent. This procedure minimizes the amount of ground truth\nproduction and does not depend on the previous construction of a specific\ntypographic model."
},{
    "category": "cs.DL", 
    "doi": "10.13140/RG.2.1.4504.9681", 
    "link": "http://arxiv.org/pdf/1606.05341v1", 
    "title": "Proceedings Scholar Metrics: H Index of proceedings on Computer Science,   Electrical & Electronic Engineering, and Communications according to Google   Scholar Metrics (2010-2014)", 
    "arxiv-id": "1606.05341v1", 
    "author": "Emilio Delgado L\u00f3pez-C\u00f3zar", 
    "publish": "2016-06-17T12:12:47Z", 
    "summary": "The objective of this report is to present a list of proceedings\n(conferences, workshops, symposia, meetings) in the areas of Computer Science,\nElectrical & Electronic Engineering, and Communications covered by Google\nScholar Metrics and ranked according to their h-index. Google Scholar Metrics\nonly displays publications that have published at least 100 papers and have\nreceived at least one citation in the last five years (2010-2014). The searches\nwere conducted between the 8th and 10th of December, 2015. A total of 1501\nproceedings have been identified"
},{
    "category": "cs.DL", 
    "doi": "10.1145/2934732.2934748", 
    "link": "http://arxiv.org/pdf/1606.05609v1", 
    "title": "Research on Wikipedia Vandalism: a brief literature review", 
    "arxiv-id": "1606.05609v1", 
    "author": "Ana I. S\u00e1nchez-Casab\u00f3n", 
    "publish": "2016-06-17T17:50:55Z", 
    "summary": "Research on vandalism in Wikipedia has been of interest for the last decade.\nThis paper performs a literature review on the subject, with the goal of\nidentifying the main research topics and approaches, methods and techniques\nused. 67 papers have been reviewed. Main topic is the detection of vandalism,\nalthough there is a increasing interest about content quality. The most\ncommonly used technique is machine learning, based on feature analysis. It\ndraws attention to the lack of research on information behavior of vandals."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2934732.2934748", 
    "link": "http://arxiv.org/pdf/1606.05741v3", 
    "title": "Connecting web-based mapping services with scientific data repositories:   collaborative curation and retrieval of simulation data via a geospatial   interface", 
    "arxiv-id": "1606.05741v3", 
    "author": "Alexandros Avdis", 
    "publish": "2016-06-18T11:46:10Z", 
    "summary": "Increasing quantities of scientific data are becoming readily accessible via\nonline repositories such as those provided by Figshare and Zenodo.\nGeoscientific simulations in particular generate large quantities of data, with\nseveral research groups studying many, often overlapping areas of the world.\nWhen studying a particular area, being able to keep track of one's own\nsimulations as well as those of collaborators can be challenging. This paper\ndescribes the design, implementation, and evaluation of a new tool for visually\ncataloguing and retrieving data associated with a given geographical location\nthrough a web-based Google Maps interface. Each data repository is pin-pointed\non the map with a marker based on the geographical location that the dataset\ncorresponds to. By clicking on the markers, users can quickly inspect the\nmetadata of the repositories and download the associated data files. The crux\nof the approach lies in the ability to easily query and retrieve data from\nmultiple sources via a common interface. While many advances are being made in\nterms of scientific data repositories, the development of this new tool has\nuncovered several issues and limitations of the current state-of-the-art which\nare discussed herein, along with some ideas for the future."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2934732.2934748", 
    "link": "http://arxiv.org/pdf/1606.05752v1", 
    "title": "Identifying the Academic Rising Stars", 
    "arxiv-id": "1606.05752v1", 
    "author": "Tao Zhou", 
    "publish": "2016-06-18T14:01:55Z", 
    "summary": "Predicting the fast-rising young researchers (Academic Rising Stars) in the\nfuture provides useful guidance to the research community, e.g., offering\ncompetitive candidates to university for young faculty hiring as they are\nexpected to have success academic careers. In this work, given a set of young\nresearchers who have published the first first-author paper recently, we solve\nthe problem of how to effectively predict the top k% researchers who achieve\nthe highest citation increment in \\Delta t years. We explore a series of\nfactors that can drive an author to be fast-rising and design a novel impact\nincrement ranking learning (IIRL) algorithm that leverages those factors to\npredict the academic rising stars. Experimental results on the large ArnetMiner\ndataset with over 1.7 million authors demonstrate the effectiveness of IIRL.\nSpecifically, it outperforms all given benchmark methods, with over 8% average\nimprovement. Further analysis demonstrates that the prediction models for\ndifferent research topics follow the similar pattern. We also find that\ntemporal features are the best indicators for rising stars prediction, while\nvenue features are less relevant."
},{
    "category": "cs.DL", 
    "doi": "10.1109/TBDATA.2016.2521657", 
    "link": "http://arxiv.org/pdf/1606.05905v1", 
    "title": "Can Scientific Impact Be Predicted?", 
    "arxiv-id": "1606.05905v1", 
    "author": "Nitesh V. Chawla", 
    "publish": "2016-06-19T19:39:49Z", 
    "summary": "A widely used measure of scientific impact is citations. However, due to\ntheir heavy-tailed distribution, citations are fundamentally difficult to\npredict. Instead, to characterize scientific impact, we address two analogous\nquestions asked by many scientific researchers: \"How will my h-index evolve\nover time, and which of my previously or newly published papers will contribute\nto it?\" To answer these questions, we perform two related tasks. First, we\ndevelop a model to predict authors' future h-indices based on their current\nscientific impact. Second, we examine the factors that drive papers---either\npreviously or newly published---to increase their authors' predicted future\nh-indices. By leveraging relevant factors, we can predict an author's h-index\nin five years with an R2 value of 0.92 and whether a previously (newly)\npublished paper will contribute to this future h-index with an F1 score of 0.99\n(0.77). We find that topical authority and publication venue are crucial to\nthese effective predictions, while topic popularity is surprisingly\ninconsequential. Further, we develop an online tool that allows users to\ngenerate informed h-index predictions. Our work demonstrates the predictability\nof scientific impact, and can help scholars to effectively leverage their\nposition of \"standing on the shoulders of giants.\""
},{
    "category": "cs.DL", 
    "doi": "10.1145/2910896.2910899", 
    "link": "http://arxiv.org/pdf/1606.09136v1", 
    "title": "Routing Memento Requests Using Binary Classifiers", 
    "arxiv-id": "1606.09136v1", 
    "author": "Herbert Van de Sompel", 
    "publish": "2016-06-29T14:54:43Z", 
    "summary": "The Memento protocol provides a uniform approach to query individual web\narchives. Soon after its emergence, Memento Aggregator infrastructure was\nintroduced that supports querying across multiple archives simultaneously. An\nAggregator generates a response by issuing the respective Memento request\nagainst each of the distributed archives it covers. As the number of archives\ngrows, it becomes increasingly challenging to deliver aggregate responses while\nkeeping response times and computational costs under control. Ad-hoc heuristic\napproaches have been introduced to address this challenge and research has been\nconducted aimed at optimizing query routing based on archive profiles. In this\npaper, we explore the use of binary, archive-specific classifiers generated on\nthe basis of the content cached by an Aggregator, to determine whether or not\nto query an archive for a given URI. Our results turn out to be readily\napplicable and can help to significantly decrease both the number of requests\nand the overall response times without compromising on recall. We find, among\nothers, that classifiers can reduce the average number of requests by 77%\ncompared to a brute force approach on all archives, and the overall response\ntime by 42% while maintaining a recall of 0.847."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2910896.2910899", 
    "link": "http://arxiv.org/pdf/1607.01266v2", 
    "title": "New features of CitedReferencesExplorer (CRExplorer)", 
    "arxiv-id": "1607.01266v2", 
    "author": "Lutz Bornmann", 
    "publish": "2016-07-05T14:26:54Z", 
    "summary": "CRExplorer version 1.6.7 was released on July 5, 2016. This version includes\nthe following new features and improvements: Scopus: Using \"File\" - \"Import\" -\n\"Scopus\", CRExplorer reads files from Scopus. The file format \"CSV\" (including\ncitations, abstracts and references) should be chosen in Scopus for downloading\nrecords. Export facilities: Using \"File\" - \"Export\" - \"Scopus\", CRExplorer\nexports files in the Scopus format. Using \"File\" - \"Export\" - \"Web of Science\",\nCRExplorer exports files in the Web of Science format. These files can be\nimported in other bibliometric programs (e.g. VOSviewer). Space bar: Select a\nspecific cited reference in the cited references table, press the space bar,\nand all bibliographic details of the CR are shown. Internal file format: Using\n\"File\" - \"Save\", working files are saved in the internal file format \"*.cre\".\nThe files include all data including matching results and manual matching\ncorrections. The files can be opened by using \"File\" - \"Open\"."
},{
    "category": "cs.DL", 
    "doi": "10.3989/redc.2016.4.1405", 
    "link": "http://arxiv.org/pdf/1607.02861v1", 
    "title": "A two-sided academic landscape: portrait of highly-cited documents in   Google Scholar (1950-2013)", 
    "arxiv-id": "1607.02861v1", 
    "author": "Emilio Delgado Lopez-Cozar", 
    "publish": "2016-07-11T08:47:41Z", 
    "summary": "The main objective of this paper is to identify the set of highly-cited\ndocuments in Google Scholar and to define their core characteristics (document\ntypes, language, free availability, source providers, and number of versions),\nunder the hypothesis that the wide coverage of this search engine may provide a\ndifferent portrait about this document set respect to that offered by the\ntraditional bibliographic databases. To do this, a query per year was carried\nout from 1950 to 2013 identifying the top 1,000 documents retrieved from Google\nScholar and obtaining a final sample of 64,000 documents, of which 40% provided\na free full-text link. The results obtained show that the average highly-cited\ndocument is a journal article or a book (62% of the top 1% most cited documents\nof the sample), written in English (92.5% of all documents) and available\nonline in PDF format (86.0% of all documents). Yet, the existence of errors\nespecially when detecting duplicates and linking cites properly must be pointed\nout. The fact of managing with highly cited papers, however, minimizes the\neffects of these limitations. Given the high presence of books, and to a lesser\nextend of other document types (such as proceedings or reports), the research\nconcludes that Google Scholar data offer an original and different vision of\nthe most influential academic documents (measured from the perspective of their\ncitation count), a set composed not only by strictly scientific material\n(journal articles) but academic in its broad sense"
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.07.006", 
    "link": "http://arxiv.org/pdf/1607.04125v1", 
    "title": "Citation count distributions for large monodisciplinary journals", 
    "arxiv-id": "1607.04125v1", 
    "author": "Mike Thelwall", 
    "publish": "2016-07-14T13:36:55Z", 
    "summary": "Many different citation-based indicators are used by researchers and research\nevaluators to help evaluate the impact of scholarly outputs. Although the\nappropriateness of individual citation indicators depends in part on the\nstatistical properties of citation counts, there is no universally agreed\nbest-fitting statistical distribution against which to check them. The two\ncurrent leading candidates are the discretised lognormal and the hooked or\nshifted power law. These have been mainly tested on sets of articles from a\nsingle field and year but these collections can include multiple specialisms\nthat might dilute their properties. This article fits statistical distributions\nto 50 large subject-specific journals in the belief that individual journals\ncan be purer than subject categories and may therefore give clearer findings.\nThe results show that in most cases the discretised lognormal fits\nsignificantly better than the hooked power law, reversing previous findings for\nentire subcategories. This suggests that the discretised lognormal is the more\nappropriate distribution for modelling pure citation data. Thus future\nanalytical investigations of the properties of citation indicators can use the\nlognormal distribution to analyse their basic properties. This article also\nincludes improved software for fitting the hooked power law."
},{
    "category": "cs.DL", 
    "doi": "10.13140/RG.2.1.1496.4724", 
    "link": "http://arxiv.org/pdf/1607.06260v1", 
    "title": "2016 Google Scholar Metrics released: a matter of languages... and   something else", 
    "arxiv-id": "1607.06260v1", 
    "author": "Emilio Delgado L\u00f3pez-C\u00f3zar", 
    "publish": "2016-07-21T10:50:02Z", 
    "summary": "The 2016 edition of Google Scholar Metrics was released on July 15th 2016.\nThere haven't been any structural changes respect to previous versions, which\nmeans that most of its limitations still persist. The biggest changes are the\naddition of five new language rankings (Russian, Korean, Polish, Ukrainian, and\nIndonesian) and elimination of two other language rankings (Italian and Dutch).\nIn addition, for reasons still unknown, this new edition doesn't include as\nmany working paper and discussion paper series as previous editions."
},{
    "category": "cs.DL", 
    "doi": "10.13140/RG.2.1.1496.4724", 
    "link": "http://arxiv.org/pdf/1607.06263v2", 
    "title": "Cited References and Medical Subject Headings (MeSH) as Two Different   Knowledge Representations: Clustering and Mappings at the Paper Level", 
    "arxiv-id": "1607.06263v2", 
    "author": "Iina Hellsten", 
    "publish": "2016-07-21T10:55:26Z", 
    "summary": "For the biomedical sciences, the Medical Subject Headings (MeSH) make\navailable a rich feature which cannot currently be merged properly with widely\nused citing/cited data. Here, we provide methods and routines that make MeSH\nterms amenable to broader usage in the study of science indicators: using\nWeb-of-Science (WoS) data, one can generate the matrix of citing versus cited\ndocuments; using PubMed/MEDLINE data, a matrix of the citing documents versus\nMeSH terms can be generated analogously. The two matrices can also be\nreorganized into a 2-mode matrix of MeSH terms versus cited references. Using\nthe abbreviated journal names in the references, one can, for example, address\nthe question whether MeSH terms can be used as an alternative to WoS Subject\nCategories for the purpose of normalizing citation data. We explore the\napplicability of the routines in the case of a research program about the\namyloid cascade hypothesis in Alzheimer's disease (AD). One conclusion is that\nreferenced journals provide archival structures, whereas MeSH terms indicate\nmainly variation (including novelty) at the research front. Furthermore, we\nexplore the option of using the citing/cited matrix for main-path analysis as a\nby-product of the software."
},{
    "category": "cs.DL", 
    "doi": "10.13140/RG.2.1.1496.4724", 
    "link": "http://arxiv.org/pdf/1607.07765v3", 
    "title": "Rightsstatements.org White Paper: Requirements for the Technical   Infrastructure for Standardized International Rights Statements", 
    "arxiv-id": "1607.07765v3", 
    "author": "Maarten Zeinstra", 
    "publish": "2015-12-01T05:07:59Z", 
    "summary": "This document is part of the deliverables created by the International Rights\nStatement Working Group, a joint working group of the Digital Public Library of\nAmerica (DPLA) and Europeana. It provides the technical requirements for\nimplementation of the Standardized International Rights Statements. These\nrequirements are based on the principles and specifications found in the\nnormative Recommendations for Standardized International Rights Statements.\nThis document replaces and supersedes the previously released Recommendations\nfor the Technical Infrastructure for Standardized Rights Statements, released\nby this working group. The Requirements for the Technical Infrastructure for\nStandardized International Rights Statements describes the expected behaviours\nfor a service that enables the delivery of human and machine-readable\nrepresentations of the rights statements. It documents the fundamental\ndecisions that informed the development of a data model grounded in Linked Data\napproaches. This document also provides proposed implementation guidelines and\na non-normative set of examples for incorporating rights statements into\nprovider metadata."
},{
    "category": "cs.DL", 
    "doi": "10.13140/RG.2.1.1496.4724", 
    "link": "http://arxiv.org/pdf/1607.08212v1", 
    "title": "arXiv@25: Key findings of a user survey", 
    "arxiv-id": "1607.08212v1", 
    "author": "Deborah Cooper", 
    "publish": "2016-07-27T18:43:57Z", 
    "summary": "As part of its 25th anniversary vision-setting process, the arXiv team at\nCornell University Library conducted a user survey in April 2016 to seek input\nfrom the global user community about arXiv's current services and future\ndirections. We were heartened to receive 36,000 responses from 127 countries,\nrepresenting arXiv's diverse, global community. The prevailing message is that\nusers are happy with the service as it currently stands, with 95 percent of\nsurvey respondents indicating they are very satisfied or satisfied with arXiv.\nFurthermore, 72 percent of respondents indicated that arXiv should continue to\nfocus on its main purpose, which is to quickly make available scientific\npapers, and this will be enough to sustain the value of arXiv in the future.\nThis theme was pervasively reflected in the open text comments; a significant\nnumber of respondents suggested remaining focused on the core mission and\nenabling arXiv's partners and related service providers to continue to build\nnew services and innovations on top of arXiv."
},{
    "category": "cs.DL", 
    "doi": "10.1186/s12967-015-0496-y", 
    "link": "http://arxiv.org/pdf/1607.08479v1", 
    "title": "Hegemonic structure of basic, clinical and patented knowledge on Ebola   research: a US army reductionist initiative", 
    "arxiv-id": "1607.08479v1", 
    "author": "Victor-M Castano", 
    "publish": "2016-04-12T05:48:07Z", 
    "summary": "Background: In this paper, we present an approach to understand how the\nbasic, clinical and patent knowledge on Ebola is organized and\nintercommunicated and what leading factor could be shaping the evolution of the\nknowledge translation process for this disease. Methodology: A combination of\ncitation network analysis; analysis of Medical heading Subject (MeSH) and Gene\nOntology (GO) terms, and quantitative content analysis for patents and\nscientific literature, aimed to map the organization of Ebola research was\ncarried out. Results: We found six putative research fronts (i.e. clusters of\nhigh interconnected papers). Three research fronts are basic research on Ebola\nvirus structural proteins: glycoprotein, VP40 and VP35, respectively. There is\na fourth research front of basic research papers on pathogenesis, which is the\norganizing hub of Ebola research. A fifth research front is pre-clinical\nresearch focused on vaccines and glycoproteins. Finally, a\nclinical-epidemiology research front related to the disease outbreaks was\nidentified. The network structure of patent families shows that the dominant\ndesign is the use of Ebola virus proteins as targets of vaccines and other\nimmunological treatments. Therefore, patents network organization resembles the\norganization of the scientific literature. Specifically, the knowledge on Ebola\nwould flow from higher (clinical-epidemiology) to intermediated\n(cellular-tissular pathogenesis) to lower (molecular interactions) levels of\norganization. Conclusion: Our results suggest a strong reductionist approach\nfor Ebola research probably influenced by the lethality of the disease. On the\nother hand, the ownership profile of the patent families network and the main\nresearches relationship with the United State Army suggest a strong involvement\nof this military institution in Ebola research."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-016-2086-z", 
    "link": "http://arxiv.org/pdf/1608.00798v1", 
    "title": "Tracking the Digital Footprints to Scholarly Articles from Social Media", 
    "arxiv-id": "1608.00798v1", 
    "author": "Xinhui Guo", 
    "publish": "2016-08-02T12:59:31Z", 
    "summary": "Scholarly articles are discussed and shared on social media, which generates\naltmetrics. On the opposite side, what is the impact of social media on the\ndissemination of scholarly articles and how to measure it? What are the\nvisiting patterns? Investigating these issues, the purpose of this study is to\nseek a solution to fill the research gap, specifically, to explore the dynamic\nvisiting patterns directed by social media, and examine the effects of social\nbuzz on the article visits. Using the unique real referral data of 110\nscholarly articles, which are daily updated in a 90-day period, this paper\nproposes a novel method to make analysis. We find that visits from social media\nare fast to accumulate but decay rapidly. Twitter and Facebook are the two most\nimportant social referrals that directing people to scholarly articles, the two\nare about the same and account for over 95% of the total social referral\ndirected visits. There is synchronism between tweets and tweets resulted\nvisits. Social media and open access are playing important roles in\ndisseminating scholarly articles and promoting public understanding science,\nwhich are confirmed quantitatively for the first time with real data in this\nstudy."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-016-2086-z", 
    "link": "http://arxiv.org/pdf/1608.06079v1", 
    "title": "A novel framework for assessing metadata quality in epidemiological and   public health research settings", 
    "arxiv-id": "1608.06079v1", 
    "author": "Spiros Denaxas", 
    "publish": "2016-08-22T08:27:24Z", 
    "summary": "Metadata are critical in epidemiological and public health research. However,\na lack of biomedical metadata quality frameworks and limited awareness of the\nimplications of poor quality metadata renders data analyses problematic. In\nthis study, we created and evaluated a novel framework to assess metadata\nquality of epidemiological and public health research datasets. We performed a\nliterature review and surveyed stakeholders to enhance our understanding of\nbiomedical metadata quality assessment. The review identified 11 studies and\nnine quality dimensions; none of which were specifically aimed at biomedical\nmetadata. 96 individuals completed the survey; of those who submitted data,\nmost only assessed metadata quality sometimes, and eight did not at all. Our\nframework has four sections: a) general information; b) tools and technologies;\nc) usability; and d) management and curation. We evaluated the framework using\nthree test cases and sought expert feedback. The framework can assess\nbiomedical metadata quality systematically and robustly."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-016-2086-z", 
    "link": "http://arxiv.org/pdf/1608.08112v1", 
    "title": "Scholarly use of social media and altmetrics: a review of the literature", 
    "arxiv-id": "1608.08112v1", 
    "author": "Stefanie Haustein", 
    "publish": "2016-08-29T15:45:35Z", 
    "summary": "Social media has become integrated into the fabric of the scholarly\ncommunication system in fundamental ways: principally through scholarly use of\nsocial media platforms and the promotion of new indicators on the basis of\ninteractions with these platforms. Research and scholarship in this area has\naccelerated since the coining and subsequent advocacy for altmetrics -- that\nis, research indicators based on social media activity. This review provides an\nextensive account of the state-of-the art in both scholarly use of social media\nand altmetrics. The review consists of two main parts: the first examines the\nuse of social media in academia, examining the various functions these\nplatforms have in the scholarly communication process and the factors that\naffect this use. The second part reviews empirical studies of altmetrics,\ndiscussing the various interpretations of altmetrics, data collection and\nmethodological limitations, and differences according to platform. The review\nends with a critical discussion of the implications of this transformation in\nthe scholarly communication system."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-016-2086-z", 
    "link": "http://arxiv.org/pdf/1609.01537v1", 
    "title": "Public scientists contributing to local literary fiction. An exploratory   analysis", 
    "arxiv-id": "1609.01537v1", 
    "author": "Nicolas Robinson-Garcia", 
    "publish": "2016-09-05T10:20:39Z", 
    "summary": "Public scientists (scientists only from now onwards), understood as a member\nof the teaching and/or research staff of a public university or a public\nresearch organization (including humanities and social sciences), benefit the\nacademic community, industry and other social collectives through teaching and\nresearch. Active involvement of scientists in culture is part of the richness\nof developed societies. Some voices in current debates on the evaluation of\nsocietal impact and the role of universities towards social development are\nclaiming a refocus from a socioeconomic perspective to also including\nsociocultural benefits from academiaIn this paper we will focus in one facet of\ncultural engagement; writing literary fiction. We will narrow our general\nobjective to local activities, due to the interest in the engagement of\nscientist on this geographic dimension. Do local publishers include the\nliterary work of scientists? Are works written by scientists more likely to be\nlocal than works not written by scientists?"
},{
    "category": "cs.DL", 
    "doi": "10.6017/ital.v35i2.8749", 
    "link": "http://arxiv.org/pdf/1609.02004v1", 
    "title": "In the Name of the Name: RDF literals, ER Attributes and the Potential   to Rethink the Structures and Visualizations of Catalogs", 
    "arxiv-id": "1609.02004v1", 
    "author": "Manolis Peponakis", 
    "publish": "2016-09-07T14:47:37Z", 
    "summary": "The aim of this study is to contribute to the field of machine-processable\nbibliographic data that is suitable for the Semantic Web. We examine the Entity\nRelationship (ER) model, which has been selected by IFLA as a \"conceptual\nframework\" in order to model the FR family (FRBR, FRAD, and RDA), and the\nproblems ER causes as we move towards the Semantic Web. Subsequently, while\nmaintaining the semantics of the aforementioned standards but rejecting the ER\nas a conceptual framework for bibliographic data, this paper builds on the RDF\n(Resource Description Framework) potential and documents how both the RDF and\nLinked Data's rationale can affect the way we model bibliographic data. In this\nway, a new approach to bibliographic data emerges where the distinction between\ndescription and authorities is obsolete. Instead, the integration of the\nauthorities with descriptive information becomes fundamental so that a network\nof correlations can be established between the entities and the names by which\nthe entities are known. Naming is a vital issue for human cultures because\nnames are not random sequences of characters or sounds that stand just as\nidentifiers for the entities; they also have socio-cultural meanings and\ninterpretations. Thus, instead of describing indivisible resources, we could\ndescribe entities that appear in a variety of names on various resources. In\nthis study, a method is proposed to connect the names with the entities they\nrepresent and, in this way, to document the provenance of these names by\nconnecting specific resources with specific names."
},{
    "category": "cs.DL", 
    "doi": "10.1080/19386389.2013.846618", 
    "link": "http://arxiv.org/pdf/1609.03385v1", 
    "title": "Libraries' Metadata as Data in the Era of the Semantic Web: Modeling a   Repository of Master Theses and PhD Dissertations for the Web of Data", 
    "arxiv-id": "1609.03385v1", 
    "author": "Manolis Peponakis", 
    "publish": "2016-09-12T13:21:44Z", 
    "summary": "This study argues that metadata of library catalogs can stand autonomously,\nproviding valuable information detached from the resources they point to and,\ntherefore, could be used as data in the context of the Semantic Web. We present\nan analysis of this perception followed by an implementation proposal for a\nMaster's thesis and PhD dissertation repository. The analysis builds on the\nflexibility of the Resource Description Framework (RDF) and takes into account\nthe Functional Requirements for Bibliographic Records (FRBR) and Functional\nRequirements for Authority Data (FRAD) in order to reveal the latent academic\nnetwork by linking its entities to a meaningful and computationally processable\nset. Current library catalogs retrieve documents to find answers, whereas in\nour approach catalogs can provide answers that could not be found in any\nspecific document."
},{
    "category": "cs.DL", 
    "doi": "10.1080/19386389.2013.846618", 
    "link": "http://arxiv.org/pdf/1609.04793v3", 
    "title": "Professional and Citizen Bibliometrics: Complementarities and   ambivalences in the development and use of indicators", 
    "arxiv-id": "1609.04793v3", 
    "author": "Lutz Bornmann", 
    "publish": "2016-09-15T19:33:39Z", 
    "summary": "Bibliometric indicators such as journal impact factors, h-indices, and total\ncitation counts are algorithmic artifacts that can be used in research\nevaluation and management. These artifacts have no meaning by themselves, but\nreceive their meaning from attributions in institutional practices. We\ndistinguish four main stakeholders in these practices: (1) producers of\nbibliometric data and indicators; (2) bibliometricians who develop and test\nindicators; (3) research managers who apply the indicators; and (4) the\nscientists being evaluated with potentially competing career interests. These\ndifferent positions may lead to different and sometimes conflicting\nperspectives on the meaning and value of the indicators. The indicators can\nthus be considered as boundary objects which are socially constructed in\ntranslations among these perspectives. This paper proposes an analytical\nclarification by listing an informed set of (sometimes unsolved) problems in\nbibliometrics which can also shed light on the tension between simple but\ninvalid indicators that are widely used (e.g., the h-index) and more\nsophisticated indicators that are not used or cannot be used in evaluation\npractices because they are not transparent for users, cannot be calculated, or\nare difficult to interpret."
},{
    "category": "cs.DL", 
    "doi": "10.1080/19386389.2013.846618", 
    "link": "http://arxiv.org/pdf/1609.04931v2", 
    "title": "Indicators as judgment devices: Citizen bibliometrics in biomedicine and   economics", 
    "arxiv-id": "1609.04931v2", 
    "author": "Alexander D. Rushforth", 
    "publish": "2016-09-16T07:56:17Z", 
    "summary": "The number of publications has been a fundamental merit in the competition\nfor academic positions since the late 18th century. Today, the simple counting\nof publications has been supplemented with a whole range of bibliometric\nmeasures, which supposedly not only measures the volume of research but also\nits impact. In this study, we investigate how bibliometrics are used for\nevaluating the impact and quality of publications in two specific settings:\nbiomedicine and economics. Our study exposes the extent and type of metrics\nused in external evaluations of candidates for academic positions at Swedish\nuniversities. Moreover, we show how different bibliometric indicators, both\nexplicitly and implicitly, are employed to value and rank candidates. Our\nfindings contribute to a further understanding of bibliometric indicators as\njudgment devices that are employed in evaluating individuals and their\npublished works within specific fields. We also show how expertise in using\nbibliometrics for evaluative purposes is negotiated at the interface between\ndomain knowledge and skills in using indicators. In line with these results we\npropose that the use of metrics in this context is best described as a form of\ncitizen bibliometrics - an underspecified term which we build upon in the\npaper."
},{
    "category": "cs.DL", 
    "doi": "10.1080/19386389.2013.846618", 
    "link": "http://arxiv.org/pdf/1609.05354v3", 
    "title": "Citation Analysis with Microsoft Academic", 
    "arxiv-id": "1609.05354v3", 
    "author": "Martin P. Braendle", 
    "publish": "2016-09-17T15:40:49Z", 
    "summary": "We explore if and how Microsoft Academic (MA) could be used for bibliometric\nanalyses. First, we examine the Academic Knowledge API (AK API), an interface\nto access MA data, and compare it to Google Scholar (GS). Second, we perform a\ncomparative citation analysis of researchers by normalizing data from MA and\nScopus. We find that MA offers structured and rich metadata, which facilitates\ndata retrieval, handling and processing. In addition, the AK API allows\nretrieving frequency distributions of citations. We consider these features to\nbe a major advantage of MA over GS. However, we identify four main limitations\nregarding the available metadata. First, MA does not provide the document type\nof a publication. Second, the 'fields of study' are dynamic, too specific and\nfield hierarchies are incoherent. Third, some publications are assigned to\nincorrect years. Fourth, the metadata of some publications did not include all\nauthors. Nevertheless, we show that an average-based indicator (i.e. the\njournal normalized citation score; JNCS) as well as a distribution-based\nindicator (i.e. percentile rank classes; PR classes) can be calculated with\nrelative ease using MA. Hence, normalization of citation counts is feasible\nwith MA. The citation analyses in MA and Scopus yield uniform results. The JNCS\nand the PR classes are similar in both databases, and, as a consequence, the\nevaluation of the researchers' publication impact is congruent in MA and\nScopus. Given the fast development in the last year, we postulate that MA has\nthe potential to be used for full-fledged bibliometric analyses."
},{
    "category": "cs.DL", 
    "doi": "10.1080/19386389.2013.846618", 
    "link": "http://arxiv.org/pdf/1609.05545v1", 
    "title": "Patterns of authors contribution in scientific manuscripts", 
    "arxiv-id": "1609.05545v1", 
    "author": "Diego R. Amancio", 
    "publish": "2016-09-18T20:44:02Z", 
    "summary": "Science is becoming increasingly more interdisciplinary, giving rise to more\ndiversity in the areas of expertise within research labs and groups. This also\nhave brought changes to the role researchers in scientific works. As a\nconsequence, multi-authored scientific papers have now became a norm for high\nquality research. Unfortunately, such a phenomenon induces bias to existing\nmetrics employed to evaluate the productivity and success of researchers. While\nsome metrics were adapted to account for the rank of authors in a paper, many\njournals are now requiring a description of the specific roles of each author\nin a publication. Surprisingly, the investigation of the relationship between\nthe rank of authors and their contributions has been limited to a few studies.\nBy analyzing such kind of data, here we show, quantitatively, that the\nregularity in the authorship contributions decreases with the number of authors\nin a paper. Furthermore, we found that the rank of authors and their roles in\npapers follows three general patterns according to the nature of their\ncontributions, such as writing, data analysis, and the conduction of\nexperiments. This was accomplished by collecting and analyzing the data\nretrieved from PLoS ONE and by devising an entropy-based measurement to\nquantify the effective number of authors in a paper according to their\ncontributions. The analysis of such patterns confirms that some aspects of the\nauthor ranking are in accordance with the expected convention, such as the fact\nthat the first and last authors are more likely to contribute more in a\nscientific work. Conversely, such analysis also revealed that authors in the\nintermediary positions of the rank contribute more in certain specific roles,\nsuch as the task of collecting data. This indicates that the an unbiased\nevaluation of researchers must take into account the distinct types of\nscientific contributions."
},{
    "category": "cs.DL", 
    "doi": "10.1080/19386389.2013.846618", 
    "link": "http://arxiv.org/pdf/1609.06499v2", 
    "title": "Towards a global scientific brain: Indicators of researcher mobility   using co-affiliation data", 
    "arxiv-id": "1609.06499v2", 
    "author": "Rodrigo Costas", 
    "publish": "2016-09-21T11:16:23Z", 
    "summary": "This paper analyses the potential use of bibliometric data for mapping and\napplying network analysis to mobility flows. We show case mobility networks at\nthree different levels of aggregation: at the country level, at the city level\nand at the institutional level. We reflect on the potential uses of\nbibliometric data to inform research policies with regard to scientific\nmobility."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-016-2132-x", 
    "link": "http://arxiv.org/pdf/1609.07171v1", 
    "title": "Measuring the match between evaluators and evaluees: Cognitive distances   between panel members and research groups at the journal level", 
    "arxiv-id": "1609.07171v1", 
    "author": "Tim C. E. Engels", 
    "publish": "2016-09-22T21:31:11Z", 
    "summary": "When research groups are evaluated by an expert panel, it is an open question\nhow one can determine the match between panel and research groups. In this\npaper, we outline two quantitative approaches that determine the cognitive\ndistance between evaluators and evaluees, based on the journals they have\npublished in. We use example data from four research evaluations carried out\nbetween 2009 and 2014 at the University of Antwerp.\n  While the barycenter approach is based on a journal map, the\nsimilarity-adapted publication vector (SAPV) approach is based on the full\njournal similarity matrix. Both approaches determine an entity's profile based\non the journals in which it has published. Subsequently, we determine the\nEuclidean distance between the barycenter or SAPV profiles of two entities as\nan indicator of the cognitive distance between them. Using a bootstrapping\napproach, we determine confidence intervals for these distances. As such, the\npresent article constitutes a refinement of a previous proposal that operates\non the level of Web of Science subject categories."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.09.001", 
    "link": "http://arxiv.org/pdf/1609.07975v1", 
    "title": "Corrigendum to \"Is the expertise of evaluation panels congruent with the   research interests of the research groups: a quantitative approach based on   barycenters\" [Journal of Informetrics 9(4) (2015) 704-721]", 
    "arxiv-id": "1609.07975v1", 
    "author": "Tim C. E. Engels", 
    "publish": "2016-09-22T21:08:44Z", 
    "summary": "In Rahman, Guns, Rousseau, and Engels (2015) we described several approaches\nto determine the cognitive distance between two units. One of these approaches\nwas based on what we called barycenters in N dimensions. This note corrects\nthis terminology and introduces the more adequate term 'similarity-adapted\npublication vectors'."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.09.001", 
    "link": "http://arxiv.org/pdf/1610.02547v1", 
    "title": "First version of a categorization of arguments for counting methods for   publication and citation indicators", 
    "arxiv-id": "1610.02547v1", 
    "author": "Marianne Gauffriau", 
    "publish": "2016-10-08T15:39:31Z", 
    "summary": "Due to the increasing number of authors per publication, a change in counting\nmethod for a publication or citation indicator will often change the result of\nthe indicator. Therefore it is important to know why a specific counting method\nhas been applied. I have analyzed arguments for counting methods in a sample of\n13 recent bibliometric studies and compared the result with discussions of\narguments for counting methods in three older studies. Based on the arguments\nin the studies I formed argument categories which were grouped based on the\nunderlying logics of the arguments. It resulted in four groups which can be\nused to describe and discuss how bibliometric studies with publication and\ncitation indicators argue for counting methods. The first group focuses on\narguments related to what an indicator measures, the next group on avoiding\ndouble counting of publications and/or citations, the third on pragmatic\nreasons for the choice of counting method, and the fourth group on an\nindicators influence on the research community or how it is influenced by the\nresearch community."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.09.001", 
    "link": "http://arxiv.org/pdf/1610.03706v1", 
    "title": "Bibliometric Index for Academic Leadership", 
    "arxiv-id": "1610.03706v1", 
    "author": "Ge Wang", 
    "publish": "2016-10-12T13:29:55Z", 
    "summary": "Academic leadership is essential for research innovation and impact. Until\nnow, there has been no dedicated measure of leadership by bibliometrics.\nPopular bibliometric indices are mainly based on academic output, such as the\njournal impact factor and the number of citations. Here we develop an academic\nleadership index based on readily available bibliometric data that is sensitive\nto not only academic output but also research efficiency. Our leadership index\nwas tested in two studies on peer-reviewed journal papers by\nextramurally-funded principal investigators in the field of life sciences from\nChina and the USA, respectively. The leadership performance of these principal\ninvestigators was quantified and compared relative to university rank and other\nfactors. As a validation measure, we show that the highest average leadership\nindex was achieved by principal investigators at top national universities in\nboth countries. More interestingly, our results also indicate that on an\nindividual basis, strong leadership and high efficiency are not necessarily\nassociated with those at top-tier universities nor with the most funding. This\nleadership index may become the basis of a comprehensive merit system,\nfacilitating academic evaluation and resource management."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.09.001", 
    "link": "http://arxiv.org/pdf/1610.03779v3", 
    "title": "Generating Clustered Journal Maps: An Automated System for Hierarchical   Classification", 
    "arxiv-id": "1610.03779v3", 
    "author": "Caroline S. Wagner", 
    "publish": "2016-10-12T16:40:16Z", 
    "summary": "Journal maps and classifications for 11,359 journals listed in the combined\nJournal Citation Reports 2015 of the Science and Social Sciences Citation\nIndexes are provided at http://www.leydesdorff.net/jcr15. A routine using\nVOSviewer for integrating the journal mapping and their hierarchical clustering\nis also made available. In this short communication, we provide background on\nthe journal mapping/clustering and an explanation and instructions about the\nroutine. We compare 2015 journal maps with those for 2014 and show the\ndelineations among fields and subfields to be sensitive to fluctuations. Labels\nfor fields and sub-fields are not provided by the routine, but can be added by\nan analyst for pragmatic or intellectual reasons. The routine provides a means\nfor testing one's assumptions against a baseline without claiming authority,\nclusters of related journals can be visualized to understand communities. The\nroutine is generic and can be used for any 1-mode network."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.09.001", 
    "link": "http://arxiv.org/pdf/1610.05937v1", 
    "title": "Gender differences in scientific collaborations: Women are more   egalitarian than men", 
    "arxiv-id": "1610.05937v1", 
    "author": "J. S. Andrade Jr", 
    "publish": "2016-10-19T09:44:32Z", 
    "summary": "By analyzing a unique dataset of more than 270,000 scientists, we discovered\nsubstantial gender differences in scientific collaborations. While men are more\nlikely to collaborate with other men, women are more egalitarian. This is\nconsistently observed over all fields and regardless of the number of\ncollaborators a scientist has. The only exception is observed in the field of\nengineering, where this gender bias disappears with increasing number of\ncollaborators. We also found that the distribution of the number of\ncollaborators follows a truncated power law with a cut-off that is gender\ndependent and related to the gender differences in the number of published\npapers. Considering interdisciplinary research, our analysis shows that men and\nwomen behave similarly across fields, except in the case of natural sciences,\nwhere women with many collaborators are more likely to have collaborators from\nother fields."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.09.001", 
    "link": "http://arxiv.org/pdf/1610.07061v1", 
    "title": "$C^3$-index: A PageRank based multi-faceted metric for authors'   performance measurement", 
    "arxiv-id": "1610.07061v1", 
    "author": "Tanmoy Chakraborty", 
    "publish": "2016-10-22T14:56:04Z", 
    "summary": "Ranking scientific authors is an important but challenging task, mostly due\nto the dynamic nature of the evolving scientific publications. The basic\nindicators of an author's productivity and impact are still the number of\npublications and the citation count (leading to the popular metrics such as\nh-index, g-index etc.). H-index and its popular variants are mostly effective\nin ranking highly-cited authors, thus fail to resolve ties while ranking\nmedium-cited and low-cited authors who are majority in number. Therefore, these\nmetrics are inefficient to predict the ability of promising young researchers\nat the beginning of their career. In this paper, we propose $C^3$-index that\ncombines the effect of citations and collaborations of an author in a\nsystematic way using a weighted multi-layered network to rank authors. We\nconduct our experiments on a massive publication dataset of Computer Science\nand show that - (i) $C^3$-index is consistent over time, which is one of the\nfundamental characteristics of a ranking metric, (ii) $C^3$-index is as\nefficient as h-index and its variants to rank highly-cited authors, (iii)\n$C^3$-index can act as a conflict resolution metric to break ties in the\nranking of medium-cited and low-cited authors, (iv) $C^3$-index can also be\nused to predict future achievers at the early stage of their career."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.09.001", 
    "link": "http://arxiv.org/pdf/1610.07241v3", 
    "title": "From Ontology to Structured Applied Epistemology", 
    "arxiv-id": "1610.07241v3", 
    "author": "Robert B. Allen", 
    "publish": "2016-10-23T22:30:47Z", 
    "summary": "Developing and organizing new knowledge is a core activity for scholars.\nRecently, ontologies have been introduced as an approach for organizing\nknowledge. However, most ontologies do not readily support the development and\norganization of new knowledge. By comparison, to ontology, epistemology is the\nstudy of what can be known. Aspects of epistemology include the acquisition of\nand justification for new knowledge. Thus, we need to coordinate ontology with\nepistemology. Because we are developing frameworks for capturing knowledge\nacross several scholarly domains, we describe the work in this paper as\nexploring structured applied epistemology. Unlike other recent proposals for\nnew approaches to scholarly publishing, we propose an integrated and\ncomprehensive approach. We have explored direct representation based on the\nrigorous Basic Formal Ontology and in this paper, we consider how epistemology\ncan be incorporated with that. In addition to highly-structured scientific\nresearch reports, we also consider how to develop highly-structured\ndescriptions of historical events on which historical analyses can be based."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.09.001", 
    "link": "http://arxiv.org/pdf/1610.07496v1", 
    "title": "4D Specialty Approximation: Ability to Distinguish between Related   Specialties", 
    "arxiv-id": "1610.07496v1", 
    "author": "Nadine Rons", 
    "publish": "2016-10-24T17:08:24Z", 
    "summary": "Publication and citation patterns can vary significantly between related\ndisciplines or more narrow specialties, even when sharing journals.\nJournal-based structures are therefore not accurate enough to approximate\ncertain specialties, neither subject categories in global citation indices, nor\ncell sub-structures (Rons, 2012). This paper presents first test results of a\nnew methodology that approximates the specialty of a highly specialized seed\nrecord by combining criteria for four publication metadata-fields, thereby\nbroadly covering conceptual components defining disciplines and scholarly\ncommunication. To offer added value compared to journal-based structures, the\nmethodology needs to generate sufficiently distinct results for seed\ndirectories in related specialties (sharing subject categories, cells, or even\nsources) with significantly different characteristics. This is tested\nsuccessfully for the sub-domains of theoretical and experimental particle\nphysics. In particular analyses of specialties with characteristics deviating\nfrom those of a broader discipline embedded in can benefit from an approach\ndiscerning down to specialty level. Such specialties are potentially present in\nall disciplines, for instance as cases of peripheral, emerging, frontier, or\nstrategically prioritized research areas."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.09.001", 
    "link": "http://arxiv.org/pdf/1610.09958v1", 
    "title": "Capturing the \"Whole Tale\" of Computational Research: Reproducibility in   Computing Environments", 
    "arxiv-id": "1610.09958v1", 
    "author": "Matthew Turk", 
    "publish": "2016-10-28T18:29:35Z", 
    "summary": "We present an overview of the recently funded \"Merging Science and\nCyberinfrastructure Pathways: The Whole Tale\" project (NSF award #1541450). Our\napproach has two nested goals: 1) deliver an environment that enables\nresearchers to create a complete narrative of the research process including\nexposure of the data-to-publication lifecycle, and 2) systematically and\npersistently link research publications to their associated digital scholarly\nobjects such as the data, code, and workflows. To enable this, Whole Tale will\ncreate an environment where researchers can collaborate on data, workspaces,\nand workflows and then publish them for future adoption or modification.\nPublished data and applications will be consumed either directly by users using\nthe Whole Tale environment or can be integrated into existing or future domain\nScience Gateways."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.09.001", 
    "link": "http://arxiv.org/pdf/1611.00217v1", 
    "title": "Sources of Change for Modern Knowledge Organization Systems", 
    "arxiv-id": "1611.00217v1", 
    "author": "Paul Groth", 
    "publish": "2016-11-01T13:23:07Z", 
    "summary": "Knowledge Organization Systems (e.g. taxonomies and ontologies) continue to\ncontribute benefits in the design of information systems by providing a shared\nconceptual underpinning for developers, users, and automated systems. However,\nthe standard mechanisms for the management of KOSs changes are inadequate for\nsystems built on top of thousands of data sources or with the involvement of\nhundreds of individuals. In this work, we review standard sources of change for\nKOSs (e.g. institutional shifts; standards cycles; cultural and political;\ndistribution, etc) and then proceed to catalog new sources of change for KOSs\nranging from massively cooperative development to always-on automated\nextraction systems. Finally, we reflect on what this means for the design and\nmanagement of KOSs."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.09.001", 
    "link": "http://arxiv.org/pdf/1611.01272v2", 
    "title": "Could freely available articles reduce faculty reliance on library for   access? An analysis of items cited by faculty from Singapore Management   University", 
    "arxiv-id": "1611.01272v2", 
    "author": "Aaron Tay", 
    "publish": "2016-11-04T06:45:56Z", 
    "summary": "Various studies have attempted to assess the amount of free full text\navailable on the web and recent work have suggested that we are close to the\n50% mark for freely available articles (Archambault et al. 2013; Bjork et al.\n2010; Jamali and Nabavi 2015). It is natural to wonder if this might reduce\nresearchers' reliance on library subscriptions for access. To do so, we need to\ndetermine not just what papers researchers are citing to that are free today,\nbut to estimate if the papers they were citing were freely available at the\ntime they were citing it. We attempt to do so for a sample of citations made by\nresearchers in the Singapore Management University in the field of Economics."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.09.001", 
    "link": "http://arxiv.org/pdf/1611.01658v1", 
    "title": "Citation algorithms for identifying research milestones driving   biomedical innovation", 
    "arxiv-id": "1611.01658v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2016-11-05T15:09:36Z", 
    "summary": "Scientific activity plays a major role in innovation for biomedicine and\nhealthcare. For instance, fundamental research on disease pathologies and\nmechanisms can generate potential targets for drug therapy. This co-evolution\nis punctuated by papers which provide new perspectives and open new domains.\nDespite the relationship between scientific discovery and biomedical\nadvancement, identifying these research milestones that truly impact biomedical\ninnovation can be difficult and is largely based solely on the opinions of\nsubject matter experts. Here, we consider whether a new class of citation\nalgorithms that identify seminal scientific works in a field, Reference\nPublication Year Spectroscopy (RPYS) and multi-RPYS, can identify the\nconnections between innovation (e.g. therapeutic treatments) and the\nfoundational research underlying them. Specifically, we assess whether the\nresults of these analytic techniques converge with expert opinions on research\nmilestones driving biomedical innovation in the treatment of Basal Cell\nCarcinoma. Our results show that these algorithms successfully identify the\nmajority of milestone papers detailed by experts (Wong and Dlugosz 2014)\nthereby validating the power of these algorithms to converge on independent\nopinions of seminal scientific works derived by subject matter experts. These\nadvances offer an opportunity to identify scientific activities enabling\ninnovation in biomedicine."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.09.001", 
    "link": "http://arxiv.org/pdf/1611.01820v1", 
    "title": "A Semi-Automatic Approach for Detecting Dataset References in Social   Science Texts", 
    "arxiv-id": "1611.01820v1", 
    "author": "S\u00f6ren AUER", 
    "publish": "2016-11-06T18:36:16Z", 
    "summary": "Today, full-texts of scientific articles are often stored in different\nlocations than the used datasets. Dataset registries aim at a closer\nintegration by making datasets citable but authors typically refer to datasets\nusing inconsistent abbreviations and heterogeneous metadata (e.g. title,\npublication year). It is thus hard to reproduce research results, to access\ndatasets for further analysis, and to determine the impact of a dataset.\nManually detecting references to datasets in scientific articles is\ntime-consuming and requires expert knowledge in the underlying research\ndomain.We propose and evaluate a semi-automatic three-step approach for finding\nexplicit references to datasets in social sciences articles.We first extract\npre-defined special features from dataset titles in the da|ra registry, then\ndetect references to datasets using the extracted features, and finally match\nthe references found with corresponding dataset titles. The approach does not\nrequire a corpus of articles (avoiding the cold start problem) and performs\nwell on a test corpus. We achieved an F-measure of 0.84 for detecting\nreferences in full-texts and an F-measure of 0.83 for finding correct matches\nof detected references in the da|ra dataset registry."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.09.001", 
    "link": "http://arxiv.org/pdf/1611.01935v2", 
    "title": "Skewness of citation impact data and covariates of citation   distributions: A large-scale empirical analysis based on Web of Science data", 
    "arxiv-id": "1611.01935v2", 
    "author": "Loet Leydesdorff", 
    "publish": "2016-11-07T08:43:53Z", 
    "summary": "Using percentile shares, one can visualize and analyze the skewness in\nbibliometric data across disciplines and over time. The resulting figures can\nbe intuitively interpreted and are more suitable for detailed analysis of the\neffects of independent and control variables on distributions than regression\nanalysis. We show this by using percentile shares to analyze so-called \"factors\ninfluencing citation impact\" (FICs; e.g., the impact factor of the publishing\njournal) across year and disciplines. All articles (n= 2,961,789) covered by\nWoS in 1990 (n= 637,301), 2000 (n= 919,485), and 2010 (n= 1,405,003) are used.\nIn 2010, nearly half of the citation impact is accounted for by the 10%\nmost-frequently cited papers; the skewness is largest in the humanities (68.5%\nin the top-10% layer) and lowest in agricultural sciences (40.6%). The\ncomparison of the effects of the different FICs (the number of cited\nreferences, number of authors, number of pages, and JIF) on citation impact\nshows that JIF has indeed the strongest correlations with the citation scores.\nHowever, the correlation between FICs and citation impact is lower, if\ncitations are normalized instead of using raw citation counts."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2998181.2998345", 
    "link": "http://arxiv.org/pdf/1611.02493v1", 
    "title": "Bots, Seeds and People: Web Archives as Infrastructure", 
    "arxiv-id": "1611.02493v1", 
    "author": "Ricardo Punzalan", 
    "publish": "2016-11-08T12:07:59Z", 
    "summary": "The field of web archiving provides a unique mix of human and automated\nagents collaborating to achieve the preservation of the web. Centuries old\ntheories of archival appraisal are being transplanted into the sociotechnical\nenvironment of the World Wide Web with varying degrees of success. The work of\nthe archivist and bots in contact with the material of the web present a\ndistinctive and understudied CSCW shaped problem. To investigate this space we\nconducted semi-structured interviews with archivists and technologists who were\ndirectly involved in the selection of content from the web for archives. These\nsemi-structured interviews identified thematic areas that inform the appraisal\nprocess in web archives, some of which are encoded in heuristics and\nalgorithms. Making the infrastructure of web archives legible to the archivist,\nthe automated agents and the future researcher is presented as a challenge to\nthe CSCW and archival community."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2998181.2998345", 
    "link": "http://arxiv.org/pdf/1611.05206v1", 
    "title": "Expected values in percentile indicators", 
    "arxiv-id": "1611.05206v1", 
    "author": "Robin Haunschild", 
    "publish": "2016-11-16T10:15:51Z", 
    "summary": "PP(top x%) is the proportion of papers of a unit (e.g. an institution or a\ngroup of researchers), which belongs to the x% most frequently cited papers in\nthe corresponding fields and publication years. It has been proposed that x% of\npapers can be expected which belongs to the x% most frequently cited papers. In\nthis Letter to the Editor we will present the results of an empirical test\nwhether we can really have this expectation and how strong the deviations from\nthe expected values are when many random samples are drawn from the database."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2998181.2998345", 
    "link": "http://arxiv.org/pdf/1611.06547v2", 
    "title": "A critical comparative analysis of five world university rankings", 
    "arxiv-id": "1611.06547v2", 
    "author": "Henk F. Moed", 
    "publish": "2016-11-20T17:06:50Z", 
    "summary": "To provide users insight into the value and limits of world university\nrankings, a comparative analysis is conducted of 5 ranking systems: ARWU,\nLeiden, THE, QS and U-Multirank. It links these systems with one another at the\nlevel of individual institutions, and analyses the overlap in institutional\ncoverage, geographical coverage, how indicators are calculated from raw data,\nthe skewness of indicator distributions, and statistical correlations between\nindicators. Four secondary analyses are presented investigating national\nacademic systems and selected pairs of indicators. It is argued that current\nsystems are still one-dimensional in the sense that they provide finalized,\nseemingly unrelated indicator values rather than offering a data set and tools\nto observe patterns in multi-faceted data. By systematically comparing\ndifferent systems, more insight is provided into how their institutional\ncoverage, rating methods, the selection of indicators and their normalizations\ninfluence the ranking positions of given institutions."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2998181.2998345", 
    "link": "http://arxiv.org/pdf/1611.06943v2", 
    "title": "Full and Fractional Counting in Bibliometric Networks", 
    "arxiv-id": "1611.06943v2", 
    "author": "Han Woo Park", 
    "publish": "2016-11-21T18:47:54Z", 
    "summary": "In their study entitled \"Constructing bibliometric networks: A comparison\nbetween full and fractional counting,\" Perianes-Rodriguez, Waltman, & van Eck\n(2016; henceforth abbreviated as PWvE) provide arguments for the use of\nfractional counting at the network level as different from the level of\npublications. Whereas fractional counting in the latter case divides the credit\namong co-authors (countries, institutions, etc.), fractional counting at the\nnetwork level can normalize the relative weights of links and thereby clarify\nthe structures in the network. PWvE, however, propose a counting scheme for\nfractional counting that is one among other possible ones. Alternative schemes\nproposed by Batagelj and Cerin\\v{s}ek (2013) and Park, Yoon, & Leydesdorff\n(2016; henceforth abbreviated as PYL) are discussed in an appendix. However,\nour approach is not correctly identified as identical to their Equation A3.\nHere below, we distinguish three approaches analytically; routines for applying\nthese approaches to bibliometric data are also provided."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.11.005", 
    "link": "http://arxiv.org/pdf/1611.08550v1", 
    "title": "The sum of it all: revealing collaboration patterns by combining   authorship and acknowledgements", 
    "arxiv-id": "1611.08550v1", 
    "author": "Vincent Lariviere", 
    "publish": "2016-11-25T18:51:13Z", 
    "summary": "Acknowledgments are one of many conventions by which researchers publicly\nbestow recognition towards individuals, organizations and institutions that\ncontributed in some way to the work that led to publication. Combining data on\nboth co-authors and acknowledged individuals, the present study analyses\ndisciplinary differences in researchers credit attribution practices in\ncollaborative context. Our results show that the important differences\ntraditionally observed between disciplines in terms of team size are greatly\nreduced when acknowledgees are taken into account. Broadening the measurement\nof collaboration beyond co-authorship by including individuals credited in the\nacknowledgements allows for an assessment of collaboration practices and team\nwork that might be closer to the reality of contemporary research, especially\nin the social sciences and humanities."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.11.005", 
    "link": "http://arxiv.org/pdf/1611.08592v1", 
    "title": "A conservation rule for constructing bibliometric network matrices", 
    "arxiv-id": "1611.08592v1", 
    "author": "Somenath Mukherjee", 
    "publish": "2016-11-25T12:03:16Z", 
    "summary": "The social network analysis of bibliometric data needs matrices to be recast\nin a network framework. In this paper we argue that a simple conservation rule\nrequires that this should be done only using fractional counting so that\nconservation at the paper level will be faithfully reproduced at higher levels\nofaggregation (i.e. author, institute, country, journal etc.) of the complex\nnetwork."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.12.002", 
    "link": "http://arxiv.org/pdf/1612.01431v2", 
    "title": "Three practical field normalised alternative indicator formulae for   research evaluation", 
    "arxiv-id": "1612.01431v2", 
    "author": "Mike Thelwall", 
    "publish": "2016-12-05T17:02:21Z", 
    "summary": "Although altmetrics and other web-based alternative indicators are now\ncommonplace in publishers' websites, they can be difficult for research\nevaluators to use because of the time or expense of the data, the need to\nbenchmark in order to assess their values, the high proportion of zeros in some\nalternative indicators, and the time taken to calculate multiple complex\nindicators. These problems are addressed here by (a) a field normalisation\nformula, the Mean Normalised Log-transformed Citation Score (MNLCS) that allows\nsimple confidence limits to be calculated and is similar to a proposal of\nLundberg, (b) field normalisation formulae for the proportion of cited articles\nin a set, the Equalised Mean-based Normalised Proportion Cited (EMNPC) and the\nMean-based Normalised Proportion Cited (MNPC), to deal with mostly uncited data\nsets, (c) a sampling strategy to minimise data collection costs, and (d) free\nunified software to gather the raw data, implement the sampling strategy, and\ncalculate the indicator formulae and confidence limits. The approach is\ndemonstrated (but not fully tested) by comparing the Scopus citations, Mendeley\nreaders and Wikipedia mentions of research funded by Wellcome, NIH, and MRC in\nthree large fields for 2013-2016. Within the results, statistically significant\ndifferences in both citation counts and Mendeley reader counts were found even\nfor sets of articles that were less than six months old. Mendeley reader counts\nwere more precise than Scopus citations for the most recent articles and all\nthree funders could be demonstrated to have an impact in Wikipedia that was\nsignificantly above the world average."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.12.002", 
    "link": "http://arxiv.org/pdf/1612.01770v2", 
    "title": "Measuring field-normalized impact of papers on specific societal groups:   An altmetrics study based on Mendeley data", 
    "arxiv-id": "1612.01770v2", 
    "author": "Robin Haunschild", 
    "publish": "2016-12-06T11:59:45Z", 
    "summary": "Bibliometrics is successful in measuring impact, because the target is\nclearly defined: the publishing scientist who is still active and working.\nThus, citations are a target-oriented metric which measures impact on science.\nIn contrast, societal impact measurements based on altmetrics are as a rule\nintended to measure impact in a broad sense on all areas of society (e.g.\nscience, culture, politics, and economics). This tendency is especially\nreflected in the efforts to design composite indicators (e.g. the Altmetric\nattention score). We deem appropriate that not only the impact measurement\nusing citations is target-oriented (citations measure the impact of papers on\nscientists), but also the measurement of impact using altmetrics. Impact\nmeasurements only make sense, if the target group - the recipient of academic\npapers - is clearly defined. Thus, we extend in this study the field-normalized\nreader impact indicator proposed by us in an earlier study, which is based on\nMendeley data (the mean normalized reader score, MNRS), to a target-oriented\nfield-normalized impact indicator (e.g., MNRS_ED measures reader impact on the\nsector of educational donation, i.e., teaching). This indicator can show - as\ndemonstrated in empirical examples - the ability of journals, countries, and\nacademic institutions to publish papers which are below or above the average\nimpact of papers on a specific sector in society (e.g., the educational or\nteaching sector). For example, the method allows to measure the impact of\nscientific papers on students - controlling for the field in which the papers\nhave been published and their publication year."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-016-2237-2", 
    "link": "http://arxiv.org/pdf/1612.01822v1", 
    "title": "How many scientific papers are mentioned in policy-related documents? An   empirical investigation using Web of Science and Altmetric data", 
    "arxiv-id": "1612.01822v1", 
    "author": "Lutz Bornmann", 
    "publish": "2016-12-06T14:28:37Z", 
    "summary": "In this short communication, we provide an overview of a relatively newly\nprovided source of altmetrics data which could possibly be used for societal\nimpact measurements in scientometrics. Recently, Altmetric - a start-up\nproviding publication level metrics - started to make data for publications\navailable which have been mentioned in policy-related documents. Using data\nfrom Altmetric, we study how many papers indexed in the Web of Science (WoS)\nare mentioned in policy-related documents. We find that less than 0.5% of the\npapers published in different subject categories are mentioned at least once in\npolicy-related documents. Based on our results, we recommend that the analysis\nof (WoS) publications with at least one policy-related mention is repeated\nregularly (annually). Mentions in policy-related documents should not be used\nfor impact measurement until new policy-related sites are tracked."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.09.012", 
    "link": "http://arxiv.org/pdf/1612.03285v1", 
    "title": "Conceptual difficulties in the use of statistical inference in citation   analysis", 
    "arxiv-id": "1612.03285v1", 
    "author": "Ludo Waltman", 
    "publish": "2016-12-10T12:45:34Z", 
    "summary": "In this comment, I discuss the use of statistical inference in citation\nanalysis. In a recent paper, Williams and Bornmann argue in favor of the use of\nstatistical inference in citation analysis. I present a critical analysis of\ntheir arguments and of similar arguments provided elsewhere in the literature.\nMy conclusion is that the use of statistical inference in citation analysis\ninvolves major conceptual difficulties and, consequently, that the usefulness\nof statistical inference in citation analysis is highly questionable."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.09.012", 
    "link": "http://arxiv.org/pdf/1612.05016v1", 
    "title": "Research performance of UNU - A bibliometric analysis of the United   Nations University", 
    "arxiv-id": "1612.05016v1", 
    "author": "Johannes Stegmann", 
    "publish": "2016-12-15T11:08:02Z", 
    "summary": "The scientific paper output of the United Nations University (UNU) was\nbibliometrically analysed.It was found that (i) a noticeable continous paper\noutput starts in 1995, (ii) about 65% of the research papers have been\npublished as international cooperations and 18% as single-authored papers, (iv)\nthe research papers rank above world average according to Pudovkin-Garfield\nPercentile Rank Index, and (v) paper content indicate the wide variety of\nscientific topics UNU has been and is working on."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.09.012", 
    "link": "http://arxiv.org/pdf/1612.05239v1", 
    "title": "The CENDARI Infrastructure", 
    "arxiv-id": "1612.05239v1", 
    "author": "Carsten Thiel", 
    "publish": "2016-12-15T20:49:58Z", 
    "summary": "The CENDARI infrastructure is a research supporting platform designed to\nprovide tools for transnational historical research, focusing on two topics:\nMedieval culture and World War I. It exposes to the end users modern web-based\ntools relying on a sophisticated infrastructure to collect, enrich, annotate,\nand search through large document corpora. Supporting researchers in their\ndaily work is a novel concern for infrastructures. We describe how we gathered\nrequirements through multiple methods to understand the historians' needs and\nderive an abstract workflow to support them. We then outline the tools we have\nbuilt, tying their technical descriptions to the user requirements. The main\ntools are the Note Taking Environment and its faceted search capabilities, the\nData Integration platform including the Data API, supporting semantic\nenrichment through entity recognition, and the environment supporting the\nsoftware development processes throughout the project to keep both technical\npartners and researchers in the loop. The outcomes are technical together with\nnew resources developed and gathered, and the research workflow that has been\ndescribed and documented."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2016.09.012", 
    "link": "http://arxiv.org/pdf/1612.05810v1", 
    "title": "Patent Portfolio Analysis of Cities: Statistics and Maps of   Technological Inventiveness", 
    "arxiv-id": "1612.05810v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2016-12-17T19:15:39Z", 
    "summary": "Cities are engines of the knowledge-based economy, because they are the\nprimary sites of knowledge production activities that subsequently shape the\nrate and direction of technological change and economic growth. Patents provide\na wealth of information to analyse the knowledge specialization at specific\nplaces, such as technological details and information on inventors and entities\ninvolved, including address information. The technology codes on each patent\ndocument indicate the specialization and scope of the underlying technological\nknowledge of a given invention. In this paper we introduce tools for portfolio\nanalysis in terms of patents that provide insights into the technological\nspecialization of cities. The mapping and analysis of patent portfolios of\ncities using data of the Unites States Patent and Trademark Office (USPTO)\nwebsite (at http://www.uspto.gov) and dedicated tools (at\nhttp://www.leydesdorff.net/portfolio) can be used to analyse the specialisation\npatterns of inventive activities among cities. The results allow policy makers\nand other stakeholders to identify promising areas of further knowledge\ndevelopment and 'smart specialisation' strategies."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.02.009", 
    "link": "http://arxiv.org/pdf/1612.06079v2", 
    "title": "An empirical and theoretical critique of the Euclidean index", 
    "arxiv-id": "1612.06079v2", 
    "author": "Jens Peter Andersen", 
    "publish": "2016-12-19T09:01:39Z", 
    "summary": "The recently proposed Euclidean index offers a novel approach to measure the\ncitation impact of academic authors, in particular as an alternative to the\nh-index. We test if the index provides new, robust information, not covered by\nexisting bibliometric indicators, discuss the measurement scale and the degree\nof distinction between analytical units the index offers. We find that the\nEuclidean index does not outperform existing indicators on these topics and\nthat the main application of the index would be solely for ranking, which is\nnot seen as a recommended practice."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.02.009", 
    "link": "http://arxiv.org/pdf/1612.07208v1", 
    "title": "Growth of International Cooperation in Science: Revisiting Six Case   Studies", 
    "arxiv-id": "1612.07208v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2016-12-20T20:32:11Z", 
    "summary": "International collaboration in science continues to grow at a remarkable\nrate, but little agreement exists about dynamics of growth and organization at\nthe discipline level. Some suggest that disciplines differ in their\ncollaborative tendencies, reflecting their epistemic culture. This study\nexamines collaborative patterns in six previously studied specialties to add\nnew data and conduct analyses over time. Our findings show that the global\nnetwork of collaboration continues to add new nations and new participants;\neach specialty has added many new nations to its lists of collaborating\npartners since 1990. We also find that the scope of international collaboration\nis positively related to impact. Network characteristics for the six\nspecialties are notable in that instead of reflecting underlying culture, they\ntend towards convergence. This observation suggests that the global level may\nrepresent next-order dynamics that feed back to the national and local levels\n(as subsystems) in a complex, networked hierarchy."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.02.009", 
    "link": "http://arxiv.org/pdf/1701.00612v1", 
    "title": "Citation indices and dimensional homogeneity", 
    "arxiv-id": "1701.00612v1", 
    "author": "Gangan Prathap", 
    "publish": "2017-01-03T09:35:59Z", 
    "summary": "The importance of dimensional analysis and dimensional homogeneity in\nbibliometric studies is always overlooked. In this paper, we look at this issue\nsystematically and show that most h-type indices have the dimensions of [P],\nwhere [P] is the basic dimensional unit in bibliometrics which is the unit\npublication or paper. The newly introduced Euclidean index, based on the\nEuclidean length of the citation vector has the dimensions [P3/2]. An empirical\nexample is used to illustrate the concepts."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.02.009", 
    "link": "http://arxiv.org/pdf/1701.02455v1", 
    "title": "Toward a Calculus of Redundancy: The feedback arrow of expectations in   knowledge-based systems", 
    "arxiv-id": "1701.02455v1", 
    "author": "Inga Ivanova", 
    "publish": "2017-01-10T07:27:57Z", 
    "summary": "Whereas the generation of Shannon-type information is coupled to the second\nlaw of thermodynamics, redundancy--that is, the complement of information to\nthe maximum entropy--can be increased by further distinctions: new options can\ndiscursively be generated. The dynamics of discursive knowledge production thus\ninfuse the historical dynamics with a cultural evolution based on expectations\n(as different from observations). We distinguish among (i) the communication of\ninformation, (ii) the sharing of meaning, and (iii) discursive knowledge.\nMeaning is provided from the perspective of hindsight as feedback on the\nentropy flow and thus generates redundancy. Specific meanings can selectively\nbe codified as discursive knowledge; knowledge-based reconstructions enable us\nto specify expectations about future states which can be invoked in the\npresent. The cycling among the dynamics of information, meaning, and knowledge\nin feedback and feedforward loops can be evaluated empirically: When mutual\nredundancy prevails over mutual information, the sign of the resulting\ninformation is negative indicating reduction of uncertainty because of new\noptions available for realization; innovation can then be expected to flourish.\nWhen historical realizations prevail, innovation may be locked-in because of\ninsufficient options for further development."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.02.009", 
    "link": "http://arxiv.org/pdf/1701.08008v1", 
    "title": "Novel processes and metrics for a scientific evaluation rooted in the   principles of science - Version 1", 
    "arxiv-id": "1701.08008v1", 
    "author": "Gary S. McDowell", 
    "publish": "2017-01-27T10:48:21Z", 
    "summary": "Scientific evaluation is a determinant of how scientists, institutions and\nfunders behave, and as such is a key element in the making of science. In this\narticle, we propose an alternative to the current norm of evaluating research\nwith journal rank. Following a well-defined notion of scientific value, we\nintroduce qualitative processes that can also be quantified and give rise to\nmeaningful and easy-to-use article-level metrics. In our approach, the goal of\na scientist is transformed from convincing an editorial board through a\nvertical process to convincing peers through an horizontal one. We argue that\nsuch an evaluation system naturally provides the incentives and logic needed to\nconstantly promote quality, reproducibility, openness and collaboration in\nscience. The system is legally and technically feasible and can gradually lead\nto the self-organized reappropriation of the scientific process by the\nscholarly community and its institutions. We propose an implementation of our\nevaluation system with the platform \"the Self-Journals of Science\"\n(www.sjscience.org)."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-319-43997-6_9", 
    "link": "http://arxiv.org/pdf/1702.00198v1", 
    "title": "ArchiveWeb: Collaboratively Extending and Exploring Web Archive   Collections", 
    "arxiv-id": "1702.00198v1", 
    "author": "Rishita Kalyani", 
    "publish": "2017-02-01T10:39:07Z", 
    "summary": "Curated web archive collections contain focused digital contents which are\ncollected by archiving organizations to provide a representative sample\ncovering specific topics and events to preserve them for future exploration and\nanalysis. In this paper, we discuss how to best support collaborative\nconstruction and exploration of these collections through the ArchiveWeb\nsystem. ArchiveWeb has been developed using an iterative evaluation-driven\ndesign-based research approach, with considerable user feedback at all stages.\nThis paper describes the functionalities of our current prototype for\nsearching, constructing, exploring and discussing web archive collections, as\nwell as feedback on this prototype from seven archiving organizations, and our\nplans for improving the next release of the system."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s00799-016-0206-2", 
    "link": "http://arxiv.org/pdf/1702.00436v1", 
    "title": "ArchiveWeb: collaboratively extending and exploring web archive   collections - How would you like to work with your collections?", 
    "arxiv-id": "1702.00436v1", 
    "author": "Wolfgang Nejdl", 
    "publish": "2017-02-01T20:05:08Z", 
    "summary": "Curated web archive collections contain focused digital content which is\ncollected by archiving organizations, groups, and individuals to provide a\nrepresentative sample covering specific topics and events to preserve them for\nfuture exploration and analysis. In this paper, we discuss how to best support\ncollaborative construction and exploration of these collections through the\nArchiveWeb system. ArchiveWeb has been developed using an iterative\nevaluation-driven design-based research approach, with considerable user\nfeedback at all stages. The first part of this paper describes the important\ninsights we gained from our initial requirements engineering phase during the\nfirst year of the project and the main functionalities of the current\nArchiveWeb system for searching, constructing, exploring, and discussing web\narchive collections. The second part summarizes the feedback we received on\nthis version from archiving organizations and libraries, as well as our\ncorresponding plans for improving and extending the system for the next\nrelease."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s00799-016-0206-2", 
    "link": "http://arxiv.org/pdf/1702.00554v1", 
    "title": "Benford's law: a 'sleeping beauty' sleeping in the dirty pages of   logarithmic tables", 
    "arxiv-id": "1702.00554v1", 
    "author": "Marcel Ausloos", 
    "publish": "2017-02-02T07:08:27Z", 
    "summary": "Benford's law is an empirical observation, first reported by Simon Newcomb in\n1881 and then independently by Frank Benford in 1938: the first significant\ndigits of numbers in large data are often distributed according to a\nlogarithmically decreasing function. Being contrary to intuition, the law was\nforgotten as a mere curious observation. However, in the last two decades,\nrelevant literature has grown exponentially, - an evolution typical of\n\"Sleeping Beauties\" (SBs) publications that go unnoticed (sleep) for a long\ntime and then suddenly become center of attention (are awakened). Thus, in the\npresent study, we show that Newcomb (1881) and Benford (1938) papers are\nclearly SBs. The former was in deep sleep for 110 years whereas the latter was\nin deep sleep for a comparatively lesser period of 31 years up to 1968, and in\na state of less deep sleep for another 27 years up to 1995. Both SBs were\nawakened in the year 1995 by Hill (1995a). In so doing, we show that the waking\nprince (Hill, 1995a) is more often quoted than the SB whom he kissed, - in this\nBenford's law case, wondering whether this is a general effect, - to be\nusefully studied."
},{
    "category": "cs.DL", 
    "doi": "10.1145/2910896.2910901", 
    "link": "http://arxiv.org/pdf/1702.01151v1", 
    "title": "The Dawn of Today's Popular Domains: A Study of the Archived German Web   over 18 Years", 
    "arxiv-id": "1702.01151v1", 
    "author": "Avishek Anand", 
    "publish": "2017-02-03T20:45:56Z", 
    "summary": "The Web has been around and maturing for 25 years. The popular websites of\ntoday have undergone vast changes during this period, with a few being there\nalmost since the beginning and many new ones becoming popular over the years.\nThis makes it worthwhile to take a look at how these sites have evolved and\nwhat they might tell us about the future of the Web. We therefore embarked on a\nlongitudinal study spanning almost the whole period of the Web, based on data\ncollected by the Internet Archive starting in 1996, to retrospectively analyze\nhow the popular Web as of now has evolved over the past 18 years.\n  For our study we focused on the German Web, specifically on the top 100 most\npopular websites in 17 categories. This paper presents a selection of the most\ninteresting findings in terms of volume, size as well as age of the Web. While\nrelated work in the field of Web Dynamics has mainly focused on change rates\nand analyzed datasets spanning less than a year, we looked at the evolution of\nwebsites over 18 years. We found that around 70% of the pages we investigated\nare younger than a year, with an observed exponential growth in age as well as\nin size up to now. If this growth rate continues, the number of pages from the\npopular domains will almost double in the next two years. In addition, we give\ninsights into our data set, provided by the Internet Archive, which hosts the\nlargest and most complete Web archive as of today."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-319-43997-6_17", 
    "link": "http://arxiv.org/pdf/1702.01163v1", 
    "title": "Archiving Software Surrogates on the Web for Future Reference", 
    "arxiv-id": "1702.01163v1", 
    "author": "Mila Runnwerth", 
    "publish": "2017-02-03T21:17:25Z", 
    "summary": "Software has long been established as an essential aspect of the scientific\nprocess in mathematics and other disciplines. However, reliably referencing\nsoftware in scientific publications is still challenging for various reasons. A\ncrucial factor is that software dynamics with temporal versions or states are\ndifficult to capture over time. We propose to archive and reference surrogates\ninstead, which can be found on the Web and reflect the actual software to a\nremarkable extent. Our study shows that about a half of the webpages of\nsoftware are already archived with almost all of them including some kind of\ndocumentation."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-319-42432-3_52", 
    "link": "http://arxiv.org/pdf/1702.01165v1", 
    "title": "Linking Mathematical Software in Web Archives", 
    "arxiv-id": "1702.01165v1", 
    "author": "Wolfram Sperber", 
    "publish": "2017-02-03T21:23:21Z", 
    "summary": "The Web is our primary source of all kinds of information today. This\nincludes information about software as well as associated materials, like\nsource code, documentation, related publications and change logs. Such data is\nof particular importance in research in order to conduct, comprehend and\nreconstruct scientific experiments that involve software. swMATH, a\nmathematical software directory, attempts to identify software mentions in\nscientific articles and provides additional information as well as links to the\nWeb. However, just like software itself, the Web is dynamic and most likely the\ninformation on the Web has changed since it was referenced in a scientific\npublication. Therefore, it is crucial to preserve the resources of a software\non the Web to capture its states over time.\n  We found that around 40% of the websites in swMATH are already included in an\nexisting Web archive. Out of these, 60% of contain some kind of documentation\nand around 45% even provide downloads of software artifacts. Hence, already\ntoday links can be established based on the publication dates of corresponding\narticles. The contained data enable enriching existing information with a\ntemporal dimension. In the future, specialized infrastructure will improve the\ncoverage of software resources and allow explicit references in scientific\npublications."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-319-42432-3_52", 
    "link": "http://arxiv.org/pdf/1702.03411v1", 
    "title": "Citation-based clustering of publications using CitNetExplorer and   VOSviewer", 
    "arxiv-id": "1702.03411v1", 
    "author": "Ludo Waltman", 
    "publish": "2017-02-11T11:25:35Z", 
    "summary": "Clustering scientific publications in an important problem in bibliometric\nresearch. We demonstrate how two software tools, CitNetExplorer and VOSviewer,\ncan be used to cluster publications and to analyze the resulting clustering\nsolutions. CitNetExplorer is used to cluster a large set of publications in the\nfield of astronomy and astrophysics. The publications are clustered based on\ndirect citation relations. CitNetExplorer and VOSviewer are used together to\nanalyze the resulting clustering solutions. Both tools use visualizations to\nsupport the analysis of the clustering solutions, with CitNetExplorer focusing\non the analysis at the level of individual publications and VOSviewer focusing\non the analysis at an aggregate level. The demonstration provided in this paper\nshows how a clustering of publications can be created and analyzed using freely\navailable software tools. Using the approach presented in this paper,\nbibliometricians are able to carry out sophisticated cluster analyses without\nthe need to have a deep knowledge of clustering techniques and without\nrequiring advanced computer skills."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-319-42432-3_52", 
    "link": "http://arxiv.org/pdf/1702.03991v1", 
    "title": "Google Scholar and the gray literature: A reply to Bonato's review", 
    "arxiv-id": "1702.03991v1", 
    "author": "Emilio Delgado Lopez-Cozar", 
    "publish": "2017-02-13T21:27:05Z", 
    "summary": "Recently, a review concluded that Google Scholar (GS) is not a suitable\nsource of information \"for identifying recent conference papers or other gray\nliterature publications\". The goal of this letter is to demonstrate that GS can\nbe an effective tool to search and find gray literature, as long as appropriate\nsearch strategies are used. To do this, we took as examples the same two case\nstudies used by the original review, describing first how GS processes\noriginal's search strategies, then proposing alternative search strategies, and\nfinally generalizing each case study to compose a general search procedure\naimed at finding gray literature in Google Scholar for two wide selected case\nstudies: a) all contributions belonging to a congress (the ASCO Annual\nMeeting); and b) indexed guidelines as well as gray literature within medical\ninstitutions (National Institutes of Health) and governmental agencies (U.S.\nDepartment of Health & Human Services). The results confirm that original\nsearch strategies were undertrained offering misleading results and erroneous\nconclusions. Google Scholar lacks many of the advanced search features\navailable in other bibliographic databases (such as Pubmed), however, it is one\nthing to have a friendly search experience, and quite another to find gray\nliterature. We finally conclude that Google Scholar is a powerful tool for\nsearching gray literature, as long as the users are familiar with all the\npossibilities it offers as a search engine. Poorly formulated searches will\nundoubtedly return misleading results."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-017-2298-x", 
    "link": "http://arxiv.org/pdf/1702.04946v1", 
    "title": "Clustering articles based on semantic similarity", 
    "arxiv-id": "1702.04946v1", 
    "author": "Rob Koopman", 
    "publish": "2017-02-16T12:48:54Z", 
    "summary": "Document clustering is generally the first step for topic identification.\nSince many clustering methods operate on the similarities between documents, it\nis important to build representations of these documents which keep their\nsemantics as much as possible and are also suitable for efficient similarity\ncalculation. The metadata of articles in the Astro dataset contribute to a\nsemantic matrix, which uses a vector space to capture the semantics of entities\nderived from these articles and consequently supports the contextual\nexploration of these entities in LittleAriadne. However, this semantic matrix\ndoes not allow to calculate similarities between articles directly. In this\npaper, we will describe in detail how we build a semantic representation for an\narticle from the entities that are associated with it. Base on such semantic\nrepresentations of articles, we apply two standard clustering methods, K-Means\nand the Louvain community detection algorithm, which leads to our two\nclustering solutions labelled as OCLC-31 (standing for K-Means) and\nOCLC-Louvain (standing for Louvain). In this paper, we will give the\nimplementation details and a basic comparison with other clustering solutions\nthat are reported in this special issue."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-017-2298-x", 
    "link": "http://arxiv.org/pdf/1702.07481v1", 
    "title": "Mapping Patent Classifications: Portfolio and Statistical Analysis, and   the Comparison of Strengths and Weaknesses", 
    "arxiv-id": "1702.07481v1", 
    "author": "Bowen Yan", 
    "publish": "2017-02-24T07:29:46Z", 
    "summary": "The Cooperative Patent Classifications (CPC) jointly developed by the\nEuropean and US Patent Offices provide a new basis for mapping and portfolio\nanalysis. This update provides an occasion for rethinking the parameter\nchoices. The new maps are significantly different from previous ones, although\nthis may not always be obvious on visual inspection. Since these maps are\nstatistical constructs based on index terms, their quality--as different from\nutility--can only be controlled discursively. We provide nested maps online and\na routine for portfolio overlays and further statistical analysis. We add a new\ntool for \"difference maps\" which is illustrated by comparing the portfolios of\npatents granted to Novartis and MSD in 2016."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-017-2298-x", 
    "link": "http://arxiv.org/pdf/1702.07960v1", 
    "title": "Citation personal display: A case study of personal websites by   physicists in 11 well-known universities", 
    "arxiv-id": "1702.07960v1", 
    "author": "Nan Zhang", 
    "publish": "2017-02-26T00:46:11Z", 
    "summary": "This paper aims to investigate the extent to which researchers display\ncitation, and wants to examine whether there are researcher differences in\ncitation personal display at the level of university, country, and academic\nrank. Physicists in 11 well-known universities in USA, Britain, and China were\nchosen as the object of study. It was manually identified if physicists had\nmentioned citation counts, citation-based indices, or a link to Google Scholar\nCitations (GSC) on the personal websites. A chi-square test is constructed to\ntest researcher differences in citation personal display. Results showed that\nthe overall proportion of citation personal display is not high (14.8%), with\n129 of 870 physicists displaying citation. And physicists from different\nwell-known universities indeed had a significant difference in citation\npersonal display. Moreover, at the national level, it was noticed that\nphysicists in well-known Chinese universities had the highest level of citation\npersonal display, followed by Britain and the USA. Further, this study also\nfound that researchers who had the academic rank of professor had the highest\ncitation personal display. In addition, the differences in h-index personal\ndisplay by university, country or academic rank were analyzed, and the results\nshowed that they were not statistically significant."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-017-2303-4", 
    "link": "http://arxiv.org/pdf/1702.08210v1", 
    "title": "Contextualization of topics: Browsing through the universe of   bibliographic information", 
    "arxiv-id": "1702.08210v1", 
    "author": "Andrea Scharnhorst", 
    "publish": "2017-02-27T10:01:08Z", 
    "summary": "This paper describes how semantic indexing can help to generate a contextual\noverview of topics and visually compare clusters of articles. The method was\noriginally developed for an innovative information exploration tool, called\nAriadne, which operates on bibliographic databases with tens of millions of\nrecords. In this paper, the method behind Ariadne is further developed and\napplied to the research question of the special issue \"Same data, different\nresults\" - the better understanding of topic (re-)construction by different\nbibliometric approaches. For the case of the Astro dataset of 111,616 articles\nin astronomy and astrophysics, a new instantiation of the interactive exploring\ntool, LittleAriadne, has been created. This paper contributes to the overall\nchallenge to delineate and define topics in two different ways. First, we\nproduce two clustering solutions based on vector representations of articles in\na lexical space. These vectors are built on semantic indexing of entities\nassociated with those articles. Second, we discuss how LittleAriadne can be\nused to browse through the network of topical terms, authors, journals,\ncitations and various cluster solutions of the Astro dataset. More\nspecifically, we treat the assignment of an article to the different clustering\nsolutions as an additional element of its bibliographic record. Keeping the\nprinciple of semantic indexing on the level of such an extended list of\nentities of the bibliographic record, LittleAriadne in turn provides a\nvisualization of the context of a specific clustering solution. It also conveys\nthe similarity of article clusters produced by different algorithms, hence\nrepresenting a complementary approach to other possible means of comparison."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-017-2303-4", 
    "link": "http://arxiv.org/pdf/1703.01072v1", 
    "title": "\u00c9tude sur les portails et agr\u00e9gateurs des ressources p\u00e9dagogiques   universitaires francophones en acc\u00e8s libre", 
    "arxiv-id": "1703.01072v1", 
    "author": "Mokhtar Ben Henda", 
    "publish": "2017-03-03T08:05:43Z", 
    "summary": "This study responds to the first measure undertaken on July 17, 2015 by\nIDNEUF prject, that of an exploratory analysis of the existing portals and\naggregators of free French-language academic resources. The idea is to provide\nan overview of the most common trends and practices in the constitution and\norganization of digital online learning resource portals. The study of these\ntrends would help to define the appropriate choices and conditions for\ndesigning the future common French-language portal and to optimize its services\nfor the conservation, exchange, integration and pooling of educational\nresources within the distributed technological framework of French-language\nuniversities. This framework should therefore be interconnected, transparent\nand interoperable, reflecting both the linguistic and cultural specificities of\npartner institutions and their ambitions for technological and economic\ndevelopments. The development of this first exploratory study of portals would\ntake into account the two technological solutions discussed at the task force\nmeeting on 17 July 2015.1. The alternative of extending the capabilities of\nFrance's Digital University's search engine to French-language academic\ninstitutions will require that the experience of the UNT (Numerical Thematic\nUniversity) be taken into account as a key player in the digital portal In\nhigher education (supnumerique.gouv.fr). Thus, the present study should first\ntarget the portals of the UNT as models replicable or extensible to the French\ncontext by analyzing their technological choices, their modes of organization\nand their modes of use and communication;2. Next, the study will not be limited\nto analyzing UNT portals. The proposed hypothesis to create a common portal of\nFrench portals from the existing university portals also requires exploring\nthis possibility and proposing an analysis of existing portals that function\naccording to other organizational models."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-017-2303-4", 
    "link": "http://arxiv.org/pdf/1703.01319v1", 
    "title": "Coverage of Author Identifiers in Web of Science and Scopus", 
    "arxiv-id": "1703.01319v1", 
    "author": "Philipp Mayr", 
    "publish": "2017-03-03T19:53:46Z", 
    "summary": "As digital collections of scientific literature are widespread and used\nfrequently in knowledge-intense working environments, it has become a challenge\nto identify author names correctly. The treatment of homonyms is crucial for\nthe reliable resolution of author names. Apart from varying handling of first,\nmiddle and last names, vendors as well as the digital library community created\ntools to address the problem of author name disambiguation. This technical\nreport focuses on two widespread collections of scientific literature, Web of\nScience (WoS) and Scopus, and the coverage with author identification\ninformation such as Researcher ID, ORCID and Scopus Author Identifier in the\nperiod 1996 - 2014. The goal of this study is to describe the significant\ndifferences of the two collections with respect to overall distribution of\nauthor identifiers and its use across different subject domains. We found that\nthe STM disciplines show the best coverage of author identifiers in our dataset\nof 6,032,000 publications which are both covered by WoS and Scopus. In our\ndataset we found 184,823 distinct ResearcherIDs and 70,043 distinct ORCIDs. In\nthe appendix of this report we list a complete overview of all WoS subject\nareas and the amount of author identifiers in these subject areas."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-017-2303-4", 
    "link": "http://arxiv.org/pdf/1703.01469v1", 
    "title": "Scientific wealth and inequality within nations", 
    "arxiv-id": "1703.01469v1", 
    "author": "Gangan Prathap", 
    "publish": "2017-03-04T14:55:41Z", 
    "summary": "We show that the greater the scientific wealth of a nation, the more likely\nthat it will tend to concentrate this excellence in a few premier institutions.\nThat is, great wealth implies great inequality of distribution. The scientific\nwealth is interpreted in terms of citation data harvested by Google Scholar\nCitations for profiled institutions from all countries in the world."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-017-2303-4", 
    "link": "http://arxiv.org/pdf/1703.02334v1", 
    "title": "Use of the journal impact factor for assessing individual articles need   not be wrong", 
    "arxiv-id": "1703.02334v1", 
    "author": "Vincent A. Traag", 
    "publish": "2017-03-07T11:28:40Z", 
    "summary": "Most scientometricians reject the use of the journal impact factor for\nassessing individual articles and their authors. The well-known San Francisco\nDeclaration on Research Assessment also strongly objects against this way of\nusing the impact factor. Arguments against the use of the impact factor at the\nlevel of individual articles are often based on statistical considerations. The\nskewness of journal citation distributions typically plays a central role in\nthese arguments. We present a theoretical analysis of statistical arguments\nagainst the use of the impact factor at the level of individual articles. Our\nanalysis shows that these arguments do not support the conclusion that the\nimpact factor should not be used for assessing individual articles. In fact,\nour computer simulations demonstrate the possibility that the impact factor is\na more accurate indicator of the value of an article than the number of\ncitations the article has received. The debate on the impact factor and its use\nin research evaluations is very important, but this debate should not be based\non misplaced statistical arguments."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-017-2303-4", 
    "link": "http://arxiv.org/pdf/1703.03220v1", 
    "title": "Reconsidering the gold open access citation advantage postulate in a   multidisciplinary context: an analysis of the subject categories in the Web   of Science database 2009-2014", 
    "arxiv-id": "1703.03220v1", 
    "author": "Maria Isabel Dorta-Gonzalez", 
    "publish": "2017-03-09T10:34:01Z", 
    "summary": "Since Lawrence in 2001 proposed the open access (OA) citation advantage, the\npotential benefit of OA in relation to the citation impact has been discussed\nin depth. The methodology to test this postulate ranges from comparing the\nimpact factors of OA journals versus traditional ones, to comparing citations\nof OA versus non-OA articles published in the same non-OA journals. However,\nconclusions are not entirely consistent among fields, and two possible\nexplications have been suggested in those fields where a citation advantage has\nbeen observed for OA: the early view and the selection bias postulates. In this\nstudy, a longitudinal and multidisciplinary analysis of the gold OA citation\nadvantage is developed. All research articles in all journals for all subject\ncategories in the multidisciplinary database Web of Science are considered. A\ntotal of 1,137,634 articles - 86,712 OA articles (7.6%) and 1,050,922 non-OA\narticles (92.4%)- published in 2009 are analysed. The citation window\nconsidered goes from 2009 to 2014, and data are aggregated for the 249\ndisciplines (subject categories). At journal level, we also study the evolution\nof journal impact factors for OA and non-OA journals in those disciplines whose\nOA prevalence is higher (top 36 subject categories). As the main conclusion,\nthere is no generalizable gold OA citation advantage, neither at article nor at\njournal level."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-017-2303-4", 
    "link": "http://arxiv.org/pdf/1703.03302v1", 
    "title": "Impact of URI Canonicalization on Memento Count", 
    "arxiv-id": "1703.03302v1", 
    "author": "Herbert Van de Sompel", 
    "publish": "2017-03-09T15:46:08Z", 
    "summary": "Quantifying the captures of a URI over time is useful for researchers to\nidentify the extent to which a Web page has been archived. Memento TimeMaps\nprovide a format to list mementos (URI-Ms) for captures along with brief\nmetadata, like Memento-Datetime, for each URI-M. However, when some URI-Ms are\ndereferenced, they simply provide a redirect to a different URI-M (instead of a\nunique representation at the datetime), often also present in the TimeMap. This\ninfers that confidently obtaining an accurate count quantifying the number of\nnon-forwarding captures for a URI-R is not possible using a TimeMap alone and\nthat the magnitude of a TimeMap is not equivalent to the number of\nrepresentations it identifies. In this work we discuss this particular\nphenomena in depth. We also perform a breakdown of the dynamics of counting\nmementos for a particular URI-R (google.com) and quantify the prevalence of the\nvarious canonicalization patterns that exacerbate attempts at counting using\nonly a TimeMap. For google.com we found that 84.9% of the URI-Ms result in an\nHTTP redirect when dereferenced. We expand on and apply this metric to TimeMaps\nfor seven other URI-Rs of large Web sites and thirteen academic institutions.\nUsing a ratio metric DI for the number of URI-Ms without redirects to those\nrequiring a redirect when dereferenced, five of the eight large web sites' and\ntwo of the thirteen academic institutions' TimeMaps had a ratio of ratio less\nthan one, indicating that more than half of the URI-Ms in these TimeMaps result\nin redirects when dereferenced."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/1703.04031v1", 
    "title": "The Accuracy of Confidence Intervals for Field Normalised Indicators", 
    "arxiv-id": "1703.04031v1", 
    "author": "Ruth Fairclough", 
    "publish": "2017-03-11T20:36:53Z", 
    "summary": "When comparing the average citation impact of research groups, universities\nand countries, field normalisation reduces the influence of discipline and\ntime. Confidence intervals for these indicators can help with attempts to infer\nwhether differences between sets of publications are due to chance factors.\nAlthough both bootstrapping and formulae have been proposed for these, their\naccuracy is unknown. In response, this article uses simulated data to\nsystematically compare the accuracy of confidence limits in the simplest\npossible case, a single field and year. The results suggest that the MNLCS\n(Mean Normalised Log-transformed Citation Score) confidence interval formula is\nconservative for large groups but almost always safe, whereas bootstrap MNLCS\nconfidence intervals tend to be accurate but can be unsafe for smaller world or\ngroup sample sizes. In contrast, bootstrap MNCS (Mean Normalised Citation\nScore) confidence intervals can be very unsafe, although their accuracy\nincreases with sample sizes."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/1703.04222v1", 
    "title": "Scholia and scientometrics with Wikidata", 
    "arxiv-id": "1703.04222v1", 
    "author": "Egon Willighagen", 
    "publish": "2017-03-13T01:50:48Z", 
    "summary": "Scholia is a tool to handle scientific bibliographic information in Wikidata.\nThe Scholia Web service creates on-the-fly scholarly profiles for researchers,\norganizations, journals, publishers, individual scholarly works, and for\nresearch topics. To collect the data, it queries the SPARQL-based Wikidata\nQuery Service. Among several display formats available in Scholia are lists of\npublications for individual researchers and organizations, publications per\nyear, employment timelines, as well as co-author networks and citation graphs.\nThe Python package implementing the Web service is also able to format Wikidata\nbibliographic entries for use in LaTeX/BIBTeX."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/1703.04428v1", 
    "title": "Opening Scholarly Communication in Social Sciences by Connecting   Collaborative Authoring to Peer Review", 
    "arxiv-id": "1703.04428v1", 
    "author": "Christoph Lange", 
    "publish": "2017-03-13T14:55:28Z", 
    "summary": "The objective of the OSCOSS research project on \"Opening Scholarly\nCommunication in the Social Sciences\" is to build a coherent collaboration\nenvironment that facilitates scholarly communication workflows of social\nscientists in the roles of authors, reviewers, editors and readers. This paper\npresents the implementation of the core of this environment: the integration of\nthe Fidus Writer academic word processor with the Open Journal Systems (OJS)\nsubmission and review management system."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/1703.04746v1", 
    "title": "Citation histories of papers: sometimes the rich get richer, sometimes   they don't", 
    "arxiv-id": "1703.04746v1", 
    "author": "Ken A. Dill", 
    "publish": "2017-03-14T22:08:34Z", 
    "summary": "We describe a simple model of how a publication's citations change over time,\nbased on pure-birth stochastic processes with a linear cumulative advantage\neffect. The model is applied to citation data from the Physical Review corpus\nprovided by APS. Our model reveals that papers fall into three different\nclusters: papers that have rapid initial citations and ultimately high impact\n(fast-hi), fast to rise but quick to plateau (fast-flat), or late bloomers\n(slow-late), which may either never achieve many citations, or do so many years\nafter publication. In \"fast-hi\" and \"slow-late\", there is a rich-get-richer\neffect: papers that have many citations accumulate additional citations more\nrapidly while the \"fast-flat\" papers do not display this effect. We conclude by\nshowing that only a few years of post-publication statistics are needed to\nidentify high impact (\"fast-hi\") papers."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/1703.05485v1", 
    "title": "A modification to Hirsch index allowing comparisons across different   scientific fields", 
    "arxiv-id": "1703.05485v1", 
    "author": "Jiri Mazurek", 
    "publish": "2017-03-16T06:41:58Z", 
    "summary": "The aim of this paper is to propose a simple modification to the original\nmeasure, the relative Hirsch index, which assigns each researcher a value\nbetween 0 (the bottom) and 1 (the top), expressing his/her distance to the top\nin a given field. By this normalization scholars from different scientific\ndisciplines can be compared."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/1703.05539v1", 
    "title": "The coverage of Microsoft Academic: Analyzing the publication output of   a university", 
    "arxiv-id": "1703.05539v1", 
    "author": "Martin P. Braendle", 
    "publish": "2017-03-16T09:56:33Z", 
    "summary": "This is the first in-depth study on the coverage of Microsoft Academic (MA).\nThe coverage of a verified publication list of a university was analyzed on the\nlevel of individual publications in MA, Scopus, and Web of Science (WoS).\nCitation counts were analyzed and issues related to data retrieval and data\nquality were examined. A Perl script was written to retrieve metadata from MA.\nWe find that MA covers journal articles, working papers, and conference items\nto a substantial extent. MA surpasses Scopus and WoS clearly with respect to\nbook-related document types and conference items but falls slightly behind\nScopus with regard to journal articles. MA shows the same biases as Scopus and\nWoS with regard to the coverage of the social sciences and humanities,\nnon-English publications, and open-access publications. Rank correlations of\ncitation counts are high between MA and the benchmark databases. We find that\nthe publication year is correct for 89.5% of all publications and the number of\nauthors for 95.1% of the journal articles. Given the fast and ongoing\ndevelopment of MA, we conclude that MA is on the verge of becoming a\nbibliometric superpower. However, comprehensive studies on the quality of MA\ndata are still lacking."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/1703.05777v1", 
    "title": "What makes papers visible on social media? An analysis of various   document characteristics", 
    "arxiv-id": "1703.05777v1", 
    "author": "Stefanie Haustein", 
    "publish": "2017-03-16T18:04:42Z", 
    "summary": "In this study we have investigated the relationship between different\ndocument characteristics and the number of Mendeley readership counts, tweets,\nFacebook posts, mentions in blogs and mainstream media for 1.3 million papers\npublished in journals covered by the Web of Science (WoS). It aims to\ndemonstrate that how factors affecting various social media-based indicators\ndiffer from those influencing citations and which document types are more\npopular across different platforms. Our results highlight the heterogeneous\nnature of altmetrics, which encompasses different types of uses and user groups\nengaging with research on social media."
},{
    "category": "astro-ph", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/astro-ph/0609794v1", 
    "title": "The Future of Technical Libraries", 
    "arxiv-id": "astro-ph/0609794v1", 
    "author": "Stephen S. Murray", 
    "publish": "2006-09-28T20:49:46Z", 
    "summary": "Technical libraries are currently experiencing very rapid change. In the near\nfuture their mission will change, their physical nature will change, and the\nskills of their employees will change. While some will not be able to make\nthese changes, and will fail, others will lead us into a new era."
},{
    "category": "cs.DB", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/9809011v1", 
    "title": "Microsoft TerraServer", 
    "arxiv-id": "cs/9809011v1", 
    "author": "Randall Sunne", 
    "publish": "1998-09-05T00:29:54Z", 
    "summary": "The Microsoft TerraServer stores aerial and satellite images of the earth in\na SQL Server Database served to the public via the Internet. It is the world's\nlargest atlas, combining five terabytes of image data from the United States\nGeodetic Survey, Sovinformsputnik, and Encarta Virtual Globe. Internet browsers\nprovide intuitive spatial and gazetteer interfaces to the data. The TerraServer\nis also an E-Commerce application. Users can buy the right to use the imagery\nusing Microsoft Site Servers managed by the USGS and Aerial Images. This paper\ndescribes the TerraServer's design and implementation."
},{
    "category": "cs.MA", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/9809025v1", 
    "title": "Novelty and Social Search in the World Wide Web", 
    "arxiv-id": "cs/9809025v1", 
    "author": "Lada A. Adamic", 
    "publish": "1998-09-18T00:07:03Z", 
    "summary": "The World Wide Web is fast becoming a source of information for a large part\nof the world's population. Because of its sheer size and complexity users often\nresort to recommendations from others to decide which sites to visit. We\npresent a dynamical theory of recommendations which predicts site visits by\nusers of the World Wide Web. We show that it leads to a universal power law for\nthe number of users that visit given sites over periods of time, with an\nexponent related to the rate at which users discover new sites on their own. An\nextensive empirical study of user behavior in the Web that we conducted\nconfirms the existence of this law of influence while yielding bounds on the\nrate of novelty encountered by users."
},{
    "category": "cs.DB", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/9811013v1", 
    "title": "The Asilomar Report on Database Research", 
    "arxiv-id": "cs/9811013v1", 
    "author": "Jeff Ullman", 
    "publish": "1998-11-09T05:09:36Z", 
    "summary": "The database research community is rightly proud of success in basic\nresearch, and its remarkable record of technology transfer. Now the field needs\nto radically broaden its research focus to attack the issues of capturing,\nstoring, analyzing, and presenting the vast array of online data. The database\nresearch community should embrace a broader research agenda -- broadening the\ndefinition of database management to embrace all the content of the Web and\nother online data stores, and rethinking our fundamental assumptions in light\nof technology shifts. To accelerate this transition, we recommend changing the\nway research results are evaluated and presented. In particular, we advocate\nencouraging more speculative and long-range work, moving conferences to a\nposter format, and publishing all research literature on the Web."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/9902002v1", 
    "title": "Automatic Identification of Subjects for Textual Documents in Digital   Libraries", 
    "arxiv-id": "cs/9902002v1", 
    "author": "Kuang-hua Chen", 
    "publish": "1999-02-01T11:01:23Z", 
    "summary": "The amount of electronic documents in the Internet grows very quickly. How to\neffectively identify subjects for documents becomes an important issue. In\npast, the researches focus on the behavior of nouns in documents. Although\nsubjects are composed of nouns, the constituents that determine which nouns are\nsubjects are not only nouns. Based on the assumption that texts are\nwell-organized and event-driven, nouns and verbs together contribute the\nprocess of subject identification. This paper considers four factors: 1) word\nimportance, 2) word frequency, 3) word co-occurrence, and 4) word distance and\nproposes a model to identify subjects for textual documents. The preliminary\nexperiments show that the performance of the proposed model is close to that of\nhuman beings."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/9902017v2", 
    "title": "Not Available", 
    "arxiv-id": "cs/9902017v2", 
    "author": "Not Available", 
    "publish": "1999-02-09T04:02:55Z", 
    "summary": "withdrawn by author"
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/9902018v1", 
    "title": "ZBroker: A Query Routing Broker for Z39.50 Databases", 
    "arxiv-id": "cs/9902018v1", 
    "author": "Wee-Keong Ng", 
    "publish": "1999-02-09T03:50:24Z", 
    "summary": "A query routing broker is a software agent that determines from a large set\nof accessing information sources the ones most relevant to a user's information\nneed. As the number of information sources on the Internet increases\ndramatically, future users will have to rely on query routing brokers to decide\na small number of information sources to query without incurring too much query\nprocessing overheads. In this paper, we describe a query routing broker known\nas ZBroker developed for bibliographic database servers that support the Z39.50\nprotocol. ZBroker samples the content of each bibliographic database by using\ntraining queries and their results, and summarizes the bibliographic database\ncontent into a knowledge base. We present the design and implementation of\nZBroker and describe its Web-based user interface."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/9902019v1", 
    "title": "Multimodal Surrogates for Video Browsing", 
    "arxiv-id": "cs/9902019v1", 
    "author": "Dagobert Soergel", 
    "publish": "1999-02-09T04:56:59Z", 
    "summary": "Three types of video surrogates - visual (keyframes), verbal\n(keywords/phrases), and combination of the two - were designed and studied in a\nqualitative investigation of user cognitive processes. The results favor the\ncombined surrogates in which verbal information and images reinforce each\nother, lead to better comprehension, and may actually require less processing\ntime. The results also highlight image features users found most helpful. These\nfindings will inform the interface design and video representation for video\nretrieval and browsing."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/9902021v1", 
    "title": "Visualization of Retrieved Documents using a Presentation Server", 
    "arxiv-id": "cs/9902021v1", 
    "author": "Sung Hyon Myaeng", 
    "publish": "1999-02-10T09:30:59Z", 
    "summary": "In any search-based digital library (DL) systems dealing with a non-trivial\nnumber of documents, users are often required to go through a long list of\nshort document descriptions in order to identify what they are looking for. To\ntackle the problem, a variety of document organization algorithms and/or\nvisualization techniques have been used to guide users in selecting relevant\ndocuments. Since these techniques require heavy computations, however, we\ndeveloped a presentation server designed to serve as an intermediary between\nretrieval servers and clients equipped with a visualization interface. In\naddition, we designed our own visual interface by which users can view a set of\ndocuments from different perspectives through layers of document maps. We\nfinally ran experiments to show that the visual interface, in conjunction with\nthe presentation server, indeed helps users in selecting relevant documents\nfrom the retrieval results."
},{
    "category": "cs.DB", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/9907009v1", 
    "title": "Designing and Mining Multi-Terabyte Astronomy Archives: The Sloan   Digital Sky Survey", 
    "arxiv-id": "cs/9907009v1", 
    "author": "Jim Gray", 
    "publish": "1999-07-06T22:56:47Z", 
    "summary": "The next-generation astronomy digital archives will cover most of the\nuniverse at fine resolution in many wave-lengths, from X-rays to ultraviolet,\noptical, and infrared. The archives will be stored at diverse geographical\nlocations. One of the first of these projects, the Sloan Digital Sky Survey\n(SDSS) will create a 5-wavelength catalog over 10,000 square degrees of the sky\n(see http://www.sdss.org/). The 200 million objects in the multi-terabyte\ndatabase will have mostly numerical attributes, defining a space of 100+\ndimensions. Points in this space have highly correlated distributions.\n  The archive will enable astronomers to explore the data interactively. Data\naccess will be aided by a multidimensional spatial index and other indices. The\ndata will be partitioned in many ways. Small tag objects consisting of the most\npopular attributes speed up frequent searches. Splitting the data among\nmultiple servers enables parallel, scalable I/O and applies parallel processing\nto the data. Hashing techniques allow efficient clustering and pair-wise\ncomparison algorithms that parallelize nicely. Randomly sampled subsets allow\ndebugging otherwise large queries at the desktop. Central servers will operate\na data pump that supports sweeping searches that touch most of the data. The\nanticipated queries require special operators related to angular distances and\ncomplex similarity tests of object properties, like shapes, colors, velocity\nvectors, or temporal behaviors. These issues pose interesting data management\nchallenges."
},{
    "category": "cs.DB", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/9907016v1", 
    "title": "Microsoft TerraServer: A Spatial Data Warehouse", 
    "arxiv-id": "cs/9907016v1", 
    "author": "Tom Barclay Jim Gray Don Slutz", 
    "publish": "1999-07-09T21:30:11Z", 
    "summary": "The TerraServer stores aerial, satellite, and topographic images of the earth\nin a SQL database available via the Internet. It is the world's largest online\natlas, combining five terabytes of image data from the United States Geological\nSurvey (USGS) and SPIN-2. This report describes the system-redesign based on\nour experience over the last year. It also reports usage and operations results\nover the last year -- over 2 billion web hits and over 20 Terabytes of imagry\nserved over the Internet. Internet browsers provide intuitive spatial and text\ninterfaces to the data. Users need no special hardware, software, or knowledge\nto locate and browse imagery. This paper describes how terabytes of \"Internet\nunfriendly\" geo-spatial images were scrubbed and edited into hundreds of\nmillions of \"Internet friendly\" image tiles and loaded into a SQL data\nwarehouse. Microsoft TerraServer demonstrates that general-purpose relational\ndatabase technology can manage large scale image repositories, and shows that\nweb browsers can be a good geospatial image presentation system."
},{
    "category": "cs.IR", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/9907042v1", 
    "title": "Raising Reliability of Web Search Tool Research through Replication and   Chaos Theory", 
    "arxiv-id": "cs/9907042v1", 
    "author": "Scott Nicholson", 
    "publish": "1999-07-27T16:42:18Z", 
    "summary": "Because the World Wide Web is a dynamic collection of information, the Web\nsearch tools (or \"search engines\") that index the Web are dynamic. Traditional\ninformation retrieval evaluation techniques may not provide reliable results\nwhen applied to the Web search tools. This study is the result of ten\nreplications of the classic 1996 Ding and Marchionini Web search tool research.\nIt explores the effects that replication can have on transforming unreliable\nresults from one iteration into replicable and therefore reliable results after\nmultiple iterations."
},{
    "category": "cs.CR", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/9908012v1", 
    "title": "Safe Deals Between Strangers", 
    "arxiv-id": "cs/9908012v1", 
    "author": "H. M. Gladney", 
    "publish": "1999-08-17T01:09:54Z", 
    "summary": "E-business, information serving, and ubiquitous computing will create heavy\nrequest traffic from strangers or even incognitos. Such requests must be\nmanaged automatically. Two ways of doing this are well known: giving every\nincognito consumer the same treatment, and rendering service in return for\nmoney. However, different behavior will be often wanted, e.g., for a university\nlibrary with different access policies for undergraduates, graduate students,\nfaculty, alumni, citizens of the same state, and everyone else.\n  For a data or process server contacted by client machines on behalf of users\nnot previously known, we show how to provide reliable automatic access\nadministration conforming to service agreements. Implementations scale well\nfrom very small collections of consumers and producers to immense client/server\nnetworks. Servers can deliver information, effect state changes, and control\nexternal equipment.\n  Consumer privacy is easily addressed by the same protocol. We support\nconsumer privacy, but allow servers to deny their resources to incognitos. A\nprotocol variant even protects against statistical attacks by consortia of\nservice organizations.\n  One e-commerce application would put the consumer's tokens on a smart card\nwhose readers are in vending kiosks. In e-business we can simplify supply chain\nadministration. Our method can also be used in sensitive networks without\nintroducing new security loopholes."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/0005003v1", 
    "title": "CoRR: A Computing Research Repository", 
    "arxiv-id": "cs/0005003v1", 
    "author": "Joseph Y. Halpern", 
    "publish": "2000-05-03T23:54:53Z", 
    "summary": "Discusses how CoRR was set up and some policy issues involved with setting up\nsuch a repository."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/0005004v1", 
    "title": "A response to the commentaries on CoRR", 
    "arxiv-id": "cs/0005004v1", 
    "author": "Joseph Y. Halpern", 
    "publish": "2000-05-04T00:06:01Z", 
    "summary": "This is a response to the commentaries on \"CoRR: A Computing Research\nRepository\"."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/0007003v1", 
    "title": "Using compression to identify acronyms in text", 
    "arxiv-id": "cs/0007003v1", 
    "author": "Ian H. Witten", 
    "publish": "2000-07-04T02:02:01Z", 
    "summary": "Text mining is about looking for patterns in natural language text, and may\nbe defined as the process of analyzing text to extract information from it for\nparticular purposes. In previous work, we claimed that compression is a key\ntechnology for text mining, and backed this up with a study that showed how\nparticular kinds of lexical tokens---names, dates, locations, etc.---can be\nidentified and located in running text, using compression models to provide the\nleverage necessary to distinguish different token types (Witten et al., 1999)"
},{
    "category": "cs.CL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/0009014v1", 
    "title": "Combining Linguistic and Spatial Information for Document Analysis", 
    "arxiv-id": "cs/0009014v1", 
    "author": "Leon Todoran", 
    "publish": "2000-09-20T13:04:11Z", 
    "summary": "We present a framework to analyze color documents of complex layout. In\naddition, no assumption is made on the layout. Our framework combines in a\ncontent-driven bottom-up approach two different sources of information: textual\nand spatial. To analyze the text, shallow natural language processing tools,\nsuch as taggers and partial parsers, are used. To infer relations of the\nlogical layout we resort to a qualitative spatial calculus closely related to\nAllen's calculus. We evaluate the system against documents from a color journal\nand present the results of extracting the reading order from the journal's\npages. In this case, our analysis is successful as it extracts the intended\nreading order from the document."
},{
    "category": "cs.CL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/0105030v1", 
    "title": "The OLAC Metadata Set and Controlled Vocabularies", 
    "arxiv-id": "cs/0105030v1", 
    "author": "Gary Simons", 
    "publish": "2001-05-21T16:53:55Z", 
    "summary": "As language data and associated technologies proliferate and as the language\nresources community rapidly expands, it has become difficult to locate and\nreuse existing resources. Are there any lexical resources for such-and-such a\nlanguage? What tool can work with transcripts in this particular format? What\nis a good format to use for linguistic data of this type? Questions like these\ndominate many mailing lists, since web search engines are an unreliable way to\nfind language resources. This paper describes a new digital infrastructure for\nlanguage resource discovery, based on the Open Archives Initiative, and called\nOLAC -- the Open Language Archives Community. The OLAC Metadata Set and the\nassociated controlled vocabularies facilitate consistent description and\nfocussed searching. We report progress on the metadata set and controlled\nvocabularies, describing current issues and soliciting input from the language\nresources community."
},{
    "category": "cs.NI", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/0107035v1", 
    "title": "Semantic Web Content Accessibility Guidelines for Current Research   Information Systems (CRIS)", 
    "arxiv-id": "cs/0107035v1", 
    "author": "A. Lopatenko", 
    "publish": "2001-07-29T18:50:17Z", 
    "summary": "The most exciting challenge for CRIS is to create a service for research\ninformation which should be wide-spread, distributed and actual like Google,\nbut at the same time structured, trusted, with a complex search and navigation\nsimilar to today CRIS application. The core technology for such a \"new\" CRIS is\nthe semantic web technology to integrate database contents with HTML and XML\nweb pages for being provided to the research interested public. One (at the\nmoment the best) possible way is to use RDF (Resource Description Framework)\nwhich is also recommended by the W3 consortium."
},{
    "category": "cs.IR", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/0108004v1", 
    "title": "Links tell us about lexical and semantic Web content", 
    "arxiv-id": "cs/0108004v1", 
    "author": "Filippo Menczer", 
    "publish": "2001-08-08T02:16:15Z", 
    "summary": "The latest generation of Web search tools is beginning to exploit hypertext\nlink information to improve ranking\\cite{Brin98,Kleinberg98} and\ncrawling\\cite{Menczer00,Ben-Shaul99etal,Chakrabarti99} algorithms. The hidden\nassumption behind such approaches, a correlation between the graph structure of\nthe Web and its content, has not been tested explicitly despite increasing\nresearch on Web topology\\cite{Lawrence98,Albert99,Adamic99,Butler00}. Here I\nformalize and quantitatively validate two conjectures drawing connections from\nlink information to lexical and semantic Web content. The clink-content\nconjecture states that a page is similar to the pages that link to it, i.e.,\none can infer the lexical content of a page by looking at the pages that link\nto it. I also show that lexical inferences based on link cues are quite\nheterogeneous across Web communities. The link-cluster conjecture states that\npages about the same topic are clustered together, i.e., one can infer the\nmeaning of a page by looking at its neighbours. These results explain the\nsuccess of the newest search technologies and open the way for more dynamic and\nscalable methods to locate information in a topic or user driven way."
},{
    "category": "cs.CL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/0110014v1", 
    "title": "The Open Language Archives Community and Asian Language Resources", 
    "arxiv-id": "cs/0110014v1", 
    "author": "Chu-Ren Huang", 
    "publish": "2001-10-03T12:45:41Z", 
    "summary": "The Open Language Archives Community (OLAC) is a new project to build a\nworldwide system of federated language archives based on the Open Archives\nInitiative and the Dublin Core Metadata Initiative. This paper aims to\ndisseminate the OLAC vision to the language resources community in Asia, and to\nshow language technologists and linguists how they can document their tools and\ndata in such a way that others can easily discover them. We describe OLAC and\nthe OLAC Metadata Set, then discuss two key issues in the Asian context:\nlanguage classification and multilingual resource classification."
},{
    "category": "cs.IR", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/0110026v1", 
    "title": "Information retrieval in Current Research Information Systems", 
    "arxiv-id": "cs/0110026v1", 
    "author": "Andrei Lopatenko", 
    "publish": "2001-10-10T15:28:00Z", 
    "summary": "In this paper we describe the requirements for research information systems\nand problems which arise in the development of such system. Here is shown which\nproblems could be solved by using of knowledge markup technologies. Ontology\nfor Research Information System offered. Architecture for collecting research\ndata and providing access to it is described."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/0111015v1", 
    "title": "The SDSS SkyServer, Public Access to the Sloan Digital Sky Server Data", 
    "arxiv-id": "cs/0111015v1", 
    "author": "Jan vandenBerg", 
    "publish": "2001-11-07T20:39:31Z", 
    "summary": "The SkyServer provides Internet access to the public Sloan Digital Sky Survey\n(SDSS) data for both astronomers and for science education. This paper\ndescribes the SkyServer goals and architecture. It also describes our\nexperience operating the SkyServer on the Internet. The SDSS data is public and\nwell-documented so it makes a good test platform for research on database\nalgorithms and performance."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/0202013v1", 
    "title": "The SDSS SkyServer: Public Access to the Sloan Digital Sky Server Data", 
    "arxiv-id": "cs/0202013v1", 
    "author": "Jan vandenBerg", 
    "publish": "2002-02-12T23:16:36Z", 
    "summary": "The SkyServer provides Internet access to the public Sloan Digi-tal Sky\nSurvey (SDSS) data for both astronomers and for science education. This paper\ndescribes the SkyServer goals and archi-tecture. It also describes our\nexperience operating the SkyServer on the Internet. The SDSS data is public and\nwell-documented so it makes a good test platform for research on database\nalgorithms and performance."
},{
    "category": "cs.DB", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/0202014v1", 
    "title": "Data Mining the SDSS SkyServer Database", 
    "arxiv-id": "cs/0202014v1", 
    "author": "Jan vandenBerg", 
    "publish": "2002-02-12T23:47:20Z", 
    "summary": "An earlier paper (Szalay et. al. \"Designing and Mining MultiTerabyte\nAstronomy Archives: The Sloan Digital Sky Survey,\" ACM SIGMOD 2000) described\nthe Sloan Digital Sky Survey's (SDSS) data management needs by defining twenty\ndatabase queries and twelve data visualization tasks that a good data\nmanagement system should support. We built a database and interfaces to support\nboth the query load and also a website for ad-hoc access. This paper reports on\nthe database design, describes the data loading pipeline, and reports on the\nquery implementation and performance. The queries typically translated to a\nsingle SQL statement. Most queries run in less than 20 seconds, allowing\nscientists to interactively explore the database. This paper is an in-depth\ntour of those queries. Readers should first have studied the companion overview\npaper Szalay et. al. \"The SDSS SkyServer, Public Access to the Sloan Digital\nSky Server Data\" ACM SIGMOND 2002."
},{
    "category": "cs.IR", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/0203024v1", 
    "title": "The structure of broad topics on the Web", 
    "arxiv-id": "cs/0203024v1", 
    "author": "David M. Pennock", 
    "publish": "2002-03-20T06:46:21Z", 
    "summary": "The Web graph is a giant social network whose properties have been measured\nand modeled extensively in recent years. Most such studies concentrate on the\ngraph structure alone, and do not consider textual properties of the nodes.\nConsequently, Web communities have been characterized purely in terms of graph\nstructure and not on page content. We propose that a topic taxonomy such as\nYahoo! or the Open Directory provides a useful framework for understanding the\nstructure of content-based clusters and communities. In particular, using a\ntopic taxonomy and an automatic classifier, we can measure the background\ndistribution of broad topics on the Web, and analyze the capability of recent\nrandom walk algorithms to draw samples which follow such distributions. In\naddition, we can measure the probability that a page about one broad topic will\nlink to another broad topic. Extending this experiment, we can measure how\nquickly topic context is lost while walking randomly on the Web graph.\nEstimates of this topic mixing distance may explain why a global PageRank is\nstill meaningful in the context of broad queries. In general, our measurements\nmay prove valuable in the design of community-specific crawlers and link-based\nranking systems."
},{
    "category": "cs.CL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/0204020v1", 
    "title": "Seven Dimensions of Portability for Language Documentation and   Description", 
    "arxiv-id": "cs/0204020v1", 
    "author": "Gary Simons", 
    "publish": "2002-04-10T13:52:19Z", 
    "summary": "The process of documenting and describing the world's languages is undergoing\nradical transformation with the rapid uptake of new digital technologies for\ncapture, storage, annotation and dissemination. However, uncritical adoption of\nnew tools and technologies is leading to resources that are difficult to reuse\nand which are less portable than the conventional printed resources they\nreplace. We begin by reviewing current uses of software tools and digital\ntechnologies for language documentation and description. This sheds light on\nhow digital language documentation and description are created and managed,\nleading to an analysis of seven portability problems under the following\nheadings: content, format, discovery, access, citation, preservation and\nrights. After characterizing each problem we provide a series of value\nstatements, and this provides the framework for a broad range of best practice\nrecommendations."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/0205071v1", 
    "title": "A Scalable Architecture for Harvest-Based Digital Libraries - The   ODU/Southampton Experiments", 
    "arxiv-id": "cs/0205071v1", 
    "author": "Michael L. Nelson", 
    "publish": "2002-05-28T15:32:55Z", 
    "summary": "This paper discusses the requirements of current and emerging applications\nbased on the Open Archives Initiative (OAI) and emphasizes the need for a\ncommon infrastructure to support them. Inspired by HTTP proxy, cache, gateway\nand web service concepts, a design for a scalable and reliable infrastructure\nthat aims at satisfying these requirements is presented. Moreover it is shown\nhow various applications can exploit the services included in the proposed\ninfrastructure. The paper concludes by discussing the current status of several\nprototype implementations."
},{
    "category": "cs.CL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/0206007v1", 
    "title": "Using the Annotated Bibliography as a Resource for Indicative   Summarization", 
    "arxiv-id": "cs/0206007v1", 
    "author": "Kathleen R. McKeown", 
    "publish": "2002-06-04T14:48:48Z", 
    "summary": "We report on a language resource consisting of 2000 annotated bibliography\nentries, which is being analyzed as part of our research on indicative document\nsummarization. We show how annotated bibliographies cover certain aspects of\nsummarization that have not been well-covered by other summary corpora, and\nmotivate why they constitute an important form to study for information\nretrieval. We detail our methodology for collecting the corpus, and overview\nour document feature markup that we introduced to facilitate summary analysis.\nWe present the characteristics of the corpus, methods of collection, and show\nits use in finding the distribution of types of information included in\nindicative summaries and their relative ordering within the summaries."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2017.03.004", 
    "link": "http://arxiv.org/pdf/cs/0208010v1", 
    "title": "TerraService.NET: An Introduction to Web Services", 
    "arxiv-id": "cs/0208010v1", 
    "author": "Jeffrey Richter", 
    "publish": "2002-08-07T22:18:35Z", 
    "summary": "This article explores the design and construction of a geo-spatial Internet\nweb service application from the host web site perspective and from the\nperspective of an application using the web service. The TerraService.NET web\nservice was added to the popular TerraServer database and web site with no\nmajor structural changes to the database. The article discusses web service\ndesign, implementation, and deployment concepts and design guidelines. Web\nservices enable applications that aggregate and interact with information and\nresources from Internet-scale distributed servers. The article presents the\ndesign of two USDA applications that interoperate with database and web service\nresources in Fort Collins Colorado and the TerraService web service located in\nTukwila Washington."
},{
    "category": "cs.DC", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0208014v1", 
    "title": "Web Services for the Virtual Observatory", 
    "arxiv-id": "cs/0208014v1", 
    "author": "Ani Thakara", 
    "publish": "2002-08-07T22:58:37Z", 
    "summary": "Web Services form a new, emerging paradigm to handle distributed access to\nresources over the Internet. There are platform independent standards (SOAP,\nWSDL), which make the developers? task considerably easier. This article\ndiscusses how web services could be used in the context of the Virtual\nObservatory. We envisage a multi-layer architecture, with interoperating\nservices. A well-designed lower layer consisting of simple, standard services\nimplemented by most data providers will go a long way towards establishing a\nmodular architecture. More complex applications can be built upon this core\nlayer. We present two prototype applications, the SdssCutout and the SkyQuery\nas examples of this layered architecture."
},{
    "category": "cs.MM", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0210021v1", 
    "title": "Reconciling MPEG-7 and MPEG-21 Semantics through a Common Event-Aware   Metadata Model", 
    "arxiv-id": "cs/0210021v1", 
    "author": "Jane Hunter", 
    "publish": "2002-10-22T02:16:57Z", 
    "summary": "The \"event\" concept appears repeatedly when developing metadata models for\nthe description and management of multimedia content. During the typical life\ncycle of multimedia content, events occur at many different levels - from the\nevents which happen during content creation (directing, acting, camera panning\nand zooming) to the events which happen to the physical form (acquisition,\nrelocation, damage of film or video) to the digital conversion, reformatting,\nediting and repackaging events, to the events which are depicted in the actual\ncontent (political, news, sporting) to the usage, ownership and copyright\nagreement events and even the metadata attribution events. Support is required\nwithin both MPEG-7 and MPEG-21 for the clear and unambiguous description of all\nof these event types which may occur at widely different levels of nesting and\ngranularity. In this paper we first describe an event-aware model (the ABC\nmodel) which is capable of modeling and yet clearly differentiating between all\nof these, often recursive and overlapping events. We then illustrate how this\nmodel can be used as the foundation to facilitate semantic interoperability\nbetween MPEG-7 and MPEG-21. By expressing the semantics of both MPEG-7 and\nMPEG-21 metadata terms in RDF Schema (and some DAML+OIL extensions) and\nattaching the MPEG-7 and MPEG-21 class and property hierarchies to the\nappropriate top-level classes and properties of the ABC model, we are\nessentially able to define a single distributed machine-understandable\nontology, which will enable interoperability of data and services across the\nentire multimedia content delivery chain."
},{
    "category": "cs.IR", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0211041v1", 
    "title": "An Approach to Automatic Indexing of Scientific Publications in High   Energy Physics for Database SPIRES HEP", 
    "arxiv-id": "cs/0211041v1", 
    "author": "L. A. Vassilevskaya", 
    "publish": "2002-11-28T17:33:19Z", 
    "summary": "We introduce an approach to automatic indexing of e-prints based on a\npattern-matching technique making extensive use of an Associative Patterns\nDictionary (APD), developed by us. Entries in the APD consist of natural\nlanguage phrases with the same semantic interpretation as a set of keywords\nfrom a controlled vocabulary. The method also allows to recognize within\ne-prints formulae written in TeX notations that might also appear as keywords.\nWe present an automatic indexing system, AUTEX, which we have applied to\nkeyword index e-prints in selected areas in high energy physics (HEP) making\nuse of the DESY-HEPI thesaurus as a controlled vocabulary."
},{
    "category": "cs.CL", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0302021v1", 
    "title": "Building an Open Language Archives Community on the OAI Foundation", 
    "arxiv-id": "cs/0302021v1", 
    "author": "Steven Bird", 
    "publish": "2003-02-14T07:11:50Z", 
    "summary": "The Open Language Archives Community (OLAC) is an international partnership\nof institutions and individuals who are creating a worldwide virtual library of\nlanguage resources. The Dublin Core (DC) Element Set and the OAI Protocol have\nprovided a solid foundation for the OLAC framework. However, we need more\nprecision in community-specific aspects of resource description than is offered\nby DC. Furthermore, many of the institutions and individuals who might\nparticipate in OLAC do not have the technical resources to support the OAI\nprotocol. This paper presents our solutions to these two problems. To address\nthe first, we have developed an extensible application profile for language\nresource metadata. To address the second, we have implemented Vida (the virtual\ndata provider) and Viser (the virtual service provider), which permit community\nmembers to provide data and services without having to implement the OAI\nprotocol. These solutions are generic and could be adopted by other specialized\nsubcommunities."
},{
    "category": "cs.DC", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0303026v3", 
    "title": "Preserving Peer Replicas By Rate-Limited Sampled Voting in LOCKSS", 
    "arxiv-id": "cs/0303026v3", 
    "author": "Yanto Muliadi", 
    "publish": "2003-03-25T20:11:57Z", 
    "summary": "The LOCKSS project has developed and deployed in a world-wide test a\npeer-to-peer system for preserving access to journals and other archival\ninformation published on the Web. It consists of a large number of independent,\nlow-cost, persistent web caches that cooperate to detect and repair damage to\ntheir content by voting in \"opinion polls.\" Based on this experience, we\npresent a design for and simulations of a novel protocol for voting in systems\nof this kind. It incorporates rate limitation and intrusion detection to ensure\nthat even some very powerful adversaries attacking over many years have only a\nsmall probability of causing irrecoverable damage before being detected."
},{
    "category": "cs.DC", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0303033v3", 
    "title": "A Digital Preservation Appliance Based on OpenBSD", 
    "arxiv-id": "cs/0303033v3", 
    "author": "David S. H. Rosenthal", 
    "publish": "2003-03-30T18:46:46Z", 
    "summary": "The LOCKSS program has developed and deployed in a world-wide test a system\nfor preserving access to academic journals published on the Web. The\nfundamental problem for any digital preservation system is that it must be\naffordable for the long term. To reduce the cost of ownership, the LOCKSS\nsystem uses generic PC hardware, open source software, and peer-to-peer\ntechnology. It is packaged as a ``network appliance'', a single-function box\nthat can be connected to the Internet, configured and left alone to do its job\nwith minimal monitoring or administration. The first version of this system was\nbased on a Linux boot floppy. After three years of testing it was replaced by a\nsecond version, based on OpenBSD and booting from CD-ROM.\n  We focus in this paper on the design, implementation and deployment of a\nnetwork appliance based on an open source operating system. We provide an\noverview of the LOCKSS application and describe the experience of deploying and\nsupporting its first version. We list the requirements we took from this to\ndrive the design of the second version, describe how we satisfied them in the\nOpenBSD environment, and report on the initial"
},{
    "category": "cs.DL", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0305010v2", 
    "title": "The NPC Framework for Building Information Dissemination Networks", 
    "arxiv-id": "cs/0305010v2", 
    "author": "Lukas C. Faulstich", 
    "publish": "2003-05-14T09:49:05Z", 
    "summary": "Numerous systems for dissemination, retrieval, and archiving of documents\nhave been developed in the past. Those systems often focus on one of these\naspects and are hard to extend and combine. Typically, the transmission\nprotocols, query and filtering languages are fixed as well as the interfaces to\nother systems. We rather envisage the seamless establishment of networks among\nthe providers, repositories and consumers of information, supporting\ninformation retrieval and dissemination while being highly interoperable and\nextensible.\n  We propose a framework with a single event-based mechanism that unifies\ndocument storage, retrieval, and dissemination. This framework offers complete\nopenness with respect to document and metadata formats, transmission protocols,\nand filtering mechanisms. It specifies a high-level building kit, by which\narbitrary processors for document streams can be incorporated to support the\nretrieval, transformation, aggregation and disaggregation of documents. Using\nthe same kit, interfaces for different transmission protocols can be added\neasily to enable the communication with various information sources and\ninformation consumers."
},{
    "category": "cs.DL", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0305053v1", 
    "title": "Developing Open Data Models for Linguistic Field Data", 
    "arxiv-id": "cs/0305053v1", 
    "author": "Baden Hughes", 
    "publish": "2003-05-29T12:12:19Z", 
    "summary": "The UQ Flint Archive houses the field notes and elicitation recordings made\nby Elwyn Flint in the 1950's and 1960's during extensive linguistic survey work\nacross Queensland, Australia.\n  The process of digitizing the contents of the UQ Flint Archive provides a\nnumber of interesting challenges in the context of EMELD. Firstly, all of the\nlinguistic data is for languages which are either endangered or extinct, and as\nsuch forms a valuable ethnographic repository. Secondly, the physical format of\nthe data is itself in danger of decline, and as such digitization is an\nimportant preservation task in the short to medium term. Thirdly, the adoption\nof open standards for the encoding and presentation of text and audio data for\nlinguistic field data, whilst enabling preservation, represents a new field of\nresearch in itself where best practice has yet to be formalised. Fourthly, the\nprovision of this linguistic data online as a new data source for future\nresearch introduces concerns of data portability and longevity.\n  This paper will outline the origins of the data model, the content creation\ncomponents, presentation forms based on the data model, data capture tools and\nmedia conversion components. It will also address some of the larger questions\nregarding the digitization and annotation of linguistic field work based on\nexperience gained through work with the Flint Archive contents."
},{
    "category": "cs.CL", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0306040v1", 
    "title": "The Open Language Archives Community: An infrastructure for distributed   archiving of language resources", 
    "arxiv-id": "cs/0306040v1", 
    "author": "Steven Bird", 
    "publish": "2003-06-10T07:33:32Z", 
    "summary": "New ways of documenting and describing language via electronic media coupled\nwith new ways of distributing the results via the World-Wide Web offer a degree\nof access to language resources that is unparalleled in history. At the same\ntime, the proliferation of approaches to using these new technologies is\ncausing serious problems relating to resource discovery and resource creation.\nThis article describes the infrastructure that the Open Language Archives\nCommunity (OLAC) has built in order to address these problems. Its technical\nand usage infrastructures address problems of resource discovery by\nconstructing a single virtual library of distributed resources. Its governance\ninfrastructure addresses problems of resource creation by providing a mechanism\nthrough which the language-resource community can express its consensus on\nrecommended best practices."
},{
    "category": "cs.CL", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0308022v1", 
    "title": "Extending Dublin Core Metadata to Support the Description and Discovery   of Language Resources", 
    "arxiv-id": "cs/0308022v1", 
    "author": "Gary Simons", 
    "publish": "2003-08-14T23:28:21Z", 
    "summary": "As language data and associated technologies proliferate and as the language\nresources community expands, it is becoming increasingly difficult to locate\nand reuse existing resources. Are there any lexical resources for such-and-such\na language? What tool works with transcripts in this particular format? What is\na good format to use for linguistic data of this type? Questions like these\ndominate many mailing lists, since web search engines are an unreliable way to\nfind language resources. This paper reports on a new digital infrastructure for\ndiscovering language resources being developed by the Open Language Archives\nCommunity (OLAC). At the core of OLAC is its metadata format, which is designed\nto facilitate description and discovery of all kinds of language resources,\nincluding data, tools, or advice. The paper describes OLAC metadata, its\nrelationship to Dublin Core metadata, and its dissemination using the metadata\nharvesting protocol of the Open Archives Initiative."
},{
    "category": "cs.DS", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0308044v1", 
    "title": "EqRank: A Self-Consistent Equivalence Relation on Graph Vertexes", 
    "arxiv-id": "cs/0308044v1", 
    "author": "Sergei Trunov", 
    "publish": "2003-08-29T13:20:03Z", 
    "summary": "A new method of hierarchical clustering of graph vertexes is suggested. In\nthe method, the graph partition is determined with an equivalence relation\nsatisfying a recursive definition stating that vertexes are equivalent if the\nvertexes they point to (or vertexes pointing to them) are equivalent. Iterative\napplication of the partitioning yields a hierarchical clustering of graph\nvertexes. The method is applied to the citation graph of hep-th. The outcome is\na two-level classification scheme for the subject field presented in hep-th,\nand indexing of the papers from hep-th in this scheme. A number of tests show\nthat the classification obtained is adequate."
},{
    "category": "cs.CL", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0310041v1", 
    "title": "A Dynamic Programming Algorithm for the Segmentation of Greek Texts", 
    "arxiv-id": "cs/0310041v1", 
    "author": "Pavlina Fragkou", 
    "publish": "2003-10-21T18:19:52Z", 
    "summary": "In this paper we introduce a dynamic programming algorithm to perform linear\ntext segmentation by global minimization of a segmentation cost function which\nconsists of: (a) within-segment word similarity and (b) prior information about\nsegment length. The evaluation of the segmentation accuracy of the algorithm on\na text collection consisting of Greek texts showed that the algorithm achieves\nhigh segmentation accuracy and appears to be very innovating and promissing."
},{
    "category": "cs.CR", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0311005v1", 
    "title": "On The Cost Distribution of a Memory Bound Function", 
    "arxiv-id": "cs/0311005v1", 
    "author": "David S. H. Rosenthal", 
    "publish": "2003-11-06T18:54:01Z", 
    "summary": "Memory Bound Functions have been proposed for fighting spam, resisting Sybil\nattacks and other purposes. A particular implementation of such functions has\nbeen proposed in which the average effort required to generate a proof of\neffort is set by parameters E and l to E * l. The distribution of effort\nrequired to generate an individual proof about this average is fairly broad.\nWhen particular uses of these functions are envisaged, the choice of E and l,\nand the system design surrounding the generation and verification of proofs of\neffort, need to take the breadth of the distribution into account.\n  We show the distribution for this implementation, discuss the system design\nissues in the context of two proposed applications, and suggest an improved\nimplementation."
},{
    "category": "cs.CY", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0311054v1", 
    "title": "Copyright and Creativity: Authors and Photographers", 
    "arxiv-id": "cs/0311054v1", 
    "author": "Douglas A. Galbi", 
    "publish": "2003-11-28T19:33:55Z", 
    "summary": "The history of the occupations \"author\" and \"photographer\" provides an\ninsightful perspective on copyright and creativity. The concept of the romantic\nauthor, associated with personal creative genius, gained prominence in the\neighteenth century. However, in the U.S. in 1900 only about three thousand\npersons professed their occupation to be \"author.\" Self-professed\n\"photographers\" were then about ten times as numerous as authors. Being a\nphotographer was associated with manufacturing and depended only on mastering\ntechnical skills and making a living. Being an author, in contrast, was an\nelite status associated with science and literature. Across the twentieth\ncentury, the number of writers and authors grew much more rapidly than the\nnumber of photographers. The relative success of writers and authors in\ncreating jobs seems to have depended not on differences in copyright or\npossibilities for self-production, but on greater occupational innovation.\nCreativity in organizing daily work is an important form of creativity."
},{
    "category": "cs.HC", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0312010v1", 
    "title": "Designing of a Community-based Translation Center", 
    "arxiv-id": "cs/0312010v1", 
    "author": "Olga I. Padilla-Falto", 
    "publish": "2003-12-04T05:26:51Z", 
    "summary": "Interfaces that support multi-lingual content can reach a broader community.\nWe wish to extend the reach of CITIDEL, a digital library for computing\neducation materials, to support multiple languages. By doing so, we hope that\nit will increase the number of users, and in turn the number of resources. This\npaper discusses three approaches to translation (automated translation,\ndeveloper-based, and community-based), and a brief evaluation of these\napproaches. It proposes a design for an online community translation center\nwhere volunteers help translate interface components and educational materials\navailable in CITIDEL."
},{
    "category": "cs.IR", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0312033v1", 
    "title": "Using sensors in the web crawling process", 
    "arxiv-id": "cs/0312033v1", 
    "author": "Ilya Zemskov", 
    "publish": "2003-12-17T11:30:56Z", 
    "summary": "This paper offers a short description of an Internet information field\nmonitoring system, which places a special module-sensor on the side of the\nWeb-server to detect changes in information resources and subsequently\nreindexes only the resources signalized by the corresponding sensor. Concise\nresults of simulation research and an implementation attempt of the given\n\"sensors\" concept are provided."
},{
    "category": "cs.DL", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0401001v1", 
    "title": "Initial Experiences Re-Exporting Duplicate and Similarity Computation   with an OAI-PMH aggregator", 
    "arxiv-id": "cs/0401001v1", 
    "author": "Michael Nelson", 
    "publish": "2004-01-05T05:41:12Z", 
    "summary": "The proliferation of the Open Archive Initiative Protocol for Metadata\nHarvesting (OAI-PMH) has resulted in the creation of a large number of service\nproviders, all harvesting from either data providers or aggregators. If data\nwere available regarding the similarity of metadata records, service providers\ncould track redundant records across harvests from multiple sources as well as\nprovide additional end-user services. Due to the large number of metadata\nformats and the diverse mapping strategies employed by data providers,\nsimilarity calculation requirements necessitate the use of information\nretrieval strategies. We describe an OAI-PMH aggregator implementation that\nuses the optional ``<about>'' container to re-export the results of similarity\ncalculations. Metadata records (3751) were harvested from a NASA data provider\nand similarities for the records were computed. The results were useful for\ndetecting duplicates, similarities and metadata errors."
},{
    "category": "cs.HC", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0401007v1", 
    "title": "Design of a Community-based Translation Center", 
    "arxiv-id": "cs/0401007v1", 
    "author": "O. I. Padilla-Falto", 
    "publish": "2004-01-12T18:45:47Z", 
    "summary": "Interfaces that support multi-lingual content can reach a broader community.\nWe wish to extend the reach of CITIDEL, a digital library for computing\neducation materials, to support multiple languages. By doing so, we hope that\nit will increase the number of users, and in turn the number of resources. This\npaper discusses three approaches to translation (automated translation,\ndeveloper-based, and community-based), and a brief evaluation of these\napproaches. It proposes a design for an online community translation center\nwhere volunteers help translate interface components and educational materials\navailable in CITIDEL."
},{
    "category": "cs.DL", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0402022v1", 
    "title": "Automatically Generating Interfaces for Personalized Interaction with   Digital Libraries", 
    "arxiv-id": "cs/0402022v1", 
    "author": "Edward A. Fox", 
    "publish": "2004-02-12T03:00:14Z", 
    "summary": "We present an approach to automatically generate interfaces supporting\npersonalized interaction with digital libraries; these interfaces augment the\nuser-DL dialog by empowering the user to (optionally) supply out-of-turn\ninformation during an interaction, flatten or restructure the dialog, and\nenquire about dialog options. Interfaces generated using this approach for\nCITIDEL are described."
},{
    "category": "cs.NI", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0403036v1", 
    "title": "Domain resource integration system", 
    "arxiv-id": "cs/0403036v1", 
    "author": "Fang Ming", 
    "publish": "2004-03-23T09:30:37Z", 
    "summary": "Domain Resource Integrated System (DRIS) is introduced in this paper. DRIS is\na hierarchical distributed Internet information retrieval system. This system\nwill solve some bottleneck problems such as long update interval, poor coverage\nin current web search system. DRIS will build the information retrieval\ninfrastructure of Internet, but not a commercial search engine. The protocol\nseries of DRIS are also detailed in this paper."
},{
    "category": "cs.DL", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0408054v1", 
    "title": "Providing Authentic Long-term Archival Access to Complex Relational Data", 
    "arxiv-id": "cs/0408054v1", 
    "author": "Frank Moehle", 
    "publish": "2004-08-24T07:01:29Z", 
    "summary": "We discuss long-term preservation of and access to relational databases. The\nfocus is on national archives and science data archives which have to ingest\nand integrate data from a broad spectrum of vendor-specific relational database\nmanagement systems (RDBMS). Furthermore, we present our solution SIARD which\nanalyzes and extracts data and data logic from almost any RDBMS. It enables, to\na reasonable level of authenticity, complete detachment of databases from their\nvendor-specific environment. The user can add archival descriptive metadata\naccording to a customizable schema. A SIARD database archive integrates data,\ndata logic, technical metadata, and archival descriptive information in one\narchival information package, independent of any specific software and\nhardware, based upon plain text files and the standardized languages SQL and\nXML. For usage purposes, a SIARD archive can be reloaded into any current or\nfuture RDBMS which supports standard SQL. In addition, SIARD contains a client\nthat enables 'on demand' reload of archives into a target RDBMS, and multi-user\nremote access for querying and browsing the data together with its technical\nand descriptive metadata in one graphical user interface."
},{
    "category": "cs.CY", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0409055v1", 
    "title": "The Building of Online Communities: An approach for learning   organizations, with a particular focus on the museum sector", 
    "arxiv-id": "cs/0409055v1", 
    "author": "Silvia Filippini-Fantoni", 
    "publish": "2004-09-28T18:10:45Z", 
    "summary": "This paper considers the move toward and potential of building online\ncommunities, with a particular focus on the museum sector. For instance, the\nincrease in the use of `personalized' toolkits that are becoming an integral\npart of the online presence for learning organizations, like museums, can\nprovide a basis for creating and sustaining communities. A set of case studies\nfurther illustrates working examples of the ways in which personalization and\nspecific tools are developing collaborative spaces, community channels and\ngroup interactions."
},{
    "category": "cs.DL", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0412019v1", 
    "title": "A Link Clustering Based Approach for Clustering Categorical Data", 
    "arxiv-id": "cs/0412019v1", 
    "author": "Shengchun Deng", 
    "publish": "2004-12-04T12:41:08Z", 
    "summary": "Categorical data clustering (CDC) and link clustering (LC) have been\nconsidered as separate research and application areas. The main focus of this\npaper is to investigate the commonalities between these two problems and the\nuses of these commonalities for the creation of new clustering algorithms for\ncategorical data based on cross-fertilization between the two disjoint research\nfields. More precisely, we formally transform the CDC problem into an LC\nproblem, and apply LC approach for clustering categorical data. Experimental\nresults on real datasets show that LC based clustering method is competitive\nwith existing CDC algorithms with respect to clustering accuracy."
},{
    "category": "cs.DL", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0501012v6", 
    "title": "Fedora: An Architecture for Complex Objects and their Relationships", 
    "arxiv-id": "cs/0501012v6", 
    "author": "Chris Wilper", 
    "publish": "2005-01-07T17:57:05Z", 
    "summary": "The Fedora architecture is an extensible framework for the storage,\nmanagement, and dissemination of complex objects and the relationships among\nthem. Fedora accommodates the aggregation of local and distributed content into\ndigital objects and the association of services with objects. This al-lows an\nobject to have several accessible representations, some of them dy-namically\nproduced. The architecture includes a generic RDF-based relation-ship model\nthat represents relationships among objects and their components. Queries\nagainst these relationships are supported by an RDF triple store. The\narchitecture is implemented as a web service, with all aspects of the complex\nobject architecture and related management functions exposed through REST and\nSOAP interfaces. The implementation is available as open-source soft-ware,\nproviding the foundation for a variety of end-user applications for digital\nlibraries, archives, institutional repositories, and learning object systems."
},{
    "category": "cs.DL", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0501019v1", 
    "title": "Clustering SPIRES with EqRank", 
    "arxiv-id": "cs/0501019v1", 
    "author": "S. E. Trunov", 
    "publish": "2005-01-11T05:00:03Z", 
    "summary": "SPIRES is the largest database of scientific papers in the subject field of\nhigh energy and nuclear physics. It contains information on the citation graph\nof more than half a million of papers (vertexes of the citation graph). We\noutline the EqRank algorithm designed to cluster vertexes of directed graphs,\nand present the results of EqRank application to the SPIRES citation graph. The\nhierarchical clustering of SPIRES yielded by EqRank is used to set up a web\nservice, which is also outlined."
},{
    "category": "cs.IR", 
    "doi": "10.1117/12.463947", 
    "link": "http://arxiv.org/pdf/cs/0504036v1", 
    "title": "Scientific impact quantity and quality: Analysis of two sources of   bibliographic data", 
    "arxiv-id": "cs/0504036v1", 
    "author": "Richard K. Belew", 
    "publish": "2005-04-11T13:52:55Z", 
    "summary": "Attempts to understand the consequence of any individual scientist's activity\nwithin the long-term trajectory of science is one of the most difficult\nquestions within the philosophy of science. Because scientific publications\nplay such as central role in the modern enterprise of science, bibliometric\ntechniques which measure the ``impact'' of an individual publication as a\nfunction of the number of citations it receives from subsequent authors have\nprovided some of the most useful empirical data on this question. Until\nrecently, Thompson/ISI has provided the only source of large-scale ``inverted''\nbibliographic data of the sort required for impact analysis. In the end of\n2004, Google introduced a new service, GoogleScholar, making much of this same\ndata available. Here we analyze 203 publications, collectively cited by more\nthan 4000 other publications. We show surprisingly good agreement between data\ncitation counts provided by the two services. Data quality across the systems\nis analyzed, and potentially useful complementarities between are considered.\nThe additional robustness offered by multiple sources of such data promises to\nincrease the utility of these measurements as open citation protocols and open\naccess increase their impact on electronic scientific publication practices."
},{
    "category": "cs.DL", 
    "doi": "10.1177/0165551506062327", 
    "link": "http://arxiv.org/pdf/cs/0504084v3", 
    "title": "The Convergence of Digital-Libraries and the Peer-Review Process", 
    "arxiv-id": "cs/0504084v3", 
    "author": "Herbert Van de Sompel", 
    "publish": "2005-04-18T14:28:12Z", 
    "summary": "Pre-print repositories have seen a significant increase in use over the past\nfifteen years across multiple research domains. Researchers are beginning to\ndevelop applications capable of using these repositories to assist the\nscientific community above and beyond the pure dissemination of information.\nThe contribution set forth by this paper emphasizes a deconstructed publication\nmodel in which the peer-review process is mediated by an OAI-PMH peer-review\nservice. This peer-review service uses a social-network algorithm to determine\npotential reviewers for a submitted manuscript and for weighting the relative\ninfluence of each participating reviewer's evaluations. This paper also\nsuggests a set of peer-review specific metadata tags that can accompany a\npre-print's existing metadata record. The combinations of these contributions\nprovide a unique repository-centric peer-review model that fits within the\nwidely deployed OAI-PMH framework."
},{
    "category": "cs.DL", 
    "doi": "10.1177/0165551506062327", 
    "link": "http://arxiv.org/pdf/cs/0507028v1", 
    "title": "Adapting CBPP platforms for instructional use", 
    "arxiv-id": "cs/0507028v1", 
    "author": "Aaron Krowne", 
    "publish": "2005-07-10T19:05:26Z", 
    "summary": "Commons based peer-production (CBPP) is the de-centralized, net-based\napproach to the creation and dissemination of information resources. Underlying\nevery CBPP system is a virtual community brought together by an internet tool\n(such as a web site) and structured by a specific collaboration protocol. In\nthis talk we will argue that the value of such platforms can be leveraged by\nadapting them for pedagogical purposes.\n  We report on one such recent adaptation. The Noosphere system is a web-based\ncollaboration environment that underlies the popular Planetmath website, a\ncollaboratively written encyclopedia of mathematics licensed under the GNU Free\nDocumentation License (FDL). Recently, the system was used to host a\ngraduate-level mathematics course at Dalhousie University, in Halifax, Canada.\nThe course consisted of regular lectures and assignment problems. The students\nin the course collaborated on a set of course notes, encapsulating the lecture\ncontent and giving solutions of assigned problems. The successful outcome of\nthis experiment demonstrated that a dedicated Noosphere system is well suited\nfor classroom applications. We argue that this ``proof of concept'' experience\nalso strongly suggests that every successful CBPP platform possesses latent\npedagogical value."
},{
    "category": "cs.DL", 
    "doi": "10.1177/0165551506062327", 
    "link": "http://arxiv.org/pdf/cs/0508065v1", 
    "title": "Representing Digital Assets using MPEG-21 Digital Item Declaration", 
    "arxiv-id": "cs/0508065v1", 
    "author": "Herbert Van de Sompel", 
    "publish": "2005-08-13T03:09:25Z", 
    "summary": "Various XML-based approaches aimed at representing compound digital assets\nhave emerged over the last several years. Approaches that are of specific\nrelevance to the digital library community include the Metadata Encoding and\nTransmission Standard (METS), the IMS Content Packaging XML Binding, and the\nXML Formatted Data Units (XFDU) developed by CCSDS Panel 2. The MPEG-21 Digital\nItem Declaration (MPEG-21 DID) is another standard specifying the\nrepresentation of digital assets in XML that, so far, has received little\nattention in the digital library community. This article gives a brief insight\ninto the MPEG-21 standardization effort, highlights the major characteristics\nof the MPEG-21 DID Abstract Model, and describes the MPEG-21 Digital Item\nDeclaration Language (MPEG-21 DIDL), an XML syntax for the representation of\ndigital assets based on the MPEG-21 DID Abstract Model. Also, it briefly\ndemonstrates the potential relevance of MPEG-21 DID to the digital library\ncommunity by describing its use in the aDORe repository environment at the\nResearch Library of the Los Alamos National Laboratory (LANL) for the\nrepresentation of digital assets."
},{
    "category": "cs.CY", 
    "doi": "10.1177/0165551506062327", 
    "link": "http://arxiv.org/pdf/cs/0508067v1", 
    "title": "Copyright and Promotion: Oxymoron or Opportunity?", 
    "arxiv-id": "cs/0508067v1", 
    "author": "Jonathan P. Bowen", 
    "publish": "2005-08-13T14:58:07Z", 
    "summary": "Copyright in the cultural sphere can act as a barrier to the dissemination of\nhigh-quality information. On the other hand it protects works of art that might\nnot be made available otherwise. This dichotomy makes the area of copyright\ndifficult, especially when it applies to the digital arena of the web where\ncopying is so easy and natural. Here we present a snapshot of the issues for\nonline copyright, with particular emphasis on the relevance to cultural\ninstitutions. We concentrate on Europe and the US; as an example we include a\nspecial section dedicated to the situation in Italy."
},{
    "category": "cs.DL", 
    "doi": "10.1177/0165551506062327", 
    "link": "http://arxiv.org/pdf/cs/0508082v1", 
    "title": "The Structure of Collaborative Tagging Systems", 
    "arxiv-id": "cs/0508082v1", 
    "author": "Bernardo A. Huberman", 
    "publish": "2005-08-18T18:34:19Z", 
    "summary": "Collaborative tagging describes the process by which many users add metadata\nin the form of keywords to shared content. Recently, collaborative tagging has\ngrown in popularity on the web, on sites that allow users to tag bookmarks,\nphotographs and other content. In this paper we analyze the structure of\ncollaborative tagging systems as well as their dynamical aspects. Specifically,\nwe discovered regularities in user activity, tag frequencies, kinds of tags\nused, bursts of popularity in bookmarking and a remarkable stability in the\nrelative proportions of tags within a given url. We also present a dynamical\nmodel of collaborative tagging that predicts these stable patterns and relates\nthem to imitation and shared knowledge."
},{
    "category": "cs.DL", 
    "doi": "10.1177/0165551506062327", 
    "link": "http://arxiv.org/pdf/cs/0509094v2", 
    "title": "Telling Great Stories: An NSDL Content and Communications System for   Aggregation, Display, and Distribution of News and Features", 
    "arxiv-id": "cs/0509094v2", 
    "author": "Carol Minton Morris", 
    "publish": "2005-09-28T16:28:19Z", 
    "summary": "Education digital libraries contain cataloged resources as well as contextual\ninformation about innovations in the use of educational technology, exemplar\nstories about community activities, and news from various user communities that\ninclude teachers, students, scholars, and developers. Long-standing library\ntraditions of service, preservation, democratization of knowledge, rich\ndiscourse, equal access, and fair use are evident in library communications\nmodels that both pull in and push out contextual information from multiple\nsources integrated with editorial production processes. This paper argues that\na dynamic narrative flow [1] is enabled by effective management of complex\ncontent and communications in a decentralized web-based education digital\nlibrary making publishing objects such as aggregations of resources, or\nselected parts of objects [4] accessible through a Content and Communications\nSystem. Providing services that encourage patrons to reuse, reflect out, and\ncontribute resources back [5] to the Library increases the reach and impact of\nthe National Science Digital Library (NSDL). This system is a model for\ndistributed content development and effective communications for education\ndigital libraries in general."
},{
    "category": "cs.IR", 
    "doi": "10.1177/0165551506062327", 
    "link": "http://arxiv.org/pdf/cs/0511002v1", 
    "title": "Bibliographic Classification using the ADS Databases", 
    "arxiv-id": "cs/0511002v1", 
    "author": "Stephen S. Murray", 
    "publish": "2005-10-31T22:34:34Z", 
    "summary": "We discuss two techniques used to characterize bibliographic records based on\ntheir similarity to and relationship with the contents of the NASA Astrophysics\nData System (ADS) databases. The first method has been used to classify input\ntext as being relevant to one or more subject areas based on an analysis of the\nfrequency distribution of its individual words. The second method has been used\nto classify existing records as being relevant to one or more databases based\non the distribution of the papers citing them. Both techniques have proven to\nbe valuable tools in assigning new and existing bibliographic records to\ndifferent disciplines within the ADS databases."
},{
    "category": "cs.DS", 
    "doi": "10.1177/0165551506062327", 
    "link": "http://arxiv.org/pdf/cs/0512080v1", 
    "title": "EqRank: Theme Evolution in Citation Graphs", 
    "arxiv-id": "cs/0512080v1", 
    "author": "S. E. Trunov", 
    "publish": "2005-12-20T14:01:45Z", 
    "summary": "Time evolution of the classification scheme generated by the EqRank algorithm\nis studied with hep-th citation graph as an example. Intuitive expectations\nabout evolution of an adequate classification scheme for a growing set of\nobjects are formulated. Evolution compliant with these expectations is called\nnatural. It is demonstrated that EqRank yields a naturally evolving\nclassification scheme. We conclude that EqRank can be used as a means to detect\nnew scientific themes, and to track their development."
},{
    "category": "cs.DS", 
    "doi": "10.1007/11758532_152", 
    "link": "http://arxiv.org/pdf/cs/0512090v2", 
    "title": "Collaborative tagging as a tripartite network", 
    "arxiv-id": "cs/0512090v2", 
    "author": "M. Ausloos", 
    "publish": "2005-12-23T13:38:57Z", 
    "summary": "We describe online collaborative communities by tripartite networks, the\nnodes being persons, items and tags. We introduce projection methods in order\nto uncover the structures of the networks, i.e. communities of users, genre\nfamilies...\n  To do so, we focus on the correlations between the nodes, depending on their\nprofiles, and use percolation techniques that consist in removing less\ncorrelated links and observing the shaping of disconnected islands. The\nstructuring of the network is visualised by using a tree representation. The\nnotion of diversity in the system is also discussed."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-006-0176-z", 
    "link": "http://arxiv.org/pdf/cs/0601030v1", 
    "title": "Journal Status", 
    "arxiv-id": "cs/0601030v1", 
    "author": "Herbert Van de Sompel", 
    "publish": "2006-01-09T16:56:01Z", 
    "summary": "The status of an actor in a social context is commonly defined in terms of\ntwo factors: the total number of endorsements the actor receives from other\nactors and the prestige of the endorsing actors. These two factors indicate the\ndistinction between popularity and expert appreciation of the actor,\nrespectively. We refer to the former as popularity and to the latter as\nprestige. These notions of popularity and prestige also apply to the domain of\nscholarly assessment. The ISI Impact Factor (ISI IF) is defined as the mean\nnumber of citations a journal receives over a 2 year period. By merely counting\nthe amount of citations and disregarding the prestige of the citing journals,\nthe ISI IF is a metric of popularity, not of prestige. We demonstrate how a\nweighted version of the popular PageRank algorithm can be used to obtain a\nmetric that reflects prestige. We contrast the rankings of journals according\nto their ISI IF and their weighted PageRank, and we provide an analysis that\nreveals both significant overlaps and differences. Furthermore, we introduce\nthe Y-factor which is a simple combination of both the ISI IF and the weighted\nPageRank, and find that the resulting journal rankings correspond well to a\ngeneral understanding of journal status."
},{
    "category": "cs.IR", 
    "doi": "10.1002/asi.20405", 
    "link": "http://arxiv.org/pdf/cs/0602060v1", 
    "title": "eJournal interface can influence usage statistics: implications for   libraries, publishers, and Project COUNTER", 
    "arxiv-id": "cs/0602060v1", 
    "author": "Jason S. Price", 
    "publish": "2006-02-16T20:29:25Z", 
    "summary": "The design of a publisher's electronic interface can have a measurable effect\non electronic journal usage statistics. A study of journal usage from six\nCOUNTER-compliant publishers at thirty-two research institutions in the United\nStates, the United Kingdom and Sweden indicates that the ratio of PDF to HTML\nviews is not consistent across publisher interfaces, even after controlling for\ndifferences in publisher content. The number of fulltext downloads may be\nartificially inflated when publishers require users to view HTML versions\nbefore accessing PDF versions or when linking mechanisms, such as CrossRef,\ndirect users to the full text, rather than the abstract, of each article. These\nresults suggest that usage reports from COUNTER-compliant publishers are not\ndirectly comparable in their current form. One solution may be to modify\npublisher numbers with adjustment factors deemed to be representative of the\nbenefit or disadvantage due to its interface. Standardization of some interface\nand linking protocols may obviate these differences and allow for more accurate\ncross-publisher comparisons."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20405", 
    "link": "http://arxiv.org/pdf/cs/0602082v1", 
    "title": "Digital Libraries: From Process Modelling to Grid-based Service Oriented   Architecture", 
    "arxiv-id": "cs/0602082v1", 
    "author": "Richard McClatchey", 
    "publish": "2006-02-23T23:12:39Z", 
    "summary": "Graphical Business Process Modelling Languages (BPML) like Role Activity\nDiagrams (RAD) provide ease and flexibility for modelling business behaviour.\nHowever, these languages show limited applicability in terms of enactment over\ndistributed systems paradigms like Service Oriented Architecture (SOA) based\ngrid computing. This paper investigates RAD modelling of a Scientific\nPublishing Process (SPP) for Digital Libraries (DL) and tries to determine the\nsuitability of Pi-Calculus based formal approaches to enact SOA based grid\ncomputing. In order to achieve this purpose, the Pi-Calculus based formal\ntransformation from a RAD model of SPP for DL draws attention towards a number\nof challenging issues including issues that require particular design\nconsiderations for appropriate enactment in a SOA based grid system."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20405", 
    "link": "http://arxiv.org/pdf/cs/0603073v1", 
    "title": "VXA: A Virtual Architecture for Durable Compressed Archives", 
    "arxiv-id": "cs/0603073v1", 
    "author": "Bryan Ford", 
    "publish": "2006-03-18T16:31:33Z", 
    "summary": "Data compression algorithms change frequently, and obsolete decoders do not\nalways run on new hardware and operating systems, threatening the long-term\nusability of content archived using those algorithms. Re-encoding content into\nnew formats is cumbersome, and highly undesirable when lossy compression is\ninvolved. Processor architectures, in contrast, have remained comparatively\nstable over recent decades. VXA, an archival storage system designed around\nthis observation, archives executable decoders along with the encoded content\nit stores. VXA decoders run in a specialized virtual machine that implements an\nOS-independent execution environment based on the standard x86 architecture.\nThe VXA virtual machine strictly limits access to host system services, making\ndecoders safe to run even if an archive contains malicious code. VXA's adoption\nof a \"native\" processor architecture instead of type-safe language technology\nallows reuse of existing \"hand-optimized\" decoders in C and assembly language,\nand permits decoders access to performance-enhancing architecture features such\nas vector processing instructions. The performance cost of VXA's virtualization\nis typically less than 15% compared with the same decoders running natively.\nThe storage cost of archived decoders, typically 30-130KB each, can be\namortized across many archived files sharing the same compression method."
},{
    "category": "cs.IR", 
    "doi": "10.1002/asi.20405", 
    "link": "http://arxiv.org/pdf/cs/0604036v2", 
    "title": "Collaborative thesaurus tagging the Wikipedia way", 
    "arxiv-id": "cs/0604036v2", 
    "author": "Jakob Voss", 
    "publish": "2006-04-10T12:04:29Z", 
    "summary": "This paper explores the system of categories that is used to classify\narticles in Wikipedia. It is compared to collaborative tagging systems like\ndel.icio.us and to hierarchical classification like the Dewey Decimal\nClassification (DDC). Specifics and commonalitiess of these systems of subject\nindexing are exposed. Analysis of structural and statistical properties\n(descriptors per record, records per descriptor, descriptor levels) shows that\nthe category system of Wikimedia is a thesaurus that combines collaborative\ntagging and hierarchical subject indexing in a special way."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20405", 
    "link": "http://arxiv.org/pdf/cs/0604061v2", 
    "title": "Effect of E-printing on Citation Rates in Astronomy and Physics", 
    "arxiv-id": "cs/0604061v2", 
    "author": "Stephen S. Murray", 
    "publish": "2006-04-13T22:02:05Z", 
    "summary": "In this report we examine the change in citation behavior since the\nintroduction of the arXiv e-print repository (Ginsparg, 2001). It has been\nobserved that papers that initially appear as arXiv e-prints get cited more\nthan papers that do not (Lawrence, 2001; Brody et al., 2004; Schwarz &\nKennicutt, 2004; Kurtz et al., 2005a, Metcalfe, 2005). Using the citation\nstatistics from the NASA-Smithsonian Astrophysics Data System (ADS; Kurtz et\nal., 1993, 2000), we confirm the findings from other studies, we examine the\naverage citation rate to e-printed papers in the Astrophysical Journal, and we\nshow that for a number of major astronomy and physics journals the most\nimportant papers are submitted to the arXiv e-print repository first."
},{
    "category": "cs.DB", 
    "doi": "10.1117/12.671721", 
    "link": "http://arxiv.org/pdf/cs/0604112v1", 
    "title": "Designing a Multi-petabyte Database for LSST", 
    "arxiv-id": "cs/0604112v1", 
    "author": "Jim Gray", 
    "publish": "2006-04-28T03:04:00Z", 
    "summary": "The 3.2 giga-pixel LSST camera will produce approximately half a petabyte of\narchive images every month. These data need to be reduced in under a minute to\nproduce real-time transient alerts, and then added to the cumulative catalog\nfor further analysis. The catalog is expected to grow about three hundred\nterabytes per year. The data volume, the real-time transient alerting\nrequirements of the LSST, and its spatio-temporal aspects require innovative\ntechniques to build an efficient data access system at reasonable cost. As\ncurrently envisioned, the system will rely on a database for catalogs and\nmetadata. Several database systems are being evaluated to understand how they\nperform at these data rates, data volumes, and access patterns. This paper\ndescribes the LSST requirements, the challenges they impose, the data access\nphilosophy, results to date from evaluating available database technologies\nagainst LSST requirements, and the proposed database architecture to meet the\ndata challenges."
},{
    "category": "cs.DB", 
    "doi": "10.1117/12.671721", 
    "link": "http://arxiv.org/pdf/cs/0605127v1", 
    "title": "Analyzing Large Collections of Electronic Text Using OLAP", 
    "arxiv-id": "cs/0605127v1", 
    "author": "Daniel Lemire", 
    "publish": "2006-05-27T00:51:46Z", 
    "summary": "Computer-assisted reading and analysis of text has various applications in\nthe humanities and social sciences. The increasing size of many electronic text\narchives has the advantage of a more complete analysis but the disadvantage of\ntaking longer to obtain results. On-Line Analytical Processing is a method used\nto store and quickly analyze multidimensional data. By storing text analysis\ninformation in an OLAP system, a user can obtain solutions to inquiries in a\nmatter of seconds as opposed to minutes, hours, or even days. This analysis is\nuser-driven allowing various users the freedom to pursue their own direction of\nresearch."
},{
    "category": "cs.DL", 
    "doi": "10.1117/12.671721", 
    "link": "http://arxiv.org/pdf/cs/0608004v1", 
    "title": "Separating the articles of authors with the same name", 
    "arxiv-id": "cs/0608004v1", 
    "author": "Jose M. Soler", 
    "publish": "2006-08-01T18:23:26Z", 
    "summary": "I describe a method to separate the articles of different authors with the\nsame name. It is based on a distance between any two publications, defined in\nterms of the probability that they would have as many coincidences if they were\ndrawn at random from all published documents. Articles with a given author name\nare then clustered according to their distance, so that all articles in a\ncluster belong very likely to the same author. The method has proven very\nuseful in generating groups of papers that are then selected manually. This\nsimplifies considerably citation analysis when the author publication lists are\nnot available."
},{
    "category": "cs.DL", 
    "doi": "10.1117/12.671721", 
    "link": "http://arxiv.org/pdf/cs/0608027v1", 
    "title": "myADS-arXiv - a Tailor-Made, Open Access, Virtual Journal", 
    "arxiv-id": "cs/0608027v1", 
    "author": "S. S. Murray", 
    "publish": "2006-08-04T15:23:32Z", 
    "summary": "The myADS-arXiv service provides the scientific community with a one stop\nshop for staying up-to-date with a researcher's field of interest. The service\nprovides a powerful and unique filter on the enormous amount of bibliographic\ninformation added to the ADS on a daily basis. It also provides a complete view\nwith the most relevant papers available in the subscriber's field of interest.\nWith this service, the subscriber will get to know the lastest developments,\npopular trends and the most important papers. This makes the service not only\nunique from a technical point of view, but also from a content point of view.\nOn this poster we will argue why myADS-arXiv is a tailor-made, open access,\nvirtual journal and we will illustrate its unique character."
},{
    "category": "cs.DL", 
    "doi": "10.1087/095315107779490661", 
    "link": "http://arxiv.org/pdf/cs/0609126v1", 
    "title": "E-prints and Journal Articles in Astronomy: a Productive Co-existence", 
    "arxiv-id": "cs/0609126v1", 
    "author": "Stephen S. Murray", 
    "publish": "2006-09-22T14:16:00Z", 
    "summary": "Are the e-prints (electronic preprints) from the arXiv repository being used\ninstead of the journal articles? In this paper we show that the e-prints have\nnot undermined the usage of journal papers in the astrophysics community. As\nsoon as the journal article is published, the astronomical community prefers to\nread the journal article and the use of e-prints through the NASA Astrophysics\nData System drops to zero. This suggests that the majority of astronomers have\naccess to institutional subscriptions and that they choose to read the journal\narticle when given the choice. Within the NASA Astrophysics Data System they\nare given this choice, because the e-print and the journal article are treated\nequally, since both are just one click away. In other words, the e-prints have\nnot undermined journal use in the astrophysics community and thus currently do\nnot pose a financial threat to the publishers. We present readership data for\nthe arXiv category \"astro-ph\" and the 4 core journals in astronomy\n(Astrophysical Journal, Astronomical Journal, Monthly Notices of the Royal\nAstronomical Society and Astronomy & Astrophysics). Furthermore, we show that\nthe half-life (the point where the use of an article drops to half the use of a\nnewly published article) for an e-print is shorter than for a journal paper.\n  The ADS is funded by NASA Grant NNG06GG68G. arXiv receives funding from NSF\naward #0404553"
},{
    "category": "cs.DL", 
    "doi": "10.1087/095315107779490661", 
    "link": "http://arxiv.org/pdf/cs/0610029v1", 
    "title": "Data in the ADS -- Understanding How to Use it Better", 
    "arxiv-id": "cs/0610029v1", 
    "author": "Stephen S. Murray", 
    "publish": "2006-10-05T18:51:54Z", 
    "summary": "The Smithsonian/NASA ADS Abstract Service contains a wealth of data for\nastronomers and librarians alike, yet the vast majority of usage consists of\nrudimentary searches. Hints on how to obtain more focused search results by\nusing more of the various capabilities of the ADS are presented, including\nsearching by affiliation. We also discuss the classification of articles by\ncontent and by referee status.\n  The ADS is funded by NASA Grant NNG06GG68G-16613687."
},{
    "category": "cs.DL", 
    "doi": "10.1087/095315107779490661", 
    "link": "http://arxiv.org/pdf/cs/0610030v1", 
    "title": "Paper to Screen: Processing Historical Scans in the ADS", 
    "arxiv-id": "cs/0610030v1", 
    "author": "Stephen S. Murray", 
    "publish": "2006-10-05T18:58:26Z", 
    "summary": "The NASA Astrophysics Data System in conjunction with the Wolbach Library at\nthe Harvard-Smithsonian Center for Astrophysics is working on a project to\nmicrofilm historical observatory publications. The microfilm is then scanned\nfor inclusion in the ADS. The ADS currently contains over 700,000 scanned pages\nof volumes of historical literature. Many of these volumes lack clear\npagination or other bibliographic data that are necessary to take advantage of\nthe searching capabilities of the ADS. This paper will address some of the\ninteresting challenges that needed to be resolved during the processing of the\nObservatory Reports included in the ADS."
},{
    "category": "cs.DL", 
    "doi": "10.1087/095315107779490661", 
    "link": "http://arxiv.org/pdf/cs/0611068v2", 
    "title": "Wikipedia: organisation from a bottom-up approach", 
    "arxiv-id": "cs/0611068v2", 
    "author": "H. Jaap van den Herik", 
    "publish": "2006-11-15T10:27:09Z", 
    "summary": "Wikipedia can be considered as an extreme form of a self-managing team, as a\nmeans of labour division. One could expect that this bottom-up approach, with\nthe absense of top-down organisational control, would lead to a chaos, but our\nanalysis shows that this is not the case. In the Dutch Wikipedia, an integrated\nand coherent data structure is created, while at the same time users succeed in\ndistributing roles by self-selection. Some users focus on an area of expertise,\nwhile others edit over the whole encyclopedic range. This constitutes our\nconclusion that Wikipedia, in general, is a successful example of a\nself-managing team."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-008-1778-4", 
    "link": "http://arxiv.org/pdf/cs/0612091v2", 
    "title": "Bias in the journal impact factor", 
    "arxiv-id": "cs/0612091v2", 
    "author": "Jerome K Vanclay", 
    "publish": "2006-12-19T00:17:03Z", 
    "summary": "The ISI journal impact factor (JIF) is based on a sample that may represent\nhalf the whole-of-life citations to some journals, but a small fraction (<10%)\nof the citations accruing to other journals. This disproportionate sampling\nmeans that the JIF provides a misleading indication of the true impact of\njournals, biased in favour of journals that have a rapid rather than a\nprolonged impact. Many journals exhibit a consistent pattern of citation\naccrual from year to year, so it may be possible to adjust the JIF to provide a\nmore reliable indication of a journal's impact."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-008-1778-4", 
    "link": "http://arxiv.org/pdf/cs/0612132v1", 
    "title": "A New Era in Citation and Bibliometric Analyses: Web of Science, Scopus,   and Google Scholar", 
    "arxiv-id": "cs/0612132v1", 
    "author": "Kiduk Yang", 
    "publish": "2006-12-23T14:47:24Z", 
    "summary": "Academic institutions, federal agencies, publishers, editors, authors, and\nlibrarians increasingly rely on citation analysis for making hiring, promotion,\ntenure, funding, and/or reviewer and journal evaluation and selection\ndecisions. The Institute for Scientific Information's (ISI) citation databases\nhave been used for decades as a starting point and often as the only tools for\nlocating citations and/or conducting citation analyses. ISI databases (or Web\nof Science), however, may no longer be adequate as the only or even the main\nsources of citations because new databases and tools that allow citation\nsearching are now available. Whether these new databases and tools complement\nor represent alternatives to Web of Science (WoS) is important to explore.\nUsing a group of 15 library and information science faculty members as a case\nstudy, this paper examines the effects of using Scopus and Google Scholar (GS)\non the citation counts and rankings of scholars as measured by WoS. The paper\ndiscusses the strengths and weaknesses of WoS, Scopus, and GS, their overlap\nand uniqueness, quality and language of the citations, and the implications of\nthe findings for citation analysis. The project involved citation searching for\napproximately 1,100 scholarly works published by the study group and over 200\nworks by a test group (an additional 10 faculty members). Overall, more than\n10,000 citing and purportedly citing documents were examined. WoS data took\nabout 100 hours of collecting and processing time, Scopus consumed 200 hours,\nand GS a grueling 3,000 hours."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-008-1778-4", 
    "link": "http://arxiv.org/pdf/cs/0701035v1", 
    "title": "Finding Astronomical Communities Through Co-readership Analysis", 
    "arxiv-id": "cs/0701035v1", 
    "author": "Stephen S. Murray", 
    "publish": "2007-01-06T00:02:53Z", 
    "summary": "Whenever a large group of people are engaged in an activity, communities will\nform. The nature of these communities depends on the relationship considered.\nIn the group of people who regularly use scholarly literature, a relationship\nlike ``person i and person j have cited the same paper'' might reveal\ncommunities of people working in a particular field. On this poster, we will\ninvestigate the relationship ``person i and person j have read the same\npaper''. Using the data logs of the NASA/Smithsonian Astrophysics Data System\n(ADS), we first determine the population that will participate by requiring\nthat a user queries the ADS at a certain rate. Next, we apply the relationship\nto this population. The result of this will be an abstract ``relationship\nspace'', which we will describe in terms of various ``representations''.\nExamples of such ``representations'' are the projection of co-read vectors onto\nPrincipal Components and the spectral density of the co-read network. We will\nshow that the co-read relationship results in structure, we will describe this\nstructure and we will provide a first attempt in the classification of this\nstructure in terms of astronomical communities.\n  The ADS is funded by NASA Grant NNG06GG68G."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-008-1778-4", 
    "link": "http://arxiv.org/pdf/cs/0701101v1", 
    "title": "Citation advantage of Open Access articles likely explained by quality   differential and media effects", 
    "arxiv-id": "cs/0701101v1", 
    "author": "Philip M. Davis", 
    "publish": "2007-01-16T20:00:35Z", 
    "summary": "In a study of articles published in the Proceedings of the National Academy\nof Sciences, Gunther Eysenbach discovered a significant citation advantage for\nthose articles made freely-available upon publication (Eysenbach 2006). While\nthe author attempted to control for confounding factors that may have explained\nthe citation differential, the study was unable to control for characteristics\nof the article that may have led some authors to pay the additional page\ncharges ($1,000) for immediate OA status. OA articles published in PNAS were\nmore than twice as likely to be featured on the front cover of the journal\n(3.3% vs. 1.4%), nearly twice as likely to be picked up by the media (15% vs.\n8%) and when cited reached, on average, nearly twice as many news outlets as\nsubscription-based articles (4.2 vs. 2.6). The citation advantage of Open\nAccess articles in PNAS may likely be explained by a quality differential and\nthe amplification of media effects."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-008-1778-4", 
    "link": "http://arxiv.org/pdf/cs/0701104v1", 
    "title": "Why is a new Journal of Informetrics needed?", 
    "arxiv-id": "cs/0701104v1", 
    "author": "Walther Umstaetter", 
    "publish": "2007-01-17T12:17:53Z", 
    "summary": "In our study we analysed 3.889 records which were indexed in the Library and\nInformation Science Abstracts (LISA) database in the research field of\ninformetrics. We can show the core journals of the field via a Bradford (power\nlaw) distribution and corroborate on the basis of the restricted LISA data set\nthat it was the appropriate time to found a new specialized journal dedicated\nto informetrics. According to Bradford's Law of scattering (pure quantitative\ncalculation), Egghe's Journal of Informetrics (JOI) first issue to appear in\n2007, comes most probable at the right time."
},{
    "category": "cs.IR", 
    "doi": "10.1007/s11192-008-1778-4", 
    "link": "http://arxiv.org/pdf/cs/0701136v1", 
    "title": "Citation Advantage For OA Self-Archiving Is Independent of Journal   Impact Factor, Article Age, and Number of Co-Authors", 
    "arxiv-id": "cs/0701136v1", 
    "author": "Stevan Harnad", 
    "publish": "2007-01-22T02:14:10Z", 
    "summary": "Eysenbach has suggested that the OA (Green) self-archiving advantage might\njust be an artifact of potential uncontrolled confounding factors such as\narticle age (older articles may be both more cited and more likely to be\nself-archived), number of authors (articles with more authors might be more\ncited and more self-archived), subject matter (the subjects that are cited\nmore, self-archive more), country (same thing), number of authors, citation\ncounts of authors, etc. Chawki Hajjem (doctoral candidate, UQaM) had already\nshown that the OA advantage was present in all cases when articles were\nanalysed separately by age, subject matter or country. He has now done a\nmultiple regression analysis jointly testing (1) article age, (2) journal\nimpact factor, (3) number of authors, and (4) OA self-archiving as separate\nfactors for 442,750 articles in 576 (biomedical) journals across 11 years, and\nhas shown that each of the four factors contributes an independent,\nstatistically significant increment to the citation counts. The\nOA-self-archiving advantage remains a robust, independent factor. Having\nsuccessfully responded to his challenge, we now challenge Eysenbach to\ndemonstrate -- by testing a sufficiently broad and representative sample of\njournals at all levels of the journal quality, visibility and prestige\nhierarchy -- that his finding of a citation advantage for Gold OA (articles\npublished OA on the high-profile website of the only journal he tested (PNAS)\nover Green OA articles in the same journal (self-archived on the author's\nwebsite) was not just an artifact of having tested only one very high-profile\njournal."
},{
    "category": "cs.IR", 
    "doi": "10.1007/s11192-008-1778-4", 
    "link": "http://arxiv.org/pdf/cs/0701137v1", 
    "title": "The Open Access Citation Advantage: Quality Advantage Or Quality Bias?", 
    "arxiv-id": "cs/0701137v1", 
    "author": "Stevan Harnad", 
    "publish": "2007-01-22T02:19:16Z", 
    "summary": "Many studies have now reported the positive correlation between Open Access\n(OA) self-archiving and citation counts (\"OA Advantage,\" OAA). But does this\nOAA occur because (QB) authors are more likely to self-selectively self-archive\narticles that are more likely to be cited (self-selection \"Quality Bias\": QB)?\nor because (QA) articles that are self-archived are more likely to be cited\n(\"Quality Advantage\": QA)? The probable answer is both. Three studies [by (i)\nKurtz and co-workers in astrophysics, (ii) Moed in condensed matter physics,\nand (iii) Davis & Fromerth in mathematics] had reported the OAA to be due to QB\n[plus Early Advantage, EA, from self-archiving the preprint before publication,\nin (i) and (ii)] rather than QA. These three fields, however, (1) have less of\na postprint access problem than most other fields and (i) and (ii) also happen\nto be among the minority of fields that (2) make heavy use of prepublication\npreprints. Chawki Hajjem has now analyzed preliminary evidence based on over\n100,000 articles from multiple fields, comparing self-selected self-archiving\nwith mandated self-archiving to estimate the contributions of QB and QA to the\nOAA. Both factors contribute, and the contribution of QA is greater."
},{
    "category": "cs.SE", 
    "doi": "10.1007/s11192-008-1778-4", 
    "link": "http://arxiv.org/pdf/cs/0701175v1", 
    "title": "On the Software and Knowledge Engineering Aspects of the Educational   Process", 
    "arxiv-id": "cs/0701175v1", 
    "author": "M. Pouliopoulou", 
    "publish": "2007-01-26T14:51:38Z", 
    "summary": "The Hellenic Open University has embarked on a large-scale effort to enhance\nits textbook-based material with content that demonstrably supports the basic\ntenets of distance learning. The challenge is to set up a framework that allows\nfor the production-level creation, distribution and consumption of content, and\nat the same time, evaluate the effort in terms of technological, educational\nand organizational knowledge gained. This paper presents a model of the\neducational process that is used as a development backbone and argues about its\nconceptual and technical practicality at large."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-008-1778-4", 
    "link": "http://arxiv.org/pdf/cs/0703083v2", 
    "title": "Characterization of Search Engine Caches", 
    "arxiv-id": "cs/0703083v2", 
    "author": "Michael L. Nelson", 
    "publish": "2007-03-15T15:16:08Z", 
    "summary": "Search engines provide cached copies of indexed content so users will have\nsomething to \"click on\" if the remote resource is temporarily or permanently\nunavailable. Depending on their proprietary caching strategies, search engines\nwill purge their indexes and caches of resources that exceed a threshold of\nunavailability. Although search engine caches are provided only as an aid to\nthe interactive user, we are interested in building reliable preservation\nservices from the aggregate of these limited caching services. But first, we\nmust understand the contents of search engine caches. In this paper, we have\nexamined the cached contents of Ask, Google, MSN and Yahoo to profile such\nthings as overlap between index and cache, size, MIME type and \"staleness\" of\nthe cached resources. We also examined the overlap of the various caches with\nthe holdings of the Internet Archive."
},{
    "category": "cs.IR", 
    "doi": "10.1007/s11192-008-1778-4", 
    "link": "http://arxiv.org/pdf/cs/0703131v1", 
    "title": "Open Access Scientometrics and the UK Research Assessment Exercise", 
    "arxiv-id": "cs/0703131v1", 
    "author": "Stevan Harnad", 
    "publish": "2007-03-26T15:40:08Z", 
    "summary": "Scientometric predictors of research performance need to be validated by\nshowing that they have a high correlation with the external criterion they are\ntrying to predict. The UK Research Assessment Exercise (RAE), together with the\ngrowing movement toward making the full-texts of research articles freely\navailable on the web -- offer a unique opportunity to test and validate a\nwealth of old and new scientometric predictors, through multiple regression\nanalysis: Publications, journal impact factors, citations, co-citations,\ncitation chronometrics (age, growth, latency to peak, decay rate),\nhub/authority scores, h-index, prior funding, student counts, co-authorship\nscores, endogamy/exogamy, textual proximity, download/co-downloads and their\nchronometrics, etc. can all be tested and validated jointly, discipline by\ndiscipline, against their RAE panel rankings in the forthcoming parallel\npanel-based and metric RAE in 2008. The weights of each predictor can be\ncalibrated to maximize the joint correlation with the rankings. Open Access\nScientometrics will provide powerful new means of navigating, evaluating,\npredicting and analyzing the growing Open Access database, as well as powerful\nincentives for making it grow faster. ~"
},{
    "category": "physics.soc-ph", 
    "doi": "10.1140/epjb/e2006-00115-0", 
    "link": "http://arxiv.org/pdf/physics/0509134v2", 
    "title": "On the genre-fication of Music: a percolation approach (long version)", 
    "arxiv-id": "physics/0509134v2", 
    "author": "M. Ausloos", 
    "publish": "2005-09-15T13:00:51Z", 
    "summary": "In this paper, we analyze web-downloaded data on people sharing their music\nlibrary. By attributing to each music group usual music genres (Rock, Pop...),\nand analysing correlations between music groups of different genres with\npercolation-idea based methods, we probe the reality of these subdivisions and\nconstruct a music genre cartography, with a tree representation. We also show\nthe diversity of music genres with Shannon entropy arguments, and discuss an\nalternative objective way to classify music, that is based on the complex\nstructure of the groups audience. Finally, a link is drawn with the theory of\nhidden variables in complex networks."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1140/epjb/e2006-00115-0", 
    "link": "http://arxiv.org/pdf/physics/0701012v1", 
    "title": "The Rise and Rise of Citation Analysis", 
    "arxiv-id": "physics/0701012v1", 
    "author": "L. I. Meho", 
    "publish": "2006-12-30T19:23:36Z", 
    "summary": "With the vast majority of scientific papers now available online, this paper\ndescribes how the Web is allowing physicists and information providers to\nmeasure more accurately the impact of these papers and their authors. Provides\na historical background of citation analysis, impact factor, new citation data\nsources (e.g., Google Scholar, Scopus, NASA's Astrophysics Data System Abstract\nService, MathSciNet, ScienceDirect, SciFinder Scholar, Scitation/SPIN, and\nSPIRES-HEP), as well as h-index, g-index, and a-index."
},{
    "category": "quant-ph", 
    "doi": "10.1142/S0219749905000748", 
    "link": "http://arxiv.org/pdf/quant-ph/0406211v1", 
    "title": "Numerical simulations of mixed states quantum computation", 
    "arxiv-id": "quant-ph/0406211v1", 
    "author": "J. A. Miszczak", 
    "publish": "2004-06-29T08:23:07Z", 
    "summary": "We describe quantum-octave package of functions useful for simulations of\nquantum algorithms and protocols. Presented package allows to perform\nsimulations with mixed states. We present numerical implementation of important\nquantum mechanical operations - partial trace and partial transpose. Those\noperations are used as building blocks of algorithms for analysis of\nentanglement and quantum error correction codes. Simulation of Shor's algorithm\nis presented as an example of package capabilities."
},{
    "category": "cs.DL", 
    "doi": "10.1142/S0219749905000748", 
    "link": "http://arxiv.org/pdf/0704.2902v1", 
    "title": "Recommending Related Papers Based on Digital Library Access Records", 
    "arxiv-id": "0704.2902v1", 
    "author": "Thorsten Joachims", 
    "publish": "2007-04-23T16:51:40Z", 
    "summary": "An important goal for digital libraries is to enable researchers to more\neasily explore related work. While citation data is often used as an indicator\nof relatedness, in this paper we demonstrate that digital access records (e.g.\nhttp-server logs) can be used as indicators as well. In particular, we show\nthat measures based on co-access provide better coverage than co-citation, that\nthey are available much sooner, and that they are more accurate for recent\npapers."
},{
    "category": "cs.DL", 
    "doi": "10.1142/S0219749905000748", 
    "link": "http://arxiv.org/pdf/0704.2963v1", 
    "title": "Using Access Data for Paper Recommendations on ArXiv.org", 
    "arxiv-id": "0704.2963v1", 
    "author": "Stefan Pohl", 
    "publish": "2007-04-23T15:52:47Z", 
    "summary": "This thesis investigates in the use of access log data as a source of\ninformation for identifying related scientific papers. This is done for\narXiv.org, the authority for publication of e-prints in several fields of\nphysics.\n  Compared to citation information, access logs have the advantage of being\nimmediately available, without manual or automatic extraction of the citation\ngraph. Because of that, a main focus is on the question, how far user behavior\ncan serve as a replacement for explicit meta-data, which potentially might be\nexpensive or completely unavailable. Therefore, we compare access, content, and\ncitation-based measures of relatedness on different recommendation tasks. As a\nfinal result, an online recommendation system has been built that can help\nscientists to find further relevant literature, without having to search for\nthem actively."
},{
    "category": "cs.IR", 
    "doi": "10.1142/S0219749905000748", 
    "link": "http://arxiv.org/pdf/0705.0751v1", 
    "title": "Approximate textual retrieval", 
    "arxiv-id": "0705.0751v1", 
    "author": "Pere Constans", 
    "publish": "2007-05-05T17:27:42Z", 
    "summary": "An approximate textual retrieval algorithm for searching sources with high\nlevels of defects is presented. It considers splitting the words in a query\ninto two overlapping segments and subsequently building composite regular\nexpressions from interlacing subsets of the segments. This procedure reduces\nthe probability of missed occurrences due to source defects, yet diminishes the\nretrieval of irrelevant, non-contextual occurrences."
},{
    "category": "cs.DL", 
    "doi": "10.1142/S0219749905000748", 
    "link": "http://arxiv.org/pdf/0705.1013v4", 
    "title": "Tracking User Attention in Collaborative Tagging Communities", 
    "arxiv-id": "0705.1013v4", 
    "author": "Adriana Iamnitchi", 
    "publish": "2007-05-07T23:57:46Z", 
    "summary": "Collaborative tagging has recently attracted the attention of both industry\nand academia due to the popularity of content-sharing systems such as\nCiteULike, del.icio.us, and Flickr. These systems give users the opportunity to\nadd data items and to attach their own metadata (or tags) to stored data. The\nresult is an effective content management tool for individual users. Recent\nstudies, however, suggest that, as tagging communities grow, the added content\nand the metadata become harder to manage due to an ease in content diversity.\nThus, mechanisms that cope with increase of diversity are fundamental to\nimprove the scalability and usability of collaborative tagging systems. This\npaper analyzes whether usage patterns can be harnessed to improve navigability\nin a growing knowledge space. To this end, it presents a characterization of\ntwo collaborative tagging communities that target scientific literature:\nCiteULike and Bibsonomy. We explore three main directions: First, we analyze\nthe tagging activity distribution across the user population. Second, we define\nnew metrics for similarity in user interest and use these metrics to uncover\nthe structure of the tagging communities we study. The structure we uncover\nsuggests a clear segmentation of interests into a large number of individuals\nwith unique preferences and a core set of users with interspersed interests.\nFinally, we offer preliminary results that demonstrate that the interest-based\nstructure of the tagging community can be used to facilitate content usage as\ncommunities scale."
},{
    "category": "cs.DL", 
    "doi": "10.1142/S0219749905000748", 
    "link": "http://arxiv.org/pdf/0705.2106v1", 
    "title": "Scientific citations in Wikipedia", 
    "arxiv-id": "0705.2106v1", 
    "author": "Finn Aarup Nielsen", 
    "publish": "2007-05-15T09:42:30Z", 
    "summary": "The Internet-based encyclopaedia Wikipedia has grown to become one of the\nmost visited web-sites on the Internet. However, critics have questioned the\nquality of entries, and an empirical study has shown Wikipedia to contain\nerrors in a 2005 sample of science entries. Biased coverage and lack of sources\nare among the \"Wikipedia risks\". The present work describes a simple assessment\nof these aspects by examining the outbound links from Wikipedia articles to\narticles in scientific journals with a comparison against journal statistics\nfrom Journal Citation Reports such as impact factors. The results show an\nincreasing use of structured citation markup and good agreement with the\ncitation pattern seen in the scientific literature though with a slight\ntendency to cite articles in high-impact journals such as Nature and Science.\nThese results increase confidence in Wikipedia as an good information organizer\nfor science in general."
},{
    "category": "cs.DL", 
    "doi": "10.1142/S0219749905000748", 
    "link": "http://arxiv.org/pdf/0707.1913v3", 
    "title": "Removing Manually-Generated Boilerplate from Electronic Texts:   Experiments with Project Gutenberg e-Books", 
    "arxiv-id": "0707.1913v3", 
    "author": "Daniel Lemire", 
    "publish": "2007-07-13T02:30:10Z", 
    "summary": "Collaborative work on unstructured or semi-structured documents, such as in\nliterature corpora or source code, often involves agreed upon templates\ncontaining metadata. These templates are not consistent across users and over\ntime. Rule-based parsing of these templates is expensive to maintain and tends\nto fail as new documents are added. Statistical techniques based on frequent\noccurrences have the potential to identify automatically a large fraction of\nthe templates, thus reducing the burden on the programmers. We investigate the\ncase of the Project Gutenberg corpus, where most documents are in ASCII format\nwith preambles and epilogues that are often copied and pasted or manually\ntyped. We show that a statistical approach can solve most cases though some\ndocuments require knowledge of English. We also survey various technical\nsolutions that make our approach applicable to large data sets."
},{
    "category": "cs.DL", 
    "doi": "10.1142/S0219749905000748", 
    "link": "http://arxiv.org/pdf/0707.3575v1", 
    "title": "An exploratory study of Google Scholar", 
    "arxiv-id": "0707.3575v1", 
    "author": "Anne-Kathrin Walter", 
    "publish": "2007-07-24T19:19:36Z", 
    "summary": "The paper discusses and analyzes the scientific search service Google Scholar\n(GS). The focus is on an exploratory study which investigates the coverage of\nscientific serials in GS. The study shows deficiencies in the coverage and\nup-to-dateness of the GS index. Furthermore, the study points up which Web\nservers are the most important data providers for this search service and which\ninformation sources are highly represented. We can show that there is a\nrelatively large gap in Google Scholars coverage of German literature as well\nas weaknesses in the accessibility of Open Access content.\n  Keywords: Search engines, Digital libraries, Worldwide Web, Serials,\nElectronic journals"
},{
    "category": "cs.DL", 
    "doi": "10.1145/1255175.1255229", 
    "link": "http://arxiv.org/pdf/0708.1150v1", 
    "title": "A Practical Ontology for the Large-Scale Modeling of Scholarly Artifacts   and their Usage", 
    "arxiv-id": "0708.1150v1", 
    "author": "Herbert Van de Sompel", 
    "publish": "2007-08-08T17:06:55Z", 
    "summary": "The large-scale analysis of scholarly artifact usage is constrained primarily\nby current practices in usage data archiving, privacy issues concerned with the\ndissemination of usage data, and the lack of a practical ontology for modeling\nthe usage domain. As a remedy to the third constraint, this article presents a\nscholarly ontology that was engineered to represent those classes for which\nlarge-scale bibliographic and usage data exists, supports usage research, and\nwhose instantiation is scalable to the order of 50 million articles along with\ntheir associated artifacts (e.g. authors and journals) and an accompanying 1\nbillion usage events. The real world instantiation of the presented abstract\nontology is a semantic network model of the scholarly community which lends the\nscholarly process to statistical analysis and computational support. We present\nthe ontology, discuss its instantiation, and provide some example inference\nrules for calculating various scholarly artifact metrics."
},{
    "category": "cs.DL", 
    "doi": "10.1145/1255175.1255229", 
    "link": "http://arxiv.org/pdf/0709.0896v1", 
    "title": "Open Access does not increase citations for research articles from The   Astrophysical Journal", 
    "arxiv-id": "0709.0896v1", 
    "author": "Edwin A. Henneken", 
    "publish": "2007-09-06T16:00:43Z", 
    "summary": "We demonstrate conclusively that there is no \"Open Access Advantage\" for\npapers from the Astrophysical Journal. The two to one citation advantage\nenjoyed by papers deposited in the arXiv e-print server is due entirely to the\nnature and timing of the deposited papers. This may have implications for other\ndisciplines."
},{
    "category": "cs.DL", 
    "doi": "10.1145/1255175.1255229", 
    "link": "http://arxiv.org/pdf/0711.4142v2", 
    "title": "Content Reuse and Interest Sharing in Tagging Communities", 
    "arxiv-id": "0711.4142v2", 
    "author": "Adriana Iamnitchi", 
    "publish": "2007-11-26T23:05:02Z", 
    "summary": "Tagging communities represent a subclass of a broader class of user-generated\ncontent-sharing online communities. In such communities users introduce and tag\ncontent for later use. Although recent studies advocate and attempt to harness\nsocial knowledge in this context by exploiting collaboration among users,\nlittle research has been done to quantify the current level of user\ncollaboration in these communities. This paper introduces two metrics to\nquantify the level of collaboration: content reuse and shared interest. Using\nthese two metrics, this paper shows that the current level of collaboration in\nCiteULike and Connotea is consistently low, which significantly limits the\npotential of harnessing the social knowledge in communities. This study also\ndiscusses implications of these findings in the context of recommendation and\nreputation systems."
},{
    "category": "astro-ph", 
    "doi": "10.1086/527522", 
    "link": "http://arxiv.org/pdf/0712.1037v1", 
    "title": "The Importance of Being First: Position Dependent Citation Rates on   arXiv:astro-ph", 
    "arxiv-id": "0712.1037v1", 
    "author": "J. P. Dietrich", 
    "publish": "2007-12-06T21:00:11Z", 
    "summary": "We study the dependence of citation counts of e-prints published on the\narXiv:astro-ph server on their position in the daily astro-ph listing. Using\nthe SPIRES literature database we reconstruct the astro-ph listings from July\n2002 to December 2005 and determine citation counts for e-prints from their ADS\nentry. We use Zipf plots to analyze the citation distributions for each\nastro-ph position. We find that e-prints appearing at or near the top of the\nastro-ph mailings receive significantly more citations than those further down\nthe list. This difference is significant at the 7 sigma level and on average\namounts to two times more citations for papers at the top than those further\ndown the listing. We propose three possible non-exclusive explanations for this\npositional citation effect and try to test them. We conclude that\nself-promotion by authors plays a role in the observed effect but cannot\nexclude that increased visibility at the top of the daily listings contributes\nto higher citation counts as well. We can rule out that the positional\ndependence of citations is caused by the coincidence of the submission deadline\nwith the working hours of a geographically constrained set of intrinsically\nhigher cited authors. We discuss several ways of mitigating the observed\neffect, including splitting astro-ph into several subject classes, randomizing\nthe order of e-prints, and a novel approach to sorting entries by relevance to\nindividual readers."
},{
    "category": "cs.DL", 
    "doi": "10.1086/527522", 
    "link": "http://arxiv.org/pdf/0801.0386v1", 
    "title": "Spam: It's Not Just for Inboxes and Search Engines! Making Hirsch   h-index Robust to Scientospam", 
    "arxiv-id": "0801.0386v1", 
    "author": "Panayiotis Bozanis", 
    "publish": "2008-01-02T13:06:37Z", 
    "summary": "What is the 'level of excellence' of a scientist and the real impact of\nhis/her work upon the scientific thinking and practising? How can we design a\nfair, an unbiased metric -- and most importantly -- a metric robust to\nmanipulation?"
},{
    "category": "cs.CL", 
    "doi": "10.1086/527522", 
    "link": "http://arxiv.org/pdf/0801.3239v1", 
    "title": "Online-concordance \"Perekhresni stezhky\" (\"The Cross-Paths\"), a novel by   Ivan Franko", 
    "arxiv-id": "0801.3239v1", 
    "author": "Andrij Rovenchak", 
    "publish": "2008-01-21T17:41:57Z", 
    "summary": "In the article, theoretical principles and practical realization for the\ncompilation of the concordance to \"Perekhresni stezhky\" (\"The Cross-Paths\"), a\nnovel by Ivan Franko, are described. Two forms for the context presentation are\nproposed. The electronic version of this lexicographic work is available\nonline."
},{
    "category": "cs.DL", 
    "doi": "10.1086/527522", 
    "link": "http://arxiv.org/pdf/0804.2273v1", 
    "title": "Object Re-Use & Exchange: A Resource-Centric Approach", 
    "arxiv-id": "0804.2273v1", 
    "author": "Pete Johnston", 
    "publish": "2008-04-14T21:02:00Z", 
    "summary": "The OAI Object Reuse and Exchange (OAI-ORE) framework recasts the\nrepository-centric notion of digital object to a bounded aggregation of Web\nresources. In this manner, digital library content is more integrated with the\nWeb architecture, and thereby more accessible to Web applications and clients.\nThis generalized notion of an aggregation that is independent of repository\ncontainment conforms more closely with notions in eScience and eScholarship,\nwhere content is distributed across multiple services and databases. We provide\na motivation for the OAI-ORE project, review previous interoperability efforts,\ndescribe draft ORE specifications and report on promising results from early\nexperimentation that illustrate improved interoperability and reuse of digital\nobjects."
},{
    "category": "astro-ph", 
    "doi": "10.1086/589836", 
    "link": "http://arxiv.org/pdf/0805.0307v2", 
    "title": "Disentangling Visibility and Self-Promotion Bias in the arXiv:astro-ph   Positional Citation Effect", 
    "arxiv-id": "0805.0307v2", 
    "author": "J. P. Dietrich", 
    "publish": "2008-05-02T20:00:06Z", 
    "summary": "We established in an earlier study that articles listed at or near the top of\nthe daily arXiv:astro-ph mailings receive on average significantly more\ncitations than articles further down the list. In our earlier work we were not\nable to decide whether this positional citation effect was due to author\nself-promotion of intrinsically more citable papers or whether papers are cited\nmore often simply because they are at the top of the astro-ph listing. Using\nnew data we can now disentangle both effects. Based on their submission times\nwe separate articles into a self-promoted sample and a sample of articles that\nachieved a high rank on astro-ph by chance and compare their citation\ndistributions with those of articles on lower astro-ph positions. We find that\nthe positional citation effect is a superposition of self-promotion and\nvisibility bias."
},{
    "category": "cs.DL", 
    "doi": "10.1086/589836", 
    "link": "http://arxiv.org/pdf/0805.1154v2", 
    "title": "Clustering of scientific citations in Wikipedia", 
    "arxiv-id": "0805.1154v2", 
    "author": "Finn Aarup Nielsen", 
    "publish": "2008-05-08T12:29:36Z", 
    "summary": "The instances of templates in Wikipedia form an interesting data set of\nstructured information. Here I focus on the cite journal template that is\nprimarily used for citation to articles in scientific journals. These citations\ncan be extracted and analyzed: Non-negative matrix factorization is performed\non a (article x journal) matrix resulting in a soft clustering of Wikipedia\narticles and scientific journals, each cluster more or less representing a\nscientific topic."
},{
    "category": "cs.DL", 
    "doi": "10.1086/589836", 
    "link": "http://arxiv.org/pdf/0805.2045v1", 
    "title": "Semantic Analysis of Tag Similarity Measures in Collaborative Tagging   Systems", 
    "arxiv-id": "0805.2045v1", 
    "author": "Gerd Stumme", 
    "publish": "2008-05-14T14:10:02Z", 
    "summary": "Social bookmarking systems allow users to organise collections of resources\non the Web in a collaborative fashion. The increasing popularity of these\nsystems as well as first insights into their emergent semantics have made them\nrelevant to disciplines like knowledge extraction and ontology learning. The\nproblem of devising methods to measure the semantic relatedness between tags\nand characterizing it semantically is still largely open. Here we analyze three\nmeasures of tag relatedness: tag co-occurrence, cosine similarity of\nco-occurrence distributions, and FolkRank, an adaptation of the PageRank\nalgorithm to folksonomies. Each measure is computed on tags from a large-scale\ndataset crawled from the social bookmarking system del.icio.us. To provide a\nsemantic grounding of our findings, a connection to WordNet (a semantic lexicon\nfor the English language) is established by mapping tags into synonym sets of\nWordNet, and applying there well-known metrics of semantic similarity. Our\nresults clearly expose different characteristics of the selected measures of\nrelatedness, making them applicable to different subtasks of knowledge\nextraction such as synonym detection or discovery of concept hierarchies."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.websem.2013.05.001", 
    "link": "http://arxiv.org/pdf/0805.2855v3", 
    "title": "LCSH, SKOS and Linked Data", 
    "arxiv-id": "0805.2855v3", 
    "author": "Dan Krech", 
    "publish": "2008-05-19T13:11:41Z", 
    "summary": "A technique for converting Library of Congress Subject Headings MARCXML to\nSimple Knowledge Organization System (SKOS) RDF is described. Strengths of the\nSKOS vocabulary are highlighted, as well as possible points for extension, and\nthe integration of other semantic web vocabularies such as Dublin Core. An\napplication for making the vocabulary available as linked-data on the Web is\nalso described."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.websem.2013.05.001", 
    "link": "http://arxiv.org/pdf/0806.1246v1", 
    "title": "ICT, Community Memory and Technological Appropriation", 
    "arxiv-id": "0806.1246v1", 
    "author": "Raisa Urribarri", 
    "publish": "2008-06-06T22:37:43Z", 
    "summary": "The core mission of universities and higher education institutions is to make\npublic the results of their work and to preserve the collective memory of the\ninstitution. This includes the effective use of information and communication\ntechnologies (ICT) to systematically compile academic and research achievements\nas well as disseminate effectively this accumulated knowledge to society at\nlarge. Current efforts in Latin America and Venezuela in particular, are\nlimited but provide some valuable insights to pave the road to this important\ngoal. The institutional repository of Universidad de Los Andes (ULA) in\nVenezuela (www.saber.ula.ve) is such an example of ICT usage to store, manage\nand disseminate digital material produced by our University. In this paper we\nelaborate on the overall process of promoting a culture of content creation,\npublishing and preservation within ULA."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.websem.2013.05.001", 
    "link": "http://arxiv.org/pdf/0806.3765v1", 
    "title": "Cross-concordances: terminology mapping and its effectiveness for   information retrieval", 
    "arxiv-id": "0806.3765v1", 
    "author": "Vivien Petras", 
    "publish": "2008-06-23T20:37:10Z", 
    "summary": "The German Federal Ministry for Education and Research funded a major\nterminology mapping initiative, which found its conclusion in 2007. The task of\nthis terminology mapping initiative was to organize, create and manage\n'cross-concordances' between controlled vocabularies (thesauri, classification\nsystems, subject heading lists) centred around the social sciences but quickly\nextending to other subject areas. 64 crosswalks with more than 500,000\nrelations were established. In the final phase of the project, a major\nevaluation effort to test and measure the effectiveness of the vocabulary\nmappings in an information system environment was conducted. The paper reports\non the cross-concordance work and evaluation results."
},{
    "category": "cs.IR", 
    "doi": "10.1145/1462198.1462199", 
    "link": "http://arxiv.org/pdf/0807.0023v2", 
    "title": "Automatic Metadata Generation using Associative Networks", 
    "arxiv-id": "0807.0023v2", 
    "author": "Herbert Van de Sompel", 
    "publish": "2008-06-30T21:23:28Z", 
    "summary": "In spite of its tremendous value, metadata is generally sparse and\nincomplete, thereby hampering the effectiveness of digital information\nservices. Many of the existing mechanisms for the automated creation of\nmetadata rely primarily on content analysis which can be costly and\ninefficient. The automatic metadata generation system proposed in this article\nleverages resource relationships generated from existing metadata as a medium\nfor propagation from metadata-rich to metadata-poor resources. Because of its\nindependence from content analysis, it can be applied to a wide variety of\nresource media types and is shown to be computationally inexpensive. The\nproposed method operates through two distinct phases. Occurrence and\nco-occurrence algorithms first generate an associative network of repository\nresources leveraging existing repository metadata. Second, using the\nassociative network as a substrate, metadata associated with metadata-rich\nresources is propagated to metadata-poor resources by means of a discrete-form\nspreading activation algorithm. This article discusses the general framework\nfor building associative networks, an algorithm for disseminating metadata\nthrough such networks, and the results of an experiment and validation of the\nproposed method using a standard bibliographic dataset."
},{
    "category": "astro-ph", 
    "doi": "10.1145/1462198.1462199", 
    "link": "http://arxiv.org/pdf/0807.0967v1", 
    "title": "Astrophysics in S.Co.P.E", 
    "arxiv-id": "0807.0967v1", 
    "author": "G. Longo", 
    "publish": "2008-07-07T08:38:00Z", 
    "summary": "S.Co.P.E. is one of the four projects funded by the Italian Government in\norder to provide Southern Italy with a distributed computing infrastructure for\nfundamental science. Beside being aimed at building the infrastructure,\nS.Co.P.E. is also actively pursuing research in several areas among which\nastrophysics and observational cosmology. We shortly summarize the most\nsignificant results obtained in the first two years of the project and related\nto the development of middleware and Data Mining tools for the Virtual\nObservatory."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1371/journal.pone.0003057", 
    "link": "http://arxiv.org/pdf/0807.1182v1", 
    "title": "Random drift versus selection in academic vocabulary: an evolutionary   analysis of published keywords", 
    "arxiv-id": "0807.1182v1", 
    "author": "R. Alexander Bentley", 
    "publish": "2008-07-08T07:05:01Z", 
    "summary": "The evolution of vocabulary in academic publishing is characterized via\nkeyword frequencies recorded the ISI Web of Science citations database. In four\ndistinct case-studies, evolutionary analysis of keyword frequency change\nthrough time is compared to a model of random copying used as the null\nhypothesis, such that selection may be identified against it. The case studies\nfrom the physical sciences indicate greater selection in keyword choice than in\nthe social sciences. Similar evolutionary analyses can be applied to a wide\nrange of phenomena; wherever the popularity of multiple items through time has\nbeen recorded, as with web searches, or sales of popular music and books, for\nexample."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20943", 
    "link": "http://arxiv.org/pdf/0807.2678v3", 
    "title": "Eigenfactor : Does the Principle of Repeated Improvement Result in   Better Journal Impact Estimates than Raw Citation Counts?", 
    "arxiv-id": "0807.2678v3", 
    "author": "Philip M. Davis", 
    "publish": "2008-07-17T01:01:59Z", 
    "summary": "Eigenfactor.org, a journal evaluation tool which uses an iterative algorithm\nto weight citations (similar to the PageRank algorithm used for Google) has\nbeen proposed as a more valid method for calculating the impact of journals.\nThe purpose of this brief communication is to investigate whether the principle\nof repeated improvement provides different rankings of journals than does a\nsimple unweighted citation count (the method used by ISI)."
},{
    "category": "cs.IR", 
    "doi": "10.1002/asi.20943", 
    "link": "http://arxiv.org/pdf/0807.3755v1", 
    "title": "Approximating Document Frequency with Term Count Values", 
    "arxiv-id": "0807.3755v1", 
    "author": "Michael L. Nelson", 
    "publish": "2008-07-23T21:44:46Z", 
    "summary": "For bounded datasets such as the TREC Web Track (WT10g) the computation of\nterm frequency (TF) and inverse document frequency (IDF) is not difficult.\nHowever, when the corpus is the entire web, direct IDF calculation is\nimpossible and values must instead be estimated. Most available datasets\nprovide values for term count (TC) meaning the number of times a certain term\noccurs in the entire corpus. Intuitively this value is different from document\nfrequency (DF), the number of documents (e.g., web pages) a certain term occurs\nin. We conduct a comparison study between TC and DF values within the Web as\nCorpus (WaC). We found a very strong correlation with Spearman's rho >0.8\n(p<0.005) which makes us confident in claiming that for such recently created\ncorpora the TC and DF values can be used interchangeably to compute IDF values.\nThese results are useful for the generation of accurate lexical signatures\nbased on the TF-IDF scheme."
},{
    "category": "cs.AI", 
    "doi": "10.1002/asi.20943", 
    "link": "http://arxiv.org/pdf/0807.3908v1", 
    "title": "A Distributed Process Infrastructure for a Distributed Data Structure", 
    "arxiv-id": "0807.3908v1", 
    "author": "Marko A. Rodriguez", 
    "publish": "2008-07-24T15:16:16Z", 
    "summary": "The Resource Description Framework (RDF) is continuing to grow outside the\nbounds of its initial function as a metadata framework and into the domain of\ngeneral-purpose data modeling. This expansion has been facilitated by the\ncontinued increase in the capacity and speed of RDF database repositories known\nas triple-stores. High-end RDF triple-stores can hold and process on the order\nof 10 billion triples. In an effort to provide a seamless integration of the\ndata contained in RDF repositories, the Linked Data community is providing\nspecifications for linking RDF data sets into a universal distributed graph\nthat can be traversed by both man and machine. While the seamless integration\nof RDF data sets is important, at the scale of the data sets that currently\nexist and will ultimately grow to become, the \"download and index\" philosophy\nof the World Wide Web will not so easily map over to the Semantic Web. This\nessay discusses the importance of adding a distributed RDF process\ninfrastructure to the current distributed RDF data structure."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2008.10.001", 
    "link": "http://arxiv.org/pdf/0808.0103v2", 
    "title": "Use of Astronomical Literature - A Report on Usage Patterns", 
    "arxiv-id": "0808.0103v2", 
    "author": "Stephen S. Murray", 
    "publish": "2008-08-01T17:55:14Z", 
    "summary": "In this paper we present a number of metrics for usage of the SAO/NASA\nAstrophysics Data System (ADS). Since the ADS is used by the entire\nastronomical community, these are indicative of how the astronomical literature\nis used. We will show how the use of the ADS has changed both quantitatively\nand qualitatively. We will also show that different types of users access the\nsystem in different ways. Finally, we show how use of the ADS has evolved over\nthe years in various regions of the world.\n  The ADS is funded by NASA Grant NNG06GG68G."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2008.10.001", 
    "link": "http://arxiv.org/pdf/0808.0518v1", 
    "title": "Building a terminology network for search: the KoMoHe project", 
    "arxiv-id": "0808.0518v1", 
    "author": "Vivien Petras", 
    "publish": "2008-08-04T22:11:45Z", 
    "summary": "The paper reports about results on the GESIS-IZ project \"Competence Center\nModeling and Treatment of Semantic Heterogeneity\" (KoMoHe). KoMoHe supervised a\nterminology mapping effort, in which 'cross-concordances' between major\ncontrolled vocabularies were organized, created and managed. In this paper we\ndescribe the establishment and implementation of cross-concordances for search\nin a digital library (DL)."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2008.10.001", 
    "link": "http://arxiv.org/pdf/0808.3296v2", 
    "title": "Confirmation Bias and the Open Access Advantage: Some Methodological   Suggestions for the Davis Citation Study", 
    "arxiv-id": "0808.3296v2", 
    "author": "Stevan Harnad", 
    "publish": "2008-08-25T03:36:14Z", 
    "summary": "Davis (2008) analyzes citations from 2004-2007 in 11 biomedical journals. 15%\nof authors paid to make them Open Access (OA). The outcome is a significant OA\ncitation Advantage, but a small one (21%). The author infers that the OA\nadvantage has been shrinking yearly, but the data suggest the opposite. Further\nanalyses are necessary:\n  (1) Not just author-choice (paid) OA but Free OA self-archiving needs to be\ntaken into account rather than being counted as non-OA.\n  (2) proportion of OA articles per journal per year needs to be reported and\ntaken into account.\n  (3) The Journal Impact Factor and the relation between the size of the OA\nAdvantage article 'citation-bracket' need to be taken into account.\n  (4) The sample-size for the highest-impact, largest-sample journal analyzed,\nPNAS, is restricted and excluded from some of the analyses. The full PNAS\ndataset is needed.\n  (5) The interaction between OA and time, 2004-2007, is based on retrospective\ndata from a June 2008 total cumulative citation count. The dates of both the\ncited articles and the citing articles need to be taken into account.\n  The author proposes that author self-selection bias for is the primary cause\nof the observed OA Advantage, but this study does not test this or of any of\nthe other potential causal factors. The author suggests that paid OA is not\nworth the cost, per extra citation. But with OA self-archiving both the OA and\nthe extra citations are free."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2008.10.001", 
    "link": "http://arxiv.org/pdf/0809.2818v1", 
    "title": "A Simple Framework to Typify Social Bibliographic Communities", 
    "arxiv-id": "0809.2818v1", 
    "author": "Christoph Schommer", 
    "publish": "2008-09-16T21:25:41Z", 
    "summary": "Social Communities in bibliographic databases exist since many years,\nresearchers share common research interests, and work and publish together. A\nsocial community may vary in type and size, being fully connected between\nparticipating members or even more expressed by a consortium of small and\nindividual members who play individual roles in it. In this work, we focus on\nsocial communities inside the bibliographic database DBLP and characterize\ncommunities through a simple typifying description model. Generally, we\nunderstand a publication as a transaction between the associated authors. The\nidea therefore is to concern with directed associative relationships among\nthem, to decompose each pattern to its fundamental structure, and to describe\nthe communities by expressive attributes. Finally, we argue that the\ndecomposition supports the management of discovered structures towards the use\nof adaptive-incremental mind-maps."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1016/j.joi.2008.10.001", 
    "link": "http://arxiv.org/pdf/0809.5250v1", 
    "title": "The decline in the concentration of citations, 1900-2007", 
    "arxiv-id": "0809.5250v1", 
    "author": "Eric Archambault", 
    "publish": "2008-09-30T16:27:42Z", 
    "summary": "This paper challenges recent research (Evans, 2008) reporting that the\nconcentration of cited scientific literature increases with the online\navailability of articles and journals. Using Thomson Reuters' Web of Science,\nthe present paper analyses changes in the concentration of citations received\n(two- and five-year citation windows) by papers published between 1900 and\n2005. Three measures of concentration are used: the percentage of papers that\nreceived at least one citation (cited papers); the percentage of papers needed\nto account for 20, 50 and 80 percent of the citations; and, the\nHerfindahl-Hirschman index. These measures are used for four broad disciplines:\nnatural sciences and engineering, medical fields, social sciences, and the\nhumanities. All these measures converge and show that, contrary to what was\nreported by Evans, the dispersion of citations is actually increasing."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1016/j.joi.2008.10.001", 
    "link": "http://arxiv.org/pdf/0810.0486v1", 
    "title": "Peer-review in the Internet age", 
    "arxiv-id": "0810.0486v1", 
    "author": "Pawel Sobkowicz", 
    "publish": "2008-10-02T17:02:18Z", 
    "summary": "The importance of peer-review in the scientific process can not be\noverestimated. Yet, due to increasing pressures of research and exponentially\ngrowing number of publications the task faced by the referees becomes ever more\ndifficult. We discuss here a few possible improvements that would enable more\nefficient review of the scientific literature, using the growing Internet\nconnectivity. In particular, a practical automated model for providing the\nreferees with references to papers that might have strong relationship with the\nwork under review, based on general network properties of citations is\nproposed."
},{
    "category": "cs.CL", 
    "doi": "10.1016/j.joi.2008.10.001", 
    "link": "http://arxiv.org/pdf/0810.4616v1", 
    "title": "Assembling Actor-based Mind-Maps from Text Stream", 
    "arxiv-id": "0810.4616v1", 
    "author": "Christoph Schommer", 
    "publish": "2008-10-25T16:00:08Z", 
    "summary": "For human beings, the processing of text streams of unknown size leads\ngenerally to problems because e.g. noise must be selected out, information be\ntested for its relevance or redundancy, and linguistic phenomenon like\nambiguity or the resolution of pronouns be advanced. Putting this into\nsimulation by using an artificial mind-map is a challenge, which offers the\ngate for a wide field of applications like automatic text summarization or\npunctual retrieval. In this work we present a framework that is a first step\ntowards an automatic intellect. It aims at assembling a mind-map based on\nincoming text streams and on a subject-verb-object strategy, having the verb as\nan interconnection between the adjacent nouns. The mind-map's performance is\nenriched by a pronoun resolution engine that bases on the work of D. Klein, and\nC. D. Manning."
},{
    "category": "cs.AI", 
    "doi": "10.1016/j.joi.2008.10.001", 
    "link": "http://arxiv.org/pdf/0810.4668v1", 
    "title": "On Granular Knowledge Structures", 
    "arxiv-id": "0810.4668v1", 
    "author": "Ning Zhong", 
    "publish": "2008-10-26T07:17:42Z", 
    "summary": "Knowledge plays a central role in human and artificial intelligence. One of\nthe key characteristics of knowledge is its structured organization. Knowledge\ncan be and should be presented in multiple levels and multiple views to meet\npeople's needs in different levels of granularities and from different\nperspectives. In this paper, we stand on the view point of granular computing\nand provide our understanding on multi-level and multi-view of knowledge\nthrough granular knowledge structures (GKS). Representation of granular\nknowledge structures, operations for building granular knowledge structures and\nhow to use them are investigated. As an illustration, we provide some examples\nthrough results from an analysis of proceeding papers. Results show that\ngranular knowledge structures could help users get better understanding of the\nknowledge source from set theoretical, logical and visual point of views. One\nmay consider using them to meet specific needs or solve certain kinds of\nproblems."
},{
    "category": "cs.IR", 
    "doi": "10.1016/j.joi.2008.10.001", 
    "link": "http://arxiv.org/pdf/0810.5057v2", 
    "title": "Combining Advanced Visualization and Automatized Reasoning for   Webometrics: A Test Study", 
    "arxiv-id": "0810.5057v2", 
    "author": "Shadi Al Shehabi", 
    "publish": "2008-10-28T15:43:45Z", 
    "summary": "This paper presents a first attempt at performing a precise and automatic\nidentification of the linking behaviour in a scientific domain through the\nanalysis of the communication of the related academic institutions on the web.\nThe proposed approach is based on the paradigm of multiple viewpoint data\nanalysis (MVDA) than can be fruitfully exploited to highlight relationships\nbetween data, like websites, carrying several kinds of description. It uses the\nMultiSOM clustering and mapping method. The domain that has been chosen for\nthis study is the domain of Computer Science in Germany. The analysis is\nconduced on a set of 438 websites of this domain using all together, thematic,\ngeographic and linking information. It highlights interesting results\nconcerning both global and local linking behaviour."
},{
    "category": "cs.CY", 
    "doi": "10.1016/j.joi.2008.10.001", 
    "link": "http://arxiv.org/pdf/0811.2519v1", 
    "title": "Origins of Modern Data Analysis Linked to the Beginnings and Early   Development of Computer Science and Information Engineering", 
    "arxiv-id": "0811.2519v1", 
    "author": "Fionn Murtagh", 
    "publish": "2008-11-15T18:41:34Z", 
    "summary": "The history of data analysis that is addressed here is underpinned by two\nthemes, -- those of tabular data analysis, and the analysis of collected\nheterogeneous data. \"Exploratory data analysis\" is taken as the heuristic\napproach that begins with data and information and seeks underlying explanation\nfor what is observed or measured. I also cover some of the evolving context of\nresearch and applications, including scholarly publishing, technology transfer\nand the economic relationship of the university to society."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2008.10.001", 
    "link": "http://arxiv.org/pdf/0811.4603v2", 
    "title": "Frozen Footprints", 
    "arxiv-id": "0811.4603v2", 
    "author": "Massimo Franceschet", 
    "publish": "2008-11-27T18:12:28Z", 
    "summary": "Bibliometrics has the ambitious goal of measuring science. To this end, it\nexploits the way science is disseminated trough scientific publications and the\nresulting citation network of scientific papers. We survey the main historical\ncontributions to the field, the most interesting bibliometric indicators, and\nthe most popular bibliometric data sources. Moreover, we discuss distributions\ncommonly used to model bibliometric phenomena and give an overview of methods\nto build bibliometric maps of science."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2008.10.001", 
    "link": "http://arxiv.org/pdf/0812.4296v1", 
    "title": "Tsallis $q$-exponential describes the distribution of scientific   citations - A new characterization of the impact", 
    "arxiv-id": "0812.4296v1", 
    "author": "Diogo B. Mussi", 
    "publish": "2008-12-22T21:34:10Z", 
    "summary": "In this work we have studied the research activity for countries of Europe,\nLatin America and Africa for all sciences between 1945 and November 2008. All\nthe data are captured from the Web of Science database during this period. The\nanalysis of the experimental data shows that, within a nonextensive\nthermostatistical formalism, the Tsallis \\emph{q}-exponential distribution\n$N(c)$ satisfactorily describes Institute of Scientific Information citations.\nThe data which are examined in the present survey can be fitted successfully as\na first approach by applying a {\\it single} curve (namely, $N(c) \\propto\n1/[1+(q-1) c/T]^{\\frac{1}{q-1}}$ with $q\\simeq 4/3$ for {\\it all} the available\ncitations $c$, $T$ being an \"effective temperature\". The present analysis\nultimately suggests that the phenomenon might essentially be {\\it one and the\nsame} along the {\\it entire} range of the citation number. Finally, this\nmanuscript provides a new ranking index, via the \"effective temperature\" $T$,\nfor the impact level of the research activity in these countries, taking into\naccount the number of the publications and their citations."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2008.10.001", 
    "link": "http://arxiv.org/pdf/0901.0213v1", 
    "title": "Filtering Microarray Correlations by Statistical Literature Analysis   Yields Potential Hypotheses for Lactation Research", 
    "arxiv-id": "0901.0213v1", 
    "author": "Kevin R. Nicholas", 
    "publish": "2009-01-02T03:47:57Z", 
    "summary": "Our results demonstrated that a previously reported protein name\nco-occurrence method (5-mention PubGene) which was not based on a hypothesis\ntesting framework, it is generally statistically more significant than the 99th\npercentile of Poisson distribution-based method of calculating co-occurrence.\nIt agrees with previous methods using natural language processing to extract\nprotein-protein interaction from text as more than 96% of the interactions\nfound by natural language processing methods to overlap with the results from\n5-mention PubGene method. However, less than 2% of the gene co-expressions\nanalyzed by microarray were found from direct co-occurrence or interaction\ninformation extraction from the literature. At the same time, combining\nmicroarray and literature analyses, we derive a novel set of 7 potential\nfunctional protein-protein interactions that had not been previously described\nin the literature."
},{
    "category": "cs.CY", 
    "doi": "10.1016/j.joi.2008.10.001", 
    "link": "http://arxiv.org/pdf/0901.3929v2", 
    "title": "Revisiting the Age of Enlightenment from a Collective Decision Making   Systems Perspective", 
    "arxiv-id": "0901.3929v2", 
    "author": "Jennifer H. Watkins", 
    "publish": "2009-01-25T22:50:41Z", 
    "summary": "The ideals of the eighteenth century's Age of Enlightenment are the\nfoundation of modern democracies. The era was characterized by thinkers who\npromoted progressive social reforms that opposed the long-established\naristocracies and monarchies of the time. Prominent examples of such reforms\ninclude the establishment of inalienable human rights, self-governing\nrepublics, and market capitalism. Twenty-first century democratic nations can\nbenefit from revisiting the systems developed during the Enlightenment and\nreframing them within the techno-social context of the Information Age. This\narticle explores the application of social algorithms that make use of Thomas\nPaine's (English: 1737--1809) representatives, Adam Smith's (Scottish:\n1723--1790) self-interested actors, and Marquis de Condorcet's (French:\n1743--1794) optimal decision making groups. It is posited that\ntechnology-enabled social algorithms can better realize the ideals articulated\nduring the Enlightenment."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2008.10.001", 
    "link": "http://arxiv.org/pdf/0901.3939v1", 
    "title": "Effectively Searching Maps in Web Documents", 
    "arxiv-id": "0901.3939v1", 
    "author": "C. Lee Giles", 
    "publish": "2009-01-26T02:14:29Z", 
    "summary": "Maps are an important source of information in archaeology and other\nsciences. Users want to search for historical maps to determine recorded\nhistory of the political geography of regions at different eras, to find out\nwhere exactly archaeological artifacts were discovered, etc. Currently, they\nhave to use a generic search engine and add the term map along with other\nkeywords to search for maps. This crude method will generate a significant\nnumber of false positives that the user will need to cull through to get the\ndesired results. To reduce their manual effort, we propose an automatic map\nidentification, indexing, and retrieval system that enables users to search and\nretrieve maps appearing in a large corpus of digital documents using simple\nkeyword queries. We identify features that can help in distinguishing maps from\nother figures in digital documents and show how a Support-Vector-Machine-based\nclassifier can be used to identify maps. We propose map-level-metadata e.g.,\ncaptions, references to the maps in text, etc. and document-level metadata,\ne.g., title, abstract, citations, how recent the publication is, etc. and show\nhow they can be automatically extracted and indexed. Our novel ranking\nalgorithm weights different metadata fields differently and also uses the\ndocument-level metadata to help rank retrieved maps. Empirical evaluations show\nwhich features should be selected and which metadata fields should be weighted\nmore. We also demonstrate improved retrieval results in comparison to\nadaptations of existing methods for map retrieval. Our map search engine has\nbeen deployed in an online map-search system that is part of the Blind-Review\ndigital library system."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2008.10.001", 
    "link": "http://arxiv.org/pdf/0901.4571v1", 
    "title": "Everyone is a Curator: Human-Assisted Preservation for ORE Aggregations", 
    "arxiv-id": "0901.4571v1", 
    "author": "Herbert Van de Sompel", 
    "publish": "2009-01-28T22:48:08Z", 
    "summary": "The Open Archives Initiative (OAI) has recently created the Object Reuse and\nExchange (ORE) project that defines Resource Maps (ReMs) for describing\naggregations of web resources. These aggregations are susceptible to many of\nthe same preservation challenges that face other web resources. In this paper,\nwe investigate how the aggregations of web resources can be preserved outside\nof the typical repository environment and instead rely on the thousands of\ninteractive users in the web community and the Web Infrastructure (the\ncollection of web archives, search engines, and personal archiving services) to\nfacilitate preservation. Inspired by Web 2.0 services such as digg,\ndeli.cio.us, and Yahoo! Buzz, we have developed a lightweight system called\nReMember that attempts to harness the collective abilities of the web community\nfor preservation purposes instead of solely placing the burden of curatorial\nresponsibilities on a small number of experts."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0006022", 
    "link": "http://arxiv.org/pdf/0902.2183v2", 
    "title": "A principal component analysis of 39 scientific impact measures", 
    "arxiv-id": "0902.2183v2", 
    "author": "Ryan Chute", 
    "publish": "2009-02-12T18:31:44Z", 
    "summary": "The impact of scientific publications has traditionally been expressed in\nterms of citation counts. However, scientific activity has moved online over\nthe past decade. To better capture scientific impact in the digital era, a\nvariety of new impact measures has been proposed on the basis of social network\nanalysis and usage log data. Here we investigate how these new measures relate\nto each other, and how accurately and completely they express scientific\nimpact. We performed a principal component analysis of the rankings produced by\n39 existing and proposed measures of scholarly impact that were calculated on\nthe basis of both citation and usage log data. Our results indicate that the\nnotion of scientific impact is a multi-dimensional construct that can not be\nadequately measured by any single indicator, although some measures are more\nsuitable than others. The commonly used citation Impact Factor is not\npositioned at the core of this construct, but at its periphery, and should thus\nbe used with caution."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1103/PhysRevE.79.066118", 
    "link": "http://arxiv.org/pdf/0903.0419v1", 
    "title": "Random hypergraphs and their applications", 
    "arxiv-id": "0903.0419v1", 
    "author": "M. E. J. Newman", 
    "publish": "2009-03-03T03:38:09Z", 
    "summary": "In the last few years we have witnessed the emergence, primarily in on-line\ncommunities, of new types of social networks that require for their\nrepresentation more complex graph structures than have been employed in the\npast. One example is the folksonomy, a tripartite structure of users,\nresources, and tags -- labels collaboratively applied by the users to the\nresources in order to impart meaningful structure on an otherwise\nundifferentiated database. Here we propose a mathematical model of such\ntripartite structures which represents them as random hypergraphs. We show that\nit is possible to calculate many properties of this model exactly in the limit\nof large network size and we compare the results against observations of a real\nfolksonomy, that of the on-line photography web site Flickr. We show that in\nsome cases the model matches the properties of the observed network well, while\nin others there are significant differences, which we find to be attributable\nto the practice of multiple tagging, i.e., the application by a single user of\nmany tags to one resource, or one tag to many resources."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1103/PhysRevE.79.066118", 
    "link": "http://arxiv.org/pdf/0903.3228v1", 
    "title": "The Smithsonian/NASA Astrophysics Data System (ADS) Decennial Report", 
    "arxiv-id": "0903.3228v1", 
    "author": "Stephen S. Murray", 
    "publish": "2009-03-18T19:36:57Z", 
    "summary": "Eight years after the ADS first appeared the last decadal survey wrote:\n\"NASA's initiative for the Astrophysics Data System has vastly increased the\naccessibility of the scientific literature for astronomers. NASA deserves\ncredit for this valuable initiative and is urged to continue it.\" Here we\nsummarize some of the changes concerning the ADS which have occurred in the\npast ten years, and we describe the current status of the ADS. We then point\nout two areas where the ADS is building an improved capability which could\nbenefit from a policy statement of support in the ASTRO2010 report. These are:\nThe Semantic Interlinking of Astronomy Observations and Datasets and The\nIndexing of the Full Text of Astronomy Research Publications."
},{
    "category": "cs.DL", 
    "doi": "10.1103/PhysRevE.79.066118", 
    "link": "http://arxiv.org/pdf/0903.3562v1", 
    "title": "Visual Conceptualizations and Models of Science", 
    "arxiv-id": "0903.3562v1", 
    "author": "Andrea Scharnhorst", 
    "publish": "2009-03-20T16:35:18Z", 
    "summary": "This Journal of Informetrics special issue aims to improve our understanding\nof the structure and dynamics of science by reviewing and advancing existing\nconceptualizations and models of scholarly activity. Several of these\nconceptualizations and models have visual manifestations supporting the\ncombination and comparison of theories and approaches developed in different\ndisciplines of science. Subsequently, we discuss challenges towards a\ntheoretically grounded and practically useful science of science and provide a\nbrief chronological review of relevant work. Then, we exemplarily present three\nconceptualizations of science that attempt to provide frameworks for the\ncomparison and combination of existing approaches, theories, laws, and\nmeasurements. Finally, we discuss the contributions of and interlinkages among\nthe eight papers included in this issue. Each paper makes a unique contribution\ntowards conceptualizations and models of science and roots this contribution in\na review and comparison with existing work."
},{
    "category": "cs.IR", 
    "doi": "10.1002/asi.21062", 
    "link": "http://arxiv.org/pdf/0903.5254v1", 
    "title": "Comparing Bibliometric Statistics Obtained from the Web of Science and   Scopus", 
    "arxiv-id": "0903.5254v1", 
    "author": "Vincent Lariviere", 
    "publish": "2009-03-30T15:56:49Z", 
    "summary": "For more than 40 years, the Institute for Scientific Information (ISI, now\npart of Thomson Reuters) produced the only available bibliographic databases\nfrom which bibliometricians could compile large-scale bibliometric indicators.\nISI's citation indexes, now regrouped under the Web of Science (WoS), were the\nmajor sources of bibliometric data until 2004, when Scopus was launched by the\npublisher Reed Elsevier. For those who perform bibliometric analyses and\ncomparisons of countries or institutions, the existence of these two major\ndatabases raises the important question of the comparability and stability of\nstatistics obtained from different data sources. This paper uses macro-level\nbibliometric indicators to compare results obtained from the WoS and Scopus. It\nshows that the correlations between the measures obtained with both databases\nfor the number of papers and the number of citations received by countries, as\nwell as for their ranks, are extremely high (R2 > .99). There is also a very\nhigh correlation when countries' papers are broken down by field. The paper\nthus provides evidence that indicators of scientific production and citations\nat the country level are stable and largely independent of the database."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.21062", 
    "link": "http://arxiv.org/pdf/0905.1594v1", 
    "title": "A Recommender System to Support the Scholarly Communication Process", 
    "arxiv-id": "0905.1594v1", 
    "author": "Gary Ebersole", 
    "publish": "2009-05-11T18:58:16Z", 
    "summary": "The number of researchers, articles, journals, conferences, funding\nopportunities, and other such scholarly resources continues to grow every year\nand at an increasing rate. Many services have emerged to support scholars in\nnavigating particular aspects of this resource-rich environment. Some\ncommercial publishers provide recommender and alert services for the articles\nand journals in their digital libraries. Similarly, numerous noncommercial\nsocial bookmarking services have emerged for citation sharing. While these\nservices do provide some support, they lack an understanding of the various\nproblem-solving scenarios that researchers face daily. Example scenarios, to\nname a few, include when a scholar is in search of an article related to\nanother article of interest, when a scholar is in search of a potential\ncollaborator for a funding opportunity, when a scholar is in search of an\noptimal venue to which to submit their article, and when a scholar, in the role\nof an editor, is in search of referees to review an article. All of these\nexample scenarios can be represented as a problem in information filtering by\nmeans of context-sensitive recommendation. This article presents an overview of\na context-sensitive recommender system to support the scholarly communication\nprocess that is based on the standards and technology set forth by the Semantic\nWeb initiative."
},{
    "category": "cs.IR", 
    "doi": "10.1002/asi.21062", 
    "link": "http://arxiv.org/pdf/0905.2416v1", 
    "title": "Identifying Influential Bloggers: Time Does Matter", 
    "arxiv-id": "0905.2416v1", 
    "author": "Panayiotis Bozanis", 
    "publish": "2009-05-14T20:05:41Z", 
    "summary": "Blogs have recently become one of the most favored services on the Web. Many\nusers maintain a blog and write posts to express their opinion, experience and\nknowledge about a product, an event and every subject of general or specific\ninterest. More users visit blogs to read these posts and comment them. This\n\"participatory journalism\" of blogs has such an impact upon the masses that\nKeller and Berry argued that through blogging \"one American in tens tells the\nother nine how to vote, where to eat and what to buy\" \\cite{keller1}.\nTherefore, a significant issue is how to identify such influential bloggers.\nThis problem is very new and the relevant literature lacks sophisticated\nsolutions, but most importantly these solutions have not taken into account\ntemporal aspects for identifying influential bloggers, even though the time is\nthe most critical aspect of the Blogosphere. This article investigates the\nissue of identifying influential bloggers by proposing two easily computed\nblogger ranking methods, which incorporate temporal aspects of the blogging\nactivity. Each method is based on a specific metric to score the blogger's\nposts. The first metric, termed MEIBI, takes into consideration the number of\nthe blog post's inlinks and its comments, along with the publication date of\nthe post. The second metric, MEIBIX, is used to score a blog post according to\nthe number and age of the blog post's inlinks and its comments. These methods\nare evaluated against the state-of-the-art influential blogger identification\nmethod utilizing data collected from a real-world community blog site. The\nobtained results attest that the new methods are able to better identify\nsignificant temporal patterns in the blogging behaviour."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.21062", 
    "link": "http://arxiv.org/pdf/0905.2636v1", 
    "title": "Information Diffusion in Computer Science Citation Networks", 
    "arxiv-id": "0905.2636v1", 
    "author": "Lada A. Adamic", 
    "publish": "2009-05-15T22:41:39Z", 
    "summary": "The paper citation network is a traditional social medium for the exchange of\nideas and knowledge. In this paper we view citation networks from the\nperspective of information diffusion. We study the structural features of the\ninformation paths through the citation networks of publications in computer\nscience, and analyze the impact of various citation choices on the subsequent\nimpact of the article. We find that citing recent papers and papers within the\nsame scholarly community garners a slightly larger number of citations on\naverage. However, this correlation is weaker among well-cited papers implying\nthat for high impact work citing within one's field is of lesser importance. We\nalso study differences in information flow for specific subsets of citation\nnetworks: books versus conference and journal articles, different areas of\ncomputer science, and different time periods."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.21062", 
    "link": "http://arxiv.org/pdf/0905.3330v3", 
    "title": "The Game of Cipher Beads", 
    "arxiv-id": "0905.3330v3", 
    "author": "S. S. Kutateladze", 
    "publish": "2009-05-20T15:04:01Z", 
    "summary": "Comparison between the various impact factors of a few Russian journals\ndemonstrates the deficiencies of the popular citation indices."
},{
    "category": "cs.AI", 
    "doi": "10.1002/asi.21062", 
    "link": "http://arxiv.org/pdf/0905.3378v2", 
    "title": "Interpretations of the Web of Data", 
    "arxiv-id": "0905.3378v2", 
    "author": "Marko A. Rodriguez", 
    "publish": "2009-05-20T19:48:10Z", 
    "summary": "The emerging Web of Data utilizes the web infrastructure to represent and\ninterrelate data. The foundational standards of the Web of Data include the\nUniform Resource Identifier (URI) and the Resource Description Framework (RDF).\nURIs are used to identify resources and RDF is used to relate resources. While\nRDF has been posited as a logic language designed specifically for knowledge\nrepresentation and reasoning, it is more generally useful if it can\nconveniently support other models of computing. In order to realize the Web of\nData as a general-purpose medium for storing and processing the world's data,\nit is necessary to separate RDF from its logic language legacy and frame it\nsimply as a data model. Moreover, there is significant advantage in seeing the\nSemantic Web as a particular interpretation of the Web of Data that is focused\nspecifically on knowledge representation and reasoning. By doing so, other\ninterpretations of the Web of Data are exposed that realize RDF in different\ncapacities and in support of different computing models."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1002/asna.200811233", 
    "link": "http://arxiv.org/pdf/0906.2291v2", 
    "title": "A standard transformation from XML to RDF via XSLT", 
    "arxiv-id": "0906.2291v2", 
    "author": "F. Breitling", 
    "publish": "2009-06-12T14:12:34Z", 
    "summary": "A generic transformation of XML data into the Resource Description Framework\n(RDF) and its implementation by XSLT transformations is presented. It was\ndeveloped by the grid integration project for robotic telescopes of AstroGrid-D\nto provide network communication through the Remote Telescope Markup Language\n(RTML) to its RDF based information service. The transformation's generality is\nexplained by this example. It automates the transformation of XML data into RDF\nand thus solves this problem of semantic computing. Its design also permits the\ninverse transformation but this is not yet implemented."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.21263", 
    "link": "http://arxiv.org/pdf/0906.2549v3", 
    "title": "From Artifacts to Aggregations: Modeling Scientific Life Cycles on the   Semantic Web", 
    "arxiv-id": "0906.2549v3", 
    "author": "Herbert Van de Sompel", 
    "publish": "2009-06-14T15:23:10Z", 
    "summary": "In the process of scientific research, many information objects are\ngenerated, all of which may remain valuable indefinitely. However, artifacts\nsuch as instrument data and associated calibration information may have little\nvalue in isolation; their meaning is derived from their relationships to each\nother. Individual artifacts are best represented as components of a life cycle\nthat is specific to a scientific research domain or project. Current cataloging\npractices do not describe objects at a sufficient level of granularity nor do\nthey offer the globally persistent identifiers necessary to discover and manage\nscholarly products with World Wide Web standards. The Open Archives\nInitiative's Object Reuse and Exchange data model (OAI-ORE) meets these\nrequirements. We demonstrate a conceptual implementation of OAI-ORE to\nrepresent the scientific life cycles of embedded networked sensor applications\nin seismology and environmental sciences. By establishing relationships between\npublications, data, and contextual research information, we illustrate how to\nobtain a richer and more realistic view of scientific practices. That view can\nfacilitate new forms of scientific research and learning. Our analysis is\nframed by studies of scientific practices in a large, multi-disciplinary,\nmulti-university science and engineering research center, the Center for\nEmbedded Networked Sensing (CENS)."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1002/asi.21263", 
    "link": "http://arxiv.org/pdf/0906.4019v1", 
    "title": "On the prevalence and scientific impact of duplicate publications in   different scientific fields (1980-2007)", 
    "arxiv-id": "0906.4019v1", 
    "author": "Yves Gingras", 
    "publish": "2009-06-22T14:28:31Z", 
    "summary": "The issue of duplicate publications has received a lot of attention in the\nmedical literature, but much less in the information science community. This\npaper aims at analyzing the prevalence and scientific impact of duplicate\npublications across all fields of research between 1980 and 2007, using a\ndefinition of duplicate papers based on their metadata. It shows that in all\nfields combined, the prevalence of duplicates is one out of two-thousand\npapers, but is higher in the natural and medical sciences than in the social\nsciences and humanities. A very high proportion (>85%) of these papers are\npublished the same year or one year apart, which suggest that most duplicate\npapers were submitted simultaneously. Furthermore, duplicate papers are\ngenerally published in journals with impact factors below the average of their\nfield and obtain a lower number of citations. This paper provides clear\nevidence that the prevalence of duplicate papers is low and, more importantly,\nthat the scientific impact of such papers is below average."
},{
    "category": "cs.IR", 
    "doi": "10.1002/asi.21263", 
    "link": "http://arxiv.org/pdf/0906.4026v2", 
    "title": "A Quantum-based Model for Interactive Information Retrieval (extended   version)", 
    "arxiv-id": "0906.4026v2", 
    "author": "M. Lalmas", 
    "publish": "2009-06-22T16:17:36Z", 
    "summary": "Even the best information retrieval model cannot always identify the most\nuseful answers to a user query. This is in particular the case with web search\nsystems, where it is known that users tend to minimise their effort to access\nrelevant information. It is, however, believed that the interaction between\nusers and a retrieval system, such as a web search engine, can be exploited to\nprovide better answers to users. Interactive Information Retrieval (IR)\nsystems, in which users access information through a series of interactions\nwith the search system, are concerned with building models for IR, where\ninteraction plays a central role. There are many possible interactions between\na user and a search system, ranging from query (re)formulation to relevance\nfeedback. However, capturing them within a single framework is difficult and\npreviously proposed approaches have mostly focused on relevance feedback. In\nthis paper, we propose a general framework for interactive IR that is able to\ncapture the full interaction process in a principled way. Our approach relies\nupon a generalisation of the probability framework of quantum physics, whose\nstrong geometric component can be a key towards a successful interactive IR\nmodel."
},{
    "category": "cs.IR", 
    "doi": "10.1002/asi.21263", 
    "link": "http://arxiv.org/pdf/0907.2268v2", 
    "title": "Evaluating Methods to Rediscover Missing Web Pages from the Web   Infrastructure", 
    "arxiv-id": "0907.2268v2", 
    "author": "Michael L Nelson", 
    "publish": "2009-07-14T15:47:57Z", 
    "summary": "Missing web pages (pages that return the 404 \"Page Not Found\" error) are part\nof the browsing experience. The manual use of search engines to rediscover\nmissing pages can be frustrating and unsuccessful. We compare four automated\nmethods for rediscovering web pages. We extract the page's title, generate the\npage's lexical signature (LS), obtain the page's tags from the bookmarking\nwebsite delicious.com and generate a LS from the page's link neighborhood. We\nuse the output of all methods to query Internet search engines and analyze\ntheir retrieval performance. Our results show that both LSs and titles perform\nfairly well with over 60% URIs returned top ranked from Yahoo!. However, the\ncombination of methods improves the retrieval performance. Considering the\ncomplexity of the LS generation, querying the title first and in case of\ninsufficient results querying the LSs second is the preferable setup. This\ncombination accounts for more than 75% top ranked URIs."
},{
    "category": "cs.IR", 
    "doi": "10.1002/asi.21263", 
    "link": "http://arxiv.org/pdf/0907.3445v1", 
    "title": "Investigating the Change of Web Pages' Titles Over Time", 
    "arxiv-id": "0907.3445v1", 
    "author": "Michael L. Nelson", 
    "publish": "2009-07-20T16:56:51Z", 
    "summary": "Inaccessible web pages are part of the browsing experience. The content of\nthese pages however is often not completely lost but rather missing. Lexical\nsignatures (LS) generated from the web pages' textual content have been shown\nto be suitable as search engine queries when trying to discover a (missing) web\npage. Since LSs are expensive to generate, we investigate the potential of web\npages' titles as they are available at a lower cost. We present the results\nfrom studying the change of titles over time. We take titles from copies\nprovided by the Internet Archive of randomly sampled web pages and show the\nfrequency of change as well as the degree of change in terms of the Levenshtein\nscore. We found very low frequencies of change and high Levenshtein scores\nindicating that titles, on average, change little from their original, first\nobserved values (rooted comparison) and even less from the values of their\nprevious observation (sliding)."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1002/asi.21263", 
    "link": "http://arxiv.org/pdf/0908.1776v1", 
    "title": "On the relationship between interdisciplinarity and scientific impact", 
    "arxiv-id": "0908.1776v1", 
    "author": "Yves Gingras", 
    "publish": "2009-08-12T19:08:59Z", 
    "summary": "This paper analyzes the effect of interdisciplinarity on the scientific\nimpact of individual papers. Using all the papers published in Web of Science\nin 2000, we define the degree of interdisciplinarity of a given paper as the\npercentage of its cited references made to journals of other disciplines. We\nshow that, although for all disciplines combined there is no clear correlation\nbetween the level of interdisciplinarity of papers and their citation rates,\nthere are nonetheless some disciplines in which a higher level of\ninterdisciplinarity is related to a higher citation rates. For other\ndisciplines, citations decline as interdisciplinarity grows. One characteristic\nis visible in all disciplines: highly disciplinary and highly interdisciplinary\npapers have a low scientific impact. This suggests that there might be an\noptimum of interdisciplinarity beyond which the research is too dispersed to\nfind its niche and under which it is too mainstream to have high impact.\nFinally, the relationship between interdisciplinarity and scientific impact is\nhighly determined by the citation characteristics of the disciplines involved:\npapers citing citation intensive disciplines are more likely to be cited by\nthose disciplines and, hence, obtain higher citation scores than papers citing\nnon citation intensive disciplines."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1103/PhysRevE.80.037101", 
    "link": "http://arxiv.org/pdf/0908.2615v1", 
    "title": "Modeling scientific-citation patterns and other triangle-rich acyclic   networks", 
    "arxiv-id": "0908.2615v1", 
    "author": "Petter Holme", 
    "publish": "2009-08-18T19:25:45Z", 
    "summary": "We propose a model of the evolution of the networks of scientific citations.\nThe model takes an out-degree distribution (distribution of number of\ncitations) and two parameters as input. The parameters capture the two main\ningredients of the model, the aging of the relevance of papers and the\nformation of triangles when new papers cite old. We compare our model with\nthree network structural quantities of an empirical citation network. We find\nthat an unique point in parameter space optimizing the match between the real\nand model data for all quantities. The optimal parameter values suggest that\nthe impact of scientific papers, at least in the empirical data set we model is\nproportional to the inverse of the number of papers since they were published."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1103/PhysRevE.80.037101", 
    "link": "http://arxiv.org/pdf/0908.3177v1", 
    "title": "The impact factor's Matthew effect: a natural experiment in   bibliometrics", 
    "arxiv-id": "0908.3177v1", 
    "author": "Yves Gingras", 
    "publish": "2009-08-21T17:56:47Z", 
    "summary": "Since the publication of Robert K. Merton's theory of cumulative advantage in\nscience (Matthew Effect), several empirical studies have tried to measure its\npresence at the level of papers, individual researchers, institutions or\ncountries. However, these studies seldom control for the intrinsic \"quality\" of\npapers or of researchers--\"better\" (however defined) papers or researchers\ncould receive higher citation rates because they are indeed of better quality.\nUsing an original method for controlling the intrinsic value of\npapers--identical duplicate papers published in different journals with\ndifferent impact factors--this paper shows that the journal in which papers are\npublished have a strong influence on their citation rates, as duplicate papers\npublished in high impact journals obtain, on average, twice as much citations\nas their identical counterparts published in journals with lower impact\nfactors. The intrinsic value of a paper is thus not the only reason a given\npaper gets cited or not; there is a specific Matthew effect attached to\njournals and this gives to paper published there an added value over and above\ntheir intrinsic quality."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20095", 
    "link": "http://arxiv.org/pdf/0909.4786v1", 
    "title": "Worldwide Use and Impact of the NASA Astrophysics Data System Digital   Library", 
    "arxiv-id": "0909.4786v1", 
    "author": "Stephen S. Murray", 
    "publish": "2009-09-25T20:31:24Z", 
    "summary": "By combining data from the text, citation, and reference databases with data\nfrom the ADS readership logs we have been able to create Second Order\nBibliometric Operators, a customizable class of collaborative filters which\npermits substantially improved accuracy in literature queries.\n  Using the ADS usage logs along with membership statistics from the\nInternational Astronomical Union and data on the population and gross domestic\nproduct (GDP) we develop an accurate model for world-wide basic research where\nthe number of scientists in a country is proportional to the GDP of that\ncountry, and the amount of basic research done by a country is proportional to\nthe number of scientists in that country times that country's per capita GDP.\n  We introduce the concept of utility time to measure the impact of the\nADS/URANIA and the electronic astronomical library on astronomical research. We\nfind that in 2002 it amounted to the equivalent of 736 FTE researchers, or $250\nMillion, or the astronomical research done in France.\n  Subject headings: digital libraries; bibliometrics; sociology of science;\ninformation retrieval"
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0909.4789v1", 
    "title": "The Bibliometric Properties of Article Readership Information", 
    "arxiv-id": "0909.4789v1", 
    "author": "Barbara Elwell", 
    "publish": "2009-09-25T20:29:52Z", 
    "summary": "The NASA Astrophysics Data System (ADS), along with astronomy's journals and\ndata centers (a collaboration dubbed URANIA), has developed a distributed\non-line digital library which has become the dominant means by which\nastronomers search, access and read their technical literature. Digital\nlibraries such as the NASA Astrophysics Data System permit the easy\naccumulation of a new type of bibliometric measure, the number of electronic\naccesses (``reads'') of individual articles. We explore various aspects of this\nnew measure. We examine the obsolescence function as measured by actual reads,\nand show that it can be well fit by the sum of four exponentials with very\ndifferent time constants. We compare the obsolescence function as measured by\nreadership with the obsolescence function as measured by citations. We find\nthat the citation function is proportional to the sum of two of the components\nof the readership function. This proves that the normative theory of citation\nis true in the mean. We further examine in detail the similarities and\ndifferences between the citation rate, the readership rate and the total\ncitations for individual articles, and discuss some of the causes. Using the\nnumber of reads as a bibliometric measure for individuals, we introduce the\nread-cite diagram to provide a two-dimensional view of an individual's\nscientific productivity. We develop a simple model to account for an\nindividual's reads and cites and use it to show that the position of a person\nin the read-cite diagram is a function of age, innate productivity, and work\nhistory. We show the age biases of both reads and cites, and develop two new\nbibliometric measures which have substantially less age bias than citations"
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0911.0486v1", 
    "title": "Building a Vietnamese Language Query Processing Framework for ELibrary   Searching Systems", 
    "arxiv-id": "0911.0486v1", 
    "author": "Tuyen Thi-Thanh Do", 
    "publish": "2009-11-03T04:13:32Z", 
    "summary": "In the objective of building intelligent searching systems for Elibraries or\nonline bookstores, we have proposed a searching system model based on a\nVietnamese language query processing component. Such document searching systems\nbased on this model can allow users to use Vietnamese queries that represent\ncontent information as input, instead of entering keywords for searching in\nspecific fields in database. To simplify the realization process of system\nbased on this searching system model, we set a target of building a framework\nto support the rapid development of Vietnamese language query processing\ncomponents. Such framework let the implementation of Vietnamese language query\nprocessing component in similar systems in this domain to be done more easily."
},{
    "category": "cs.IR", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0911.1112v2", 
    "title": "Memento: Time Travel for the Web", 
    "arxiv-id": "0911.1112v2", 
    "author": "Harihar Shankar", 
    "publish": "2009-11-05T20:52:22Z", 
    "summary": "The Web is ephemeral. Many resources have representations that change over\ntime, and many of those representations are lost forever. A lucky few manage to\nreappear as archived resources that carry their own URIs. For example, some\ncontent management systems maintain version pages that reflect a frozen prior\nstate of their changing resources. Archives recurrently crawl the web to obtain\nthe actual representation of resources, and subsequently make those available\nvia special-purpose archived resources. In both cases, the archival copies have\nURIs that are protocol-wise disconnected from the URI of the resource of which\nthey represent a prior state. Indeed, the lack of temporal capabilities in the\nmost common Web protocol, HTTP, prevents getting to an archived resource on the\nbasis of the URI of its original. This turns accessing archived resources into\na significant discovery challenge for both human and software agents, which\ntypically involves following a multitude of links from the original to the\narchival resource, or of searching archives for the original URI. This paper\nproposes the protocol-based Memento solution to address this problem, and\ndescribes a proof-of-concept experiment that includes major servers of archival\ncontent, including Wikipedia and the Internet Archive. The Memento solution is\nbased on existing HTTP capabilities applied in a novel way to add the temporal\ndimension. The result is a framework in which archived resources can seamlessly\nbe reached via the URI of their original: protocol-based time travel for the\nWeb."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0911.1440v1", 
    "title": "Caveats for the Use of Citation Indicators in Research and Journal   Evaluations", 
    "arxiv-id": "0911.1440v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2009-11-07T18:43:47Z", 
    "summary": "Ageing of publications, percentage of self-citations, and impact vary from\njournal to journal within fields of science. The assumption that citation and\npublication practices are homogenous within specialties and fields of science\nis invalid. Furthermore, the delineation of fields and among specialties is\nfuzzy. Institutional units of analysis and persons may move between fields or\nspan different specialties. The match between the citation index and\ninstitutional profiles varies among institutional units and nations. The\nrespective matches may heavily affect the representation of the units. Non-ISI\njournals are increasingly cornered into \"transdisciplinary\" Mode-2 functions\nwith the exception of specialist journals publishing in languages other than\nEnglish. An \"externally cited impact factor\" can be calculated for these\njournals. The citation impact of non-ISI journals will be demonstrated using\nScience and Public Policy as the example."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0911.1445v1", 
    "title": "The delineation of nanoscience and nanotechnology in terms of journals   and patents: a most recent update", 
    "arxiv-id": "0911.1445v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2009-11-07T18:47:52Z", 
    "summary": "The journal set which provides a representation of nanoscience and\nnanotechnology at the interfaces among applied physics, chemistry, and the life\nsciences is developing rapidly because of the introduction of new journals. The\nrelevant contributions of nations can be expected to change according to the\nrepresentations of the relevant interfaces among journal sets. In the 2005 set\nthe position of the USA decreased more than in the 2004-set, while the EU-27\ngained in terms of its percentage of world share of citations. The tag \"Y01N\"\nwhich was newly added to the EU classification system for patents, allows for\nthe visualization of national profiles of nanotechnology in terms of relevant\npatents and patent classes."
},{
    "category": "cs.CL", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0911.1451v1", 
    "title": "Co-word Analysis using the Chinese Character Set", 
    "arxiv-id": "0911.1451v1", 
    "author": "Ping Zhou", 
    "publish": "2009-11-07T19:15:33Z", 
    "summary": "Until recently, Chinese texts could not be studied using co-word analysis\nbecause the words are not separated by spaces in Chinese (and Japanese). A word\ncan be composed of one or more characters. The online availability of programs\nthat separate Chinese texts makes it possible to analyze them using semantic\nmaps. Chinese characters contain not only information, but also meaning. This\nmay enhance the readability of semantic maps. In this study, we analyze 58\nwords which occur ten or more times in the 1652 journal titles of the China\nScientific and Technical Papers and Citations Database. The word occurrence\nmatrix is visualized and factor-analyzed."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0911.1454v1", 
    "title": "Main-path analysis and path-dependent transitions in HistCite(TM)-based   historiograms", 
    "arxiv-id": "0911.1454v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2009-11-07T19:36:46Z", 
    "summary": "With the program HistCite(TM) it is possible to generate and visualize the\nmost relevant papers in a set of documents retrieved from the Science Citation\nIndex. Historical reconstructions of scientific developments can be represented\nchronologically as developments in networks of citation relations extracted\nfrom scientific literature. This study aims to go beyond the historical\nreconstruction of scientific knowledge, enriching the output of HistCite(TM)\nwith algorithms from social network analysis and information theory."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0911.1456v1", 
    "title": "Korean journals in the Science Citation Index: What do they reveal about   the intellectual structure of S&T in Korea?", 
    "arxiv-id": "0911.1456v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2009-11-07T20:05:08Z", 
    "summary": "During the last decade, we have witnessed a sustained growth of South Korea's\nresearch output in terms of the world share of publications in the Science\nCitation Index database. However, Korea's citation performance is not yet as\ncompetitive as publication performance. In this study, the authors examine the\nintellectual structure of Korean S&T field based on social network analysis of\njournal-journal citation data using the ten Korean SCI journals as seed\njournals. The results reveal that Korean SCI journals function more like\npublication places, neither research channels nor information sources among\nnational scientists. Thus, these journals may provide Korean scholars with\naccess to international scientific communities by facilitating the respective\nentry barriers. However, there are no citation relations based on their Korean\nbackground. Furthermore, we intend to draw some policy implications which may\nbe helpful to increase Korea's research potential."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0911.2364v1", 
    "title": "Journals as constituents of scientific discourse: economic heterodoxy", 
    "arxiv-id": "0911.2364v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2009-11-12T11:12:11Z", 
    "summary": "Purpose: to provide a view and analysis of the immediate field of journals\nwhich surround a number of key heterodox economics journals.\nDesign/methodology/approach: Using citation data from the Science and Social\nScience Citation Index, the individual and collective networks of a number of\njournals in this field are analyzed. Findings: The size and shape of the\ncitation networks of journals can differ substantially, even if in a broadly\nsimilar category. Heterodox economics cannot (yet) be considered as an\nintegrated specialty: authors in several journals in heterodox economics cite\nmore from mainstream economics than from other heterodox journals. There are\nalso strong links with other disciplinary fields such as geography, development\nstudies, women studies, etc."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0911.2632v1", 
    "title": "Measuring contextual citation impact of scientific journals", 
    "arxiv-id": "0911.2632v1", 
    "author": "Henk F. Moed", 
    "publish": "2009-11-13T15:10:31Z", 
    "summary": "This paper explores a new indicator of journal citation impact, denoted as\nsource normalized impact per paper (SNIP). It measures a journal's contextual\ncitation impact, taking into account characteristics of its properly defined\nsubject field, especially the frequency at which authors cite other papers in\ntheir reference lists, the rapidity of maturing of citation impact, and the\nextent to which a database used for the assessment covers the field's\nliterature. It further develops Eugene Garfield's notions of a field's\n'citation potential' defined as the average length of references lists in a\nfield and determining the probability of being cited, and the need in fair\nperformance assessments to correct for differences between subject fields. A\njournal's subject field is defined as the set of papers citing that journal.\nSNIP is defined as the ratio of the journal's citation count per paper and the\ncitation potential in its subject field. It aims to allow direct comparison of\nsources in different subject fields. Citation potential is shown to vary not\nonly between journal subject categories - groupings of journals sharing a\nresearch field - or disciplines (e.g., journals in mathematics, engineering and\nsocial sciences tend to have lower values than titles in life sciences), but\nalso between journals within the same subject category. For instance, basic\njournals tend to show higher citation potentials than applied or clinical\njournals, and journals covering emerging topics higher than periodicals in\nclassical subjects or more general journals. SNIP corrects for such\ndifferences. Its strengths and limitations are critically discussed, and\nsuggestions are made for further research. All empirical results are derived\nfrom Elsevier's Scopus."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0911.2731v1", 
    "title": "Visualization of the Citation Impact Environments of Scientific   Journals: An online mapping exercise", 
    "arxiv-id": "0911.2731v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2009-11-13T23:20:36Z", 
    "summary": "Aggregated journal-journal citation networks based on the Journal Citation\nReports 2004 of the Science Citation Index (5968 journals) and the Social\nScience Citation Index (1712 journals) are made accessible from the perspective\nof any of these journals. The user is thus able to analyze the citation\nenvironment in terms of links and graphs. Furthermore, the local impact of a\njournal is defined as its share of the total citations in the specific\njournal's citation environments; the vertical size of the nodes is varied\nproportionally to this citation impact. The horizontal size of each node can be\nused to provide the same information after correction for within-journal\n(self)-citations. In the \"citing\" environment, the equivalents of this measure\ncan be considered as a citation activity index which maps how the relevant\njournal environment is perceived by the collective of authors of a given\njournal. As a policy application, the mechanism of interdisciplinary\ndevelopments among the sciences is elaborated for the case of nanotechnology\njournals."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0911.3086v1", 
    "title": "Citation Environment of Angewandte Chemie", 
    "arxiv-id": "0911.3086v1", 
    "author": "Werner Marx", 
    "publish": "2009-11-16T17:19:46Z", 
    "summary": "Recently, aggregated journal-journal citation networks were made accessible\nfrom the perspective of each journal included in the Science Citation Index see\n(http://www.leydesdorff.net/). The local matrices can be used to inspect the\nrelevant citation environment of a journal using statistical analysis and\nvisualization techniques from social network analysis. The inspection gives an\nanswer to the question what the local impact of this and other journals in the\nenvironment is. In this study the citation environment of Angewandte Chemie was\nanalysed. Angewandte Chemie is one of the prime chemistry journals in the\nworld. Its environment was compared with that of the Journal of the American\nChemical Society. The results of the environment analyses give a detailed\ninsight into the field-embeddedness of Angewandte Chemie. The impacts of the\nGerman and international editions of this journal are compared."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0911.3087v1", 
    "title": "A Comparison between the China Scientific and Technical Papers and   Citations Database and the Science Citation Index in terms of journal   hierarchies and inter-journal citation relations", 
    "arxiv-id": "0911.3087v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2009-11-16T17:24:56Z", 
    "summary": "The journal structure in the China Scientific and Technical Papers and\nCitations Database (CSTPCD) is analysed from three perspectives: the database\nlevel, the specialty level and the institutional level (i.e., university\njournals versus journals issued by the Chinese Academy of Sciences). The\nresults are compared with those for (Chinese) journals included in the Science\nCitation Index. The frequency of journal-journal citation relations in the\nCSTPCD is an order of magnitude lower than in the SCI. Chinese journals,\nespecially high-quality journals, prefer to cite international journals rather\nthan domestic ones. However, Chinese journals do not get an equivalent\nreception from their international counterparts. The international visibility\nof Chinese journals is low, but varies among fields of science. Journals of the\nChinese Academy of Sciences (CAS) have a better reception in the international\nscientific community than university journals."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0911.3093v1", 
    "title": "Indicators of Structural Change in the Dynamics of Science: Entropy   Statistics of the SCI Journal Citation Reports", 
    "arxiv-id": "0911.3093v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2009-11-16T17:39:35Z", 
    "summary": "Can change in citation patterns among journals be used as an indicator of\nstructural change in the organization of the sciences? Aggregated\njournal-journal citations for 1999 are compared with similar data in the\nJournal Citation Reports 1998 of the Science Citation Index. In addition to\nindicating local change, probabilistic entropy measures enable us to analyze\nchanges in distributions at different levels of aggregation. The results of\nvarious statistics are discussed and compared by elaborating the\njournal-journal mappings. The relevance of this indicator for science and\ntechnology policies is further specified."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0911.3095v1", 
    "title": "Environment and Planning B as a Journal: The interdisciplinarity of its   environment and the citation impact", 
    "arxiv-id": "0911.3095v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2009-11-16T17:44:32Z", 
    "summary": "The citation impact of Environment and Planning B can be visualized using its\ncitation relations with journals in its environment as the links of a network.\nThe size of the nodes is varied in correspondence to the relative citation\nimpact in this environment. Additionally, one can correct for the effect of\nwithin-journal \"self\"-citations. The network can be partitioned and clustered\nusing algorithms from social network analysis. After transposing the matrix in\nterms of rows and columns, the citing patterns can be mapped analogously.\nCiting patterns reflect the activity of the community of authors who publish in\nthe journal, while being cited indicates reception. Environment and Planning B\nis cited across the interface between the social sciences and the natural\nsciences, but its authors cite almost exclusively from the domain of the Social\nScience Citation Index."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0911.3641v1", 
    "title": "The Import and Export of Cognitive Science", 
    "arxiv-id": "0911.3641v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2009-11-18T20:00:02Z", 
    "summary": "From its inception, a large part of the motivation for Cognitive Science has\nbeen the need for an interdisciplinary journal for the study of minds and\nintelligent systems. One threat to the interdisciplinarity of Cognitive\nScience, both the field and journal, is that it may become, or already be, too\ndominated by psychologists. In 2005, psychology was a keyword for 51% of\nsubmissions, followed distantly by linguistics (17%), artificial intelligence\n(13%), neuroscience (10%), computer science (9%), and philosophy (8%). The\nInstitute for Scientific Information (ISI) gathers data not only on how\nindividual articles cite one another, but also on macroscopic citation patterns\namong journals. Journals or sets of journals can be considered as proxies for\nfields. As fields become established, they often create journals. By studying\nthe patterns of citations among journals that cite and are cited by Cognitive\nScience, we can better: 1) appreciate the scholarly ecology surrounding the\njournal and the journals role within this ecology, 2) establish competitor and\nalternate journals, and 3) determine the natural clustering of fields related\nto cognitive science."
},{
    "category": "physics.comp-ph", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0912.0360v1", 
    "title": "Geant4 in Scientific Literature", 
    "arxiv-id": "0912.0360v1", 
    "author": "P. V. Dressendorfer", 
    "publish": "2009-12-02T08:46:24Z", 
    "summary": "The Geant4 reference paper published in Nuclear Instruments and Methods A in\n2003 has become the most cited publication in the whole Nuclear Science and\nTechnology category of Thomson-Reuter's Journal Citation Reports. It is\ncurrently the second most cited article among the publications authored by two\nmajor research institutes, CERN and INFN. An overview of Geant4 presence (and\nabsence) in scholarly literature is presented; the patterns of Geant4 citations\nare quantitatively examined and discussed."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0912.1221v1", 
    "title": "Clusters and Maps of Science Journals Based on Bi-connected Graphs in   the Journal Citation Reports", 
    "arxiv-id": "0912.1221v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2009-12-07T12:56:11Z", 
    "summary": "The aggregated journal-journal citation matrix derived from the Journal\nCitation Reports 2001 can be decomposed into a unique subject classification by\nusing the graph-analytical algorithm of bi-connected components. This technique\nwas recently incorporated in software tools for social network analysis. The\nmatrix can be assessed in terms of its decomposability using articulation\npoints which indicate overlap between the components. The articulation points\nof this set did not exhibit a next-order network of 'general science' journals.\nHowever, the clusters differ in size and in terms of the internal density of\ntheir relations. A full classification of the journals is provided in an\nAppendix. The clusters can also be extracted and mapped for the visualization."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0912.1227v1", 
    "title": "Mapping the Chinese Science Citation Database", 
    "arxiv-id": "0912.1227v1", 
    "author": "Jin Bihui", 
    "publish": "2009-12-07T13:07:49Z", 
    "summary": "Methods developed for mapping the journal structures contained in aggregated\njournal-journal citations in the Science Citation Index are applied to the\nChinese Science Citation Database of the Chinese Academy of Sciences. This\ndatabase covers 991 journals, of which only 37 had originally English titles.\nUsing factor-analytical and graph-analytical techniques we show that this data\nis dually structured. The main structure is the intellectual organization of\nthe journals in journal groups (as in the international SCI), but the\nuniversity-based journals provide an institutional layer that orients this\nstructure towards practical ends (e.g., agriculture). The Chinese Science\nCitation Database exhibits the characteristics of Mode 2 in the production of\nscientific knowledge more than its western counterparts. The contexts of\napplication lead to correlation (interfactorial complexity) among the\ncomponents."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0912.1231v1", 
    "title": "Scientometrics and the evaluation of European integration", 
    "arxiv-id": "0912.1231v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2009-12-07T13:15:09Z", 
    "summary": "In this chapter, we elaborate on the topic of European integration in\nscience. We will not deal with questions related to the effects of European\nintegration, but only with the scientometric question how one can\nquantitatively indicate integration of the European science system. Our study\nis intended to facilitate and supplement debates rather than to provide a final\nanswer to the questions whether European integration 'exists'. In this chapter,\nwe first discuss the use of scientometric indicators in research evaluation\nfrom a historical perspective in (section 2). A discussion of European science\npolicy follows (section 3). Then, we introduce a number of indicators of\nintegration and discuss our empirical results concerning the evolution of the\nEuropean science system in the 1980s and 1990s (section 4). We close the\nchapter with a discussion of possible avenues of future research for enhancing\nresearch evaluation (section 5)."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0912.1371v1", 
    "title": "A study of seismology as a dynamic, distributed area of scientific   research", 
    "arxiv-id": "0912.1371v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2009-12-07T23:33:33Z", 
    "summary": "Seismology has several features that suggest it is a highly internationalized\nfield: the subject matter is global, the tools used to analyse seismic waves\nare dependent upon information technologies, and governments are interested in\nfunding cooperative research. We explore whether an emerging field like\nseismology has a more internationalised structure than the older, related field\nof geophysics. Using aggregated journal-journal citations, we first show that,\nwithin the citing environment, seismology emerged from within geophysics as its\nown field in the 1990s. The bibliographic analysis, however, does not show that\nseismology is more internationalised than geophysics: in 2000, seismology had a\nlower percentage of all articles co-authored on an international basis.\nNevertheless, social network analysis shows that the core group of cooperating\ncountries within seismology is proportionately larger and more distributed than\nthat within geophysics. While the latter exhibits an established network with a\nhierarchy, the formation of a field in terms of new partnership relations is\nongoing in seismology."
},{
    "category": "cs.CY", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0912.2601v1", 
    "title": "The first Italian research assessment exercise: a bibliometric   perspective", 
    "arxiv-id": "0912.2601v1", 
    "author": "Antonio Costantini", 
    "publish": "2009-12-14T09:43:20Z", 
    "summary": "In December 2003, seventeen years after the first UK research assessment\nexercise, Italy started up its first-ever national research evaluation, with\nthe aim to evaluate, using the peer review method, the excellence of the\nnational research production. The evaluation involved 20 disciplinary areas,\n102 research structures, 18,500 research products and 6,661 peer reviewers\n(1,465 from abroad); it had a direct cost of 3.55 millions Euros and a time\nlength spanning over 18 months. The introduction of ratings based on ex post\nquality of output and not on ex ante respect for parameters and compliance is\nan important leap forward of the national research evaluation system toward\nmeritocracy. From the bibliometric perspective, the national assessment offered\nthe unprecedented opportunity to perform a large-scale comparison of peer\nreview and bibliometric indicators for an important share of the Italian\nresearch production. The present investigation takes full advantage of this\nopportunity to test whether peer review judgements and (article and journal)\nbibliometric indicators are independent variables and, in the negative case, to\nmeasure the sign and strength of the association. Outcomes allow us to advocate\nthe use of bibliometric evaluation, suitably integrated with expert review, for\nthe forthcoming national assessment exercises, with the goal of shifting from\nthe assessment of research excellence to the evaluation of average research\nperformance without significant increase of expenses."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0912.3098v1", 
    "title": "Maps on the basis of the Arts & Humanities Citation Index: The journals   Leonardo and Art Journal versus \"Digital Humanities\" as a topic", 
    "arxiv-id": "0912.3098v1", 
    "author": "Alkim Almila Akdag Salah", 
    "publish": "2009-12-16T10:53:03Z", 
    "summary": "The possibilities of using the Arts & Humanities Citation Index (A&HCI) for\njournal mapping have not been sufficiently recognized because of the absence of\na Journal Citations Report (JCR) for this database. A quasi-JCR for the A&HCI\n(2008) was constructed from the data contained in the Web-of-Science and is\nused for the evaluation of two journals as examples: Leonardo and Art Journal.\nThe maps on the basis of the aggregated journal-journal citations within this\ndomain can be compared with maps including references to journals in the\nScience Citation Index and Social Science Citation Index. Art journals are\ncited by (social) science journals more than by other art journals, but these\njournals draw upon one another in terms of their own references. This cultural\nimpact in terms of being cited is not found when documents with a topic such as\n\"digital humanities\" are analyzed. This community of practice functions more as\nan intellectual organizer than a journal."
},{
    "category": "physics.data-an", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0912.3573v1", 
    "title": "An index to link scientific productivity with visibility", 
    "arxiv-id": "0912.3573v1", 
    "author": "Ren Zhang", 
    "publish": "2009-12-18T02:27:59Z", 
    "summary": "I here propose an index that links the number of papers a researcher has\npublished with impact factors (IFs) of the journals that publish these papers.\nA researcher is said to have an index z if totally z of his/her papers are\npublished in journals with IFs of at least z/2. The z-index, not meant to\nevaluate, compare and rank scientists, is a number that hopefully conveniently\nsummarizes the number of publications in journals with high IFs."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0912.3953v1", 
    "title": "Studies on access: a review", 
    "arxiv-id": "0912.3953v1", 
    "author": "Philip M. Davis", 
    "publish": "2009-12-20T02:26:12Z", 
    "summary": "A review of the empirical literature on access to scholarly information. This\nreview focuses on surveys of authors, article download and citation analysis."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0912.4141v1", 
    "title": "The SJR indicator: A new indicator of journals' scientific prestige", 
    "arxiv-id": "0912.4141v1", 
    "author": "Felix Moya-Anegon", 
    "publish": "2009-12-21T11:32:08Z", 
    "summary": "This paper proposes an indicator of journals' scientific prestige, the SJR\nindicator, for ranking scholarly journals based on citation weighting schemes\nand eigenvector centrality to be used in complex and heterogeneous citation\nnetworks such Scopus. Its computation methodology is described and the results\nafter implementing the indicator over Scopus 2007 dataset are compared to an\nad-hoc Journal Impact Factor both generally and inside specific scientific\nareas. The results showed that SJR indicator and JIF distributions fitted well\nto a power law distribution and that both metrics were strongly correlated,\nalthough there were also major changes in rank. There was an observable general\ntrend that might indicate that SJR indicator values decreased certain JIF\nvalues whose citedeness was greater than would correspond to their scientific\ninfluence."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/0912.4188v2", 
    "title": "The skewness of computer science", 
    "arxiv-id": "0912.4188v2", 
    "author": "Massimo Franceschet", 
    "publish": "2009-12-21T15:24:08Z", 
    "summary": "Computer science is a relatively young discipline combining science,\nengineering, and mathematics. The main flavors of computer science research\ninvolve the theoretical development of conceptual models for the different\naspects of computing and the more applicative building of software artifacts\nand assessment of their properties. In the computer science publication\nculture, conferences are an important vehicle to quickly move ideas, and\njournals often publish deeper versions of papers already presented at\nconferences. These peculiarities of the discipline make computer science an\noriginal research field within the sciences, and, therefore, the assessment of\nclassical bibliometric laws is particularly important for this field. In this\npaper, we study the skewness of the distribution of citations to papers\npublished in computer science publication venues (journals and conferences). We\nfind that the skewness in the distribution of mean citedness of different\nvenues combines with the asymmetry in citedness of articles in each venue,\nresulting in a highly asymmetric citation distribution with a power law tail.\nFurthermore, the skewness of conference publications is more pronounced than\nthe asymmetry of journal papers. Finally, the impact of journal papers, as\nmeasured with bibliometric indicators, largely dominates that of proceeding\npapers."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1002/asi.20096", 
    "link": "http://arxiv.org/pdf/1001.0039v1", 
    "title": "TGCat, The Chandra Transmission Grating Catalog and Archive: Systems,   Design and Accessibility", 
    "arxiv-id": "1001.0039v1", 
    "author": "Joy S. Nichols", 
    "publish": "2009-12-30T22:37:24Z", 
    "summary": "The recently released Chandra Transmission Grating Catalog and Archive,\nTGCat, presents a fully dynamic on-line catalog allowing users to browse and\ncategorize Chandra gratings observations quickly and easily, generate custom\nplots of resulting response corrected spectra on-line without the need for\nspecial software and to download analysis ready products from multiple\nobservations in one convenient operation. TGCat has been registered as a VO\nresource with the NVO providing direct access to the catalogs interface. The\ncatalog is supported by a back-end designed to automatically fetch newly public\ndata, process, archive and catalog them, At the same time utilizing an advanced\nqueue system integrated into the archive's MySQL database allowing large\nprocessing projects to take advantage of an unlimited number of CPUs across a\nnetwork for rapid completion. A unique feature of the catalog is that all of\nthe high level functions used to retrieve inputs from the Chandra archive and\nto generate the final data products are available to the user in an ISIS\nwritten library with detailed documentation. Here we present a structural\noverview of the Systems, Design, and Accessibility features of the catalog and\narchive."
},{
    "category": "cs.CY", 
    "doi": "10.1371/journal.pone.0013636", 
    "link": "http://arxiv.org/pdf/1001.0361v2", 
    "title": "Self-Selected or Mandated, Open Access Increases Citation Impact for   Higher Quality Research", 
    "arxiv-id": "1001.0361v2", 
    "author": "Stevan Harnad", 
    "publish": "2010-01-03T11:57:20Z", 
    "summary": "Articles whose authors make them Open Access (OA) by self-archiving them\nonline are cited significantly more than articles accessible only to\nsubscribers. Some have suggested that this \"OA Advantage\" may not be causal but\njust a self-selection bias, because authors preferentially make higher-quality\narticles OA. To test this we compared self-selective self-archiving with\nmandatory self-archiving for a sample of 27,197 articles published 2002-2006 in\n1,984 journals. The OA Advantage proved just as high for both. Logistic\nregression showed that the advantage is independent of other correlates of\ncitations (article age; journal impact factor; number of co-authors, references\nor pages; field; article type; or country) and greatest for the most highly\ncited articles. The OA Advantage is real, independent and causal, but skewed.\nIts size is indeed correlated with quality, just as citations themselves are\n(the top 20% of articles receive about 80% of all citations). The advantage is\ngreater for the more citeable articles, not because of a quality bias from\nauthors self-selecting what to make OA, but because of a quality advantage,\nfrom users self-selecting what to use and cite, freed by OA from the\nconstraints of selective accessibility to subscribers only."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1371/journal.pone.0013636", 
    "link": "http://arxiv.org/pdf/1001.2837v1", 
    "title": "The long-term dynamics of co-authorship scientific networks,   Iberoamerican Countries (1973-2006)", 
    "arxiv-id": "1001.2837v1", 
    "author": "Guillermo A. Lemarchand", 
    "publish": "2010-01-16T15:44:28Z", 
    "summary": "We study the national production of academic knowledge in all Iberoamerican\ncountries (IAC) between 1973 and 2007. We show that the total number of\nmainstream scientific publications listed in SCI,SSCI and A&HCI follows an\nexponential growth, the same as the national productivity expressed in the\nnumber of publications per capita. We also explore the temporal evolution of\nthe co-authorship patterns between a sample of 12 IAC responsible for 98% of\nthe total regional publications, with a group of other 45 nations. We show that\nthe scientific co-authorship among countries follows a power-law and behaves as\na self-organizing scale-free network, where each country appears as a node and\neach co-publication as a link. We develop a mathematical model to study the\ntemporal evolution of co-authorship networks, based on a preferential\nattachment strategy and we show that the number of co-publications among\ncountries growths quadraticly against time. We empirically determine the\nquadratic growth constants for 352 different networks within. We corroborate\nthat the connectivity of regional countries with larger scientific networks is\ngrowing faster than with other less connected countries. We determine the\ndates, at which the co-authorship connectivities trigger the self-organizing\nscale free network for each of the 352 cases. We find that the last follows a\nnormal distribution around year 1981.4 +/-2.2 and we connect the last effect\nwith a brain-drainage process generated in the region. We show how the number\nof co-publications Pki (t) between country k and country i, is related with a\npower-law against the coupling growth coefficients aki."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0013636", 
    "link": "http://arxiv.org/pdf/1001.4433v1", 
    "title": "Scientometrics and Communication Theory: Towards Theoretically Informed   Indicators", 
    "arxiv-id": "1001.4433v1", 
    "author": "Peter Van den Besselaar", 
    "publish": "2010-01-25T14:08:00Z", 
    "summary": "A theory of citations should not consider cited and/or citing agents as its\nsole subject of study. One is able to study also the dynamics in the networks\nof communications. While communicating agents (e.g., authors, laboratories,\njournals) can be made comparable in terms of their publication and citation\ncounts, one would expect the communication networks not to be homogeneous. The\nlatent structures of the network indicate different codifications that span a\nspace of possible 'translations'. The various subdynamics can be hypothesized\nfrom an evolutionary perspective. Using the network of aggregated\njournal-journal citations in Science & Technology Studies as an empirical case,\nthe operation of such subdynamics can be demonstrated. Policy implications and\nthe consequences for a theory-driven type of scientometrics will be elaborated."
},{
    "category": "hep-lat", 
    "doi": "10.1371/journal.pone.0013636", 
    "link": "http://arxiv.org/pdf/1001.5207v1", 
    "title": "International Lattice Data Grid: Turn on, plug in,and download", 
    "arxiv-id": "1001.5207v1", 
    "author": "C. M. Maynard", 
    "publish": "2010-01-28T16:10:01Z", 
    "summary": "In the beginning there was the internet, then came the world wide web, and\nnow there is the grid. In the future perhaps there will be the cloud. In the\nage of persistent, pervasive, and pandemic networks I review how the lattice\nQCD community embraced the open source paradigm for both code and data whilst\nadopting the emerging grid technologies, and why having your data persistently\naccessible via standardized protocols and services might be a good idea."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0013636", 
    "link": "http://arxiv.org/pdf/1002.0532v1", 
    "title": "What Can Heterogeneity Add to the Scientometric Map? Steps towards   algorithmic historiography", 
    "arxiv-id": "1002.0532v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2010-02-02T16:45:27Z", 
    "summary": "The Actor Network represents heterogeneous entities as actants (Callon et\nal., 1983; 1986). Although computer programs for the visualization of social\nnetworks increasingly allow us to represent heterogeneity in a network using\ndifferent shapes and colors for the visualization, hitherto this possibility\nhas scarcely been exploited (Mogoutov et al., 2008). In this contribution to\nthe Festschrift, I study the question of what heterogeneity can add\nspecifically to the visualization of a network. How does an integrated network\nimprove on the one-dimensional ones (such as co-word and co-author maps)? The\noeuvre of Michel Callon is used as the case materials, that is, his 65 papers\nwhich can be retrieved from the (Social) Science Citation Index since 1975."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0013636", 
    "link": "http://arxiv.org/pdf/1002.2769v1", 
    "title": "Caveats for the journal and field normalizations in the CWTS (\"Leiden\")   evaluations of research performance", 
    "arxiv-id": "1002.2769v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2010-02-14T12:07:43Z", 
    "summary": "The Center for Science and Technology Studies at Leiden University advocates\nthe use of specific normalizations for assessing research performance with\nreference to a world average. The Journal Citation Score (JCS) and Field\nCitation Score (FCS) are averaged for the research group or individual\nresearcher under study, and then these values are used as denominators of the\n(mean) Citations per publication (CPP). Thus, this normalization is based on\ndividing two averages. This procedure only generates a legitimate indicator in\nthe case of underlying normal distributions. Given the skewed distributions\nunder study, one should average the observed versus expected values which are\nto be divided first for each publication. We show the effects of the Leiden\nnormalization for a recent evaluation where we happened to have access to the\nunderlying data."
},{
    "category": "cs.IR", 
    "doi": "10.1371/journal.pone.0013636", 
    "link": "http://arxiv.org/pdf/1002.2858v3", 
    "title": "PageRank: Standing on the shoulders of giants", 
    "arxiv-id": "1002.2858v3", 
    "author": "Massimo Franceschet", 
    "publish": "2010-02-15T12:47:16Z", 
    "summary": "PageRank is a Web page ranking technique that has been a fundamental\ningredient in the development and success of the Google search engine. The\nmethod is still one of the many signals that Google uses to determine which\npages are most important. The main idea behind PageRank is to determine the\nimportance of a Web page in terms of the importance assigned to the pages\nhyperlinking to it. In fact, this thesis is not new, and has been previously\nsuccessfully exploited in different contexts. We review the PageRank method and\nlink it to some renowned previous techniques that we have found in the fields\nof Web information retrieval, bibliometrics, sociometry, and econometrics."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0013636", 
    "link": "http://arxiv.org/pdf/1003.2113v1", 
    "title": "Rivals for the crown: Reply to Opthof and Leydesdorff", 
    "arxiv-id": "1003.2113v1", 
    "author": "Ludo Waltman", 
    "publish": "2010-03-10T14:06:54Z", 
    "summary": "We reply to the criticism of Opthof and Leydesdorff [arXiv:1002.2769] on the\nway in which our institute applies journal and field normalizations to citation\ncounts. We point out why we believe most of the criticism is unjustified, but\nwe also indicate where we think Opthof and Leydesdorff raise a valid point."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0013636", 
    "link": "http://arxiv.org/pdf/1003.2167v2", 
    "title": "Towards a new crown indicator: Some theoretical considerations", 
    "arxiv-id": "1003.2167v2", 
    "author": "Anthony F. J. van Raan", 
    "publish": "2010-03-10T18:23:57Z", 
    "summary": "The crown indicator is a well-known bibliometric indicator of research\nperformance developed by our institute. The indicator aims to normalize\ncitation counts for differences among fields. We critically examine the\ntheoretical basis of the normalization mechanism applied in the crown\nindicator. We also make a comparison with an alternative normalization\nmechanism. The alternative mechanism turns out to have more satisfactory\nproperties than the mechanism applied in the crown indicator. In particular,\nthe alternative mechanism has a so-called consistency property. The mechanism\napplied in the crown indicator lacks this important property. As a consequence\nof our findings, we are currently moving towards a new crown indicator, which\nrelies on the alternative normalization mechanism."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0013636", 
    "link": "http://arxiv.org/pdf/1003.2198v1", 
    "title": "The relation between Eigenfactor, audience factor, and influence weight", 
    "arxiv-id": "1003.2198v1", 
    "author": "Nees Jan van Eck", 
    "publish": "2010-03-10T20:52:40Z", 
    "summary": "We present a theoretical and empirical analysis of a number of bibliometric\nindicators of journal performance. We focus on three indicators in particular,\nnamely the Eigenfactor indicator, the audience factor, and the influence weight\nindicator. Our main finding is that the last two indicators can be regarded as\na kind of special cases of the first indicator. We also find that the three\nindicators can be nicely characterized in terms of two properties. We refer to\nthese properties as the property of insensitivity to field differences and the\nproperty of insensitivity to insignificant journals. The empirical results that\nwe present illustrate our theoretical findings. We also show empirically that\nthe differences between various indicators of journal performance are quite\nsubstantial."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0013636", 
    "link": "http://arxiv.org/pdf/1003.2551v1", 
    "title": "A comparison of two techniques for bibliometric mapping:   Multidimensional scaling and VOS", 
    "arxiv-id": "1003.2551v1", 
    "author": "Jan van den Berg", 
    "publish": "2010-03-12T14:47:28Z", 
    "summary": "VOS is a new mapping technique that can serve as an alternative to the\nwell-known technique of multidimensional scaling. We present an extensive\ncomparison between the use of multidimensional scaling and the use of VOS for\nconstructing bibliometric maps. In our theoretical analysis, we show the\nmathematical relation between the two techniques. In our experimental analysis,\nwe use the techniques for constructing maps of authors, journals, and keywords.\nTwo commonly used approaches to bibliometric mapping, both based on\nmultidimensional scaling, turn out to produce maps that suffer from artifacts.\nMaps constructed using VOS turn out not to have this problem. We conclude that\nin general maps constructed using VOS provide a more satisfactory\nrepresentation of a data set than maps constructed using well-known\nmultidimensional scaling approaches."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0013636", 
    "link": "http://arxiv.org/pdf/1003.3530v1", 
    "title": "Topic Map: An Ontology Framework for Information Retrieval", 
    "arxiv-id": "1003.3530v1", 
    "author": "Rajkumar Kannan", 
    "publish": "2010-03-18T09:17:26Z", 
    "summary": "The basic classification techniques for organizing information are thesauri,\ntaxonomy and faceted classification. Topic map is relatively a new entrant to\nthis information space. Topic map standard describes how complex relationships\nbetween abstract concepts and real world resources can be represented using XML\nsyntax. This paper explores how topic map incorporates the traditional\ntechniques and what are its advantages and disadvantages in several dimensions\nsuch as content management, indexing, knowledge representation, constraint\nspecification and query languages in the context of information retrieval. The\nconstructs of topic maps are illustrated with a use-case implemented in XTM"
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0013636", 
    "link": "http://arxiv.org/pdf/1003.3613v2", 
    "title": "Indicators of the Interdisciplinarity of Journals: Diversity,   Centrality, and Citations", 
    "arxiv-id": "1003.3613v2", 
    "author": "Ismael Rafols", 
    "publish": "2010-03-18T15:52:27Z", 
    "summary": "A citation-based indicator for interdisciplinarity has been missing hitherto\namong the set of available journal indicators. In this study, we investigate\nnetwork indicators (betweenness centrality), journal indicators (Shannon\nentropy, the Gini coefficient), and more recently proposed Rao-Stirling\nmeasures for \"interdisciplinarity.\" The latter index combines the statistics of\nboth citation distributions of journals (vector-based) and distances in\ncitation networks among journals (matrix-based). The effects of various\nnormalizations are specified and measured using the matrix of 8,207 journals\ncontained in the Journal Citation Reports of the (Social) Science Citation\nIndex 2008. Betweenness centrality in symmetrical (1-mode) cosine-normalized\nnetworks provides an indicator outperforming betweenness in the asymmetrical\n(2-mode) citation network. Among the vector-based indicators, Shannon entropy\nperforms better than the Gini coefficient, but is sensitive to size. Science\nand Nature, for example, are indicated at the top of the list. The new\ndiversity measure provides reasonable results when (1 - cosine) is assumed as a\nmeasure for the distance, but results using Euclidean distances were difficult\nto interpret."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0013636", 
    "link": "http://arxiv.org/pdf/1003.3661v1", 
    "title": "An HTTP-Based Versioning Mechanism for Linked Data", 
    "arxiv-id": "1003.3661v1", 
    "author": "Scott Ainsworth", 
    "publish": "2010-03-18T19:21:11Z", 
    "summary": "Dereferencing a URI returns a representation of the current state of the\nresource identified by that URI. But, on the Web representations of prior\nstates of a resource are also available, for example, as resource versions in\nContent Management Systems or archival resources in Web Archives such as the\nInternet Archive. This paper introduces a resource versioning mechanism that is\nfully based on HTTP and uses datetime as a global version indicator. The\napproach allows \"follow your nose\" style navigation both from the current\ntime-generic resource to associated time-specific version resources as well as\namong version resources. The proposed versioning mechanism is congruent with\nthe Architecture of the World Wide Web, and is based on the Memento framework\nthat extends HTTP with transparent content negotiation in the datetime\ndimension. The paper shows how the versioning approach applies to Linked Data,\nand by means of a demonstrator built for DBpedia, it also illustrates how it\ncan be used to conduct a time-series analysis across versions of Linked Data\ndescriptions."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0013636", 
    "link": "http://arxiv.org/pdf/1003.5884v1", 
    "title": "CWTS crown indicator measures citation impact of a research group's   publication oeuvre", 
    "arxiv-id": "1003.5884v1", 
    "author": "Henk F. Moed", 
    "publish": "2010-03-30T18:17:58Z", 
    "summary": "The article \"Caveats for the journal and field normalizations in the CWTS\n(`Leiden') evaluations of research performance\", published by Tobias Opthof and\nLoet Leydesdorff (arXiv:1002.2769) deals with a subject as important as the\napplication of so called field normalized indicators of citation impact in the\nassessment of research performance of individual researchers and research\ngroups. Field normalization aims to account for differences in citation\npractices across scientific-scholarly subject fields. As the primary author of\nthe papers presenting the \"Leiden\" indicators and of many reports and articles\nreporting on the outcomes of assessments actually using these measures, I\ncomment on the 3 main issues addressed in the paper by Opthof and Leydesdorff."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0013636", 
    "link": "http://arxiv.org/pdf/1004.1632v2", 
    "title": "Towards a new crown indicator: An empirical analysis", 
    "arxiv-id": "1004.1632v2", 
    "author": "Anthony F. J. van Raan", 
    "publish": "2010-04-09T19:49:55Z", 
    "summary": "We present an empirical comparison between two normalization mechanisms for\ncitation-based indicators of research performance. These mechanisms aim to\nnormalize citation counts for the field and the year in which a publication was\npublished. One mechanism is applied in the current so-called crown indicator of\nour institute. The other mechanism is applied in the new crown indicator that\nour institute is planning to adopt. We find that at high aggregation levels,\nsuch as at the level of large research institutions or at the level of\ncountries, the differences between the two mechanisms are very small. At lower\naggregation levels, such as at the level of research groups or at the level of\njournals, the differences between the two mechanisms are somewhat larger. We\npay special attention to the way in which recent publications are handled.\nThese publications typically have very low citation counts and should therefore\nbe handled with special care."
},{
    "category": "cs.DL", 
    "doi": "10.1371/journal.pone.0013636", 
    "link": "http://arxiv.org/pdf/1004.3580v2", 
    "title": "Scopus's Source Normalized Impact per Paper (SNIP) versus a Journal   Impact Factor based on Fractional Counting of Citations", 
    "arxiv-id": "1004.3580v2", 
    "author": "Tobias Opthof", 
    "publish": "2010-04-20T21:17:52Z", 
    "summary": "Impact factors (and similar measures such as the Scimago Journal Rankings)\nsuffer from two problems: (i) citation behavior varies among fields of science\nand therefore leads to systematic differences, and (ii) there are no statistics\nto inform us whether differences are significant. The recently introduced SNIP\nindicator of Scopus tries to remedy the first of these two problems, but a\nnumber of normalization decisions are involved which makes it impossible to\ntest for significance. Using fractional counting of citations-based on the\nassumption that impact is proportionate to the number of references in the\nciting documents-citations can be contextualized at the paper level and\naggregated impacts of sets can be tested for their significance. It can be\nshown that the weighted impact of Annals of Mathematics (0.247) is not so much\nlower than that of Molecular Cell (0.386) despite a five-fold difference\nbetween their impact factors (2.793 and 13.156, respectively)."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1002/asi.21331", 
    "link": "http://arxiv.org/pdf/1004.5176v1", 
    "title": "Modes of Collaboration in Modern Science - Beyond Power Laws and   Preferential Attachment", 
    "arxiv-id": "1004.5176v1", 
    "author": "Sta\u0161a Milojevi\u0107", 
    "publish": "2010-04-29T02:35:46Z", 
    "summary": "The goal of the study is to determine the underlying processes leading to the\nobserved collaborator distribution in modern scientific fields, with special\nattention to non-power law behavior. Nanoscience is used as a case study of a\nmodern interdisciplinary field, and its coauthorship network for 2000-04 period\nis constructed from NanoBank database. We find three collaboration modes that\ncorrespond to three distinct ranges in the distribution of collaborators: (1)\nfor authors with fewer than 20 collaborators (the majority) preferential\nattachment does not hold and they form a log-normal \"hook\" instead of a power\nlaw, (2) authors with more than 20 collaborators benefit from preferential\nattachment and form a power law tail, and (3) authors with between 250 and 800\ncollaborators are more frequent than expected because of the hyperauthorship\npractices in certain subfields."
},{
    "category": "cs.DL", 
    "doi": "10.1002/asi.21331", 
    "link": "http://arxiv.org/pdf/1005.2223v1", 
    "title": "Worldwide topology of the scientific subject profile: a macro approach   on the country level", 
    "arxiv-id": "1005.2223v1", 
    "author": "Victor Herrero-Solana", 
    "publish": "2010-05-12T22:59:51Z", 
    "summary": "Models for the production of knowledge and systems of innovation and science\nare key elements for characterizing a country in view of its scientific\nthematic profile. With regard to scientific output and publication in journals\nof international visibility, the countries of the world may be classified into\nthree main groups according to their thematic bias. This paper aims to classify\nthe countries of the world in several broad groups, described in terms of\nbehavioural models that attempt to sum up the characteristics of their systems\nof knowledge and innovation. We perceive three clusters in our analysis: 1) the\nbiomedical cluster, 2) the basic science & engineering cluster, and 3) the\nagricultural cluster. The countries are conceptually associated with the\nclusters via Principal Component Analysis (PCA), and a Multidimensional Scaling\n(MDS) map with all the countries is presented."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-1-4419-8369-5_14", 
    "link": "http://arxiv.org/pdf/1005.2308v1", 
    "title": "Finding Your Literature Match -- A Recommender System", 
    "arxiv-id": "1005.2308v1", 
    "author": "Stephen S. Murray", 
    "publish": "2010-05-13T12:35:22Z", 
    "summary": "The universe of potentially interesting, searchable literature is expanding\ncontinuously. Besides the normal expansion, there is an additional influx of\nliterature because of interdisciplinary boundaries becoming more and more\ndiffuse. Hence, the need for accurate, efficient and intelligent search tools\nis bigger than ever. Even with a sophisticated search engine, looking for\ninformation can still result in overwhelming results. An overload of\ninformation has the intrinsic danger of scaring visitors away, and any\norganization, for-profit or not-for-profit, in the business of providing\nscholarly information wants to capture and keep the attention of its target\naudience. Publishers and search engine engineers alike will benefit from a\nservice that is able to provide visitors with recommendations that closely meet\ntheir interests. Providing visitors with special deals, new options and\nhighlights may be interesting to a certain degree, but what makes more sense\n(especially from a commercial point of view) than to let visitors do most of\nthe work by the mere action of making choices? Hiring psychics is not an\noption, so a technological solution is needed to recommend items that a visitor\nis likely to be looking for. In this presentation we will introduce such a\nsolution and argue that it is practically feasible to incorporate this approach\ninto a useful addition to any information retrieval system with enough usage."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1007/978-1-4419-8369-5_14", 
    "link": "http://arxiv.org/pdf/1005.2643v1", 
    "title": "Metadata and provenance management", 
    "arxiv-id": "1005.2643v1", 
    "author": "Luc Moreau", 
    "publish": "2010-05-15T00:28:43Z", 
    "summary": "Scientists today collect, analyze, and generate TeraBytes and PetaBytes of\ndata. These data are often shared and further processed and analyzed among\ncollaborators. In order to facilitate sharing and data interpretations, data\nneed to carry with it metadata about how the data was collected or generated,\nand provenance information about how the data was processed. This chapter\ndescribes metadata and provenance in the context of the data lifecycle. It also\ngives an overview of the approaches to metadata and provenance management,\nfollowed by examples of how applications use metadata and provenance in their\nscientific processes."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1007/s11192-012-0630-z", 
    "link": "http://arxiv.org/pdf/1005.3063v2", 
    "title": "Good practices for a literature survey are not followed by authors while   preparing scientific manuscripts", 
    "arxiv-id": "1005.3063v2", 
    "author": "L. da F. Costa", 
    "publish": "2010-05-17T21:45:47Z", 
    "summary": "The number of citations received by authors in scientific journals has become\na major parameter to assess individual researchers and the journals themselves\nthrough the impact factor. A fair assessment therefore requires that the\ncriteria for selecting references in a given manuscript should be unbiased with\nrespect to the authors or the journals cited. In this paper, we advocate that\nauthors should follow two mandatory principles to select papers (later\nreflected in the list of references) while studying the literature for a given\nresearch: i) consider similarity of content with the topics investigated, lest\nvery related work should be reproduced or ignored; ii) perform a systematic\nsearch over the network of citations including seminal or very related papers.\nWe use formalisms of complex networks for two datasets of papers from the arXiv\nrepository to show that neither of these two criteria is fulfilled in practice."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-012-0630-z", 
    "link": "http://arxiv.org/pdf/1005.4906v1", 
    "title": "The Source-Normalized Impact per Paper (SNIP) is a valid and   sophisticated indicator of journal citation impact", 
    "arxiv-id": "1005.4906v1", 
    "author": "Henk F. Moed", 
    "publish": "2010-05-26T18:37:13Z", 
    "summary": "This paper is a reply to the article \"Scopus's Source Normalized Impact per\nPaper (SNIP) versus a Journal Impact Factor based on Fractional Counting of\nCitations\", published by Loet Leydesdorff and Tobias Opthof (arXiv:1004.3580v2\n[cs.DL]). It clarifies the relationship between SNIP and Elsevier's Scopus.\nSince Leydesdorff and Opthof's description of SNIP is not complete, it\nindicates four key differences between SNIP and the indicator proposed by the\ntwo authors, and argues why the former is more valid than the latter.\nNevertheless, the idea of fractional citation counting deserves further\nexploration. The paper discusses difficulties that arise if one attempts to\napply this principle at the level of individual (citing) papers."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1002/andp.201000046", 
    "link": "http://arxiv.org/pdf/1005.5227v1", 
    "title": "Twenty Hirsch index variants and other indicators giving more or less   preference to highly cited papers", 
    "arxiv-id": "1005.5227v1", 
    "author": "Michael Schreiber", 
    "publish": "2010-05-28T07:08:09Z", 
    "summary": "The Hirsch index or h-index is widely used to quantify the impact of an\nindividual's scientific research output, determining the highest number h of a\nscientist's papers that received at least h citations. Several variants of the\nindex have been proposed in order to give more or less preference to highly\ncited papers. I analyse the citation records of 26 physicists discussing\nvarious suggestions, in particular A, e, f, g, h(2), h_w, h_T, \\hbar, m, {\\pi},\nR, s, t, w, and maxprod. The total number of all and of all cited publications\nas well as the highest and the average number of citations are also compared.\nAdvantages and disadvantages of these indices and indicators are discussed.\nCorrelation coefficients are determined quantifying which indices and\nindicators yield similar and which yield more deviating rankings of the 26\ndatasets. For 6 datasets the determination of the indices and indicators is\nvisualized."
},{
    "category": "cs.DL", 
    "doi": "10.1002/andp.201000046", 
    "link": "http://arxiv.org/pdf/1005.5444v1", 
    "title": "Eugene Garfield and Algorithmic Historiography: Co-Words, Co-Authors,   and Journal Names", 
    "arxiv-id": "1005.5444v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2010-05-29T09:34:13Z", 
    "summary": "Algorithmic historiography was proposed by Eugene Garfield in collaboration\nwith Irving Sher in the 1960s, but further developed only recently into\nHistCite^{TM} with Alexander Pudovkin. As in history writing, HistCite^{TM}\nreconstructs by drawing intellectual lineages. In addition to cited references,\nhowever, documents can be attributed a multitude of other variables such as\ntitle words, keywords, journal names, author names, and even full texts. New\ndevelopments in multidimensional scaling (MDS) enable us not only to visualize\nthese patterns at each moment of time, but also to animate them over time.\nUsing title words, co-authors, and journal names in Garfield's oeuvre, the\nmethod is demonstrated and further developed in this paper (and in the\nanimation at http://www.leydesdorff.net/garfield/animation). The variety and\nsubstantive content of the animation enables us to write, visualize, and\nanimate the author's intellectual history."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1002/andp.201000046", 
    "link": "http://arxiv.org/pdf/1006.0670v1", 
    "title": "Astronomy 3.0 Style", 
    "arxiv-id": "1006.0670v1", 
    "author": "Alberto Accomazzi", 
    "publish": "2010-06-03T15:06:56Z", 
    "summary": "Over the next decade we will witness the development of a new infrastructure\nin support of data-intensive scientific research, which includes Astronomy.\nThis new networked environment will offer both challenges and opportunities to\nour community and has the potential to transform the way data are described,\ncurated and preserved. Based on the lessons learned during the development and\nmanagement of the ADS, a case is made for adopting the emerging technologies\nand practices of the Semantic Web to support the way Astronomy research will be\nconducted. Examples of how small, incremental steps can, in the aggregate, make\na significant difference in the provision and repurposing of astronomical data\nare provided."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1002/andp.201000046", 
    "link": "http://arxiv.org/pdf/1006.1714v1", 
    "title": "Bibliometric Evaluation of the Changing Finnish Astronomy", 
    "arxiv-id": "1006.1714v1", 
    "author": "Eva Isaksson", 
    "publish": "2010-06-09T06:46:28Z", 
    "summary": "This is a follow-up on the bibliometric evaluation of Finnish astronomy\npresented by the author at the LISA V conference in 2006. The data from the\nprevious study are revisited to determine how a wider institutional base and\nmergers affect comparisons between research units."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1002/andp.201000046", 
    "link": "http://arxiv.org/pdf/1006.1788v2", 
    "title": "Communities and Patterns of Scientific collaboration", 
    "arxiv-id": "1006.1788v2", 
    "author": "P. Panzarasa", 
    "publish": "2010-06-09T12:38:33Z", 
    "summary": "This paper investigates the role of homophily and focus constraint in shaping\ncollaborative scientific research. First, homophily structures collaboration\nwhen scientists adhere to a norm of exclusivity in selecting similar partners\nat a higher rate than dissimilar ones. Two dimensions on which similarity\nbetween scientists can be assessed are their research specialties and status\npositions. Second, focus constraint shapes collaboration when connections among\nscientists depend on opportunities for social contact. Constraint comes in two\nforms, depending on whether it originates in institutional or geographic space.\nInstitutional constraint refers to the tendency of scientists to select\ncollaborators within rather than across institutional boundaries. Geographic\nconstraint is the principle that, when collaborations span different\ninstitutions, they are more likely to involve scientists that are\ngeographically co-located than dispersed. To study homophily and focus\nconstraint, the paper will argue in favour of an idea of collaboration that\nmoves beyond formal co-authorship to include also other forms of informal\nintellectual exchange that do not translate into the publication of joint work.\nA community-detection algorithm is applied to the co-authorship network of the\nscientists that submitted in Business and Management in the 2001 UK RAE. While\nresults only partially support research-based homophily, they indicate that\nscientists use status positions for discriminating between potential partners\nby selecting collaborators from institutions with a rating similar to their\nown. Strong support is provided in favour of institutional and geographic\nconstraints. Scientists tend to forge intra-institutional collaborations; yet,\nwhen they seek collaborators outside their own institutions, they tend to\nselect those who are in geographic proximity."
},{
    "category": "cs.AI", 
    "doi": "10.1002/andp.201000046", 
    "link": "http://arxiv.org/pdf/1006.2718v1", 
    "title": "From RESTful Services to RDF: Connecting the Web and the Semantic Web", 
    "arxiv-id": "1006.2718v1", 
    "author": "Erik Wilde", 
    "publish": "2010-06-11T18:39:20Z", 
    "summary": "RESTful services on the Web expose information through retrievable resource\nrepresentations that represent self-describing descriptions of resources, and\nthrough the way how these resources are interlinked through the hyperlinks that\ncan be found in those representations. This basic design of RESTful services\nmeans that for extracting the most useful information from a service, it is\nnecessary to understand a service's representations, which means both the\nsemantics in terms of describing a resource, and also its semantics in terms of\ndescribing its linkage with other resources. Based on the Resource Linking\nLanguage (ReLL), this paper describes a framework for how RESTful services can\nbe described, and how these descriptions can then be used to harvest\ninformation from these services. Building on this framework, a layered model of\nRESTful service semantics allows to represent a service's information in\nRDF/OWL. Because REST is based on the linkage between resources, the same model\ncan be used for aggregating and interlinking multiple services for extracting\nRDF data from sets of RESTful services."
},{
    "category": "cs.DL", 
    "doi": "10.1002/andp.201000046", 
    "link": "http://arxiv.org/pdf/1006.2895v1", 
    "title": "Scopus' SNIP Indicator", 
    "arxiv-id": "1006.2895v1", 
    "author": "Tobias Opthof", 
    "publish": "2010-06-15T06:15:09Z", 
    "summary": "Rejoinder to Moed [arXiv:1005.4906]: Our main objection is against developing\nnew indicators which, like some of the older ones (for example, the \"crown\nindicator\" of CWTS), do not allow for indicating error because they do not\nprovide a statistics, but are based, in our opinion, on a violation of the\norder of operations. The claim of validity for the SNIP indicator is hollow\nbecause the normalizations are based on field classifications which are not\nvalid. Both problems can perhaps be solved by using fractional counting."
},{
    "category": "cs.DL", 
    "doi": "10.1002/andp.201000046", 
    "link": "http://arxiv.org/pdf/1006.2896v1", 
    "title": "Normalization at the field level: fractional counting of citations", 
    "arxiv-id": "1006.2896v1", 
    "author": "Tobias Opthof", 
    "publish": "2010-06-15T06:21:43Z", 
    "summary": "Van Raan et al. (2010; arXiv:1003.2113) have proposed a new indicator (MNCS)\nfor field normalization. Since field normalization is also used in the Leiden\nRankings of universities, we elaborate our critique of journal normalization in\nOpthof & Leydesdorff (2010; arXiv:1002.2769) in this rejoinder concerning field\nnormalization. Fractional citation counting thoroughly solves the issue of\nnormalization for differences in citation behavior among fields. This indicator\ncan also be used to obtain a normalized impact factor."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1002/andp.201000046", 
    "link": "http://arxiv.org/pdf/1006.3701v1", 
    "title": "Concentration versus dispersion of research resources: a contribution to   the debate", 
    "arxiv-id": "1006.3701v1", 
    "author": "Bertrand Berche", 
    "publish": "2010-06-18T14:24:39Z", 
    "summary": "Using the results of the UK's research assessment exercise, we show that the\nsize or mass of research groups, rather than individual caliber or prestige of\nthe institution, is the dominant factor which drives the quality of research\nteams. There are two critical masses in research: a lower one, below which\nteams are vulnerable and an upper one, above which average dependency of\nresearch quality on team size reduces. This leveling off refutes arguments\nwhich advocate ever increasing concentration of research support into a few\nlarge institutions. We also show that to increase research quality, policies\nwhich nourish two-way communication links between researchers are paramount."
},{
    "category": "physics.soc-ph", 
    "doi": "10.3152/095820211X12941371876625", 
    "link": "http://arxiv.org/pdf/1006.3863v2", 
    "title": "Normalization of peer-evaluation measures of group research quality   across academic disciplines", 
    "arxiv-id": "1006.3863v2", 
    "author": "Bertrand Berche", 
    "publish": "2010-06-19T12:36:42Z", 
    "summary": "Peer-evaluation based measures of group research quality such as the UK's\nResearch Assessment Exercise (RAE), which do not employ bibliometric analyses,\ncannot directly avail of such methods to normalize research impact across\ndisciplines. This is seen as a conspicuous flaw of such exercises and calls\nhave been made to find a remedy. Here a simple, systematic solution is proposed\nbased upon a mathematical model for the relationship between research quality\nand group quantity. This model manifests both the Matthew effect and a\nphenomenon akin to the Ringelmann effect and reveals the existence of two\ncritical masses for each academic discipline: a lower value, below which groups\nare vulnerable, and an upper value beyond which the dependency of quality on\nquantity reduces and plateaus appear when the critical masses are large. A\npossible normalization procedure is then to pitch these plateaus at similar\nlevels. We examine the consequences of this procedure at RAE for a multitude of\nacademic disciplines, corresponding to a range of critical masses."
},{
    "category": "cs.DL", 
    "doi": "10.3152/095820211X12941371876625", 
    "link": "http://arxiv.org/pdf/1006.4057v1", 
    "title": "Towards OpenMath Content Dictionaries as Linked Data", 
    "arxiv-id": "1006.4057v1", 
    "author": "Christoph Lange", 
    "publish": "2010-06-21T13:00:22Z", 
    "summary": "\"The term 'Linked Data' refers to a set of best practices for publishing and\nconnecting structured data on the web\". Linked Data make the Semantic Web work\npractically, which means that information can be retrieved without complicated\nlookup mechanisms, that a lightweight semantics enables scalable reasoning, and\nthat the decentral nature of the Web is respected. OpenMath Content\nDictionaries (CDs) have the same characteristics - in principle, but not yet in\npractice. The Linking Open Data movement has made a considerable practical\nimpact: Governments, broadcasting stations, scientific publishers, and many\nmore actors are already contributing to the \"Web of Data\". Queries can be\nanswered in a distributed way, and services aggregating data from different\nsources are replacing hard-coded mashups. However, these services are currently\nentirely lacking mathematical functionality. I will discuss real-world\nscenarios, where today's RDF-based Linked Data do not quite get their job done,\nbut where an integration of OpenMath would help - were it not for certain\nconceptual and practical restrictions. I will point out conceptual shortcomings\nin the OpenMath 2 specification and common bad practices in publishing CDs and\nthen propose concrete steps to overcome them and to contribute OpenMath CDs to\nthe Web of Data."
},{
    "category": "cs.DL", 
    "doi": "10.3152/095820211X12941371876625", 
    "link": "http://arxiv.org/pdf/1008.3977v1", 
    "title": "Collaborative Structuring of Knowledge by Experts and the Public", 
    "arxiv-id": "1008.3977v1", 
    "author": "Daniel Mietchen", 
    "publish": "2010-08-24T07:50:14Z", 
    "summary": "There is much debate on how public participation and expertise can be brought\ntogether in collaborative knowledge environments. One of the experiments\naddressing the issue directly is Citizendium. In seeking to harvest the\nstrengths (and avoiding the major pitfalls) of both user-generated wiki\nprojects and traditional expert-approved reference works, it is a wiki to which\nanybody can contribute using their real names, while those with specific\nexpertise are given a special role in assessing the quality of content. Upon\nfulfillment of a set of criteria like factual and linguistic accuracy, lack of\nbias, and readability by non-specialists, these entries are forked into two\nversions: a stable (and thus citable) approved \"cluster\" (an article with\nsubpages providing supplementary information) and a draft version, the latter\nto allow for further development and updates. We provide an overview of how\nCitizendium is structured and what it offers to the open knowledge communities,\nparticularly to those engaged in education and research. Special attention will\nbe paid to the structures and processes put in place to provide for transparent\ngovernance, to encourage collaboration, to resolve disputes in a civil manner\nand by taking into account expert opinions, and to facilitate navigation of the\nsite and contextualization of its contents."
},{
    "category": "cs.IR", 
    "doi": "10.3152/095820211X12941371876625", 
    "link": "http://arxiv.org/pdf/1009.5003v1", 
    "title": "Demonstrating a Service-Enhanced Retrieval System", 
    "arxiv-id": "1009.5003v1", 
    "author": "Peter Mutschke", 
    "publish": "2010-09-25T10:33:42Z", 
    "summary": "This paper is a short description of an information retrieval system enhanced\nby three model driven retrieval services: (1) co-word analysis based query\nexpansion, re-ranking via (2) Bradfordizing and (3) author centrality. The\ndifferent services each favor quite other - but still relevant - documents than\npure term-frequency based rankings. Each service can be interactively combined\nwith each other to allow an iterative retrieval refinement."
},{
    "category": "cs.GR", 
    "doi": "10.3152/095820211X12941371876625", 
    "link": "http://arxiv.org/pdf/1009.5183v1", 
    "title": "A Framework for an Ego-centered and Time-aware Visualization of   Relations in Arbitrary Data Repositories", 
    "arxiv-id": "1009.5183v1", 
    "author": "Florian Reitz", 
    "publish": "2010-09-27T08:16:36Z", 
    "summary": "Understanding constellations in large data collections has become a common\ntask. One obstacle a user has to overcome is the internal complexity of these\nrepositories. For example, extracting connected data from a normalized\nrelational database requires knowledge of the table structure which might not\nbe available for the casual user. In this paper we present a visualization\nframework which presents the collection as a set of entities and relations (on\nthe data level). Using rating functions, we divide large relation networks into\nsmall graphs which resemble ego-centered networks. These graphs are connected\nso the user can browse from one to another. To further assist the user, we\npresent two views which embed information on the evolution of the relations\ninto the graphs. Each view emphasizes another aspect of temporal development.\nThe framework can be adapted to any repository by a flexible data interface and\na graph configuration file. We present some first web-based applications\nincluding a visualization of the DBLP data set. We use the DBLP visualization\nto evaluate our approach."
},{
    "category": "cs.DB", 
    "doi": "10.3152/095820211X12941371876625", 
    "link": "http://arxiv.org/pdf/1009.5233v3", 
    "title": "A Simple Abstraction for Data Modeling", 
    "arxiv-id": "1009.5233v3", 
    "author": "Nassib Nassar", 
    "publish": "2010-09-27T12:00:32Z", 
    "summary": "The problems that scientists face in creating well designed databases\nintersect with the concerns of data curation. Entity-relationship modeling and\nits variants have been the basis of most relational data modeling for decades.\nHowever, these abstractions and the relational model itself are intricate and\nhave proved not to be very accessible among scientists with limited resources\nfor data management. This paper explores one aspect of relational data models,\nthe meaning of foreign key relationships. We observe that a foreign key\nproduces a table relationship that generally references either an entity or\nrepeating attributes. This paper proposes constructing foreign keys based on\nthese two cases, and suggests that the method promotes intuitive data modeling\nand normalization."
},{
    "category": "cs.DL", 
    "doi": "10.3152/095820211X12941371876625", 
    "link": "http://arxiv.org/pdf/1009.5352v1", 
    "title": "Establishing a Multi-Thesauri-Scenario based on SKOS and   Cross-Concordances", 
    "arxiv-id": "1009.5352v1", 
    "author": "York Sure", 
    "publish": "2010-09-27T18:51:31Z", 
    "summary": "This case study proposes a scenario with three topic-related thesauri, which\nhave been connected with bilateral cross-concordances as part of a major\nterminology mapping initiative in the project KoMoHe (Mayr & Petras, 2008). The\nthesauri have already been or will be converted to SKOS and in order to not\nomit the relevant crosswalks, the mapping properties of SKOS will be used for\nmodeling them adequately."
},{
    "category": "math.HO", 
    "doi": "10.3152/095820211X12941371876625", 
    "link": "http://arxiv.org/pdf/1010.0278v4", 
    "title": "Nefarious Numbers", 
    "arxiv-id": "1010.0278v4", 
    "author": "Kristine K. Fowler", 
    "publish": "2010-10-01T23:44:12Z", 
    "summary": "We investigate the journal impact factor, focusing on the applied mathematics\ncategory. We discuss impact factor manipulation and demonstrate that the impact\nfactor gives an inaccurate view of journal quality, which is poorly correlated\nwith expert opinion."
},{
    "category": "cs.DL", 
    "doi": "10.3152/095820211X12941371876625", 
    "link": "http://arxiv.org/pdf/1010.2345v1", 
    "title": "Using Context Dependent Semantic Similarity to Browse Information   Resources: an Application for the Industrial Design", 
    "arxiv-id": "1010.2345v1", 
    "author": "Monica De Martino", 
    "publish": "2010-10-12T10:17:32Z", 
    "summary": "This paper deals with the semantic interpretation of information resources\n(e.g., images, videos, 3D models). We present a case study of an approach based\non semantic and context dependent similarity applied to the industrial design.\nDifferent application contexts are considered and modelled to browse a\nrepository of 3D digital objects according to different perspectives. The paper\nbriefly summarises the basic concepts behind the semantic similarity approach\nand illustrates its application and results."
},{
    "category": "cs.DL", 
    "doi": "10.3152/095820211X12941371876625", 
    "link": "http://arxiv.org/pdf/1010.2379v3", 
    "title": "Remaining problems with the \"New Crown Indicator\" (MNCS) of the CWTS", 
    "arxiv-id": "1010.2379v3", 
    "author": "Tobias Opthof", 
    "publish": "2010-10-12T13:04:55Z", 
    "summary": "In their article, entitled \"Towards a new crown indicator: some theoretical\nconsiderations,\" Waltman et al. (2010; at arXiv:1003.2167) show that the \"old\ncrown indicator\" of CWTS in Leiden was mathematically inconsistent and that one\nshould move to the normalization as applied in the \"new crown indicator.\"\nAlthough we now agree about the statistical normalization, the \"new crown\nindicator\" inherits the scientometric problems of the \"old\" one in treating\nsubject categories of journals as a standard for normalizing differences in\ncitation behavior among fields of science.\n  We further note that the \"mean\" is not a proper statistics for measuring\ndifferences among skewed distributions. Without changing the acronym of \"MNCS,\"\none could define the \"Median Normalized Citation Score.\" This would relate the\nnew crown indicator directly to the percentile approach that is, for example,\nused in the Science and Engineering Indicators of US National Science Board\n(2010). The median is by definition equal to the 50th percentile. The indicator\ncan thus easily be extended with the 1% (= 99th percentile) most highly-cited\npapers (Bornmann et al., in press). The seeming disadvantage of having to use\nnon-parametric statistics is more than compensated by possible gains in the\nprecision."
},{
    "category": "cs.DL", 
    "doi": "10.3152/095820211X12941371876625", 
    "link": "http://arxiv.org/pdf/1010.2440v2", 
    "title": "Enabling Data Discovery through Virtual Internet Repositories", 
    "arxiv-id": "1010.2440v2", 
    "author": "Bruce Wilson", 
    "publish": "2010-10-12T16:57:25Z", 
    "summary": "Mercury is a federated metadata harvesting, search and retrieval tool based\non both open source and software developed at Oak Ridge National Laboratory. It\nwas originally developed for NASA, and the Mercury development consortium now\nincludes funding from NASA, USGS, and DOE. A major new version of Mercury was\ndeveloped during 2007. This new version provides orders of magnitude\nimprovements in search speed, support for additional metadata formats,\nintegration with Google Maps for spatial queries, support for RSS delivery of\nsearch results, among other features. Mercury provides a single portal to\ninformation contained in disparate data management systems. It collects\nmetadata and key data from contributing project servers distributed around the\nworld and builds a centralized index. The Mercury search interfaces then allow\nthe users to perform simple, fielded, spatial and temporal searches across\nthese metadata sources. This centralized repository of metadata with\ndistributed data sources provides extremely fast search results to the user,\nwhile allowing data providers to advertise the availability of their data and\nmaintain complete control and ownership of that data."
},{
    "category": "cs.DL", 
    "doi": "10.3152/095820211X12941371876625", 
    "link": "http://arxiv.org/pdf/1010.2465v1", 
    "title": "How to evaluate universities in terms of their relative citation   impacts: Fractional counting of citations and the normalization of   differences among disciplines", 
    "arxiv-id": "1010.2465v1", 
    "author": "Jung C. Shin", 
    "publish": "2010-10-12T18:39:10Z", 
    "summary": "Fractional counting of citations can improve on ranking of multi-disciplinary\nresearch units (such as universities) by normalizing the differences among\nfields of science in terms of differences in citation behavior. Furthermore,\nnormalization in terms of citing papers abolishes the unsolved questions in\nscientometrics about the delineation of fields of science in terms of journals\nand normalization when comparing among different journals. Using publication\nand citation data of seven Korean research universities, we demonstrate the\nadvantages and the differences in the rankings, explain the possible\nstatistics, and suggest ways to visualize the differences in (citing) audiences\nin terms of a network."
},{
    "category": "physics.soc-ph", 
    "doi": "10.3152/095820211X12941371876625", 
    "link": "http://arxiv.org/pdf/1010.3525v1", 
    "title": "Tracing scientific influence", 
    "arxiv-id": "1010.3525v1", 
    "author": "Eugene Garfield", 
    "publish": "2010-10-18T09:03:29Z", 
    "summary": "Scientometrics is the field of quantitative studies of scholarly activity. It\nhas been used for systematic studies of the fundamentals of scholarly practice\nas well as for evaluation purposes. Although advocated from the very beginning\nthe use of scientometrics as an additional method for science history is still\nunder explored. In this paper we show how a scientometric analysis can be used\nto shed light on the reception history of certain outstanding scholars. As a\ncase, we look into citation patterns of a specific paper by the American\nsociologist Robert K. Merton."
},{
    "category": "cs.DL", 
    "doi": "10.3152/095820211X12941371876625", 
    "link": "http://arxiv.org/pdf/1010.5939v1", 
    "title": "Analysis of temporal characteristics of the editorial processing in   scientific periodicals", 
    "arxiv-id": "1010.5939v1", 
    "author": "Ihor Mryglod", 
    "publish": "2010-10-28T12:25:32Z", 
    "summary": "The first part of our work is connected with the analysis of typical random\nvariables for the specific human-initiated process. We study the data\ncharacterizing editorial work with received manuscripts in several scientific\njournals. In such a way we found the waiting time distributions that could be\ncalled the typical for an ordinary peer-review scientific journal. In the\nsecond part of this study a model of editorial processing of received\nmanuscripts is developed. Within the model, different scenarios of the\nmanuscript editorial processing are examined. Combining the results of the\nquantitative experiment and model simulations we arrive to the set of\nconclusions about time characteristics of editorial process in scientific\njournals and a peer-review contribution."
},{
    "category": "cs.DL", 
    "doi": "10.3152/095820211X12941371876625", 
    "link": "http://arxiv.org/pdf/1011.1979v2", 
    "title": "Can Knowledge be preserved in the long run?", 
    "arxiv-id": "1011.1979v2", 
    "author": "Rina Panigrahy", 
    "publish": "2010-11-09T06:00:08Z", 
    "summary": "Can (scientific) knowledge be reliably preserved over the long term? We have\ntoday very efficient and reliable methods to encode, store and retrieve data in\na storage medium that is fault tolerant against many types of failures. But\ndoes this guarantee -- or does it even seem likely -- that all knowledge can be\npreserved over thousands of years and beyond? History shows that many types of\nknowledge that were known before have been lost. We observe that the nature of\nstored and communicated information and the way it is interpreted is such that\nit always tends to decay and therefore must lost eventually in the long term.\nThe likely fundamental conclusion is that knowledge cannot be reliably\npreserved indefinitely."
},{
    "category": "cs.DL", 
    "doi": "10.3152/095820211X12941371876625", 
    "link": "http://arxiv.org/pdf/1011.3120v2", 
    "title": "The Local Emergence and Global Diffusion of Research Technologies: An   Exploration of Patterns of Network Formation", 
    "arxiv-id": "1011.3120v2", 
    "author": "Ismael Rafols", 
    "publish": "2010-11-13T09:29:04Z", 
    "summary": "Grasping the fruits of \"emerging technologies\" is an objective of many\ngovernment priority programs in a knowledge-based and globalizing economy. We\nuse the publication records (in the Science Citation Index) of two emerging\ntechnologies to study the mechanisms of diffusion in the case of two innovation\ntrajectories: small interference RNA (siRNA) and nano-crystalline solar cells\n(NCSC). Methods for analyzing and visualizing geographical and cognitive\ndiffusion are specified as indicators of different dynamics. Geographical\ndiffusion is illustrated with overlays to Google Maps; cognitive diffusion is\nmapped using an overlay to a map based on the ISI Subject Categories. The\nevolving geographical networks show both preferential attachment and\nsmall-world characteristics. The strength of preferential attachment decreases\nover time, while the network evolves into an oligopolistic control structure\nwith small-world characteristics. The transition from disciplinary-oriented\n(\"mode-1\") to transfer-oriented (\"mode-2\") research is suggested as the crucial\ndifference in explaining the different rates of diffusion between siRNA and\nNCSC."
},{
    "category": "cs.DL", 
    "doi": "10.1140/epjst/e2011-01403-6", 
    "link": "http://arxiv.org/pdf/1011.3794v3", 
    "title": "How to Create an Innovation Accelerator", 
    "arxiv-id": "1011.3794v3", 
    "author": "Stefano Balietti", 
    "publish": "2010-11-16T19:38:05Z", 
    "summary": "Too many policy failures are fundamentally failures of knowledge. This has\nbecome particularly apparent during the recent financial and economic crisis,\nwhich is questioning the validity of mainstream scholarly paradigms. We propose\nto pursue a multi-disciplinary approach and to establish new institutional\nsettings which remove or reduce obstacles impeding efficient knowledge\ncreation. We provided suggestions on (i) how to modernize and improve the\nacademic publication system, and (ii) how to support scientific coordination,\ncommunication, and co-creation in large-scale multi-disciplinary projects. Both\nconstitute important elements of what we envision to be a novel ICT\ninfrastructure called \"Innovation Accelerator\" or \"Knowledge Accelerator\"."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1140/epjst/e2011-01403-6", 
    "link": "http://arxiv.org/pdf/1011.5311v1", 
    "title": "Citations and impact of Dutch astronomy", 
    "arxiv-id": "1011.5311v1", 
    "author": "P. C. van der Kruit", 
    "publish": "2010-11-24T07:52:47Z", 
    "summary": "The aim of this study is to make a bibliometric comparison of the performance\nof research astronomers in the Netherlands Research School for Astronomy (NOVA)\nwith astronomers elsewhere by using the NASA Astrophysics Data System (ADS). We\nuse various indices for bibliometric performance for a sample of NOVA\nastronomers to compare to samples of astronomers worldwide, and from the United\nStates. We give much weight to normalising bibliometric measures by number of\nauthors, and number of years since first publication. In particular we\ncalculate the `Hirsh-index' normalized to number of authors and for\nfirst-author papers. Secondly, we consider the results of the 'Nederlands\nObservatorium van Wetenschap en Technologie' (NOWT; Netherlands Observatory of\nScience and Technology), which regularly publishes a report 'Science and\nTechnology Indicators'. We reproduce those results using publication lists from\ninstitutions in the Netherlands, again using ADS, and examine and discuss the\nconclusions and indications in these reports. We find that the NOVA researchers\nperform much better in bibliometric measures than samples drawn from IAU or AAS\nmembership lists. A more suitable comparison is one with the (tenured) staff of\nthe top-15 US institutions and there the NOVA staff performs in these respects\nas good or almost as good as that of American top institutes. From a citation\nanalysis through the use of ADS we conclude that the impact ratio of Dutch\nastronomical publications is rising which is opposite to what is reported by\nNOWT. This difference is most likely caused by a better separation of astronomy\nand physics in ADS than in World of Knowledge. ADS probably finds more\ncitations in conference proceedings, while the inclusion of citations to\narticles with their pre-print identifier could also help explain the difference\n(especially since the citation windows in the reports are short)."
},{
    "category": "cs.DL", 
    "doi": "10.1140/epjst/e2011-01403-6", 
    "link": "http://arxiv.org/pdf/1012.1650v1", 
    "title": "The CALBC RDF Triple Store: retrieval over large literature content", 
    "arxiv-id": "1012.1650v1", 
    "author": "Dietrich Rebholz-Schuhmann", 
    "publish": "2010-12-08T00:19:06Z", 
    "summary": "Integration of the scientific literature into a biomedical research\ninfrastructure requires the processing of the literature, identification of the\ncontained named entities (NEs) and concepts, and to represent the content in a\nstandardised way. The CALBC project partners (PPs) have produced a large-scale\nannotated biomedical corpus with four different semantic groups through the\nharmonisation of annotations from automatic text mining solutions (Silver\nStandard Corpus, SSC). The four semantic groups were chemical entities and\ndrugs (CHED), genes and proteins (PRGE), diseases and disorders (DISO) and\nspecies (SPE). The content of the SSC has been fully integrated into RDF Triple\nStore (4,568,678 triples) and has been aligned with content from the GeneAtlas\n(182,840 triples), UniProtKb (12,552,239 triples for human) and the lexical\nresource LexEBI (BioLexicon). RDF Triple Store enables querying the scientific\nliterature and bioinformatics resources at the same time for evidence of\ngenetic causes, such as drug targets and disease involvement."
},{
    "category": "cs.DL", 
    "doi": "10.1140/epjst/e2011-01403-6", 
    "link": "http://arxiv.org/pdf/1012.4752v1", 
    "title": "Semantic Web: Who is who in the field - A bibliometric analysis", 
    "arxiv-id": "1012.4752v1", 
    "author": "Ying Ding", 
    "publish": "2010-12-21T18:07:45Z", 
    "summary": "The Semantic Web is one of the main efforts aiming to enhance human and\nmachine interaction by representing data in an understandable way for machines\nto mediate data and services. It is a fast-moving and multidisciplinary field.\nThis study conducts a thorough bibliometric analysis of the field by collecting\ndata from Web of Science (WOS) and Scopus for the period of 1960-2009. It\nutilizes a total of 44,157 papers with 651,673 citations from Scopus, and\n22,951 papers with 571,911 citations from WOS. Based on these papers and\ncitations, it evaluates the research performance of the Semantic Web (SW) by\nidentifying the most productive players, major scholarly communication media,\nhighly cited authors, influential papers and emerging stars."
},{
    "category": "cs.DL", 
    "doi": "10.1140/epjst/e2011-01403-6", 
    "link": "http://arxiv.org/pdf/1012.5199v1", 
    "title": "Severe Language Effect in University Rankings: Particularly Germany and   France are wronged in citation-based rankings", 
    "arxiv-id": "1012.5199v1", 
    "author": "Martijn S. Visser", 
    "publish": "2010-12-23T13:44:10Z", 
    "summary": "We applied a set of standard bibliometric indicators to monitor the\nscientific state-of-arte of 500 universities worldwide and constructed a\nranking on the basis of these indicators (Leiden Ranking 2010). We find a\ndramatic and hitherto largely underestimated language effect in the\nbibliometric, citation-based measurement of research performance when comparing\nthe ranking based on all Web of Science (WoS) covered publications and on only\nEnglish WoS covered publications, particularly for Germany and France."
},{
    "category": "cs.DL", 
    "doi": "10.1103/PhysRevE.83.046116", 
    "link": "http://arxiv.org/pdf/1012.5314v2", 
    "title": "Rescaling citations of publications in physics", 
    "arxiv-id": "1012.5314v2", 
    "author": "Claudio Castellano", 
    "publish": "2010-12-23T22:37:27Z", 
    "summary": "We analyze the citation distributions of all papers published in Physical\nReview journals between 1985 and 2009. The average number of citations received\nby papers published in a given year and in a given field is computed. Large\nvariations are found, showing that it is not fair to compare citation numbers\nacross fields and years. However, when a rescaling procedure by the average is\nused, it is possible to compare impartially articles across years and fields.\nWe make the rescaling factors available for use by the readers. We also show\nthat rescaling citation numbers by the number of publication authors has strong\neffects and should therefore be taken into account when assessing the\nbibliometric performance of researchers."
},{
    "category": "cs.IR", 
    "doi": "10.1103/PhysRevE.83.046116", 
    "link": "http://arxiv.org/pdf/1101.1637v1", 
    "title": "A Science Model Driven Retrieval Prototype", 
    "arxiv-id": "1101.1637v1", 
    "author": "Peter Mutschke", 
    "publish": "2011-01-09T14:32:41Z", 
    "summary": "This paper is about a better understanding on the structure and dynamics of\nscience and the usage of these insights for compensating the typical problems\nthat arises in metadata-driven Digital Libraries. Three science model driven\nretrieval services are presented: co-word analysis based query expansion,\nre-ranking via Bradfordizing and author centrality. The services are evaluated\nwith relevance assessments from which two important implications emerge: (1)\nprecision values of the retrieval service are the same or better than the\ntf-idf retrieval baseline and (2) each service retrieved a disjoint set of\ndocuments. The different services each favor quite other - but still relevant -\ndocuments than pure term-frequency based rankings. The proposed models and\nderived retrieval services therefore open up new viewpoints on the scientific\nknowledge space and provide an alternative framework to structure scholarly\ninformation systems."
},{
    "category": "cs.IR", 
    "doi": "10.1103/PhysRevE.83.046116", 
    "link": "http://arxiv.org/pdf/1101.1639v1", 
    "title": "Applying Science Models for Search", 
    "arxiv-id": "1101.1639v1", 
    "author": "York Sure", 
    "publish": "2011-01-09T14:42:04Z", 
    "summary": "The paper proposes three different kinds of science models as value-added\nservices that are integrated in the retrieval process to enhance retrieval\nquality. The paper discusses the approaches Search Term Recommendation,\nBradfordizing and Author Centrality on a general level and addresses\nimplementation issues of the models within a real-life retrieval environment."
},{
    "category": "nlin.AO", 
    "doi": "10.1103/PhysRevE.83.046116", 
    "link": "http://arxiv.org/pdf/1101.2591v1", 
    "title": "Emerging Search Regimes: Measuring Co-evolutions among Research,   Science, and Society", 
    "arxiv-id": "1101.2591v1", 
    "author": "Loet Leydesdorff", 
    "publish": "2011-01-13T15:45:58Z", 
    "summary": "Scientometric data is used to investigate empirically the emergence of search\nregimes in Biotechnology, Genomics, and Nanotechnology. Complex regimes can\nemerge when three independent sources of variance interact. In our model,\nresearchers can be considered as the nodes that carry the science system.\nResearch is geographically situated with site-specific skills, tacit knowledge\nand infrastructures. Second, the emergent science level refers to the formal\ncommunication of codified knowledge published in journals. Third, the\nsocio-economic dynamics indicate the ways in which knowledge production relates\nto society. Although Biotechnology, Genomics, and Nanotechnology can all be\ncharacterised by rapid growth and divergent dynamics, the regimes differ in\nterms of self-organization among these three sources of variance. The scope of\nopportunities for researchers to contribute within the constraints of the\nexisting body of knowledge are different in each field. Furthermore, the\nrelevance of the context of application contributes to the knowledge dynamics\nto various degrees."
},{
    "category": "cs.DL", 
    "doi": "10.1103/PhysRevE.83.046116", 
    "link": "http://arxiv.org/pdf/1101.3863v2", 
    "title": "Turning the tables in citation analysis one more time: Principles for   comparing sets of documents", 
    "arxiv-id": "1101.3863v2", 
    "author": "Tobias Opthof", 
    "publish": "2011-01-20T10:51:39Z", 
    "summary": "We submit newly developed citation impact indicators based not on arithmetic\naverages of citations but on percentile ranks. Citation distributions are-as a\nrule-highly skewed and should not be arithmetically averaged. With percentile\nranks, the citation of each paper is rated in terms of its percentile in the\ncitation distribution. The percentile ranks approach allows for the formulation\nof a more abstract indicator scheme that can be used to organize and/or\nschematize different impact indicators according to three degrees of freedom:\nthe selection of the reference sets, the evaluation criteria, and the choice of\nwhether or not to define the publication sets as independent. Bibliometric data\nof seven principal investigators (PIs) of the Academic Medical Center of the\nUniversity of Amsterdam is used as an exemplary data set. We demonstrate that\nthe proposed indicators [R(6), R(100), R(6,k), R(100,k)] are an improvement of\naverages-based indicators because one can account for the shape of the\ndistributions of citations over papers."
},{
    "category": "cs.DL", 
    "doi": "10.1103/PhysRevE.83.046116", 
    "link": "http://arxiv.org/pdf/1102.1064v1", 
    "title": "A Decade of Database Research Publications", 
    "arxiv-id": "1102.1064v1", 
    "author": "Mohammad Alomari", 
    "publish": "2011-02-05T11:52:53Z", 
    "summary": "We analyze the database research publications of four major core database\ntechnology conferences (SIGMOD, VLDB, ICDE, EDBT), two main theoretical\ndatabase conferences (PODS, ICDT) and three database journals (TODS, VLDB\nJournal, TKDE) over a period of 10 years (2001 - 2010). Our analysis considers\nonly regular papers as we do not include short papers, demo papers, posters,\ntutorials or panels into our statistics. We rank the research scholars\naccording to their number of publication in each conference/journal separately\nand in combined. We also report about the growth in the number of research\npublications and the size of the research community in the last decade."
},{
    "category": "cs.DL", 
    "doi": "10.1103/PhysRevE.83.046116", 
    "link": "http://arxiv.org/pdf/1102.1934v3", 
    "title": "The structure of the Arts & Humanities Citation Index: A mapping on the   basis of aggregated citations among 1,157 journals", 
    "arxiv-id": "1102.1934v3", 
    "author": "Alkim Almila Akdag Salah", 
    "publish": "2011-02-09T18:34:00Z", 
    "summary": "Using the Arts & Humanities Citation Index (A&HCI) 2008, we apply mapping\ntechniques previously developed for mapping journal structures in the Science\nand Social Science Citation Indices. Citation relations among the 110,718\nrecords were aggregated at the level of 1,157 journals specific to the A&HCI,\nand the journal structures are questioned on whether a cognitive structure can\nbe reconstructed and visualized. Both cosine-normalization (bottom up) and\nfactor analysis (top down) suggest a division into approximately twelve\nsubsets. The relations among these subsets are explored using various\nvisualization techniques. However, we were not able to retrieve this structure\nusing the ISI Subject Categories, including the 25 categories which are\nspecific to the A&HCI. We discuss options for validation such as against the\ncategories of the Humanities Indicators of the American Academy of Arts and\nSciences, the panel structure of the European Reference Index for the\nHumanities (ERIH), and compare our results with the curriculum organization of\nthe Humanities Section of the College of Letters and Sciences of UCLA as an\nexample of institutional organization."
},{
    "category": "cs.DL", 
    "doi": "10.1103/PhysRevE.83.046116", 
    "link": "http://arxiv.org/pdf/1102.2567v2", 
    "title": "Simple arithmetic versus intuitive understanding: The case of the impact   factor", 
    "arxiv-id": "1102.2567v2", 
    "author": "Loet Leydesdorff", 
    "publish": "2011-02-13T07:32:39Z", 
    "summary": "We show that as a consequence of basic properties of elementary arithmetic\njournal impact factors show a counterintuitive behaviour with respect to adding\nnon-cited articles. Synchronous as well as diachronous journal impact factors\nare affected. Our findings provide a rationale for not taking uncitable\npublications into account in impact factor calculations, at least if these\nitems are truly uncitable."
},{
    "category": "cs.DL", 
    "doi": "10.1103/PhysRevE.83.046116", 
    "link": "http://arxiv.org/pdf/1102.2569v2", 
    "title": "Citation analysis cannot legitimate the strategic selection of   excellence", 
    "arxiv-id": "1102.2569v2", 
    "author": "Loet Leydesdorff", 
    "publish": "2011-02-13T08:49:10Z", 
    "summary": "In reaction to a previous critique(Opthof & Leydesdorff, 2010), the Center\nfor Science and Technology Studies (CWTS) in Leiden proposed to change their\nold \"crown\" indicator in citation analysis into a new one. Waltman et al.\n(2011)argue that this change does not affect rankings at various aggregated\nlevels. However, CWTS data is not publicly available for testing and criticism.\nIn this correspondence, we use previously published data of Van Raan (2006) to\naddress the pivotal issue of how the results of citation analysis correlate\nwith the results of peer review. A quality parameter based on peer review was\nneither significantly correlated with the two parameters developed by the CWTS\nin the past (CPP/JCSm or CPP/FCSm) nor with the more recently proposed h-index\n(Hirsch, 2005). Given the high correlations between the old and new \"crown\"\nindicators, one can expect that the lack of correlation with the peer-review\nbased quality indicator applies equally to the newly developed ones."
},{
    "category": "physics.data-an", 
    "doi": "10.1016/j.nima.2011.03.018", 
    "link": "http://arxiv.org/pdf/1102.2806v2", 
    "title": "The Nuclear Science References (NSR) Database and Web Retrieval System", 
    "arxiv-id": "1102.2806v2", 
    "author": "J. Totans", 
    "publish": "2011-02-14T15:49:19Z", 
    "summary": "The Nuclear Science References (NSR) database together with its associated\nWeb interface, is the world's only comprehensive source of easily accessible\nlow- and intermediate-energy nuclear physics bibliographic information for more\nthan 200,000 articles since the beginning of nuclear science. The\nweekly-updated NSR database provides essential support for nuclear data\nevaluation, compilation and research activities. The principles of the database\nand Web application development and maintenance are described. Examples of\nnuclear structure, reaction and decay applications are specifically included.\nThe complete NSR database is freely available at the websites of the National\nNuclear Data Center http://www.nndc.bnl.gov/nsr and the International Atomic\nEnergy Agency http://www-nds.iaea.org/nsr."
},{
    "category": "math.HO", 
    "doi": "10.1016/j.nima.2011.03.018", 
    "link": "http://arxiv.org/pdf/1102.5720v1", 
    "title": "Liber Mathematicae: A Web-Based Documentation and Collaboration Project   for Mathematics", 
    "arxiv-id": "1102.5720v1", 
    "author": "John Tuley", 
    "publish": "2011-02-28T18:00:32Z", 
    "summary": "Traditionally, mathematical knowledge is published in printed media such as\nbooks or journals. With the advent of the Internet, a new method of publication\nbecame available. To date, however, most online mathematical publications do\nnot employ the full capabilities of the medium. We describe a project to\nmodernize online mathematics presentation and build a community-focused\nenvironment in which the lines between \"author\" and \"reader\" are blurred,\nenhancing collaboration and improving publication quality."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.nima.2011.03.018", 
    "link": "http://arxiv.org/pdf/1103.0738v1", 
    "title": "A Medial Axis Based Thinning Strategy for Character Images", 
    "arxiv-id": "1103.0738v1", 
    "author": "Gaurav Harit", 
    "publish": "2011-03-03T17:31:48Z", 
    "summary": "Thinning of character images is a big challenge. Removal of strokes or\ndeformities in thinning is a difficult problem. In this paper, we have proposed\na medial axis based thinning strategy used for performing skeletonization of\nprinted and handwritten character images. In this method, we have used shape\ncharacteristics of text to get skeleton of nearly same as the true character\nshape. This approach helps to preserve the local features and true shape of the\ncharacter images. The proposed algorithm produces one pixel width thin\nskeleton. As a by-product of our thinning approach, the skeleton also gets\nsegmented into strokes in vector form. Hence further stroke segmentation is not\nrequired. Experiment is done on printed English and Bengali characters and we\nobtain less spurious branches comparing with other thinning methods without any\npost processing."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.nima.2011.03.018", 
    "link": "http://arxiv.org/pdf/1103.1482v1", 
    "title": "The Planetary System: Executable Science, Technology, Engineering and   Math Papers", 
    "arxiv-id": "1103.1482v1", 
    "author": "Vyacheslav Zholudev", 
    "publish": "2011-03-08T10:12:40Z", 
    "summary": "Executable scientific papers contain not just layouted text for reading. They\ncontain, or link to, machine-comprehensible representations of the scientific\nfindings or experiments they describe. Client-side players can thus enable\nreaders to \"check, manipulate and explore the result space\". We have realized\nexecutable papers in the STEM domain with the Planetary system. Semantic\nannotations associate the papers with a content commons holding the background\nontology, the annotations are exposed as Linked Data, and a frontend player\napplication hooks modular interactive services into the semantic annotations."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.nima.2011.03.018", 
    "link": "http://arxiv.org/pdf/1103.3075v1", 
    "title": "Connectivity Damage to a Graph by the Removal of an Edge or a Vertex", 
    "arxiv-id": "1103.3075v1", 
    "author": "Michael L. Nelson", 
    "publish": "2011-03-16T01:33:42Z", 
    "summary": "The approach of quantifying the damage inflicted on a graph in Albert, Jeong\nand Barabsi's (AJB) report \"Error and Attack Tolerance of Complex Networks\"\nusing the size of the largest connected component and the average size of the\nremaining components does not capture our intuitive idea of the damage to a\ngraph caused by disconnections. We evaluate an alternative metric based on\naverage inverse path lengths (AIPLs) that better fits our intuition that a\ngraph can still be reasonably functional even when it is disconnected. We\ncompare our metric with AJB's using a test set of graphs and report the\ndifferences. AJB's report should not be confused with a report by Crucitti et\nal. with the same name. Based on our analysis of graphs of different sizes and\ntypes, and using various numerical and statistical tools; the ratio of the\naverage inverse path lengths of a connected graph of the same size as the sum\nof the size of the fragments of the disconnected graph can be used as a metric\nabout the damage of a graph by the removal of an edge or a node. This damage is\nreported in the range (0,1) where 0 means that the removal had no effect on the\ngraph's capability to perform its functions. A 1 means that the graph is\ntotally dysfunctional. We exercise our metric on a collection of sample graphs\nthat have been subjected to various attack profiles that focus on edge, node or\ndegree betweenness values. We believe that this metric can be used to quantify\nthe damage done to the graph by an attacker, and that it can be used in\nevaluating the positive effect of adding additional edges to an existing graph."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.nima.2011.03.018", 
    "link": "http://arxiv.org/pdf/1103.3216v5", 
    "title": "Which cities produce excellent papers worldwide more than can be   expected? A new mapping approach--using Google Maps--based on statistical   significance testing", 
    "arxiv-id": "1103.3216v5", 
    "author": "Loet Leydesdorff", 
    "publish": "2011-03-16T16:14:45Z", 
    "summary": "The methods presented in this paper allow for a statistical analysis\nrevealing centers of excellence around the world using programs that are freely\navailable. Based on Web of Science data, field-specific excellence can be\nidentified in cities where highly-cited papers were published significantly.\nCompared to the mapping approaches published hitherto, our approach is more\nanalytically oriented by allowing the assessment of an observed number of\nexcellent papers for a city (in the sample) against the expected number. Using\nthis test, the approach cannot only identify the top performers in output but\nthe \"true jewels.\" These are cities locating authors who publish significantly\nmore top cited papers than can be expected. As the examples in this paper show\nfor physics, chemistry, and psychology, these cities do not necessarily have a\nhigh output of excellent papers."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1007/978-1-4419-8369-5_15", 
    "link": "http://arxiv.org/pdf/1103.4295v1", 
    "title": "Linking Literature and Data: Status Report and Future Efforts", 
    "arxiv-id": "1103.4295v1", 
    "author": "Alberto Accomazzi", 
    "publish": "2011-03-22T15:52:51Z", 
    "summary": "In the current era of data-intensive science, it is increasingly important\nfor researchers to be able to have access to published results, the supporting\ndata, and the processes used to produce them. Six years ago, recognizing this\nneed, the American Astronomical Society and the Astrophysics Data Centers\nExecutive Committee (ADEC) sponsored an effort to facilitate the annotation and\nlinking of datasets during the publishing process, with limited success. I will\nreview the status of this effort and describe a new, more general one now being\nconsidered in the context of the Virtual Astronomical Observatory."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-1-4419-8369-5_15", 
    "link": "http://arxiv.org/pdf/1103.5241v2", 
    "title": "Integrated Impact Indicators (I3) compared with Impact Factors (IFs): An   alternative research design with policy implications", 
    "arxiv-id": "1103.5241v2", 
    "author": "Lutz Bornmann", 
    "publish": "2011-03-27T18:33:12Z", 
    "summary": "In bibliometrics, the association of \"impact\" with central-tendency\nstatistics is mistaken. Impacts add up, and citation curves should therefore be\nintegrated instead of averaged. For example, the journals MIS Quarterly and\nJASIST differ by a factor of two in terms of their respective impact factors\n(IF), but the journal with the lower IF has the higher impact. Using percentile\nranks (e.g., top-1%, top-10%, etc.), an integrated impact indicator (I3) can be\nbased on integration of the citation curves, but after normalization of the\ncitation curves to the same scale. The results across document sets can be\ncompared as percentages of the total impact of a reference set. Total number of\ncitations, however, should not be used instead because the shape of the\ncitation curves is then not appreciated. I3 can be applied to any document set\nand any citation window. The results of the integration (summation) are fully\ndecomposable in terms of journals or instititutional units such as nations,\nuniversities, etc., because percentile ranks are determined at the paper level.\nIn this study, we first compare I3 with IFs for the journals in two ISI Subject\nCategories (\"Information Science & Library Science\" and \"Multidisciplinary\nSciences\"). The LIS set is additionally decomposed in terms of nations. Policy\nimplications of this possible paradigm shift in citation impact analysis are\nspecified."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1007/978-1-4419-8369-5_12", 
    "link": "http://arxiv.org/pdf/1103.5474v1", 
    "title": "Telescope Bibliometrics 101", 
    "arxiv-id": "1103.5474v1", 
    "author": "Jill Lagerstrom", 
    "publish": "2011-03-28T20:21:22Z", 
    "summary": "During recent years, bibliometric studies have become increasingly important\nin evaluating individual scientists, institutes, and entire observatories. In\nastronomy, often librarians are involved in maintaining publication databases\nand compiling statistics for their institutions. In this paper, we present a\nlook behind the scenes to understand who is interested in bibliometric\nstatistics, which methodologies astronomy librarians apply, and what kind of\nfeatures next-generation bibliographies may include."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1007/978-1-4419-8369-5_12", 
    "link": "http://arxiv.org/pdf/1103.5958v1", 
    "title": "Semantic Interlinking of Resources in the Virtual Observatory Era", 
    "arxiv-id": "1103.5958v1", 
    "author": "Rahul Dave", 
    "publish": "2011-03-30T15:26:43Z", 
    "summary": "In the coming era of data-intensive science, it will be increasingly\nimportant to be able to seamlessly move between scientific results, the data\nanalyzed in them, and the processes used to produce them. As observations,\nderived data products, publications, and object metadata are curated by\ndifferent projects and archived in different locations, establishing the proper\nlinkages between these resources and describing their relationships becomes an\nessential activity in their curation and preservation. In this paper we\ndescribe initial efforts to create a semantic knowledge base allowing easier\nintegration and linking of the body of heterogeneous astronomical resources\nwhich we call the Virtual Observatory (VO). The ultimate goal of this effort is\nthe creation of a semantic layer over existing resources, allowing applications\nto cross boundaries between archives. The proposed approach follows the current\nbest practices in Semantic Computing and the architecture of the web, allowing\nthe use of off-the-shelf technologies and providing a path for VO resources to\nbecome part of the global web of linked data."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.wasman.2012.01.017", 
    "link": "http://arxiv.org/pdf/1105.1227v4", 
    "title": "How journal rankings can suppress interdisciplinary research. A   comparison between Innovation Studies and Business & Management", 
    "arxiv-id": "1105.1227v4", 
    "author": "Andy Stirling", 
    "publish": "2011-05-06T05:42:30Z", 
    "summary": "This study provides quantitative evidence on how the use of journal rankings\ncan disadvantage interdisciplinary research in research evaluations. Using\npublication and citation data, it compares the degree of interdisciplinarity\nand the research performance of a number of Innovation Studies units with that\nof leading Business & Management schools in the UK. On the basis of various\nmappings and metrics, this study shows that: (i) Innovation Studies units are\nconsistently more interdisciplinary in their research than Business &\nManagement schools; (ii) the top journals in the Association of Business\nSchools' rankings span a less diverse set of disciplines than lower-ranked\njournals; (iii) this results in a more favourable assessment of the performance\nof Business & Management schools, which are more disciplinary-focused. This\ncitation-based analysis challenges the journal ranking-based assessment. In\nshort, the investigation illustrates how ostensibly 'excellence-based' journal\nrankings exhibit a systematic bias in favour of mono-disciplinary research. The\npaper concludes with a discussion of implications of these phenomena, in\nparticular how the bias is likely to affect negatively the evaluation and\nassociated financial resourcing of interdisciplinary research organisations,\nand may result in researchers becoming more compliant with disciplinary\nauthority over time."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.wasman.2012.01.017", 
    "link": "http://arxiv.org/pdf/1105.2441v1", 
    "title": "Science Models as Value-Added Services for Scholarly Information Systems", 
    "arxiv-id": "1105.2441v1", 
    "author": "York Sure", 
    "publish": "2011-05-12T12:07:42Z", 
    "summary": "The paper introduces scholarly Information Retrieval (IR) as a further\ndimension that should be considered in the science modeling debate. The IR use\ncase is seen as a validation model of the adequacy of science models in\nrepresenting and predicting structure and dynamics in science. Particular\nconceptualizations of scholarly activity and structures in science are used as\nvalue-added search services to improve retrieval quality: a co-word model\ndepicting the cognitive structure of a field (used for query expansion), the\nBradford law of information concentration, and a model of co-authorship\nnetworks (both used for re-ranking search results). An evaluation of the\nretrieval quality when science model driven services are used turned out that\nthe models proposed actually provide beneficial effects to retrieval quality.\nFrom an IR perspective, the models studied are therefore verified as expressive\nconceptualizations of central phenomena in science. Thus, it could be shown\nthat the IR perspective can significantly contribute to a better understanding\nof scholarly structures and activities."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.wasman.2012.01.017", 
    "link": "http://arxiv.org/pdf/1105.4318v1", 
    "title": "Correction of Noisy Sentences using a Monolingual Corpus", 
    "arxiv-id": "1105.4318v1", 
    "author": "Diptesh Chatterhee", 
    "publish": "2011-05-22T09:01:38Z", 
    "summary": "Correction of Noisy Natural Language Text is an important and well studied\nproblem in Natural Language Processing. It has a number of applications in\ndomains like Statistical Machine Translation, Second Language Learning and\nNatural Language Generation. In this work, we consider some statistical\ntechniques for Text Correction. We define the classes of errors commonly found\nin text and describe algorithms to correct them. The data has been taken from a\npoorly trained Machine Translation system. The algorithms use only a language\nmodel in the target language in order to correct the sentences. We use phrase\nbased correction methods in both the algorithms. The phrases are replaced and\ncombined to give us the final corrected sentence. We also present the methods\nto model different kinds of errors, in addition to results of the working of\nthe algorithms on the test set. We show that one of the approaches fail to\nachieve the desired goal, whereas the other succeeds well. In the end, we\nanalyze the possible reasons for such a trend in performance."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.wasman.2012.01.017", 
    "link": "http://arxiv.org/pdf/1105.5316v1", 
    "title": "On the correlation between bibliometric indicators and peer review:   Reply to Opthof and Leydesdorff", 
    "arxiv-id": "1105.5316v1", 
    "author": "Anthony F. J. van Raan", 
    "publish": "2011-05-26T14:51:45Z", 
    "summary": "Opthof and Leydesdorff [arXiv:1102.2569] reanalyze data reported by Van Raan\n[arXiv:physics/0511206] and conclude that there is no significant correlation\nbetween on the one hand average citation scores measured using the CPP/FCSm\nindicator and on the other hand the quality judgment of peers. We point out\nthat Opthof and Leydesdorff draw their conclusions based on a very limited\namount of data. We also criticize the statistical methodology used by Opthof\nand Leydesdorff. Using a larger amount of data and a more appropriate\nstatistical methodology, we do find a significant correlation between the\nCPP/FCSm indicator and peer judgment."
},{
    "category": "cs.IR", 
    "doi": "10.1016/j.wasman.2012.01.017", 
    "link": "http://arxiv.org/pdf/1105.5789v1", 
    "title": "Clustering and Classification in Text Collections Using Graph Modularity", 
    "arxiv-id": "1105.5789v1", 
    "author": "Sergei Trunov", 
    "publish": "2011-05-29T14:06:44Z", 
    "summary": "A new fast algorithm for clustering and classification of large collections\nof text documents is introduced. The new algorithm employs the bipartite graph\nthat realizes the word-document matrix of the collection. Namely, the\nmodularity of the bipartite graph is used as the optimization functional.\nExperiments performed with the new algorithm on a number of text collections\nhad shown a competitive quality of the clustering (classification), and a\nrecord-breaking speed."
},{
    "category": "cs.IR", 
    "doi": "10.1016/j.wasman.2012.01.017", 
    "link": "http://arxiv.org/pdf/1106.0217v1", 
    "title": "Using Lotkaian Informetrics for Ranking in Digital Libraries", 
    "arxiv-id": "1106.0217v1", 
    "author": "Philipp Schaer", 
    "publish": "2011-06-01T16:13:18Z", 
    "summary": "The purpose of this paper is to propose the use of models, theories and laws\nin bibliometrics and scientometrics to enhance information retrieval processes,\nespecially ranking. A common pattern in many man-made data sets is Lotka's Law\nwhich follows the well-known power-law distributions. These informetric\ndistributions can be used to give an alternative order to large and scattered\nresult sets and can be applied as a new ranking mechanism. The\npolyrepresentation of information in Digital Library systems is used to enhance\nthe retrieval quality, to overcome the drawbacks of the typical term-based\nranking approaches and to enable users to explore retrieved document sets from\na different perspective."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.wasman.2012.01.017", 
    "link": "http://arxiv.org/pdf/1106.1523v1", 
    "title": "A Novel Combined Term Suggestion Service for Domain-Specific Digital   Libraries", 
    "arxiv-id": "1106.1523v1", 
    "author": "Philipp Mayr", 
    "publish": "2011-06-08T09:04:58Z", 
    "summary": "Interactive query expansion can assist users during their query formulation\nprocess. We conducted a user study with over 4,000 unique visitors and four\ndifferent design approaches for a search term suggestion service. As a basis\nfor our evaluation we have implemented services which use three different\nvocabularies: (1) user search terms, (2) terms from a terminology service and\n(3) thesaurus terms. Additionally, we have created a new combined service which\nutilizes thesaurus term and terms from a domain-specific search term\nre-commender. Our results show that the thesaurus-based method clearly is used\nmore often compared to the other single-method implementations. We interpret\nthis as a strong indicator that term suggestion mechanisms should be\ndomain-specific to be close to the user terminology. Our novel combined\napproach which interconnects a thesaurus service with additional statistical\nrelations out-performed all other implementations. All our observations show\nthat domain-specific vocabulary can support the user in finding alternative\nconcepts and formulating queries."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1007/978-1-4614-3323-1_4", 
    "link": "http://arxiv.org/pdf/1106.3305v1", 
    "title": "The Art of Data Science", 
    "arxiv-id": "1106.3305v1", 
    "author": "Matthew J. Graham", 
    "publish": "2011-06-16T18:45:32Z", 
    "summary": "To flourish in the new data-intensive environment of 21st century science, we\nneed to evolve new skills. These can be expressed in terms of the systemized\nframework that formed the basis of mediaeval education - the trivium (logic,\ngrammar, and rhetoric) and quadrivium (arithmetic, geometry, music, and\nastronomy). However, rather than focusing on number, data is the new keystone.\nWe need to understand what rules it obeys, how it is symbolized and\ncommunicated and what its relationship to physical space and time is. In this\npaper, we will review this understanding in terms of the technologies and\nprocesses that it requires. We contend that, at least, an appreciation of all\nthese aspects is crucial to enable us to extract scientific information and\nknowledge from the data sets which threaten to engulf and overwhelm us."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-1-4614-3323-1_4", 
    "link": "http://arxiv.org/pdf/1106.5304v1", 
    "title": "OpenPh - Numerical Physics Library", 
    "arxiv-id": "1106.5304v1", 
    "author": "Florin Pop", 
    "publish": "2011-06-27T06:03:50Z", 
    "summary": "Numerical physics has gained a lot of importance in the last decade, its\nefficiency being motivated and sustained by the growth of computational power.\nThis paper presents a concept that is to be developed in the next few years:\nOpenPh. OpenPh is a numerical physics library that makes use of the advantages\nof both open source software and MATLAB programming. Its aim is to deliver the\ninstruments for providing numerical and graphical solutions for various physics\nproblems. It has a modular structure, allowing the user to add new modules to\nthe existing ones and to create its own modules according to its needs, being\nvirtually unlimited extendable. The modules of OpenPh are implemented using\nMATLAB engine because it is the best solution used in engineering and science,\nproviding a wide range of optimized methods to accomplish even the toughest\njobs. Current version of OpenPh includes two modules, the first one providing\ntools for quantum physics and the second one for mechanics. The quantum physics\nmodule deals with the photoelectric effect, the radioactive decay of carbon-11,\nand the Schr\\\"odinger equation - particle in a box. The classical mechanics\nmodule includes the study of the uniform circular motion, the forced damped\nharmonic oscillations and the vibration of a fixed-fixed string."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1007/978-1-4614-3323-1_4", 
    "link": "http://arxiv.org/pdf/1106.5644v1", 
    "title": "The ADS in the Information Age - Impact on Discovery", 
    "arxiv-id": "1106.5644v1", 
    "author": "Alberto Accomazzi", 
    "publish": "2011-06-28T12:21:55Z", 
    "summary": "The SAO/NASA Astrophysics Data System (ADS) grew up with and has been riding\nthe waves of the Information Age, closely monitoring and anticipating the needs\nof its end-users. By now, all professional astronomers are using the ADS on a\ndaily basis, and a substantial fraction have been using it for their entire\nprofessional career. In addition to being an indispensable tool for\nprofessional scientists, the ADS also moved into the public domain, as a tool\nfor science education. In this paper we will highlight and discuss some aspects\nindicative of the impact the ADS has had on research and the access to\nscholarly publications.\n  The ADS is funded by NASA Grant NNX09AB39G"
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-642-22673-1_10", 
    "link": "http://arxiv.org/pdf/1107.3212v1", 
    "title": "Licensing the Mizar Mathematical Library", 
    "arxiv-id": "1107.3212v1", 
    "author": "Lionel Mamane", 
    "publish": "2011-07-16T09:06:49Z", 
    "summary": "The Mizar Mathematical Library (MML) is a large corpus of formalised\nmathematical knowledge. It has been constructed over the course of many years\nby a large number of authors and maintainers. Yet the legal status of these\nefforts of the Mizar community has never been clarified. In 2010, after many\nyears of loose deliberations, the community decided to investigate the issue of\nlicensing the content of the MML, thereby clarifying and crystallizing the\nstatus of the texts, the text's authors, and the library's long-term\nmaintainers. The community has settled on a copyright and license policy that\nsuits the peculiar features of Mizar and its community. In this paper we\ndiscuss the copyright and license solutions. We offer our experience in the\nhopes that the communities of other libraries of formalised mathematical\nknowledge might take up the legal and scientific problems that we addressed for\nMizar."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-3-642-22673-1_19", 
    "link": "http://arxiv.org/pdf/1107.4721v2", 
    "title": "mizar-items: Exploring fine-grained dependencies in the Mizar   Mathematical Library", 
    "arxiv-id": "1107.4721v2", 
    "author": "Jesse Alama", 
    "publish": "2011-07-24T04:25:44Z", 
    "summary": "The Mizar Mathematical Library (MML) is a rich database of formalized\nmathematical proofs (see http://mizar.org). Owing to its large size (it\ncontains more than 1100 \"articles\" summing to nearly 2.5 million lines of text,\nexpressing more than 50000 theorems and 10000 definitions using more than 7000\nsymbols), the nature of its contents (the MML is slanted toward pure\nmathematics), and its classical foundations (first-order logic, set theory,\nnatural deduction), the MML is an especially attractive target for research on\nfoundations of mathematics. We have implemented a system, mizar-items, on which\na variety of such foundational experiements can be based. The heart of\nmizar-items is a method for decomposing the contents of the MML into\nfine-grained \"items\" (e.g., theorem, definition, notation, etc.) and computing\ndependency relations among these items. mizar-items also comes equipped with a\nwebsite for exploring these dependencies and interacting with them."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1103/PhysRevE.84.046104", 
    "link": "http://arxiv.org/pdf/1108.1325v1", 
    "title": "Tracing the Evolution of Physics on the Backbone of Citation Networks", 
    "arxiv-id": "1108.1325v1", 
    "author": "Y. -C. Zhang", 
    "publish": "2011-08-05T13:38:58Z", 
    "summary": "Many innovations are inspired by past ideas in a non-trivial way. Tracing\nthese origins and identifying scientific branches is crucial for research\ninspirations. In this paper, we use citation relations to identify the\ndescendant chart, i.e. the family tree of research papers. Unlike other\nspanning trees which focus on cost or distance minimization, we make use of the\nnature of citations and identify the most important parent for each\npublication, leading to a tree-like backbone of the citation network. Measures\nare introduced to validate the backbone as the descendant chart. We show that\ncitation backbones can well characterize the hierarchical and fractal structure\nof scientific development, and lead to accurate classification of fields and\nsub-fields."
},{
    "category": "cs.DL", 
    "doi": "10.1103/PhysRevE.84.046104", 
    "link": "http://arxiv.org/pdf/1108.3901v1", 
    "title": "The inconsistency of the h-index", 
    "arxiv-id": "1108.3901v1", 
    "author": "Nees Jan van Eck", 
    "publish": "2011-08-19T06:05:06Z", 
    "summary": "The h-index is a popular bibliometric indicator for assessing individual\nscientists. We criticize the h-index from a theoretical point of view. We argue\nthat for the purpose of measuring the overall scientific impact of a scientist\n(or some other unit of analysis) the h-index behaves in a counterintuitive way.\nIn certain cases, the mechanism used by the h-index to aggregate publication\nand citation statistics into a single number leads to inconsistencies in the\nway in which scientists are ranked. Our conclusion is that the h-index cannot\nbe considered an appropriate indicator of a scientist's overall scientific\nimpact. Based on recent theoretical insights, we discuss what kind of\nindicators can be used as an alternative to the h-index. We pay special\nattention to the highly cited publications indicator. This indicator has a lot\nin common with the h-index, but unlike the h-index it does not produce\ninconsistent rankings."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1103/PhysRevE.84.046104", 
    "link": "http://arxiv.org/pdf/1108.5648v1", 
    "title": "On the shoulders of students? The contribution of PhD students to the   advancement of knowledge", 
    "arxiv-id": "1108.5648v1", 
    "author": "Vincent Lariviere", 
    "publish": "2011-08-29T16:51:11Z", 
    "summary": "Using the participation in peer reviewed publications of all doctoral\nstudents in Quebec over the 2000-2007 period this paper provides the first\nlarge scale analysis of their research effort. It shows that PhD students\ncontribute to about a third of the publication output of the province, with\ndoctoral students in the natural and medical sciences being present in a higher\nproportion of papers published than their colleagues of the social sciences and\nhumanities. Collaboration is an important component of this socialization:\ndisciplines in which student collaboration is higher are also those in which\ndoctoral students are the most involved in peer-reviewed publications. In terms\nof scientific impact, papers co-signed by doctorate students obtain\nsignificantly lower citation rates than other Quebec papers, except in natural\nsciences and engineering. Finally, this paper shows that involving doctoral\nstudents in publications is positively linked with degree completion and\nulterior career in research."
},{
    "category": "cs.DL", 
    "doi": "10.1103/PhysRevE.84.046104", 
    "link": "http://arxiv.org/pdf/1108.5845v1", 
    "title": "A Rejoinder on Energy versus Impact Indicators", 
    "arxiv-id": "1108.5845v1", 
    "author": "Tobias Opthof", 
    "publish": "2011-08-30T06:43:41Z", 
    "summary": "Citation distributions are so skewed that using the mean or any other central\ntendency measure is ill-advised. Unlike G. Prathap's scalar measures (Energy,\nExergy, and Entropy or EEE), the Integrated Impact Indicator (I3) is based on\nnon-parametric statistics using the (100) percentiles of the distribution.\nObserved values can be tested against expected ones; impact can be qualified at\nthe article level and then aggregated."
},{
    "category": "cs.DL", 
    "doi": "10.1103/PhysRevE.84.046104", 
    "link": "http://arxiv.org/pdf/1110.0791v1", 
    "title": "Rapid, Impartial and Comprehensive (RIC) publishing: A new concept for   scientific journals", 
    "arxiv-id": "1110.0791v1", 
    "author": "Sergey I. Bozhevolnyi", 
    "publish": "2011-10-04T18:51:53Z", 
    "summary": "Publishing scientific journals governed by editors relying on anonymous peer\nreviewing is slow (even one round of reviewing involves several communications\nbetween authors, editor and reviewers), partial (arguments of authors can\nhardly overrule those of reviewers) and not using all available scientific\nmaterial (even the most thorough and insightful reviews remain for the eyes of\nauthors and editors only). Here I propose a new concept for scientific journals\nthat ensures rapid, impartial and comprehensive (RIC) publishing. RIC concept\nis based on implementation of two novel publishing principles: the first\n(rapid) editorial screening of a submitted manuscript should result in its\neither \"rejection\" or \"acceptance with optional revisions\", and, in the latter\ncase, the optionally revised (taking into account open reviews) paper should be\npublished along with all (positive and negative) reviews, presenting thereby to\nthe scientific community all available scientific material on the topic in\nquestion."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1086/665581", 
    "link": "http://arxiv.org/pdf/1110.1212v2", 
    "title": "Chandra Publication Statistics", 
    "arxiv-id": "1110.1212v2", 
    "author": "Glenn Becker", 
    "publish": "2011-10-06T10:36:46Z", 
    "summary": "In this study we develop and propose publication metrics, based on an\nanalysis of data from the Chandra bibliographic database, that are more\nmeaningful and less sensitive to observatory-specific characteristics than the\ntraditional metrics. They fall in three main categories: speed of publication;\nfraction of observing time published; and archival usage. Citation of results\nis a fourth category, but lends itself less well to definite statements. For\nChandra, the median time from observation to publication is 2.36 years; after\nabout 7 years 90% of the observing time is published; after 10 years 70% of the\nobserving time is published more than twice; and the total annual publication\noutput of the mission is 60-70% of the cumulative observing time available,\nassuming a two year lag between data retrieval and publication."
},{
    "category": "cs.CL", 
    "doi": "10.1086/665581", 
    "link": "http://arxiv.org/pdf/1110.1428v1", 
    "title": "Product Review Summarization based on Facet Identification and Sentence   Clustering", 
    "arxiv-id": "1110.1428v1", 
    "author": "Min-Yen Kan", 
    "publish": "2011-10-07T04:56:43Z", 
    "summary": "Product review nowadays has become an important source of information, not\nonly for customers to find opinions about products easily and share their\nreviews with peers, but also for product manufacturers to get feedback on their\nproducts. As the number of product reviews grows, it becomes difficult for\nusers to search and utilize these resources in an efficient way. In this work,\nwe build a product review summarization system that can automatically process a\nlarge collection of reviews and aggregate them to generate a concise summary.\nMore importantly, the drawback of existing product summarization systems is\nthat they cannot provide the underlying reasons to justify users' opinions. In\nour method, we solve this problem by applying clustering, prior to selecting\nrepresentative candidates for summarization."
},{
    "category": "cs.DL", 
    "doi": "10.1086/665581", 
    "link": "http://arxiv.org/pdf/1110.1802v3", 
    "title": "World Shares of Publications of the USA, EU-27, and China Compared and   Predicted using the New Interface of the Web-of-Science versus Scopus", 
    "arxiv-id": "1110.1802v3", 
    "author": "Loet Leydesdorff", 
    "publish": "2011-10-09T07:17:43Z", 
    "summary": "The new interface of the Web of Science (of Thomson Reuters) enables users to\nretrieve sets larger than 100,000 documents in a single search. This makes it\npossible to compare publication trends for China, the USA, EU-27, and a number\nof smaller countries. China no longer grew exponentially during the 2000s, but\nlinearly. Contrary to previous predictions on the basis of exponential growth\nor Scopus data, the cross-over of the lines for China and the USA is postponed\nto the next decade (after 2020) according to this data. These long\nextrapolations, however, should be used only as indicators and not as\npredictions. Along with the dynamics in the publication trends, one also has to\ntake into account the dynamics of the databases used for the measurement."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1007/s11192-012-0694-9", 
    "link": "http://arxiv.org/pdf/1110.3271v2", 
    "title": "Universality of Performance Indicators based on Citation and Reference   Counts", 
    "arxiv-id": "1110.3271v2", 
    "author": "B. S. Kaube", 
    "publish": "2011-10-14T17:21:16Z", 
    "summary": "We find evidence for the universality of two relative bibliometric indicators\nof the quality of individual scientific publications taken from different data\nsets. One of these is a new index that considers both citation and reference\ncounts. We demonstrate this universality for relatively well cited publications\nfrom a single institute, grouped by year of publication and by faculty or by\ndepartment. We show similar behaviour in publications submitted to the arXiv\ne-print archive, grouped by year of submission and by sub-archive. We also find\nthat for reasonably well cited papers this distribution is well fitted by a\nlognormal with a variance of around 1.3 which is consistent with the results of\nRadicchi, Fortunato, and Castellano (2008). Our work demonstrates that\ncomparisons can be made between publications from different disciplines and\npublication dates, regardless of their citation count and without expensive\naccess to the whole world-wide citation graph. Further, it shows that averages\nof the logarithm of such relative bibliometric indices deal with the issue of\nlong tails and avoid the need for statistics based on lengthy ranking\nprocedures."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1007/s11192-012-0694-9", 
    "link": "http://arxiv.org/pdf/1110.5825v1", 
    "title": "IVOA Recommendation: IVOA Support Interfaces", 
    "arxiv-id": "1110.5825v1", 
    "author": "Web Services Working Group", 
    "publish": "2011-10-26T15:49:00Z", 
    "summary": "This document describes the minimum interface that a (SOAP- or REST-based)\nweb service requires to participate in the IVOA. Note that this is not required\nof standard VO services developed prior to this specification, although uptake\nis strongly encouraged on any subsequent revision. All new standard VO\nservices, however, must feature a VOSI-compliant interface.\n  This document has been produced by the Grid and Web Services Working Group.\nIt has been reviewed by IVOA Members and other interested parties, and has been\nendorsed by the IVOA Executive Committee as an IVOA Recommendation. It is a\nstable document and may be used as reference material or cited as a normative\nreference from another document. IVOA's role in making the Recommendation is to\ndraw attention to the specification and to promote its widespread deployment.\nThis enhances the functionality and interoperability inside the Astronomical\nCommunity."
},{
    "category": "cs.DL", 
    "doi": "10.1007/s11192-012-0694-9", 
    "link": "http://arxiv.org/pdf/1110.5863v1", 
    "title": "A Wikipedia Literature Review", 
    "arxiv-id": "1110.5863v1", 
    "author": "Owen S. Martin", 
    "publish": "2011-10-17T21:19:58Z", 
    "summary": "This paper was originally designed as a literature review for a doctoral\ndissertation focusing on Wikipedia. This exposition gives the structure of\nWikipedia and the latest trends in Wikipedia research."
},{
    "category": "hep-ex", 
    "doi": "10.1088/1742-6596/368/1/012026", 
    "link": "http://arxiv.org/pdf/1111.2788v1", 
    "title": "Data Preservation in High Energy Physics", 
    "arxiv-id": "1111.2788v1", 
    "author": "Michael Steder", 
    "publish": "2011-11-11T16:24:02Z", 
    "summary": "Data from high-energy physics experiments are collected with significant\nfinancial and human effort and are mostly unique. However, until recently no\ncoherent strategy existed for data preservation and re-use, and many important\nand complex data sets have simply been lost. While the current focus is on the\nLHC at CERN, in the current period several important and unique experimental\nprograms at other facilities are coming to an end, including those at HERA,\nb-factories and the Tevatron. To address this issue, an inter-experimental\nstudy group on HEP data preservation and long-term analysis (DPHEP) was\nconvened at the end of 2008. The group now aims to publish a full and detailed\nreview of the present status of data preservation in high energy physics. This\ncontribution summarises the results of the DPHEP study group, describing the\nchallenges of data preservation in high energy physics and the group's first\nconclusions and recommendations. The physics motivation for data preservation,\ngeneric computing and preservation models, technological expectations and\ngovernance aspects at local and international levels are examined."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1016/j.physa.2011.11.021", 
    "link": "http://arxiv.org/pdf/1111.2829v1", 
    "title": "Universality in Bibliometrics", 
    "arxiv-id": "1111.2829v1", 
    "author": "Jose Palazzo Moreira de Oliveira", 
    "publish": "2011-11-11T19:33:03Z", 
    "summary": "Many discussions have enlarged the literature in Bibliometrics since the\nHirsh proposal, the so called $h$-index. Ranking papers according to their\ncitations, this index quantifies a researcher only by its greatest possible\nnumber of papers that are cited at least $h$ times. A closed formula for\n$h$-index distribution that can be applied for distinct databases is not yet\nknown. In fact, to obtain such distribution, the knowledge of citation\ndistribution of the authors and its specificities are required. Instead of\ndealing with researchers randomly chosen, here we address different groups\nbased on distinct databases. The first group is composed by physicists and\nbiologists, with data extracted from Institute of Scientific Information (ISI).\nThe second group composed by computer scientists, which data were extracted\nfrom Google-Scholar system. In this paper, we obtain a general formula for the\n$h$-index probability density function (pdf) for groups of authors by using\ngeneralized exponentials in the context of escort probability. Our analysis\nincludes the use of several statistical methods to estimate the necessary\nparameters. Also an exhaustive comparison among the possible candidate\ndistributions are used to describe the way the citations are distributed among\nauthors. The $h$-index pdf should be used to classify groups of researchers\nfrom a quantitative point of view, which is meaningfully interesting to\neliminate obscure qualitative methods."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.physa.2011.11.021", 
    "link": "http://arxiv.org/pdf/1111.3618v1", 
    "title": "Linking to Data - Effect on Citation Rates in Astronomy", 
    "arxiv-id": "1111.3618v1", 
    "author": "Alberto Accomazzi", 
    "publish": "2011-11-15T19:40:32Z", 
    "summary": "Is there a difference in citation rates between articles that were published\nwith links to data and articles that were not? Besides being interesting from a\npurely academic point of view, this question is also highly relevant for the\nprocess of furthering science. Data sharing not only helps the process of\nverification of claims, but also the discovery of new findings in archival\ndata. However, linking to data still is a far cry away from being a \"practice\",\nespecially where it comes to authors providing these links during the writing\nand submission process. You need to have both a willingness and a publication\nmechanism in order to create such a practice. Showing that articles with links\nto data get higher citation rates might increase the willingness of scientists\nto take the extra steps of linking data sources to their publications. In this\npresentation we will show this is indeed the case: articles with links to data\nresult in higher citation rates than articles without such links. The ADS is\nfunded by NASA Grant NNX09AB39G."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1016/j.physa.2011.11.021", 
    "link": "http://arxiv.org/pdf/1111.3983v1", 
    "title": "The ADS All-Sky Survey", 
    "arxiv-id": "1111.3983v1", 
    "author": "August Muench", 
    "publish": "2011-11-16T22:09:57Z", 
    "summary": "The ADS All-Sky Survey (ADSASS) is an ongoing effort aimed at turning the\nNASA Astrophysics Data System (ADS), widely known for its unrivaled value as a\nliterature resource for astronomers, into a data resource. The ADS is not a\ndata repository per se, but it implicitly contains valuable holdings of\nastronomical data, in the form of images, tables and object references\ncontained within articles. The objective of the ADSASS effort is to extract\nthese data and make them discoverable and available through existing data\nviewers. The resulting ADSASS data layer promises to greatly enhance workflows\nand enable new research by tying astronomical literature and data assets into\none resource."
},{
    "category": "cs.CY", 
    "doi": "10.1016/j.physa.2011.11.021", 
    "link": "http://arxiv.org/pdf/1111.5684v2", 
    "title": "The Disclosure of University Research for Third Parties: A Non-Market   Perspective on an Italian University", 
    "arxiv-id": "1111.5684v2", 
    "author": "Loet Leydesdorff", 
    "publish": "2011-11-24T07:05:29Z", 
    "summary": "Nations, universities, and regional governments commit resources to promote\nthe dissemination of scientific and technical knowledge. One focuses on\nknowledge-based innovations and the economic function of the university in\nterms of technology transfer, intellectual property,\nuniversity-industry-government relations, etc. Faculties other than engineering\nor applied sciences, however, may not be able to recognize opportunities in\nthis \"linear model\" of technology transfer. We elaborate a non-market\nperspective on the third mission in terms of disclosure of the knowledge and\nareas of expertise available for disclosure to other audiences at a provincial\nuniversity. The use of ICT can enhance communication between actors on the\nsupply and demand sides. Using an idea originally developed in the context of\nthe Dutch science shops, the university staff was questionnaired about keywords\nand areas of expertise with the specific purpose of disclosing this information\nto audiences other than academic colleagues. The results were brought online in\na thesaurus-like structure that enables users to access the university at the\nlevel of individual email address. This model stimulates variation on both the\nsupply and demand side of the innovation process, and strengthens the\naccessibility and embeddedness of the knowledge base in a regional economy."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1016/j.joi.2011.09.002", 
    "link": "http://arxiv.org/pdf/1111.6053v1", 
    "title": "Testing the fairness of citation indicators for comparison across   scientific domains: the case of fractional citation counts", 
    "arxiv-id": "1111.6053v1", 
    "author": "Claudio Castellano", 
    "publish": "2011-11-25T17:00:24Z", 
    "summary": "Citation numbers are extensively used for assessing the quality of scientific\nresearch. The use of raw citation counts is generally misleading, especially\nwhen applied to cross-disciplinary comparisons, since the average number of\ncitations received is strongly dependent on the scientific discipline of\nreference of the paper. Measuring and eliminating biases in citation patterns\nis crucial for a fair use of citation numbers. Several numerical indicators\nhave been introduced with this aim, but so far a specific statistical test for\nestimating the fairness of these numerical indicators has not been developed.\nHere we present a statistical method aimed at estimating the effectiveness of\nnumerical indicators in the suppression of citation biases. The method is\nsimple to implement and can be easily generalized to various scenarios. As a\npractical example we test, in a controlled case, the fairness of fractional\ncitation count, which has been recently proposed as a tool for cross-discipline\ncomparison. We show that this indicator is not able to remove biases in\ncitation patterns and performs much worse than the rescaling of citation counts\nwith average values."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1016/j.joi.2011.09.002", 
    "link": "http://arxiv.org/pdf/1111.6465v1", 
    "title": "Astro-WISE Information System", 
    "arxiv-id": "1111.6465v1", 
    "author": "Gijs A. Verdoes Kleijn", 
    "publish": "2011-11-28T15:05:20Z", 
    "summary": "Astro-WISE is a scientific information system for the data processing of\noptical images. In this paper we review main features of Astro-WISE and\ndescribe the current status of the system."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1016/j.joi.2011.09.002", 
    "link": "http://arxiv.org/pdf/1111.6792v1", 
    "title": "Astro-WISE processing of wide-field images and other data", 
    "arxiv-id": "1111.6792v1", 
    "author": "Andrey Belikov", 
    "publish": "2011-11-29T12:31:17Z", 
    "summary": "Astro-WISE is the Astronomical Wide-field Imaging System for Europe. It is a\nscientific information system which consists of hardware and software federated\nover about a dozen institutes throughout Europe. It has been developed to\nexploit the ever increasing avalanche of data produced by astronomical surveys\nand data intensive scientific experiments in general.\n  The demo explains the architecture of the Astro-WISE information system and\nshows the use of Astro-WISE interfaces. Wide-field astronomical images are\nderived from the raw image to the final catalog according to the user's\nrequest. The demo is based on the standard Astro-WISE guided tour, which can be\naccessed from the Astro-WISE website.\n  The typical Astro-WISE data processing chain is shown, which can be used for\ndata handling for a variety of different instruments, currently 14, including\nOmegaCAM, MegaCam, WFI, WFC, ACS/HST, etc."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1016/j.joi.2011.09.002", 
    "link": "http://arxiv.org/pdf/1112.0742v1", 
    "title": "The DAME/VO-Neural Infrastructure: an Integrated Data Mining System   Support for the Science Community", 
    "arxiv-id": "1112.0742v1", 
    "author": "B. Skordovski", 
    "publish": "2011-12-04T10:41:01Z", 
    "summary": "Astronomical data are gathered through a very large number of heterogeneous\ntechniques and stored in very diversified and often incompatible data\nrepositories. Moreover in the e-science environment, it is needed to integrate\nservices across distributed, heterogeneous, dynamic \"virtual organizations\"\nformed by different resources within a single enterprise and/or external\nresource sharing and service provider relationships. The DAME/VONeural project,\nrun jointly by the University Federico II, INAF (National Institute of\nAstrophysics) Astronomical Observatories of Napoli and the California Institute\nof Technology, aims at creating a single, sustainable, distributed\ne-infrastructure for data mining and exploration in massive data sets, to be\noffered to the astronomical (but not only) community as a web application. The\nframework makes use of distributed computing environments (e.g. S.Co.P.E.) and\nmatches the international IVOA standards and requirements. The integration\nprocess is technically challenging due to the need of achieving a specific\nquality of service when running on top of different native platforms. In these\nterms, the result of the DAME/VO-Neural project effort will be a\nservice-oriented architecture, obtained by using appropriate standards and\nincorporating Grid paradigms and restful Web services frameworks where needed,\nthat will have as main target the integration of interdisciplinary distributed\nsystems within and across organizational domains."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1016/j.joi.2011.09.002", 
    "link": "http://arxiv.org/pdf/1112.0750v1", 
    "title": "DAME: A Distributed Data Mining & Exploration Framework within the   Virtual Observatory", 
    "arxiv-id": "1112.0750v1", 
    "author": "G. Longo", 
    "publish": "2011-12-04T13:06:35Z", 
    "summary": "Nowadays, many scientific areas share the same broad requirements of being\nable to deal with massive and distributed datasets while, when possible, being\nintegrated with services and applications. In order to solve the growing gap\nbetween the incremental generation of data and our understanding of it, it is\nrequired to know how to access, retrieve, analyze, mine and integrate data from\ndisparate sources. One of the fundamental aspects of any new generation of data\nmining software tool or package which really wants to become a service for the\ncommunity is the possibility to use it within complex workflows which each user\ncan fine tune in order to match the specific demands of his scientific goal.\nThese workflows need often to access different resources (data, providers,\ncomputing facilities and packages) and require a strict interoperability on (at\nleast) the client side. The project DAME (DAta Mining & Exploration) arises\nfrom these requirements by providing a distributed WEB-based data mining\ninfrastructure specialized on Massive Data Sets exploration with Soft Computing\nmethods. Originally designed to deal with astrophysical use cases, where first\nscientific application examples have demonstrated its effectiveness, the DAME\nSuite results as a multi-disciplinary platform-independent tool perfectly\ncompliant with modern KDD (Knowledge Discovery in Databases) requirements and\nInformation & Communication Technology trends."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1016/j.joi.2011.09.002", 
    "link": "http://arxiv.org/pdf/1112.1688v1", 
    "title": "Why don't we already have an Integrated Framework for the Publication   and Preservation of all Data Products?", 
    "arxiv-id": "1112.1688v1", 
    "author": "Norman Gray", 
    "publish": "2011-12-07T20:58:34Z", 
    "summary": "Astronomy has long had a working network of archives supporting the curation\nof publications and data. The discipline has already created many of the\nfeatures which perplex other areas of science: (1) data repositories:\n(supra)national institutes, dedicated to large projects; a culture of\nuser-contributed data; practical experience of long-term data preservation; (2)\ndataset identifiers: the community has already piloted experiments, knows what\ncan undermine these efforts, and is participating in the development of\nnext-generation standards; (3) citation of datasets in papers: the community\nhas an innovative and expanding infrastructure for the curation of data and\nbibliographic resources, and through them a community of author s and editors\nfamiliar with such electronic publication efforts; as well, it has experimented\nwith next-generation web standards (e.g. the Semantic Web); (4) publisher\nbuy-in: publishers in this area have been willing to innovate within the\nconstraints of their commercial imperatives. What can possibly be missing? Why\ndon't we have an integrated framework for the publication and preservation of\nall data products already? Are there technical barriers? We don't believe so.\nAre there cultural or commercial forces inhibiting this? We aren't aware of\nany. This Birds of a Feather session (BoF) attempted to identify existing\nbarriers to the creation of such a framework, and attempted to identify the\nparties or groups which can contribute to the creation of a VO-powered\ndata-publishing framework."
},{
    "category": "hep-lat", 
    "doi": "10.1016/j.joi.2011.09.002", 
    "link": "http://arxiv.org/pdf/1112.2193v1", 
    "title": "Making QCD Lattice Data Accessible and Organized through Advanced Web   Interfaces", 
    "arxiv-id": "1112.2193v1", 
    "author": "David Skinner", 
    "publish": "2011-12-09T19:47:27Z", 
    "summary": "The Gauge Connection at qcd.nersc.gov is one of the most popular repositories\nof QCD lattice ensembles. It is used to access 16TB of archived QCD data from\nthe High Performance Storage System (HPSS) at the National Energy Research\nScientific Computing Center (NERSC). Here, we present a new web interface for\nqcd.nersc.gov which allows physicists to browse and search the data, as well as\ndownload individual files or entire ensembles in batch. Our system\ndistinguishes itself from others because of its ease of use and web based\nworkflow."
},{
    "category": "cs.DL", 
    "doi": "10.1016/j.joi.2012.08.005", 
    "link": "http://arxiv.org/pdf/1112.2516v2", 
    "title": "Caveats for using statistical significance tests in research assessments", 
    "arxiv-id": "1112.2516v2", 
    "author": "Jesper W. Schneider", 
    "publish": "2011-12-12T11:57:12Z", 
    "summary": "This paper raises concerns about the advantages of using statistical\nsignificance tests in research assessments as has recently been suggested in\nthe debate about proper normalization procedures for citation indicators.\nStatistical significance tests are highly controversial and numerous criticisms\nhave been leveled against their use. Based on examples from articles by\nproponents of the use statistical significance tests in research assessments,\nwe address some of the numerous problems with such tests. The issues\nspecifically discussed are the ritual practice of such tests, their dichotomous\napplication in decision making, the difference between statistical and\nsubstantive significance, the implausibility of most null hypotheses, the\ncrucial assumption of randomness, as well as the utility of standard errors and\nconfidence intervals for inferential purposes. We argue that applying\nstatistical significance tests and mechanically adhering to their results is\nhighly problematic and detrimental to critical thinking. We claim that the use\nof such tests do not provide any advantages in relation to citation indicators,\ninterpretations of them, or the decision making processes based upon them. On\nthe contrary their use may be harmful. Like many other critics, we generally\nbelieve that statistical significance tests are over- and misused in the social\nsciences including scientometrics and we encourage a reform on these matters."
},{
    "category": "physics.geo-ph", 
    "doi": "10.1007/978-94-007-0152-6_10", 
    "link": "http://arxiv.org/pdf/1201.0587v1", 
    "title": "Distributed archive and single access system for accelerometric event   data : a NERIES initiative", 
    "arxiv-id": "1201.0587v1", 
    "author": "Laurent Frobert", 
    "publish": "2012-01-03T07:35:51Z", 
    "summary": "We developed a common access facility to homogeneously formatted\naccelerometric event data and to the corresponding sheet of ground motion\nparameters. This paper is focused on the description of the technical\ndevelopment of the accelerometric data server and the link with the\naccelerometric data explorer. The server is the third node of the 3-tier\narchitecture of the distributed archive system for accelerometric data. The\nserver is the link between the data users and the accelero- metric data portal.\nThe server follows three main steps: (1) Reading and analysis of the end-user\nrequest; (2) Processing and converting data; and (3) Archiving and updating the\naccelerometric data explorer. This paper presents the description of the data\nserver and the data explorer for accessing data."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-94-007-0152-6_10", 
    "link": "http://arxiv.org/pdf/1201.2515v1", 
    "title": "Integrating Interactive Visualizations in the Search Process of Digital   Libraries and IR Systems", 
    "arxiv-id": "1201.2515v1", 
    "author": "Philipp Mayr", 
    "publish": "2012-01-12T10:24:16Z", 
    "summary": "Interactive visualizations for exploring and retrieval have not yet become an\nintegral part of digital libraries and information retrieval systems. We have\nintegrated a set of interactive graphics in a real world social science digital\nlibrary. These visualizations support the exploration of search queries,\nresults and authors, can filter search results, show trends in the database and\ncan support the creation of new search queries. The use of weighted brushing\nsupports the identification of related metadata for search facets. We discuss\nsome use cases of the combination of IR systems and interactive graphics. In a\nuser study we verify that users can gain insights from statistical graphics\nintuitively and can adopt interaction techniques."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-94-007-0152-6_10", 
    "link": "http://arxiv.org/pdf/1201.3900v1", 
    "title": "Elasticity on Ontology Matching of Folksodriven Structure Network", 
    "arxiv-id": "1201.3900v1", 
    "author": "Massimiliano Dal Mas", 
    "publish": "2012-01-18T20:24:35Z", 
    "summary": "Nowadays folksonomy tags are used not just for personal organization, but for\ncommunication and sharing between people sharing their own local interests. In\nthis paper is considered the new concept structure called \"Folksodriven\" to\nrepresent folksonomies. The Folksodriven Structure Network (FSN) was thought as\nfolksonomy tags suggestions for the user on a dataset built on chosen websites\n- based on Natural Language Processing (NLP). Morphological changes, such as\nchanges in folksonomy tags chose have direct impact on network connectivity\n(structural plasticity) of the folksonomy tags considered. The goal of this\npaper is on defining a base for a FSN plasticity theory to analyze. To perform\nsuch goal it is necessary a systematic mathematical analysis on deformation and\nfracture for the ontology matching on the FSN. The advantages of that approach\ncould be used on a new interesting method to be employed by a knowledge\nmanagement system."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-94-007-0152-6_10", 
    "link": "http://arxiv.org/pdf/1201.5102v1", 
    "title": "Conception and Use of Ontologies for Indexing and Searching by Semantic   Contents of Video Courses", 
    "arxiv-id": "1201.5102v1", 
    "author": "Amel Behaz", 
    "publish": "2012-01-24T20:01:43Z", 
    "summary": "Nowadays, the video documents like educational courses available on the web\nincreases significantly. However, the information retrieval systems today can\nnot return to the users (students or teachers) of parts of those videos that\nmeet their exact needs expressed by a query consisting of semantic information.\nIn this paper, we present a model of pedagogical knowledge of current videos.\nThis knowledge is used throughout the process of indexing and semantic search\nsegments instructional videos. Our experimental results show that the proposed\napproach is promising."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-94-007-0152-6_10", 
    "link": "http://arxiv.org/pdf/1201.6179v2", 
    "title": "Decomposition of the h-index", 
    "arxiv-id": "1201.6179v2", 
    "author": "Francesco Bartolucci", 
    "publish": "2012-01-30T11:36:39Z", 
    "summary": "I introduce a decomposition of the h-index, which is nowadays the leading\ncriterion to assess the relevance of a scientist in his/her research field.\nAccording to the proposed decomposition, the h-index is the product of two\nindicators, the first of which measures the impact of the scientist on the\nresearch community and the second may be seen as a measure of concentration of\nthe citations in correspondence of a reduced number of papers. The\ndecomposition is illustrated by an application based on data concerning a group\nof top level economists."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-94-007-0152-6_10", 
    "link": "http://arxiv.org/pdf/1202.0984v1", 
    "title": "OWL: Yet to arrive on the Web of Data?", 
    "arxiv-id": "1202.0984v1", 
    "author": "Axel Polleres", 
    "publish": "2012-02-01T17:51:00Z", 
    "summary": "Seven years on from OWL becoming a W3C recommendation, and two years on from\nthe more recent OWL 2 W3C recommendation, OWL has still experienced only patchy\nuptake on the Web. Although certain OWL features (like owl:sameAs) are very\npopular, other features of OWL are largely neglected by publishers in the\nLinked Data world. This may suggest that despite the promise of easy\nimplementations and the proposal of tractable profiles suggested in OWL's\nsecond version, there is still no \"right\" standard fragment for the Linked Data\ncommunity. In this paper, we (1) analyse uptake of OWL on the Web of Data, (2)\ngain insights into the OWL fragment that is actually used/usable on the Web,\nwhere we arrive at the conclusion that this fragment is likely to be a\nsimplified profile based on OWL RL, (3) propose and discuss such a new\nfragment, which we call OWL LD (for Linked Data)."
},{
    "category": "cs.DL", 
    "doi": "10.1007/978-94-007-0152-6_10", 
    "link": "http://arxiv.org/pdf/1202.1914v3", 
    "title": "Global Maps of Science based on the new Web-of-Science Categories", 
    "arxiv-id": "1202.1914v3", 
    "author": "Ismael Rafols", 
    "publish": "2012-02-09T08:55:33Z", 
    "summary": "In August 2011, Thomson Reuters launched version 5 of the Science and Social\nScience Citation Index in the Web of Science (WoS). Among other things, the 222\nISI Subject Categories (SCs) for these two databases in version 4 of WoS were\nrenamed and extended to 225 WoS Categories (WCs). A new set of 151 Subject\nCategories (SCs) was added, but at a higher level of aggregation. Since we\npreviously used the ISI SCs as the baseline for a global map in Pajek (Rafols\net al., 2010) and brought this facility online (at\nhttp://www.leydesdorff.net/overlaytoolkit), we recalibrated this map for the\nnew WC categories using the Journal Citation Reports 2010. In the new\ninstallation, the base maps can also be made using VOSviewer (Van Eck &\nWaltman, 2010)."
},{
    "category": "cs.SE", 
    "doi": "10.1007/978-94-007-0152-6_10", 
    "link": "http://arxiv.org/pdf/1202.2131v1", 
    "title": "Temporal Analysis of Literary and Programming Prose", 
    "arxiv-id": "1202.2131v1", 
    "author": "Tsz-Yam Lau", 
    "publish": "2012-02-09T21:11:55Z", 
    "summary": "Literary works reference a variety of globally shared themes including\nwell-known people, events, and time periods. It is particularly interesting to\nlocate patterns that are either invariant across time or exhibit a\ncharacteristic change across time, as they could imply something important\nabout society that those works record. This paper suggests the use of Google\nn-gram viewer as a fast prototyping method for examining time-based properties\nover a rich sample of literary prose. Using this method, we find that some\nrepeating periods of time, like Sunday, are referenced disproportionally,\nallowing us to pose questions such as why a day like Thursday is so unpopular.\nFurthermore, by treating software as a work of prose, we can apply a similar\nanalysis to open-source software repositories and explore time-based relations\nin commit logs. Doing a simple statistical analysis on a few temporal keywords\nin the log records, we reinforce and weaken a few beliefs on how college\nstudents approach open source software. Finally, we help readers working on\ntheir own temporal analysis by comparing the fundamental differences between\nliterary works and code repositories, and suggest blog or wiki as\nrecently-emerging works."
},{
    "category": "q-bio.QM", 
    "doi": "10.1038/npre.2008.2083.1", 
    "link": "http://arxiv.org/pdf/1202.3952v1", 
    "title": "Check Your Data Freedom: A Taxonomy to Assess Life Science Database   Openness", 
    "arxiv-id": "1202.3952v1", 
    "author": "Melanie Dulong De Rosnay", 
    "publish": "2012-02-17T16:26:09Z", 
    "summary": "Molecular biology data are subject to terms of use that vary widely between\ndatabases and curating institutions. This research presents a taxonomy of\ncontractual and technical restrictions applicable to databases in life science.\nIt builds upon research led by Science Commons demonstrating why open data and\nthe freedom to integrate facilitate innovation and how this openness can be\nachieved. The taxonomy describes technical and legal restrictions applicable to\nlife science databases, and its metadata have been used to assess terms of use\nof databases hosted by Life Science Resource Name (LSRN) Schema. While a few\npublic domain policies are standardized, most terms of use are not harmonized,\ndifficult to understand and impose controls that prevent others from\neffectively reusing data. Identifying a small number of restrictions allows one\nto quickly appreciate which databases are open. A checklist for data openness\nis proposed in order to assist database curators who wish to make their data\nmore open to make sure they do so."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1071/AS12011", 
    "link": "http://arxiv.org/pdf/1202.4051v4", 
    "title": "Citations to Australian Astronomy: 5 and 10 Year Benchmarks", 
    "arxiv-id": "1202.4051v4", 
    "author": "Alister W. Graham", 
    "publish": "2012-02-18T02:30:21Z", 
    "summary": "Expanding upon Pimbblet's informative 2011 analysis of career h-indices for\nmembers of the Astronomical Society of Australia, we provide additional\ncitation metrics which are geared to a) quantifying the current performance of\nb) all professional astronomers in Australia. We have trawled the staff\nweb-pages of Australian Universities, Observatories and Research Organisations\nhosting professional astronomers, and identified 383 PhD-qualified,\nresearch-active, astronomers in the nation - 131 of these are not members of\nthe Astronomical Society of Australia. Using the SAO/NASA Astrophysics Data\nSystem, we provide the three following common metrics based on publications in\nthe first decade of the 21st century (2001-2010): h-index, author-normalised\ncitation count and lead-author citation count. We additionally present a\nsomewhat more inclusive analysis, applicable for many early-career researchers,\nthat is based on publications from 2006-2010. Histograms and percentiles, plus\ntop-performer lists, are presented for each category. Finally, building on\nHirsch's empirical equation, we find that the (10-year) h-index and (10-year)\ntotal citation count T can be approximated by the relation h =\n(0.5+sqrt{T})/sqrt{5} for h > 5."
},{
    "category": "cs.DL", 
    "doi": "10.1071/AS12011", 
    "link": "http://arxiv.org/pdf/1202.4185v1", 
    "title": "When Should I Make Preservation Copies of Myself?", 
    "arxiv-id": "1202.4185v1", 
    "author": "Michael L. Nelson", 
    "publish": "2012-02-19T21:03:33Z", 
    "summary": "We investigate how different preservation policies ranging from least\naggressive to Most aggressive affect the level of preservation achieved by\nautonomic processes used by smart digital objects (DOs). The mechanisms used to\nsupport preservation across different hosts can be used for automatic link\ngeneration and support preservation activities by moving data preservation from\nan archive centric perspective to a data centric preservation. Based on\nsimulations of small-world graphs of DOs created using the Unsupervised\nSmall-World algorithm, we report quantitative and qualitative results for\ngraphs ranging in size from 10 to 5000 DOs. Our results show that a Most\naggressive preservation policy makes the best use of distributed host resources\nwhile using one half of the number of messages of a Moderately aggressive\npreservation policy."
},{
    "category": "cs.DL", 
    "doi": "10.1071/AS12011", 
    "link": "http://arxiv.org/pdf/1202.4646v1", 
    "title": "Publication Trends in Astronomy: The Lone Author", 
    "arxiv-id": "1202.4646v1", 
    "author": "Edwin A. Henneken", 
    "publish": "2012-02-21T14:27:54Z", 
    "summary": "In this short communication I highlight how the number of collaborators on\npapers in the main astronomy journals has evolved over time. We see a trend of\nmoving away from single-author papers. This communication is based on data in\nthe holdings of the SAO/NASA Astrophysics Data System (ADS).\n  The ADS is funded by NASA Grant NNX09AB39G."
},{
    "category": "cs.DL", 
    "doi": "10.1071/AS12011", 
    "link": "http://arxiv.org/pdf/1202.5477v1", 
    "title": "Analyzing Tag Distributions in Folksonomies for Resource Classification", 
    "arxiv-id": "1202.5477v1", 
    "author": "V\u00edctor Fresno", 
    "publish": "2012-02-23T18:36:06Z", 
    "summary": "Recent research has shown the usefulness of social tags as a data source to\nfeed resource classification. Little is known about the effect of settings on\nfolksonomies created on social tagging systems. In this work, we consider the\nsettings of social tagging systems to further understand tag distributions in\nfolksonomies. We analyze in depth the tag distributions on three large-scale\nsocial tagging datasets, and analyze the effect on a resource classification\ntask. To this end, we study the appropriateness of applying weighting schemes\nbased on the well-known TF-IDF for resource classification. We show the great\nimportance of settings as to altering tag distributions. Among those settings,\ntag suggestions produce very different folksonomies, which condition the\nsuccess of the employed weighting schemes. Our findings and analyses are\nrelevant for researchers studying tag-based resource classification, user\nbehavior in social networks, the structure of folksonomies and tag\ndistributions, as well as for developers of social tagging systems in search of\nan appropriate setting."
},{
    "category": "cs.DL", 
    "doi": "10.1071/AS12011", 
    "link": "http://arxiv.org/pdf/1202.6235v2", 
    "title": "Innovation as a Nonlinear Process, the Scientometric Perspective, and   the Specification of an \"Innovation Opportunities Explorer\"", 
    "arxiv-id": "1202.6235v2", 
    "author": "Wouter de Nooy", 
    "publish": "2012-02-28T14:20:07Z", 
    "summary": "The process of innovation follows non-linear patterns across the domains of\nscience, technology, and the economy. Novel bibliometric mapping techniques can\nbe used to investigate and represent distinctive, but complementary\nperspectives on the innovation process (e.g., \"demand\" and \"supply\") as well as\nthe interactions among these perspectives. The perspectives can be represented\nas \"continents\" of data related to varying extents over time. For example, the\ndifferent branches of Medical Subject Headings (MeSH) in the Medline database\nprovide sources of such perspectives (e.g., \"Diseases\" versus \"Drugs and\nChemicals\"). The multiple-perspective approach enables us to reconstruct facets\nof the dynamics of innovation, in terms of selection mechanisms shaping\nlocalizable trajectories and/or resulting in more globalized regimes. By\nexpanding the data with patents and scholarly publications, we demonstrate the\nuse of this multi-perspective approach in the case of RNA Interference (RNAi).\nThe possibility to develop an \"Innovation Opportunities Explorer\" is specified."
},{
    "category": "cs.IR", 
    "doi": "10.1071/AS12011", 
    "link": "http://arxiv.org/pdf/1203.4494v1", 
    "title": "Can an Ad-hoc ontology Beat a Medical Search Engine? The Chronious   Search Engine case", 
    "arxiv-id": "1203.4494v1", 
    "author": "Roberto Rosso", 
    "publish": "2012-03-20T16:28:54Z", 
    "summary": "Chronious is an Open, Ubiquitous and Adaptive Chronic Disease Management\nPlatform for Chronic Obstructive Pulmonary Disease(COPD) Chronic Kidney Disease\n(CKD) and Renal Insufficiency. It consists of several modules: an ontology\nbased literature search engine, a rule based decision support system, remote\nsensors interacting with lifestyle interfaces (PDA, monitor touch-screen) and a\nmachine learning module. All these modules interact each other to allow the\nmonitoring of two types of chronic diseases and to help clinician in taking\ndecision for care purpose. This paper illustrates how the ontology search\nengine was created and fed and how some comparative test indicated that the\nontology based approach give better results, on some estimation parameters,\nthan the main reference web search engine."
},{
    "category": "cs.IR", 
    "doi": "10.1071/AS12011", 
    "link": "http://arxiv.org/pdf/1203.5324v1", 
    "title": "Improving an Hybrid Literary Book Recommendation System through Author   Ranking", 
    "arxiv-id": "1203.5324v1", 
    "author": "Pavel Calado", 
    "publish": "2012-03-23T19:28:25Z", 
    "summary": "Literary reading is an important activity for individuals and choosing to\nread a book can be a long time commitment, making book choice an important task\nfor book lovers and public library users. In this paper we present an hybrid\nrecommendation system to help readers decide which book to read next. We study\nbook and author recommendation in an hybrid recommendation setting and test our\napproach in the LitRec data set. Our hybrid book recommendation approach\npurposed combines two item-based collaborative filtering algorithms to predict\nbooks and authors that the user will like. Author predictions are expanded in\nto a book list that is subsequently aggregated with the former list generated\nthrough the initial collaborative recommender. Finally, the resulting book list\nis used to yield the top-n book recommendations. By means of various\nexperiments, we demonstrate that author recommendation can improve overall book\nrecommendation."
},lol]