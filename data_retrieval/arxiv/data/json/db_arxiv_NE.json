[{
    "category": "cs.NE", 
    "doi": "10.1145/2140522.2140525", 
    "link": "http://arxiv.org/pdf/cs/9809049v1", 
    "other_authors": "Peter J Bentley", 
    "title": "Aspects of Evolutionary Design by Computers", 
    "arxiv-id": "cs/9809049v1", 
    "author": "Peter J Bentley", 
    "publish": "1998-09-23T11:01:55Z", 
    "summary": "This paper examines the four main types of Evolutionary Design by computers:\nEvolutionary Design Optimisation, Evolutionary Art, Evolutionary Artificial\nLife Forms and Creative Evolutionary Design. Definitions for all four areas are\nprovided. A review of current work in each of these areas is given, with\nexamples of the types of applications that have been tackled. The different\nproperties and requirements of each are examined. Descriptions of typical\nrepresentations and evolutionary algorithms are provided and examples of\ndesigns evolved using these techniques are shown. The paper then discusses how\nthe boundaries of these areas are beginning to merge, resulting in four new\n'overlapping' types of Evolutionary Design: Integral Evolutionary Design,\nArtificial Life Based Evolutionary Design, Aesthetic Evolutionary AL and\nAesthetic Evolutionary Design. Finally, the last part of the paper discusses\nsome common problems faced by creators of Evolutionary Design systems,\nincluding: interdependent elements in designs, epistasis, and constraint\nhandling."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2140522.2140525", 
    "link": "http://arxiv.org/pdf/cs/9812002v1", 
    "other_authors": "A. Likas, I. E. Lagaris", 
    "title": "Training Reinforcement Neurocontrollers Using the Polytope Algorithm", 
    "arxiv-id": "cs/9812002v1", 
    "author": "I. E. Lagaris", 
    "publish": "1998-12-03T09:08:03Z", 
    "summary": "A new training algorithm is presented for delayed reinforcement learning\nproblems that does not assume the existence of a critic model and employs the\npolytope optimization algorithm to adjust the weights of the action network so\nthat a simple direct measure of the training performance is maximized.\nExperimental results from the application of the method to the pole balancing\nproblem indicate improved training performance compared with critic-based and\ngenetic reinforcement approaches."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2140522.2140525", 
    "link": "http://arxiv.org/pdf/cs/9902025v1", 
    "other_authors": "Mattias Ohlsson, Carsten Peterson, Bo S\u00f6derberg", 
    "title": "An Efficient Mean Field Approach to the Set Covering Problem", 
    "arxiv-id": "cs/9902025v1", 
    "author": "Bo S\u00f6derberg", 
    "publish": "1999-02-12T09:18:53Z", 
    "summary": "A mean field feedback artificial neural network algorithm is developed and\nexplored for the set covering problem. A convenient encoding of the inequality\nconstraints is achieved by means of a multilinear penalty function. An\napproximate energy minimum is obtained by iterating a set of mean field\nequations, in combination with annealing. The approach is numerically tested\nagainst a set of publicly available test problems with sizes ranging up to\n5x10^3 rows and 10^6 columns. When comparing the performance with exact results\nfor sizes where these are available, the approach yields results within a few\npercent from the optimal solutions. Comparisons with other approximate methods\nalso come out well, in particular given the very low CPU consumption required\n-- typically a few seconds. Arbitrary problems can be processed using the\nalgorithm via a public domain server."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2140522.2140525", 
    "link": "http://arxiv.org/pdf/cs/0110021v1", 
    "other_authors": "Mikhail S. Burtsev, Vladimir G. Redko, Roman V. Gusarev", 
    "title": "Alife Model of Evolutionary Emergence of Purposeful Adaptive Behavior", 
    "arxiv-id": "cs/0110021v1", 
    "author": "Roman V. Gusarev", 
    "publish": "2001-10-08T11:34:34Z", 
    "summary": "The process of evolutionary emergence of purposeful adaptive behavior is\ninvestigated by means of computer simulations. The model proposed implies that\nthere is an evolving population of simple agents, which have two natural needs:\nenergy and reproduction. Any need is characterized quantitatively by a\ncorresponding motivation. Motivations determine goal-directed behavior of\nagents. The model demonstrates that purposeful behavior does emerge in the\nsimulated evolutionary processes. Emergence of purposefulness is accompanied by\norigin of a simple hierarchy in the control system of agents."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2140522.2140525", 
    "link": "http://arxiv.org/pdf/cs/0201024v1", 
    "other_authors": "Aristides T. Hatjimihail, Theophanes T. Hatjimihail", 
    "title": "Design of statistical quality control procedures using genetic   algorithms", 
    "arxiv-id": "cs/0201024v1", 
    "author": "Theophanes T. Hatjimihail", 
    "publish": "2002-01-27T21:01:45Z", 
    "summary": "In general, we can not use algebraic or enumerative methods to optimize a\nquality control (QC) procedure so as to detect the critical random and\nsystematic analytical errors with stated probabilities, while the probability\nfor false rejection is minimum. Genetic algorithms (GAs) offer an alternative,\nas they do not require knowledge of the objective function to be optimized and\nsearch through large parameter spaces quickly. To explore the application of\nGAs in statistical QC, we have developed an interactive GAs based computer\nprogram that designs a novel near optimal QC procedure, given an analytical\nprocess. The program uses the deterministic crowding algorithm. An illustrative\napplication of the program suggests that it has the potential to design QC\nprocedures that are significantly better than 45 alternative ones that are used\nin the clinical laboratories."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2140522.2140525", 
    "link": "http://arxiv.org/pdf/cs/0210012v1", 
    "other_authors": "Igor B. Konovalov", 
    "title": "Selection of future events from a time series in relation to estimations   of forecasting uncertainty", 
    "arxiv-id": "cs/0210012v1", 
    "author": "Igor B. Konovalov", 
    "publish": "2002-10-14T09:00:23Z", 
    "summary": "A new general procedure for a priori selection of more predictable events\nfrom a time series of observed variable is proposed. The procedure is\napplicable to time series which contains different types of events that feature\nsignificantly different predictability, or, in other words, to heteroskedastic\ntime series. A priori selection of future events in accordance to expected\nuncertainty of their forecasts may be helpful for making practical decisions.\nThe procedure first implies creation of two neural network based forecasting\nmodels, one of which is aimed at prediction of conditional mean and other -\nconditional dispersion, and then elaboration of the rule for future event\nselection into groups of more and less predictable events. The method is\ndemonstrated and tested by the example of the computer generated time series,\nand then applied to the real world time series, Dow Jones Industrial Average\nindex."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2140522.2140525", 
    "link": "http://arxiv.org/pdf/cs/0212019v1", 
    "other_authors": "Joerg D. Becker", 
    "title": "Thinking, Learning, and Autonomous Problem Solving", 
    "arxiv-id": "cs/0212019v1", 
    "author": "Joerg D. Becker", 
    "publish": "2002-12-10T15:18:33Z", 
    "summary": "Ever increasing computational power will require methods for automatic\nprogramming. We present an alternative to genetic programming, based on a\ngeneral model of thinking and learning. The advantage is that evolution takes\nplace in the space of constructs and can thus exploit the mathematical\nstructures of this space. The model is formalized, and a macro language is\npresented which allows for a formal yet intuitive description of the problem\nunder consideration. A prototype has been developed to implement the scheme in\nPERL. This method will lead to a concentration on the analysis of problems, to\na more rapid prototyping, to the treatment of new problem classes, and to the\ninvestigation of philosophical problems. We see fields of application in\nnonlinear differential equations, pattern recognition, robotics, model\nbuilding, and animated pictures."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2140522.2140525", 
    "link": "http://arxiv.org/pdf/cs/0302002v1", 
    "other_authors": "Matthew Pratola, Thomas Wolf", 
    "title": "Optimizing GoTools' Search Heuristics using Genetic Algorithms", 
    "arxiv-id": "cs/0302002v1", 
    "author": "Thomas Wolf", 
    "publish": "2003-02-02T03:30:52Z", 
    "summary": "GoTools is a program which solves life & death problems in the game of Go.\nThis paper describes experiments using a Genetic Algorithm to optimize\nheuristic weights used by GoTools' tree-search. The complete set of heuristic\nweights is composed of different subgroups, each of which can be optimized with\na suitable fitness function. As a useful side product, an MPI interface for\nFreePascal was implemented to allow the use of a parallelized fitness function\nrunning on a Beowulf cluster. The aim of this exercise is to optimize the\ncurrent version of GoTools, and to make tools available in preparation of an\nextension of GoTools for solving open boundary life & death problems, which\nwill introduce more heuristic parameters to be fine tuned."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2140522.2140525", 
    "link": "http://arxiv.org/pdf/cs/0306125v1", 
    "other_authors": "R. C. Gupta, Ankur Agarwal, Ruchi Gupta, Sanjay Gupta", 
    "title": "Predicting Response-Function Results of Electrical/Mechanical Systems   Through Artificial Neural Network", 
    "arxiv-id": "cs/0306125v1", 
    "author": "Sanjay Gupta", 
    "publish": "2003-06-24T06:28:12Z", 
    "summary": "In the present paper a newer application of Artificial Neural Network (ANN)\nhas been developed i.e., predicting response-function results of\nelectrical-mechanical system through ANN. This method is specially useful to\ncomplex systems for which it is not possible to find the response-function\nbecause of complexity of the system. The proposed approach suggests that how\neven without knowing the response-function, the response-function results can\nbe predicted with the use of ANN to the system. The steps used are: (i)\nDepending on the system, the ANN-architecture and the input & output parameters\nare decided, (ii) Training & test data are generated from simplified circuits\nand through tactic-superposition of it for complex circuits, (iii) Training the\nANN with training data through many cycles and (iv) Test-data are used for\npredicting the response-function results. It is found that the proposed novel\nmethod for response prediction works satisfactorily. Thus this method could be\nused specially for complex systems where other methods are unable to tackle it.\nIn this paper the application of ANN is particularly demonstrated to\nelectrical-circuit system but can be applied to other systems too."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s10878-004-4835-9", 
    "link": "http://arxiv.org/pdf/cs/0309038v1", 
    "other_authors": "V. C. Barbosa, L. C. D. Campos", 
    "title": "A novel evolutionary formulation of the maximum independent set problem", 
    "arxiv-id": "cs/0309038v1", 
    "author": "L. C. D. Campos", 
    "publish": "2003-09-22T13:05:51Z", 
    "summary": "We introduce a novel evolutionary formulation of the problem of finding a\nmaximum independent set of a graph. The new formulation is based on the\nrelationship that exists between a graph's independence number and its acyclic\norientations. It views such orientations as individuals and evolves them with\nthe aid of evolutionary operators that are very heavily based on the structure\nof the graph and its acyclic orientations. The resulting heuristic has been\ntested on some of the Second DIMACS Implementation Challenge benchmark graphs,\nand has been found to be competitive when compared to several of the other\nheuristics that have also been tested on those graphs."
},{
    "category": "cs.NE", 
    "doi": "10.1023/B:JOCO.0000021937.26468.b2", 
    "link": "http://arxiv.org/pdf/cs/0309039v1", 
    "other_authors": "V. C. Barbosa, C. A. G. Assis, J. O. do Nascimento", 
    "title": "Two novel evolutionary formulations of the graph coloring problem", 
    "arxiv-id": "cs/0309039v1", 
    "author": "J. O. do Nascimento", 
    "publish": "2003-09-23T00:53:20Z", 
    "summary": "We introduce two novel evolutionary formulations of the problem of coloring\nthe nodes of a graph. The first formulation is based on the relationship that\nexists between a graph's chromatic number and its acyclic orientations. It\nviews such orientations as individuals and evolves them with the aid of\nevolutionary operators that are very heavily based on the structure of the\ngraph and its acyclic orientations. The second formulation, unlike the first\none, does not tackle one graph at a time, but rather aims at evolving a\n`program' to color all graphs belonging to a class whose members all have the\nsame number of nodes and other common attributes. The heuristics that result\nfrom these formulations have been tested on some of the Second DIMACS\nImplementation Challenge benchmark graphs, and have been found to be\ncompetitive when compared to the several other heuristics that have also been\ntested on those graphs."
},{
    "category": "cs.NE", 
    "doi": "10.1023/B:JOCO.0000021937.26468.b2", 
    "link": "http://arxiv.org/pdf/cs/0310009v3", 
    "other_authors": "Artur Rataj", 
    "title": "On Interference of Signals and Generalization in Feedforward Neural   Networks", 
    "arxiv-id": "cs/0310009v3", 
    "author": "Artur Rataj", 
    "publish": "2003-10-06T15:40:44Z", 
    "summary": "This paper studies how the generalization ability of neurons can be affected\nby mutual processing of different signals. This study is done on the basis of a\nfeedforward artificial neural network. The mutual processing of signals can\npossibly be a good model of patterns in a set generalized by a neural network\nand in effect may improve generalization. In this paper it is discussed that\nthe interference may also cause a highly random generalization. Adaptive\nactivation functions are discussed as a way of reducing that type of\ngeneralization. A test of a feedforward neural network is performed that shows\nthe discussed random generalization."
},{
    "category": "cs.NE", 
    "doi": "10.1023/B:JOCO.0000021937.26468.b2", 
    "link": "http://arxiv.org/pdf/cs/0310050v4", 
    "other_authors": "Artur Rataj", 
    "title": "Feedforward Neural Networks with Diffused Nonlinear Weight Functions", 
    "arxiv-id": "cs/0310050v4", 
    "author": "Artur Rataj", 
    "publish": "2003-10-27T14:27:14Z", 
    "summary": "In this paper, feedforward neural networks are presented that have nonlinear\nweight functions based on look--up tables, that are specially smoothed in a\nregularization called the diffusion. The idea of such a type of networks is\nbased on the hypothesis that the greater number of adaptive parameters per a\nweight function might reduce the total number of the weight functions needed to\nsolve a given problem. Then, if the computational complexity of a propagation\nthrough a single such a weight function would be kept low, then the introduced\nneural networks might possibly be relatively fast.\n  A number of tests is performed, showing that the presented neural networks\nmay indeed perform better in some cases than the classic neural networks and a\nnumber of other learning machines."
},{
    "category": "cs.NE", 
    "doi": "10.1023/B:JOCO.0000021937.26468.b2", 
    "link": "http://arxiv.org/pdf/cs/0312047v1", 
    "other_authors": "Juan-J. Merelo-Guervos, Beatriz Prieto, Fatima Rateb, Fernando Tricas", 
    "title": "Mapping weblog communities", 
    "arxiv-id": "cs/0312047v1", 
    "author": "Fernando Tricas", 
    "publish": "2003-12-20T08:55:48Z", 
    "summary": "Websites of a particular class form increasingly complex networks, and new\ntools are needed to map and understand them. A way of visualizing this complex\nnetwork is by mapping it. A map highlights which members of the community have\nsimilar interests, and reveals the underlying social network. In this paper, we\nwill map a network of websites using Kohonen's self-organizing map (SOM), a\nneural-net like method generally used for clustering and visualization of\ncomplex data sets. The set of websites considered has been the Blogalia weblog\nhosting site (based at http://www.blogalia.com/), a thriving community of\naround 200 members, created in January 2002. In this paper we show how SOM\ndiscovers interesting community features, its relation with other\ncommunity-discovering algorithms, and the way it highlights the set of\ncommunities formed over the network."
},{
    "category": "cs.NE", 
    "doi": "10.1023/B:JOCO.0000021937.26468.b2", 
    "link": "http://arxiv.org/pdf/cs/0402047v1", 
    "other_authors": "Claudio F. Lima, Fernando G. Lobo", 
    "title": "Parameter-less Optimization with the Extended Compact Genetic Algorithm   and Iterated Local Search", 
    "arxiv-id": "cs/0402047v1", 
    "author": "Fernando G. Lobo", 
    "publish": "2004-02-19T19:37:32Z", 
    "summary": "This paper presents a parameter-less optimization framework that uses the\nextended compact genetic algorithm (ECGA) and iterated local search (ILS), but\nis not restricted to these algorithms. The presented optimization algorithm\n(ILS+ECGA) comes as an extension of the parameter-less genetic algorithm (GA),\nwhere the parameters of a selecto-recombinative GA are eliminated. The approach\nthat we propose is tested on several well known problems. In the absence of\ndomain knowledge, it is shown that ILS+ECGA is a robust and easy-to-use\noptimization method."
},{
    "category": "cs.NE", 
    "doi": "10.1023/B:JOCO.0000021937.26468.b2", 
    "link": "http://arxiv.org/pdf/cs/0402049v1", 
    "other_authors": "Fernando G. Lobo, Claudio F. Lima, Hugo Martires", 
    "title": "An architecture for massive parallelization of the compact genetic   algorithm", 
    "arxiv-id": "cs/0402049v1", 
    "author": "Hugo Martires", 
    "publish": "2004-02-20T16:36:20Z", 
    "summary": "This paper presents an architecture which is suitable for a massive\nparallelization of the compact genetic algorithm. The resulting scheme has\nthree major advantages. First, it has low synchronization costs. Second, it is\nfault tolerant, and third, it is scalable.\n  The paper argues that the benefits that can be obtained with the proposed\napproach is potentially higher than those obtained with traditional parallel\ngenetic algorithms. In addition, the ideas suggested in the paper may also be\nrelevant towards parallelizing more complex probabilistic model building\ngenetic algorithms."
},{
    "category": "cs.NE", 
    "doi": "10.1023/B:JOCO.0000021937.26468.b2", 
    "link": "http://arxiv.org/pdf/cs/0402050v1", 
    "other_authors": "Fernando G. Lobo", 
    "title": "A philosophical essay on life and its connections with genetic   algorithms", 
    "arxiv-id": "cs/0402050v1", 
    "author": "Fernando G. Lobo", 
    "publish": "2004-02-20T16:52:11Z", 
    "summary": "This paper makes a number of connections between life and various facets of\ngenetic and evolutionary algorithms research. Specifically, it addresses the\ntopics of adaptation, multiobjective optimization, decision making, deception,\nand search operators, among others. It argues that human life, from birth to\ndeath, is an adaptive or dynamic optimization problem where people are\ncontinuously searching for happiness. More important, the paper speculates that\ngenetic algorithms can be used as a source of inspiration for helping people\nmake decisions in their everyday life."
},{
    "category": "cs.NE", 
    "doi": "10.1023/B:JOCO.0000021937.26468.b2", 
    "link": "http://arxiv.org/pdf/cs/0403003v1", 
    "other_authors": "Gilson A. Giraldi, Renato Portugal, Ricardo N. Thess", 
    "title": "Genetic Algorithms and Quantum Computation", 
    "arxiv-id": "cs/0403003v1", 
    "author": "Ricardo N. Thess", 
    "publish": "2004-03-04T19:24:10Z", 
    "summary": "Recently, researchers have applied genetic algorithms (GAs) to address some\nproblems in quantum computation. Also, there has been some works in the\ndesigning of genetic algorithms based on quantum theoretical concepts and\ntechniques. The so called Quantum Evolutionary Programming has two major\nsub-areas: Quantum Inspired Genetic Algorithms (QIGAs) and Quantum Genetic\nAlgorithms (QGAs). The former adopts qubit chromosomes as representations and\nemploys quantum gates for the search of the best solution. The later tries to\nsolve a key question in this field: what GAs will look like as an\nimplementation on quantum hardware? As we shall see, there is not a complete\nanswer for this question. An important point for QGAs is to build a quantum\nalgorithm that takes advantage of both the GA and quantum computing parallelism\nas well as true randomness provided by quantum computers. In the first part of\nthis paper we present a survey of the main works in GAs plus quantum computing\nincluding also our works in this area. Henceforth, we review some basic\nconcepts in quantum computation and GAs and emphasize their inherent\nparallelism. Next, we review the application of GAs for learning quantum\noperators and circuit design. Then, quantum evolutionary programming is\nconsidered. Finally, we present our current research in this field and some\nperspectives."
},{
    "category": "cs.NE", 
    "doi": "10.1023/B:JOCO.0000021937.26468.b2", 
    "link": "http://arxiv.org/pdf/cs/0405062v1", 
    "other_authors": "Kumara Sastry, David E. Goldberg, Martin Pelikan", 
    "title": "Efficiency Enhancement of Probabilistic Model Building Genetic   Algorithms", 
    "arxiv-id": "cs/0405062v1", 
    "author": "Martin Pelikan", 
    "publish": "2004-05-18T16:19:59Z", 
    "summary": "This paper presents two different efficiency-enhancement techniques for\nprobabilistic model building genetic algorithms. The first technique proposes\nthe use of a mutation operator which performs local search in the sub-solution\nneighborhood identified through the probabilistic model. The second technique\nproposes building and using an internal probabilistic model of the fitness\nalong with the probabilistic model of variable interactions. The fitness values\nof some offspring are estimated using the probabilistic model, thereby avoiding\ncomputationally expensive function evaluations. The scalability of the\naforementioned techniques are analyzed using facetwise models for convergence\ntime and population sizing. The speed-up obtained by each of the methods is\npredicted and verified with empirical results. The results show that for\nadditively separable problems the competent mutation operator requires O(k 0.5\nlogm)--where k is the building-block size, and m is the number of building\nblocks--less function evaluations than its selectorecombinative counterpart.\nThe results also show that the use of an internal probabilistic fitness model\nreduces the required number of function evaluations to as low as 1-10% and\nyields a speed-up of 2--50."
},{
    "category": "cs.NE", 
    "doi": "10.1023/B:JOCO.0000021937.26468.b2", 
    "link": "http://arxiv.org/pdf/cs/0405063v1", 
    "other_authors": "Kumara Sastry, David E. Goldberg", 
    "title": "Let's Get Ready to Rumble: Crossover Versus Mutation Head to Head", 
    "arxiv-id": "cs/0405063v1", 
    "author": "David E. Goldberg", 
    "publish": "2004-05-18T16:31:56Z", 
    "summary": "This paper analyzes the relative advantages between crossover and mutation on\na class of deterministic and stochastic additively separable problems. This\nstudy assumes that the recombination and mutation operators have the knowledge\nof the building blocks (BBs) and effectively exchange or search among competing\nBBs. Facetwise models of convergence time and population sizing have been used\nto determine the scalability of each algorithm. The analysis shows that for\nadditively separable deterministic problems, the BB-wise mutation is more\nefficient than crossover, while the crossover outperforms the mutation on\nadditively separable problems perturbed with additive Gaussian noise. The\nresults show that the speed-up of using BB-wise mutation on deterministic\nproblems is O(k^{0.5}logm), where k is the BB size, and m is the number of BBs.\nLikewise, the speed-up of using crossover on stochastic problems with fixed\nnoise variance is O(mk^{0.5}log m)."
},{
    "category": "cs.NE", 
    "doi": "10.1023/B:JOCO.0000021937.26468.b2", 
    "link": "http://arxiv.org/pdf/cs/0405064v1", 
    "other_authors": "Kumara Sastry, David E. Goldberg", 
    "title": "Designing Competent Mutation Operators via Probabilistic Model Building   of Neighborhoods", 
    "arxiv-id": "cs/0405064v1", 
    "author": "David E. Goldberg", 
    "publish": "2004-05-18T16:41:34Z", 
    "summary": "This paper presents a competent selectomutative genetic algorithm (GA), that\nadapts linkage and solves hard problems quickly, reliably, and accurately. A\nprobabilistic model building process is used to automatically identify key\nbuilding blocks (BBs) of the search problem. The mutation operator uses the\nprobabilistic model of linkage groups to find the best among competing building\nblocks. The competent selectomutative GA successfully solves additively\nseparable problems of bounded difficulty, requiring only subquadratic number of\nfunction evaluations. The results show that for additively separable problems\nthe probabilistic model building BB-wise mutation scales as O(2^km^{1.5}), and\nrequires O(k^{0.5}logm) less function evaluations than its selectorecombinative\ncounterpart, confirming theoretical results reported elsewhere (Sastry &\nGoldberg, 2004)."
},{
    "category": "cs.NE", 
    "doi": "10.1109/CEC.2004.1330930", 
    "link": "http://arxiv.org/pdf/cs/0405065v1", 
    "other_authors": "Kumara Sastry, Martin Pelikan, David E. Goldberg", 
    "title": "Efficiency Enhancement of Genetic Algorithms via Building-Block-Wise   Fitness Estimation", 
    "arxiv-id": "cs/0405065v1", 
    "author": "David E. Goldberg", 
    "publish": "2004-05-18T16:55:00Z", 
    "summary": "This paper studies fitness inheritance as an efficiency enhancement technique\nfor a class of competent genetic algorithms called estimation distribution\nalgorithms. Probabilistic models of important sub-solutions are developed to\nestimate the fitness of a proportion of individuals in the population, thereby\navoiding computationally expensive function evaluations. The effect of fitness\ninheritance on the convergence time and population sizing are modeled and the\nspeed-up obtained through inheritance is predicted. The results show that a\nfitness-inheritance mechanism which utilizes information on building-block\nfitnesses provides significant efficiency enhancement. For additively separable\nproblems, fitness inheritance reduces the number of function evaluations to\nabout half and yields a speed-up of about 1.75--2.25."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.cor.2005.06.017", 
    "link": "http://arxiv.org/pdf/cs/0501005v1", 
    "other_authors": "Alberto Fernandez, Sergio Gomez", 
    "title": "Portfolio selection using neural networks", 
    "arxiv-id": "cs/0501005v1", 
    "author": "Sergio Gomez", 
    "publish": "2005-01-03T18:55:47Z", 
    "summary": "In this paper we apply a heuristic method based on artificial neural networks\nin order to trace out the efficient frontier associated to the portfolio\nselection problem. We consider a generalization of the standard Markowitz\nmean-variance model which includes cardinality and bounding constraints. These\nconstraints ensure the investment in a given number of different assets and\nlimit the amount of capital to be invested in each asset. We present some\nexperimental results obtained with the neural network heuristic and we compare\nthem to those obtained with three previous heuristic methods."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.cor.2005.06.017", 
    "link": "http://arxiv.org/pdf/cs/0503078v1", 
    "other_authors": "Angelo Luis Pagliosa, Claudio Cesar de Sa, Fernando D. Sasse", 
    "title": "Obtaining Membership Functions from a Neuron Fuzzy System extended by   Kohonen Network", 
    "arxiv-id": "cs/0503078v1", 
    "author": "Fernando D. Sasse", 
    "publish": "2005-03-29T19:40:14Z", 
    "summary": "This article presents the Neo-Fuzzy-Neuron Modified by Kohonen Network\n(NFN-MK), an hybrid computational model that combines fuzzy system technique\nand artificial neural networks. Its main task consists in the automatic\ngeneration of membership functions, in particular, triangle forms, aiming a\ndynamic modeling of a system. The model is tested by simulating real systems,\nhere represented by a nonlinear mathematical function. Comparison with the\nresults obtained by traditional neural networks, and correlated studies of\nneurofuzzy systems applied in system identification area, shows that the NFN-MK\nmodel has a similar performance, despite its greater simplicity."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.cor.2005.06.017", 
    "link": "http://arxiv.org/pdf/cs/0504053v1", 
    "other_authors": "V. V. Zharkova, V. Schetinin", 
    "title": "A Neural-Network Technique for Recognition of Filaments in Solar Images", 
    "arxiv-id": "cs/0504053v1", 
    "author": "V. Schetinin", 
    "publish": "2005-04-13T13:28:15Z", 
    "summary": "We describe a new neural-network technique developed for an automated\nrecognition of solar filaments visible in the hydrogen H-alpha line full disk\nspectroheliograms. This technique allows neural networks learn from a few image\nfragments labelled manually to recognize the single filaments depicted on a\nlocal background. The trained network is able to recognize filaments depicted\non the backgrounds with variations in brightness caused by atmospherics\ndistortions. Despite the difference in backgrounds in our experiments the\nneural network has properly recognized filaments in the testing image\nfragments. Using a parabolic activation function we extend this technique to\nrecognize multiple solar filaments which may appear in one fragment."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.cor.2005.06.017", 
    "link": "http://arxiv.org/pdf/cs/0505003v1", 
    "other_authors": "Xiaofei Huang", 
    "title": "A New Kind of Hopfield Networks for Finding Global Optimum", 
    "arxiv-id": "cs/0505003v1", 
    "author": "Xiaofei Huang", 
    "publish": "2005-04-30T16:13:32Z", 
    "summary": "The Hopfield network has been applied to solve optimization problems over\ndecades. However, it still has many limitations in accomplishing this task.\nMost of them are inherited from the optimization algorithms it implements. The\ncomputation of a Hopfield network, defined by a set of difference equations,\ncan easily be trapped into one local optimum or another, sensitive to initial\nconditions, perturbations, and neuron update orders. It doesn't know how long\nit will take to converge, as well as if the final solution is a global optimum,\nor not. In this paper, we present a Hopfield network with a new set of\ndifference equations to fix those problems. The difference equations directly\nimplement a new powerful optimization algorithm."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.cor.2005.06.017", 
    "link": "http://arxiv.org/pdf/cs/0505016v1", 
    "other_authors": "Shashank Araokar", 
    "title": "Visual Character Recognition using Artificial Neural Networks", 
    "arxiv-id": "cs/0505016v1", 
    "author": "Shashank Araokar", 
    "publish": "2005-05-07T20:56:58Z", 
    "summary": "The recognition of optical characters is known to be one of the earliest\napplications of Artificial Neural Networks, which partially emulate human\nthinking in the domain of artificial intelligence. In this paper, a simplified\nneural approach to recognition of optical or visual characters is portrayed and\ndiscussed. The document is expected to serve as a resource for learners and\namateur investigators in pattern recognition, neural networking and related\ndisciplines."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.cor.2005.06.017", 
    "link": "http://arxiv.org/pdf/cs/0505019v1", 
    "other_authors": "Nitin Malik", 
    "title": "Artificial Neural Networks and their Applications", 
    "arxiv-id": "cs/0505019v1", 
    "author": "Nitin Malik", 
    "publish": "2005-05-10T06:37:31Z", 
    "summary": "The Artificial Neural network is a functional imitation of simplified model\nof the biological neurons and their goal is to construct useful computers for\nreal world problems. The ANN applications have increased dramatically in the\nlast few years fired by both theoretical and practical applications in a wide\nvariety of applications. A brief theory of ANN is presented and potential areas\nare identified and future trends are discussed."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.cor.2005.06.017", 
    "link": "http://arxiv.org/pdf/cs/0505021v3", 
    "other_authors": "Artur Rataj", 
    "title": "Distant generalization by feedforward neural networks", 
    "arxiv-id": "cs/0505021v3", 
    "author": "Artur Rataj", 
    "publish": "2005-05-10T11:36:35Z", 
    "summary": "This paper discusses the notion of generalization of training samples over\nlong distances in the input space of a feedforward neural network. Such a\ngeneralization might occur in various ways, that differ in how great the\ncontribution of different training features should be.\n  The structure of a neuron in a feedforward neural network is analyzed and it\nis concluded, that the actual performance of the discussed generalization in\nsuch neural networks may be problematic -- while such neural networks might be\ncapable for such a distant generalization, a random and spurious generalization\nmay occur as well.\n  To illustrate the differences in generalizing of the same function by\ndifferent learning machines, results given by the support vector machines are\nalso presented."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.cor.2005.06.017", 
    "link": "http://arxiv.org/pdf/cs/0505065v2", 
    "other_authors": "Xiao-Feng Xie, Wen-Jun Zhang, Zhi-Lian Yang", 
    "title": "A dissipative particle swarm optimization", 
    "arxiv-id": "cs/0505065v2", 
    "author": "Zhi-Lian Yang", 
    "publish": "2005-05-24T14:54:06Z", 
    "summary": "A dissipative particle swarm optimization is developed according to the\nself-organization of dissipative structure. The negative entropy is introduced\nto construct an opening dissipative system that is far-from-equilibrium so as\nto driving the irreversible evolution process with better fitness. The testing\nof two multimodal functions indicates it improves the performance effectively"
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.cor.2005.06.017", 
    "link": "http://arxiv.org/pdf/cs/0505067v1", 
    "other_authors": "Xiao-Feng Xie, Wen-Jun Zhang, De-Chun Bi", 
    "title": "Optimizing semiconductor devices by self-organizing particle swarm", 
    "arxiv-id": "cs/0505067v1", 
    "author": "De-Chun Bi", 
    "publish": "2005-05-25T01:28:18Z", 
    "summary": "A self-organizing particle swarm is presented. It works in dissipative state\nby employing the small inertia weight, according to experimental analysis on a\nsimplified model, which with fast convergence. Then by recognizing and\nreplacing inactive particles according to the process deviation information of\ndevice parameters, the fluctuation is introduced so as to driving the\nirreversible evolution process with better fitness. The testing on benchmark\nfunctions and an application example for device optimization with designed\nfitness function indicates it improves the performance effectively."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.cor.2005.06.017", 
    "link": "http://arxiv.org/pdf/cs/0505068v1", 
    "other_authors": "Xiao-Feng Xie, Wen-Jun Zhang, De-Chun Bi", 
    "title": "Handling equality constraints by adaptive relaxing rule for swarm   algorithms", 
    "arxiv-id": "cs/0505068v1", 
    "author": "De-Chun Bi", 
    "publish": "2005-05-25T01:32:30Z", 
    "summary": "The adaptive constraints relaxing rule for swarm algorithms to handle with\nthe problems with equality constraints is presented. The feasible space of such\nproblems may be similiar to ridge function class, which is hard for applying\nswarm algorithms. To enter the solution space more easily, the relaxed quasi\nfeasible space is introduced and shrinked adaptively. The experimental results\non benchmark functions are compared with the performance of other algorithms,\nwhich show its efficiency."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.cor.2005.06.017", 
    "link": "http://arxiv.org/pdf/cs/0505069v1", 
    "other_authors": "Wen-Jun Zhang, Xiao-Feng Xie, De-Chun Bi", 
    "title": "Handling boundary constraints for numerical optimization by particle   swarm flying in periodic search space", 
    "arxiv-id": "cs/0505069v1", 
    "author": "De-Chun Bi", 
    "publish": "2005-05-25T01:36:07Z", 
    "summary": "The periodic mode is analyzed together with two conventional boundary\nhandling modes for particle swarm. By providing an infinite space that\ncomprises periodic copies of original search space, it avoids possible\ndisorganizing of particle swarm that is induced by the undesired mutations at\nthe boundary. The results on benchmark functions show that particle swarm with\nperiodic mode is capable of improving the search performance significantly, by\ncompared with that of conventional modes and other algorithms."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.cor.2005.06.017", 
    "link": "http://arxiv.org/pdf/cs/0505070v1", 
    "other_authors": "Xiao-Feng Xie, Wen-Jun Zhang", 
    "title": "SWAF: Swarm Algorithm Framework for Numerical Optimization", 
    "arxiv-id": "cs/0505070v1", 
    "author": "Wen-Jun Zhang", 
    "publish": "2005-05-25T01:39:55Z", 
    "summary": "A swarm algorithm framework (SWAF), realized by agent-based modeling, is\npresented to solve numerical optimization problems. Each agent is a bare bones\ncognitive architecture, which learns knowledge by appropriately deploying a set\nof simple rules in fast and frugal heuristics. Two essential categories of\nrules, the generate-and-test and the problem-formulation rules, are\nimplemented, and both of the macro rules by simple combination and subsymbolic\ndeploying of multiple rules among them are also studied. Experimental results\non benchmark problems are presented, and performance comparison between SWAF\nand other existing algorithms indicates that it is efficiently."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.cor.2005.06.017", 
    "link": "http://arxiv.org/pdf/cs/0506032v1", 
    "other_authors": "R. Shankar", 
    "title": "Framework for Hopfield Network based Adaptive routing - A design level   approach for adaptive routing phenomena with Artificial Neural Network", 
    "arxiv-id": "cs/0506032v1", 
    "author": "R. Shankar", 
    "publish": "2005-06-10T05:30:41Z", 
    "summary": "Routing, as a basic phenomena, by itself, has got umpteen scopes to analyse,\ndiscuss and arrive at an optimal solution for the technocrats over years.\nRouting is analysed based on many factors; few key constraints that decide the\nfactors are communication medium, time dependency, information source nature.\nParametric routing has become the requirement of the day, with some kind of\nadaptation to the underlying network environment. Satellite constellations,\nparticularly LEO satellite constellations have become a reality in operational\nto have a non-breaking voice/data communication around the world.Routing in\nthese constellations has to be treated in a non conventional way, taking their\nnetwork geometry into consideration. One of the efficient methods of\noptimization is putting Neural Networks to use. Few Artificial Neural Network\nmodels are very much suitable for the adaptive control mechanism, by their\nnature of network arrangement. One such efficient model is Hopfield Network\nmodel.\n  This paper is an attempt to design a framework for the Hopfield Network based\nadaptive routing phenomena in satellite constellations."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.cor.2005.06.017", 
    "link": "http://arxiv.org/pdf/cs/0511022v1", 
    "other_authors": "Emanuel Diamant", 
    "title": "Does a Plane Imitate a Bird? Does Computer Vision Have to Follow   Biological Paradigms?", 
    "arxiv-id": "cs/0511022v1", 
    "author": "Emanuel Diamant", 
    "publish": "2005-11-04T15:08:47Z", 
    "summary": "We posit a new paradigm for image information processing. For the last 25\nyears, this task was usually approached in the frame of Treisman's two-stage\nparadigm [1]. The latter supposes an unsupervised, bottom-up directed process\nof preliminary information pieces gathering at the lower processing stages and\na supervised, top-down directed process of information pieces binding and\ngrouping at the higher stages. It is acknowledged that these sub-processes\ninteract and intervene between them in a tricky and a complicated manner.\nNotwithstanding the prevalence of this paradigm in biological and computer\nvision, we nevertheless propose to replace it with a new one, which we would\nlike to designate as a two-part paradigm. In it, information contained in an\nimage is initially extracted in an independent top-down manner by one part of\nthe system, and then it is examined and interpreted by another, separate system\npart. We argue that the new paradigm seems to be more plausible than its\nforerunner. We provide evidence from human attention vision studies and\ninsights of Kolmogorov's complexity theory to support our arguments. We also\nprovide some reasons in favor of separate image interpretation issues."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.cor.2005.06.017", 
    "link": "http://arxiv.org/pdf/cs/0511027v1", 
    "other_authors": "Stephen Luttrell", 
    "title": "Discrete Network Dynamics. Part 1: Operator Theory", 
    "arxiv-id": "cs/0511027v1", 
    "author": "Stephen Luttrell", 
    "publish": "2005-11-07T19:09:01Z", 
    "summary": "An operator algebra implementation of Markov chain Monte Carlo algorithms for\nsimulating Markov random fields is proposed. It allows the dynamics of networks\nwhose nodes have discrete state spaces to be specified by the action of an\nupdate operator that is composed of creation and annihilation operators. This\nformulation of discrete network dynamics has properties that are similar to\nthose of a quantum field theory of bosons, which allows reuse of many\nconceptual and theoretical structures from QFT. The equilibrium behaviour of\none of these generalised MRFs and of the adaptive cluster expansion network\n(ACEnet) are shown to be equivalent, which provides a way of unifying these two\ntheories."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.cor.2005.06.017", 
    "link": "http://arxiv.org/pdf/cs/0512062v1", 
    "other_authors": "Juergen Schmidhuber, Matteo Gagliolo, Daan Wierstra, Faustino Gomez", 
    "title": "Evolino for recurrent support vector machines", 
    "arxiv-id": "cs/0512062v1", 
    "author": "Faustino Gomez", 
    "publish": "2005-12-15T15:05:22Z", 
    "summary": "Traditional Support Vector Machines (SVMs) need pre-wired finite time windows\nto predict and classify time series. They do not have an internal state\nnecessary to deal with sequences involving arbitrary long-term dependencies.\nHere we introduce a new class of recurrent, truly sequential SVM-like devices\nwith internal adaptive states, trained by a novel method called EVOlution of\nsystems with KErnel-based outputs (Evoke), an instance of the recent Evolino\nclass of methods. Evoke evolves recurrent neural networks to detect and\nrepresent temporal dependencies while using quadratic programming/support\nvector regression to produce precise outputs. Evoke is the first SVM-based\nmechanism learning to classify a context-sensitive language. It also\noutperforms recent state-of-the-art gradient-based recurrent neural networks\n(RNNs) on various time series prediction tasks."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.cor.2005.06.017", 
    "link": "http://arxiv.org/pdf/cs/0602036v1", 
    "other_authors": "Ren\u00e9 Ndoundam, Maurice Tchuente", 
    "title": "R\u00e9seaux d'Automates de Caianiello Revisit\u00e9", 
    "arxiv-id": "cs/0602036v1", 
    "author": "Maurice Tchuente", 
    "publish": "2006-02-10T06:32:29Z", 
    "summary": "We exhibit a family of neural networks of McCulloch and Pitts of size $2nk+2$\nwhich can be simulated by a neural networks of Caianiello of size $2n+2$ and\nmemory length $k$. This simulation allows us to find again one of the result of\nthe following article: [Cycles exponentiels des r\\'{e}seaux de Caianiello et\ncompteurs en arithm\\'{e}tique redondante, Technique et Science Informatiques\nVol. 19, pages 985-1008] on the existence of neural networks of Caianiello of\nsize $2n+2$ and memory length $k$ which describes a cycle of length $k \\times\n2^{nk}$."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.cor.2005.06.017", 
    "link": "http://arxiv.org/pdf/cs/0602051v1", 
    "other_authors": "Fernando G. Lobo, Claudio F. Lima", 
    "title": "On the utility of the multimodal problem generator for assessing the   performance of Evolutionary Algorithms", 
    "arxiv-id": "cs/0602051v1", 
    "author": "Claudio F. Lima", 
    "publish": "2006-02-14T10:30:36Z", 
    "summary": "This paper looks in detail at how an evolutionary algorithm attempts to solve\ninstances from the multimodal problem generator. The paper shows that in order\nto consistently reach the global optimum, an evolutionary algorithm requires a\npopulation size that should grow at least linearly with the number of peaks. It\nis also shown a close relationship between the supply and decision making\nissues that have been identified previously in the context of population sizing\nmodels for additively decomposable problems.\n  The most important result of the paper, however, is that solving an instance\nof the multimodal problem generator is like solving a peak-in-a-haystack, and\nit is argued that evolutionary algorithms are not the best algorithms for such\na task. Finally, and as opposed to what several researchers have been doing, it\nis our strong belief that the multimodal problem generator is not adequate for\nassessing the performance of evolutionary algorithms."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.cor.2005.06.017", 
    "link": "http://arxiv.org/pdf/cs/0602055v1", 
    "other_authors": "Fernando G. Lobo, Claudio F. Lima", 
    "title": "Revisiting Evolutionary Algorithms with On-the-Fly Population Size   Adjustment", 
    "arxiv-id": "cs/0602055v1", 
    "author": "Claudio F. Lima", 
    "publish": "2006-02-15T13:48:13Z", 
    "summary": "In an evolutionary algorithm, the population has a very important role as its\nsize has direct implications regarding solution quality, speed, and\nreliability. Theoretical studies have been done in the past to investigate the\nrole of population sizing in evolutionary algorithms. In addition to those\nstudies, several self-adjusting population sizing mechanisms have been proposed\nin the literature. This paper revisits the latter topic and pays special\nattention to the genetic algorithm with adaptive population size (APGA), for\nwhich several researchers have claimed to be very effective at autonomously\n(re)sizing the population.\n  As opposed to those previous claims, this paper suggests a complete opposite\nview. Specifically, it shows that APGA is not capable of adapting the\npopulation size at all. This claim is supported on theoretical grounds and\nconfirmed by computer simulations."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.cor.2005.06.017", 
    "link": "http://arxiv.org/pdf/cs/0603004v1", 
    "other_authors": "P. A. Castillo, M. G. Arenas, J. G. Castellano, J. J. Merelo, A. Prieto, V. Rivas, G. Romero", 
    "title": "Lamarckian Evolution and the Baldwin Effect in Evolutionary Neural   Networks", 
    "arxiv-id": "cs/0603004v1", 
    "author": "G. Romero", 
    "publish": "2006-03-01T12:26:09Z", 
    "summary": "Hybrid neuro-evolutionary algorithms may be inspired on Darwinian or\nLamarckian evolu- tion. In the case of Darwinian evolution, the Baldwin effect,\nthat is, the progressive incorporation of learned characteristics to the\ngenotypes, can be observed and leveraged to improve the search. The purpose of\nthis paper is to carry out an exper- imental study into how learning can\nimprove G-Prop genetic search. Two ways of combining learning and genetic\nsearch are explored: one exploits the Baldwin effect, while the other uses a\nLamarckian strategy. Our experiments show that using a Lamarckian op- erator\nmakes the algorithm find networks with a low error rate, and the smallest size,\nwhile using the Bald- win effect obtains MLPs with the smallest error rate, and\na larger size, taking longer to reach a solution. Both approaches obtain a\nlower average error than other BP-based algorithms like RPROP, other evolu-\ntionary methods and fuzzy logic based methods"
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.cor.2005.06.017", 
    "link": "http://arxiv.org/pdf/cs/0603015v1", 
    "other_authors": "Pritam Rajagopal", 
    "title": "The Basic Kak Neural Network with Complex Inputs", 
    "arxiv-id": "cs/0603015v1", 
    "author": "Pritam Rajagopal", 
    "publish": "2006-03-02T23:59:19Z", 
    "summary": "The Kak family of neural networks is able to learn patterns quickly, and this\nspeed of learning can be a decisive advantage over other competing models in\nmany applications. Amongst the implementations of these networks are those\nusing reconfigurable networks, FPGAs and optical networks. In some\napplications, it is useful to use complex data, and it is with that in mind\nthat this introduction to the basic Kak network with complex inputs is being\npresented. The training algorithm is prescriptive and the network weights are\nassigned simply upon examining the inputs. The input is mapped using quaternary\nencoding for purpose of efficienty. This network family is part of a larger\nhierarchy of learning schemes that include quantum models."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.cor.2005.06.017", 
    "link": "http://arxiv.org/pdf/cs/0603042v1", 
    "other_authors": "Willie L. Scott II", 
    "title": "The NoN Approach to Autonomic Face Recognition", 
    "arxiv-id": "cs/0603042v1", 
    "author": "Willie L. Scott II", 
    "publish": "2006-03-09T17:35:31Z", 
    "summary": "A method of autonomic face recognition based on the biologically plausible\nnetwork of networks (NoN) model of information processing is presented. The NoN\nmodel is based on locally parallel and globally coordinated transformations in\nwhich the neurons or computational units form distributed networks, which\nthemselves link to form larger networks. This models the structures in the\ncerebral cortex described by Mountcastle and the architecture based on that\nproposed for information processing by Sutton. In the proposed implementation,\nface images are processed by a nested family of locally operating networks\nalong with a hierarchically superior network that classifies the information\nfrom each of the local networks. The results of the experiments yielded a\nmaximum of 98.5% recognition accuracy and an average of 97.4% recognition\naccuracy on a benchmark database."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s11063-005-3100-2", 
    "link": "http://arxiv.org/pdf/cs/0604001v1", 
    "other_authors": "Fabrice Rossi, Brieuc Conan-Guez", 
    "title": "Theoretical Properties of Projection Based Multilayer Perceptrons with   Functional Inputs", 
    "arxiv-id": "cs/0604001v1", 
    "author": "Brieuc Conan-Guez", 
    "publish": "2006-04-01T20:16:39Z", 
    "summary": "Many real world data are sampled functions. As shown by Functional Data\nAnalysis (FDA) methods, spectra, time series, images, gesture recognition data,\netc. can be processed more efficiently if their functional nature is taken into\naccount during the data analysis process. This is done by extending standard\ndata analysis methods so that they can apply to functional inputs. A general\nway to achieve this goal is to compute projections of the functional data onto\na finite dimensional sub-space of the functional space. The coordinates of the\ndata on a basis of this sub-space provide standard vector representations of\nthe functions. The obtained vectors can be processed by any standard method. In\nour previous work, this general approach has been used to define projection\nbased Multilayer Perceptrons (MLPs) with functional inputs. We study in this\npaper important theoretical properties of the proposed model. We show in\nparticular that MLPs with functional inputs are universal approximators: they\ncan approximate to arbitrary accuracy any continuous mapping from a compact\nsub-space of a functional space to R. Moreover, we provide a consistency result\nthat shows that any mapping from a functional space to R can be learned thanks\nto examples by a projection based MLP: the generalization mean square error of\nthe MLP decreases to the smallest possible mean square error on the data when\nthe number of examples goes to infinity."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s11063-005-3100-2", 
    "link": "http://arxiv.org/pdf/cs/0607019v1", 
    "other_authors": "Stephen Luttrell", 
    "title": "Modelling the Probability Density of Markov Sources", 
    "arxiv-id": "cs/0607019v1", 
    "author": "Stephen Luttrell", 
    "publish": "2006-07-06T18:49:20Z", 
    "summary": "This paper introduces an objective function that seeks to minimise the\naverage total number of bits required to encode the joint state of all of the\nlayers of a Markov source. This type of encoder may be applied to the problem\nof optimising the bottom-up (recognition model) and top-down (generative model)\nconnections in a multilayer neural network, and it unifies several previous\nresults on the optimisation of multilayer neural networks."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s11063-005-3100-2", 
    "link": "http://arxiv.org/pdf/cs/0607090v1", 
    "other_authors": "Adityan Rishiyur", 
    "title": "Neural Networks with Complex and Quaternion Inputs", 
    "arxiv-id": "cs/0607090v1", 
    "author": "Adityan Rishiyur", 
    "publish": "2006-07-18T21:01:43Z", 
    "summary": "This article investigates Kak neural networks, which can be instantaneously\ntrained, for complex and quaternion inputs. The performance of the basic\nalgorithm has been analyzed and shown how it provides a plausible model of\nhuman perception and understanding of images. The motivation for studying\nquaternion inputs is their use in representing spatial rotations that find\napplications in computer graphics, robotics, global navigation, computer vision\nand the spatial orientation of instruments. The problem of efficient mapping of\ndata in quaternion neural networks is examined. Some problems that need to be\naddressed before quaternion neural networks find applications are identified."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s11063-005-3100-2", 
    "link": "http://arxiv.org/pdf/cs/0609125v1", 
    "other_authors": "Goren Gordon, Uri Einziger-Lowicz", 
    "title": "Problem Evolution: A new approach to problem solving systems", 
    "arxiv-id": "cs/0609125v1", 
    "author": "Uri Einziger-Lowicz", 
    "publish": "2006-09-22T12:40:07Z", 
    "summary": "In this paper we present a novel tool to evaluate problem solving systems.\nInstead of using a system to solve a problem, we suggest using the problem to\nevaluate the system. By finding a numerical representation of a problem's\ncomplexity, one can implement genetic algorithm to search for the most complex\nproblem the given system can solve. This allows a comparison between different\nsystems that solve the same set of problems. In this paper we implement this\napproach on pattern recognition neural networks to try and find the most\ncomplex pattern a given configuration can solve. The complexity of the pattern\nis calculated using linguistic complexity. The results demonstrate the power of\nthe problem evolution approach in ranking different neural network\nconfigurations according to their pattern recognition abilities. Future\nresearch and implementations of this technique are also discussed."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s11063-005-3100-2", 
    "link": "http://arxiv.org/pdf/cs/0610041v1", 
    "other_authors": "J\u00e9r\u00e9my Fix, Julien Vitay, Nicolas Rougier", 
    "title": "A Computational Model of Spatial Memory Anticipation during Visual   Search", 
    "arxiv-id": "cs/0610041v1", 
    "author": "Nicolas Rougier", 
    "publish": "2006-10-09T11:42:27Z", 
    "summary": "Some visual search tasks require to memorize the location of stimuli that\nhave been previously scanned. Considerations about the eye movements raise the\nquestion of how we are able to maintain a coherent memory, despite the frequent\ndrastically changes in the perception. In this article, we present a\ncomputational model that is able to anticipate the consequences of the eye\nmovements on the visual perception in order to update a spatial memory"
},{
    "category": "cs.NE", 
    "doi": "10.1162/artl.2008.14.2.179", 
    "link": "http://arxiv.org/pdf/cs/0611032v2", 
    "other_authors": "Andre Nathan, Valmir C. Barbosa", 
    "title": "V-like formations in flocks of artificial birds", 
    "arxiv-id": "cs/0611032v2", 
    "author": "Valmir C. Barbosa", 
    "publish": "2006-11-07T20:25:28Z", 
    "summary": "We consider flocks of artificial birds and study the emergence of V-like\nformations during flight. We introduce a small set of fully distributed\npositioning rules to guide the birds' movements and demonstrate, by means of\nsimulations, that they tend to lead to stabilization into several of the\nwell-known V-like formations that have been observed in nature. We also provide\nquantitative indicators that we believe are closely related to achieving V-like\nformations, and study their behavior over a large set of independent\nsimulations."
},{
    "category": "cs.NE", 
    "doi": "10.1162/artl.2008.14.2.179", 
    "link": "http://arxiv.org/pdf/cs/0702055v1", 
    "other_authors": "A. V. Paraskevov", 
    "title": "On the possibility of making the complete computer model of a human   brain", 
    "arxiv-id": "cs/0702055v1", 
    "author": "A. V. Paraskevov", 
    "publish": "2007-02-09T13:16:14Z", 
    "summary": "The development of the algorithm of a neural network building by the\ncorresponding parts of a DNA code is discussed."
},{
    "category": "cs.NE", 
    "doi": "10.1162/artl.2008.14.2.179", 
    "link": "http://arxiv.org/pdf/0704.2725v2", 
    "other_authors": "Manuel Cebrian, Ivan Cantador", 
    "title": "Exploiting Heavy Tails in Training Times of Multilayer Perceptrons: A   Case Study with the UCI Thyroid Disease Database", 
    "arxiv-id": "0704.2725v2", 
    "author": "Ivan Cantador", 
    "publish": "2007-04-20T15:58:04Z", 
    "summary": "The random initialization of weights of a multilayer perceptron makes it\npossible to model its training process as a Las Vegas algorithm, i.e. a\nrandomized algorithm which stops when some required training error is obtained,\nand whose execution time is a random variable. This modeling is used to perform\na case study on a well-known pattern recognition benchmark: the UCI Thyroid\nDisease Database. Empirical evidence is presented of the training time\nprobability distribution exhibiting a heavy tail behavior, meaning a big\nprobability mass of long executions. This fact is exploited to reduce the\ntraining time cost by applying two simple restart strategies. The first assumes\nfull knowledge of the distribution yielding a 40% cut down in expected time\nwith respect to the training without restarts. The second, assumes null\nknowledge, yielding a reduction ranging from 9% to 23%."
},{
    "category": "cs.NE", 
    "doi": "10.1162/artl.2008.14.2.179", 
    "link": "http://arxiv.org/pdf/0704.3780v1", 
    "other_authors": "Pierre Collet, Jean-Philippe Rennard", 
    "title": "Stochastic Optimization Algorithms", 
    "arxiv-id": "0704.3780v1", 
    "author": "Jean-Philippe Rennard", 
    "publish": "2007-04-28T06:52:19Z", 
    "summary": "When looking for a solution, deterministic methods have the enormous\nadvantage that they do find global optima. Unfortunately, they are very\nCPU-intensive, and are useless on untractable NP-hard problems that would\nrequire thousands of years for cutting-edge computers to explore. In order to\nget a result, one needs to revert to stochastic algorithms, that sample the\nsearch space without exploring it thoroughly. Such algorithms can find very\ngood results, without any guarantee that the global optimum has been reached;\nbut there is often no other choice than using them. This chapter is a short\nintroduction to the main methods used in stochastic optimization."
},{
    "category": "cs.NE", 
    "doi": "10.1162/artl.2008.14.2.179", 
    "link": "http://arxiv.org/pdf/0705.0602v1", 
    "other_authors": "Alejandro Chinea Manrique De Lara, Michel Parent", 
    "title": "Risk Assessment Algorithms Based On Recursive Neural Networks", 
    "arxiv-id": "0705.0602v1", 
    "author": "Michel Parent", 
    "publish": "2007-05-04T11:53:35Z", 
    "summary": "The assessment of highly-risky situations at road intersections have been\nrecently revealed as an important research topic within the context of the\nautomotive industry. In this paper we shall introduce a novel approach to\ncompute risk functions by using a combination of a highly non-linear processing\nmodel in conjunction with a powerful information encoding procedure.\nSpecifically, the elements of information either static or dynamic that appear\nin a road intersection scene are encoded by using directed positional acyclic\nlabeled graphs. The risk assessment problem is then reformulated in terms of an\ninductive learning task carried out by a recursive neural network. Recursive\nneural networks are connectionist models capable of solving supervised and\nnon-supervised learning problems represented by directed ordered acyclic\ngraphs. The potential of this novel approach is demonstrated through well\npredefined scenarios. The major difference of our approach compared to others\nis expressed by the fact of learning the structure of the risk. Furthermore,\nthe combination of a rich information encoding procedure with a generalized\nmodel of dynamical recurrent networks permit us, as we shall demonstrate, a\nsophisticated processing of information that we believe as being a first step\nfor building future advanced intersection safety systems"
},{
    "category": "cs.NE", 
    "doi": "10.1162/artl.2008.14.2.179", 
    "link": "http://arxiv.org/pdf/0705.1481v1", 
    "other_authors": "Raihan H. Kibria", 
    "title": "Actin - Technical Report", 
    "arxiv-id": "0705.1481v1", 
    "author": "Raihan H. Kibria", 
    "publish": "2007-05-10T14:10:08Z", 
    "summary": "The Boolean satisfiability problem (SAT) can be solved efficiently with\nvariants of the DPLL algorithm. For industrial SAT problems, DPLL with conflict\nanalysis dependent dynamic decision heuristics has proved to be particularly\nefficient, e.g. in Chaff. In this work, algorithms that initialize the variable\nactivity values in the solver MiniSAT v1.14 by analyzing the CNF are evolved\nusing genetic programming (GP), with the goal to reduce the total number of\nconflicts of the search and the solving time. The effect of using initial\nactivities other than zero is examined by initializing with random numbers. The\npossibility of countering the detrimental effects of reordering the CNF with\nimproved initialization is investigated. The best result found (with validation\ntesting on further problems) was used in the solver Actin, which was submitted\nto SAT-Race 2006."
},{
    "category": "cs.NE", 
    "doi": "10.1162/artl.2008.14.2.179", 
    "link": "http://arxiv.org/pdf/0706.1051v1", 
    "other_authors": "Donald A. Sofge, David L. Elliott", 
    "title": "Improved Neural Modeling of Real-World Systems Using Genetic Algorithm   Based Variable Selection", 
    "arxiv-id": "0706.1051v1", 
    "author": "David L. Elliott", 
    "publish": "2007-06-07T18:13:59Z", 
    "summary": "Neural network models of real-world systems, such as industrial processes,\nmade from sensor data must often rely on incomplete data. System states may not\nall be known, sensor data may be biased or noisy, and it is not often known\nwhich sensor data may be useful for predictive modelling. Genetic algorithms\nmay be used to help to address this problem by determining the near optimal\nsubset of sensor variables most appropriate to produce good models. This paper\ndescribes the use of genetic search to optimize variable selection to determine\ninputs into the neural network model. We discuss genetic algorithm\nimplementation issues including data representation types and genetic operators\nsuch as crossover and mutation. We present the use of this technique for neural\nnetwork modelling of a typical industrial application, a liquid fed ceramic\nmelter, and detail the results of the genetic search to optimize the neural\nnetwork model for this application."
},{
    "category": "cs.NE", 
    "doi": "10.1162/artl.2008.14.2.179", 
    "link": "http://arxiv.org/pdf/0707.0548v1", 
    "other_authors": "Michael Defoin Platel, Sebastien Verel, Manuel Clergue, Philippe Collard", 
    "title": "From Royal Road to Epistatic Road for Variable Length Evolution   Algorithm", 
    "arxiv-id": "0707.0548v1", 
    "author": "Philippe Collard", 
    "publish": "2007-07-04T06:57:52Z", 
    "summary": "Although there are some real world applications where the use of variable\nlength representation (VLR) in Evolutionary Algorithm is natural and suitable,\nan academic framework is lacking for such representations. In this work we\npropose a family of tunable fitness landscapes based on VLR of genotypes. The\nfitness landscapes we propose possess a tunable degree of both neutrality and\nepistasis; they are inspired, on the one hand by the Royal Road fitness\nlandscapes, and the other hand by the NK fitness landscapes. So these\nlandscapes offer a scale of continuity from Royal Road functions, with\nneutrality and no epistasis, to landscapes with a large amount of epistasis and\nno redundancy. To gain insight into these fitness landscapes, we first use\nstandard tools such as adaptive walks and correlation length. Second, we\nevaluate the performances of evolutionary algorithms on these landscapes for\nvarious values of the neutral and the epistatic parameters; the results allow\nus to correlate the performances with the expected degrees of neutrality and\nepistasis."
},{
    "category": "cs.NE", 
    "doi": "10.1109/CEC.2003.1299585", 
    "link": "http://arxiv.org/pdf/0707.0641v1", 
    "other_authors": "S\u00e9bastien Verel, Philippe Collard, Manuel Clergue", 
    "title": "Where are Bottlenecks in NK Fitness Landscapes?", 
    "arxiv-id": "0707.0641v1", 
    "author": "Manuel Clergue", 
    "publish": "2007-07-04T15:30:54Z", 
    "summary": "Usually the offspring-parent fitness correlation is used to visualize and\nanalyze some caracteristics of fitness landscapes such as evolvability. In this\npaper, we introduce a more general representation of this correlation, the\nFitness Cloud (FC). We use the bottleneck metaphor to emphasise fitness levels\nin landscape that cause local search process to slow down. For a local search\nheuristic such as hill-climbing or simulated annealing, FC allows to visualize\nbottleneck and neutrality of landscapes. To confirm the relevance of the FC\nrepresentation we show where the bottlenecks are in the well-know NK fitness\nlandscape and also how to use neutrality information from the FC to combine\nsome neutral operator with local search heuristic."
},{
    "category": "cs.NE", 
    "doi": "10.1109/CEC.2004.1330960", 
    "link": "http://arxiv.org/pdf/0707.0643v1", 
    "other_authors": "S\u00e9bastien Verel, Philippe Collard, Manuel Clergue", 
    "title": "Scuba Search : when selection meets innovation", 
    "arxiv-id": "0707.0643v1", 
    "author": "Manuel Clergue", 
    "publish": "2007-07-04T15:36:35Z", 
    "summary": "We proposed a new search heuristic using the scuba diving metaphor. This\napproach is based on the concept of evolvability and tends to exploit\nneutrality in fitness landscape. Despite the fact that natural evolution does\nnot directly select for evolvability, the basic idea behind the scuba search\nheuristic is to explicitly push the evolvability to increase. The search\nprocess switches between two phases: Conquest-of-the-Waters and\nInvasion-of-the-Land. A comparative study of the new algorithm and standard\nlocal search heuristics on the NKq-landscapes has shown advantage and limit of\nthe scuba search. To enlighten qualitative differences between neutral search\nprocesses, the space is changed into a connected graph to visualize the\npathways that the search is likely to follow."
},{
    "category": "cs.NE", 
    "doi": "10.1109/CEC.2004.1330960", 
    "link": "http://arxiv.org/pdf/0707.0652v1", 
    "other_authors": "Philippe Collard, S\u00e9bastien Verel, Manuel Clergue", 
    "title": "How to use the Scuba Diving metaphor to solve problem with neutrality ?", 
    "arxiv-id": "0707.0652v1", 
    "author": "Manuel Clergue", 
    "publish": "2007-07-04T16:12:17Z", 
    "summary": "We proposed a new search heuristic using the scuba diving metaphor. This\napproach is based on the concept of evolvability and tends to exploit\nneutrality which exists in many real-world problems. Despite the fact that\nnatural evolution does not directly select for evolvability, the basic idea\nbehind the scuba search heuristic is to explicitly push evolvability to\nincrease. A comparative study of the scuba algorithm and standard local search\nheuristics has shown the advantage and the limitation of the scuba search. In\norder to tune neutrality, we use the NKq fitness landscapes and a family of\ntravelling salesman problems (TSP) where cities are randomly placed on a\nlattice and where travel distance between cities is computed with the Manhattan\nmetric. In this last problem the amount of neutrality varies with the city\nconcentration on the grid ; assuming the concentration below one, this TSP\nreasonably remains a NP-hard problem."
},{
    "category": "cs.NE", 
    "doi": "10.1109/CEC.2004.1330960", 
    "link": "http://arxiv.org/pdf/0708.2686v1", 
    "other_authors": "D. Roglic", 
    "title": "The universal evolutionary computer based on super-recursive algorithms   of evolvability", 
    "arxiv-id": "0708.2686v1", 
    "author": "D. Roglic", 
    "publish": "2007-07-24T18:50:22Z", 
    "summary": "This work exposes which mechanisms and procesess in the Nature of evolution\ncompute a function not computable by Turing machine. The computer with\nintelligence that is not higher than one bacteria population could have, but\nwith efficency to solve the problems that are non-computable by Turing machine\nis represented. This theoretical construction is called Universal Evolutinary\nComputer and it is based on the superecursive algorithms of evolvability."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.neucom.2004.11.012", 
    "link": "http://arxiv.org/pdf/0709.3641v1", 
    "other_authors": "Fabrice Rossi, Nicolas Delannay, Brieuc Conan-Guez, Michel Verleysen", 
    "title": "Representation of Functional Data in Neural Networks", 
    "arxiv-id": "0709.3641v1", 
    "author": "Michel Verleysen", 
    "publish": "2007-09-23T14:10:08Z", 
    "summary": "Functional Data Analysis (FDA) is an extension of traditional data analysis\nto functional data, for example spectra, temporal series, spatio-temporal\nimages, gesture recognition data, etc. Functional data are rarely known in\npractice; usually a regular or irregular sampling is known. For this reason,\nsome processing is needed in order to benefit from the smooth character of\nfunctional data in the analysis methods. This paper shows how to extend the\nRadial-Basis Function Networks (RBFN) and Multi-Layer Perceptron (MLP) models\nto functional data inputs, in particular when the latter are known through\nlists of input-output pairs. Various possibilities for functional processing\nare discussed, including the projection on smooth bases, Functional Principal\nComponent Analysis, functional centering and reduction, and the use of\ndifferential operators. It is shown how to incorporate these functional\nprocessing into the RBFN and MLP models. The functional approach is illustrated\non a benchmark of spectrometric data analysis."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.neunet.2004.07.001", 
    "link": "http://arxiv.org/pdf/0709.3642v1", 
    "other_authors": "Fabrice Rossi, Brieuc Conan-Guez", 
    "title": "Functional Multi-Layer Perceptron: a Nonlinear Tool for Functional Data   Analysis", 
    "arxiv-id": "0709.3642v1", 
    "author": "Brieuc Conan-Guez", 
    "publish": "2007-09-23T14:10:48Z", 
    "summary": "In this paper, we study a natural extension of Multi-Layer Perceptrons (MLP)\nto functional inputs. We show that fundamental results for classical MLP can be\nextended to functional MLP. We obtain universal approximation results that show\nthe expressive power of functional MLP is comparable to that of numerical MLP.\nWe obtain consistency results which imply that the estimation of optimal\nparameters for functional MLP is statistically well defined. We finally show on\nsimulated and real world data that the proposed model performs in a very\nsatisfactory way."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s11047-010-9209-x", 
    "link": "http://arxiv.org/pdf/0710.0672v2", 
    "other_authors": "Fabio R. J. Vieira, Valmir C. Barbosa", 
    "title": "Optimization of supply diversity for the self-assembly of simple objects   in two and three dimensions", 
    "arxiv-id": "0710.0672v2", 
    "author": "Valmir C. Barbosa", 
    "publish": "2007-10-03T18:29:12Z", 
    "summary": "The field of algorithmic self-assembly is concerned with the design and\nanalysis of self-assembly systems from a computational perspective, that is,\nfrom the perspective of mathematical problems whose study may give insight into\nthe natural processes through which elementary objects self-assemble into more\ncomplex ones. One of the main problems of algorithmic self-assembly is the\nminimum tile set problem (MTSP), which asks for a collection of types of\nelementary objects (called tiles) to be found for the self-assembly of an\nobject having a pre-established shape. Such a collection is to be as concise as\npossible, thus minimizing supply diversity, while satisfying a set of stringent\nconstraints having to do with the termination and other properties of the\nself-assembly process from its tile types. We present a study of what we think\nis the first practical approach to MTSP. Our study starts with the introduction\nof an evolutionary heuristic to tackle MTSP and includes results from extensive\nexperimentation with the heuristic on the self-assembly of simple objects in\ntwo and three dimensions. The heuristic we introduce combines classic elements\nfrom the field of evolutionary computation with a problem-specific variant of\nPareto dominance into a multi-objective approach to MTSP."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s11047-010-9209-x", 
    "link": "http://arxiv.org/pdf/0710.4182v1", 
    "other_authors": "Roman Ilin, Robert Kozma, Paul J. Werbos", 
    "title": "Beyond Feedforward Models Trained by Backpropagation: a Practical   Training Tool for a More Efficient Universal Approximator", 
    "arxiv-id": "0710.4182v1", 
    "author": "Paul J. Werbos", 
    "publish": "2007-10-23T03:43:57Z", 
    "summary": "Cellular Simultaneous Recurrent Neural Network (SRN) has been shown to be a\nfunction approximator more powerful than the MLP. This means that the\ncomplexity of MLP would be prohibitively large for some problems while SRN\ncould realize the desired mapping with acceptable computational constraints.\nThe speed of training of complex recurrent networks is crucial to their\nsuccessful application. Present work improves the previous results by training\nthe network with extended Kalman filter (EKF). We implemented a generic\nCellular SRN and applied it for solving two challenging problems: 2D maze\nnavigation and a subset of the connectedness problem. The speed of convergence\nhas been improved by several orders of magnitude in comparison with the earlier\nresults in the case of maze navigation, and superior generalization has been\ndemonstrated in the case of connectedness. The implications of this\nimprovements are discussed."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s11047-010-9209-x", 
    "link": "http://arxiv.org/pdf/0710.4725v1", 
    "other_authors": "Carlos Eduardo Savioli, Claudio C. Czendrodi, Jose Vicente Calvano, Antonio Carneiro De Mesquita Filho", 
    "title": "Fault-Trajectory Approach for Fault Diagnosis on Analog Circuits", 
    "arxiv-id": "0710.4725v1", 
    "author": "Antonio Carneiro De Mesquita Filho", 
    "publish": "2007-10-25T09:37:48Z", 
    "summary": "This issue discusses the fault-trajectory approach suitability for fault\ndiagnosis on analog networks. Recent works have shown promising results\nconcerning a method based on this concept for ATPG for diagnosing faults on\nanalog networks. Such method relies on evolutionary techniques, where a generic\nalgorithm (GA) is coded to generate a set of optimum frequencies capable to\ndisclose faults."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s11047-010-9209-x", 
    "link": "http://arxiv.org/pdf/0711.2897v1", 
    "other_authors": "J. Izquierdo, M. M. Tung, R. Perez, F. J. Martinez", 
    "title": "Estimation of fuzzy anomalies in Water Distribution Systems", 
    "arxiv-id": "0711.2897v1", 
    "author": "F. J. Martinez", 
    "publish": "2007-11-19T11:24:47Z", 
    "summary": "State estimation is necessary in diagnosing anomalies in Water Demand Systems\n(WDS). In this paper we present a neural network performing such a task. State\nestimation is performed by using optimization, which tries to reconcile all the\navailable information. Quantification of the uncertainty of the input data\n(telemetry measures and demand predictions) can be achieved by means of robust\nestate estimation. Using a mathematical model of the network, fuzzy estimated\nstates for anomalous states of the network can be obtained. They are used to\ntrain a neural network capable of assessing WDS anomalies associated with\nparticular sets of measurements."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s11047-010-9209-x", 
    "link": "http://arxiv.org/pdf/0712.3973v1", 
    "other_authors": "Pierre Collet, Marc Schoenauer", 
    "title": "GUIDE: Unifying Evolutionary Engines through a Graphical User Interface", 
    "arxiv-id": "0712.3973v1", 
    "author": "Marc Schoenauer", 
    "publish": "2007-12-24T07:31:58Z", 
    "summary": "Many kinds of Evolutionary Algorithms (EAs) have been described in the\nliterature since the last 30 years. However, though most of them share a common\nstructure, no existing software package allows the user to actually shift from\none model to another by simply changing a few parameters, e.g. in a single\nwindow of a Graphical User Interface. This paper presents GUIDE, a Graphical\nUser Interface for DREAM Experiments that, among other user-friendly features,\nunifies all kinds of EAs into a single panel, as far as evolution parameters\nare concerned. Such a window can be used either to ask for one of the well\nknown ready-to-use algorithms, or to very easily explore new combinations that\nhave not yet been studied. Another advantage of grouping all necessary elements\nto describe virtually all kinds of EAs is that it creates a fantastic pedagogic\ntool to teach EAs to students and newcomers to the field."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s11047-010-9209-x", 
    "link": "http://arxiv.org/pdf/0712.4099v3", 
    "other_authors": "G. Briscoe, P. De Wilde", 
    "title": "Digital Ecosystems: Optimisation by a Distributed Intelligence", 
    "arxiv-id": "0712.4099v3", 
    "author": "P. De Wilde", 
    "publish": "2007-12-26T04:13:20Z", 
    "summary": "Can intelligence optimise Digital Ecosystems? How could a distributed\nintelligence interact with the ecosystem dynamics? Can the software components\nthat are part of genetic selection be intelligent in themselves, as in an\nadaptive technology? We consider the effect of a distributed intelligence\nmechanism on the evolutionary and ecological dynamics of our Digital Ecosystem,\nwhich is the digital counterpart of a biological ecosystem for evolving\nsoftware services in a distributed network. We investigate Neural Networks and\nSupport Vector Machine for the learning based pattern recognition functionality\nof our distributed intelligence. Simulation results imply that the Digital\nEcosystem performs better with the application of a distributed intelligence,\nmarginally more effectively when powered by Support Vector Machine than Neural\nNetworks, and suggest that it can contribute to optimising the operation of our\nDigital Ecosystem."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s11047-010-9209-x", 
    "link": "http://arxiv.org/pdf/0712.4101v5", 
    "other_authors": "P. De Wilde, G. Briscoe", 
    "title": "Digital Ecosystems: Stability of Evolving Agent Populations", 
    "arxiv-id": "0712.4101v5", 
    "author": "G. Briscoe", 
    "publish": "2007-12-26T04:40:16Z", 
    "summary": "Stability is perhaps one of the most desirable features of any engineered\nsystem, given the importance of being able to predict its response to various\nenvironmental conditions prior to actual deployment. Engineered systems are\nbecoming ever more complex, approaching the same levels of biological\necosystems, and so their stability becomes ever more important, but taking on\nmore and more differential dynamics can make stability an ever more elusive\nproperty. The Chli-DeWilde definition of stability views a Multi-Agent System\nas a discrete time Markov chain with potentially unknown transition\nprobabilities. With a Multi-Agent System being considered stable when its\nstate, a stochastic process, has converged to an equilibrium distribution,\nbecause stability of a system can be understood intuitively as exhibiting\nbounded behaviour. We investigate an extension to include Multi-Agent Systems\nwith evolutionary dynamics, focusing on the evolving agent populations of our\nDigital Ecosystem. We then built upon this to construct an entropy-based\ndefinition for the degree of instability (entropy of the limit probabilities),\nwhich was later used to perform a stability analysis. The Digital Ecosystem is\nconsidered to investigate the stability of an evolving agent population through\nsimulations, for which the results were consistent with the original\nChli-DeWilde definition."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s11047-010-9209-x", 
    "link": "http://arxiv.org/pdf/0712.4102v6", 
    "other_authors": "G. Briscoe, P. De Wilde", 
    "title": "Digital Ecosystems: Evolving Service-Oriented Architectures", 
    "arxiv-id": "0712.4102v6", 
    "author": "P. De Wilde", 
    "publish": "2007-12-26T05:44:31Z", 
    "summary": "We view Digital Ecosystems to be the digital counterparts of biological\necosystems, exploiting the self-organising properties of biological ecosystems,\nwhich are considered to be robust, self-organising and scalable architectures\nthat can automatically solve complex, dynamic problems. Digital Ecosystems are\na novel optimisation technique where the optimisation works at two levels: a\nfirst optimisation, migration of agents (representing services) which are\ndistributed in a decentralised peer-to-peer network, operating continuously in\ntime; this process feeds a second optimisation based on evolutionary computing\nthat operates locally on single peers and is aimed at finding solutions to\nsatisfy locally relevant constraints. We created an Ecosystem-Oriented\nArchitecture of Digital Ecosystems by extending Service-Oriented Architectures\nwith distributed evolutionary computing, allowing services to recombine and\nevolve over time, constantly seeking to improve their effectiveness for the\nuser base. Individuals within our Digital Ecosystem will be applications\n(groups of services), created in response to user requests by using\nevolutionary optimisation to aggregate the services. These individuals will\nmigrate through the Digital Ecosystem and adapt to find niches where they are\nuseful in fulfilling other user requests for applications. Simulation results\nimply that the Digital Ecosystem performs better at large scales than a\ncomparable Service-Oriented Architecture, suggesting that incorporating ideas\nfrom theoretical ecology can contribute to useful self-organising properties in\ndigital ecosystems."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s11047-010-9209-x", 
    "link": "http://arxiv.org/pdf/0712.4159v5", 
    "other_authors": "G Briscoe", 
    "title": "Creating a Digital Ecosystem: Service-Oriented Architectures with   Distributed Evolutionary Computing", 
    "arxiv-id": "0712.4159v5", 
    "author": "G Briscoe", 
    "publish": "2007-12-26T23:32:10Z", 
    "summary": "We start with a discussion of the relevant literature, including Nature\nInspired Computing as a framework in which to understand this work, and the\nprocess of biomimicry to be used in mimicking the necessary biological\nprocesses to create Digital Ecosystems. We then consider the relevant\ntheoretical ecology in creating the digital counterpart of a biological\necosystem, including the topological structure of ecosystems, and evolutionary\nprocesses within distributed environments. This leads to a discussion of the\nrelevant fields from computer science for the creation of Digital Ecosystems,\nincluding evolutionary computing, Multi-Agent Systems, and Service-Oriented\nArchitectures. We then define Ecosystem-Oriented Architectures for the creation\nof Digital Ecosystems, imbibed with the properties of self-organisation and\nscalability from biological ecosystems, including a novel form of distributed\nevolutionary computing."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s11047-010-9209-x", 
    "link": "http://arxiv.org/pdf/0802.0251v1", 
    "other_authors": "Fabrice Rossi, Brieuc Conan-Guez", 
    "title": "Multi-Layer Perceptrons and Symbolic Data", 
    "arxiv-id": "0802.0251v1", 
    "author": "Brieuc Conan-Guez", 
    "publish": "2008-02-02T15:09:42Z", 
    "summary": "In some real world situations, linear models are not sufficient to represent\naccurately complex relations between input variables and output variables of a\nstudied system. Multilayer Perceptrons are one of the most successful\nnon-linear regression tool but they are unfortunately restricted to inputs and\noutputs that belong to a normed vector space. In this chapter, we propose a\ngeneral recoding method that allows to use symbolic data both as inputs and\noutputs to Multilayer Perceptrons. The recoding is quite simple to implement\nand yet provides a flexible framework that allows to deal with almost all\npractical cases. The proposed method is illustrated on a real world data set."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s11047-010-9209-x", 
    "link": "http://arxiv.org/pdf/0802.0252v1", 
    "other_authors": "Brieuc Conan-Guez, Fabrice Rossi", 
    "title": "Acc\u00e9l\u00e9ration des cartes auto-organisatrices sur tableau de   dissimilarit\u00e9s par s\u00e9paration et \u00e9valuation", 
    "arxiv-id": "0802.0252v1", 
    "author": "Fabrice Rossi", 
    "publish": "2008-02-02T15:10:35Z", 
    "summary": "In this paper, a new implementation of the adaptation of Kohonen\nself-organising maps (SOM) to dissimilarity matrices is proposed. This\nimplementation relies on the branch and bound principle to reduce the algorithm\nrunning time. An important property of this new approach is that the obtained\nalgorithm produces exactly the same results as the standard algorithm."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.chemolab.2007.09.004", 
    "link": "http://arxiv.org/pdf/0802.0287v1", 
    "other_authors": "Catherine Krier, Fabrice Rossi, Damien Fran\u00e7ois, Michel Verleysen", 
    "title": "A data-driven functional projection approach for the selection of   feature ranges in spectra with ICA or cluster analysis", 
    "arxiv-id": "0802.0287v1", 
    "author": "Michel Verleysen", 
    "publish": "2008-02-03T19:02:49Z", 
    "summary": "Prediction problems from spectra are largely encountered in chemometry. In\naddition to accurate predictions, it is often needed to extract information\nabout which wavelengths in the spectra contribute in an effective way to the\nquality of the prediction. This implies to select wavelengths (or wavelength\nintervals), a problem associated to variable selection. In this paper, it is\nshown how this problem may be tackled in the specific case of smooth (for\nexample infrared) spectra. The functional character of the spectra (their\nsmoothness) is taken into account through a functional variable projection\nprocedure. Contrarily to standard approaches, the projection is performed on a\nbasis that is driven by the spectra themselves, in order to best fit their\ncharacteristics. The methodology is illustrated by two examples of functional\nprojection, using Independent Component Analysis and functional variable\nclustering, respectively. The performances on two standard infrared spectra\nbenchmarks are illustrated."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.chemolab.2007.09.004", 
    "link": "http://arxiv.org/pdf/0802.0861v1", 
    "other_authors": "Paul R. Gazis, Jeffrey D. Scargle", 
    "title": "Using Bayesian Blocks to Partition Self-Organizing Maps", 
    "arxiv-id": "0802.0861v1", 
    "author": "Jeffrey D. Scargle", 
    "publish": "2008-02-06T18:50:16Z", 
    "summary": "Self organizing maps (SOMs) are widely-used for unsupervised classification.\nFor this application, they must be combined with some partitioning scheme that\ncan identify boundaries between distinct regions in the maps they produce. We\ndiscuss a novel partitioning scheme for SOMs based on the Bayesian Blocks\nsegmentation algorithm of Scargle [1998]. This algorithm minimizes a cost\nfunction to identify contiguous regions over which the values of the attributes\ncan be represented as approximately constant. Because this cost function is\nwell-defined and largely independent of assumptions regarding the number and\nstructure of clusters in the original sample space, this partitioning scheme\noffers significant advantages over many conventional methods. Sample code is\navailable."
},{
    "category": "cs.NE", 
    "doi": "10.1002/cplx.20269", 
    "link": "http://arxiv.org/pdf/0802.3875v1", 
    "other_authors": "Andy Adamatzky, Larry Bull", 
    "title": "Are complex systems hard to evolve?", 
    "arxiv-id": "0802.3875v1", 
    "author": "Larry Bull", 
    "publish": "2008-02-26T19:07:53Z", 
    "summary": "Evolutionary complexity is here measured by the number of trials/evaluations\nneeded for evolving a logical gate in a non-linear medium. Behavioural\ncomplexity of the gates evolved is characterised in terms of cellular automata\nbehaviour. We speculate that hierarchies of behavioural and evolutionary\ncomplexities are isomorphic up to some degree, subject to substrate specificity\nof evolution and the spectrum of evolution parameters."
},{
    "category": "cs.NE", 
    "doi": "10.1002/cplx.20269", 
    "link": "http://arxiv.org/pdf/0804.1133v1", 
    "other_authors": "Donald A. Sofge", 
    "title": "Prospective Algorithms for Quantum Evolutionary Computation", 
    "arxiv-id": "0804.1133v1", 
    "author": "Donald A. Sofge", 
    "publish": "2008-04-07T20:11:24Z", 
    "summary": "This effort examines the intersection of the emerging field of quantum\ncomputing and the more established field of evolutionary computation. The goal\nis to understand what benefits quantum computing might offer to computational\nintelligence and how computational intelligence paradigms might be implemented\nas quantum programs to be run on a future quantum computer. We critically\nexamine proposed algorithms and methods for implementing computational\nintelligence paradigms, primarily focused on heuristic optimization methods\nincluding and related to evolutionary computation, with particular regard for\ntheir potential for eventual implementation on quantum computing hardware."
},{
    "category": "cs.NE", 
    "doi": "10.1002/cplx.20269", 
    "link": "http://arxiv.org/pdf/0804.4622v3", 
    "other_authors": "Pierre Courrieu", 
    "title": "Fast Density Codes for Image Data", 
    "arxiv-id": "0804.4622v3", 
    "author": "Pierre Courrieu", 
    "publish": "2008-04-29T14:25:30Z", 
    "summary": "Recently, a new method for encoding data sets in the form of \"Density Codes\"\nwas proposed in the literature (Courrieu, 2006). This method allows to compare\nsets of points belonging to every multidimensional space, and to build shape\nspaces invariant to a wide variety of affine and non-affine transformations.\nHowever, this general method does not take advantage of the special properties\nof image data, resulting in a quite slow encoding process that makes this tool\npractically unusable for processing large image databases with conventional\ncomputers. This paper proposes a very simple variant of the density code method\nthat directly works on the image function, which is thousands times faster than\nthe original Parzen window based method, without loss of its useful properties."
},{
    "category": "cs.NE", 
    "doi": "10.1002/cplx.20269", 
    "link": "http://arxiv.org/pdf/0804.4808v1", 
    "other_authors": "Pierre Courrieu", 
    "title": "Solving Time of Least Square Systems in Sigma-Pi Unit Networks", 
    "arxiv-id": "0804.4808v1", 
    "author": "Pierre Courrieu", 
    "publish": "2008-04-30T12:23:05Z", 
    "summary": "The solving of least square systems is a useful operation in\nneurocomputational modeling of learning, pattern matching, and pattern\nrecognition. In these last two cases, the solution must be obtained on-line,\nthus the time required to solve a system in a plausible neural architecture is\ncritical. This paper presents a recurrent network of Sigma-Pi neurons, whose\nsolving time increases at most like the logarithm of the system size, and of\nits condition number, which provides plausible computation times for biological\nsystems."
},{
    "category": "cs.NE", 
    "doi": "10.1002/cplx.20269", 
    "link": "http://arxiv.org/pdf/0804.4809v1", 
    "other_authors": "Pierre Courrieu", 
    "title": "Fast Computation of Moore-Penrose Inverse Matrices", 
    "arxiv-id": "0804.4809v1", 
    "author": "Pierre Courrieu", 
    "publish": "2008-04-30T12:24:54Z", 
    "summary": "Many neural learning algorithms require to solve large least square systems\nin order to obtain synaptic weights. Moore-Penrose inverse matrices allow for\nsolving such systems, even with rank deficiency, and they provide minimum-norm\nvectors of synaptic weights, which contribute to the regularization of the\ninput-output mapping. It is thus of interest to develop fast and accurate\nalgorithms for computing Moore-Penrose inverse matrices. In this paper, an\nalgorithm based on a full rank Cholesky factorization is proposed. The\nresulting pseudoinverse matrices are similar to those provided by other\nalgorithms. However the computation time is substantially shorter, particularly\nfor large systems."
},{
    "category": "cs.NE", 
    "doi": "10.1002/cplx.20269", 
    "link": "http://arxiv.org/pdf/0805.0231v4", 
    "other_authors": "Nikolaus Hansen", 
    "title": "CMA-ES with Two-Point Step-Size Adaptation", 
    "arxiv-id": "0805.0231v4", 
    "author": "Nikolaus Hansen", 
    "publish": "2008-05-02T13:55:37Z", 
    "summary": "We combine a refined version of two-point step-size adaptation with the\ncovariance matrix adaptation evolution strategy (CMA-ES). Additionally, we\nsuggest polished formulae for the learning rate of the covariance matrix and\nthe recombination weights. In contrast to cumulative step-size adaptation or to\nthe 1/5-th success rule, the refined two-point adaptation (TPA) does not rely\non any internal model of optimality. In contrast to conventional\nself-adaptation, the TPA will achieve a better target step-size in particular\nwith large populations. The disadvantage of TPA is that it relies on two\nadditional objective function"
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.eswa.2012.04.019", 
    "link": "http://arxiv.org/pdf/0805.0697v1", 
    "other_authors": "Meir Perez, Tshilidzi Marwala", 
    "title": "Stochastic Optimization Approaches for Solving Sudoku", 
    "arxiv-id": "0805.0697v1", 
    "author": "Tshilidzi Marwala", 
    "publish": "2008-05-06T11:06:49Z", 
    "summary": "In this paper the Sudoku problem is solved using stochastic search techniques\nand these are: Cultural Genetic Algorithm (CGA), Repulsive Particle Swarm\nOptimization (RPSO), Quantum Simulated Annealing (QSA) and the Hybrid method\nthat combines Genetic Algorithm with Simulated Annealing (HGASA). The results\nobtained show that the CGA, QSA and HGASA are able to solve the Sudoku puzzle\nwith CGA finding a solution in 28 seconds, while QSA finding a solution in 65\nseconds and HGASA in 1.447 seconds. This is mainly because HGASA combines the\nparallel searching of GA with the flexibility of SA. The RPSO was found to be\nunable to solve the puzzle."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.eswa.2012.04.019", 
    "link": "http://arxiv.org/pdf/0805.4247v1", 
    "other_authors": "Ralph Linsker", 
    "title": "Neural network learning of optimal Kalman prediction and control", 
    "arxiv-id": "0805.4247v1", 
    "author": "Ralph Linsker", 
    "publish": "2008-05-28T01:57:11Z", 
    "summary": "Although there are many neural network (NN) algorithms for prediction and for\ncontrol, and although methods for optimal estimation (including filtering and\nprediction) and for optimal control in linear systems were provided by Kalman\nin 1960 (with nonlinear extensions since then), there has been, to my\nknowledge, no NN algorithm that learns either Kalman prediction or Kalman\ncontrol (apart from the special case of stationary control). Here we show how\noptimal Kalman prediction and control (KPC), as well as system identification,\ncan be learned and executed by a recurrent neural network composed of\nlinear-response nodes, using as input only a stream of noisy measurement data.\n  The requirements of KPC appear to impose significant constraints on the\nallowed NN circuitry and signal flows. The NN architecture implied by these\nconstraints bears certain resemblances to the local-circuit architecture of\nmammalian cerebral cortex. We discuss these resemblances, as well as caveats\nthat limit our current ability to draw inferences for biological function. It\nhas been suggested that the local cortical circuit (LCC) architecture may\nperform core functions (as yet unknown) that underlie sensory, motor,and other\ncortical processing. It is reasonable to conjecture that such functions may\ninclude prediction, the estimation or inference of missing or noisy sensory\ndata, and the goal-driven generation of control signals. The resemblances found\nbetween the KPC NN architecture and that of the LCC are consistent with this\nconjecture."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.eswa.2012.04.019", 
    "link": "http://arxiv.org/pdf/0809.4622v1", 
    "other_authors": "J\u00e9r\u00e9my Fix, Nicolas P. Rougier, Fr\u00e9d\u00e9ric Alexandre", 
    "title": "A computational approach to the covert and overt deployment of spatial   attention", 
    "arxiv-id": "0809.4622v1", 
    "author": "Fr\u00e9d\u00e9ric Alexandre", 
    "publish": "2008-09-26T13:12:36Z", 
    "summary": "Popular computational models of visual attention tend to neglect the\ninfluence of saccadic eye movements whereas it has been shown that the primates\nperform on average three of them per seconds and that the neural substrate for\nthe deployment of attention and the execution of an eye movement might\nconsiderably overlap. Here we propose a computational model in which the\ndeployment of attention with or without a subsequent eye movement emerges from\nlocal, distributed and numerical computations."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.eswa.2012.04.019", 
    "link": "http://arxiv.org/pdf/0809.5087v1", 
    "other_authors": "Yuhua Chen, Subhash Kak, Lei Wang", 
    "title": "Hybrid Neural Network Architecture for On-Line Learning", 
    "arxiv-id": "0809.5087v1", 
    "author": "Lei Wang", 
    "publish": "2008-09-29T23:00:22Z", 
    "summary": "Approaches to machine intelligence based on brain models have stressed the\nuse of neural networks for generalization. Here we propose the use of a hybrid\nneural network architecture that uses two kind of neural networks\nsimultaneously: (i) a surface learning agent that quickly adapt to new modes of\noperation; and, (ii) a deep learning agent that is very accurate within a\nspecific regime of operation. The two networks of the hybrid architecture\nperform complementary functions that improve the overall performance. The\nperformance of the hybrid architecture has been compared with that of\nback-propagation perceptrons and the CC and FC networks for chaotic time-series\nprediction, the CATS benchmark test, and smooth function approximation. It has\nbeen shown that the hybrid architecture provides a superior performance based\non the RMS error criterion."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.eswa.2012.04.019", 
    "link": "http://arxiv.org/pdf/0810.3356v1", 
    "other_authors": "Keki Burjorjee", 
    "title": "The Fundamental Problem with the Building Block Hypothesis", 
    "arxiv-id": "0810.3356v1", 
    "author": "Keki Burjorjee", 
    "publish": "2008-10-19T00:38:06Z", 
    "summary": "Skepticism of the building block hypothesis (BBH) has previously been\nexpressed on account of the weak theoretical foundations of this hypothesis and\nthe anomalies in the empirical record of the simple genetic algorithm. In this\npaper we hone in on a more fundamental cause for skepticism--the extraordinary\nstrength of some of the assumptions that undergird the BBH. Specifically, we\nfocus on assumptions made about the distribution of fitness over the genome\nset, and argue that these assumptions are unacceptably strong. As most of these\nassumptions have been embraced by the designers of so-called \"competent\"\ngenetic algorithms, our critique is relevant to an appraisal of such algorithms\nas well."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.eswa.2012.04.019", 
    "link": "http://arxiv.org/pdf/0810.3357v2", 
    "other_authors": "Keki M. Burjorjee", 
    "title": "Two Remarkable Computational Competencies of the Simple Genetic   Algorithm", 
    "arxiv-id": "0810.3357v2", 
    "author": "Keki M. Burjorjee", 
    "publish": "2008-10-19T01:08:00Z", 
    "summary": "Since the inception of genetic algorithmics the identification of\ncomputational efficiencies of the simple genetic algorithm (SGA) has been an\nimportant goal. In this paper we distinguish between a computational competency\nof the SGA--an efficient, but narrow computational ability--and a computational\nproficiency of the SGA--a computational ability that is both efficient and\nbroad. Till date, attempts to deduce a computational proficiency of the SGA\nhave been unsuccessful. It may, however, be possible to inductively infer a\ncomputational proficiency of the SGA from a set of related computational\ncompetencies that have been deduced. With this in mind we deduce two\ncomputational competencies of the SGA. These competencies, when considered\ntogether, point toward a remarkable computational proficiency of the SGA. This\nproficiency is pertinent to a general problem that is closely related to a\nwell-known statistical problem at the cutting edge of computational genetics."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0810.3484v1", 
    "other_authors": "Gabriela Ochoa, Marco Tomassini, S\u00e9bastien Verel, Christian Darabos", 
    "title": "A Study of NK Landscapes' Basins and Local Optima Networks", 
    "arxiv-id": "0810.3484v1", 
    "author": "Christian Darabos", 
    "publish": "2008-10-20T08:06:40Z", 
    "summary": "We propose a network characterization of combinatorial fitness landscapes by\nadapting the notion of inherent networks proposed for energy surfaces (Doye,\n2002). We use the well-known family of $NK$ landscapes as an example. In our\ncase the inherent network is the graph where the vertices are all the local\nmaxima and edges mean basin adjacency between two maxima. We exhaustively\nextract such networks on representative small NK landscape instances, and show\nthat they are 'small-worlds'. However, the maxima graphs are not random, since\ntheir clustering coefficients are much larger than those of corresponding\nrandom graphs. Furthermore, the degree distributions are close to exponential\ninstead of Poissonian. We also describe the nature of the basins of attraction\nand their relationship with the local maxima network."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0810.3492v1", 
    "other_authors": "S\u00e9bastien Verel, Gabriela Ochoa, Marco Tomassini", 
    "title": "The Connectivity of NK Landscapes' Basins: A Network Analysis", 
    "arxiv-id": "0810.3492v1", 
    "author": "Marco Tomassini", 
    "publish": "2008-10-20T08:36:22Z", 
    "summary": "We propose a network characterization of combinatorial fitness landscapes by\nadapting the notion of inherent networks proposed for energy surfaces. We use\nthe well-known family of NK landscapes as an example. In our case the inherent\nnetwork is the graph where the vertices represent the local maxima in the\nlandscape, and the edges account for the transition probabilities between their\ncorresponding basins of attraction. We exhaustively extracted such networks on\nrepresentative small NK landscape instances, and performed a statistical\ncharacterization of their properties. We found that most of these network\nproperties can be related to the search difficulty on the underlying NK\nlandscapes with varying values of K."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0812.0882v1", 
    "other_authors": "Philippe Thomas, Andr\u00e9 Thomas", 
    "title": "Elagage d'un perceptron multicouches : utilisation de l'analyse de la   variance de la sensibilit\u00e9 des param\u00e8tres", 
    "arxiv-id": "0812.0882v1", 
    "author": "Andr\u00e9 Thomas", 
    "publish": "2008-12-04T09:12:14Z", 
    "summary": "The stucture determination of a neural network for the modelisation of a\nsystem remain the core of the problem. Within this framework, we propose a\npruning algorithm of the network based on the use of the analysis of the\nsensitivity of the variance of all the parameters of the network. This\nalgorithm will be tested on two examples of simulation and its performances\nwill be compared with three other algorithms of pruning of the literature"
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0812.1094v1", 
    "other_authors": "Philippe Thomas, Andr\u00e9 Thomas", 
    "title": "S\u00e9lection de la structure d'un perceptron multicouches pour la   r\u00e9duction dun mod\u00e8le de simulation d'une scierie", 
    "arxiv-id": "0812.1094v1", 
    "author": "Andr\u00e9 Thomas", 
    "publish": "2008-12-05T08:49:53Z", 
    "summary": "Simulation is often used to evaluate the relevance of a Directing Program of\nProduction (PDP) or to evaluate its impact on detailed sc\\'enarii of\nscheduling. Within this framework, we propose to reduce the complexity of a\nmodel of simulation by exploiting a multilayer perceptron. A main phase of the\nmodeling of one system using a multilayer perceptron remains the determination\nof the structure of the network. We propose to compare and use various pruning\nalgorithms in order to determine the optimal structure of the network used to\nreduce the complexity of the model of simulation of our case of application: a\nsawmill."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0904.3063v1", 
    "other_authors": "C. M. Fernandes, J. J. Merelo, A. C. Rosa", 
    "title": "Using Dissortative Mating Genetic Algorithms to Track the Extrema of   Dynamic Deceptive Functions", 
    "arxiv-id": "0904.3063v1", 
    "author": "A. C. Rosa", 
    "publish": "2009-04-20T15:57:20Z", 
    "summary": "Traditional Genetic Algorithms (GAs) mating schemes select individuals for\ncrossover independently of their genotypic or phenotypic similarities. In\nNature, this behaviour is known as random mating. However, non-random schemes -\nin which individuals mate according to their kinship or likeness - are more\ncommon in natural systems. Previous studies indicate that, when applied to GAs,\nnegative assortative mating (a specific type of non-random mating, also known\nas dissortative mating) may improve their performance (on both speed and\nreliability) in a wide range of problems. Dissortative mating maintains the\ngenetic diversity at a higher level during the run, and that fact is frequently\nobserved as an explanation for dissortative GAs ability to escape local optima\ntraps. Dynamic problems, due to their specificities, demand special care when\ntuning a GA, because diversity plays an even more crucial role than it does\nwhen tackling static ones. This paper investigates the behaviour of\ndissortative mating GAs, namely the recently proposed Adaptive Dissortative\nMating GA (ADMGA), on dynamic trap functions. ADMGA selects parents according\nto their Hamming distance, via a self-adjustable threshold value. The method,\nby keeping population diversity during the run, provides an effective means to\ndeal with dynamic problems. Tests conducted with deceptive and nearly deceptive\ntrap functions indicate that ADMGA is able to outperform other GAs, some\nspecifically designed for tracking moving extrema, on a wide range of tests,\nbeing particularly effective when speed of change is not very fast. When\ncomparing the algorithm to a previously proposed dissortative GA, results show\nthat performance is equivalent on the majority of the experiments, but ADMGA\nperforms better when solving the hardest instances of the test set."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0904.3650v1", 
    "other_authors": "Dan L. Lacrama, Ioan Snep", 
    "title": "The use of invariant moments in hand-written character recognition", 
    "arxiv-id": "0904.3650v1", 
    "author": "Ioan Snep", 
    "publish": "2009-04-23T10:44:21Z", 
    "summary": "The goal of this paper is to present the implementation of a Radial Basis\nFunction neural network with built-in knowledge to recognize hand-written\ncharacters. The neural network includes in its architecture gates controlled by\nan attraction/repulsion system of coefficients. These coefficients are derived\nfrom a preprocessing stage which groups the characters according to their\nascendant, central, or descendent components. The neural network is trained\nusing data from invariant moment functions. Results are compared with those\nobtained using a K nearest neighbor method on the same moment data."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0905.2649v1", 
    "other_authors": "Soumya Banerjee", 
    "title": "An Immune System Inspired Approach to Automated Program Verification", 
    "arxiv-id": "0905.2649v1", 
    "author": "Soumya Banerjee", 
    "publish": "2009-05-16T02:34:32Z", 
    "summary": "An immune system inspired Artificial Immune System (AIS) algorithm is\npresented, and is used for the purposes of automated program verification.\nRelevant immunological concepts are discussed and the field of AIS is briefly\nreviewed. It is proposed to use this AIS algorithm for a specific automated\nprogram verification task: that of predicting shape of program invariants. It\nis shown that the algorithm correctly predicts program invariant shape for a\nvariety of benchmarked programs."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0906.0798v1", 
    "other_authors": "Subhash Kak", 
    "title": "Single Neuron Memories and the Network's Proximity Matrix", 
    "arxiv-id": "0906.0798v1", 
    "author": "Subhash Kak", 
    "publish": "2009-06-03T23:10:25Z", 
    "summary": "This paper extends the treatment of single-neuron memories obtained by the\nB-matrix approach. The spreading of the activity within the network is\ndetermined by the network's proximity matrix which represents the separations\namongst the neurons through the neural pathways."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0906.1900v1", 
    "other_authors": "Philippe Thomas, Andr\u00e9 Thomas", 
    "title": "How deals with discrete data for the reduction of simulation models   using neural network", 
    "arxiv-id": "0906.1900v1", 
    "author": "Andr\u00e9 Thomas", 
    "publish": "2009-06-10T09:56:29Z", 
    "summary": "Simulation is useful for the evaluation of a Master Production/distribution\nSchedule (MPS). Also, the goal of this paper is the study of the design of a\nsimulation model by reducing its complexity. According to theory of\nconstraints, we want to build reduced models composed exclusively by\nbottlenecks and a neural network. Particularly a multilayer perceptron, is\nused. The structure of the network is determined by using a pruning procedure.\nThis work focuses on the impact of discrete data on the results and compares\ndifferent approaches to deal with these data. This approach is applied to\nsawmill internal supply chain"
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0906.4846v1", 
    "other_authors": "Lorentz Jantschi", 
    "title": "A genetic algorithm for structure-activity relationships: software   implementation", 
    "arxiv-id": "0906.4846v1", 
    "author": "Lorentz Jantschi", 
    "publish": "2009-06-26T06:25:07Z", 
    "summary": "The design and the implementation of a genetic algorithm are described. The\napplicability domain is on structure-activity relationships expressed as\nmultiple linear regressions and predictor variables are from families of\nstructure-based molecular descriptors. An experiment to compare different\nselection and survival strategies was designed and realized. The genetic\nalgorithm was run using the designed experiment on a set of 206 polychlorinated\nbiphenyls searching on structure-activity relationships having known the\nmeasured octanol-water partition coefficients and a family of molecular\ndescriptors. The experiment shows that different selection and survival\nstrategies create different partitions on the entire population of all possible\ngenotypes."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0907.0075v1", 
    "other_authors": "Hamidreza Mahini, Alireza Mahini, Javad Ghofrani", 
    "title": "XDANNG: XML based Distributed Artificial Neural Network with Globus   Toolkit", 
    "arxiv-id": "0907.0075v1", 
    "author": "Javad Ghofrani", 
    "publish": "2009-07-01T07:35:52Z", 
    "summary": "Artificial Neural Network is one of the most common AI application fields.\nThis field has direct and indirect usages most sciences. The main goal of ANN\nis to imitate biological neural networks for solving scientific problems. But\nthe level of parallelism is the main problem of ANN systems in comparison with\nbiological systems. To solve this problem, we have offered a XML-based\nframework for implementing ANN on the Globus Toolkit Platform. Globus Toolkit\nis well known management software for multipurpose Grids. Using the Grid for\nsimulating the neuron network will lead to a high degree of parallelism in the\nimplementation of ANN. We have used the XML for improving flexibility and\nscalability in our framework."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0907.0516v1", 
    "other_authors": "James M Whitacre", 
    "title": "Adaptation and Self-Organization in Evolutionary Algorithms", 
    "arxiv-id": "0907.0516v1", 
    "author": "James M Whitacre", 
    "publish": "2009-07-03T02:21:36Z", 
    "summary": "Abbreviated Abstract: The objective of Evolutionary Computation is to solve\npractical problems (e.g. optimization, data mining) by simulating the\nmechanisms of natural evolution. This thesis addresses several topics related\nto adaptation and self-organization in evolving systems with the overall aims\nof improving the performance of Evolutionary Algorithms (EA), understanding its\nrelation to natural evolution, and incorporating new mechanisms for mimicking\ncomplex biological systems."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0907.0611v1", 
    "other_authors": "S. Butdee, Chaiwat Noomtong, Serge Tichkiewitch", 
    "title": "A process planning system with feature based neural network search   strategy for aluminum extrusion die manufacturing", 
    "arxiv-id": "0907.0611v1", 
    "author": "Serge Tichkiewitch", 
    "publish": "2009-07-03T12:08:13Z", 
    "summary": "Aluminum extrusion die manufacturing is a critical task for productive\nimprovement and increasing potential of competition in aluminum extrusion\nindustry. It causes to meet the efficiency not only consistent quality but also\ntime and production cost reduction. Die manufacturing consists first of die\ndesign and process planning in order to make a die for extruding the customer's\nrequirement products. The efficiency of die design and process planning are\nbased on the knowledge and experience of die design and die manufacturer\nexperts. This knowledge has been formulated into a computer system called the\nknowledge-based system. It can be reused to support a new die design and\nprocess planning. Such knowledge can be extracted directly from die geometry\nwhich is composed of die features. These features are stored in die feature\nlibrary to be prepared for producing a new die manufacturing. Die geometry is\ndefined according to the characteristics of the profile so we can reuse die\nfeatures from the previous similar profile design cases. This paper presents\nthe CaseXpert Process Planning System for die manufacturing based on feature\nbased neural network technique. Die manufacturing cases in the case library\nwould be retrieved with searching and learning method by neural network for\nreusing or revising it to build a die design and process planning when a new\ncase is similar with the previous die manufacturing cases. The results of the\nsystem are dies design and machining process. The system has been successfully\ntested, it has been proved that the system can reduce planning time and respond\nhigh consistent plans."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0907.4426v1", 
    "other_authors": "Christopher M. Frenz, Steve Peters, Wilson Julien", 
    "title": "Evolution of Digital Logic Functionality via a Genetic Algorithm", 
    "arxiv-id": "0907.4426v1", 
    "author": "Wilson Julien", 
    "publish": "2009-07-25T15:21:16Z", 
    "summary": "Digital logic forms the functional basics of most modern electronic equipment\nand as such the creation of novel digital logic circuits is an active area of\ncomputer engineering research. This study demonstrates that genetic algorithms\ncan be used to evolve functionally useful sets of logic gate interconnections\nto create useful digital logic circuits. The efficacy of this approach is\nillustrated via the evolution of AND, OR, XOR, NOR, and XNOR functionality from\nsets of NAND gates, thereby illustrating that evolutionary methods have the\npotential be applied to the design of digital electronics."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0908.0516v1", 
    "other_authors": "Juan J. Merelo Guervos", 
    "title": "Still doing evolutionary algorithms with Perl", 
    "arxiv-id": "0908.0516v1", 
    "author": "Juan J. Merelo Guervos", 
    "publish": "2009-08-04T19:16:14Z", 
    "summary": "Algorithm::Evolutionary (A::E from now on) was introduced in 2002, after a\ntalk in YAPC::EU in Munich. 7 years later, A::E is in its 0.67 version (past\nits \"number of the beast\" 0.666), and has been used extensively, to the point\nof being the foundation of much of the (computer) science being done by our\nresearch group (and, admittedly, not many others). All is not done, however;\nnow A::E is being integrated with POE so that evolutionary algorithms (EAs) can\nbe combined with all kinds of servers and used in client, servers, and anything\nin between. In this companion to the talk I will explain what evolutionary\nalgorithms are, what they are being used for, how to do them with Perl (using\nthese or other fine modules found in CPAN) and what evolutionary algorithms can\ndo for Perl at large."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0908.1453v1", 
    "other_authors": "Roya Asadi, Norwati Mustapha, Nasir Sulaiman", 
    "title": "Training Process Reduction Based On Potential Weights Linear Analysis To   Accelarate Back Propagation Network", 
    "arxiv-id": "0908.1453v1", 
    "author": "Nasir Sulaiman", 
    "publish": "2009-08-11T05:30:01Z", 
    "summary": "Learning is the important property of Back Propagation Network (BPN) and\nfinding the suitable weights and thresholds during training in order to improve\ntraining time as well as achieve high accuracy. Currently, data pre-processing\nsuch as dimension reduction input values and pre-training are the contributing\nfactors in developing efficient techniques for reducing training time with high\naccuracy and initialization of the weights is the important issue which is\nrandom and creates paradox, and leads to low accuracy with high training time.\nOne good data preprocessing technique for accelerating BPN classification is\ndimension reduction technique but it has problem of missing data. In this\npaper, we study current pre-training techniques and new preprocessing technique\ncalled Potential Weight Linear Analysis (PWLA) which combines normalization,\ndimension reduction input values and pre-training. In PWLA, the first data\npreprocessing is performed for generating normalized input values and then\napplying them by pre-training technique in order to obtain the potential\nweights. After these phases, dimension of input values matrix will be reduced\nby using real potential weights. For experiment results XOR problem and three\ndatasets, which are SPECT Heart, SPECTF Heart and Liver disorders (BUPA) will\nbe evaluated. Our results, however, will show that the new technique of PWLA\nwill change BPN to new Supervised Multi Layer Feed Forward Neural Network\n(SMFFNN) model with high accuracy in one epoch without training cycle. Also\nPWLA will be able to have power of non linear supervised and unsupervised\ndimension reduction property for applying by other supervised multi layer feed\nforward neural network model in future work."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0908.1597v1", 
    "other_authors": "George Kesidis", 
    "title": "A quantum diffusion network", 
    "arxiv-id": "0908.1597v1", 
    "author": "George Kesidis", 
    "publish": "2009-08-11T23:45:08Z", 
    "summary": "Wong's diffusion network is a stochastic, zero-input Hopfield network with a\nGibbs stationary distribution over a bounded, connected continuum. Previously,\nlogarithmic thermal annealing was demonstrated for the diffusion network and\ndigital versions of it were studied and applied to imaging. Recently, \"quantum\"\nannealed Markov chains have garnered significant attention because of their\nimproved performance over \"pure\" thermal annealing. In this note, a joint\nquantum and thermal version of Wong's diffusion network is described and its\nconvergence properties are studied. Different choices for \"auxiliary\" functions\nare discussed, including those of the kinetic type previously associated with\nquantum annealing."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0908.3025v1", 
    "other_authors": "David Corne, Joshua Knowles", 
    "title": "Techniques for Highly Multiobjective Optimisation: Some Nondominated   Points are Better than Others", 
    "arxiv-id": "0908.3025v1", 
    "author": "Joshua Knowles", 
    "publish": "2009-08-20T21:44:32Z", 
    "summary": "The research area of evolutionary multiobjective optimization (EMO) is\nreaching better understandings of the properties and capabilities of EMO\nalgorithms, and accumulating much evidence of their worth in practical\nscenarios. An urgent emerging issue is that the favoured EMO algorithms scale\npoorly when problems have many (e.g. five or more) objectives. One of the chief\nreasons for this is believed to be that, in many-objective EMO search,\npopulations are likely to be largely composed of nondominated solutions. In\nturn, this means that the commonly-used algorithms cannot distinguish between\nthese for selective purposes. However, there are methods that can be used\nvalidly to rank points in a nondominated set, and may therefore usefully\nunderpin selection in EMO search. Here we discuss and compare several such\nmethods. Our main finding is that simple variants of the often-overlooked\nAverage Ranking strategy usually outperform other methods tested, covering\nproblems with 5-20 objectives and differing amounts of inter-objective\ncorrelation."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0908.3184v2", 
    "other_authors": "Krishna Chaithanya Lingashetty", 
    "title": "Location of Single Neuron Memories in a Hebbian Network", 
    "arxiv-id": "0908.3184v2", 
    "author": "Krishna Chaithanya Lingashetty", 
    "publish": "2009-08-21T19:53:54Z", 
    "summary": "This paper reports the results of an experiment on the use of Kak's B-Matrix\napproach to spreading activity in a Hebbian neural network. Specifically, it\nconcentrates on the memory retrieval from single neurons and compares the\nperformance of the B-Matrix approach to that of the traditional approach."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0910.0646v1", 
    "other_authors": "Gerard Briscoe, Suzanne Sadedin", 
    "title": "Digital Business Ecosystems: Natural Science Paradigms", 
    "arxiv-id": "0910.0646v1", 
    "author": "Suzanne Sadedin", 
    "publish": "2009-10-04T22:09:18Z", 
    "summary": "A primary motivation for research in Digital Ecosystems is the desire to\nexploit the self-organising properties of natural ecosystems. Ecosystems arc\nthought to be robust, scalable architectures that can automatically solve\ncomplex, dynamic problems. However, the biological processes that contribute to\nthese properties have not been made explicit in Digital Ecosystem research.\nHere, we introduce how biological properties contribute to the self-organising\nfeatures of natural ecosystems. These properties include populations of\nevolving agents, a complex dynamic environment, and spatial distributions which\ngenerate local interactions. The potential for exploiting these properties in\nartificial systems is then considered."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0912.0936v1", 
    "other_authors": "F. F. Paes, H. F. Campos Velho", 
    "title": "Neural-estimator for the surface emission rate of atmospheric gases", 
    "arxiv-id": "0912.0936v1", 
    "author": "H. F. Campos Velho", 
    "publish": "2009-12-04T21:33:10Z", 
    "summary": "The emission rate of minority atmospheric gases is inferred by a new approach\nbased on neural networks. The neural network applied is the multi-layer\nperceptron with backpropagation algorithm for learning. The identification of\nthese surface fluxes is an inverse problem. A comparison between the new\nneural-inversion and regularized inverse solution id performed. The results\nobtained from the neural networks are significantly better. In addition, the\ninversion with the neural netwroks is fster than regularized approaches, after\ntraining."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0912.2310v1", 
    "other_authors": "Vincy Joseph, Shalini Bhatia", 
    "title": "NeuralNetwork Based 3D Surface Reconstruction", 
    "arxiv-id": "0912.2310v1", 
    "author": "Shalini Bhatia", 
    "publish": "2009-12-11T18:40:06Z", 
    "summary": "This paper proposes a novel neural-network-based adaptive hybrid-reflectance\nthree-dimensional (3-D) surface reconstruction model. The neural network\ncombines the diffuse and specular components into a hybrid model. The proposed\nmodel considers the characteristics of each point and the variant albedo to\nprevent the reconstructed surface from being distorted. The neural network\ninputs are the pixel values of the two-dimensional images to be reconstructed.\nThe normal vectors of the surface can then be obtained from the output of the\nneural network after supervised learning, where the illuminant direction does\nnot have to be known in advance. Finally, the obtained normal vectors can be\napplied to integration method when reconstructing 3-D objects. Facial images\nwere used for training in the proposed approach"
},{
    "category": "cs.NE", 
    "doi": "10.1145/1389095.1389204", 
    "link": "http://arxiv.org/pdf/0912.3960v2", 
    "other_authors": "M. Mary Linda, N. Kesavan Nair", 
    "title": "Optimal Design of Fuzzy Based Power System Stabilizer Self Tuned by   Robust Search Algorithm", 
    "arxiv-id": "0912.3960v2", 
    "author": "N. Kesavan Nair", 
    "publish": "2009-12-20T02:21:40Z", 
    "summary": "In the interconnected power system network, instability problems are caused\nmainly by the low frequency oscillations of 0.2 to 2.5 Hz. The supplementary\ncontrol signal in addition with AVR and high gain excitation systems are\nprovided by means of Power System Stabilizer (PSS). Conventional power system\nstabilizers provide effective damping only on a particular operating point. But\nfuzzy based PSS provides good damping for a wide range of operating points. The\nbottlenecks faced in designing a fuzzy logic controller can be minimized by\nusing appropriate optimization techniques like Genetic Algorithm, Particle Swam\nOptimization, Ant Colony Optimization etc.In this paper the membership\nfunctions of FLC are optimized by the new breed optimization technique called\nGenetic Algorithm. This design methodology is implemented on a Single Machine\nInfinite Bus (SMIB) system. Simulation results on SMIB show the effectiveness\nand robustness of the proposed PSS over a wide range of operating conditions\nand system configurations."
},{
    "category": "cs.NE", 
    "doi": "10.4229/24thEUPVSEC2009-5BV.2.35", 
    "link": "http://arxiv.org/pdf/1001.2097v1", 
    "other_authors": "Cyril Voyant, Marc Muselli, Christophe Paoli, Marie Laure Nivet, Philippe Poggi, P. Haurant", 
    "title": "Predictability of PV power grid performance on insular sites without   weather stations: use of artificial neural networks", 
    "arxiv-id": "1001.2097v1", 
    "author": "P. Haurant", 
    "publish": "2010-01-13T08:11:12Z", 
    "summary": "The official meteorological network is poor on the island of Corsica: only\nthree sites being about 50 km apart are equipped with pyranometers which enable\nmeasurements by hourly and daily step. These sites are Ajaccio (41\\degree 55'N\nand 8\\degree 48'E, seaside), Bastia (42\\degree 33'N, 9\\degree 29'E, seaside)\nand Corte (42\\degree 30'N, 9\\degree 15'E average altitude of 486 meters). This\nlack of weather station makes difficult the predictability of PV power grid\nperformance. This work intends to study a methodology which can predict global\nsolar irradiation using data available from another location for daily and\nhourly horizon. In order to achieve this prediction, we have used Artificial\nNeural Network which is a popular artificial intelligence technique in the\nforecasting domain. A simulator has been obtained using data available for the\nstation of Ajaccio that is the only station for which we have a lot of data: 16\nyears from 1972 to 1987. Then we have tested the efficiency of this simulator\nin two places with different geographical features: Corte, a mountainous region\nand Bastia, a coastal region. On daily horizon, the relocation has implied\nfewer errors than a \"na\\\"ive\" prediction method based on the persistence\n(RMSE=1468 Vs 1383Wh/m^2 to Bastia and 1325 Vs 1213Wh/m^2 to Corte). On hourly\ncase, the results were still satisfactory, and widely better than persistence\n(RMSE=138.8 Vs 109.3 Wh/m^2 to Bastia and 135.1 Vs 114.7 Wh/m^2 to Corte). The\nlast experiment was to evaluate the accuracy of our simulator on a PV power\ngrid localized at 10 km from the station of Ajaccio. We got errors very\nsuitable (nRMSE=27.9%, RMSE=99.0 W.h) compared to those obtained with the\npersistence (nRMSE=42.2%, RMSE=149.7 W.h)."
},{
    "category": "cs.NE", 
    "doi": "10.4229/24thEUPVSEC2009-5BV.2.35", 
    "link": "http://arxiv.org/pdf/1001.3491v1", 
    "other_authors": "P. R. Sujin, T. Ruban Deva Prakash, M. Mary Linda", 
    "title": "Particle Swarm Optimization Based Reactive Power Optimization", 
    "arxiv-id": "1001.3491v1", 
    "author": "M. Mary Linda", 
    "publish": "2010-01-20T07:57:02Z", 
    "summary": "Reactive power plays an important role in supporting the real power transfer\nby maintaining voltage stability and system reliability. It is a critical\nelement for a transmission operator to ensure the reliability of an electric\nsystem while minimizing the cost associated with it. The traditional objectives\nof reactive power dispatch are focused on the technical side of reactive\nsupport such as minimization of transmission losses. Reactive power cost\ncompensation to a generator is based on the incurred cost of its reactive power\ncontribution less the cost of its obligation to support the active power\ndelivery. In this paper an efficient Particle Swarm Optimization (PSO) based\nreactive power optimization approach is presented. The optimal reactive power\ndispatch problem is a nonlinear optimization problem with several constraints.\nThe objective of the proposed PSO is to minimize the total support cost from\ngenerators and reactive compensators. It is achieved by maintaining the whole\nsystem power loss as minimum thereby reducing cost allocation. The purpose of\nreactive power dispatch is to determine the proper amount and location of\nreactive support. Reactive Optimal Power Flow (ROPF) formulation is developed\nas an analysis tool and the validity of proposed method is examined using an\nIEEE-14 bus system."
},{
    "category": "cs.NE", 
    "doi": "10.4229/24thEUPVSEC2009-5BV.2.35", 
    "link": "http://arxiv.org/pdf/1001.3741v1", 
    "other_authors": "Soumitra Paul, Kunal Kapoor, Devashish Jasani, Rachit Dudhwewala, Vijay Bore Gowda, T. R. Gopalakrishnan Nair", 
    "title": "Application of Artificial Neural Networks in Aircraft Maintenance,   Repair and Overhaul Solutions", 
    "arxiv-id": "1001.3741v1", 
    "author": "T. R. Gopalakrishnan Nair", 
    "publish": "2010-01-21T08:36:23Z", 
    "summary": "This paper reviews application of Artificial Neural Networks in Aircraft\nMaintenance, Repair and Overhaul (MRO). MRO solutions are designed to\nfacilitate the authoring and delivery of maintenance and repair information to\nthe line maintenance technicians who need to improve aircraft repair turn\naround time, optimize the efficiency and consistency of fleet maintenance and\nensure regulatory compliance. The technical complexity of aircraft systems,\nespecially in avionics, has increased to the point at which it poses a\nsignificant troubleshotting and repair challenge for MRO personnel. As per the\nexisting scenario, the MRO systems in place are inefficient. In this paper, we\npropose the centralization and integration of the MRO database to increase its\nefficiency. Moreover the implementation of Artificial Neural Networks in this\nsystem can rid the system of many of its deficiencies. In order to make the\nsystem more efficient we propose to integrate all the modules so as to reduce\nthe efficacy of repair."
},{
    "category": "cs.NE", 
    "doi": "10.4229/24thEUPVSEC2009-5BV.2.35", 
    "link": "http://arxiv.org/pdf/1002.1164v1", 
    "other_authors": "A. K. Ojha, Dushmanta Mallick, C. Mallick", 
    "title": "Existence and Global Logarithmic Stability of Impulsive Neural Networks   with Time Delay", 
    "arxiv-id": "1002.1164v1", 
    "author": "C. Mallick", 
    "publish": "2010-02-05T09:20:51Z", 
    "summary": "The stability and convergence of the neural networks are the fundamental\ncharacteristics in the Hopfield type networks. Since time delay is ubiquitous\nin most physical and biological systems, more attention is being made for the\ndelayed neural networks. The inclusion of time delay into a neural model is\nnatural due to the finite transmission time of the interactions. The stability\nanalysis of the neural networks depends on the Lyapunov function and hence it\nmust be constructed for the given system. In this paper we have made an attempt\nto establish the logarithmic stability of the impulsive delayed neural networks\nby constructing suitable Lyapunov function."
},{
    "category": "cs.NE", 
    "doi": "10.4229/24thEUPVSEC2009-5BV.2.35", 
    "link": "http://arxiv.org/pdf/1002.1176v1", 
    "other_authors": "Boufeldja Kadri, Miloud Boussahla, Fethi Tarik Bendimerad", 
    "title": "Phase-Only Planar Antenna Array Synthesis with Fuzzy Genetic Algorithms", 
    "arxiv-id": "1002.1176v1", 
    "author": "Fethi Tarik Bendimerad", 
    "publish": "2010-02-05T10:08:22Z", 
    "summary": "This paper describes a new method for the synthesis of planar antenna arrays\nusing fuzzy genetic algorithms (FGAs) by optimizing phase excitation\ncoefficients to best meet a desired radiation pattern. We present the\napplication of a rigorous optimization technique based on fuzzy genetic\nalgorithms (FGAs), the optimizing algorithm is obtained by adjusting control\nparameters of a standard version of genetic algorithm (SGAs) using a fuzzy\ncontroller (FLC) depending on the best individual fitness and the population\ndiversity measurements (PDM). The presented optimization algorithms were\npreviously checked on specific mathematical test function and show their\nsuperior capabilities with respect to the standard version (SGAs). A planar\narray with rectangular cells using a probe feed is considered. Included example\nusing FGA demonstrates the good agreement between the desired and calculated\nradiation patterns than those obtained by a SGA."
},{
    "category": "cs.NE", 
    "doi": "10.4229/24thEUPVSEC2009-5BV.2.35", 
    "link": "http://arxiv.org/pdf/1002.1184v1", 
    "other_authors": "R. Shivakumar, R. Lakshmipathi", 
    "title": "Implementation of an Innovative Bio Inspired GA and PSO Algorithm for   Controller design considering Steam GT Dynamics", 
    "arxiv-id": "1002.1184v1", 
    "author": "R. Lakshmipathi", 
    "publish": "2010-02-05T10:27:13Z", 
    "summary": "The Application of Bio Inspired Algorithms to complicated Power System\nStability Problems has recently attracted the researchers in the field of\nArtificial Intelligence. Low frequency oscillations after a disturbance in a\nPower system, if not sufficiently damped, can drive the system unstable. This\npaper provides a systematic procedure to damp the low frequency oscillations\nbased on Bio Inspired Genetic (GA) and Particle Swarm Optimization (PSO)\nalgorithms. The proposed controller design is based on formulating a System\nDamping ratio enhancement based Optimization criterion to compute the optimal\ncontroller parameters for better stability. The Novel and contrasting feature\nof this work is the mathematical modeling and simulation of the Synchronous\ngenerator model including the Steam Governor Turbine (GT) dynamics. To show the\nrobustness of the proposed controller, Non linear Time domain simulations have\nbeen carried out under various system operating conditions. Also, a detailed\nComparative study has been done to show the superiority of the Bio inspired\nalgorithm based controllers over the Conventional Lead lag controller."
},{
    "category": "cs.NE", 
    "doi": "10.4229/24thEUPVSEC2009-5BV.2.35", 
    "link": "http://arxiv.org/pdf/1002.2012v1", 
    "other_authors": "Nuno Alves", 
    "title": "Implementing Genetic Algorithms on Arduino Micro-Controllers", 
    "arxiv-id": "1002.2012v1", 
    "author": "Nuno Alves", 
    "publish": "2010-02-10T01:16:21Z", 
    "summary": "Since their conception in 1975, Genetic Algorithms have been an extremely\npopular approach to find exact or approximate solutions to optimization and\nsearch problems. Over the last years there has been an enhanced interest in the\nfield with related techniques, such as grammatical evolution, being developed.\nUnfortunately, work on developing genetic optimizations for low-end embedded\narchitectures hasn't embraced the same enthusiasm. This short paper tackles\nthat situation by demonstrating how genetic algorithms can be implemented in\nArduino Duemilanove, a 16 MHz open-source micro-controller, with limited\ncomputation power and storage resources. As part of this short paper, the\nlibraries used in this implementation are released into the public domain under\na GPL license."
},{
    "category": "cs.NE", 
    "doi": "10.4229/24thEUPVSEC2009-5BV.2.35", 
    "link": "http://arxiv.org/pdf/1002.2195v1", 
    "other_authors": "S. Narmadha, Dr. V. Selladurai, G. Sathish", 
    "title": "Multi Product Inventory Optimization using Uniform Crossover Genetic   Algorithm", 
    "arxiv-id": "1002.2195v1", 
    "author": "G. Sathish", 
    "publish": "2010-02-10T20:00:15Z", 
    "summary": "Inventory management is considered to be an important field in Supply Chain\nManagement because the cost of inventories in a supply chain accounts for about\n30 percent of the value of the product. The service provided to the customer\neventually gets enhanced once the efficient and effective management of\ninventory is carried out all through the supply chain. The precise estimation\nof optimal inventory is essential since shortage of inventory yields to lost\nsales, while excess of inventory may result in pointless storage costs. Thus\nthe determination of the inventory to be held at various levels in a supply\nchain becomes inevitable so as to ensure minimal cost for the supply chain. The\nminimization of the total supply chain cost can only be achieved when\noptimization of the base stock level is carried out at each member of the\nsupply chain. This paper deals with the problem of determination of base stock\nlevels in a ten member serial supply chain with multiple products produced by\nfactories using Uniform Crossover Genetic Algorithms. The complexity of the\nproblem increases when more distribution centers and agents and multiple\nproducts were involved. These considerations leading to very complex inventory\nmanagement process has been resolved in this work."
},{
    "category": "cs.NE", 
    "doi": "10.4229/24thEUPVSEC2009-5BV.2.35", 
    "link": "http://arxiv.org/pdf/1002.2196v1", 
    "other_authors": "S. Narmadha, Dr. V. Selladurai, G. Sathish", 
    "title": "Efficient Inventory Optimization of Multi Product, Multiple Suppliers   with Lead Time using PSO", 
    "arxiv-id": "1002.2196v1", 
    "author": "G. Sathish", 
    "publish": "2010-02-10T20:03:20Z", 
    "summary": "With information revolution, increased globalization and competition, supply\nchain has become longer and more complicated than ever before. These\ndevelopments bring supply chain management to the forefront of the managements\nattention. Inventories are very important in a supply chain. The total\ninvestment in inventories is enormous, and the management of inventory is\ncrucial to avoid shortages or delivery delays for the customers and serious\ndrain on a companys financial resources. The supply chain cost increases\nbecause of the influence of lead times for supplying the stocks as well as the\nraw materials. Practically, the lead times will not be same through out all the\nperiods. Maintaining abundant stocks in order to avoid the impact of high lead\ntime increases the holding cost. Similarly, maintaining fewer stocks because of\nballpark lead time may lead to shortage of stocks. This also happens in the\ncase of lead time involved in supplying raw materials. A better optimization\nmethodology that utilizes the Particle Swarm Optimization algorithm, one of the\nbest optimization algorithms, is proposed to overcome the impasse in\nmaintaining the optimal stock levels in each member of the supply chain. Taking\ninto account the stock levels thus obtained from the proposed methodology, an\nappropriate stock levels to be maintained in the approaching periods that will\nminimize the supply chain inventory cost can be arrived at."
},{
    "category": "cs.NE", 
    "doi": "10.4229/24thEUPVSEC2009-5BV.2.35", 
    "link": "http://arxiv.org/pdf/1002.4004v1", 
    "other_authors": "Manoj Kumar Singh", 
    "title": "Nature inspired artificial intelligence based adaptive traffic flow   distribution in computer network", 
    "arxiv-id": "1002.4004v1", 
    "author": "Manoj Kumar Singh", 
    "publish": "2010-02-21T19:41:45Z", 
    "summary": "Because of the stochastic nature of traffic requirement matrix, it is very\ndifficult to get the optimal traffic distribution to minimize the delay even\nwith adaptive routing protocol in a fixed connection network where capacity\nalready defined for each link. Hence there is a requirement to define such a\nmethod, which could generate the optimal solution very quickly and efficiently.\nThis paper presenting a new concept to provide the adaptive optimal traffic\ndistribution for dynamic condition of traffic matrix using nature based\nintelligence methods. With the defined load and fixed capacity of links,\naverage delay for packet has minimized with various variations of evolutionary\nprogramming and particle swarm optimization. Comparative study has given over\ntheir performance in terms of converging speed. Universal approximation\ncapability, the key feature of feed forward neural network has applied to\npredict the flow distribution on each link to minimize the average delay for a\ntotal load available at present on the network. For any variation in the total\nload, the new flow distribution can be generated by neural network immediately,\nwhich could generate minimum delay in the network. With the inclusion of this\ninformation, performance of routing protocol will be improved very much."
},{
    "category": "cs.NE", 
    "doi": "10.4229/24thEUPVSEC2009-5BV.2.35", 
    "link": "http://arxiv.org/pdf/1002.4831v1", 
    "other_authors": "F. A. Al-Zahrani, H. M. Mustafa, A. Al-Hamadi", 
    "title": "On Analysis and Evaluation of Multi-Sensory Cognitive Learning of a   Mathematical Topic Using Artificial Neural Networks", 
    "arxiv-id": "1002.4831v1", 
    "author": "A. Al-Hamadi", 
    "publish": "2010-02-25T17:15:50Z", 
    "summary": "This piece of research belongs to the field of educational assessment issue\nbased upon the cognitive multimedia theory. Considering that theory; visual and\nauditory material should be presented simultaneously to reinforce the retention\nof a mathematical learned topic, a carefully computer-assisted learning (CAL)\nmodule is designed for development of a multimedia tutorial for our suggested\nmathematical topic. The designed CAL module is a multimedia tutorial computer\npackage with visual and/or auditory material. So, via suggested computer\npackage, Multi-Sensory associative memories and classical conditioning theories\nare practically applicable at an educational field (a children classroom). It\nis noticed that comparative practical results obtained are interesting for\nfield application of CAL package with and without associated teacher's voice.\nFinally, the presented study highly recommends application of a novel teaching\ntrend aiming to improve quality of children mathematical learning performance."
},{
    "category": "cs.NE", 
    "doi": "10.4229/24thEUPVSEC2009-5BV.2.35", 
    "link": "http://arxiv.org/pdf/1003.1457v2", 
    "other_authors": "Reza Gharoie Ahangar, Mahmood Yahyazadehfar, Hassan Pournaghshband", 
    "title": "The Comparison of Methods Artificial Neural Network with Linear   Regression Using Specific Variables for Prediction Stock Price in Tehran   Stock Exchange", 
    "arxiv-id": "1003.1457v2", 
    "author": "Hassan Pournaghshband", 
    "publish": "2010-03-07T12:05:22Z", 
    "summary": "In this paper, researchers estimated the stock price of activated companies\nin Tehran (Iran) stock exchange. It is used Linear Regression and Artificial\nNeural Network methods and compared these two methods. In Artificial Neural\nNetwork, of General Regression Neural Network method (GRNN) for architecture is\nused. In this paper, first, researchers considered 10 macro economic variables\nand 30 financial variables and then they obtained seven final variables\nincluding 3 macro economic variables and 4 financial variables to estimate the\nstock price using Independent components Analysis (ICA). So, we presented an\nequation for two methods and compared their results which shown that artificial\nneural network method is more efficient than linear regression method."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1004.0514v1", 
    "other_authors": "Sisir Koppaka, Ashish Ranjan Hota", 
    "title": "Superior Exploration-Exploitation Balance with Quantum-Inspired Hadamard   Walks", 
    "arxiv-id": "1004.0514v1", 
    "author": "Ashish Ranjan Hota", 
    "publish": "2010-04-04T15:38:48Z", 
    "summary": "This paper extends the analogies employed in the development of\nquantum-inspired evolutionary algorithms by proposing quantum-inspired Hadamard\nwalks, called QHW. A novel quantum-inspired evolutionary algorithm, called\nHQEA, for solving combinatorial optimization problems, is also proposed. The\nnovelty of HQEA lies in it's incorporation of QHW Remote Search and QHW Local\nSearch - the quantum equivalents of classical mutation and local search, that\nthis paper defines. The intuitive reasoning behind this approach, and the\nexploration-exploitation balance thus occurring is explained. From the results\nof the experiments carried out on the 0,1-knapsack problem, HQEA performs\nsignificantly better than a conventional genetic algorithm, CGA, and two\nquantum-inspired evolutionary algorithms - QEA and NQEA, in terms of\nconvergence speed and accuracy."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1004.3557v1", 
    "other_authors": "Eva Volna", 
    "title": "Neuroevolutionary optimization", 
    "arxiv-id": "1004.3557v1", 
    "author": "Eva Volna", 
    "publish": "2010-04-20T20:17:41Z", 
    "summary": "This paper presents an application of evolutionary search procedures to\nartificial neural networks. Here, we can distinguish among three kinds of\nevolution in artificial neural networks, i.e. the evolution of connection\nweights, of architectures, and of learning rules. We review each kind of\nevolution in detail and analyse critical issues related to different\nevolutions. This article concentrates on finding the suitable way of using\nevolutionary algorithms for optimizing the artificial neural network\nparameters."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1004.3725v1", 
    "other_authors": "Manabu Kitagata, Jun-ichi Inoue", 
    "title": "A Gibbs distribution that learns from GA dynamics", 
    "arxiv-id": "1004.3725v1", 
    "author": "Jun-ichi Inoue", 
    "publish": "2010-04-21T15:24:02Z", 
    "summary": "A general procedure of average-case performance evaluation for population\ndynamics such as genetic algorithms (GAs) is proposed and its validity is\nnumerically examined. We introduce a learning algorithm of Gibbs distributions\nfrom training sets which are gene configurations (strings) generated by GA in\norder to figure out the statistical properties of GA from the view point of\nthermodynamics. The learning algorithm is constructed by means of minimization\nof the Kullback-Leibler information between a parametric Gibbs distribution and\nthe empirical distribution of gene configurations. The formulation is applied\nto the solvable probabilistic models having multi-valley energy landscapes,\nnamely, the spin glass chain and the Sherrington-Kirkpatrick model. By using\ncomputer simulations, we discuss the asymptotic behaviour of the effective\ntemperature scheduling and the residual energy induced by the GA dynamics."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1004.4610v1", 
    "other_authors": "Heni Kaaniche, Farouk Kamoun", 
    "title": "Mobility Prediction in Wireless Ad Hoc Networks using Neural Networks", 
    "arxiv-id": "1004.4610v1", 
    "author": "Farouk Kamoun", 
    "publish": "2010-04-26T19:18:48Z", 
    "summary": "Mobility prediction allows estimating the stability of paths in a mobile\nwireless Ad Hoc networks. Identifying stable paths helps to improve routing by\nreducing the overhead and the number of connection interruptions. In this\npaper, we introduce a neural network based method for mobility prediction in Ad\nHoc networks. This method consists of a multi-layer and recurrent neural\nnetwork using back propagation through time algorithm for training."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1006.0448v1", 
    "other_authors": "Karo Gregor, Yann LeCun", 
    "title": "Emergence of Complex-Like Cells in a Temporal Product Network with Local   Receptive Fields", 
    "arxiv-id": "1006.0448v1", 
    "author": "Yann LeCun", 
    "publish": "2010-06-02T17:08:29Z", 
    "summary": "We introduce a new neural architecture and an unsupervised algorithm for\nlearning invariant representations from temporal sequence of images. The system\nuses two groups of complex cells whose outputs are combined multiplicatively:\none that represents the content of the image, constrained to be constant over\nseveral consecutive frames, and one that represents the precise location of\nfeatures, which is allowed to vary over time but constrained to be sparse. The\narchitecture uses an encoder to extract features, and a decoder to reconstruct\nthe input from the features. The method was applied to patches extracted from\nconsecutive movie frames and produces orientation and frequency selective units\nanalogous to the complex cells in V1. An extension of the method is proposed to\ntrain a network composed of units with local receptive field spread over a\nlarge image of arbitrary size. A layer of complex cells, subject to sparsity\nconstraints, pool feature units over overlapping local neighborhoods, which\ncauses the feature units to organize themselves into pinwheel patterns of\norientation-selective receptive fields, similar to those observed in the\nmammalian visual cortex. A feed-forward encoder efficiently computes the\nfeature representation of full images."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1006.1543v1", 
    "other_authors": "Raajay Viswanathan, P. S. Sastry, K. P. Unnikrishnan", 
    "title": "Efficient Discovery of Large Synchronous Events in Neural Spike Streams", 
    "arxiv-id": "1006.1543v1", 
    "author": "K. P. Unnikrishnan", 
    "publish": "2010-06-08T13:03:45Z", 
    "summary": "We address the problem of finding patterns from multi-neuronal spike trains\nthat give us insights into the multi-neuronal codes used in the brain and help\nus design better brain computer interfaces. We focus on the synchronous firings\nof groups of neurons as these have been shown to play a major role in coding\nand communication. With large electrode arrays, it is now possible to\nsimultaneously record the spiking activity of hundreds of neurons over large\nperiods of time. Recently, techniques have been developed to efficiently count\nthe frequency of synchronous firing patterns. However, when the number of\nneurons being observed grows they suffer from the combinatorial explosion in\nthe number of possible patterns and do not scale well. In this paper, we\npresent a temporal data mining scheme that overcomes many of these problems. It\ngenerates a set of candidate patterns from frequent patterns of smaller size;\nall possible patterns are not counted. Also we count only a certain well\ndefined subset of occurrences and this makes the process more efficient. We\nhighlight the computational advantage that this approach offers over the\nexisting methods through simulations.\n  We also propose methods for assessing the statistical significance of the\ndiscovered patterns. We detect only those patterns that repeat often enough to\nbe significant and thus be able to automatically fix the threshold for the\ndata-mining application. Finally we discuss the usefulness of these methods for\nbrain computer interfaces."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1006.4754v1", 
    "other_authors": "Krishna Chaithanya Lingashetty", 
    "title": "Active Sites model for the B-Matrix Approach", 
    "arxiv-id": "1006.4754v1", 
    "author": "Krishna Chaithanya Lingashetty", 
    "publish": "2010-06-24T11:28:30Z", 
    "summary": "This paper continues on the work of the B-Matrix approach in hebbian learning\nproposed by Dr. Kak. It reports the results on methods of improving the memory\nretrieval capacity of the hebbian neural network which implements the B-Matrix\napproach. Previously, the approach to retrieving the memories from the network\nwas to clamp all the individual neurons separately and verify the integrity of\nthese memories. Here we present a network with the capability to identify the\n\"active sites\" in the network during the training phase and use these \"active\nsites\" to generate the memories retrieved from these neurons. Three methods are\nproposed for obtaining the update order of the network from the proximity\nmatrix when multiple neurons are to be clamped. We then present a comparison\nbetween the new methods to the classical case and also among the methods\nthemselves."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1009.0915v1", 
    "other_authors": "Lorentz J\u00e4ntschi, Sorana D. Bolboac{\\ba}, Mugur C. B\u0103lan, Radu E. Sestra\u015f", 
    "title": "Results of Evolution Supervised by Genetic Algorithms", 
    "arxiv-id": "1009.0915v1", 
    "author": "Radu E. Sestra\u015f", 
    "publish": "2010-09-05T13:17:01Z", 
    "summary": "A series of results of evolution supervised by genetic algorithms with\ninterest to agricultural and horticultural fields are reviewed. New obtained\noriginal results from the use of genetic algorithms on structure-activity\nrelationships are reported."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1009.1513v2", 
    "other_authors": "Onay Urfalioglu, Orhan Arikan", 
    "title": "Artificial Neural Networks, Symmetries and Differential Evolution", 
    "arxiv-id": "1009.1513v2", 
    "author": "Orhan Arikan", 
    "publish": "2010-09-08T12:33:03Z", 
    "summary": "Neuroevolution is an active and growing research field, especially in times\nof increasingly parallel computing architectures. Learning methods for\nArtificial Neural Networks (ANN) can be divided into two groups. Neuroevolution\nis mainly based on Monte-Carlo techniques and belongs to the group of global\nsearch methods, whereas other methods such as backpropagation belong to the\ngroup of local search methods. ANN's comprise important symmetry properties,\nwhich can influence Monte-Carlo methods. On the other hand, local search\nmethods are generally unaffected by these symmetries. In the literature,\ndealing with the symmetries is generally reported as being not effective or\neven yielding inferior results. In this paper, we introduce the so called\nMinimum Global Optimum Proximity principle derived from theoretical\nconsiderations for effective symmetry breaking, applied to offline supervised\nlearning. Using Differential Evolution (DE), which is a popular and robust\nevolutionary global optimization method, we experimentally show significant\nglobal search efficiency improvements by symmetry breaking."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1009.4318v1", 
    "other_authors": "Mst. Farhana Rahman, S. M. Masud Karim, Kazi Shah Nawaz Ripon, Md. Iqbal Hossain Suvo", 
    "title": "Performance Analysis of Estimation of Distribution Algorithm and Genetic   Algorithm in Zone Routing Protocol", 
    "arxiv-id": "1009.4318v1", 
    "author": "Md. Iqbal Hossain Suvo", 
    "publish": "2010-09-22T10:14:31Z", 
    "summary": "In this paper, Estimation of Distribution Algorithm (EDA) is used for Zone\nRouting Protocol (ZRP) in Mobile Ad-hoc Network (MANET) instead of Genetic\nAlgorithm (GA). It is an evolutionary approach, and used when the network size\ngrows and the search space increases. When the destination is outside the zone,\nEDA is applied to find the route with minimum cost and time. The implementation\nof proposed method is compared with Genetic ZRP, i.e., GZRP and the result\ndemonstrates better performance for the proposed method. Since the method\nprovides a set of paths to the destination, it results in load balance to the\nnetwork. As both EDA and GA use random search method to reach the optimal\npoint, the searching cost reduced significantly, especially when the number of\ndata is large."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1009.4495v1", 
    "other_authors": "Subhash Kak", 
    "title": "Unary Coding for Neural Network Learning", 
    "arxiv-id": "1009.4495v1", 
    "author": "Subhash Kak", 
    "publish": "2010-09-22T22:32:37Z", 
    "summary": "This paper presents some properties of unary coding of significance for\nbiological learning and instantaneously trained neural networks."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1009.4564v1", 
    "other_authors": "Abu Bakar Siddiquee, Md. Ehsanul Hoque Mazumder, S. M. Kamruzzaman", 
    "title": "A Constructive Algorithm for Feedforward Neural Networks for Medical   Diagnostic Reasoning", 
    "arxiv-id": "1009.4564v1", 
    "author": "S. M. Kamruzzaman", 
    "publish": "2010-09-23T10:25:04Z", 
    "summary": "This research is to search for alternatives to the resolution of complex\nmedical diagnosis where human knowledge should be apprehended in a general\nfashion. Successful application examples show that human diagnostic\ncapabilities are significantly worse than the neural diagnostic system. Our\nresearch describes a constructive neural network algorithm with\nbackpropagation; offer an approach for the incremental construction of\nnearminimal neural network architectures for pattern classification. The\nalgorithm starts with minimal number of hidden units in the single hidden\nlayer; additional units are added to the hidden layer one at a time to improve\nthe accuracy of the network and to get an optimal size of a neural network. Our\nalgorithm was tested on several benchmarking classification problems including\nCancer1, Heart, and Diabetes with good generalization ability."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1009.4566v1", 
    "other_authors": "S. M. Kamruzzaman, Md. Monirul Islam", 
    "title": "An Algorithm to Extract Rules from Artificial Neural Networks for   Medical Diagnosis Problems", 
    "arxiv-id": "1009.4566v1", 
    "author": "Md. Monirul Islam", 
    "publish": "2010-09-23T10:30:55Z", 
    "summary": "Artificial neural networks (ANNs) have been successfully applied to solve a\nvariety of classification and function approximation problems. Although ANNs\ncan generally predict better than decision trees for pattern classification\nproblems, ANNs are often regarded as black boxes since their predictions cannot\nbe explained clearly like those of decision trees. This paper presents a new\nalgorithm, called rule extraction from ANNs (REANN), to extract rules from\ntrained ANNs for medical diagnosis problems. A standard three-layer feedforward\nANN with four-phase training is the basis of the proposed algorithm. In the\nfirst phase, the number of hidden nodes in ANNs is determined automatically by\na constructive algorithm. In the second phase, irrelevant connections and input\nnodes are removed from trained ANNs without sacrificing the predictive accuracy\nof ANNs. The continuous activation values of the hidden nodes are discretized\nby using an efficient heuristic clustering algorithm in the third phase.\nFinally, rules are extracted from compact ANNs by examining the discretized\nactivation values of the hidden nodes. Extensive experimental studies on three\nbenchmark classification problems, i.e. breast cancer, diabetes and lenses,\ndemonstrate that REANN can generate high quality rules from ANNs, which are\ncomparable with other methods in terms of number of rules, average number of\nconditions for a rule, and predictive accuracy."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1009.4570v1", 
    "other_authors": "S. M. Kamruzzaman, Md. Monirul Islam", 
    "title": "Extraction of Symbolic Rules from Artificial Neural Networks", 
    "arxiv-id": "1009.4570v1", 
    "author": "Md. Monirul Islam", 
    "publish": "2010-09-23T10:37:54Z", 
    "summary": "Although backpropagation ANNs generally predict better than decision trees do\nfor pattern classification problems, they are often regarded as black boxes,\ni.e., their predictions cannot be explained as those of decision trees. In many\napplications, it is desirable to extract knowledge from trained ANNs for the\nusers to gain a better understanding of how the networks solve the problems. A\nnew rule extraction algorithm, called rule extraction from artificial neural\nnetworks (REANN) is proposed and implemented to extract symbolic rules from\nANNs. A standard three-layer feedforward ANN is the basis of the algorithm. A\nfour-phase training algorithm is proposed for backpropagation learning.\nExplicitness of the extracted rules is supported by comparing them to the\nsymbolic rules generated by other methods. Extracted rules are comparable with\nother methods in terms of number of rules, average number of conditions for a\nrule, and predictive accuracy. Extensive experimental studies on several\nbenchmarks classification problems, such as breast cancer, iris, diabetes, and\nseason classification problems, demonstrate the effectiveness of the proposed\napproach with good generalization ability."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1009.4572v1", 
    "other_authors": "S. M. Kamruzzaman, Ahmed Ryadh Hasan, Abu Bakar Siddiquee, Md. Ehsanul Hoque Mazumder", 
    "title": "Medical diagnosis using neural network", 
    "arxiv-id": "1009.4572v1", 
    "author": "Md. Ehsanul Hoque Mazumder", 
    "publish": "2010-09-23T10:44:24Z", 
    "summary": "This research is to search for alternatives to the resolution of complex\nmedical diagnosis where human knowledge should be apprehended in a general\nfashion. Successful application examples show that human diagnostic\ncapabilities are significantly worse than the neural diagnostic system. This\npaper describes a modified feedforward neural network constructive algorithm\n(MFNNCA), a new algorithm for medical diagnosis. The new constructive algorithm\nwith backpropagation; offer an approach for the incremental construction of\nnear-minimal neural network architectures for pattern classification. The\nalgorithm starts with minimal number of hidden units in the single hidden\nlayer; additional units are added to the hidden layer one at a time to improve\nthe accuracy of the network and to get an optimal size of a neural network. The\nMFNNCA was tested on several benchmarking classification problems including the\ncancer, heart disease and diabetes. Experimental results show that the MFNNCA\ncan produce optimal neural network architecture with good generalization\nability."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1009.4962v1", 
    "other_authors": "S. M. Kamruzzaman", 
    "title": "RGANN: An Efficient Algorithm to Extract Rules from ANNs", 
    "arxiv-id": "1009.4962v1", 
    "author": "S. M. Kamruzzaman", 
    "publish": "2010-09-25T00:59:18Z", 
    "summary": "This paper describes an efficient rule generation algorithm, called rule\ngeneration from artificial neural networks (RGANN) to generate symbolic rules\nfrom ANNs. Classification rules are sought in many areas from automatic\nknowledge acquisition to data mining and ANN rule extraction. This is because\nclassification rules possess some attractive features. They are explicit,\nunderstandable and verifiable by domain experts, and can be modified, extended\nand passed on as modular knowledge. A standard three-layer feedforward ANN is\nthe basis of the algorithm. A four-phase training algorithm is proposed for\nbackpropagation learning. Comparing them to the symbolic rules generated by\nother methods supports explicitness of the generated rules. Generated rules are\ncomparable with other methods in terms of number of rules, average number of\nconditions for a rule, and predictive accuracy. Extensive experimental studies\non several benchmarks classification problems, including breast cancer, wine,\nseason, golf-playing, and lenses classification demonstrate the effectiveness\nof the proposed approach with good generalization ability."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1009.4978v1", 
    "other_authors": "S. M. Kamruzzaman", 
    "title": "Extracting Symbolic Rules for Medical Diagnosis Problem", 
    "arxiv-id": "1009.4978v1", 
    "author": "S. M. Kamruzzaman", 
    "publish": "2010-09-25T06:22:30Z", 
    "summary": "Neural networks (NNs) have been successfully applied to solve a variety of\napplication problems involving classification and function approximation.\nAlthough backpropagation NNs generally predict better than decision trees do\nfor pattern classification problems, they are often regarded as black boxes,\ni.e., their predictions cannot be explained as those of decision trees. In many\napplications, it is desirable to extract knowledge from trained NNs for the\nusers to gain a better understanding of how the networks solve the problems. An\nalgorithm is proposed and implemented to extract symbolic rules for medical\ndiagnosis problem. Empirical study on three benchmarks classification problems,\nsuch as breast cancer, diabetes, and lenses demonstrates that the proposed\nalgorithm generates high quality rules from NNs comparable with other methods\nin terms of number of rules, average number of conditions for a rule, and\npredictive accuracy."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1009.4983v1", 
    "other_authors": "S. M. Kamruzzaman, Ahmed Ryadh Hasan", 
    "title": "Pattern Classification using Simplified Neural Networks", 
    "arxiv-id": "1009.4983v1", 
    "author": "Ahmed Ryadh Hasan", 
    "publish": "2010-09-25T07:00:25Z", 
    "summary": "In recent years, many neural network models have been proposed for pattern\nclassification, function approximation and regression problems. This paper\npresents an approach for classifying patterns from simplified NNs. Although the\npredictive accuracy of ANNs is often higher than that of other methods or human\nexperts, it is often said that ANNs are practically \"black boxes\", due to the\ncomplexity of the networks. In this paper, we have an attempted to open up\nthese black boxes by reducing the complexity of the network. The factor makes\nthis possible is the pruning algorithm. By eliminating redundant weights,\nredundant input and hidden units are identified and removed from the network.\nUsing the pruning algorithm, we have been able to prune networks such that only\na few input units, hidden units and connections left yield a simplified\nnetwork. Experimental results on several benchmarks problems in neural networks\nshow the effectiveness of the proposed approach with good generalization\nability."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1009.4984v1", 
    "other_authors": "S. M. Kamruzzaman, Ahmed Ryadh Hasan", 
    "title": "Rule Extraction using Artificial Neural Networks", 
    "arxiv-id": "1009.4984v1", 
    "author": "Ahmed Ryadh Hasan", 
    "publish": "2010-09-25T07:05:29Z", 
    "summary": "Artificial neural networks have been successfully applied to a variety of\nbusiness application problems involving classification and regression. Although\nbackpropagation neural networks generally predict better than decision trees do\nfor pattern classification problems, they are often regarded as black boxes,\ni.e., their predictions are not as interpretable as those of decision trees. In\nmany applications, it is desirable to extract knowledge from trained neural\nnetworks so that the users can gain a better understanding of the solution.\nThis paper presents an efficient algorithm to extract rules from artificial\nneural networks. We use two-phase training algorithm for backpropagation\nlearning. In the first phase, the number of hidden nodes of the network is\ndetermined automatically in a constructive fashion by adding nodes one after\nanother based on the performance of the network on training data. In the second\nphase, the number of relevant input units of the network is determined using\npruning algorithm. The pruning process attempts to eliminate as many\nconnections as possible from the network. Relevant and irrelevant attributes of\nthe data are distinguished during the training process. Those that are relevant\nwill be kept and others will be automatically discarded. From the simplified\nnetworks having small number of connections and nodes we may easily able to\nextract symbolic rules using the proposed algorithm. Extensive experimental\nresults on several benchmarks problems in neural networks demonstrate the\neffectiveness of the proposed approach with good generalization ability."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1009.4988v1", 
    "other_authors": "S. M. Kamruzzaman", 
    "title": "REx: An Efficient Rule Generator", 
    "arxiv-id": "1009.4988v1", 
    "author": "S. M. Kamruzzaman", 
    "publish": "2010-09-25T07:33:44Z", 
    "summary": "This paper describes an efficient algorithm REx for generating symbolic rules\nfrom artificial neural network (ANN). Classification rules are sought in many\nareas from automatic knowledge acquisition to data mining and ANN rule\nextraction. This is because classification rules possess some attractive\nfeatures. They are explicit, understandable and verifiable by domain experts,\nand can be modified, extended and passed on as modular knowledge. REx exploits\nthe first order information in the data and finds shortest sufficient\nconditions for a rule of a class that can differentiate it from patterns of\nother classes. It can generate concise and perfect rules in the sense that the\nerror rate of the rules is not worse than the inconsistency rate found in the\noriginal data. An important feature of rule extraction algorithm, REx, is its\nrecursive nature. They are concise, comprehensible, order insensitive and do\nnot involve any weight values. Extensive experimental studies on several\nbenchmark classification problems, such as breast cancer, iris, season, and\ngolf-playing, demonstrate the effectiveness of the proposed approach with good\ngeneralization ability."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1009.5031v1", 
    "other_authors": "Imen Harbaoui Dridi, Ryan Kammarti, Mekki Ksouri, Pierre Borne", 
    "title": "A Genetic Algorithm for the Multi-Pickup and Delivery Problem with time   windows", 
    "arxiv-id": "1009.5031v1", 
    "author": "Pierre Borne", 
    "publish": "2010-09-25T19:44:51Z", 
    "summary": "In This paper we present a genetic algorithm for the multi-pickup and\ndelivery problem with time windows (m-PDPTW). The m-PDPTW is an optimization\nvehicles routing problem which must meet requests for transport between\nsuppliers and customers satisfying precedence, capacity and time constraints.\nThis paper purposes a brief literature review of the PDPTW, present our\napproach based on genetic algorithms to minimizing the total travel distance\nand thereafter the total travel cost, by showing that an encoding represents\nthe parameters of each individual."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1010.0771v2", 
    "other_authors": "Imen Harbaoui Dridi, Ryan Kammarti, Mekki Ksouri, Pierre Borne", 
    "title": "Genetic Algorithm for Mulicriteria Optimization of a Multi-Pickup and   Delivery Problem with Time Windows", 
    "arxiv-id": "1010.0771v2", 
    "author": "Pierre Borne", 
    "publish": "2010-10-05T06:01:24Z", 
    "summary": "In This paper we present a genetic algorithm for mulicriteria optimization of\na multipickup and delivery problem with time windows (m-PDPTW). The m-PDPTW is\nan optimization vehicles routing problem which must meet requests for transport\nbetween suppliers and customers satisfying precedence, capacity and time\nconstraints. This paper purposes a brief literature review of the PDPTW,\npresent an approach based on genetic algorithms and Pareto dominance method to\ngive a set of satisfying solutions to the m-PDPTW minimizing total travel cost,\ntotal tardiness time and the vehicles number."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1010.0979v1", 
    "other_authors": "Imen Harbaoui Dridi, Ryan Kammarti, Pierre Borne, Mekki Ksouri", 
    "title": "Un Algorithme g\u00e9n\u00e9tique pour le probl\u00e8me de ramassage et de   livraison avec fen\u00eatres de temps \u00e0 plusieurs v\u00e9hicules", 
    "arxiv-id": "1010.0979v1", 
    "author": "Mekki Ksouri", 
    "publish": "2010-10-05T18:54:43Z", 
    "summary": "The PDPTW is an optimization vehicles routing problem which must meet\nrequests for transport between suppliers and customers satisfying precedence,\ncapacity and time constraints. We present, in this paper, a genetic algorithm\nfor optimization of a multi pickup and delivery problem with time windows\n(m-PDPTW). We purposes a brief literature review of the PDPTW, present an\napproach based on genetic algorithms to give a satisfying solution to the\nm-PDPTW minimizing the total travel cost."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1010.0980v1", 
    "other_authors": "Imen Harbaoui Dridi, Ryan Kammarti, Mekki Ksouri, Pierre Borne", 
    "title": "Approche Multicrit\u00e8re pour le Probl\u00e8me de Ramassage et de Livraison   avec Fen\u00eatres de Temps \u00e0 Plusieurs V\u00e9hicules", 
    "arxiv-id": "1010.0980v1", 
    "author": "Pierre Borne", 
    "publish": "2010-10-05T18:55:13Z", 
    "summary": "Nowadays, the transport goods problem occupies an important place in the\neconomic life of modern societies. The pickup and delivery problem with time\nwindows (PDPTW) is one of the problems which a large part of the research was\ninterested. In this paper, we present a a brief literature review of the VRP\nand the PDPTW, propose our multicriteria approach based on genetic algorithms\nwhich allows minimize the compromise between the vehicles number, the total\ntardiness time and the total travel cost. And this, by treating the case where\na customer can have multiple suppliers and one supplier can have multiple\ncustomers"
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1010.1429v2", 
    "other_authors": "Benjamin Doerr, Thomas Jansen, Dirk Sudholt, Carola Winzen, Christine Zarges", 
    "title": "Optimizing Monotone Functions Can Be Difficult", 
    "arxiv-id": "1010.1429v2", 
    "author": "Christine Zarges", 
    "publish": "2010-10-07T13:21:28Z", 
    "summary": "Extending previous analyses on function classes like linear functions, we\nanalyze how the simple (1+1) evolutionary algorithm optimizes pseudo-Boolean\nfunctions that are strictly monotone. Contrary to what one would expect, not\nall of these functions are easy to optimize. The choice of the constant $c$ in\nthe mutation probability $p(n) = c/n$ can make a decisive difference.\n  We show that if $c < 1$, then the (1+1) evolutionary algorithm finds the\noptimum of every such function in $\\Theta(n \\log n)$ iterations. For $c=1$, we\ncan still prove an upper bound of $O(n^{3/2})$. However, for $c > 33$, we\npresent a strictly monotone function such that the (1+1) evolutionary algorithm\nwith overwhelming probability does not find the optimum within $2^{\\Omega(n)}$\niterations. This is the first time that we observe that a constant factor\nchange of the mutation probability changes the run-time by more than constant\nfactors."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1010.4138v1", 
    "other_authors": "Andr\u00e1s L\u0151rincz, Zsolt Palotai, G\u00e1bor Szirtes", 
    "title": "Sparse and silent coding in neural circuits", 
    "arxiv-id": "1010.4138v1", 
    "author": "G\u00e1bor Szirtes", 
    "publish": "2010-10-20T09:29:03Z", 
    "summary": "Sparse coding algorithms are about finding a linear basis in which signals\ncan be represented by a small number of active (non-zero) coefficients. Such\ncoding has many applications in science and engineering and is believed to play\nan important role in neural information processing. However, due to the\ncomputational complexity of the task, only approximate solutions provide the\nrequired efficiency (in terms of time). As new results show, under particular\nconditions there exist efficient solutions by minimizing the magnitude of the\ncoefficients (`$l_1$-norm') instead of minimizing the size of the active subset\nof features (`$l_0$-norm'). Straightforward neural implementation of these\nsolutions is not likely, as they require \\emph{a priori} knowledge of the\nnumber of active features. Furthermore, these methods utilize iterative\nre-evaluation of the reconstruction error, which in turn implies that final\nsparse forms (featuring `population sparseness') can only be reached through\nthe formation of a series of non-sparse representations, which is in contrast\nwith the overall sparse functioning of the neural systems (`lifetime\nsparseness'). In this article we present a novel algorithm which integrates our\nprevious `$l_0$-norm' model on spike based probabilistic optimization for\nsparse coding with ideas coming from novel `$l_1$-norm' solutions.\n  The resulting algorithm allows neurally plausible implementation and does not\nrequire an exactly defined sparseness level thus it is suitable for\nrepresenting natural stimuli with a varying number of features. We also\ndemonstrate that the combined method significantly extends the domain where\noptimal solutions can be found by `$l_1$-norm' based algorithms."
},{
    "category": "cs.NE", 
    "doi": "10.1145/1830761.1830878", 
    "link": "http://arxiv.org/pdf/1011.0800v1", 
    "other_authors": "P. Bhargavi, S. Jyothi", 
    "title": "Soil Classification Using GATree", 
    "arxiv-id": "1011.0800v1", 
    "author": "S. Jyothi", 
    "publish": "2010-11-03T05:07:02Z", 
    "summary": "This paper details the application of a genetic programming framework for\nclassification of decision tree of Soil data to classify soil texture. The\ndatabase contains measurements of soil profile data. We have applied GATree for\ngenerating classification decision tree. GATree is a decision tree builder that\nis based on Genetic Algorithms (GAs). The idea behind it is rather simple but\npowerful. Instead of using statistic metrics that are biased towards specific\ntrees we use a more flexible, global metric of tree quality that try to\noptimize accuracy and size. GATree offers some unique features not to be found\nin any other tree inducers while at the same time it can produce better results\nfor many difficult problems. Experimental results are presented which\nillustrate the performance of generating best decision tree for classifying\nsoil texture for soil data set."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.artint.2012.01.001", 
    "link": "http://arxiv.org/pdf/1011.4028v4", 
    "other_authors": "Yang Yu, Xin Yao, Zhi-Hua Zhou", 
    "title": "On the approximation ability of evolutionary optimization with   application to minimum set cover", 
    "arxiv-id": "1011.4028v4", 
    "author": "Zhi-Hua Zhou", 
    "publish": "2010-11-17T19:08:42Z", 
    "summary": "Evolutionary algorithms (EAs) are heuristic algorithms inspired by natural\nevolution. They are often used to obtain satisficing solutions in practice. In\nthis paper, we investigate a largely underexplored issue: the approximation\nperformance of EAs in terms of how close the solution obtained is to an optimal\nsolution. We study an EA framework named simple EA with isolated population\n(SEIP) that can be implemented as a single- or multi-objective EA. We analyze\nthe approximation performance of SEIP using the partial ratio, which\ncharacterizes the approximation ratio that can be guaranteed. Specifically, we\nanalyze SEIP using a set cover problem that is NP-hard. We find that in a\nsimple configuration, SEIP efficiently achieves an $H_n$-approximation ratio,\nthe asymptotic lower bound, for the unbounded set cover problem. We also find\nthat SEIP efficiently achieves an $(H_k-\\frac{k-1}/{8k^9})$-approximation\nratio, the currently best-achievable result, for the k-set cover problem.\nMoreover, for an instance class of the k-set cover problem, we disclose how\nSEIP, using either one-bit or bit-wise mutation, can overcome the difficulty\nthat limits the greedy algorithm."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.artint.2012.01.001", 
    "link": "http://arxiv.org/pdf/1011.6022v4", 
    "other_authors": "Gene I. Sher", 
    "title": "DXNN Platform: The Shedding of Biological Inefficiencies", 
    "arxiv-id": "1011.6022v4", 
    "author": "Gene I. Sher", 
    "publish": "2010-11-28T09:10:11Z", 
    "summary": "This paper introduces a novel type of memetic algorithm based Topology and\nWeight Evolving Artificial Neural Network (TWEANN) system called DX Neural\nNetwork (DXNN). DXNN implements a number of interesting features, amongst which\nis: a simple and database friendly tuple based encoding method, a 2 phase\nneuroevolutionary approach aimed at removing the need for speciation due to its\nintrinsic population diversification effects, a new \"Targeted Tuning Phase\"\naimed at dealing with \"the curse of dimensionality\", and a new Random Intensity\nMutation (RIM) method that removes the need for crossover algorithms. The paper\nwill discuss DXNN's architecture, mutation operators, and its built in feature\nselection method that allows for the evolved systems to expand and incorporate\nnew sensors and actuators. I then compare DXNN to other state of the art\nTWEANNs on the standard double pole balancing benchmark, and demonstrate its\nsuperior ability to evolve highly compact solutions faster than its\ncompetitors. Then a set of oblation experiments is performed to demonstrate how\neach feature of DXNN effects its performance, followed by a set of experiments\nwhich demonstrate the platform's ability to create NN populations with\nexceptionally high diversity profiles. Finally, DXNN is used to evolve\nartificial robots in a set of two dimensional open-ended food gathering and\npredator-prey simulations, demonstrating the system's ability to produce ever\nmore complex Neural Networks, and the system's applicability to the domain of\nrobotics, artificial life, and coevolution."
},{
    "category": "cs.NE", 
    "doi": "10.1109/NABIC.2010.5716320", 
    "link": "http://arxiv.org/pdf/1101.0362v1", 
    "other_authors": "Ashish Ranjan Hota, Ankit Pat", 
    "title": "An Adaptive Quantum-inspired Differential Evolution Algorithm for 0-1   Knapsack Problem", 
    "arxiv-id": "1101.0362v1", 
    "author": "Ankit Pat", 
    "publish": "2011-01-01T18:26:29Z", 
    "summary": "Differential evolution (DE) is a population based evolutionary algorithm\nwidely used for solving multidimensional global optimization problems over\ncontinuous spaces. However, the design of its operators makes it unsuitable for\nmany real-life constrained combinatorial optimization problems which operate on\nbinary space. On the other hand, the quantum inspired evolutionary algorithm\n(QEA) is very well suitable for handling such problems by applying several\nquantum computing techniques such as Q-bit representation and rotation gate\noperator, etc. This paper extends the concept of differential operators with\nadaptive parameter control to the quantum paradigm and proposes the adaptive\nquantum-inspired differential evolution algorithm (AQDE). The performance of\nAQDE is found to be significantly superior as compared to QEA and a discrete\nversion of DE on the standard 0-1 knapsack problem for all the considered test\ncases."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s00453-012-9622-x", 
    "link": "http://arxiv.org/pdf/1101.0776v1", 
    "other_authors": "Benjamin Doerr, Daniel Johannsen, Carola Winzen", 
    "title": "Multiplicative Drift Analysis", 
    "arxiv-id": "1101.0776v1", 
    "author": "Carola Winzen", 
    "publish": "2011-01-04T17:44:56Z", 
    "summary": "In this work, we introduce multiplicative drift analysis as a suitable way to\nanalyze the runtime of randomized search heuristics such as evolutionary\nalgorithms.\n  We give a multiplicative version of the classical drift theorem. This allows\neasier analyses in those settings where the optimization progress is roughly\nproportional to the current distance to the optimum.\n  To display the strength of this tool, we regard the classical problem how the\n(1+1) Evolutionary Algorithm optimizes an arbitrary linear pseudo-Boolean\nfunction. Here, we first give a relatively simple proof for the fact that any\nlinear function is optimized in expected time $O(n \\log n)$, where $n$ is the\nlength of the bit string. Afterwards, we show that in fact any such function is\noptimized in expected time at most ${(1+o(1)) 1.39 \\euler n\\ln (n)}$, again\nusing multiplicative drift analysis. We also prove a corresponding lower bound\nof ${(1-o(1))e n\\ln(n)}$ which actually holds for all functions with a unique\nglobal optimum.\n  We further demonstrate how our drift theorem immediately gives natural proofs\n(with better constants) for the best known runtime bounds for the (1+1)\nEvolutionary Algorithm on combinatorial problems like finding minimum spanning\ntrees, shortest paths, or Euler tours."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s00453-012-9622-x", 
    "link": "http://arxiv.org/pdf/1101.4445v1", 
    "other_authors": "Santosh Kumar Singh, Gajendra Singh, Vibhakar Pathak, Dr. Krishna Chandra Roy", 
    "title": "Spectrum Management for Cognitive Radio based on Genetics Algorithm", 
    "arxiv-id": "1101.4445v1", 
    "author": "Dr. Krishna Chandra Roy", 
    "publish": "2011-01-24T05:21:33Z", 
    "summary": "Spectrum scarceness is one of the major challenges that the present world is\nfacing. The efficient use of existing licensed spectrum is becoming most\ncritical as growing demand of the radio spectrum. Different researches show\nthat the use of licensed are not utilized inefficiently. It has been also shown\nthat primary user does not use more than 70% of the licensed frequency band\nmost of the time. Many researchers are trying to found the techniques that\nefficiently utilize the under-utilized licensed spectrum. One of the approaches\nis the use of \"Cognitive Radio\". This allows the radio to learn from its\nenvironment, changing certain parameters. Based on this knowledge the radio can\ndynamically exploit the spectrum holes in the licensed band of the spectrum.\nThis paper w i l l focus on the performance of spectrum allocation technique,\nbased on popular meta-heuristics Genetics Algorithm and analyzing the\nperformance of this technique using Mat Lab."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s00453-012-9622-x", 
    "link": "http://arxiv.org/pdf/1101.5997v1", 
    "other_authors": "Bojin Zheng, Yuanxiang Li", 
    "title": "New Model for Multi-Objective Evolutionary Algorithms", 
    "arxiv-id": "1101.5997v1", 
    "author": "Yuanxiang Li", 
    "publish": "2011-01-31T15:47:05Z", 
    "summary": "Multi-Objective Evolutionary Algorithms (MOEAs) have been proved efficient to\ndeal with Multi-objective Optimization Problems (MOPs). Until now tens of MOEAs\nhave been proposed. The unified mode would provide a more systematic approach\nto build new MOEAs. Here a new model is proposed which includes two sub-models\nbased on two classes of different schemas of MOEAs. According to the new model,\nsome representatives algorithms are decomposed and some interesting issues are\ndiscussed."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s00453-012-9622-x", 
    "link": "http://arxiv.org/pdf/1102.2559v1", 
    "other_authors": "Mike Stimpson", 
    "title": "Toward Measuring the Scaling of Genetic Programming", 
    "arxiv-id": "1102.2559v1", 
    "author": "Mike Stimpson", 
    "publish": "2011-02-13T05:09:32Z", 
    "summary": "Several genetic programming systems are created, each solving a different\nproblem. In these systems, the median number of generations G needed to evolve\na working program is measured. The behavior of G is observed as the difficulty\nof the problem is increased. In these systems, the density D of working\nprograms in the universe of all possible programs is measured. The relationship\nG ~ 1/sqrt(D) is observed to approximately hold for two program-like systems.\nFor parallel systems (systems that look like several independent programs\nevolving in parallel), the relationship G ~ 1/(n ln n) is observed to\napproximately hold. Finally, systems that are anti-parallel are considered."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s00453-012-9622-x", 
    "link": "http://arxiv.org/pdf/1102.5757v1", 
    "other_authors": "Amit Choudhary, Rahul Rishi", 
    "title": "Improving the character recognition efficiency of feed forward BP neural   network", 
    "arxiv-id": "1102.5757v1", 
    "author": "Rahul Rishi", 
    "publish": "2011-02-28T19:58:20Z", 
    "summary": "This work is focused on improving the character recognition capability of\nfeed-forward back-propagation neural network by using one, two and three hidden\nlayers and the modified additional momentum term. 182 English letters were\ncollected for this work and the equivalent binary matrix form of these\ncharacters was applied to the neural network as training patterns. While the\nnetwork was getting trained, the connection weights were modified at each epoch\nof learning. For each training sample, the error surface was examined for\nminima by computing the gradient descent. We started the experiment by using\none hidden layer and the number of hidden layers was increased up to three and\nit has been observed that accuracy of the network was increased with low mean\nsquare error but at the cost of training time. The recognition accuracy was\nimproved further when modified additional momentum term was used."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s00453-012-9622-x", 
    "link": "http://arxiv.org/pdf/1103.0087v1", 
    "other_authors": "E. P. Ephzibah", 
    "title": "Cost effective approach on feature selection using genetic algorithms   and fuzzy logic for diabetes diagnosis", 
    "arxiv-id": "1103.0087v1", 
    "author": "E. P. Ephzibah", 
    "publish": "2011-03-01T06:10:18Z", 
    "summary": "A way to enhance the performance of a model that combines genetic algorithms\nand fuzzy logic for feature selection and classification is proposed. Early\ndiagnosis of any disease with less cost is preferable. Diabetes is one such\ndisease. Diabetes has become the fourth leading cause of death in developed\ncountries and there is substantial evidence that it is reaching epidemic\nproportions in many developing and newly industrialized nations. In medical\ndiagnosis, patterns consist of observable symptoms along with the results of\ndiagnostic tests. These tests have various associated costs and risks. In the\nautomated design of pattern classification, the proposed system solves the\nfeature subset selection problem. It is a task of identifying and selecting a\nuseful subset of pattern-representing features from a larger set of features.\nUsing fuzzy rule-based classification system, the proposed system proves to\nimprove the classification accuracy."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s00453-012-9622-x", 
    "link": "http://arxiv.org/pdf/1103.2741v1", 
    "other_authors": "Prerana Laddha", 
    "title": "Memory Retrieval in the B-Matrix Neural Network", 
    "arxiv-id": "1103.2741v1", 
    "author": "Prerana Laddha", 
    "publish": "2011-03-14T18:58:59Z", 
    "summary": "This paper is an extension to the memory retrieval procedure of the B-Matrix\napproach [6],[17] to neural network learning. The B-Matrix is a part of the\ninterconnection matrix generated from the Hebbian neural network, and in memory\nretrieval, the B-matrix is clamped with a small fragment of the memory. The\nfragment gradually enlarges by means of feedback, until the entire vector is\nobtained. In this paper, we propose the use of delta learning to enhance the\nretrieval rate of the stored memories."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s00453-012-9622-x", 
    "link": "http://arxiv.org/pdf/1103.4820v1", 
    "other_authors": "Alexandru-Adrian Tantar, Emilia Tantar, Pascal Bouvry", 
    "title": "Design and classification of dynamic multi-objective optimization   problems", 
    "arxiv-id": "1103.4820v1", 
    "author": "Pascal Bouvry", 
    "publish": "2011-03-24T17:59:10Z", 
    "summary": "In this work we provide a formal model for the different time-dependent\ncomponents that can appear in dynamic multi-objective optimization problems,\nalong with a classification of these components. Four main classes are\nidentified, corresponding to the influence of the parameters, objective\nfunctions, previous states of the dynamic system and, last, environment\nchanges, which in turn lead to online optimization problems. For illustration\npurposes, examples are provided for each class identified - by no means\nstanding as the most representative ones or exhaustive in scope."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s00453-012-9622-x", 
    "link": "http://arxiv.org/pdf/1103.5081v2", 
    "other_authors": "Praveen Kuruvada", 
    "title": "Using Variable Threshold to Increase Capacity in a Feedback Neural   Network", 
    "arxiv-id": "1103.5081v2", 
    "author": "Praveen Kuruvada", 
    "publish": "2011-03-25T20:59:13Z", 
    "summary": "The article presents new results on the use of variable thresholds to\nincrease the capacity of a feedback neural network. Non-binary networks are\nalso considered in this analysis."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s00453-012-9622-x", 
    "link": "http://arxiv.org/pdf/1103.5797v2", 
    "other_authors": "Markus Wagner, Frank Neumann", 
    "title": "Computational Complexity Results for Genetic Programming and the Sorting   Problem", 
    "arxiv-id": "1103.5797v2", 
    "author": "Frank Neumann", 
    "publish": "2011-03-29T23:52:30Z", 
    "summary": "Genetic Programming (GP) has found various applications. Understanding this\ntype of algorithm from a theoretical point of view is a challenging task. The\nfirst results on the computational complexity of GP have been obtained for\nproblems with isolated program semantics. With this paper, we push forward the\ncomputational complexity analysis of GP on a problem with dependent program\nsemantics. We study the well-known sorting problem in this context and analyze\nrigorously how GP can deal with different measures of sortedness."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s00453-012-9622-x", 
    "link": "http://arxiv.org/pdf/1105.0332v1", 
    "other_authors": "C. Ramya, G. Kavitha, Dr. K. S. Shreedhara", 
    "title": "Recalling of Images using Hopfield Neural Network Model", 
    "arxiv-id": "1105.0332v1", 
    "author": "Dr. K. S. Shreedhara", 
    "publish": "2011-05-02T13:54:40Z", 
    "summary": "In the present paper, an effort has been made for storing and recalling\nimages with Hopfield Neural Network Model of auto-associative memory. Images\nare stored by calculating a corresponding weight matrix. Thereafter, starting\nfrom an arbitrary configuration, the memory will settle on exactly that stored\nimage, which is nearest to the starting configuration in terms of Hamming\ndistance. Thus given an incomplete or corrupted version of a stored image, the\nnetwork is able to recall the corresponding original image. The storing of the\nobjects has been performed according to the Hopfield algorithm explained below.\nOnce the net has completely learnt this set of input patterns, a set of testing\npatterns containing degraded images will be given to the net. Then the Hopfield\nnet will tend to recall the closest matching pattern for the given degraded\nimage. The simulated results show that Hopfield model is the best for storing\nand recalling images."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s00453-012-9622-x", 
    "link": "http://arxiv.org/pdf/1105.0355v1", 
    "other_authors": "Y\u0131lmaz Kaya, Murat Uyar, Ramazan Tek\\D{j}n", 
    "title": "A Novel Crossover Operator for Genetic Algorithms: Ring Crossover", 
    "arxiv-id": "1105.0355v1", 
    "author": "Ramazan Tek\\D{j}n", 
    "publish": "2011-05-02T15:22:36Z", 
    "summary": "The genetic algorithm (GA) is an optimization and search technique based on\nthe principles of genetics and natural selection. A GA allows a population\ncomposed of many individuals to evolve under specified selection rules to a\nstate that maximizes the \"fitness\" function. In that process, crossover\noperator plays an important role. To comprehend the GAs as a whole, it is\nnecessary to understand the role of a crossover operator. Today, there are a\nnumber of different crossover operators that can be used in GAs. However, how\nto decide what operator to use for solving a problem? A number of test\nfunctions with various levels of difficulty has been selected as a test polygon\nfor determine the performance of crossover operators. In this paper, a novel\ncrossover operator called 'ring crossover' is proposed. In order to evaluate\nthe efficiency and feasibility of the proposed operator, a comparison between\nthe results of this study and results of different crossover operators used in\nGAs is made through a number of test functions with various levels of\ndifficulty. Results of this study clearly show significant differences between\nthe proposed operator and the other crossover operators."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s00453-012-9622-x", 
    "link": "http://arxiv.org/pdf/1105.1641v1", 
    "other_authors": "Tanja Magoc, Dejan Magoc", 
    "title": "Neural network to identify individuals at health risk", 
    "arxiv-id": "1105.1641v1", 
    "author": "Dejan Magoc", 
    "publish": "2011-05-09T11:45:04Z", 
    "summary": "The risk of diseases such as heart attack and high blood pressure could be\nreduced by adequate physical activity. However, even though majority of general\npopulation claims to perform some physical exercise, only a minority exercises\nenough to keep a healthy living style. Thus, physical inactivity has become one\nof the major concerns of public health in the past decade. Research shows that\nthe highest decrease in physical activity is noticed from high school to\ncollege. Thus, it is of great importance to quickly identify college students\nat health risk due to physical inactivity. Research also shows that the level\nof physical activity of an individual is highly correlated to demographic\nfeatures such as race and gender, as well as self motivation and support from\nfamily and friends. This information could be collected from each student via a\n20 minute questionnaire, but the time needed to distribute and analyze each\nquestionnaire is infeasible on a collegiate campus. Thus, we propose an\nautomatic identifier of students at risk, so that these students could easier\nbe targeted by collegiate campuses and physical activity promotion departments.\nWe present in this paper preliminary results of a supervised backpropagation\nmultilayer neural network for classifying students into at-risk or not at-risk\ngroup."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijaia.2011.2209", 
    "link": "http://arxiv.org/pdf/1105.1901v1", 
    "other_authors": "G. Jeyakumar C. Shanmugavelayutham", 
    "title": "Convergence Analysis of Differential Evolution Variants on Unconstrained   Global Optimization Functions", 
    "arxiv-id": "1105.1901v1", 
    "author": "G. Jeyakumar C. Shanmugavelayutham", 
    "publish": "2011-05-10T10:32:01Z", 
    "summary": "In this paper, we present an empirical study on convergence nature of\nDifferential Evolution (DE) variants to solve unconstrained global optimization\nproblems. The aim is to identify the competitive nature of DE variants in\nsolving the problem at their hand and compare. We have chosen fourteen\nbenchmark functions grouped by feature: unimodal and separable, unimodal and\nnonseparable, multimodal and separable, and multimodal and nonseparable.\nFourteen variants of DE were implemented and tested on fourteen benchmark\nproblems for dimensions of 30. The competitiveness of the variants are\nidentified by the Mean Objective Function value, they achieved in 100 runs. The\nconvergence nature of the best and worst performing variants are analyzed by\nmeasuring their Convergence Speed (Cs) and Quality Measure (Qm)."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijaia.2011.2209", 
    "link": "http://arxiv.org/pdf/1105.2894v2", 
    "other_authors": "Ankit Pat, Ashish Ranjan Hota", 
    "title": "Ant Colony Optimization and Hypergraph Covering Problems", 
    "arxiv-id": "1105.2894v2", 
    "author": "Ashish Ranjan Hota", 
    "publish": "2011-05-14T12:22:42Z", 
    "summary": "Ant Colony Optimization (ACO) is a very popular metaheuristic for solving\ncomputationally hard combinatorial optimization problems. Runtime analysis of\nACO with respect to various pseudo-boolean functions and different graph based\ncombinatorial optimization problems has been taken up in recent years. In this\npaper, we investigate the runtime behavior of an MMAS*(Max-Min Ant System) ACO\nalgorithm on some well known hypergraph covering problems that are NP-Hard. In\nparticular, we have addressed the Minimum Edge Cover problem, the Minimum\nVertex Cover problem and the Maximum Weak- Independent Set problem. The\ninfluence of pheromone values and heuristic information on the running time is\nanalysed. The results indicate that the heuristic information has greater\nimpact towards improving the expected optimization time as compared to\npheromone values. For certain instances of hypergraphs, we show that the MMAS*\nalgorithm gives a constant order expected optimization time when the dominance\nof heuristic information is suitably increased."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijaia.2011.2209", 
    "link": "http://arxiv.org/pdf/1105.3538v1", 
    "other_authors": "Alden H. Wright", 
    "title": "The Exact Schema Theorem", 
    "arxiv-id": "1105.3538v1", 
    "author": "Alden H. Wright", 
    "publish": "2011-05-18T05:37:36Z", 
    "summary": "A schema is a naturally defined subset of the space of fixed-length binary\nstrings. The Holland Schema Theorem gives a lower bound on the expected\nfraction of a population in a schema after one generation of a simple genetic\nalgorithm. This paper gives formulas for the exact expected fraction of a\npopulation in a schema after one generation of the simple genetic algorithm.\nHolland's schema theorem has three parts, one for selection, one for crossover,\nand one for mutation. The selection part is exact, whereas the crossover and\nmutation parts are approximations. This paper shows how the crossover and\nmutation parts can be made exact. Holland's schema theorem follows naturally as\na corollary. There is a close relationship between schemata and the\nrepresentation of the population in the Walsh basis. This relationship is used\nin the derivation of the results, and can also make computation of the schema\naverages more efficient. This paper gives a version of the Vose infinite\npopulation model where crossover and mutation are separated into two functions\nrather than a single \"mixing\" function."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijaia.2011.2209", 
    "link": "http://arxiv.org/pdf/1105.4971v1", 
    "other_authors": "P. A. Castillo, M. G. Arenas, A. M. Mora, J. L. J. Laredo, G. Romero, V. M Rivas, J. J. Merelo", 
    "title": "Distributed Evolutionary Computation using REST", 
    "arxiv-id": "1105.4971v1", 
    "author": "J. J. Merelo", 
    "publish": "2011-05-25T09:13:31Z", 
    "summary": "This paper analises distributed evolutionary computation based on the\nRepresentational State Transfer (REST) protocol, which overlays a farming model\non evolutionary computation. An approach to evolutionary distributed\noptimisation of multilayer perceptrons (MLP) using REST and language Perl has\nbeen done. In these experiments, a master-slave based evolutionary algorithm\n(EA) has been implemented, where slave processes evaluate the costly fitness\nfunction (training a MLP to solve a classification problem). Obtained results\nshow that the parallel version of the developed programs obtains similar or\nbetter results using much less time than the sequential version, obtaining a\ngood speedup."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijaia.2011.2209", 
    "link": "http://arxiv.org/pdf/1105.4978v1", 
    "other_authors": "P. A. Castillo, J. L. Bernier, M. G. Arenas, J. J. Merelo, P. Garcia-Sanchez", 
    "title": "SOAP vs REST: Comparing a master-slave GA implementation", 
    "arxiv-id": "1105.4978v1", 
    "author": "P. Garcia-Sanchez", 
    "publish": "2011-05-25T09:44:17Z", 
    "summary": "In this paper, a high-level comparison of both SOAP (Simple Object Access\nProtocol) and REST (Representational State Transfer) is made. These are the two\nmain approaches for interfacing to the web with web services. Both approaches\nare different and present some advantages and disadvantages for interfacing to\nweb services: SOAP is conceptually more difficult (has a steeper learning\ncurve) and more \"heavy-weight\" than REST, although it lacks of standards\nsupport for security. In order to test their eficiency (in time), two\nexperiments have been performed using both technologies: a client-server model\nimplementation and a master-slave based genetic algorithm (GA). The results\nobtained show clear differences in time between SOAP and REST implementations.\nAlthough both techniques are suitable for developing parallel systems, SOAP is\nheavier than REST, mainly due to the verbosity of SOAP communications (XML\nincreases the time taken to parse the messages)."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijaia.2011.2209", 
    "link": "http://arxiv.org/pdf/1105.5540v1", 
    "other_authors": "Per Kristian Lehre, Carsten Witt", 
    "title": "Finite First Hitting Time versus Stochastic Convergence in Particle   Swarm Optimisation", 
    "arxiv-id": "1105.5540v1", 
    "author": "Carsten Witt", 
    "publish": "2011-05-27T12:21:29Z", 
    "summary": "We reconsider stochastic convergence analyses of particle swarm optimisation,\nand point out that previously obtained parameter conditions are not always\nsufficient to guarantee mean square convergence to a local optimum. We show\nthat stagnation can in fact occur for non-trivial configurations in non-optimal\nparts of the search space, even for simple functions like SPHERE. The\nconvergence properties of the basic PSO may in these situations be detrimental\nto the goal of optimisation, to discover a sufficiently good solution within\nreasonable time. To characterise optimisation ability of algorithms, we suggest\nthe expected first hitting time (FHT), i.e., the time until a search point in\nthe vicinity of the optimum is visited. It is shown that a basic PSO may have\ninfinite expected FHT, while an algorithm introduced here, the Noisy PSO, has\nfinite expected FHT on some functions."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijaia.2011.2209", 
    "link": "http://arxiv.org/pdf/1108.0342v1", 
    "other_authors": "Benjamin Doerr, Timo K\u00f6tzing, Johannes Lengler, Carola Winzen", 
    "title": "Black-Box Complexities of Combinatorial Problems", 
    "arxiv-id": "1108.0342v1", 
    "author": "Carola Winzen", 
    "publish": "2011-08-01T15:44:21Z", 
    "summary": "Black-box complexity is a complexity theoretic measure for how difficult a\nproblem is to be optimized by a general purpose optimization algorithm. It is\nthus one of the few means trying to understand which problems are tractable for\ngenetic algorithms and other randomized search heuristics.\n  Most previous work on black-box complexity is on artificial test functions.\nIn this paper, we move a step forward and give a detailed analysis for the two\ncombinatorial problems minimum spanning tree and single-source shortest paths.\nBesides giving interesting bounds for their black-box complexities, our work\nreveals that the choice of how to model the optimization problem is non-trivial\nhere. This in particular comes true where the search space does not consist of\nbit strings and where a reasonable definition of unbiasedness has to be agreed\non."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijaia.2011.2209", 
    "link": "http://arxiv.org/pdf/1108.1530v1", 
    "other_authors": "Ewan Orr, Ben Martin", 
    "title": "Evolving A-Type Artificial Neural Networks", 
    "arxiv-id": "1108.1530v1", 
    "author": "Ben Martin", 
    "publish": "2011-08-07T07:23:32Z", 
    "summary": "We investigate Turing's notion of an A-type artificial neural network. We\nstudy a refinement of Turing's original idea, motivated by work of Teuscher,\nBull, Preen and Copeland. Our A-types can process binary data by accepting and\noutputting sequences of binary vectors; hence we can associate a function to an\nA-type, and we say the A-type {\\em represents} the function. There are two\nmodes of data processing: clamped and sequential. We describe an evolutionary\nalgorithm, involving graph-theoretic manipulations of A-types, which searches\nfor A-types representing a given function. The algorithm uses both mutation and\ncrossover operators. We implemented the algorithm and applied it to three\nbenchmark tasks. We found that the algorithm performed much better than a\nrandom search. For two out of the three tasks, the algorithm with crossover\nperformed better than a mutation-only version."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijaia.2011.2209", 
    "link": "http://arxiv.org/pdf/1108.3489v1", 
    "other_authors": "Yifeng Gao, Shuhong Gong, Ge Zhao", 
    "title": "A Novel and Robust Evolution Algorithm for Optimizing Complicated   Functions", 
    "arxiv-id": "1108.3489v1", 
    "author": "Ge Zhao", 
    "publish": "2011-08-17T14:22:25Z", 
    "summary": "In this paper, a novel mutation operator of differential evolution algorithm\nis proposed. A new algorithm called divergence differential evolution algorithm\n(DDEA) is developed by combining the new mutation operator with divergence\noperator and assimilation operator (divergence operator divides population,\nand, assimilation operator combines population), which can detect multiple\nsolutions and robustness in noisy environment. The new algorithm is applied to\noptimize Michalewicz Function and to track changing of rain-induced-attenuation\nprocess. The results based on DDEA are compared with those based on\nDifferential Evolution Algorithm (DEA). It shows that DDEA algorithm gets\nbetter results than DEA does in the same premise. The new algorithm is\nsignificant for optimizing and tracking the characteristics of MIMO (Multiple\nInput Multiple Output) channel at millimeter waves."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijaia.2011.2209", 
    "link": "http://arxiv.org/pdf/1108.4080v1", 
    "other_authors": "Aram Ter-Sarkisov, Stephen Marsland", 
    "title": "Convergence Properties of Two (\u03bc + \u03bb) Evolutionary   Algorithms On OneMax and Royal Roads Test Functions", 
    "arxiv-id": "1108.4080v1", 
    "author": "Stephen Marsland", 
    "publish": "2011-08-20T02:11:57Z", 
    "summary": "We present a number of bounds on convergence time for two elitist\npopulation-based Evolutionary Algorithms using a recombination operator\nk-Bit-Swap and a mainstream Randomized Local Search algorithm. We study the\neffect of distribution of elite species and population size."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijaia.2011.2209", 
    "link": "http://arxiv.org/pdf/1108.4083v2", 
    "other_authors": "Aram Ter-Sarkisov, Stephen Marsland", 
    "title": "Convergence of a Recombination-Based Elitist Evolutionary Algorithm on   the Royal Roads Test Function", 
    "arxiv-id": "1108.4083v2", 
    "author": "Stephen Marsland", 
    "publish": "2011-08-20T02:40:33Z", 
    "summary": "We present an analysis of the performance of an elitist Evolutionary\nalgorithm using a recombination operator known as 1-Bit-Swap on the Royal Roads\ntest function based on a population. We derive complete, approximate and\nasymptotic convergence rates for the algorithm. The complete model shows the\nbenefit of the size of the population and re- combination pool."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijaia.2011.2209", 
    "link": "http://arxiv.org/pdf/1108.4386v2", 
    "other_authors": "Carsten Witt", 
    "title": "Tight Bounds on the Optimization Time of the (1+1) EA on Linear   Functions", 
    "arxiv-id": "1108.4386v2", 
    "author": "Carsten Witt", 
    "publish": "2011-08-22T17:43:35Z", 
    "summary": "The analysis of randomized search heuristics on classes of functions is\nfundamental for the understanding of the underlying stochastic process and the\ndevelopment of suitable proof techniques. Recently, remarkable progress has\nbeen made in bounding the expected optimization time of the simple (1+1) EA on\nthe class of linear functions. We improve the best known bound in this setting\nfrom $(1.39+o(1))en\\ln n$ to $en\\ln n+O(n)$ in expectation and with high\nprobability, which is tight up to lower-order terms. Moreover, upper and lower\nbounds for arbitrary mutations probabilities $p$ are derived, which imply\nexpected polynomial optimization time as long as $p=O((\\ln n)/n)$ and which are\ntight if $p=c/n$ for a constant $c$. As a consequence, the standard mutation\nprobability $p=1/n$ is optimal for all linear functions, and the (1+1) EA is\nfound to be an optimal mutation-based algorithm. The proofs are based on\nadaptive drift functions and the recent multiplicative drift theorem."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijaia.2011.2209", 
    "link": "http://arxiv.org/pdf/1108.4531v4", 
    "other_authors": "Jun He, Tianshi Chen, Boris Mitavskiy", 
    "title": "Novel Analysis of Population Scalability in Evolutionary Algorithms", 
    "arxiv-id": "1108.4531v4", 
    "author": "Boris Mitavskiy", 
    "publish": "2011-08-23T09:12:04Z", 
    "summary": "Population-based evolutionary algorithms (EAs) have been widely applied to\nsolve various optimization problems. The question of how the performance of a\npopulation-based EA depends on the population size arises naturally. The\nperformance of an EA may be evaluated by different measures, such as the\naverage convergence rate to the optimal set per generation or the expected\nnumber of generations to encounter an optimal solution for the first time.\nPopulation scalability is the performance ratio between a benchmark EA and\nanother EA using identical genetic operators but a larger population size.\nAlthough intuitively the performance of an EA may improve if its population\nsize increases, currently there exist only a few case studies for simple\nfitness functions. This paper aims at providing a general study for discrete\noptimisation. A novel approach is introduced to analyse population scalability\nusing the fundamental matrix. The following two contributions summarize the\nmajor results of the current article. (1) We demonstrate rigorously that for\nelitist EAs with identical global mutation, using a lager population size\nalways increases the average rate of convergence to the optimal set; and yet,\nsometimes, the expected number of generations needed to find an optimal\nsolution (measured by either the maximal value or the average value) may\nincrease, rather than decrease. (2) We establish sufficient and/or necessary\nconditions for the superlinear scalability, that is, when the average\nconvergence rate of a $(\\mu+\\mu)$ EA (where $\\mu\\ge2$) is bigger than $\\mu$\ntimes that of a $(1+1)$ EA."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijaia.2011.2209", 
    "link": "http://arxiv.org/pdf/1108.4548v1", 
    "other_authors": "J. L. Mpanza, T. Marwala", 
    "title": "Ant Colony Optimization of Rough Set for HV Bushings Fault Detection", 
    "arxiv-id": "1108.4548v1", 
    "author": "T. Marwala", 
    "publish": "2011-08-23T10:47:23Z", 
    "summary": "Most transformer failures are attributed to bushings failures. Hence it is\nnecessary to monitor the condition of bushings. In this paper three methods are\ndeveloped to monitor the condition of oil filled bushing. Multi-layer\nperceptron (MLP), Radial basis function (RBF) and Rough Set (RS) models are\ndeveloped and combined through majority voting to form a committee. The MLP\nperforms better that the RBF and the RS is terms of classification accuracy.\nThe RBF is the fasted to train. The committee performs better than the\nindividual models. The diversity of models is measured to evaluate their\nsimilarity when used in the committee."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijaia.2011.2209", 
    "link": "http://arxiv.org/pdf/1108.4618v1", 
    "other_authors": "LJ Mpanza, T. Marwala", 
    "title": "Artificial Neural Network and Rough Set for HV Bushings Condition   Monitoring", 
    "arxiv-id": "1108.4618v1", 
    "author": "T. Marwala", 
    "publish": "2011-08-23T14:44:44Z", 
    "summary": "Most transformer failures are attributed to bushings failures. Hence it is\nnecessary to monitor the condition of bushings. In this paper three methods are\ndeveloped to monitor the condition of oil filled bushing. Multi-layer\nperceptron (MLP), Radial basis function (RBF) and Rough Set (RS) models are\ndeveloped and combined through majority voting to form a committee. The MLP\nperforms better that the RBF and the RS is terms of classification accuracy.\nThe RBF is the fasted to train. The committee performs better than the\nindividual models. The diversity of models is measured to evaluate their\nsimilarity when used in the committee."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijaia.2011.2209", 
    "link": "http://arxiv.org/pdf/1110.1038v1", 
    "other_authors": "Parisa Soleimani, Reza Sabbaghi-Nadooshan, Sattar Mirzakuchaki, Mahdi Bagheri", 
    "title": "Using Genetic Algorithm in the Evolutionary Design of Sequential Logic   Circuits", 
    "arxiv-id": "1110.1038v1", 
    "author": "Mahdi Bagheri", 
    "publish": "2011-10-05T16:52:26Z", 
    "summary": "Evolvable hardware (EHW) is a set of techniques that are based on the idea of\ncombining reconfiguration hardware systems with evolutionary algorithms. In\nother word, EHW has two sections; the reconfigurable hardware and evolutionary\nalgorithm where the configurations are under the control of an evolutionary\nalgorithm. This paper, suggests a method to design and optimize the synchronous\nsequential circuits. Genetic algorithm (GA) was applied as evolutionary\nalgorithm. In this approach, for building input combinational logic circuit of\neach DFF, and also output combinational logic circuit, the cell arrays have\nbeen used. The obtained results show that our method can reduce the average\nnumber of generations by limitation the search space."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29124-1_19", 
    "link": "http://arxiv.org/pdf/1112.1517v4", 
    "other_authors": "Jun He, Feidun He, Hongbin Dong", 
    "title": "Pure Strategy or Mixed Strategy?", 
    "arxiv-id": "1112.1517v4", 
    "author": "Hongbin Dong", 
    "publish": "2011-12-07T10:37:14Z", 
    "summary": "Mixed strategy EAs aim to integrate several mutation operators into a single\nalgorithm. However few theoretical analysis has been made to answer the\nquestion whether and when the performance of mixed strategy EAs is better than\nthat of pure strategy EAs. In theory, the performance of EAs can be measured by\nasymptotic convergence rate and asymptotic hitting time. In this paper, it is\nproven that given a mixed strategy (1+1) EAs consisting of several mutation\noperators, its performance (asymptotic convergence rate and asymptotic hitting\ntime)is not worse than that of the worst pure strategy (1+1) EA using one\nmutation operator; if these mutation operators are mutually complementary, then\nit is possible to design a mixed strategy (1+1) EA whose performance is better\nthan that of any pure strategy (1+1) EA using one mutation operator."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29124-1_19", 
    "link": "http://arxiv.org/pdf/1112.2183v1", 
    "other_authors": "P. Isakki alias Devi, S. P. Rajagopalan", 
    "title": "The Expert System Designed to Improve Customer Satisfaction", 
    "arxiv-id": "1112.2183v1", 
    "author": "S. P. Rajagopalan", 
    "publish": "2011-12-09T18:49:28Z", 
    "summary": "Customer Relationship Management becomes a leading business strategy in\nhighly competitive business environment. It aims to enhance the performance of\nthe businesses by improving the customer satisfaction and loyalty. The\nobjective of this paper is to improve customer satisfaction on product's colors\nand design with the help of the expert system developed by using Artificial\nNeural Networks. The expert system's role is to capture the knowledge of the\nexperts and the data from the customer requirements, and then, process the\ncollected data and form the appropriate rules for choosing product's colors and\ndesign. In order to identify the hidden pattern of the customer's needs, the\nArtificial Neural Networks technique has been applied to classify the colors\nand design based upon a list of selected information. Moreover, the expert\nsystem has the capability to make decisions in ranking the scores of the colors\nand design presented in the selection. In addition, the expert system has been\nvalidated with a different customer types."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29124-1_19", 
    "link": "http://arxiv.org/pdf/1112.4323v2", 
    "other_authors": "Loris Serafino", 
    "title": "Between theory and practice: guidelines for an optimization scheme with   genetic algorithms - Part I: single-objective continuous global optimization", 
    "arxiv-id": "1112.4323v2", 
    "author": "Loris Serafino", 
    "publish": "2011-12-19T13:00:23Z", 
    "summary": "The rapid advances in the field of optimization methods in many pure and\napplied science pose the difficulty of keeping track of the developments as\nwell as selecting an appropriate technique that best suits the problem in-hand.\nFrom a practitioner point of view is rightful to wander \"which optimization\nmethod is the best for my problem?\". Looking at the optimization process as a\n\"system\" of intercon- nected parts, in this paper are collected some ideas\nabout how to tackle an optimization problem using a class of tools from\nevolutionary computations called Genetic Algorithms. Despite the number of\noptimization techniques available nowadays the author of this paper thinks that\nGenetic Algorithms still play a central role for their versatility, robustness,\ntheoretical framework and simplicity of use. The paper can be considered a\n\"collection of tips\" (from literature and personal experience) for the\nnon-computer-scientist that has to deal with optimization problems both in the\nscience and engineering practice. No original methods or algorithms are\nproposed."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29124-1_19", 
    "link": "http://arxiv.org/pdf/1112.5980v2", 
    "other_authors": "Susan Khor", 
    "title": "Search space analysis with Wang-Landau sampling and slow adaptive walks", 
    "arxiv-id": "1112.5980v2", 
    "author": "Susan Khor", 
    "publish": "2011-12-27T15:56:06Z", 
    "summary": "Two complementary techniques for analyzing search spaces are proposed: (i) an\nalgorithm to detect search points with potential to be local optima; and (ii) a\nslightly adjusted Wang-Landau sampling algorithm to explore larger search\nspaces. The detection algorithm assumes that local optima are points which are\neasier to reach and harder to leave by a slow adaptive walker. A slow adaptive\nwalker moves to a nearest fitter point. Thus, points with larger outgoing step\nsizes relative to incoming step sizes are marked using the local optima score\nformulae as potential local optima points (PLOPs). Defining local optima in\nthese more general terms allows their detection within the closure of a subset\nof a search space, and the sampling of a search space unshackled by a\nparticular move set. Tests are done with NK and HIFF problems to confirm that\nPLOPs detected in the manner proposed retain characteristics of local optima,\nand that the adjusted Wang-Landau samples are more representative of the search\nspace than samples produced by choosing points uniformly at random. While our\napproach shows promise, more needs to be done to reduce its computation cost\nthat it may pave a way toward analyzing larger search spaces of practical\nmeaning."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29124-1_19", 
    "link": "http://arxiv.org/pdf/1201.2100v1", 
    "other_authors": "Raja Mohamed S., P. Raviraj", 
    "title": "Biologically inspired design framework for Robot in Dynamic Environments   using Framsticks", 
    "arxiv-id": "1201.2100v1", 
    "author": "P. Raviraj", 
    "publish": "2012-01-10T16:19:23Z", 
    "summary": "Robot design complexity is increasing day by day especially in automated\nindustries. In this paper we propose biologically inspired design framework for\nrobots in dynamic world on the basis of Co-Evolution, Virtual Ecology, Life\ntime learning which are derived from biological creatures. We have created a\nvirtual khepera robot in Framsticks and tested its operational credibility in\nterms hardware and software components by applying the above suggested\ntechniques. Monitoring complex and non complex behaviors in different\nenvironments and obtaining the parameters that influence software and hardware\ndesign of the robot that influence anticipated and unanticipated failures,\ncontrol programs of robot generation are the major concerns of our techniques."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29124-1_19", 
    "link": "http://arxiv.org/pdf/1201.4737v1", 
    "other_authors": "Larry Bull", 
    "title": "Production System Rules as Protein Complexes from Genetic Regulatory   Networks", 
    "arxiv-id": "1201.4737v1", 
    "author": "Larry Bull", 
    "publish": "2012-01-20T20:30:59Z", 
    "summary": "This short paper introduces a new way by which to design production system\nrules. An indirect encoding scheme is presented which views such rules as\nprotein complexes produced by the temporal behaviour of an artificial genetic\nregulatory network. This initial study begins by using a simple Boolean\nregulatory network to produce traditional ternary-encoded rules before moving\nto a fuzzy variant to produce real-valued rules. Competitive performance is\nshown with related genetic regulatory networks and rule-based systems on\nbenchmark problems."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29124-1_19", 
    "link": "http://arxiv.org/pdf/1201.4908v1", 
    "other_authors": "Gerard Briscoe, Philippe De Wilde", 
    "title": "Self-Organisation of Evolving Agent Populations in Digital Ecosystems", 
    "arxiv-id": "1201.4908v1", 
    "author": "Philippe De Wilde", 
    "publish": "2012-01-24T03:16:43Z", 
    "summary": "We investigate the self-organising behaviour of Digital Ecosystems, because a\nprimary motivation for our research is to exploit the self-organising\nproperties of biological ecosystems. We extended a definition for the\ncomplexity, grounded in the biological sciences, providing a measure of the\ninformation in an organism's genome. Next, we extended a definition for the\nstability, originating from the computer sciences, based upon convergence to an\nequilibrium distribution. Finally, we investigated a definition for the\ndiversity, relative to the selection pressures provided by the user requests.\nWe conclude with a summary and discussion of the achievements, including the\nexperimental results."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29124-1_19", 
    "link": "http://arxiv.org/pdf/1203.0197v2", 
    "other_authors": "G. S. Raghavendra, N. Prasanna Kumar", 
    "title": "Statistical Approach for Selecting Elite Ants", 
    "arxiv-id": "1203.0197v2", 
    "author": "N. Prasanna Kumar", 
    "publish": "2012-03-01T14:25:50Z", 
    "summary": "Applications of ACO algorithms to obtain better solutions for combinatorial\noptimization problems have become very popular in recent years. In ACO\nalgorithms, group of agents repeatedly perform well defined actions and\ncollaborate with other ants in order to accomplish the defined task. In this\npaper, we introduce new mechanisms for selecting the Elite ants dynamically\nbased on simple statistical tools. We also investigate the performance of newly\nproposed mechanisms."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29124-1_19", 
    "link": "http://arxiv.org/pdf/1203.3847v1", 
    "other_authors": "Anshuman Sharma", 
    "title": "Handwritten digit Recognition using Support Vector Machine", 
    "arxiv-id": "1203.3847v1", 
    "author": "Anshuman Sharma", 
    "publish": "2012-03-17T09:17:21Z", 
    "summary": "Handwritten Numeral recognition plays a vital role in postal automation\nservices especially in countries like India where multiple languages and\nscripts are used Discrete Hidden Markov Model (HMM) and hybrid of Neural\nNetwork (NN) and HMM are popular methods in handwritten word recognition\nsystem. The hybrid system gives better recognition result due to better\ndiscrimination capability of the NN. A major problem in handwriting recognition\nis the huge variability and distortions of patterns. Elastic models based on\nlocal observations and dynamic programming such HMM are not efficient to absorb\nthis variability. But their vision is local. But they cannot face to length\nvariability and they are very sensitive to distortions. Then the SVM is used to\nestimate global correlations and classify the pattern. Support Vector Machine\n(SVM) is an alternative to NN. In Handwritten recognition, SVM gives a better\nrecognition result. The aim of this paper is to develop an approach which\nimprove the efficiency of handwritten recognition using artificial neural\nnetwork"
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29124-1_19", 
    "link": "http://arxiv.org/pdf/1203.4111v1", 
    "other_authors": "Benjamin Doerr, Carola Winzen", 
    "title": "Reducing the Arity in Unbiased Black-Box Complexity", 
    "arxiv-id": "1203.4111v1", 
    "author": "Carola Winzen", 
    "publish": "2012-03-19T14:12:52Z", 
    "summary": "We show that for all $1<k \\leq \\log n$ the $k$-ary unbiased black-box\ncomplexity of the $n$-dimensional $\\onemax$ function class is $O(n/k)$. This\nindicates that the power of higher arity operators is much stronger than what\nthe previous $O(n/\\log k)$ bound by Doerr et al. (Faster black-box algorithms\nthrough higher arity operators, Proc. of FOGA 2011, pp. 163--172, ACM, 2011)\nsuggests.\n  The key to this result is an encoding strategy, which might be of independent\ninterest. We show that, using $k$-ary unbiased variation operators only, we may\nsimulate an unrestricted memory of size $O(2^k)$ bits."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29124-1_19", 
    "link": "http://arxiv.org/pdf/1203.4881v1", 
    "other_authors": "Frank Neumann", 
    "title": "Computational Complexity Analysis of Multi-Objective Genetic Programming", 
    "arxiv-id": "1203.4881v1", 
    "author": "Frank Neumann", 
    "publish": "2012-03-22T04:22:36Z", 
    "summary": "The computational complexity analysis of genetic programming (GP) has been\nstarted recently by analyzing simple (1+1) GP algorithms for the problems ORDER\nand MAJORITY. In this paper, we study how taking the complexity as an\nadditional criteria influences the runtime behavior. We consider\ngeneralizations of ORDER and MAJORITY and present a computational complexity\nanalysis of (1+1) GP using multi-criteria fitness functions that take into\naccount the original objective and the complexity of a syntax tree as a\nsecondary measure. Furthermore, we study the expected time until\npopulation-based multi-objective genetic programming algorithms have computed\nthe Pareto front when taking the complexity of a syntax tree as an equally\nimportant objective."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29124-1_19", 
    "link": "http://arxiv.org/pdf/1203.5028v1", 
    "other_authors": "Otman Abdoun, Chakir Tajani, Jaafar Abouchabka", 
    "title": "Hybridizing PSM and RSM Operator for Solving NP-Complete Problems:   Application to Travelling Salesman Problem", 
    "arxiv-id": "1203.5028v1", 
    "author": "Jaafar Abouchabka", 
    "publish": "2012-03-22T16:09:51Z", 
    "summary": "In this paper, we present a new mutation operator, Hybrid Mutation (HPRM),\nfor a genetic algorithm that generates high quality solutions to the Traveling\nSalesman Problem (TSP). The Hybrid Mutation operator constructs an offspring\nfrom a pair of parents by hybridizing two mutation operators, PSM and RSM. The\nefficiency of the HPRM is compared as against some existing mutation operators;\nnamely, Reverse Sequence Mutation (RSM) and Partial Shuffle Mutation (PSM) for\nBERLIN52 as instance of TSPLIB. Experimental results show that the new mutation\noperator is better than the RSM and PSM."
},{
    "category": "cs.NE", 
    "doi": "10.1109/TEVC.2014.2318025", 
    "link": "http://arxiv.org/pdf/1203.6286v5", 
    "other_authors": "Jun He, Tianshi Chen, Xin Yao", 
    "title": "On the Easiest and Hardest Fitness Functions", 
    "arxiv-id": "1203.6286v5", 
    "author": "Xin Yao", 
    "publish": "2012-03-28T15:01:53Z", 
    "summary": "The hardness of fitness functions is an important research topic in the field\nof evolutionary computation. In theory, the study can help understanding the\nability of evolutionary algorithms. In practice, the study may provide a\nguideline to the design of benchmarks. The aim of this paper is to answer the\nfollowing research questions: Given a fitness function class, which functions\nare the easiest with respect to an evolutionary algorithm? Which are the\nhardest? How are these functions constructed? The paper provides theoretical\nanswers to these questions. The easiest and hardest fitness functions are\nconstructed for an elitist (1+1) evolutionary algorithm to maximise a class of\nfitness functions with the same optima. It is demonstrated that the unimodal\nfunctions are the easiest and deceptive functions are the hardest in terms of\nthe time-fitness landscape. The paper also reveals that the easiest fitness\nfunction to one algorithm may become the hardest to another algorithm, and vice\nversa."
},{
    "category": "cs.NE", 
    "doi": "10.1109/TEVC.2014.2318025", 
    "link": "http://arxiv.org/pdf/1302.0324v1", 
    "other_authors": "Hou Muzhou, Moon Ho Lee", 
    "title": "A New Constructive Method to Optimize Neural Network Architecture and   Generalization", 
    "arxiv-id": "1302.0324v1", 
    "author": "Moon Ho Lee", 
    "publish": "2013-02-02T00:43:42Z", 
    "summary": "In this paper, after analyzing the reasons of poor generalization and\noverfitting in neural networks, we consider some noise data as a singular value\nof a continuous function - jump discontinuity point. The continuous part can be\napproximated with the simplest neural networks, which have good generalization\nperformance and optimal network architecture, by traditional algorithms such as\nconstructive algorithm for feed-forward neural networks with incremental\ntraining, BP algorithm, ELM algorithm, various constructive algorithm, RBF\napproximation and SVM. At the same time, we will construct RBF neural networks\nto fit the singular value with every error in, and we prove that a function\nwith jumping discontinuity points can be approximated by the simplest neural\nnetworks with a decay RBF neural networks in by each error, and a function with\njumping discontinuity point can be constructively approximated by a decay RBF\nneural networks in by each error and the constructive part have no\ngeneralization influence to the whole machine learning system which will\noptimize neural network architecture and generalization performance, reduce the\noverfitting phenomenon by avoid fitting the noisy data."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-32711-7_6", 
    "link": "http://arxiv.org/pdf/1302.0797v1", 
    "other_authors": "Ella Gale, Ben de Lacy Costello, Andrew Adamatzky", 
    "title": "Comparison of Ant-Inspired Gatherer Allocation Approaches using   Memristor-Based Environmental Models", 
    "arxiv-id": "1302.0797v1", 
    "author": "Andrew Adamatzky", 
    "publish": "2013-02-04T18:50:14Z", 
    "summary": "Memristors are used to compare three gathering techniques in an\nalready-mapped environment where resource locations are known. The All Site\nmodel, which apportions gatherers based on the modeled memristance of that\npath, proves to be good at increasing overall efficiency and decreasing time to\nfully deplete an environment, however it only works well when the resources are\nof similar quality. The Leaf Cutter method, based on Leaf Cutter Ant behaviour,\nassigns all gatherers first to the best resource, and once depleted, uses the\nAll Site model to spread them out amongst the rest. The Leaf Cutter model is\nbetter at increasing resource influx in the short-term and vastly out-performs\nthe All Site model in a more varied environments. It is demonstrated that\nmemristor based abstractions of gatherer models provide potential methods for\nboth the comparison and implementation of agent controls."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-32711-7_6", 
    "link": "http://arxiv.org/pdf/1302.1156v2", 
    "other_authors": "Amir Hesam Salavati, K. Raj Kumar, Amin Shokrollahi", 
    "title": "A Non-Binary Associative Memory with Exponential Pattern Retrieval   Capacity and Iterative Learning: Extended Results", 
    "arxiv-id": "1302.1156v2", 
    "author": "Amin Shokrollahi", 
    "publish": "2013-02-05T19:14:39Z", 
    "summary": "We consider the problem of neural association for a network of non-binary\nneurons. Here, the task is to first memorize a set of patterns using a network\nof neurons whose states assume values from a finite number of integer levels.\nLater, the same network should be able to recall previously memorized patterns\nfrom their noisy versions. Prior work in this area consider storing a finite\nnumber of purely random patterns, and have shown that the pattern retrieval\ncapacities (maximum number of patterns that can be memorized) scale only\nlinearly with the number of neurons in the network.\n  In our formulation of the problem, we concentrate on exploiting redundancy\nand internal structure of the patterns in order to improve the pattern\nretrieval capacity. Our first result shows that if the given patterns have a\nsuitable linear-algebraic structure, i.e. comprise a sub-space of the set of\nall possible patterns, then the pattern retrieval capacity is in fact\nexponential in terms of the number of neurons. The second result extends the\nprevious finding to cases where the patterns have weak minor components, i.e.\nthe smallest eigenvalues of the correlation matrix tend toward zero. We will\nuse these minor components (or the basis vectors of the pattern null space) to\nboth increase the pattern retrieval capacity and error correction capabilities.\n  An iterative algorithm is proposed for the learning phase, and two simple\nneural update algorithms are presented for the recall phase. Using analytical\nresults and simulations, we show that the proposed methods can tolerate a fair\namount of errors in the input while being able to memorize an exponentially\nlarge number of patterns."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-32711-7_6", 
    "link": "http://arxiv.org/pdf/1302.3541v1", 
    "other_authors": "Jeffrey S. Buzas, Jeffrey Dinitz", 
    "title": "An analysis of NK and generalized NK landscapes", 
    "arxiv-id": "1302.3541v1", 
    "author": "Jeffrey Dinitz", 
    "publish": "2013-02-14T20:30:46Z", 
    "summary": "Simulated landscapes have been used for decades to evaluate search strategies\nwhose goal is to find the landscape location with maximum fitness. Applications\ninclude modeling the capacity of enzymes to catalyze reactions and the clinical\neffectiveness of medical treatments. Understanding properties of landscapes is\nimportant for understanding search difficulty. This paper presents a novel and\ntransparent characterization of NK landscapes.\n  We prove that NK landscapes can be represented by parametric linear\ninteraction models where model coefficients have meaningful interpretations. We\nderive the statistical properties of the model coefficients, providing insight\ninto how the NK algorithm parses importance to main effects and interactions.\nAn important insight derived from the linear model representation is that the\nrank of the linear model defined by the NK algorithm is correlated with the\nnumber of local optima, a strong determinant of landscape complexity and search\ndifficulty. We show that the maximal rank for an NK landscape is achieved\nthrough epistatic interactions that form partially balanced incomplete block\ndesigns. Finally, an analytic expression representing the expected number of\nlocal optima on the landscape is derived, providing a way to quickly compute\nthe expected number of local optima for very large landscapes."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-32711-7_6", 
    "link": "http://arxiv.org/pdf/1302.6310v1", 
    "other_authors": "Adesesan . B Adeyemo, Adebola A. Oketola, Emmanuel O. Adetula, O. Osibanjo", 
    "title": "Estimating Sectoral Pollution Load in Lagos, Nigeria Using Data Mining   Techniques", 
    "arxiv-id": "1302.6310v1", 
    "author": "O. Osibanjo", 
    "publish": "2013-02-26T04:22:44Z", 
    "summary": "Industrial pollution is often considered to be one of the prime factors\ncontributing to air, water and soil pollution. Sectoral pollution loads\n(ton/yr) into different media (i.e. air, water and land) in Lagos were\nestimated using Industrial Pollution Projected System (IPPS). These were\nfurther studied using Artificial neural Networks (ANNs), a data mining\ntechnique that has the ability of detecting and describing patterns in large\ndata sets with variables that are non- linearly related. Time Lagged Recurrent\nNetwork (TLRN) appeared as the best Neural Network model among all the neural\nnetworks considered which includes Multilayer Perceptron (MLP) Network,\nGeneralized Feed Forward Neural Network (GFNN), Radial Basis Function (RBF)\nNetwork and Recurrent Network (RN). TLRN modelled the data-sets better than the\nothers in terms of the mean average error (MAE) (0.14), time (39 s) and linear\ncorrelation coefficient (0.84). The results showed that Artificial Neural\nNetworks (ANNs) technique (i.e., Time Lagged Recurrent Network) is also\napplicable and effective in environmental assessment study. Keywords:\nArtificial Neural Networks (ANNs), Data Mining Techniques, Industrial Pollution\nProjection System (IPPS), Pollution load, Pollution Intensity."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-32711-7_6", 
    "link": "http://arxiv.org/pdf/1302.6426v1", 
    "other_authors": "A. Meena, K. Raja", 
    "title": "Segmentation of Alzheimers Disease in PET scan datasets using MATLAB", 
    "arxiv-id": "1302.6426v1", 
    "author": "K. Raja", 
    "publish": "2013-02-26T13:19:26Z", 
    "summary": "Positron Emission Tomography (PET) scan images are one of the bio medical\nimaging techniques similar to that of MRI scan images but PET scan images are\nhelpful in finding the development of tumors.The PET scan images requires\nexpertise in the segmentation where clustering plays an important role in the\nautomation process.The segmentation of such images is manual to automate the\nprocess clustering is used.Clustering is commonly known as unsupervised\nlearning process of n dimensional data sets are clustered into k groups so as\nto maximize the inter cluster similarity and to minimize the intra cluster\nsimilarity.This paper is proposed to implement the commonly used K Means and\nFuzzy CMeans (FCM) clustering algorithm.This work is implemented using MATrix\nLABoratory (MATLAB) and tested with sample PET scan image. The sample data is\ncollected from Alzheimers Disease Neuro imaging Initiative ADNI. Medical Image\nProcessing and Visualization Tool (MIPAV) are used to compare the resultant\nimages."
},{
    "category": "cs.NE", 
    "doi": "10.1109/IAdCC.2013.6514315", 
    "link": "http://arxiv.org/pdf/1302.6615v1", 
    "other_authors": "Ratnadip Adhikari, R. K. Agrawal, Laxmi Kant", 
    "title": "PSO based Neural Networks vs. Traditional Statistical Models for   Seasonal Time Series Forecasting", 
    "arxiv-id": "1302.6615v1", 
    "author": "Laxmi Kant", 
    "publish": "2013-02-26T22:25:16Z", 
    "summary": "Seasonality is a distinctive characteristic which is often observed in many\npractical time series. Artificial Neural Networks (ANNs) are a class of\npromising models for efficiently recognizing and forecasting seasonal patterns.\nIn this paper, the Particle Swarm Optimization (PSO) approach is used to\nenhance the forecasting strengths of feedforward ANN (FANN) as well as Elman\nANN (EANN) models for seasonal data. Three widely popular versions of the basic\nPSO algorithm, viz. Trelea-I, Trelea-II and Clerc-Type1 are considered here.\nThe empirical analysis is conducted on three real-world seasonal time series.\nResults clearly show that each version of the PSO algorithm achieves notably\nbetter forecasting accuracies than the standard Backpropagation (BP) training\nmethod for both FANN and EANN models. The neural network forecasting results\nare also compared with those from the three traditional statistical models,\nviz. Seasonal Autoregressive Integrated Moving Average (SARIMA), Holt-Winters\n(HW) and Support Vector Machine (SVM). The comparison demonstrates that both\nPSO and BP based neural networks outperform SARIMA, HW and SVM models for all\nthree time series datasets. The forecasting performances of ANNs are further\nimproved through combining the outputs from the three PSO based models."
},{
    "category": "cs.NE", 
    "doi": "10.1109/IAdCC.2013.6514315", 
    "link": "http://arxiv.org/pdf/1302.7051v2", 
    "other_authors": "Wesam Elshamy, Hassan M Emara, Ahmed Bahgat", 
    "title": "Polyploidy and Discontinuous Heredity Effect on Evolutionary   Multi-Objective Optimization", 
    "arxiv-id": "1302.7051v2", 
    "author": "Ahmed Bahgat", 
    "publish": "2013-02-28T01:32:28Z", 
    "summary": "This paper examines the effect of mimicking discontinuous heredity caused by\ncarrying more than one chromosome in some living organisms cells in\nEvolutionary Multi-Objective Optimization algorithms. In this representation,\nthe phenotype may not fully reflect the genotype. By doing so we are mimicking\nliving organisms inheritance mechanism, where traits may be silently carried\nfor many generations to reappear later. Representations with different number\nof chromosomes in each solution vector are tested on different benchmark\nproblems with high number of decision variables and objectives. A comparison\nwith Non-Dominated Sorting Genetic Algorithm-II is done on all problems."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ISIE.2008.4677254", 
    "link": "http://arxiv.org/pdf/1302.7080v1", 
    "other_authors": "Hassan M Emara, Wesam Elshamy, Ahmed Bahgat", 
    "title": "Parameter Identification of Induction Motor Using Modified Particle   Swarm Optimization Algorithm", 
    "arxiv-id": "1302.7080v1", 
    "author": "Ahmed Bahgat", 
    "publish": "2013-02-28T04:41:53Z", 
    "summary": "This paper presents a new technique for induction motor parameter\nidentification. The proposed technique is based on a simple startup test using\na standard V/F inverter. The recorded startup currents are compared to that\nobtained by simulation of an induction motor model. A Modified PSO optimization\nis used to find out the best model parameter that minimizes the sum square\nerror between the measured and the simulated currents. The performance of the\nmodified PSO is compared with other optimization methods including line search,\nconventional PSO and Genetic Algorithms. Simulation results demonstrate the\nability of the proposed technique to capture the true values of the machine\nparameters and the superiority of the results obtained using the modified PSO\nover other optimization techniques."
},{
    "category": "cs.NE", 
    "doi": "10.1109/SIS.2007.367950", 
    "link": "http://arxiv.org/pdf/1303.0323v1", 
    "other_authors": "Wesam Elshamy, Hassan M Emara, Ahmed Bahgat", 
    "title": "Clubs-based Particle Swarm Optimization", 
    "arxiv-id": "1303.0323v1", 
    "author": "Ahmed Bahgat", 
    "publish": "2013-03-02T00:05:26Z", 
    "summary": "This paper introduces a new dynamic neighborhood network for particle swarm\noptimization. In the proposed Clubs-based Particle Swarm Optimization (C-PSO)\nalgorithm, each particle initially joins a default number of what we call\n'clubs'. Each particle is affected by its own experience and the experience of\nthe best performing member of the clubs it is a member of. Clubs membership is\ndynamic, where the worst performing particles socialize more by joining more\nclubs to learn from other particles and the best performing particles are made\nto socialize less by leaving clubs to reduce their strong influence on other\nmembers. Particles return gradually to default membership level when they stop\nshowing extreme performance. Inertia weights of swarm members are made random\nwithin a predefined range. This proposed dynamic neighborhood algorithm is\ncompared with other two algorithms having static neighborhood topologies on a\nset of classic benchmark problems. The results showed superior performance for\nC-PSO regarding escaping local optima and convergence speed."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijdps.2011.2604", 
    "link": "http://arxiv.org/pdf/1303.0462v1", 
    "other_authors": "Moslema Jahan, M. M. A. Hashem, Gazi Abdullah Shahriar", 
    "title": "Distributed Evolutionary Computation: A New Technique for Solving Large   Number of Equations", 
    "arxiv-id": "1303.0462v1", 
    "author": "Gazi Abdullah Shahriar", 
    "publish": "2013-03-03T05:38:41Z", 
    "summary": "Evolutionary computation techniques have mostly been used to solve various\noptimization and learning problems successfully. Evolutionary algorithm is more\neffective to gain optimal solution(s) to solve complex problems than\ntraditional methods. In case of problems with large set of parameters,\nevolutionary computation technique incurs a huge computational burden for a\nsingle processing unit. Taking this limitation into account, this paper\npresents a new distributed evolutionary computation technique, which decomposes\ndecision vectors into smaller components and achieves optimal solution in a\nshort time. In this technique, a Jacobi-based Time Variant Adaptive (JBTVA)\nHybrid Evolutionary Algorithm is distributed incorporating cluster computation.\nMoreover, two new selection methods named Best All Selection (BAS) and Twin\nSelection (TS) are introduced for selecting best fit solution vector.\nExperimental results show that optimal solution is achieved for different kinds\nof problems having huge parameters and a considerable speedup is obtained in\nproposed distributed system."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijdps.2011.2604", 
    "link": "http://arxiv.org/pdf/1303.1051v1", 
    "other_authors": "I. Ayachi, R. Kammarti, M. Ksouri, P. Borne, :, LAGIS, Ecole Centrale de Lille, :, LACS, Ecole Nationale des Ingenieurs de Tunis", 
    "title": "A Genetic algorithm to solve the container storage space allocation   problem", 
    "arxiv-id": "1303.1051v1", 
    "author": "Ecole Nationale des Ingenieurs de Tunis", 
    "publish": "2013-03-05T14:45:30Z", 
    "summary": "This paper presented a genetic algorithm (GA) to solve the container storage\nproblem in the port. This problem is studied with different container types\nsuch as regular, open side, open top, tank, empty and refrigerated containers.\nThe objective of this problem is to determine an optimal containers\narrangement, which respects customers delivery deadlines, reduces the rehandle\noperations of containers and minimizes the stop time of the container ship. In\nthis paper, an adaptation of the genetic algorithm to the container storage\nproblem is detailed and some experimental results are presented and discussed.\nThe proposed approach was compared to a Last In First Out (LIFO) algorithm\napplied to the same problem and has recorded good results"
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijcsit.2010.2415", 
    "link": "http://arxiv.org/pdf/1303.1243v1", 
    "other_authors": "Md. Amjad Hossain, Md. Kawser Hossain, M. M. A. Hashem", 
    "title": "A Generalized Hybrid Real-Coded Quantum Evolutionary Algorithm Based on   Particle Swarm Theory with Arithmetic Crossover", 
    "arxiv-id": "1303.1243v1", 
    "author": "M. M. A. Hashem", 
    "publish": "2013-03-06T02:55:20Z", 
    "summary": "This paper proposes a generalized Hybrid Real-coded Quantum Evolutionary\nAlgorithm (HRCQEA) for optimizing complex functions as well as combinatorial\noptimization. The main idea of HRCQEA is to devise a new technique for mutation\nand crossover operators. Using the evolutionary equation of PSO a\nSingle-Multiple gene Mutation (SMM) is designed and the concept of Arithmetic\nCrossover (AC) is used in the new Crossover operator. In HRCQEA, each triploid\nchromosome represents a particle and the position of the particle is updated\nusing SMM and Quantum Rotation Gate (QRG), which can make the balance between\nexploration and exploitation. Crossover is employed to expand the search space,\nHill Climbing Selection (HCS) and elitism help to accelerate the convergence\nspeed. Simulation results on Knapsack Problem and five benchmark complex\nfunctions with high dimension show that HRCQEA performs better in terms of\nability to discover the global optimum and convergence speed."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijcsit.2010.2415", 
    "link": "http://arxiv.org/pdf/1303.1913v1", 
    "other_authors": "S. Arun Balaji, K. Baskaran", 
    "title": "Design and Development of Artificial Neural Networking (ANN) system   using sigmoid activation function to predict annual rice production in   Tamilnadu", 
    "arxiv-id": "1303.1913v1", 
    "author": "K. Baskaran", 
    "publish": "2013-03-08T08:53:15Z", 
    "summary": "Prediction of annual rice production in all the 31 districts of Tamilnadu is\nan important decision for the Government of Tamilnadu. Rice production is a\ncomplex process and non linear problem involving soil, crop, weather, pest,\ndisease, capital, labour and management parameters. ANN software was designed\nand developed with Feed Forward Back Propagation (FFBP) network to predict rice\nproduction. The input layer has six independent variables like area of\ncultivation and rice production in three seasons like Kuruvai, Samba and Kodai.\nThe popular sigmoid activation function was adopted to convert input data into\nsigmoid values. The hidden layer computes the summation of six sigmoid values\nwith six sets of weightages. The final output was converted into sigmoid values\nusing a sigmoid transfer function. ANN outputs are the predicted results. The\nerror between original data and ANN output values were computed. A threshold\nvalue of 10-9 was used to test whether the error is greater than the threshold\nlevel. If the error is greater than threshold then updating of weights was done\nall summations were done by back propagation. This process was repeated until\nerror equal to zero. The predicted results were printed and it was found to be\nexactly matching with the expected values. It shows that the ANN prediction was\n100% accurate."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijcsit.2010.2415", 
    "link": "http://arxiv.org/pdf/1303.2215v1", 
    "other_authors": "Maumita Bhattacharya", 
    "title": "Expensive Optimisation: A Metaheuristics Perspective", 
    "arxiv-id": "1303.2215v1", 
    "author": "Maumita Bhattacharya", 
    "publish": "2013-03-09T14:41:24Z", 
    "summary": "Stochastic, iterative search methods such as Evolutionary Algorithms (EAs)\nare proven to be efficient optimizers. However, they require evaluation of the\ncandidate solutions which may be prohibitively expensive in many real world\noptimization problems. Use of approximate models or surrogates is being\nexplored as a way to reduce the number of such evaluations. In this paper we\ninvestigated three such methods. The first method (DAFHEA) partially replaces\nan expensive function evaluation by its approximate model. The approximation is\nrealized with support vector machine (SVM) regression models. The second method\n(DAFHEA II) is an enhancement on DAFHEA to accommodate for uncertain\nenvironments. The third one uses surrogate ranking with preference learning or\nordinal regression. The fitness of the candidates is estimated by modeling\ntheir rank. The techniques' performances on some of the benchmark numerical\noptimization problems have been reported. The comparative benefits and\nshortcomings of both techniques have been identified."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijcsit.2010.2415", 
    "link": "http://arxiv.org/pdf/1303.2745v1", 
    "other_authors": "Maumita Bhattacharya", 
    "title": "Evolutionary Approaches to Expensive Optimisation", 
    "arxiv-id": "1303.2745v1", 
    "author": "Maumita Bhattacharya", 
    "publish": "2013-03-12T01:39:11Z", 
    "summary": "Surrogate assisted evolutionary algorithms (EA) are rapidly gaining\npopularity where applications of EA in complex real world problem domains are\nconcerned. Although EAs are powerful global optimizers, finding optimal\nsolution to complex high dimensional, multimodal problems often require very\nexpensive fitness function evaluations. Needless to say, this could brand any\npopulation-based iterative optimization technique to be the most crippling\nchoice to handle such problems. Use of approximate model or surrogates provides\na much cheaper option. However, naturally this cheaper option comes with its\nown price. This paper discusses some of the key issues involved with use of\napproximation in evolutionary algorithm, possible best practices and solutions.\nAnswers to the following questions have been sought: what type of fitness\napproximation to be used; which approximation model to use; how to integrate\nthe approximation model in EA; how much approximation to use; and how to ensure\nreliable approximation."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijcsit.2010.2415", 
    "link": "http://arxiv.org/pdf/1303.3145v2", 
    "other_authors": "Pu Wang, Michael Emmerich, Rui Li, Ke Tang, Thomas Ba\u007feck, Xin Yao", 
    "title": "Convex Hull-Based Multi-objective Genetic Programming for Maximizing ROC   Performance", 
    "arxiv-id": "1303.3145v2", 
    "author": "Xin Yao", 
    "publish": "2013-03-13T12:51:31Z", 
    "summary": "ROC is usually used to analyze the performance of classifiers in data mining.\nROC convex hull (ROCCH) is the least convex major-ant (LCM) of the empirical\nROC curve, and covers potential optima for the given set of classifiers.\nGenerally, ROC performance maximization could be considered to maximize the\nROCCH, which also means to maximize the true positive rate (tpr) and minimize\nthe false positive rate (fpr) for each classifier in the ROC space. However,\ntpr and fpr are conflicting with each other in the ROCCH optimization process.\nThough ROCCH maximization problem seems like a multi-objective optimization\nproblem (MOP), the special characters make it different from traditional MOP.\nIn this work, we will discuss the difference between them and propose convex\nhull-based multi-objective genetic programming (CH-MOGP) to solve ROCCH\nmaximization problems. Convex hull-based sort is an indicator based selection\nscheme that aims to maximize the area under convex hull, which serves as a\nunary indicator for the performance of a set of points. A selection procedure\nis described that can be efficiently implemented and follows similar design\nprinciples than classical hyper-volume based optimization algorithms. It is\nhypothesized that by using a tailored indicator-based selection scheme CH-MOGP\ngets more efficient for ROC convex hull approximation than algorithms which\ncompute all Pareto optimal points. To test our hypothesis we compare the new\nCH-MOGP to MOGP with classical selection schemes, including NSGA-II, MOEA/D)\nand SMS-EMOA. Meanwhile, CH-MOGP is also compared with traditional machine\nlearning algorithms such as C4.5, Naive Bayes and Prie. Experimental results\nbased on 22 well-known UCI data sets show that CH-MOGP outperforms\nsignificantly traditional EMOAs."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijcsit.2010.2415", 
    "link": "http://arxiv.org/pdf/1303.3469v1", 
    "other_authors": "Hassan A. Bashir, Richard S. Neville", 
    "title": "Hybrid Evolutionary Computation for Continuous Optimization", 
    "arxiv-id": "1303.3469v1", 
    "author": "Richard S. Neville", 
    "publish": "2013-03-14T14:59:32Z", 
    "summary": "Hybrid optimization algorithms have gained popularity as it has become\napparent there cannot be a universal optimization strategy which is globally\nmore beneficial than any other. Despite their popularity, hybridization\nframeworks require more detailed categorization regarding: the nature of the\nproblem domain, the constituent algorithms, the coupling schema and the\nintended area of application. This report proposes a hybrid algorithm for\nsolving small to large-scale continuous global optimization problems. It\ncomprises evolutionary computation (EC) algorithms and a sequential quadratic\nprogramming (SQP) algorithm; combined in a collaborative portfolio. The SQP is\na gradient based local search method. To optimize the individual contributions\nof the EC and SQP algorithms for the overall success of the proposed hybrid\nsystem, improvements were made in key features of these algorithms. The report\nproposes enhancements in: i) the evolutionary algorithm, ii) a new convergence\ndetection mechanism was proposed; and iii) in the methods for evaluating the\nsearch directions and step sizes for the SQP local search algorithm. The\nproposed hybrid design aim was to ensure that the two algorithms complement\neach other by exploring and exploiting the problem search space. Preliminary\nresults justify that an adept hybridization of evolutionary algorithms with a\nsuitable local search method, could yield a robust and efficient means of\nsolving wide range of global optimization problems. Finally, a discussion of\nthe outcomes of the initial investigation and a review of the associated\nchallenges and inherent limitations of the proposed method is presented to\ncomplete the investigation. The report highlights extensive research,\nparticularly, some potential case studies and application areas."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijcsit.2010.2415", 
    "link": "http://arxiv.org/pdf/1303.3901v2", 
    "other_authors": "Ankur Sinha, Pekka Malo, Kalyanmoy Deb", 
    "title": "Efficient Evolutionary Algorithm for Single-Objective Bilevel   Optimization", 
    "arxiv-id": "1303.3901v2", 
    "author": "Kalyanmoy Deb", 
    "publish": "2013-03-15T20:30:57Z", 
    "summary": "Bilevel optimization problems are a class of challenging optimization\nproblems, which contain two levels of optimization tasks. In these problems,\nthe optimal solutions to the lower level problem become possible feasible\ncandidates to the upper level problem. Such a requirement makes the\noptimization problem difficult to solve, and has kept the researchers busy\ntowards devising methodologies, which can efficiently handle the problem.\nDespite the efforts, there hardly exists any effective methodology, which is\ncapable of handling a complex bilevel problem. In this paper, we introduce\nbilevel evolutionary algorithm based on quadratic approximations (BLEAQ) of\noptimal lower level variables with respect to the upper level variables. The\napproach is capable of handling bilevel problems with different kinds of\ncomplexities in relatively smaller number of function evaluations. Ideas from\nclassical optimization have been hybridized with evolutionary methods to\ngenerate an efficient optimization algorithm for generic bilevel problems. The\nefficacy of the algorithm has been shown on two sets of test problems. The\nfirst set is a recently proposed SMD test set, which contains problems with\ncontrollable complexities, and the second set contains standard test problems\ncollected from the literature. The proposed method has been evaluated against\ntwo benchmarks, and the performance gain is observed to be significant."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijcsit.2010.2415", 
    "link": "http://arxiv.org/pdf/1303.6310v3", 
    "other_authors": "Iztok Fister Jr., Du\u0161an Fister, Xin-She Yang", 
    "title": "A hybrid bat algorithm", 
    "arxiv-id": "1303.6310v3", 
    "author": "Xin-She Yang", 
    "publish": "2013-03-25T20:53:09Z", 
    "summary": "Swarm intelligence is a very powerful technique to be used for optimization\npurposes. In this paper we present a new swarm intelligence algorithm, based on\nthe bat algorithm. The Bat algorithm is hybridized with differential evolution\nstrategies. Besides showing very promising results of the standard benchmark\nfunctions, this hybridization also significantly improves the original bat\nalgorithm."
},{
    "category": "cs.NE", 
    "doi": "10.1088/1742-6596/490/1/012040", 
    "link": "http://arxiv.org/pdf/1308.1940v1", 
    "other_authors": "Cyril Voyant, Wani W. Tamas, Christophe Paoli, Aur\u00e9lia Balu, Marc Muselli, Marie Laure Nivet, Gilles Notton", 
    "title": "Time series modeling with pruned multi-layer perceptron and 2-stage   damped least-squares method", 
    "arxiv-id": "1308.1940v1", 
    "author": "Gilles Notton", 
    "publish": "2013-08-08T19:18:05Z", 
    "summary": "A Multi-Layer Perceptron (MLP) defines a family of artificial neural networks\noften used in TS modeling and forecasting. Because of its \"black box\" aspect,\nmany researchers refuse to use it. Moreover, the optimization (often based on\nthe exhaustive approach where \"all\" configurations are tested) and learning\nphases of this artificial intelligence tool (often based on the\nLevenberg-Marquardt algorithm; LMA) are weaknesses of this approach\n(exhaustively and local minima). These two tasks must be repeated depending on\nthe knowledge of each new problem studied, making the process, long, laborious\nand not systematically robust. In this paper a pruning process is proposed.\nThis method allows, during the training phase, to carry out an inputs selecting\nmethod activating (or not) inter-nodes connections in order to verify if\nforecasting is improved. We propose to use iteratively the popular damped\nleast-squares method to activate inputs and neurons. A first pass is applied to\n10% of the learning sample to determine weights significantly different from 0\nand delete other. Then a classical batch process based on LMA is used with the\nnew MLP. The validation is done using 25 measured meteorological TS and\ncross-comparing the prediction results of the classical LMA and the 2-stage\nLMA."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.apenergy.2011.12.085", 
    "link": "http://arxiv.org/pdf/1308.2375v1", 
    "other_authors": "Francesco Bonanno, Giacomo Capizzi, Christian Napoli, Giorgio Graditi, Giuseppe Marco Tina", 
    "title": "A radial basis function neural network based approach for the electrical   characteristics estimation of a photovoltaic module", 
    "arxiv-id": "1308.2375v1", 
    "author": "Giuseppe Marco Tina", 
    "publish": "2013-08-11T08:17:35Z", 
    "summary": "The design process of photovoltaic (PV) modules can be greatly enhanced by\nusing advanced and accurate models in order to predict accurately their\nelectrical output behavior. The main aim of this paper is to investigate the\napplication of an advanced neural network based model of a module to improve\nthe accuracy of the predicted output I--V and P--V curves and to keep in\naccount the change of all the parameters at different operating conditions.\nRadial basis function neural networks (RBFNN) are here utilized to predict the\noutput characteristic of a commercial PV module, by reading only the data of\nsolar irradiation and temperature. A lot of available experimental data were\nused for the training of the RBFNN, and a backpropagation algorithm was\nemployed. Simulation and experimental validation is reported."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.apenergy.2011.12.085", 
    "link": "http://arxiv.org/pdf/1308.3080v4", 
    "other_authors": "Jun He, Xin Yao", 
    "title": "Average Drift Analysis and Population Scalability", 
    "arxiv-id": "1308.3080v4", 
    "author": "Xin Yao", 
    "publish": "2013-08-14T10:21:35Z", 
    "summary": "This paper aims to study how the population size affects the computation time\nof evolutionary algorithms in a rigorous way. The computation time of an\nevolutionary algorithm can be measured by either the expected number of\ngenerations (hitting time) or the expected number of fitness evaluations\n(running time) to find an optimal solution. Population scalability is the ratio\nof the expected hitting time between a benchmark algorithm and an algorithm\nusing a larger population size. Average drift analysis is presented for\ncomparing the expected hitting time of two algorithms and estimating lower and\nupper bounds on population scalability. Several intuitive beliefs are\nrigorously analysed. It is prove that (1) using a population sometimes\nincreases rather than decreases the expected hitting time; (2) using a\npopulation cannot shorten the expected running time of any elitist evolutionary\nalgorithm on unimodal functions in terms of the time-fitness landscape, but\nthis is not true in terms of the distance-based fitness landscape; (3) using a\npopulation cannot always reduce the expected running time on fully-deceptive\nfunctions, which depends on the benchmark algorithm using elitist selection or\nrandom selection."
},{
    "category": "cs.NE", 
    "doi": "10.1109/TNNLS.2012.2216546", 
    "link": "http://arxiv.org/pdf/1308.3524v1", 
    "other_authors": "Giacomo Capizzi, Christian Napoli, Francesco Bonanno", 
    "title": "Innovative Second-Generation Wavelets Construction With Recurrent Neural   Networks for Solar Radiation Forecasting", 
    "arxiv-id": "1308.3524v1", 
    "author": "Francesco Bonanno", 
    "publish": "2013-08-15T23:42:02Z", 
    "summary": "Solar radiation prediction is an important challenge for the electrical\nengineer because it is used to estimate the power developed by commercial\nphotovoltaic modules. This paper deals with the problem of solar radiation\nprediction based on observed meteorological data. A 2-day forecast is obtained\nby using novel wavelet recurrent neural networks (WRNNs). In fact, these WRNNS\nare used to exploit the correlation between solar radiation and\ntimescale-related variations of wind speed, humidity, and temperature. The\ninput to the selected WRNN is provided by timescale-related bands of wavelet\ncoefficients obtained from meteorological time series. The experimental setup\navailable at the University of Catania, Italy, provided this information. The\nnovelty of this approach is that the proposed WRNN performs the prediction in\nthe wavelet domain and, in addition, also performs the inverse wavelet\ntransform, giving the predicted signal as output. The obtained simulation\nresults show a very low root-mean-square error compared to the results of the\nsolar radiation prediction approaches obtained by hybrid neural networks\nreported in the recent literature."
},{
    "category": "cs.NE", 
    "doi": "10.1109/TNNLS.2012.2216546", 
    "link": "http://arxiv.org/pdf/1308.4506v1", 
    "other_authors": "Ala Aboudib, Vincent Gripon, Xiaoran Jiang", 
    "title": "A study of retrieval algorithms of sparse messages in networks of neural   cliques", 
    "arxiv-id": "1308.4506v1", 
    "author": "Xiaoran Jiang", 
    "publish": "2013-08-21T08:19:14Z", 
    "summary": "Associative memories are data structures addressed using part of the content\nrather than an index. They offer good fault reliability and biological\nplausibility. Among different families of associative memories, sparse ones are\nknown to offer the best efficiency (ratio of the amount of bits stored to that\nof bits used by the network itself). Their retrieval process performance has\nbeen shown to benefit from the use of iterations. However classical algorithms\nrequire having prior knowledge about the data to retrieve such as the number of\nnonzero symbols. We introduce several families of algorithms to enhance the\nretrieval process performance in recently proposed sparse associative memories\nbased on binary neural networks. We show that these algorithms provide better\nperformance, along with better plausibility than existing techniques. We also\nanalyze the required number of iterations and derive corresponding curves."
},{
    "category": "cs.NE", 
    "doi": "10.1109/TNNLS.2012.2216546", 
    "link": "http://arxiv.org/pdf/1308.4675v1", 
    "other_authors": "Denny Hermawanto", 
    "title": "Genetic Algorithm for Solving Simple Mathematical Equality Problem", 
    "arxiv-id": "1308.4675v1", 
    "author": "Denny Hermawanto", 
    "publish": "2013-08-16T04:36:03Z", 
    "summary": "This paper explains genetic algorithm for novice in this field. Basic\nphilosophy of genetic algorithm and its flowchart are described. Step by step\nnumerical computation of genetic algorithm for solving simple mathematical\nequality problem will be briefly explained"
},{
    "category": "cs.NE", 
    "doi": "10.1109/TNNLS.2012.2216546", 
    "link": "http://arxiv.org/pdf/1308.5033v1", 
    "other_authors": "Guanghui Huang, Zhifeng Pan", 
    "title": "A hybrid evolutionary algorithm with importance sampling for   multi-dimensional optimization", 
    "arxiv-id": "1308.5033v1", 
    "author": "Zhifeng Pan", 
    "publish": "2013-08-23T03:11:54Z", 
    "summary": "A hybrid evolutionary algorithm with importance sampling method is proposed\nfor multi-dimensional optimization problems in this paper. In order to make use\nof the information provided in the search process, a set of visited solutions\nis selected to give scores for intervals in each dimension, and they are\nupdated as algorithm proceeds. Those intervals with higher scores are regarded\nas good intervals, which are used to estimate the joint distribution of optimal\nsolutions through an interaction between the pool of good genetics, which are\nthe individuals with smaller fitness values. And the sampling probabilities for\ngood genetics are determined through an interaction between those estimated\ngood intervals. It is a cross validation mechanism which determines the\nsampling probabilities for good intervals and genetics, and the resulted\nprobabilities are used to design crossover, mutation and other stochastic\noperators with importance sampling method. As the selection of genetics and\nintervals is not directly dependent on the values of fitness, the resulted\noffsprings may avoid the trap of local optima. And a purely random EA is also\ncombined into the proposed algorithm to maintain the diversity of population.\n30 benchmark test functions are used to evaluate the performance of the\nproposed algorithm, and it is found that the proposed hybrid algorithm is an\nefficient algorithm for multi-dimensional optimization problems considered in\nthis paper."
},{
    "category": "cs.NE", 
    "doi": "10.1109/TNNLS.2012.2216546", 
    "link": "http://arxiv.org/pdf/1308.5269v2", 
    "other_authors": "Hamed Yousefi Mesri", 
    "title": "A comparative analysis of methods for estimating axon diameter using DWI", 
    "arxiv-id": "1308.5269v2", 
    "author": "Hamed Yousefi Mesri", 
    "publish": "2013-08-24T00:57:26Z", 
    "summary": "The importance of studying the brain microstructure is described and the\nexisting and state of the art non-invasive methods for the investigation of the\nbrain microstructure using Diffusion Weighted Magnetic Resonance Imaging (DWI)\nis studied. In the next step, Cramer-Rao Lower Bound (CRLB) analysis is\ndescribed and utilised for assessment of the minimum estimation error and\nuncertainty level of different Diffusion Weighted Magnetic Resonance (DWMR)\nsignal decay models. The analyses are performed considering the best scenario\nthrough which, we assume that the models are the appropriate representation of\nthe measured phenomena. This includes the study of the sensitivity of the\nestimations to the measurement and model parameters. It is demonstrated that\nnone of the existing models can achieve a reasonable minimum uncertainty level\nunder typical measurement setup. At the end, the practical obstacles for\nachieving higher performance in clinical and experimental environments are\nstudied and their effects on feasibility of the methods are discussed."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijaia.2014.5110", 
    "link": "http://arxiv.org/pdf/1402.0708v1", 
    "other_authors": "Ezgi Deniz Ulker, Sadik Ulker", 
    "title": "Microstrip Coupler Design Using Bat Algorithm", 
    "arxiv-id": "1402.0708v1", 
    "author": "Sadik Ulker", 
    "publish": "2014-02-04T12:25:31Z", 
    "summary": "Evolutionary and swarm algorithms have found many applications in design\nproblems since todays computing power enables these algorithms to find\nsolutions to complicated design problems very fast. Newly proposed hybrid\nalgorithm, bat algorithm, has been applied for the design of microwave\nmicrostrip couplers for the first time. Simulation results indicate that the\nbat algorithm is a very fast algorithm and it produces very reliable results."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ISMVL.2014.44", 
    "link": "http://arxiv.org/pdf/1402.0808v1", 
    "other_authors": "Hooman Jarollahi, Naoya Onizawa, Takahiro Hanyu, Warren J. Gross", 
    "title": "Associative Memories Based on Multiple-Valued Sparse Clustered Networks", 
    "arxiv-id": "1402.0808v1", 
    "author": "Warren J. Gross", 
    "publish": "2014-02-03T16:23:33Z", 
    "summary": "Associative memories are structures that store data patterns and retrieve\nthem given partial inputs. Sparse Clustered Networks (SCNs) are\nrecently-introduced binary-weighted associative memories that significantly\nimprove the storage and retrieval capabilities over the prior state-of-the art.\nHowever, deleting or updating the data patterns result in a significant\nincrease in the data retrieval error probability. In this paper, we propose an\nalgorithm to address this problem by incorporating multiple-valued weights for\nthe interconnections used in the network. The proposed algorithm lowers the\nerror rate by an order of magnitude for our sample network with 60% deleted\ncontents. We then investigate the advantages of the proposed algorithm for\nhardware implementations."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ISMVL.2014.44", 
    "link": "http://arxiv.org/pdf/1402.1931v1", 
    "other_authors": "Rashid Ahmed, John A. Avaritsiotis", 
    "title": "MCA Learning Algorithm for Incident Signals Estimation: A Review", 
    "arxiv-id": "1402.1931v1", 
    "author": "John A. Avaritsiotis", 
    "publish": "2014-02-09T09:55:13Z", 
    "summary": "Recently there has been many works on adaptive subspace filtering in the\nsignal processing literature. Most of them are concerned with tracking the\nsignal subspace spanned by the eigenvectors corresponding to the eigenvalues of\nthe covariance matrix of the signal plus noise data. Minor Component Analysis\n(MCA) is important tool and has a wide application in telecommunications,\nantenna array processing, statistical parametric estimation, etc. As an\nimportant feature extraction technique, MCA is a statistical method of\nextracting the eigenvector associated with the smallest eigenvalue of the\ncovariance matrix. In this paper, we will present a MCA learning algorithm to\nextract minor component from input signals, and the learning rate parameter is\nalso presented, which ensures fast convergence of the algorithm, because it has\ndirect effect on the convergence of the weight vector and the error level is\naffected by this value. MCA is performed to determine the estimated DOA.\nSimulation results will be furnished to illustrate the theoretical results\nachieved."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ISMVL.2014.44", 
    "link": "http://arxiv.org/pdf/1402.5428v1", 
    "other_authors": "Khalid jebari, Mohammed Madiafi, Abdelaziz Elmoujahid", 
    "title": "An Evolutionary approach for solving Shr\u00f6dinger Equation", 
    "arxiv-id": "1402.5428v1", 
    "author": "Abdelaziz Elmoujahid", 
    "publish": "2014-02-21T21:18:58Z", 
    "summary": "The purpose of this paper is to present a method of solving the Shr\\\"odinger\nEquation (SE) by Genetic Algorithms and Grammatical Evolution. The method forms\ngenerations of trial solutions expressed in an analytical form. We illustrate\nthe effectiveness of this method providing, for example, the results of its\napplication to a quantum system minimal energy, and we compare these results\nwith those produced by traditional analytical methods"
},{
    "category": "cs.NE", 
    "doi": "10.1109/ISMVL.2014.44", 
    "link": "http://arxiv.org/pdf/1402.6428v1", 
    "other_authors": "Jayshree Ghorpade-Aher, Vishakha A. Metre", 
    "title": "Clustering Multidimensional Data with PSO based Algorithm", 
    "arxiv-id": "1402.6428v1", 
    "author": "Vishakha A. Metre", 
    "publish": "2014-02-26T06:08:27Z", 
    "summary": "Data clustering is a recognized data analysis method in data mining whereas\nK-Means is the well known partitional clustering method, possessing pleasant\nfeatures. We observed that, K-Means and other partitional clustering techniques\nsuffer from several limitations such as initial cluster centre selection,\npreknowledge of number of clusters, dead unit problem, multiple cluster\nmembership and premature convergence to local optima. Several optimization\nmethods are proposed in the literature in order to solve clustering\nlimitations, but Swarm Intelligence (SI) has achieved its remarkable position\nin the concerned area. Particle Swarm Optimization (PSO) is the most popular SI\ntechnique and one of the favorite areas of researchers. In this paper, we\npresent a brief overview of PSO and applicability of its variants to solve\nclustering challenges. Also, we propose an advanced PSO algorithm named as\nSubtractive Clustering based Boundary Restricted Adaptive Particle Swarm\nOptimization (SC-BR-APSO) algorithm for clustering multidimensional data. For\ncomparison purpose, we have studied and analyzed various algorithms such as\nK-Means, PSO, K-Means-PSO, Hybrid Subtractive + PSO, BRAPSO, and proposed\nalgorithm on nine different datasets. The motivation behind proposing\nSC-BR-APSO algorithm is to deal with multidimensional data clustering, with\nminimum error rate and maximum convergence rate."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ISMVL.2014.44", 
    "link": "http://arxiv.org/pdf/1402.6888v1", 
    "other_authors": "Adam Erskine, J Michael Herrmann", 
    "title": "CriPS: Critical Dynamics in Particle Swarm Optimization", 
    "arxiv-id": "1402.6888v1", 
    "author": "J Michael Herrmann", 
    "publish": "2014-02-27T12:35:27Z", 
    "summary": "Particle Swarm Optimisation (PSO) makes use of a dynamical system for solving\na search task. Instead of adding search biases in order to improve performance\nin certain problems, we aim to remove algorithm-induced scales by controlling\nthe swarm with a mechanism that is scale-free except possibly for a suppression\nof scales beyond the system size. In this way a very promising performance is\nachieved due to the balance of large-scale exploration and local search. The\nresulting algorithm shows evidence for self-organised criticality, brought\nabout via the intrinsic dynamics of the swarm as it interacts with the\nobjective function, rather than being explicitly specified. The Critical\nParticle Swarm (CriPS) can be easily combined with many existing extensions\nsuch as chaotic exploration, additional force terms or non-trivial topologies."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ISMVL.2014.44", 
    "link": "http://arxiv.org/pdf/1007.0417v1", 
    "other_authors": "Krishna Chaithanya Lingashetty", 
    "title": "Delta Learning Rule for the Active Sites Model", 
    "arxiv-id": "1007.0417v1", 
    "author": "Krishna Chaithanya Lingashetty", 
    "publish": "2010-07-02T18:05:29Z", 
    "summary": "This paper reports the results on methods of comparing the memory retrieval\ncapacity of the Hebbian neural network which implements the B-Matrix approach,\nby using the Widrow-Hoff rule of learning. We then, extend the recently\nproposed Active Sites model by developing a delta rule to increase memory\ncapacity. Also, this paper extends the binary neural network to a multi-level\n(non-binary) neural network."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ISMVL.2014.44", 
    "link": "http://arxiv.org/pdf/1007.4221v2", 
    "other_authors": "Robert Nowotniak, Jacek Kucharski", 
    "title": "Building Blocks Propagation in Quantum-Inspired Genetic Algorithm", 
    "arxiv-id": "1007.4221v2", 
    "author": "Jacek Kucharski", 
    "publish": "2010-07-23T21:30:18Z", 
    "summary": "This paper presents an analysis of building blocks propagation in\nQuantum-Inspired Genetic Algorithm, which belongs to a new class of\nmetaheuristics drawing their inspiration from both biological evolution and\nunitary evolution of quantum systems. The expected number of quantum\nchromosomes matching a schema has been analyzed and a random variable\ncorresponding to this issue has been introduced. The results have been compared\nwith Simple Genetic Algorithm. Also, it has been presented how selected binary\nquantum chromosomes cover a domain of one-dimensional fitness function."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ISMVL.2014.44", 
    "link": "http://arxiv.org/pdf/1007.4707v1", 
    "other_authors": "Timo K\u00f6tzing, Frank Neumann, Dirk Sudholt, Markus Wagner", 
    "title": "Simple Max-Min Ant Systems and the Optimization of Linear Pseudo-Boolean   Functions", 
    "arxiv-id": "1007.4707v1", 
    "author": "Markus Wagner", 
    "publish": "2010-07-27T13:07:24Z", 
    "summary": "With this paper, we contribute to the understanding of ant colony\noptimization (ACO) algorithms by formally analyzing their runtime behavior. We\nstudy simple MAX-MIN ant systems on the class of linear pseudo-Boolean\nfunctions defined on binary strings of length 'n'. Our investigations point out\nhow the progress according to function values is stored in pheromone. We\nprovide a general upper bound of O((n^3 \\log n)/ \\rho) for two ACO variants on\nall linear functions, where (\\rho) determines the pheromone update strength.\nFurthermore, we show improved bounds for two well-known linear pseudo-Boolean\nfunctions called OneMax and BinVal and give additional insights using an\nexperimental study."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ISMVL.2014.44", 
    "link": "http://arxiv.org/pdf/1104.0283v1", 
    "other_authors": "Mike Stimpson", 
    "title": "Evolving a New Feature for a Working Program", 
    "arxiv-id": "1104.0283v1", 
    "author": "Mike Stimpson", 
    "publish": "2011-04-02T03:33:02Z", 
    "summary": "A genetic programming system is created. A first fitness function f1 is used\nto evolve a program that implements a first feature. Then the fitness function\nis switched to a second function f2, which is used to evolve a program that\nimplements a second feature while still maintaining the first feature. The\nmedian number of generations G1 and G2 needed to evolve programs that work as\ndefined by f1 and f2 are measured. The behavior of G1 and G2 are observed as\nthe difficulty of the problem is increased.\n  In these systems, the density D1 of programs that work (for fitness function\nf1) is measured in the general population of programs. The relationship\nG1~1/sqrt(D1) is observed to approximately hold. Also, the density D2 of\nprograms that work (for fitness function f2) is measured in the general\npopulation of programs. The relationship G2~1/sqrt(D2) is observed to\napproximately hold."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ISMVL.2014.44", 
    "link": "http://arxiv.org/pdf/1104.0775v2", 
    "other_authors": "Markus Wagner, Jareth Day, Diora Jordan, Trent Kroeger, Frank Neumann", 
    "title": "Evolving Pacing Strategies for Team Pursuit Track Cycling", 
    "arxiv-id": "1104.0775v2", 
    "author": "Frank Neumann", 
    "publish": "2011-04-05T08:46:33Z", 
    "summary": "Team pursuit track cycling is a bicycle racing sport held on velodromes and\nis part of the Summer Olympics. It involves the use of strategies to minimize\nthe overall time that a team of cyclists needs to complete a race. We present\nan optimisation framework for team pursuit track cycling and show how to evolve\nstrategies using metaheuristics for this interesting real-world problem. Our\nexperimental results show that these heuristics lead to significantly better\nstrategies than state-of-art strategies that are currently used by teams of\ncyclists."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ISMVL.2014.44", 
    "link": "http://arxiv.org/pdf/1104.2644v1", 
    "other_authors": "Fernando G. Lobo", 
    "title": "Idealized Dynamic Population Sizing for Uniformly Scaled Problems", 
    "arxiv-id": "1104.2644v1", 
    "author": "Fernando G. Lobo", 
    "publish": "2011-04-13T23:24:49Z", 
    "summary": "This paper explores an idealized dynamic population sizing strategy for\nsolving additive decomposable problems of uniform scale. The method is designed\non top of the foundations of existing population sizing theory for this class\nof problems, and is carefully compared with an optimal fixed population sized\ngenetic algorithm. The resulting strategy should be close to a lower bound in\nterms of what can be achieved, performance-wise, by self-adjusting population\nsizing algorithms for this class of problems."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ISMVL.2014.44", 
    "link": "http://arxiv.org/pdf/1204.0183v1", 
    "other_authors": "Youssef Bassil", 
    "title": "Neural Network Model for Path-Planning of Robotic Rover Systems", 
    "arxiv-id": "1204.0183v1", 
    "author": "Youssef Bassil", 
    "publish": "2012-04-01T09:24:19Z", 
    "summary": "Today, robotics is an auspicious and fast-growing branch of technology that\ninvolves the manufacturing, design, and maintenance of robot machines that can\noperate in an autonomous fashion and can be used in a wide variety of\napplications including space exploration, weaponry, household, and\ntransportation. More particularly, in space applications, a common type of\nrobots has been of widespread use in the recent years. It is called planetary\nrover which is a robot vehicle that moves across the surface of a planet and\nconducts detailed geological studies pertaining to the properties of the\nlanding cosmic environment. However, rovers are always impeded by obstacles\nalong the traveling path which can destabilize the rover's body and prevent it\nfrom reaching its goal destination. This paper proposes an ANN model that\nallows rover systems to carry out autonomous path-planning to successfully\nnavigate through challenging planetary terrains and follow their goal location\nwhile avoiding dangerous obstacles. The proposed ANN is a multilayer network\nmade out of three layers: an input, a hidden, and an output layer. The network\nis trained in offline mode using back-propagation supervised learning\nalgorithm. A software-simulated rover was experimented and it revealed that it\nwas able to follow the safest trajectory despite existing obstacles. As future\nwork, the proposed ANN is to be parallelized so as to speed-up the execution\ntime of the training process."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ISMVL.2014.44", 
    "link": "http://arxiv.org/pdf/1204.0262v2", 
    "other_authors": "Greg Fish", 
    "title": "Managing contextual artificial neural networks with a service-based   mediator", 
    "arxiv-id": "1204.0262v2", 
    "author": "Greg Fish", 
    "publish": "2012-04-01T20:17:32Z", 
    "summary": "Today, a wide variety of probabilistic and expert AI systems used to analyze\nreal world inputs such as unstructured text, sounds, images, and statistical\ndata. However, all these systems exist on different platforms, with different\nimplementations, and with very different, often very specific goals in mind.\nThis paper introduces a concept for a mediator framework for such systems and\nseeks to show several architectures which would support it, potential benefits\nin combining the signals of disparate networks for formalized, high level logic\nand signal processing, and its possible academic and industrial uses."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ISMVL.2014.44", 
    "link": "http://arxiv.org/pdf/1204.1706v1", 
    "other_authors": "Mostafa Rahimi Azghadi, Said Al-Sarawi, Nicolangelo Iannella, Derek Abbott", 
    "title": "Efficient Design of Triplet Based Spike-Timing Dependent Plasticity", 
    "arxiv-id": "1204.1706v1", 
    "author": "Derek Abbott", 
    "publish": "2012-04-08T04:02:52Z", 
    "summary": "Spike-Timing Dependent Plasticity (STDP) is believed to play an important\nrole in learning and the formation of computational function in the brain. The\nclassical model of STDP which considers the timing between pairs of\npre-synaptic and post-synaptic spikes (p-STDP) is incapable of reproducing\nsynaptic weight changes similar to those seen in biological experiments which\ninvestigate the effect of either higher order spike trains (e.g. triplet and\nquadruplet of spikes), or, simultaneous effect of the rate and timing of spike\npairs on synaptic plasticity. In this paper, we firstly investigate synaptic\nweight changes using a p-STDP circuit and show how it fails to reproduce the\nmentioned complex biological experiments. We then present a new STDP VLSI\ncircuit which acts based on the timing among triplets of spikes (t-STDP) that\nis able to reproduce all the mentioned experimental results. We believe that\nour new STDP VLSI circuit improves upon previous circuits, whose learning\ncapacity exceeds current designs due to its capability of mimicking the\noutcomes of biological experiments more closely; thus plays a significant role\nin future VLSI implementation of neuromorphic systems."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ISMVL.2014.44", 
    "link": "http://arxiv.org/pdf/1204.2139v1", 
    "other_authors": "Mosab Bazargani, Ant\u00f3nio dos Anjos, Fernando G. Lobo, Ali Mollahosseini, Hamid Reza Shahbazkia", 
    "title": "Affine Image Registration Transformation Estimation Using a Real Coded   Genetic Algorithm with SBX", 
    "arxiv-id": "1204.2139v1", 
    "author": "Hamid Reza Shahbazkia", 
    "publish": "2012-04-10T13:19:45Z", 
    "summary": "This paper describes the application of a real coded genetic algorithm (GA)\nto align two or more 2-D images by means of image registration. The proposed\nsearch strategy is a transformation parameters-based approach involving the\naffine transform. The real coded GA uses Simulated Binary Crossover (SBX), a\nparent-centric recombination operator that has shown to deliver a good\nperformance in many optimization problems in the continuous domain. In\naddition, we propose a new technique for matching points between a warped and\nstatic images by using a randomized ordering when visiting the points during\nthe matching procedure. This new technique makes the evaluation of the\nobjective function somewhat noisy, but GAs and other population-based search\nalgorithms have been shown to cope well with noisy fitness evaluations. The\nresults obtained are competitive to those obtained by state-of-the-art\nclassical methods in image registration, confirming the usefulness of the\nproposed noisy objective function and the suitability of SBX as a recombination\noperator for this type of problem."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ISMVL.2014.44", 
    "link": "http://arxiv.org/pdf/1204.2356v1", 
    "other_authors": "Ilya Loshchilov, Marc Schoenauer, Mich\u00e8le Sebag", 
    "title": "Self-Adaptive Surrogate-Assisted Covariance Matrix Adaptation Evolution   Strategy", 
    "arxiv-id": "1204.2356v1", 
    "author": "Mich\u00e8le Sebag", 
    "publish": "2012-04-11T07:00:31Z", 
    "summary": "This paper presents a novel mechanism to adapt surrogate-assisted\npopulation-based algorithms. This mechanism is applied to ACM-ES, a recently\nproposed surrogate-assisted variant of CMA-ES. The resulting algorithm,\nsaACM-ES, adjusts online the lifelength of the current surrogate model (the\nnumber of CMA-ES generations before learning a new surrogate) and the surrogate\nhyper-parameters. Both heuristics significantly improve the quality of the\nsurrogate model, yielding a significant speed-up of saACM-ES compared to the\nACM-ES and CMA-ES baselines. The empirical validation of saACM-ES on the\nBBOB-2012 noiseless testbed demonstrates the efficiency and the scalability\nw.r.t the problem dimension and the population size of the proposed approach,\nthat reaches new best results on some of the benchmark problems."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ISMVL.2014.44", 
    "link": "http://arxiv.org/pdf/1204.4560v1", 
    "other_authors": "Markus Wagner, Jareth Day, Frank Neumann", 
    "title": "A Fast and Effective Local Search Algorithm for Optimizing the Placement   of Wind Turbines", 
    "arxiv-id": "1204.4560v1", 
    "author": "Frank Neumann", 
    "publish": "2012-04-20T08:20:41Z", 
    "summary": "The placement of wind turbines on a given area of land such that the wind\nfarm produces a maximum amount of energy is a challenging optimization problem.\nIn this article, we tackle this problem, taking into account wake effects that\nare produced by the different turbines on the wind farm. We significantly\nimprove upon existing results for the minimization of wake effects by\ndeveloping a new problem-specific local search algorithm. One key step in the\nspeed-up of our algorithm is the reduction in computation time needed to assess\na given wind farm layout compared to previous approaches. Our new method allows\nthe optimization of large real-world scenarios within a single night on a\nstandard computer, whereas weeks on specialized computing servers were required\nfor previous approaches."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ISMVL.2014.44", 
    "link": "http://arxiv.org/pdf/1207.0369v1", 
    "other_authors": "Benjamin Doerr, Daniel Johannsen, Timo K\u00f6tzing, Frank Neumann, Madeleine Theile", 
    "title": "More Effective Crossover Operators for the All-Pairs Shortest Path   Problem", 
    "arxiv-id": "1207.0369v1", 
    "author": "Madeleine Theile", 
    "publish": "2012-07-02T13:14:14Z", 
    "summary": "The all-pairs shortest path problem is the first non-artificial problem for\nwhich it was shown that adding crossover can significantly speed up a\nmutation-only evolutionary algorithm. Recently, the analysis of this algorithm\nwas refined and it was shown to have an expected optimization time (w.r.t. the\nnumber of fitness evaluations) of $\\Theta(n^{3.25}(\\log n)^{0.25})$.\n  In contrast to this simple algorithm, evolutionary algorithms used in\npractice usually employ refined recombination strategies in order to avoid the\ncreation of infeasible offspring. We study extensions of the basic algorithm by\ntwo such concepts which are central in recombination, namely \\emph{repair\nmechanisms} and \\emph{parent selection}. We show that repairing infeasible\noffspring leads to an improved expected optimization time of\n$\\mathord{O}(n^{3.2}(\\log n)^{0.2})$. As a second part of our study we prove\nthat choosing parents that guarantee feasible offspring results in an even\nbetter optimization time of $\\mathord{O}(n^{3}\\log n)$.\n  Both results show that already simple adjustments of the recombination\noperator can asymptotically improve the runtime of evolutionary algorithms."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ISMVL.2014.44", 
    "link": "http://arxiv.org/pdf/1207.0702v1", 
    "other_authors": "Liang Feng, Yew Soon Ong, Ah Hwee Tan, Ivor Wai-Hung Tsang", 
    "title": "Meme as Building Block for Evolutionary Optimization of Problem   Instances", 
    "arxiv-id": "1207.0702v1", 
    "author": "Ivor Wai-Hung Tsang", 
    "publish": "2012-07-03T14:44:27Z", 
    "summary": "A significantly under-explored area of evolutionary optimization in the\nliterature is the study of optimization methodologies that can evolve along\nwith the problems solved. Particularly, present evolutionary optimization\napproaches generally start their search from scratch or the ground-zero state\nof knowledge, independent of how similar the given new problem of interest is\nto those optimized previously. There has thus been the apparent lack of\nautomated knowledge transfers and reuse across problems. Taking the cue, this\npaper introduces a novel Memetic Computational Paradigm for search, one that\nmodels after how human solves problems, and embarks on a study towards\nintelligent evolutionary optimization of problems through the transfers of\nstructured knowledge in the form of memes learned from previous problem-solving\nexperiences, to enhance future evolutionary searches. In particular, the\nproposed memetic search paradigm is composed of four culture-inspired\noperators, namely, Meme Learning, Meme Selection, Meme Variation and Meme\nImitation. The learning operator mines for memes in the form of latent\nstructures derived from past experiences of problem-solving. The selection\noperator identifies the fit memes that replicate and transmit across problems,\nwhile the variation operator introduces innovations into the memes. The\nimitation operator, on the other hand, defines how fit memes assimilate into\nthe search process of newly encountered problems, thus gearing towards\nefficient and effective evolutionary optimization. Finally, comprehensive\nstudies on two widely studied challenging well established NP-hard routing\nproblem domains, particularly, the capacitated vehicle routing (CVR) and\ncapacitated arc routing (CAR), confirm the high efficacy of the proposed\nmemetic computational search paradigm for intelligent evolutionary optimization\nof problems."
},{
    "category": "cs.NE", 
    "doi": "10.5121/cseij.2012.2302", 
    "link": "http://arxiv.org/pdf/1207.2630v1", 
    "other_authors": "Sujatha Srinivasan, Sivakumar Ramakrishnan", 
    "title": "Nugget Discovery with a Multi-objective Cultural Algorithm", 
    "arxiv-id": "1207.2630v1", 
    "author": "Sivakumar Ramakrishnan", 
    "publish": "2012-07-11T13:18:55Z", 
    "summary": "Partial classification popularly known as nugget discovery comes under\ndescriptive knowledge discovery. It involves mining rules for a target class of\ninterest. Classification \"If-Then\" rules are the most sought out by decision\nmakers since they are the most comprehensible form of knowledge mined by data\nmining techniques. The rules have certain properties namely the rule metrics\nwhich are used to evaluate them. Mining rules with user specified properties\ncan be considered as a multi-objective optimization problem since the rules\nhave to satisfy more than one property to be used by the user. Cultural\nalgorithm (CA) with its knowledge sources have been used in solving many\noptimization problems. However research gap exists in using cultural algorithm\nfor multi-objective optimization of rules. In the current study a\nmulti-objective cultural algorithm is proposed for partial classification.\nResults of experiments on benchmark data sets reveal good performance."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.neunet.2013.02.008", 
    "link": "http://arxiv.org/pdf/1207.3368v1", 
    "other_authors": "Jonathan Tapson, Andre van Schaik", 
    "title": "Learning the Pseudoinverse Solution to Network Weights", 
    "arxiv-id": "1207.3368v1", 
    "author": "Andre van Schaik", 
    "publish": "2012-07-13T21:28:17Z", 
    "summary": "The last decade has seen the parallel emergence in computational neuroscience\nand machine learning of neural network structures which spread the input signal\nrandomly to a higher dimensional space; perform a nonlinear activation; and\nthen solve for a regression or classification output by means of a mathematical\npseudoinverse operation. In the field of neuromorphic engineering, these\nmethods are increasingly popular for synthesizing biologically plausible neural\nnetworks, but the \"learning method\" - computation of the pseudoinverse by\nsingular value decomposition - is problematic both for biological plausibility\nand because it is not an online or an adaptive method. We present an online or\nincremental method of computing the pseudoinverse, which we argue is\nbiologically plausible as a learning method, and which can be made adaptable\nfor non-stationary data streams. The method is significantly more\nmemory-efficient than the conventional computation of pseudoinverses by\nsingular value decomposition."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.neunet.2013.02.008", 
    "link": "http://arxiv.org/pdf/1207.4318v1", 
    "other_authors": "Johannes M. Dieterich, Bernd Hartke", 
    "title": "Empirical review of standard benchmark functions using evolutionary   global optimization", 
    "arxiv-id": "1207.4318v1", 
    "author": "Bernd Hartke", 
    "publish": "2012-07-18T09:44:22Z", 
    "summary": "We have employed a recent implementation of genetic algorithms to study a\nrange of standard benchmark functions for global optimization. It turns out\nthat some of them are not very useful as challenging test functions, since they\nneither allow for a discrimination between different variants of genetic\noperators nor exhibit a dimensionality scaling resembling that of real-world\nproblems, for example that of global structure optimization of atomic and\nmolecular clusters. The latter properties seem to be simulated better by two\nother types of benchmark functions. One type is designed to be deceptive,\nexemplified here by Lunacek's function. The other type offers additional\nadvantages of markedly increased complexity and of broad tunability in search\nspace characteristics. For the latter type, we use an implementation based on\nrandomly distributed Gaussians. We advocate the use of the latter types of test\nfunctions for algorithm development and benchmarking."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2001576.2001842", 
    "link": "http://arxiv.org/pdf/1207.4626v1", 
    "other_authors": "Marie-Eleonore Marmion, Clarisse Dhaenens, Laetitia Jourdan, Arnaud Liefooghe, S\u00e9bastien Verel", 
    "title": "The Road to VEGAS: Guiding the Search over Neutral Networks", 
    "arxiv-id": "1207.4626v1", 
    "author": "S\u00e9bastien Verel", 
    "publish": "2012-07-19T12:05:15Z", 
    "summary": "VEGAS (Varying Evolvability-Guided Adaptive Search) is a new methodology\nproposed to deal with the neutrality property of some optimization problems. ts\nmain feature is to consider the whole neutral network rather than an arbitrary\nsolution. Moreover, VEGAS is designed to escape from plateaus based on the\nevolvability of solution and a multi-armed bandit. Experiments are conducted on\nNK-landscapes with neutrality. Results show the importance of considering the\nwhole neutral network and of guiding the search cleverly. The impact of the\nlevel of neutrality and of the exploration-exploitation trade-off are deeply\nanalyzed."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2001576.2001842", 
    "link": "http://arxiv.org/pdf/1207.6682v1", 
    "other_authors": "Brian G. Woolley, Kenneth O. Stanley", 
    "title": "Exploring Promising Stepping Stones by Combining Novelty Search with   Interactive Evolution", 
    "arxiv-id": "1207.6682v1", 
    "author": "Kenneth O. Stanley", 
    "publish": "2012-07-28T03:11:41Z", 
    "summary": "The field of evolutionary computation is inspired by the achievements of\nnatural evolution, in which there is no final objective. Yet the pursuit of\nobjectives is ubiquitous in simulated evolution. A significant problem is that\nobjective approaches assume that intermediate stepping stones will increasingly\nresemble the final objective when in fact they often do not. The consequence is\nthat while solutions may exist, searching for such objectives may not discover\nthem. This paper highlights the importance of leveraging human insight during\nsearch as an alternative to articulating explicit objectives. In particular, a\nnew approach called novelty-assisted interactive evolutionary computation\n(NA-IEC) combines human intuition with novelty search for the first time to\nfacilitate the serendipitous discovery of agent behaviors. In this approach,\nthe human user directs evolution by selecting what is interesting from the\non-screen population of behaviors. However, unlike in typical IEC, the user can\nnow request that the next generation be filled with novel descendants. The\nexperimental results demonstrate that combining human insight with novelty\nsearch finds solutions significantly faster and at lower genomic complexities\nthan fully-automated processes, including pure novelty search, suggesting an\nimportant role for human users in the search for solutions."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2001576.2001842", 
    "link": "http://arxiv.org/pdf/1307.0841v1", 
    "other_authors": "Iztok Fister Jr., Iztok Fister, Janez Brest", 
    "title": "Comparing various regression methods on ensemble strategies in   differential evolution", 
    "arxiv-id": "1307.0841v1", 
    "author": "Janez Brest", 
    "publish": "2013-07-02T20:47:26Z", 
    "summary": "Differential evolution possesses a multitude of various strategies for\ngenerating new trial solutions. Unfortunately, the best strategy is not known\nin advance. Moreover, this strategy usually depends on the problem to be\nsolved. This paper suggests using various regression methods (like random\nforest, extremely randomized trees, gradient boosting, decision trees, and a\ngeneralized linear model) on ensemble strategies in differential evolution\nalgorithm by predicting the best differential evolution strategy during the\nrun. Comparing the preliminary results of this algorithm by optimizing a suite\nof five well-known functions from literature, it was shown that using the\nrandom forest regression method substantially outperformed the results of the\nother regression methods."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2001576.2001842", 
    "link": "http://arxiv.org/pdf/1307.2559v1", 
    "other_authors": "Per Kristian Lehre, Carsten Witt", 
    "title": "General Drift Analysis with Tail Bounds", 
    "arxiv-id": "1307.2559v1", 
    "author": "Carsten Witt", 
    "publish": "2013-07-09T19:40:15Z", 
    "summary": "Drift analysis is one of the state-of-the-art techniques for the runtime\nanalysis of randomized search heuristics. In recent years, many different drift\ntheorems, including additive, multiplicative and variable drift, have been\ndeveloped, applied and partly generalized or adapted to particular processes. A\ncomprehensive overview article was missing.\n  We provide not only such an overview but also present a universal drift\ntheorem that generalizes virtually all existing drift theorems found in the\nliterature. On the one hand, the new theorem bounds the expected first hitting\ntime of optimal states in the underlying stochastic process. On the other hand,\nit also allows for general upper and lower tail bounds on the hitting time,\nwhich were not known before except for the special case of upper bounds in\nmultiplicative drift scenarios. As a proof of concept, the new tail bounds are\napplied to prove very precise sharp-concentration results on the running time\nof the (1+1) EA on OneMax, general linear functions and LeadingOnes. Moreover,\nuser-friendly specializations of the general drift theorem are given."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2001576.2001842", 
    "link": "http://arxiv.org/pdf/1307.3463v4", 
    "other_authors": "Anton Eremeev", 
    "title": "Non-Elitist Genetic Algorithm as a Local Search Method", 
    "arxiv-id": "1307.3463v4", 
    "author": "Anton Eremeev", 
    "publish": "2013-07-12T14:07:09Z", 
    "summary": "Sufficient conditions are found under which the iterated non-elitist genetic\nalgorithm with tournament selection first visits a local optimum in\npolynomially bounded time on average. It is shown that these conditions are\nsatisfied on a class of problems with guaranteed local optima (GLO) if\nappropriate parameters of the algorithm are chosen."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2001576.2001842", 
    "link": "http://arxiv.org/pdf/1307.4186v1", 
    "other_authors": "Iztok Fister Jr., Xin-She Yang, Iztok Fister, Janez Brest, Du\u0161an Fister", 
    "title": "A Brief Review of Nature-Inspired Algorithms for Optimization", 
    "arxiv-id": "1307.4186v1", 
    "author": "Du\u0161an Fister", 
    "publish": "2013-07-16T08:04:01Z", 
    "summary": "Swarm intelligence and bio-inspired algorithms form a hot topic in the\ndevelopments of new algorithms inspired by nature. These nature-inspired\nmetaheuristic algorithms can be based on swarm intelligence, biological\nsystems, physical and chemical systems. Therefore, these algorithms can be\ncalled swarm-intelligence-based, bio-inspired, physics-based and\nchemistry-based, depending on the sources of inspiration. Though not all of\nthem are efficient, a few algorithms have proved to be very efficient and thus\nhave become popular tools for solving real-world problems. Some algorithms are\ninsufficiently studied. The purpose of this review is to present a relatively\ncomprehensive list of all the algorithms in the literature, so as to inspire\nfurther research."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2001576.2001842", 
    "link": "http://arxiv.org/pdf/1307.4274v1", 
    "other_authors": "Carsten Witt", 
    "title": "The Fitness Level Method with Tail Bounds", 
    "arxiv-id": "1307.4274v1", 
    "author": "Carsten Witt", 
    "publish": "2013-07-16T13:45:24Z", 
    "summary": "The fitness-level method, also called the method of f-based partitions, is an\nintuitive and widely used technique for the running time analysis of randomized\nsearch heuristics. It was originally defined to prove upper and lower bounds on\nthe expected running time. Recently, upper tail bounds were added to the\ntechnique; however, these tail bounds only apply to running times that are at\nleast twice as large as the expectation.\n  We remove this restriction and supplement the fitness-level method with sharp\ntail bounds, including lower tails. As an exemplary application, we prove that\nthe running time of randomized local search on OneMax is sharply concentrated\naround n ln n - 0.1159 n."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2001576.2001842", 
    "link": "http://arxiv.org/pdf/1307.7435v1", 
    "other_authors": "Farhad Soleimanian Gharehchopogh, Isa Maleki, Seyyed Reza Khaze", 
    "title": "A new approach in dynamic traveling salesman problem: a hybrid of ant   colony optimization and descending gradient", 
    "arxiv-id": "1307.7435v1", 
    "author": "Seyyed Reza Khaze", 
    "publish": "2013-07-29T01:39:01Z", 
    "summary": "Nowadays swarm intelligence-based algorithms are being used widely to\noptimize the dynamic traveling salesman problem (DTSP). In this paper, we have\nused mixed method of Ant Colony Optimization (AOC)and gradient descent to\noptimize DTSP which differs with ACO algorithm in evaporation rate and\ninnovative data. This approach prevents premature convergence and scape from\nlocal optimum spots and also makes it possible to find better solutions for\nalgorithm. In this paper, we are going to offer gradient descent and ACO\nalgorithm which in comparison to some former methods it shows that algorithm\nhas significantly improved routes optimization."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2001576.2001842", 
    "link": "http://arxiv.org/pdf/1307.8104v1", 
    "other_authors": "Matt Stowe, Subhash Kak", 
    "title": "Neural Network Capacity for Multilevel Inputs", 
    "arxiv-id": "1307.8104v1", 
    "author": "Subhash Kak", 
    "publish": "2013-07-30T19:51:12Z", 
    "summary": "This paper examines the memory capacity of generalized neural networks.\nHopfield networks trained with a variety of learning techniques are\ninvestigated for their capacity both for binary and non-binary alphabets. It is\nshown that the capacity can be much increased when multilevel inputs are used.\nNew learning strategies are proposed to increase Hopfield network capacity, and\nthe scalability of these methods is also examined in respect to size of the\nnetwork. The ability to recall entire patterns from stimulation of a single\nneuron is examined for the increased capacity networks."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2001576.2001842", 
    "link": "http://arxiv.org/pdf/1407.0007v1", 
    "other_authors": "Yu Sun, Louis F. Rossi, Chien-Chung Shen, Jennifer Miller, X. Rosalind Wang, Joseph T. Lizier, Mikhail Prokopenko, Upul Senanayake", 
    "title": "Information Transfer in Swarms with Leaders", 
    "arxiv-id": "1407.0007v1", 
    "author": "Upul Senanayake", 
    "publish": "2014-06-30T02:18:17Z", 
    "summary": "Swarm dynamics is the study of collections of agents that interact with one\nanother without central control. In natural systems, insects, birds, fish and\nother large mammals function in larger units to increase the overall fitness of\nthe individuals. Their behavior is coordinated through local interactions to\nenhance mate selection, predator detection, migratory route identification and\nso forth [Andersson and Wallander 2003; Buhl et al. 2006; Nagy et al. 2010;\nPartridge 1982; Sumpter et al. 2008]. In artificial systems, swarms of\nautonomous agents can augment human activities such as search and rescue, and\nenvironmental monitoring by covering large areas with multiple nodes [Alami et\nal. 2007; Caruso et al. 2008; Ogren et al. 2004; Paley et al. 2007; Sibley et\nal. 2002]. In this paper, we explore the interplay between swarm dynamics,\ncovert leadership and theoretical information transfer. A leader is a member of\nthe swarm that acts upon information in addition to what is provided by local\ninteractions. Depending upon the leadership model, leaders can use their\nexternal information either all the time or in response to local conditions\n[Couzin et al. 2005; Sun et al. 2013]. A covert leader is a leader that is\ntreated no differently than others in the swarm, so leaders and followers\nparticipate equally in whatever interaction model is used [Rossi et al. 2007].\nIn this study, we use theoretical information transfer as a means of analyzing\nswarm interactions to explore whether or not it is possible to distinguish\nbetween followers and leaders based on interactions within the swarm. We find\nthat covert leaders can be distinguished from followers in a swarm because they\nreceive less transfer entropy than followers."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2001576.2001842", 
    "link": "http://arxiv.org/pdf/1407.0008v1", 
    "other_authors": "Grace Gao", 
    "title": "Navigating Robot Swarms Using Collective Intelligence Learned from   Golden Shiner Fish", 
    "arxiv-id": "1407.0008v1", 
    "author": "Grace Gao", 
    "publish": "2014-06-30T02:38:10Z", 
    "summary": "Navigating networked robot swarms often requires knowing where to go, sensing\nthe environment, and path-planning based on the destination and barriers in the\nenvironment. Such a process is computationally intensive. Moreover, as the\nnetwork scales up, the computational load increases quadratically, or even\nexponentially. Unlike these man-made systems, most biological systems scale\nlinearly in complexity. Furthermore, the scale of a biological swarm can even\nenable collective intelligence. One example comes from observations of golden\nshiner fish. Golden shiners naturally prefer darkness and school together. Each\nindividual golden shiner does not know where the darkness is. Neither does it\nsense the light gradients in the environment. However, by moving together as a\nschool, they always end up in the shady area. We apply such collective\nintelligence learned from golden shiner fish to navigating robot swarms. Each\nindividual robot's dynamic is based on the gold shiners' movement strategy---a\nrandom walk with its speed modulated by the light intensity and its direction\naffected by its neighbors. The theoretical analysis and simulation results show\nthat our method 1) promises to navigate a robot swarm with little situational\nknowledge, 2) simplifies control and decision-making for each individual robot,\n3) requires minimal or even no information exchange within the swarm, and 4) is\nhighly distributed, adaptive, and robust."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2001576.2001842", 
    "link": "http://arxiv.org/pdf/1407.0014v1", 
    "other_authors": "Donghwa Jeong, Kiju Lee", 
    "title": "Dispersion and Line Formation in Artificial Swarm Intelligence", 
    "arxiv-id": "1407.0014v1", 
    "author": "Kiju Lee", 
    "publish": "2014-06-30T13:40:02Z", 
    "summary": "One of the major motifs in collective or swarm intelligence is that, even\nthough individuals follow simple rules, the resulting global behavior can be\ncomplex and intelligent. In artificial swarm systems, such as swarm robots, the\ngoal is to use systems that are as simple and cheap as possible, deploy many of\nthem, and coordinate them to conduct complex tasks that each individual cannot\naccomplish. Shape formation in artificial intelligence systems is usually\nrequired for specific task-oriented performance, including 1) forming sensing\ngrids, 2) exploring and mapping in space, underwater, or hazardous\nenvironments, and 3) forming a barricade for surveillance or protecting an area\nor a person. This paper presents a dynamic model of an artificial swarm system\nbased on a virtual spring damper model and algorithms for dispersion without a\nleader and line formation with an interim leader using only the distance\nestimation among the neighbors."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2001576.2001842", 
    "link": "http://arxiv.org/pdf/1407.0061v1", 
    "other_authors": "Erik Cuevas, Daniel Zaldivar, Marco Perez, Humberto Sossa, Valentin Osuna", 
    "title": "Block matching algorithm for motion estimation based on Artificial Bee   Colony (ABC)", 
    "arxiv-id": "1407.0061v1", 
    "author": "Valentin Osuna", 
    "publish": "2014-06-30T21:23:11Z", 
    "summary": "Block matching (BM) motion estimation plays a very important role in video\ncoding. In a BM approach, image frames in a video sequence are divided into\nblocks. For each block in the current frame, the best matching block is\nidentified inside a region of the previous frame, aiming to minimize the sum of\nabsolute differences (SAD). Unfortunately, the SAD evaluation is\ncomputationally expensive and represents the most consuming operation in the BM\nprocess. Therefore, BM motion estimation can be approached as an optimization\nproblem, where the goal is to find the best matching block within a search\nspace. The simplest available BM method is the full search algorithm (FSA)\nwhich finds the most accurate motion vector through an exhaustive computation\nof SAD values for all elements of the search window. Recently, several fast BM\nalgorithms have been proposed to reduce the number of SAD operations by\ncalculating only a fixed subset of search locations at the price of poor\naccuracy. In this paper, a new algorithm based on Artificial Bee Colony (ABC)\noptimization is proposed to reduce the number of search locations in the BM\nprocess. In our algorithm, the computation of search locations is drastically\nreduced by considering a fitness calculation strategy which indicates when it\nis feasible to calculate or only estimate new search locations. Since the\nproposed algorithm does not consider any fixed search pattern or any other\nmovement assumption as most of other BM approaches do, a high probability for\nfinding the true minimum (accurate motion vector) is expected. Conducted\nsimulations show that the proposed method achieves the best balance over other\nfast BM algorithms, in terms of both estimation accuracy and computational\ncost."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2001576.2001842", 
    "link": "http://arxiv.org/pdf/1407.0265v1", 
    "other_authors": "Evangelos Stromatias, John Marsland", 
    "title": "Supervised learning in Spiking Neural Networks with Limited Precision:   SNN/LP", 
    "arxiv-id": "1407.0265v1", 
    "author": "John Marsland", 
    "publish": "2014-07-01T14:50:36Z", 
    "summary": "A new supervised learning algorithm, SNN/LP, is proposed for Spiking Neural\nNetworks. This novel algorithm uses limited precision for both synaptic weights\nand synaptic delays; 3 bits in each case. Also a genetic algorithm is used for\nthe supervised training. The results are comparable or better than previously\npublished work. The results are applicable to the realization of large scale\nhardware neural networks. One of the trained networks is implemented in\nprogrammable hardware."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2001576.2001842", 
    "link": "http://arxiv.org/pdf/1407.3000v1", 
    "other_authors": "Paul Szerlip, Kenneth O. Stanley", 
    "title": "A Proposed Infrastructure for Adding Online Interaction to Any   Evolutionary Domain", 
    "arxiv-id": "1407.3000v1", 
    "author": "Kenneth O. Stanley", 
    "publish": "2014-07-11T01:11:32Z", 
    "summary": "To address the difficulty of creating online collaborative evolutionary\nsystems, this paper presents a new prototype library called Worldwide\nInfrastructure for Neuroevolution (WIN) and its accompanying site WIN Online\n(http://winark.org/). The WIN library is a collection of software packages\nbuilt on top of Node.js that reduce the complexity of creating fully\npersistent, online, and interactive (or automated) evolutionary platforms\naround any domain. WIN Online is the public interface for WIN, providing an\nonline collection of domains built with the WIN library that lets novice and\nexpert users browse and meaningfully contribute to ongoing experiments. The\nlong term goal of WIN is to make it trivial to connect any platform to the\nworld, providing both a stream of online users, and archives of data and\ndiscoveries for later extension by humans or computers."
},{
    "category": "cs.NE", 
    "doi": "10.1145/2001576.2001842", 
    "link": "http://arxiv.org/pdf/1407.3077v1", 
    "other_authors": "Yourim Yoon, Yong-Hyuk Kim", 
    "title": "Charge Scheduling of an Energy Storage System under Time-of-use Pricing   and a Demand Charge", 
    "arxiv-id": "1407.3077v1", 
    "author": "Yong-Hyuk Kim", 
    "publish": "2014-07-11T09:18:20Z", 
    "summary": "A real-coded genetic algorithm is used to schedule the charging of an energy\nstorage system (ESS), operated in tandem with renewable power by an electricity\nconsumer who is subject to time-of-use pricing and a demand charge. Simulations\nbased on load and generation profiles of typical residential customers show\nthat an ESS scheduled by our algorithm can reduce electricity costs by\napproximately 17%, compared to a system without an ESS, and by 8% compared to a\nscheduling algorithm based on net power."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ICIEA.2014.6931307", 
    "link": "http://arxiv.org/pdf/1407.4000v2", 
    "other_authors": "Maumita Bhattacharya, R. Islam, A. Mahmood", 
    "title": "Uncertainty And Evolutionary Optimization: A Novel Approach", 
    "arxiv-id": "1407.4000v2", 
    "author": "A. Mahmood", 
    "publish": "2014-07-15T14:05:24Z", 
    "summary": "Evolutionary algorithms (EA) have been widely accepted as efficient solvers\nfor complex real world optimization problems, including engineering\noptimization. However, real world optimization problems often involve uncertain\nenvironment including noisy and/or dynamic environments, which pose major\nchallenges to EA-based optimization. The presence of noise interferes with the\nevaluation and the selection process of EA, and thus adversely affects its\nperformance. In addition, as presence of noise poses challenges to the\nevaluation of the fitness function, it may need to be estimated instead of\nbeing evaluated. Several existing approaches attempt to address this problem,\nsuch as introduction of diversity (hyper mutation, random immigrants, special\noperators) or incorporation of memory of the past (diploidy, case based\nmemory). However, these approaches fail to adequately address the problem. In\nthis paper we propose a Distributed Population Switching Evolutionary Algorithm\n(DPSEA) method that addresses optimization of functions with noisy fitness\nusing a distributed population switching architecture, to simulate a\ndistributed self-adaptive memory of the solution space. Local regression is\nused in the pseudo-populations to estimate the fitness. Successful applications\nto benchmark test problems ascertain the proposed method's superior performance\nin terms of both robustness and accuracy."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ICIEA.2014.6931307", 
    "link": "http://arxiv.org/pdf/1407.5739v1", 
    "other_authors": "Truyen Tran, Trung Thanh Nguyen, Hoang Linh Nguyen", 
    "title": "Global optimization using L\u00e9vy flights", 
    "arxiv-id": "1407.5739v1", 
    "author": "Hoang Linh Nguyen", 
    "publish": "2014-07-22T05:48:08Z", 
    "summary": "This paper studies a class of enhanced diffusion processes in which random\nwalkers perform L\\'evy flights and apply it for global optimization. L\\'evy\nflights offer controlled balance between exploitation and exploration. We\ndevelop four optimization algorithms based on such properties. We compare new\nalgorithms with the well-known Simulated Annealing on hard test functions and\nthe results are very promising."
},{
    "category": "cs.NE", 
    "doi": "10.5120/15579-4304", 
    "link": "http://arxiv.org/pdf/1407.5753v1", 
    "other_authors": "Sandeep Kumar, Vivek Kumar Sharma, Rajani Kumari", 
    "title": "Improved Onlooker Bee Phase in Artificial Bee Colony Algorithm", 
    "arxiv-id": "1407.5753v1", 
    "author": "Rajani Kumari", 
    "publish": "2014-07-22T06:40:09Z", 
    "summary": "Artificial Bee Colony (ABC) is a distinguished optimization strategy that can\nresolve nonlinear and multifaceted problems. It is comparatively a\nstraightforward and modern population based probabilistic approach for\ncomprehensive optimization. In the vein of the other population based\nalgorithms, ABC is moreover computationally classy due to its slow nature of\nsearch procedure. The solution exploration equation of ABC is extensively\ninfluenced by a arbitrary quantity which helps in exploration at the cost of\nexploitation of the better search space. In the solution exploration equation\nof ABC due to the outsized step size the chance of skipping the factual\nsolution is high. Therefore, here this paper improve onlooker bee phase with\nhelp of a local search strategy inspired by memetic algorithm to balance the\ndiversity and convergence capability of the ABC. The proposed algorithm is\nnamed as Improved Onlooker Bee Phase in ABC (IoABC). It is tested over 12 well\nknown un-biased test problems of diverse complexities and two engineering\noptimization problems; results show that the anticipated algorithm go one\nbetter than the basic ABC and its recent deviations in a good number of the\nexperiments."
},{
    "category": "cs.NE", 
    "doi": "10.5120/15579-4304", 
    "link": "http://arxiv.org/pdf/1407.5949v2", 
    "other_authors": "Sharat C. Prasad, Piyush Prasad", 
    "title": "Deep Recurrent Neural Networks for Time Series Prediction", 
    "arxiv-id": "1407.5949v2", 
    "author": "Piyush Prasad", 
    "publish": "2014-07-22T17:25:50Z", 
    "summary": "Ability of deep networks to extract high level features and of recurrent\nnetworks to perform time-series inference have been studied. In view of\nuniversality of one hidden layer network at approximating functions under weak\nconstraints, the benefit of multiple layers is to enlarge the space of\ndynamical systems approximated or, given the space, reduce the number of units\nrequired for a certain error. Traditionally shallow networks with manually\nengineered features are used, back-propagation extent is limited to one and\nattempt to choose a large number of hidden units to satisfy the Markov\ncondition is made. In case of Markov models, it has been shown that many\nsystems need to be modeled as higher order. In the present work, we present\ndeep recurrent networks with longer backpropagation through time extent as a\nsolution to modeling systems that are high order and to predicting ahead. We\nstudy epileptic seizure suppression electro-stimulator. Extraction of manually\nengineered complex features and prediction employing them has not allowed small\nlow-power implementations as, to avoid possibility of surgery, extraction of\nany features that may be required has to be included. In this solution, a\nrecurrent neural network performs both feature extraction and prediction. We\nprove analytically that adding hidden layers or increasing backpropagation\nextent increases the rate of decrease of approximation error. A Dynamic\nProgramming (DP) training procedure employing matrix operations is derived. DP\nand use of matrix operations makes the procedure efficient particularly when\nusing data-parallel computing. The simulation studies show the geometry of the\nparameter space, that the network learns the temporal structure, that\nparameters converge while model output displays same dynamic behavior as the\nsystem and greater than .99 Average Detection Rate on all real seizure data\ntried."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/1407.6637v1", 
    "other_authors": "Michiel Hermans, Micha\u00ebl Burm, Joni Dambre, Peter Bienstman", 
    "title": "Trainable and Dynamic Computing: Error Backpropagation through Physical   Media", 
    "arxiv-id": "1407.6637v1", 
    "author": "Peter Bienstman", 
    "publish": "2014-07-24T16:14:55Z", 
    "summary": "Machine learning algorithms, and more in particular neural networks, arguably\nexperience a revolution in terms of performance. Currently, the best systems we\nhave for speech recognition, computer vision and similar problems are based on\nneural networks, trained using the half-century old backpropagation algorithm.\nDespite the fact that neural networks are a form of analog computers, they are\nstill implemented digitally for reasons of convenience and availability. In\nthis paper we demonstrate how we can design physical linear dynamic systems\nwith non-linear feedback as a generic platform for dynamic, neuro-inspired\nanalog computing. We show that a crucial advantage of this setup is that the\nerror backpropagation can be performed physically as well, which greatly speeds\nup the optimisation process. As we show in this paper, using one experimentally\nvalidated and one conceptual example, such systems may be the key to providing\na relatively straightforward mechanism for constructing highly scalable, fully\ndynamic analog computers."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/1407.7399v1", 
    "other_authors": "F. Merrikh-Bayat", 
    "title": "A Numerical Optimization Algorithm Inspired by the Strawberry Plant", 
    "arxiv-id": "1407.7399v1", 
    "author": "F. Merrikh-Bayat", 
    "publish": "2014-07-28T12:58:41Z", 
    "summary": "This paper proposes a new numerical optimization algorithm inspired by the\nstrawberry plant for solving complicated engineering problems. Plants like\nstrawberry develop both runners and roots for propagation and search for water\nresources and minerals. In these plants, runners and roots can be thought of as\ntools for global and local searches, respectively. The proposed algorithm has\nthree main differences with the trivial nature-inspired optimization\nalgorithms: duplication-elimination of the computational agents at all\niterations, subjecting all agents to both small and large movements from the\nbeginning to end, and the lack of communication (information exchange) between\nagents. Moreover, it has the advantage of using only three parameters to be\ntuned by user. This algorithm is applied to standard test functions and the\nresults are compared with GA and PSO. The proposed algorithm is also used to\nsolve an open problem in the field of robust control theory. These simulations\nshow that the proposed algorithm can very effectively solve complicated\noptimization problems."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/1407.7737v1", 
    "other_authors": "Ke Ding, Ying Tan", 
    "title": "A CUDA-Based Real Parameter Optimization Benchmark", 
    "arxiv-id": "1407.7737v1", 
    "author": "Ying Tan", 
    "publish": "2014-07-29T14:26:57Z", 
    "summary": "Benchmarking is key for developing and comparing optimization algorithms. In\nthis paper, a CUDA-based real parameter optimization benchmark (cuROB) is\nintroduced. Test functions of diverse properties are included within cuROB and\nimplemented efficiently with CUDA. Speedup of one order of magnitude can be\nachieved in comparison with CPU-based benchmark of CEC'14."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/0803.1598v1", 
    "other_authors": "Peer-Olaf Siebers, Uwe Aickelin, Helen Celia, Christopher Clegg", 
    "title": "A Multi-Agent Simulation of Retail Management Practices", 
    "arxiv-id": "0803.1598v1", 
    "author": "Christopher Clegg", 
    "publish": "2008-03-11T14:37:40Z", 
    "summary": "We apply Agent-Based Modeling and Simulation (ABMS) to investigate a set of\nproblems in a retail context. Specifically, we are working to understand the\nrelationship between human resource management practices and retail\nproductivity. Despite the fact we are working within a relatively novel and\ncomplex domain, it is clear that intelligent agents do offer potential for\ndeveloping organizational capabilities in the future. Our multi-disciplinary\nresearch team has worked with a UK department store to collect data and capture\nperceptions about operations from actors within departments. Based on this case\nstudy work, we have built a simulator that we present in this paper. We then\nuse the simulator to gather empirical evidence regarding two specific\nmanagement practices: empowerment and employee development."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/0803.1600v1", 
    "other_authors": "Peer-Olaf Siebers, Uwe Aickelin, Helen Celia, Christopher Clegg", 
    "title": "Understanding Retail Productivity by Simulating Management Practise", 
    "arxiv-id": "0803.1600v1", 
    "author": "Christopher Clegg", 
    "publish": "2008-03-11T14:46:10Z", 
    "summary": "Intelligent agents offer a new and exciting way of understanding the world of\nwork. In this paper we apply agent-based modeling and simulation to investigate\na set of problems in a retail context. Specifically, we are working to\nunderstand the relationship between human resource management practices and\nretail productivity. Despite the fact we are working within a relatively novel\nand complex domain, it is clear that intelligent agents could offer potential\nfor fostering sustainable organizational capabilities in the future. Our\nresearch so far has led us to conduct case study work with a top ten UK\nretailer, collecting data in four departments in two stores. Based on our case\nstudy data we have built and tested a first version of a department store\nsimulator. In this paper we will report on the current development of our\nsimulator which includes new features concerning more realistic data on the\npattern of footfall during the day and the week, a more differentiated view of\ncustomers, and the evolution of customers over time. This allows us to\ninvestigate more complex scenarios and to analyze the impact of various\nmanagement practices."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/0803.2314v1", 
    "other_authors": "Fr\u00e9d\u00e9ric Guinand, Yoann Pign\u00e9", 
    "title": "Problem Solving and Complex Systems", 
    "arxiv-id": "0803.2314v1", 
    "author": "Yoann Pign\u00e9", 
    "publish": "2008-03-15T18:07:49Z", 
    "summary": "The observation and modeling of natural Complex Systems (CSs) like the human\nnervous system, the evolution or the weather, allows the definition of special\nabilities and models reusable to solve other problems. For instance, Genetic\nAlgorithms or Ant Colony Optimizations are inspired from natural CSs to solve\noptimization problems. This paper proposes the use of ant-based systems to\nsolve various problems with a non assessing approach. This means that solutions\nto some problem are not evaluated. They appear as resultant structures from the\nactivity of the system. Problems are modeled with graphs and such structures\nare observed directly on these graphs. Problems of Multiple Sequences Alignment\nand Natural Language Processing are addressed with this approach."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/0803.2925v1", 
    "other_authors": "Kassel Hingee, Marcus Hutter", 
    "title": "Equivalence of Probabilistic Tournament and Polynomial Ranking Selection", 
    "arxiv-id": "0803.2925v1", 
    "author": "Marcus Hutter", 
    "publish": "2008-03-20T03:50:53Z", 
    "summary": "Crucial to an Evolutionary Algorithm's performance is its selection scheme.\nWe mathematically investigate the relation between polynomial rank and\nprobabilistic tournament methods which are (respectively) generalisations of\nthe popular linear ranking and tournament selection schemes. We show that every\nprobabilistic tournament is equivalent to a unique polynomial rank scheme. In\nfact, we derived explicit operators for translating between these two types of\nselection. Of particular importance is that most linear and most practical\nquadratic rank schemes are probabilistic tournaments."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/0803.4240v1", 
    "other_authors": "S\u00e9bastien Verel, Philippe Collard, Marco Tomassini, Leonardo Vanneschi", 
    "title": "Neutral Fitness Landscape in the Cellular Automata Majority Problem", 
    "arxiv-id": "0803.4240v1", 
    "author": "Leonardo Vanneschi", 
    "publish": "2008-03-29T07:50:24Z", 
    "summary": "We study in detail the fitness landscape of a difficult cellular automata\ncomputational task: the majority problem. Our results show why this problem\nlandscape is so hard to search, and we quantify the large degree of neutrality\nfound in various ways. We show that a particular subspace of the solution\nspace, called the \"Olympus\", is where good solutions concentrate, and give\nmeasures to quantitatively characterize this subspace."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/0803.4241v1", 
    "other_authors": "Maroun Bercachi, Philippe Collard, Manuel Clergue, S\u00e9bastien Verel", 
    "title": "Evolving Dynamic Change and Exchange of Genotype Encoding in Genetic   Algorithms for Difficult Optimization Problems", 
    "arxiv-id": "0803.4241v1", 
    "author": "S\u00e9bastien Verel", 
    "publish": "2008-03-29T07:51:18Z", 
    "summary": "The application of genetic algorithms (GAs) to many optimization problems in\norganizations often results in good performance and high quality solutions. For\nsuccessful and efficient use of GAs, it is not enough to simply apply simple\nGAs (SGAs). In addition, it is necessary to find a proper representation for\nthe problem and to develop appropriate search operators that fit well to the\nproperties of the genotype encoding. The representation must at least be able\nto encode all possible solutions of an optimization problem, and genetic\noperators such as crossover and mutation should be applicable to it. In this\npaper, serial alternation strategies between two codings are formulated in the\nframework of dynamic change of genotype encoding in GAs for function\noptimization. Likewise, a new variant of GAs for difficult optimization\nproblems denoted {\\it Split-and-Merge} GA (SM-GA) is developed using a parallel\nimplementation of an SGA and evolving a dynamic exchange of individual\nrepresentation in the context of Dual Coding concept. Numerical experiments\nshow that the evolved SM-GA significantly outperforms an SGA with static single\ncoding."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/0803.4248v1", 
    "other_authors": "David Simoncini, Philippe Collard, S\u00e9bastien Verel, Manuel Clergue", 
    "title": "From Cells to Islands: An unified Model of Cellular Parallel Genetic   Algorithms", 
    "arxiv-id": "0803.4248v1", 
    "author": "Manuel Clergue", 
    "publish": "2008-03-29T08:20:58Z", 
    "summary": "This paper presents the Anisotropic selection scheme for cellular Genetic\nAlgorithms (cGA). This new scheme allows to enhance diversity and to control\nthe selective pressure which are two important issues in Genetic Algorithms,\nespecially when trying to solve difficult optimization problems. Varying the\nanisotropic degree of selection allows swapping from a cellular to an island\nmodel of parallel genetic algorithm. Measures of performances and diversity\nhave been performed on one well-known problem: the Quadratic Assignment Problem\nwhich is known to be difficult to optimize. Experiences show that, tuning the\nanisotropic degree, we can find the accurate trade-off between cGA and island\nmodels to optimize performances of parallel evolutionary algorithms. This\ntrade-off can be interpreted as the suitable degree of migration among\nsubpopulations in a parallel Genetic Algorithm."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/0806.4650v1", 
    "other_authors": "Ismoyo Haryanto, Joga Dharma Setiawan, Agus Budiyono", 
    "title": "Structural Damage Detection Using Randomized Trained Neural Networks", 
    "arxiv-id": "0806.4650v1", 
    "author": "Agus Budiyono", 
    "publish": "2008-06-28T04:43:40Z", 
    "summary": "A computationally method on damage detection problems in structures was\nconducted using neural networks. The problem that is considered in this works\nconsists of estimating the existence, location and extent of stiffness\nreduction in structure which is indicated by the changes of the structural\nstatic parameters such as deflection and strain. The neural network was trained\nto recognize the behaviour of static parameter of the undamaged structure as\nwell as of the structure with various possible damage extent and location which\nwere modelled as random states. The proposed techniques were applied to detect\ndamage in a simply supported beam. The structure was analyzed using\nfinite-element-method (FEM) and the damage identification was conducted by a\nback-propagation neural network using the change of the structural strain and\ndisplacement. The results showed that using proposed method the strain is more\nefficient for identification of damage than the displacement."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/0903.2516v1", 
    "other_authors": "Susan Khor", 
    "title": "Effect of Degree Distribution on Evolutionary Search", 
    "arxiv-id": "0903.2516v1", 
    "author": "Susan Khor", 
    "publish": "2009-03-14T00:18:08Z", 
    "summary": "This paper introduces a method to generate hierarchically modular networks\nwith prescribed node degree list and proposes a metric to measure network\nmodularity based on the notion of edge distance. The generated networks are\nused as test problems to explore the effect of modularity and degree\ndistribution on evolutionary algorithm performance. Results from the\nexperiments (i) confirm a previous finding that modularity increases the\nperformance advantage of genetic algorithms over hill climbers, and (ii)\nsupport a new conjecture that test problems with modularized constraint\nnetworks having heavy-tailed right-skewed degree distributions are more easily\nsolved than test problems with modularized constraint networks having\nbell-shaped normal degree distributions."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/0909.3384v1", 
    "other_authors": "Anna I Esparcia-Alc\u00e1zar, J. J. Merelo, Ana\u00eds Mart\u00ednez-Garc\u00eda, Pablo Garc\u00eda-S\u00e1nchez, Eva Alfaro-Cid, Ken Sharman", 
    "title": "Comparing Single and Multiobjective Evolutionary Approaches to the   Inventory and Transportation Problem", 
    "arxiv-id": "0909.3384v1", 
    "author": "Ken Sharman", 
    "publish": "2009-09-18T08:35:42Z", 
    "summary": "EVITA, standing for Evolutionary Inventory and Transportation Algorithm, is a\ntwo-level methodology designed to address the Inventory and Transportation\nProblem (ITP) in retail chains. The top level uses an evolutionary algorithm to\nobtain delivery patterns for each shop on a weekly basis so as to minimise the\ninventory costs, while the bottom level solves the Vehicle Routing Problem\n(VRP) for every day in order to obtain the minimum transport costs associated\nto a particular set of patterns. The aim of this paper is to investigate\nwhether a multiobjective approach to this problem can yield any advantage over\nthe previously used single objective approach. The analysis performed allows us\nto conclude that this is not the case and that the single objective approach is\nin gene- ral preferable for the ITP in the case studied. A further conclusion\nis that it is useful to employ a classical algorithm such as Clarke & Wright's\nas the seed for other metaheuristics like local search or tabu search in order\nto provide good results for the Vehicle Routing Problem."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/1005.0965v1", 
    "other_authors": "Bikrampal Kaur, Himanshu Aggarwal", 
    "title": "Artificial Neural Network based Diagnostic Model For Causes of Success   and Failures", 
    "arxiv-id": "1005.0965v1", 
    "author": "Himanshu Aggarwal", 
    "publish": "2010-05-06T10:22:40Z", 
    "summary": "In this paper an attempt has been made to identify most important human\nresource factors and propose a diagnostic model based on the back-propagation\nand connectionist model approaches of artificial neural network (ANN). The\nfocus of the study is on the mobile -communication industry of India. The ANN\nbased approach is particularly important because conventional approaches (such\nas algorithmic) to the problem solving have their inherent disadvantages. The\nalgorithmic approach is well-suited to the problems that are well-understood\nand known solution(s). On the other hand the ANNs have learning by example and\nprocessing capabilities similar to that of a human brain. ANN has been followed\ndue to its inherent advantage over conversion algorithmic like approaches and\nhaving capabilities, training and human like intuitive decision making\ncapabilities. Therefore, this ANN based approach is likely to help researchers\nand organizations to reach a better solution to the problem of managing the\nhuman resource. The study is particularly important as many studies have been\ncarried in developed countries but there is a shortage of such studies in\ndeveloping nations like India. Here, a model has been derived using\nconnectionist-ANN approach and improved and verified via back-propagation\nalgorithm. This suggested ANN based model can be used for testing the success\nand failure human factors in any of the communication Industry. Results have\nbeen obtained on the basis of connectionist model, which has been further\nrefined by BPNN to an accuracy of 99.99%. Any company to predict failure due to\nHR factors can directly deploy this model."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/1005.5115v1", 
    "other_authors": "M. Nguyen-H, C. Zhou", 
    "title": "Improving GPS/INS Integration through Neural Networks", 
    "arxiv-id": "1005.5115v1", 
    "author": "C. Zhou", 
    "publish": "2010-05-27T16:46:13Z", 
    "summary": "The Global Positioning Systems (GPS) and Inertial Navigation System (INS)\ntechnology have attracted a considerable importance recently because of its\nlarge number of solutions serving both military as well as civilian\napplications. This paper aims to develop a more efficient and especially a\nfaster method for processing the GPS signal in case of INS signal loss without\nlosing the accuracy of the data. The conventional or usual method consists of\nprocessing data through a neural network and obtaining accurate positioning\noutput data. The new or improved method adds selective filtering at the\nlow-band frequency, the mid-band frequency and the high band frquency, before\nprocessing the GPS data through the neural network, so that the processing time\nis decreased significantly while the accuracy remains the same."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/1008.0063v1", 
    "other_authors": "Y. A. Skobtsov, D. E. Ivanov, V. Y. Skobtsov, R. Ubar, J. Raik", 
    "title": "Evolutionary Approach to Test Generation for Functional BIST", 
    "arxiv-id": "1008.0063v1", 
    "author": "J. Raik", 
    "publish": "2010-07-31T07:31:41Z", 
    "summary": "In the paper, an evolutionary approach to test generation for functional BIST\nis considered. The aim of the proposed scheme is to minimize the test data\nvolume by allowing the device's microprogram to test its logic, providing an\nobservation structure to the system, and generating appropriate test data for\nthe given architecture. Two methods of deriving a deterministic test set at\nfunctional level are suggested. The first method is based on the classical\ngenetic algorithm with binary and arithmetic crossover and mutation operators.\nThe second one uses genetic programming, where test is represented as a\nsequence of microoperations. In the latter case, we apply two-point crossover\nbased on exchanging test subsequences and mutation implemented as random\nreplacement of microoperations or operands. Experimental data of the program\nrealization showing the efficiency of the proposed methods are presented."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/1008.3450v3", 
    "other_authors": "Farnood Merrikh-Bayat, Saeed Bagheri Shouraki, Iman Esmaili Paeen Afrakoti", 
    "title": "Bottleneck of using single memristor as a synapse and its solution", 
    "arxiv-id": "1008.3450v3", 
    "author": "Iman Esmaili Paeen Afrakoti", 
    "publish": "2010-08-20T07:43:24Z", 
    "summary": "It is now widely accepted that memristive devices are perfect candidates for\nthe emulation of biological synapses in neuromorphic systems. This is mainly\nbecause of the fact that like the strength of synapse, memristance of the\nmemristive device can be tuned actively (e.g., by the application of volt- age\nor current). In addition, it is also possible to fabricate very high density of\nmemristive devices (comparable to the number of synapses in real biological\nsystem) through the nano-crossbar structures. However, in this paper we will\nshow that there are some problems associated with memristive synapses\n(memristive devices which are playing the role of biological synapses). For\nexample, we show that the variation rate of the memristance of memristive\ndevice depends completely on the current memristance of the device and\ntherefore it can change significantly with time during the learning phase. This\nphenomenon can degrade the performance of learning methods like Spike\nTiming-Dependent Plasticity (STDP) and cause the corresponding neuromorphic\nsystems to become unstable. Finally, at the end of this paper, we illustrate\nthat using two serially connected memristive devices with different polarities\nas a synapse can somewhat fix the aforementioned problem."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/1008.4049v2", 
    "other_authors": "Kevin Curran, Peng Yuan, Damian Coyle", 
    "title": "Discriminating between Nasal and Mouth Breathing", 
    "arxiv-id": "1008.4049v2", 
    "author": "Damian Coyle", 
    "publish": "2010-08-24T14:12:07Z", 
    "summary": "The recommendation to change breathing patterns from the mouth to the nose\ncan have a significantly positive impact upon the general well being of the\nindividual. We classify nasal and mouth breathing by using an acoustic sensor\nand intelligent signal processing techniques. The overall purpose is to\ninvestigate the possibility of identifying the differences in patterns between\nnasal and mouth breathing in order to integrate this information into a\ndecision support system which will form the basis of a patient monitoring and\nmotivational feedback system to recommend the change from mouth to nasal\nbreathing. Our findings show that the breath pattern can be discriminated in\ncertain places of the body both by visual spectrum analysis and with a Back\nPropagation neural network classifier. The sound file recoded from the sensor\nplaced on the hollow in the neck shows the most promising accuracy which is as\nhigh as 90%."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/1012.0952v1", 
    "other_authors": "Benjamin Doerr, Daniel Johannsen, Timo K\u00f6tzing, Per Kristian Lehre, Markus Wagner, Carola Winzen", 
    "title": "Faster Black-Box Algorithms Through Higher Arity Operators", 
    "arxiv-id": "1012.0952v1", 
    "author": "Carola Winzen", 
    "publish": "2010-12-04T22:11:48Z", 
    "summary": "We extend the work of Lehre and Witt (GECCO 2010) on the unbiased black-box\nmodel by considering higher arity variation operators. In particular, we show\nthat already for binary operators the black-box complexity of \\leadingones\ndrops from $\\Theta(n^2)$ for unary operators to $O(n \\log n)$. For \\onemax, the\n$\\Omega(n \\log n)$ unary black-box complexity drops to O(n) in the binary case.\nFor $k$-ary operators, $k \\leq n$, the \\onemax-complexity further decreases to\n$O(n/\\log k)$."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/1106.0190v1", 
    "other_authors": "A. E. Eiben, N. Ferreira, M. Schut, S. Kernbach", 
    "title": "Evolution of Things", 
    "arxiv-id": "1106.0190v1", 
    "author": "S. Kernbach", 
    "publish": "2011-06-01T14:32:58Z", 
    "summary": "Evolution is one of the major omnipresent powers in the universe that has\nbeen studied for about two centuries. Recent scientific and technical\ndevelopments make it possible to make the transition from passively\nunderstanding to actively mastering evolution. As of today, the only area where\nhuman experimenters can design and manipulate evolutionary processes in full is\nthat of Evolutionary Computing, where evolutionary processes are carried out in\na digital space, inside computers, in simulation. We argue that in the near\nfuture it will be possible to move evolutionary computing outside such\nimaginary spaces and make it physically embodied. In other words, we envision\nthe \"Evolution of Things\", rather than just the evolution of code, leading to a\nnew field of Embodied Artificial Evolution (EAE). The main objective of the\npresent paper is to offer an umbrella term and vision in order to aid the\ndevelopment of this high potential research area. To this end, we introduce the\nnotion of EAE, discuss a few examples and applications, and elaborate on the\nexpected benefits as well as the grand challenges this developing field will\nhave to address."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/1106.1570v1", 
    "other_authors": "Ismaail ElSawy, Hossam Hosny, Mohammed Abdel Razek", 
    "title": "A Neural Network Model for Construction Projects Site Overhead Cost   Estimating in Egypt", 
    "arxiv-id": "1106.1570v1", 
    "author": "Mohammed Abdel Razek", 
    "publish": "2011-06-08T14:29:41Z", 
    "summary": "Estimating of the overhead costs of building construction projects is an\nimportant task in the management of these projects. The quality of construction\nmanagement depends heavily on their accurate cost estimation. Construction\ncosts prediction is a very difficult and sophisticated task especially when\nusing manual calculation methods. This paper uses Artificial Neural Network\n(ANN) approach to develop a parametric cost-estimating model for site overhead\ncost in Egypt. Fifty-two actual real-life cases of building projects\nconstructed in Egypt during the seven year period 2002-2009 were used as\ntraining materials. The neural network architecture is presented for the\nestimation of the site overhead costs as a percentage from the total project\nprice."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/1106.2113v1", 
    "other_authors": "Caixing Liu, Jierui Xie, Yueming Hu", 
    "title": "Using Hopfield to Solve Resource-Leveling Problem", 
    "arxiv-id": "1106.2113v1", 
    "author": "Yueming Hu", 
    "publish": "2011-05-28T00:55:18Z", 
    "summary": "Although the traditional permute matrix coming along with Hopfield is able to\ndescribe many common problems, it seems to have limitation in solving more\ncomplicated problem with more constrains, like resource leveling which is\nactually a NP problem. This paper tries to find a better solution for it by\nusing neural network. In order to give the neural network description of\nresource leveling problem, a new description method called Augmented permute\nmatrix is proposed by expending the ability of the traditional one. An Embedded\nHybrid Model combining Hopfield model and SA are put forward to improve the\noptimization in essence in which Hopfield servers as State Generator for the\nSA. The experiment results show that Augmented permute matrix is able to\ncompletely and appropriately describe the application. The energy function and\nhybrid model given in this study are also highly efficient in solving resource\nleveling problem."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/1106.2156v1", 
    "other_authors": "Axel Wism\u00fcller", 
    "title": "A Computational Framework for Nonlinear Dimensionality Reduction of   Large Data Sets: The Exploratory Inspection Machine (XIM)", 
    "arxiv-id": "1106.2156v1", 
    "author": "Axel Wism\u00fcller", 
    "publish": "2011-06-10T19:48:01Z", 
    "summary": "In this paper, we present a novel computational framework for nonlinear\ndimensionality reduction which is specifically suited to process large data\nsets: the Exploratory Inspection Machine (XIM). XIM introduces a conceptual\ncross-link between hitherto separate domains of machine learning, namely\ntopographic vector quantization and divergence-based neighbor embedding\napproaches. There are three ways to conceptualize XIM, namely (i) as the\ninversion of the Exploratory Observation Machine (XOM) and its variants, such\nas Neighbor Embedding XOM (NE-XOM), (ii) as a powerful optimization scheme for\ndivergence-based neighbor embedding cost functions inspired by Stochastic\nNeighbor Embedding (SNE) and its variants, such as t-distributed SNE (t-SNE),\nand (iii) as an extension of topographic vector quantization methods, such as\nthe Self-Organizing Map (SOM). By preserving both global and local data\nstructure, XIM combines the virtues of classical and advanced recent embedding\nmethods. It permits direct visualization of large data collections without the\nneed for prior data reduction. Finally, XIM can contribute to many application\ndomains of data analysis and visualization important throughout the sciences\nand engineering, such as pattern matching, constrained incremental learning,\ndata clustering, and the analysis of non-metric dissimilarity data."
},{
    "category": "cs.NE", 
    "doi": "10.1038/ncomms7729", 
    "link": "http://arxiv.org/pdf/1106.2312v1", 
    "other_authors": "R. Rathipriya, Dr. K. Thangavel, J. Bagyamani", 
    "title": "Evolutionary Biclustering of Clickstream Data", 
    "arxiv-id": "1106.2312v1", 
    "author": "J. Bagyamani", 
    "publish": "2011-06-12T14:34:16Z", 
    "summary": "Biclustering is a two way clustering approach involving simultaneous\nclustering along two dimensions of the data matrix. Finding biclusters of web\nobjects (i.e. web users and web pages) is an emerging topic in the context of\nweb usage mining. It overcomes the problem associated with traditional\nclustering methods by allowing automatic discovery of browsing pattern based on\na subset of attributes. A coherent bicluster of clickstream data is a local\nbrowsing pattern such that users in bicluster exhibit correlated browsing\npattern through a subset of pages of a web site. This paper proposed a new\napplication of biclustering to web data using a combination of heuristics and\nmeta-heuristics such as K-means, Greedy Search Procedure and Genetic Algorithms\nto identify the coherent browsing pattern. Experiment is conducted on the\nbenchmark clickstream msnbc dataset from UCI repository. Results demonstrate\nthe efficiency and beneficial outcome of the proposed method by correlating the\nusers and pages of a web site in high degree.This approach shows excellent\nperformance at finding high degree of overlapped coherent biclusters from web\ndata."
},{
    "category": "cs.NE", 
    "doi": "10.1007/s11047-012-9322-0", 
    "link": "http://arxiv.org/pdf/1106.6223v1", 
    "other_authors": "Melvin Gauci, Tony J. Dodd, Roderich Gross", 
    "title": "Why 'GSA: A Gravitational Search Algorithm' Is Not Genuinely Based on   the Law of Gravity", 
    "arxiv-id": "1106.6223v1", 
    "author": "Roderich Gross", 
    "publish": "2011-06-30T13:38:35Z", 
    "summary": "Why 'GSA: A Gravitational Search Algorithm' Is Not Genuinely Based on the Law\nof Gravity"
},{
    "category": "cs.NE", 
    "doi": "10.1109/MFI.2008.4648056", 
    "link": "http://arxiv.org/pdf/1107.4414v1", 
    "other_authors": "Annapurna Sharma, Amit Purwar, Young-Dong Lee Young-Sook Lee Wan-Young Chung", 
    "title": "Frequency based Classification of Activities using Accelerometer Data", 
    "arxiv-id": "1107.4414v1", 
    "author": "Young-Dong Lee Young-Sook Lee Wan-Young Chung", 
    "publish": "2011-07-22T04:41:13Z", 
    "summary": "This work presents, the classification of user activities such as Rest, Walk\nand Run, on the basis of frequency component present in the acceleration data\nin a wireless sensor network environment. As the frequencies of the above\nmentioned activities differ slightly for different person, so it gives a more\naccurate result. The algorithm uses just one parameter i.e. the frequency of\nthe body acceleration data of the three axes for classifying the activities in\na set of data. The algorithm includes a normalization step and hence there is\nno need to set a different value of threshold value for magnitude for different\ntest person. The classification is automatic and done on a block by block\nbasis."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ICCIT.2008.394", 
    "link": "http://arxiv.org/pdf/1107.4429v1", 
    "other_authors": "Annapurna Sharma, Young-Dong Lee, Wan-Young Chung", 
    "title": "High Accuracy Human Activity Monitoring using Neural network", 
    "arxiv-id": "1107.4429v1", 
    "author": "Wan-Young Chung", 
    "publish": "2011-07-22T06:48:01Z", 
    "summary": "This paper presents the designing of a neural network for the classification\nof Human activity. A Triaxial accelerometer sensor, housed in a chest worn\nsensor unit, has been used for capturing the acceleration of the movements\nassociated. All the three axis acceleration data were collected at a base\nstation PC via a CC2420 2.4GHz ISM band radio (zigbee wireless compliant),\nprocessed and classified using MATLAB. A neural network approach for\nclassification was used with an eye on theoretical and empirical facts. The\nwork shows a detailed description of the designing steps for the classification\nof human body acceleration data. A 4-layer back propagation neural network,\nwith Levenberg-marquardt algorithm for training, showed best performance among\nthe other neural network training algorithms."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ICCIT.2008.394", 
    "link": "http://arxiv.org/pdf/1107.4470v1", 
    "other_authors": "Onay Urfalioglu, Orhan Arikan", 
    "title": "Symmetry Breaking in Neuroevolution: A Technical Report", 
    "arxiv-id": "1107.4470v1", 
    "author": "Orhan Arikan", 
    "publish": "2011-07-22T10:08:58Z", 
    "summary": "Artificial Neural Networks (ANN) comprise important symmetry properties,\nwhich can influence the performance of Monte Carlo methods in Neuroevolution.\nThe problem of the symmetries is also known as the competing conventions\nproblem or simply as the permutation problem. In the literature, symmetries are\nmainly addressed in Genetic Algoritm based approaches. However, investigations\nin this direction based on other Evolutionary Algorithms (EA) are rare or\nmissing. Furthermore, there are different and contradictionary reports on the\nefficacy of symmetry breaking. By using a novel viewpoint, we offer a possible\nexplanation for this issue. As a result, we show that a strategy which is\ninvariant to the global optimum can only be successfull on certain problems,\nwhereas it must fail to improve the global convergence on others. We introduce\nthe \\emph{Minimum Global Optimum Proximity} principle as a generalized and\nadaptive strategy to symmetry breaking, which depends on the location of the\nglobal optimum. We apply the proposed principle to Differential Evolution (DE)\nand Covariance Matrix Adaptation Evolution Strategies (CMA-ES), which are two\npopular and conceptually different global optimization methods. Using a wide\nrange of feedforward ANN problems, we experimentally illustrate significant\nimprovements in the global search efficiency by the proposed symmetry breaking\ntechnique."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijcsit.2011.3409", 
    "link": "http://arxiv.org/pdf/1109.0085v1", 
    "other_authors": "Chaiwat Jassadapakorn, Prabhas Chongstitvatana", 
    "title": "Self-Adaptation Mechanism to Control the Diversity of the Population in   Genetic Algorithm", 
    "arxiv-id": "1109.0085v1", 
    "author": "Prabhas Chongstitvatana", 
    "publish": "2011-09-01T04:01:27Z", 
    "summary": "One of the problems in applying Genetic Algorithm is that there is some\nsituation where the evolutionary process converges too fast to a solution which\ncauses it to be trapped in local optima. To overcome this problem, a proper\ndiversity in the candidate solutions must be determined. Most existing\ndiversity-maintenance mechanisms require a problem specific knowledge to setup\nparameters properly. This work proposes a method to control diversity of the\npopulation without explicit parameter setting. A self-adaptation mechanism is\nproposed based on the competition of preference characteristic in mating. It\ncan adapt the population toward proper diversity for the problems. The\nexperiments are carried out to measure the effectiveness of the proposed method\nbased on nine well-known test problems. The performance of the adaptive method\nis comparable to traditional Genetic Algorithm with the best parameter setting."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijcsit.2011.3409", 
    "link": "http://arxiv.org/pdf/1109.1074v1", 
    "other_authors": "A. Martin, Na. Ba. Anutthamaa, M. Sathyavathy, Marie Manjari Saint Francois, Dr. V. Prasanna Venkatesan", 
    "title": "A Framework for Predicting Phishing Websites using Neural Networks", 
    "arxiv-id": "1109.1074v1", 
    "author": "Dr. V. Prasanna Venkatesan", 
    "publish": "2011-09-06T06:05:12Z", 
    "summary": "In India many people are now dependent on online banking. This raises\nsecurity concerns as the banking websites are forged and fraud can be committed\nby identity theft. These forged websites are called as Phishing websites and\ncreated by malicious people to mimic web pages of real websites and it attempts\nto defraud people of their personal information. Detecting and identifying\nphishing websites is a really complex and dynamic problem involving many\nfactors and criteria. This paper discusses about the prediction of phishing\nwebsites using neural networks. A neural network is a multilayer system which\nreduces the error and increases the performance. This paper describes a\nframework to better classify and predict the phishing sites using neural\nnetworks."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijcsit.2011.3409", 
    "link": "http://arxiv.org/pdf/1109.1211v1", 
    "other_authors": "C. Ramya, G. Kavitha", 
    "title": "An Efficient Preprocessing Methodology for Discovering Patterns and   Clustering of Web Users using a Dynamic ART1 Neural Network", 
    "arxiv-id": "1109.1211v1", 
    "author": "G. Kavitha", 
    "publish": "2011-09-06T15:19:48Z", 
    "summary": "In this paper, a complete preprocessing methodology for discovering patterns\nin web usage mining process to improve the quality of data by reducing the\nquantity of data has been proposed. A dynamic ART1 neural network clustering\nalgorithm to group users according to their Web access patterns with its neat\narchitecture is also proposed. Several experiments are conducted and the\nresults show the proposed methodology reduces the size of Web log files down to\n73-82% of the initial size and the proposed ART1 algorithm is dynamic and\nlearns relatively stable quality clusters."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijcsit.2011.3409", 
    "link": "http://arxiv.org/pdf/1109.1504v2", 
    "other_authors": "Dirk Sudholt", 
    "title": "A New Method for Lower Bounds on the Running Time of Evolutionary   Algorithms", 
    "arxiv-id": "1109.1504v2", 
    "author": "Dirk Sudholt", 
    "publish": "2011-09-07T16:08:28Z", 
    "summary": "We present a new method for proving lower bounds on the expected running time\nof evolutionary algorithms. It is based on fitness-level partitions and an\nadditional condition on transition probabilities between fitness levels. The\nmethod is versatile, intuitive, elegant, and very powerful. It yields exact or\nnear-exact lower bounds for LO, OneMax, long k-paths, and all functions with a\nunique optimum. Most lower bounds are very general: they hold for all\nevolutionary algorithms that only use bit-flip mutation as variation\noperator---i.e. for all selection operators and population models. The lower\nbounds are stated with their dependence on the mutation rate.\n  These results have very strong implications. They allow to determine the\noptimal mutation-based algorithm for LO and OneMax, i.e., which algorithm\nminimizes the expected number of fitness evaluations. This includes the choice\nof the optimal mutation rate."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijcsit.2011.3409", 
    "link": "http://arxiv.org/pdf/1109.1766v1", 
    "other_authors": "J\u00f6rg L\u00e4ssig, Dirk Sudholt", 
    "title": "Analysis of Speedups in Parallel Evolutionary Algorithms for   Combinatorial Optimization", 
    "arxiv-id": "1109.1766v1", 
    "author": "Dirk Sudholt", 
    "publish": "2011-09-08T16:40:49Z", 
    "summary": "Evolutionary algorithms are popular heuristics for solving various\ncombinatorial problems as they are easy to apply and often produce good\nresults. Island models parallelize evolution by using different populations,\ncalled islands, which are connected by a graph structure as communication\ntopology. Each island periodically communicates copies of good solutions to\nneighboring islands in a process called migration.\n  We consider the speedup gained by island models in terms of the parallel\nrunning time for problems from combinatorial optimization: sorting (as\nmaximization of sortedness), shortest paths, and Eulerian cycles. Different\nsearch operators are considered. The results show in which settings and up to\nwhat degree evolutionary algorithms can be parallelized efficiently. Along the\nway, we also investigate how island models deal with plateaus. In particular,\nwe show that natural settings lead to exponential vs. logarithmic speedups,\ndepending on the frequency of migration."
},{
    "category": "cs.NE", 
    "doi": "10.1613/jair.1660", 
    "link": "http://arxiv.org/pdf/1109.2146v1", 
    "other_authors": "N. Garc\u00eda-Pedrajas, C. Herv\u00e1s-Mart\u00ednez, D. Ortiz-Boyer", 
    "title": "CIXL2: A Crossover Operator for Evolutionary Algorithms Based on   Population Features", 
    "arxiv-id": "1109.2146v1", 
    "author": "D. Ortiz-Boyer", 
    "publish": "2011-09-09T20:32:23Z", 
    "summary": "In this paper we propose a crossover operator for evolutionary algorithms\nwith real values that is based on the statistical theory of population\ndistributions. The operator is based on the theoretical distribution of the\nvalues of the genes of the best individuals in the population. The proposed\noperator takes into account the localization and dispersion features of the\nbest individuals of the population with the objective that these features would\nbe inherited by the offspring. Our aim is the optimization of the balance\nbetween exploration and exploitation in the search process. In order to test\nthe efficiency and robustness of this crossover, we have used a set of\nfunctions to be optimized with regard to different criteria, such as,\nmultimodality, separability, regularity and epistasis. With this set of\nfunctions we can extract conclusions in function of the problem at hand. We\nanalyze the results using ANOVA and multiple comparison statistical tests. As\nan example of how our crossover can be used to solve artificial intelligence\nproblems, we have applied the proposed model to the problem of obtaining the\nweight of each network in a ensemble of neural networks. The results obtained\nare above the performance of standard methods."
},{
    "category": "cs.NE", 
    "doi": "10.1613/jair.1660", 
    "link": "http://arxiv.org/pdf/1109.2788v1", 
    "other_authors": "Evangelos Stromatias", 
    "title": "Developing a supervised training algorithm for limited precision   feed-forward spiking neural networks", 
    "arxiv-id": "1109.2788v1", 
    "author": "Evangelos Stromatias", 
    "publish": "2011-09-13T13:58:07Z", 
    "summary": "Spiking neural networks have been referred to as the third generation of\nartificial neural networks where the information is coded as time of the\nspikes. There are a number of different spiking neuron models available and\nthey are categorized based on their level of abstraction. In addition, there\nare two known learning methods, unsupervised and supervised learning. This\nthesis focuses on supervised learning where a new algorithm is proposed, based\non genetic algorithms. The proposed algorithm is able to train both synaptic\nweights and delays and also allow each neuron to emit multiple spikes thus\ntaking full advantage of the spatial-temporal coding power of the spiking\nneurons. In addition, limited synaptic precision is applied; only six bits are\nused to describe and train a synapse, three bits for the weights and three bits\nfor the delays. Two limited precision schemes are investigated. The proposed\nalgorithm is tested on the XOR classification problem where it produces better\nresults for even smaller network architectures than the proposed ones.\nFurthermore, the algorithm is benchmarked on the Fisher iris classification\nproblem where it produces higher classification accuracies compared to\nSpikeProp, QuickProp and Rprop. Finally, a hardware implementation on a\nmicrocontroller is done for the XOR problem as a proof of concept. Keywords:\nSpiking neural networks, supervised learning, limited synaptic precision,\ngenetic algorithms, hardware implementation."
},{
    "category": "cs.NE", 
    "doi": "10.1613/jair.1660", 
    "link": "http://arxiv.org/pdf/1109.6441v1", 
    "other_authors": "Dirk Sudholt", 
    "title": "Memetic Algorithms: Parametrization and Balancing Local and Global   Search", 
    "arxiv-id": "1109.6441v1", 
    "author": "Dirk Sudholt", 
    "publish": "2011-09-29T08:53:36Z", 
    "summary": "This is a preprint of a book chapter from the Handbook of Memetic Algorithms,\nStudies in Computational Intelligence, Vol. 379, ISBN 978-3-642-23246-6,\nSpringer, edited by F. Neri, C. Cotta, and P. Moscato. It is devoted to the\nparametrization of memetic algorithms and how to find a good balance between\nglobal and local search."
},{
    "category": "cs.NE", 
    "doi": "10.1613/jair.1660", 
    "link": "http://arxiv.org/pdf/1111.0907v2", 
    "other_authors": "Yang Yu, Chao Qian, Zhi-Hua Zhou", 
    "title": "Towards Analyzing Crossover Operators in Evolutionary Search via General   Markov Chain Switching Theorem", 
    "arxiv-id": "1111.0907v2", 
    "author": "Zhi-Hua Zhou", 
    "publish": "2011-11-03T16:38:02Z", 
    "summary": "Evolutionary algorithms (EAs), simulating the evolution process of natural\nspecies, are used to solve optimization problems. Crossover (also called\nrecombination), originated from simulating the chromosome exchange phenomena in\nzoogamy reproduction, is widely employed in EAs to generate offspring\nsolutions, of which the effectiveness has been examined empirically in\napplications. However, due to the irregularity of crossover operators and the\ncomplicated interactions to mutation, crossover operators are hard to analyze\nand thus have few theoretical results. Therefore, analyzing crossover not only\nhelps in understanding EAs, but also helps in developing novel techniques for\nanalyzing sophisticated metaheuristic algorithms.\n  In this paper, we derive the General Markov Chain Switching Theorem (GMCST)\nto facilitate theoretical studies of crossover-enabled EAs. The theorem allows\nus to analyze the running time of a sophisticated EA from an easy-to-analyze\nEA. Using this tool, we analyze EAs with several crossover operators on the\nLeadingOnes and OneMax problems, which are noticeably two well studied problems\nfor mutation-only EAs but with few results for crossover-enabled EAs. We first\nderive the bounds of running time of the (2+2)-EA with crossover operators;\nthen we study the running time gap between the mutation-only (2:2)-EA and the\n(2:2)-EA with crossover operators; finally, we develop strategies that apply\ncrossover operators only when necessary, which improve from the mutation-only\nas well as the crossover-all-the-time (2:2)-EA. The theoretical results are\nverified by experiments."
},{
    "category": "cs.NE", 
    "doi": "10.1613/jair.1660", 
    "link": "http://arxiv.org/pdf/1111.1353v1", 
    "other_authors": "Gerald Paul", 
    "title": "An efficient implementation of the simulated annealing heuristic for the   quadratic assignment problem", 
    "arxiv-id": "1111.1353v1", 
    "author": "Gerald Paul", 
    "publish": "2011-11-05T21:43:56Z", 
    "summary": "The quadratic assignment problem (QAP) is one of the most difficult\ncombinatorial optimization problems. One of the most powerful and commonly used\nheuristics to obtain approximations to the optimal solution of the QAP is\nsimulated annealing (SA). We present an efficient implementation of the SA\nheuristic which performs more than 100 times faster then existing\nimplementations for large problem sizes and a large number of SA iterations."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijaia.2011.2302", 
    "link": "http://arxiv.org/pdf/1111.1564v1", 
    "other_authors": "Balwnder Singh, Sukhleen Bindra Narang, Arun Khosla", 
    "title": "Particle Swarm Optimization Framework for Low Power Testing of VLSI   Circuits", 
    "arxiv-id": "1111.1564v1", 
    "author": "Arun Khosla", 
    "publish": "2011-11-07T13:04:48Z", 
    "summary": "Power dissipation in sequential circuits is due to increased toggling count\nof Circuit under Test, which depends upon test vectors applied. If successive\ntest vectors sequences have more toggling nature then it is sure that toggling\nrate of flip flops is higher. Higher toggling for flip flops results more power\ndissipation. To overcome this problem, one method is to use GA to have test\nvectors of high fault coverage in short interval, followed by Hamming distance\nmanagement on test patterns. This approach is time consuming and needs more\nefforts. Another method which is purposed in this paper is a PSO based Frame\nWork to optimize power dissipation. Here target is to set the entire test\nvector in a frame for time period 'T', so that the frame consists of all those\nvectors strings which not only provide high fault coverage but also arrange\nvectors in frame to produce minimum toggling."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijaia.2011.2302", 
    "link": "http://arxiv.org/pdf/1202.0678v2", 
    "other_authors": "Matteo De Felice, Sandro Meloni, Stefano Panzieri", 
    "title": "Influence of Topological Features on Spatially-Structured Evolutionary   Algorithms Dynamics", 
    "arxiv-id": "1202.0678v2", 
    "author": "Stefano Panzieri", 
    "publish": "2012-02-03T12:24:37Z", 
    "summary": "In the last decades, complex networks theory significantly influenced other\ndisciplines on the modeling of both static and dynamic aspects of systems\nobserved in nature. This work aims to investigate the effects of networks'\ntopological features on the dynamics of an evolutionary algorithm, considering\nin particular the ability to find a large number of optima on multi-modal\nproblems. We introduce a novel spatially-structured evolutionary algorithm and\nwe apply it on two combinatorial problems: ONEMAX and the multi-modal NMAX.\nConsidering three different network models we investigate the relationships\nbetween their features, algorithm's convergence and its ability to find\nmultiple optima (for the multi-modal problem). In order to perform a deeper\nanalysis we investigate the introduction of weighted graphs with time-varying\nweights. The results show that networks with a large Average Path Length lead\nto an higher number of optima and a consequent slow exploration dynamics (i.e.\nlow First Hitting Time). Furthermore, the introduction of weighted networks\nshows the possibility to tune algorithm's dynamics during its execution with\nthe parameter related with weights' change. This work gives a first answer\nabout the effects of various graph topologies on the diversity of evolutionary\nalgorithms and it describes a simple but powerful algorithmic framework which\nallows to investigate many aspects of ssEAs dynamics."
},{
    "category": "cs.NE", 
    "doi": "10.1109/CEC.2012.6256166", 
    "link": "http://arxiv.org/pdf/1202.1708v2", 
    "other_authors": "Boris Mitavskiy, Jun He", 
    "title": "A Polynomial Time Approximation Scheme for a Single Machine Scheduling   Problem Using a Hybrid Evolutionary Algorithm", 
    "arxiv-id": "1202.1708v2", 
    "author": "Jun He", 
    "publish": "2012-02-08T14:30:55Z", 
    "summary": "Nowadays hybrid evolutionary algorithms, i.e, heuristic search algorithms\ncombining several mutation operators some of which are meant to implement\nstochastically a well known technique designed for the specific problem in\nquestion while some others playing the role of random search, have become\nrather popular for tackling various NP-hard optimization problems. While\nempirical studies demonstrate that hybrid evolutionary algorithms are\nfrequently successful at finding solutions having fitness sufficiently close to\nthe optimal, many fewer articles address the computational complexity in a\nmathematically rigorous fashion. This paper is devoted to a mathematically\nmotivated design and analysis of a parameterized family of evolutionary\nalgorithms which provides a polynomial time approximation scheme for one of the\nwell-known NP-hard combinatorial optimization problems, namely the \"single\nmachine scheduling problem without precedence constraints\". The authors hope\nthat the techniques and ideas developed in this article may be applied in many\nother situations."
},{
    "category": "cs.NE", 
    "doi": "10.1134/S1064562411030197", 
    "link": "http://arxiv.org/pdf/1205.0732v1", 
    "other_authors": "Boris Kryzhanovsky, Mikhail Kryzhanovsky, Magomed Malsagov", 
    "title": "Discretization of a matrix in the problem of quadratic functional binary   minimization", 
    "arxiv-id": "1205.0732v1", 
    "author": "Magomed Malsagov", 
    "publish": "2012-05-03T15:15:21Z", 
    "summary": "The capability of discretization of matrix elements in the problem of\nquadratic functional minimization with linear member built on matrix in\nN-dimensional configuration space with discrete coordinates is researched. It\nis shown, that optimal procedure of replacement matrix elements by the integer\nquantities with the limited number of gradations exist, and the efficient of\nminimization does not reduce. Parameter depends on matrix properties, which\nallows estimate the capability of using described procedure for given type of\nmatrix, is found. Computational complexities of algorithm and RAM requirements\nare reduced by 16 times, correct using of integer elements allows increase\nminimization algorithm speed by the orders."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijcsea.2012.2204", 
    "link": "http://arxiv.org/pdf/1205.2797v1", 
    "other_authors": "Yusuf Perwej, Asif Perwej", 
    "title": "Forecasting of Indian Rupee (INR) / US Dollar (USD) Currency Exchange   Rate Using Artificial Neural Network", 
    "arxiv-id": "1205.2797v1", 
    "author": "Asif Perwej", 
    "publish": "2012-05-12T17:26:49Z", 
    "summary": "A large part of the workforce, and growing every day, is originally from\nIndia. India one of the second largest populations in the world, they have a\nlot to offer in terms of jobs. The sheer number of IT workers makes them a\nformidable travelling force as well, easily picking up employment in English\nspeaking countries. The beginning of the economic crises since 2008 September,\nmany Indians have return homeland, and this has had a substantial impression on\nthe Indian Rupee (INR) as liken to the US Dollar (USD). We are using\nnumerational knowledge based techniques for forecasting has been proved highly\nsuccessful in present time. The purpose of this paper is to examine the effects\nof several important neural network factors on model fitting and forecasting\nthe behaviours. In this paper, Artificial Neural Network has successfully been\nused for exchange rate forecasting. This paper examines the effects of the\nnumber of inputs and hidden nodes and the size of the training sample on the\nin-sample and out-of-sample performance. The Indian Rupee (INR) / US Dollar\n(USD) is used for detailed examinations. The number of input nodes has a\ngreater impact on performance than the number of hidden nodes, while a large\nnumber of observations do reduce forecast errors."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijcsea.2012.2204", 
    "link": "http://arxiv.org/pdf/1206.0730v1", 
    "other_authors": "Youhei Akimoto, Yuichi Nagata, Isao Ono, Shigenobu Kobayashi", 
    "title": "Theoretical foundation for CMA-ES from information geometric perspective", 
    "arxiv-id": "1206.0730v1", 
    "author": "Shigenobu Kobayashi", 
    "publish": "2012-06-04T17:20:58Z", 
    "summary": "This paper explores the theoretical basis of the covariance matrix adaptation\nevolution strategy (CMA-ES) from the information geometry viewpoint.\n  To establish a theoretical foundation for the CMA-ES, we focus on a geometric\nstructure of a Riemannian manifold of probability distributions equipped with\nthe Fisher metric. We define a function on the manifold which is the\nexpectation of fitness over the sampling distribution, and regard the goal of\nupdate of the parameters of sampling distribution in the CMA-ES as maximization\nof the expected fitness. We investigate the steepest ascent learning for the\nexpected fitness maximization, where the steepest ascent direction is given by\nthe natural gradient, which is the product of the inverse of the Fisher\ninformation matrix and the conventional gradient of the function.\n  Our first result is that we can obtain under some types of parameterization\nof multivariate normal distribution the natural gradient of the expected\nfitness without the need for inversion of the Fisher information matrix. We\nfind that the update of the distribution parameters in the CMA-ES is the same\nas natural gradient learning for expected fitness maximization. Our second\nresult is that we derive the range of learning rates such that a step in the\ndirection of the exact natural gradient improves the parameters in the expected\nfitness. We see from the close relation between the CMA-ES and natural gradient\nlearning that the default setting of learning rates in the CMA-ES seems\nsuitable in terms of monotone improvement in expected fitness. Then, we discuss\nthe relation to the expectation-maximization framework and provide an\ninformation geometric interpretation of the CMA-ES."
},{
    "category": "cs.NE", 
    "doi": "10.5121/ijcsea.2012.2204", 
    "link": "http://arxiv.org/pdf/1206.0974v1", 
    "other_authors": "Ilya Loshchilov, Marc Schoenauer, Mich\u00e8le Sebag", 
    "title": "Black-box optimization benchmarking of IPOP-saACM-ES on the BBOB-2012   noisy testbed", 
    "arxiv-id": "1206.0974v1", 
    "author": "Mich\u00e8le Sebag", 
    "publish": "2012-04-24T06:22:19Z", 
    "summary": "In this paper, we study the performance of IPOP-saACM-ES, recently proposed\nself-adaptive surrogate-assisted Covariance Matrix Adaptation Evolution\nStrategy. The algorithm was tested using restarts till a total number of\nfunction evaluations of $10^6D$ was reached, where $D$ is the dimension of the\nfunction search space. The experiments show that the surrogate model control\nallows IPOP-saACM-ES to be as robust as the original IPOP-aCMA-ES and\noutperforms the latter by a factor from 2 to 3 on 6 benchmark problems with\nmoderate noise. On 15 out of 30 benchmark problems in dimension 20,\nIPOP-saACM-ES exceeds the records observed during BBOB-2009 and BBOB-2010."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29353-5_8", 
    "link": "http://arxiv.org/pdf/1206.1012v1", 
    "other_authors": "Iztok Fister Jr., Iztok Fister, Janez Brest", 
    "title": "A Hybrid Artificial Bee Colony Algorithm for Graph 3-Coloring", 
    "arxiv-id": "1206.1012v1", 
    "author": "Janez Brest", 
    "publish": "2012-05-06T18:44:15Z", 
    "summary": "The Artificial Bee Colony (ABC) is the name of an optimization algorithm that\nwas inspired by the intelligent behavior of a honey bee swarm. It is widely\nrecognized as a quick, reliable, and efficient methods for solving optimization\nproblems. This paper proposes a hybrid ABC (HABC) algorithm for graph\n3-coloring, which is a well-known discrete optimization problem. The results of\nHABC are compared with results of the well-known graph coloring algorithms of\ntoday, i.e. the Tabucol and Hybrid Evolutionary algorithm (HEA) and results of\nthe traditional evolutionary algorithm with SAW method (EA-SAW). Extensive\nexperimentations has shown that the HABC matched the competitive results of the\nbest graph coloring algorithms, and did better than the traditional heuristics\nEA-SAW when solving equi-partite, flat, and random generated medium-sized\ngraphs."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29353-5_8", 
    "link": "http://arxiv.org/pdf/1206.1443v1", 
    "other_authors": "Asif Perwej", 
    "title": "On applying Neuro - Computing in E-com Domain", 
    "arxiv-id": "1206.1443v1", 
    "author": "Asif Perwej", 
    "publish": "2012-06-07T10:48:48Z", 
    "summary": "Prior studies have generally suggested that Artificial Neural Networks (ANNs)\nare superior to conventional statistical models in predicting consumer buying\nbehavior. There are, however, contradicting findings which raise question over\nusefulness of ANNs. This paper discusses development of three neural networks\nfor modeling consumer e-commerce behavior and compares the findings to\nequivalent logistic regression models. The results showed that ANNs predict\ne-commerce adoption slightly more accurately than logistic models but this is\nhardly justifiable given the added complexity. Further, ANNs seem to be highly\nadaptive, particularly when a small sample is coupled with a large number of\nnodes in hidden layers which, in turn, limits the neural networks'\ngeneralisability."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29353-5_8", 
    "link": "http://arxiv.org/pdf/1206.1971v2", 
    "other_authors": "Siby Abraham, Sugata Sanyal, Mukund Sanglikar", 
    "title": "A Connectionist Network Approach to Find Numerical Solutions of   Diophantine Equations", 
    "arxiv-id": "1206.1971v2", 
    "author": "Mukund Sanglikar", 
    "publish": "2012-06-09T20:24:09Z", 
    "summary": "The paper introduces a connectionist network approach to find numerical\nsolutions of Diophantine equations as an attempt to address the famous\nHilbert's tenth problem. The proposed methodology uses a three layer feed\nforward neural network with back propagation as sequential learning procedure\nto find numerical solutions of a class of Diophantine equations. It uses a\ndynamically constructed network architecture where number of nodes in the input\nlayer is chosen based on the number of variables in the equation. The powers of\nthe given Diophantine equation are taken as input to the input layer. The\ntraining of the network starts with initial random integral weights. The\nweights are updated based on the back propagation of the error values at the\noutput layer. The optimization of weights is augmented by adding a momentum\nfactor into the network. The optimized weights of the connection between the\ninput layer and the hidden layer are taken as numerical solution of the given\nDiophantine equation. The procedure is validated using different Diophantine\nEquations of different number of variables and different powers."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29353-5_8", 
    "link": "http://arxiv.org/pdf/1206.3522v1", 
    "other_authors": "J\u00f6rg L\u00e4ssig, Dirk Sudholt", 
    "title": "General Upper Bounds on the Running Time of Parallel Evolutionary   Algorithms", 
    "arxiv-id": "1206.3522v1", 
    "author": "Dirk Sudholt", 
    "publish": "2012-06-15T17:28:51Z", 
    "summary": "We present a new method for analyzing the running time of parallel\nevolutionary algorithms with spatially structured populations. Based on the\nfitness-level method, it yields upper bounds on the expected parallel running\ntime. This allows to rigorously estimate the speedup gained by parallelization.\nTailored results are given for common migration topologies: ring graphs, torus\ngraphs, hypercubes, and the complete graph. Example applications for\npseudo-Boolean optimization show that our method is easy to apply and that it\ngives powerful results. In our examples the possible speedup increases with the\ndensity of the topology. Surprisingly, even sparse topologies like ring graphs\nlead to a significant speedup for many functions while not increasing the total\nnumber of function evaluations by more than a constant factor. We also identify\nwhich number of processors yield asymptotically optimal speedups, thus giving\nhints on how to parametrize parallel evolutionary algorithms."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29353-5_8", 
    "link": "http://arxiv.org/pdf/1206.5559v1", 
    "other_authors": "Susan Khor", 
    "title": "Speeding up the construction of slow adaptive walks", 
    "arxiv-id": "1206.5559v1", 
    "author": "Susan Khor", 
    "publish": "2012-06-25T02:16:01Z", 
    "summary": "An algorithm (bliss) is proposed to speed up the construction of slow\nadaptive walks. Slow adaptive walks are adaptive walks biased towards closer\npoints or smaller move steps. They were previously introduced to explore a\nsearch space, e.g. to detect potential local optima or to assess the ruggedness\nof a fitness landscape. To avoid the quadratic cost of computing Hamming\ndistance (HD) for all-pairs of strings in a set in order to find the set of\nclosest strings for each string, strings are sorted and clustered by bliss such\nthat similar strings are more likely to get paired off for HD computation. To\nefficiently arrange the strings by similarity, bliss employs the idea of shared\nnon-overlapping position specific subsequences between strings which is\ninspired by an alignment-free protein sequence comparison algorithm. Tests are\nperformed to evaluate the quality of b-walks, i.e. slow adaptive walks\nconstructed from the output of bliss, on enumerated search spaces. Finally,\nb-walks are applied to explore larger search spaces with the help of\nWang-Landau sampling."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29353-5_8", 
    "link": "http://arxiv.org/pdf/1206.5651v2", 
    "other_authors": "Garimella Ramamurthy, Bondalapati Nischal", 
    "title": "Optimization of Real, Hermitian Quadratic Forms: Real, Complex   Hopfield-Amari Neural Network", 
    "arxiv-id": "1206.5651v2", 
    "author": "Bondalapati Nischal", 
    "publish": "2012-06-25T11:30:44Z", 
    "summary": "In this research paper, the problem of optimization of quadratic forms\nassociated with the dynamics of Hopfield-Amari neural network is considered. An\nelegant (and short) proof of the states at which local/global minima of\nquadratic form are attained is provided. A theorem associated with local/global\nminimization of quadratic energy function using the Hopfield-Amari neural\nnetwork is discussed. The results are generalized to a \"Complex Hopfield neural\nnetwork\" dynamics over the complex hypercube (using a \"complex signum\nfunction\"). It is also reasoned through two theorems that there is no loss of\ngenerality in assuming the threshold vector to be a zero vector in the case of\nreal as well as a \"Complex Hopfield neural network\". Some structured quadratic\nforms like Toeplitz form and Complex Toeplitz form are discussed."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29353-5_8", 
    "link": "http://arxiv.org/pdf/1206.5780v1", 
    "other_authors": "Ilya Loshchilov, Marc Schoenauer, Mich\u00e8le Sebag", 
    "title": "Black-box optimization benchmarking of IPOP-saACM-ES and BIPOP-saACM-ES   on the BBOB-2012 noiseless testbed", 
    "arxiv-id": "1206.5780v1", 
    "author": "Mich\u00e8le Sebag", 
    "publish": "2012-04-24T06:23:46Z", 
    "summary": "In this paper, we study the performance of IPOP-saACM-ES and BIPOP-saACM-ES,\nrecently proposed self-adaptive surrogate-assisted Covariance Matrix Adaptation\nEvolution Strategies. Both algorithms were tested using restarts till a total\nnumber of function evaluations of $10^6D$ was reached, where $D$ is the\ndimension of the function search space. We compared surrogate-assisted\nalgorithms with their surrogate-less versions IPOP-saACM-ES and BIPOP-saACM-ES,\ntwo algorithms with one of the best overall performance observed during the\nBBOB-2009 and BBOB-2010. The comparison shows that the surrogate-assisted\nversions outperform the original CMA-ES algorithms by a factor from 2 to 4 on 8\nout of 24 noiseless benchmark problems, showing the best results among all\nalgorithms of the BBOB-2009 and BBOB-2010 on Ellipsoid, Discus, Bent Cigar,\nSharp Ridge and Sum of different powers functions."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29353-5_8", 
    "link": "http://arxiv.org/pdf/1208.2214v1", 
    "other_authors": "Fereydoun Farrahi Moghaddam, Reza Farrahi Moghaddam, Mohamed Cheriet", 
    "title": "Curved Space Optimization: A Random Search based on General Relativity   Theory", 
    "arxiv-id": "1208.2214v1", 
    "author": "Mohamed Cheriet", 
    "publish": "2012-08-10T16:53:57Z", 
    "summary": "Designing a fast and efficient optimization method with local optima\navoidance capability on a variety of optimization problems is still an open\nproblem for many researchers. In this work, the concept of a new global\noptimization method with an open implementation area is introduced as a Curved\nSpace Optimization (CSO) method, which is a simple probabilistic optimization\nmethod enhanced by concepts of general relativity theory. To address global\noptimization challenges such as performance and convergence, this new method is\ndesigned based on transformation of a random search space into a new search\nspace based on concepts of space-time curvature in general relativity theory.\nIn order to evaluate the performance of our proposed method, an implementation\nof CSO is deployed and its results are compared on benchmark functions with\nstate-of-the art optimization methods. The results show that the performance of\nCSO is promising on unimodal and multimodal benchmark functions with different\nsearch space dimension sizes."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29353-5_8", 
    "link": "http://arxiv.org/pdf/1208.2345v1", 
    "other_authors": "Tianshi Chen, Ke Tang, Guoliang Chen, Xin Yao", 
    "title": "A Large Population Size Can Be Unhelpful in Evolutionary Algorithms", 
    "arxiv-id": "1208.2345v1", 
    "author": "Xin Yao", 
    "publish": "2012-08-11T13:55:53Z", 
    "summary": "The utilization of populations is one of the most important features of\nevolutionary algorithms (EAs). There have been many studies analyzing the\nimpact of different population sizes on the performance of EAs. However, most\nof such studies are based computational experiments, except for a few cases.\nThe common wisdom so far appears to be that a large population would increase\nthe population diversity and thus help an EA. Indeed, increasing the population\nsize has been a commonly used strategy in tuning an EA when it did not perform\nas well as expected for a given problem. He and Yao (2002) showed theoretically\nthat for some problem instance classes, a population can help to reduce the\nruntime of an EA from exponential to polynomial time. This paper analyzes the\nrole of population further in EAs and shows rigorously that large populations\nmay not always be useful. Conditions, under which large populations can be\nharmful, are discussed in this paper. Although the theoretical analysis was\ncarried out on one multi-modal problem using a specific type of EAs, it has\nmuch wider implications. The analysis has revealed certain problem\ncharacteristics, which can be either the problem considered here or other\nproblems, that lead to the disadvantages of large population sizes. The\nanalytical approach developed in this paper can also be applied to analyzing\nEAs on other problems."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29353-5_8", 
    "link": "http://arxiv.org/pdf/1208.2437v1", 
    "other_authors": "Mauro Castelli, Luca Manzoni, Leonardo Vanneschi", 
    "title": "An Efficient Genetic Programming System with Geometric Semantic   Operators and its Application to Human Oral Bioavailability Prediction", 
    "arxiv-id": "1208.2437v1", 
    "author": "Leonardo Vanneschi", 
    "publish": "2012-08-12T16:01:54Z", 
    "summary": "Very recently new genetic operators, called geometric semantic operators,\nhave been defined for genetic programming. Contrarily to standard genetic\noperators, which are uniquely based on the syntax of the individuals, these new\noperators are based on their semantics, meaning with it the set of input-output\npairs on training data. Furthermore, these operators present the interesting\nproperty of inducing a unimodal fitness landscape for every problem that\nconsists in finding a match between given input and output data (for instance\nregression and classification). Nevertheless, the current definition of these\noperators has a serious limitation: they impose an exponential growth in the\nsize of the individuals in the population, so their use is impossible in\npractice. This paper is intended to overcome this limitation, presenting a new\ngenetic programming system that implements geometric semantic operators in an\nextremely efficient way. To demonstrate the power of the proposed system, we\nuse it to solve a complex real-life application in the field of\npharmacokinetic: the prediction of the human oral bioavailability of potential\nnew drugs. Besides the excellent performances on training data, which were\nexpected because the fitness landscape is unimodal, we also report an excellent\ngeneralization ability of the proposed system, at least for the studied\napplication. In fact, it outperforms standard genetic programming and a wide\nset of other well-known machine learning methods."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29353-5_8", 
    "link": "http://arxiv.org/pdf/1208.4009v1", 
    "other_authors": "Behrooz Kamary Aliabadi, Claude Berrou, Vincent Gripon, Xiaoran Jiang", 
    "title": "Learning sparse messages in networks of neural cliques", 
    "arxiv-id": "1208.4009v1", 
    "author": "Xiaoran Jiang", 
    "publish": "2012-08-20T13:54:26Z", 
    "summary": "An extension to a recently introduced binary neural network is proposed in\norder to allow the learning of sparse messages, in large numbers and with high\nmemory efficiency. This new network is justified both in biological and\ninformational terms. The learning and retrieval rules are detailed and\nillustrated by various simulation results."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29353-5_8", 
    "link": "http://arxiv.org/pdf/1208.4583v1", 
    "other_authors": "N. Fogarasi, K. Tornai, J. Levendovszky", 
    "title": "A novel Hopfield neural network approach for minimizing total weighted   tardiness of jobs scheduled on identical machines", 
    "arxiv-id": "1208.4583v1", 
    "author": "J. Levendovszky", 
    "publish": "2012-07-26T19:18:29Z", 
    "summary": "This paper explores fast, polynomial time heuristic approximate solutions to\nthe NP-hard problem of scheduling jobs on N identical machines. The jobs are\nindependent and are allowed to be stopped and restarted on another machine at a\nlater time. They have well-defined deadlines, and relative priorities\nquantified by non-negative real weights. The objective is to find schedules\nwhich minimize the total weighted tardiness (TWT) of all jobs. We show how this\nproblem can be mapped into quadratic form and present a polynomial time\nheuristic solution based on the Hopfield Neural Network (HNN) approach. It is\ndemonstrated, through the results of extensive numerical simulations, that this\nsolution outperforms other popular heuristic methods. The proposed heuristic is\nboth theoretically and empirically shown to be scalable to large problem sizes\n(over 100 jobs to be scheduled), which makes it applicable to grid computing\nscheduling, arising in fields such as computational biology, chemistry and\nfinance."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29353-5_8", 
    "link": "http://arxiv.org/pdf/1208.6025v1", 
    "other_authors": "Md. Tarek Habib, Rahat Hossain Faisal, M. Rokonuzzaman", 
    "title": "Feasibility of Genetic Algorithm for Textile Defect Classification Using   Neural Network", 
    "arxiv-id": "1208.6025v1", 
    "author": "M. Rokonuzzaman", 
    "publish": "2012-08-11T21:45:46Z", 
    "summary": "The global market for textile industry is highly competitive nowadays.\nQuality control in production process in textile industry has been a key factor\nfor retaining existence in such competitive market. Automated textile\ninspection systems are very useful in this respect, because manual inspection\nis time consuming and not accurate enough. Hence, automated textile inspection\nsystems have been drawing plenty of attention of the researchers of different\ncountries in order to replace manual inspection. Defect detection and defect\nclassification are the two major problems that are posed by the research of\nautomated textile inspection systems. In this paper, we perform an extensive\ninvestigation on the applicability of genetic algorithm (GA) in the context of\ntextile defect classification using neural network (NN). We observe the effect\nof tuning different network parameters and explain the reasons. We empirically\nfind a suitable NN model in the context of textile defect classification. We\ncompare the performance of this model with that of the classification models\nimplemented by others."
},{
    "category": "cs.NE", 
    "doi": "10.1007/978-3-642-29353-5_8", 
    "link": "http://arxiv.org/pdf/1208.6028v1", 
    "other_authors": "Sadik Ulker", 
    "title": "Design of Low Noise Amplifiers Using Particle Swarm Optimization", 
    "arxiv-id": "1208.6028v1", 
    "author": "Sadik Ulker", 
    "publish": "2012-08-13T11:32:03Z", 
    "summary": "This short paper presents a work on the design of low noise microwave\namplifiers using particle swarm optimization (PSO) technique. Particle Swarm\nOptimization is used as a method that is applied to a single stage amplifier\ncircuit to meet two criteria: desired gain and desired low noise. The aim is to\nget the best optimized design using the predefined constraints for gain and low\nnoise values. The code is written to apply the algorithm to meet the desired\ngoals and the obtained results are verified using different simulators. The\nresults obtained show that PSO can be applied very efficiently for this kind of\ndesign problems with multiple constraints."
}]