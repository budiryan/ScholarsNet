[{
    "category": "cs.LO", 
    "doi": "10.1145/2783258.2783340", 
    "link": "http://arxiv.org/pdf/cs/9301101v1", 
    "title": "Verifying the Unification Algorithm in LCF", 
    "arxiv-id": "cs/9301101v1", 
    "author": "Lawrence C. Paulson", 
    "publish": "2000-09-29T00:00:00Z", 
    "summary": "Manna and Waldinger's theory of substitutions and unification has been\nverified using the Cambridge LCF theorem prover. A proof of the monotonicity of\nsubstitution is presented in detail, as an example of interaction with LCF.\nTranslating the theory into LCF's domain-theoretic logic is largely\nstraightforward. Well-founded induction on a complex ordering is translated\ninto nested structural inductions. Correctness of unification is expressed\nusing predicates for such properties as idempotence and most-generality. The\nverification is presented as a series of lemmas. The LCF proofs are compared\nwith the original ones, and with other approaches. It appears difficult to find\na logic that is both simple and flexible, especially for proving termination."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2783258.2783340", 
    "link": "http://arxiv.org/pdf/cs/9301102v1", 
    "title": "Constructing Recursion Operators in Intuitionistic Type Theory", 
    "arxiv-id": "cs/9301102v1", 
    "author": "Lawrence C. Paulson", 
    "publish": "2000-10-31T00:00:00Z", 
    "summary": "Martin-L\\\"of's Intuitionistic Theory of Types is becoming popular for formal\nreasoning about computer programs. To handle recursion schemes other than\nprimitive recursion, a theory of well-founded relations is presented. Using\nprimitive recursion over higher types, induction and recursion are formally\nderived for a large class of well-founded relations. Included are < on natural\nnumbers, and relations formed by inverse images, addition, multiplication, and\nexponentiation of other relations. The constructions are given in full detail\nto allow their use in theorem provers for Type Theory, such as Nuprl. The\ntheory is compared with work in the field of ordinal recursion over higher\ntypes."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2783258.2783340", 
    "link": "http://arxiv.org/pdf/cs/9301103v1", 
    "title": "Proving Termination of Normalization Functions for Conditional   Expressions", 
    "arxiv-id": "cs/9301103v1", 
    "author": "Lawrence C. Paulson", 
    "publish": "2000-10-02T00:00:00Z", 
    "summary": "Boyer and Moore have discussed a recursive function that puts conditional\nexpressions into normal form [1]. It is difficult to prove that this function\nterminates on all inputs. Three termination proofs are compared: (1) using a\nmeasure function, (2) in domain theory using LCF, (3) showing that its\nrecursion relation, defined by the pattern of recursive calls, is well-founded.\nThe last two proofs are essentially the same though conducted in markedly\ndifferent logical frameworks. An obviously total variant of the normalize\nfunction is presented as the `computational meaning' of those two proofs. A\nrelated function makes nested recursive calls. The three termination proofs\nbecome more complex: termination and correctness must be proved simultaneously.\nThe recursion relation approach seems flexible enough to handle subtle\ntermination proofs where previously domain theory seemed essential."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2783258.2783340", 
    "link": "http://arxiv.org/pdf/cs/9301104v1", 
    "title": "Natural Deduction as Higher-Order Resolution", 
    "arxiv-id": "cs/9301104v1", 
    "author": "Lawrence C. Paulson", 
    "publish": "2000-10-31T00:00:00Z", 
    "summary": "An interactive theorem prover, Isabelle, is under development. In LCF, each\ninference rule is represented by one function for forwards proof and another (a\ntactic) for backwards proof. In Isabelle, each inference rule is represented by\na Horn clause. Resolution gives both forwards and backwards proof, supporting a\nlarge class of logics. Isabelle has been used to prove theorems in\nMartin-L\\\"of's Constructive Type Theory. Quantifiers pose several difficulties:\nsubstitution, bound variables, Skolemization. Isabelle's representation of\nlogical syntax is the typed lambda-calculus, requiring higher- order\nunification. It may have potential for logic programming. Depth-first\nsubgoaling along inference rules constitutes a higher-order Prolog."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2783258.2783340", 
    "link": "http://arxiv.org/pdf/cs/9301105v1", 
    "title": "The Foundation of a Generic Theorem Prover", 
    "arxiv-id": "cs/9301105v1", 
    "author": "Lawrence C. Paulson", 
    "publish": "2000-10-31T00:00:00Z", 
    "summary": "Isabelle is an interactive theorem prover that supports a variety of logics.\nIt represents rules as propositions (not as functions) and builds proofs by\ncombining rules. These operations constitute a meta-logic (or `logical\nframework') in which the object-logics are formalized. Isabelle is now based on\nhigher-order logic -- a precise and well-understood foundation. Examples\nillustrate use of this meta-logic to formalize logics and proofs. Axioms for\nfirst-order logic are shown sound and complete. Backwards proof is formalized\nby meta-reasoning about object-level entailment. Higher-order logic has several\npractical advantages over other meta-logics. Many proof techniques are known,\nsuch as Huet's higher-order unification procedure."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2783258.2783340", 
    "link": "http://arxiv.org/pdf/cs/9301106v1", 
    "title": "Isabelle: The Next 700 Theorem Provers", 
    "arxiv-id": "cs/9301106v1", 
    "author": "Lawrence C. Paulson", 
    "publish": "2000-10-31T00:00:00Z", 
    "summary": "Isabelle is a generic theorem prover, designed for interactive reasoning in a\nvariety of formal theories. At present it provides useful proof procedures for\nConstructive Type Theory, various first-order logics, Zermelo-Fraenkel set\ntheory, and higher-order logic. This survey of Isabelle serves as an\nintroduction to the literature. It explains why generic theorem proving is\nbeneficial. It gives a thorough history of Isabelle, beginning with its origins\nin the LCF system. It presents an account of how logics are represented,\nillustrated using classical logic. The approach is compared with the Edinburgh\nLogical Framework. Several of the Isabelle object-logics are presented."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2783258.2783340", 
    "link": "http://arxiv.org/pdf/cs/9301107v1", 
    "title": "A Formulation of the Simple Theory of Types (for Isabelle)", 
    "arxiv-id": "cs/9301107v1", 
    "author": "Lawrence C. Paulson", 
    "publish": "2000-10-31T00:00:00Z", 
    "summary": "Simple type theory is formulated for use with the generic theorem prover\nIsabelle. This requires explicit type inference rules. There are function,\nproduct, and subset types, which may be empty. Descriptions (the eta-operator)\nintroduce the Axiom of Choice. Higher-order logic is obtained through\nreflection between formulae and terms of type bool. Recursive types and\nfunctions can be formally constructed. Isabelle proof procedures are described.\nThe logic appears suitable for general mathematics as well as computational\nproblems."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2783258.2783340", 
    "link": "http://arxiv.org/pdf/cs/9301108v1", 
    "title": "A Higher-Order Implementation of Rewriting", 
    "arxiv-id": "cs/9301108v1", 
    "author": "Lawrence C. Paulson", 
    "publish": "2001-03-29T00:00:00Z", 
    "summary": "Many automatic theorem-provers rely on rewriting. Using theorems as rewrite\nrules helps to simplify the subgoals that arise during a proof.\n  LCF is an interactive theorem-prover intended for reasoning about\ncomputation. Its implementation of rewriting is presented in detail. LCF\nprovides a family of rewriting functions, and operators to combine them. A\nsuccession of functions is described, from pattern matching primitives to the\nrewriting tool that performs most inferences in LCF proofs.\n  The design is highly modular. Each function performs a basic, specific task,\nsuch as recognizing a certain form of tautology. Each operator implements one\nmethod of building a rewriting function from simpler ones. These pieces can be\nput together in numerous ways, yielding a variety of rewrit- ing strategies.\n  The approach involves programming with higher-order functions. Rewriting\nfunctions are data values, produced by computation on other rewriting\nfunctions. The code is in daily use at Cambridge, demonstrating the practical\nuse of functional programming."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2783258.2783340", 
    "link": "http://arxiv.org/pdf/cs/9301109v1", 
    "title": "Logic Programming, Functional Programming, and Inductive Definitions", 
    "arxiv-id": "cs/9301109v1", 
    "author": "Andrew W. Smith", 
    "publish": "2001-03-29T00:00:00Z", 
    "summary": "An attempt at unifying logic and functional programming is reported. As a\nstarting point, we take the view that \"logic programs\" are not about logic but\nconstitute inductive definitions of sets and relations. A skeletal language\ndesign based on these considerations is sketched and a prototype implementation\ndiscussed."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2783258.2783340", 
    "link": "http://arxiv.org/pdf/cs/9301110v1", 
    "title": "Designing a Theorem Prover", 
    "arxiv-id": "cs/9301110v1", 
    "author": "Lawrence C. Paulson", 
    "publish": "2001-03-29T00:00:00Z", 
    "summary": "A step-by-step presentation of the code for a small theorem prover introduces\ntheorem-proving techniques. The programming language used is Standard ML. The\nprover operates on a sequent calculus formulation of first-order logic, which\nis briefly explained. The implementation of unification and logical inference\nis shown. The prover is demonstrated on several small examples, including one\nthat shows its limitations. The final part of the paper is a survey of\ncontemporary research on interactive theorem proving."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2783258.2783340", 
    "link": "http://arxiv.org/pdf/cs/9311103v1", 
    "title": "Set Theory for Verification: I. From Foundations to Functions", 
    "arxiv-id": "cs/9311103v1", 
    "author": "Lawrence C. Paulson", 
    "publish": "2000-10-31T00:00:00Z", 
    "summary": "A logic for specification and verification is derived from the axioms of\nZermelo-Fraenkel set theory. The proofs are performed using the proof assistant\nIsabelle. Isabelle is generic, supporting several different logics. Isabelle\nhas the flexibility to adapt to variants of set theory. Its higher-order syntax\nsupports the definition of new binding operators. Unknowns in subgoals can be\ninstantiated incrementally. The paper describes the derivation of rules for\ndescriptions, relations and functions, and discusses interactive proofs of\nCantor's Theorem, the Composition of Homomorphisms challenge [9], and Ramsey's\nTheorem [5]. A generic proof assistant can stand up against provers dedicated\nto particular logics."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2783258.2783340", 
    "link": "http://arxiv.org/pdf/cs/9511102v1", 
    "title": "Set Theory for Verification: II. Induction and Recursion", 
    "arxiv-id": "cs/9511102v1", 
    "author": "Lawrence C. Paulson", 
    "publish": "2000-11-14T00:00:00Z", 
    "summary": "A theory of recursive definitions has been mechanized in Isabelle's\nZermelo-Fraenkel (ZF) set theory. The objective is to support the formalization\nof particular recursive definitions for use in verification, semantics proofs\nand other computational reasoning. Inductively defined sets are expressed as\nleast fixedpoints, applying the Knaster-Tarski Theorem over a suitable set.\nRecursive functions are defined by well-founded recursion and its derivatives,\nsuch as transfinite recursion. Recursive data structures are expressed by\napplying the Knaster-Tarski Theorem to a set, such as V[omega], that is closed\nunder Cartesian product and disjoint sum. Worked examples include the\ntransitive closure of a relation, lists, variable-branching trees and mutually\nrecursive trees and forests. The Schr\\\"oder-Bernstein Theorem and the soundness\nof propositional logic are proved in Isabelle sessions."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2783258.2783340", 
    "link": "http://arxiv.org/pdf/cs/9511103v1", 
    "title": "A Concrete Final Coalgebra Theorem for ZF Set Theory", 
    "arxiv-id": "cs/9511103v1", 
    "author": "Lawrence C. Paulson", 
    "publish": "2001-03-29T00:00:00Z", 
    "summary": "A special final coalgebra theorem, in the style of Aczel's, is proved within\nstandard Zermelo-Fraenkel set theory. Aczel's Anti-Foundation Axiom is replaced\nby a variant definition of function that admits non-well-founded constructions.\nVariant ordered pairs and tuples, of possibly infinite length, are special\ncases of variant functions. Analogues of Aczel's Solution and Substitution\nLemmas are proved in the style of Rutten and Turi. The approach is less general\nthan Aczel's, but the treatment of non-well-founded objects is simple and\nconcrete. The final coalgebra of a functor is its greatest fixedpoint. The\ntheory is intended for machine implementation and a simple case of it is\nalready implemented using the theorem prover Isabelle."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2783258.2783340", 
    "link": "http://arxiv.org/pdf/cs/9612104v1", 
    "title": "Mechanizing Set Theory: Cardinal Arithmetic and the Axiom of Choice.", 
    "arxiv-id": "cs/9612104v1", 
    "author": "Krzysztof Grabczewski", 
    "publish": "2001-03-29T00:00:00Z", 
    "summary": "Fairly deep results of Zermelo-Frenkel (ZF) set theory have been mechanized\nusing the proof assistant Isabelle. The results concern cardinal arithmetic and\nthe Axiom of Choice (AC). A key result about cardinal multiplication is K*K =\nK, where K is any infinite cardinal. Proving this result required developing\ntheories of orders, order-isomorphisms, order types, ordinal arithmetic,\ncardinals, etc.; this covers most of Kunen, Set Theory, Chapter I. Furthermore,\nwe have proved the equivalence of 7 formulations of the Well-ordering Theorem\nand 20 formulations of AC; this covers the first two chapters of Rubin and\nRubin, Equivalents of the Axiom of Choice, and involves highly technical\nmaterial. The definitions used in the proofs are largely faithful in style to\nthe original mathematics."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2783258.2783340", 
    "link": "http://arxiv.org/pdf/cs/9711105v1", 
    "title": "Mechanizing Coinduction and Corecursion in Higher-order Logic", 
    "arxiv-id": "cs/9711105v1", 
    "author": "Lawrence C. Paulson", 
    "publish": "2000-10-31T00:00:00Z", 
    "summary": "A theory of recursive and corecursive definitions has been developed in\nhigher-order logic (HOL) and mechanized using Isabelle. Least fixedpoints\nexpress inductive data types such as strict lists; greatest fixedpoints express\ncoinductive data types, such as lazy lists. Well-founded recursion expresses\nrecursive functions over inductive data types; corecursion expresses functions\nthat yield elements of coinductive data types. The theory rests on a\ntraditional formalization of infinite trees. The theory is intended for use in\nspecification and verification. It supports reasoning about a wide range of\ncomputable functions, but it does not formalize their operational semantics and\ncan express noncomputable functions also. The theory is illustrated using\nfinite and infinite lists. Corecursion expresses functions over infinite lists;\ncoinduction reasons about such functions."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2783258.2783340", 
    "link": "http://arxiv.org/pdf/cs/9711106v1", 
    "title": "Generic Automatic Proof Tools", 
    "arxiv-id": "cs/9711106v1", 
    "author": "Lawrence C. Paulson", 
    "publish": "2001-03-29T00:00:00Z", 
    "summary": "This book chapter establishes connections between the interactive proof tool\nIsabelle and classical tableau and resolution technology. Isabelle's classical\nreasoner is described and demonstrated by an extended case study: the\nChurch-Rosser theorem for combinators. Compared with other interactive theorem\nprovers, Isabelle's classical reasoner achieves a high degree of automation."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2783258.2783340", 
    "link": "http://arxiv.org/pdf/cs/9809014v1", 
    "title": "Uniform Provability in Classical Logic", 
    "arxiv-id": "cs/9809014v1", 
    "author": "Gopalan Nadathur", 
    "publish": "1998-09-10T15:17:05Z", 
    "summary": "Uniform proofs are sequent calculus proofs with the following characteristic:\nthe last step in the derivation of a complex formula at any stage in the proof\nis always the introduction of the top-level logical symbol of that formula. We\ninvestigate the relevance of this uniform proof notion to structuring proof\nsearch in classical logic. A logical language in whose context provability is\nequivalent to uniform provability admits of a goal-directed proof procedure\nthat interprets logical symbols as search directives whose meanings are given\nby the corresponding inference rules. While this uniform provability property\ndoes not hold directly of classical logic, we show that it holds of a fragment\nof it that only excludes essentially positive occurrences of universal\nquantifiers under a modest, sound, modification to the set of assumptions: the\naddition to them of the negation of the formula being proved. We further note\nthat all uses of the added formula can be factored into certain derived rules.\nThe resulting proof system and the uniform provability property that holds of\nit are used to outline a proof procedure for classical logic. An interesting\naspect of this proof procedure is that it incorporates within it previously\nproposed mechanisms for dealing with disjunctive information in assumptions and\nfor handling hypotheticals. Our analysis sheds light on the relationship\nbetween these mechanisms and the notion of uniform proofs."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2783258.2783340", 
    "link": "http://arxiv.org/pdf/cs/9809015v1", 
    "title": "Correspondences between Classical, Intuitionistic and Uniform   Provability", 
    "arxiv-id": "cs/9809015v1", 
    "author": "Gopalan Nadathur", 
    "publish": "1998-09-10T15:39:30Z", 
    "summary": "Based on an analysis of the inference rules used, we provide a\ncharacterization of the situations in which classical provability entails\nintuitionistic provability. We then examine the relationship of these\nderivability notions to uniform provability, a restriction of intuitionistic\nprovability that embodies a special form of goal-directedness. We determine,\nfirst, the circumstances in which the former relations imply the latter. Using\nthis result, we identify the richest versions of the so-called abstract logic\nprogramming languages in classical and intuitionistic logic. We then study the\nreduction of classical and, derivatively, intuitionistic provability to uniform\nprovability via the addition to the assumption set of the negation of the\nformula to be proved. Our focus here is on understanding the situations in\nwhich this reduction is achieved. However, our discussions indicate the\nstructure of a proof procedure based on the reduction, a matter also considered\nexplicitly elsewhere."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2783258.2783340", 
    "link": "http://arxiv.org/pdf/cs/9809120v1", 
    "title": "A Natural Deduction style proof system for propositional $\u03bc$-calculus   and its formalization in inductive type theories", 
    "arxiv-id": "cs/9809120v1", 
    "author": "Marino Miculan", 
    "publish": "1998-09-29T11:57:32Z", 
    "summary": "In this paper, we present a formalization of Kozen's propositional modal\n$\\mu$-calculus, in the Calculus of Inductive Constructions. We address several\nproblematic issues, such as the use of higher-order abstract syntax in\ninductive sets in presence of recursive constructors, the encoding of modal\n(``proof'') rules and of context sensitive grammars. The encoding can be used\nin the \\Coq system, providing an experimental computer-aided proof environment\nfor the interactive development of error-free proofs in the $\\mu$-calculus. The\ntechniques we adopted can be readily ported to other languages and proof\nsystems featuring similar problematic issues."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2783258.2783340", 
    "link": "http://arxiv.org/pdf/cs/9810008v1", 
    "title": "Axiomatizing Flat Iteration", 
    "arxiv-id": "cs/9810008v1", 
    "author": "R. J. van Glabbeek", 
    "publish": "1998-10-07T22:39:16Z", 
    "summary": "Flat iteration is a variation on the original binary version of the Kleene\nstar operation P*Q, obtained by restricting the first argument to be a sum of\natomic actions. It generalizes prefix iteration, in which the first argument is\na single action. Complete finite equational axiomatizations are given for five\nnotions of bisimulation congruence over basic CCS with flat iteration, viz.\nstrong congruence, branching congruence, eta-congruence, delay congruence and\nweak congruence. Such axiomatizations were already known for prefix iteration\nand are known not to exist for general iteration. The use of flat iteration has\ntwo main advantages over prefix iteration: 1.The current axiomatizations\ngeneralize to full CCS, whereas the prefix iteration approach does not allow an\nelimination theorem for an asynchronous parallel composition operator. 2.The\ngreater expressiveness of flat iteration allows for much shorter completeness\nproofs.\n  In the setting of prefix iteration, the most convenient way to obtain the\ncompleteness theorems for eta-, delay, and weak congruence was by reduction to\nthe completeness theorem for branching congruence. In the case of weak\ncongruence this turned out to be much simpler than the only direct proof found.\nIn the setting of flat iteration on the other hand, the completeness theorems\nfor delay and weak (but not eta-) congruence can equally well be obtained by\nreduction to the one for strong congruence, without using branching congruence\nas an intermediate step. Moreover, the completeness results for prefix\niteration can be retrieved from those for flat iteration, thus obtaining a\nsecond indirect approach for proving completeness for delay and weak congruence\nin the setting of prefix iteration."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2783258.2783340", 
    "link": "http://arxiv.org/pdf/cs/9903006v1", 
    "title": "Designing SAT for HCP", 
    "arxiv-id": "cs/9903006v1", 
    "author": "Anatoly D. Plotnikov", 
    "publish": "1999-03-05T16:10:41Z", 
    "summary": "For arbitrary undirected graph $G$, we are designing SATISFIABILITY problem\n(SAT) for HCP, using tools of Boolean algebra only. The obtained SAT be the\nlogic formulation of conditions for Hamiltonian cycle existence, and use $m$\nBoolean variables, where $m$ is the number of graph edges. This Boolean\nexpression is true if and only if an initial graph is Hamiltonian. That is,\neach satisfying assignment of the Boolean variables determines a Hamiltonian\ncycle of $G$, and each Hamiltonian cycle of $G$ corresponds to a satisfying\nassignment of the Boolean variables. In common case, the obtained Boolean\nexpression may has an exponential length (the number of Boolean literals)."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2783258.2783340", 
    "link": "http://arxiv.org/pdf/cs/9907022v1", 
    "title": "Weak length induction and slow growing depth boolean circuits", 
    "arxiv-id": "cs/9907022v1", 
    "author": "Satoru Kuroda", 
    "publish": "1999-07-16T08:41:25Z", 
    "summary": "We define a hierarchy of circuit complexity classes LD^i, whose depth are the\ninverse of a function in Ackermann hierarchy. Then we introduce extremely weak\nversions of length induction and construct a bounded arithmetic theory L^i_2\nwhose provably total functions exactly correspond to functions computable by\nLD^i circuits. Finally, we prove a non-conservation result between L^i_2 and a\nweaker theory AC^0CA which corresponds to the class AC^0. Our proof utilizes\nKPT witnessing theorem."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/9910023v4", 
    "title": "A System of Interaction and Structure", 
    "arxiv-id": "cs/9910023v4", 
    "author": "Alessio Guglielmi", 
    "publish": "1999-10-28T09:17:34Z", 
    "summary": "This paper introduces a logical system, called BV, which extends\nmultiplicative linear logic by a non-commutative self-dual logical operator.\nThis extension is particularly challenging for the sequent calculus, and so far\nit is not achieved therein. It becomes very natural in a new formalism, called\nthe calculus of structures, which is the main contribution of this work.\nStructures are formulae submitted to certain equational laws typical of\nsequents. The calculus of structures is obtained by generalising the sequent\ncalculus in such a way that a new top-down symmetry of derivations is observed,\nand it employs inference rules that rewrite inside structures at any depth.\nThese properties, in addition to allow the design of BV, yield a modular proof\nof cut elimination."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0003026v1", 
    "title": "A Comparison of Logic Programming Approaches for Representation and   Solving of Constraint Satisfaction Problems", 
    "arxiv-id": "cs/0003026v1", 
    "author": "Maurice Bruynooghe", 
    "publish": "2000-03-08T12:52:32Z", 
    "summary": "Many logic programming based approaches can be used to describe and solve\ncombinatorial search problems. On the one hand there are definite programs and\nconstraint logic programs that compute a solution as an answer substitution to\na query containing the variables of the constraint satisfaction problem. On the\nother hand there are approaches based on stable model semantics, abduction, and\nfirst-order logic model generation that compute solutions as models of some\ntheory. This paper compares these different approaches from point of view of\nknowledge representation (how declarative are the programs) and from point of\nview of performance (how good are they at solving typical problems)."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0003045v1", 
    "title": "Termination Proofs for Logic Programs with Tabling", 
    "arxiv-id": "cs/0003045v1", 
    "author": "Konstantinos Sagonas", 
    "publish": "2000-03-09T16:27:22Z", 
    "summary": "Tabled logic programming is receiving increasing attention in the Logic\nProgramming community. It avoids many of the shortcomings of SLD execution and\nprovides a more flexible and often extremely efficient execution mechanism for\nlogic programs. In particular, tabled execution of logic programs terminates\nmore often than execution based on SLD-resolution. In this article, we\nintroduce two notions of universal termination of logic programming with\nTabling: quasi-termination and (the stronger notion of) LG-termination. We\npresent sufficient conditions for these two notions of termination, namely\nquasi-acceptability and LG-acceptability, and we show that these conditions are\nalso necessary in case the tabling is well-chosen. Starting from these\nconditions, we give modular termination proofs, i.e., proofs capable of\ncombining termination proofs of separate programs to obtain termination proofs\nof combined programs. Finally, in the presence of mode information, we state\nsufficient conditions which form the basis for automatically proving\ntermination in a constraint-based way."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0003069v1", 
    "title": "Proving Failure of Queries for Definite Logic Programs Using XSB-Prolog", 
    "arxiv-id": "cs/0003069v1", 
    "author": "Maurice Bruynooghe", 
    "publish": "2000-03-20T09:45:00Z", 
    "summary": "Proving failure of queries for definite logic programs can be done by\nconstructing a finite model of the program in which the query is false. A\ngeneral purpose model generator for first order logic can be used for this. A\nrecent paper presented at PLILP98 shows how the peculiarities of definite\nprograms can be exploited to obtain a better solution. There a procedure is\ndescribed which combines abduction with tabulation and uses a meta-interpreter\nfor heuristic control of the search. The current paper shows how similar\nresults can be obtained by direct execution under the standard tabulation of\nthe XSB-Prolog system. The loss of control is compensated for by better\nintelligent backtracking and more accurate failure analysis."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0003071v1", 
    "title": "Axiomatic Synthesis of Computer Programs and Computability Theorems", 
    "arxiv-id": "cs/0003071v1", 
    "author": "Charlie Volkstorf", 
    "publish": "2000-03-22T00:01:09Z", 
    "summary": "We introduce a set of eight universal Rules of Inference by which computer\nprograms with known properties (axioms) are transformed into new programs with\nknown properties (theorems). Axioms are presented to formalize a segment of\nNumber Theory, DataBase retrieval and Computability Theory. The resulting\nProgram Calculus is used to generate programs to (1) Determine if one number is\na factor of another. (2) List all employees who earn more than their manager.\n(3) List the set of programs that halt no on themselves, thus proving that it\nis recursively enumerable. The well-known fact that the set of programs that do\nnot halt yes on themselves is not recursively enumerable is formalized as a\nprogram requirement that has no solution, an Incompleteness Axiom. Thus, any\naxioms (programs) which could be used to generate this program are themselves\nunattainable. Such proofs are presented to formally generate several additional\ntheorems, including (4) The halting problem is unsolvable.\n  Open problems and future research is discussed, including the use of\ntemporary sort files, programs that calculate statistics (such as counts and\nsums), the synthesis of programs to solve other well-known problems from Number\nTheory, Logic, DataBase retrieval and Computability Theory, application to\nProgramming Language Semantics, and the formalization of incompleteness results\nfrom Logic and the semantic paradoxes."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0006010v1", 
    "title": "Light Affine Logic (Proof Nets, Programming Notation, P-Time Correctness   and Completeness)", 
    "arxiv-id": "cs/0006010v1", 
    "author": "Luca Roversi", 
    "publish": "2000-06-05T12:06:50Z", 
    "summary": "This paper is a structured introduction to Light Affine Logic, and to its\nintuitionistic fragment. Light Affine Logic has a polynomially costing cut\nelimination (P-Time correctness), and encodes all P-Time Turing machines\n(P-Time completeness). P-Time correctness is proved by introducing the Proof\nnets for Intuitionistic Light Affine Logic. P-Time completeness is demonstrated\nin full details thanks to a very compact program notation. On one side, the\nproof of P-Time correctness describes how the complexity of cut elimination is\ncontrolled, thanks to a suitable cut elimination strategy that exploits\nstructural properties of the Proof nets. This allows to have a good catch on\nthe meaning of the ``paragraph'' modality, which is a peculiarity of light\nlogics. On the other side, the proof of P-Time completeness, together with a\nlot of programming examples, gives a flavor of the non trivial task of\nprogramming with resource limitations, using Intuitionistic Light Affine Logic\nderivations as programs."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0007030v2", 
    "title": "A theory of normed simulations", 
    "arxiv-id": "cs/0007030v2", 
    "author": "F. W. Vaandrager", 
    "publish": "2000-07-19T14:38:48Z", 
    "summary": "In existing simulation proof techniques, a single step in a lower-level\nspecification may be simulated by an extended execution fragment in a\nhigher-level one. As a result, it is cumbersome to mechanize these techniques\nusing general purpose theorem provers. Moreover, it is undecidable whether a\ngiven relation is a simulation, even if tautology checking is decidable for the\nunderlying specification logic. This paper introduces various types of normed\nsimulations. In a normed simulation, each step in a lower-level specification\ncan be simulated by at most one step in the higher-level one, for any related\npair of states. In earlier work we demonstrated that normed simulations are\nquite useful as a vehicle for the formalization of refinement proofs via\ntheorem provers. Here we show that normed simulations also have pleasant\ntheoretical properties: (1) under some reasonable assumptions, it is decidable\nwhether a given relation is a normed forward simulation, provided tautology\nchecking is decidable for the underlying logic; (2) at the semantic level,\nnormed forward and backward simulations together form a complete proof method\nfor establishing behavior inclusion, provided that the higher-level\nspecification has finite invisible nondeterminism."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0007037v1", 
    "title": "Knowledge Theoretic Properties of Topological Spaces", 
    "arxiv-id": "cs/0007037v1", 
    "author": "Konstantinos Georgatos", 
    "publish": "2000-07-26T18:36:37Z", 
    "summary": "We study the topological models of a logic of knowledge for topological\nreasoning, introduced by Larry Moss and Rohit Parikh. Among our results is a\nsolution of a conjecture by the formentioned authors, finite satisfiability\nproperty and decidability for the theory of topological models."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0008001v1", 
    "title": "Boolean Satisfiability with Transitivity Constraints", 
    "arxiv-id": "cs/0008001v1", 
    "author": "Miroslav N. Velev", 
    "publish": "2000-08-01T13:51:56Z", 
    "summary": "We consider a variant of the Boolean satisfiability problem where a subset E\nof the propositional variables appearing in formula Fsat encode a symmetric,\ntransitive, binary relation over N elements. Each of these relational\nvariables, e[i,j], for 1 <= i < j <= N, expresses whether or not the relation\nholds between elements i and j. The task is to either find a satisfying\nassignment to Fsat that also satisfies all transitivity constraints over the\nrelational variables (e.g., e[1,2] & e[2,3] ==> e[1,3]), or to prove that no\nsuch assignment exists. Solving this satisfiability problem is the final and\nmost difficult step in our decision procedure for a logic of equality with\nuninterpreted functions. This procedure forms the core of our tool for\nverifying pipelined microprocessors.\n  To use a conventional Boolean satisfiability checker, we augment the set of\nclauses expressing Fsat with clauses expressing the transitivity constraints.\nWe consider methods to reduce the number of such clauses based on the sparse\nstructure of the relational variables.\n  To use Ordered Binary Decision Diagrams (OBDDs), we show that for some sets\nE, the OBDD representation of the transitivity constraints has exponential size\nfor all possible variable orderings. By considering only those relational\nvariables that occur in the OBDD representation of Fsat, our experiments show\nthat we can readily construct an OBDD representation of the relevant\ntransitivity constraints and thus solve the constrained satisfiability problem."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0010029v2", 
    "title": "Using Modes to Ensure Subject Reduction for Typed Logic Programs with   Subtyping", 
    "arxiv-id": "cs/0010029v2", 
    "author": "Pierre Deransart", 
    "publish": "2000-10-20T08:04:15Z", 
    "summary": "We consider a general prescriptive type system with parametric polymorphism\nand subtyping for logic programs. The property of subject reduction expresses\nthe consistency of the type system w.r.t. the execution model: if a program is\n\"well-typed\", then all derivations starting in a \"well-typed\" goal are again\n\"well-typed\". It is well-established that without subtyping, this property is\nreadily obtained for logic programs w.r.t. their standard (untyped) execution\nmodel. Here we give syntactic conditions that ensure subject reduction also in\nthe presence of general subtyping relations between type constructors. The idea\nis to consider logic programs with a fixed dataflow, given by modes."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0011013v1", 
    "title": "Transformation-Based Bottom-Up Computation of the Well-Founded Model", 
    "arxiv-id": "cs/0011013v1", 
    "author": "Ulrich Zukowski", 
    "publish": "2000-11-08T14:32:48Z", 
    "summary": "We present a framework for expressing bottom-up algorithms to compute the\nwell-founded model of non-disjunctive logic programs. Our method is based on\nthe notion of conditional facts and elementary program transformations studied\nby Brass and Dix for disjunctive programs. However, even if we restrict their\nframework to nondisjunctive programs, their residual program can grow to\nexponential size, whereas for function-free programs our program remainder is\nalways polynomial in the size of the extensional database (EDB).\n  We show that particular orderings of our transformations (we call them\nstrategies) correspond to well-known computational methods like the alternating\nfixpoint approach, the well-founded magic sets method and the magic alternating\nfixpoint procedure. However, due to the confluence of our calculi, we come up\nwith computations of the well-founded model that are provably better than these\nmethods.\n  In contrast to other approaches, our transformation method treats magic set\ntransformed programs correctly, i.e. it always computes a relevant part of the\nwell-founded model of the original program."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0011037v2", 
    "title": "A syntactical analysis of non-size-increasing polynomial time   computation", 
    "arxiv-id": "cs/0011037v2", 
    "author": "Helmut Schwichtenberg", 
    "publish": "2000-11-23T10:09:06Z", 
    "summary": "A syntactical proof is given that all functions definable in a certain affine\nlinear typed lambda-calculus with iteration in all types are polynomial time\ncomputable. The proof provides explicit polynomial bounds that can easily be\ncalculated."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0011039v1", 
    "title": "A Complete Characterization of Complete Intersection-Type Theories", 
    "arxiv-id": "cs/0011039v1", 
    "author": "F. Alessi", 
    "publish": "2000-11-23T17:40:24Z", 
    "summary": "We characterize those intersection-type theories which yield complete\nintersection-type assignment systems for lambda-calculi, with respect to the\nthree canonical set-theoretical semantics for intersection-types: the inference\nsemantics, the simple semantics and the F-semantics. These semantics arise by\ntaking as interpretation of types subsets of applicative structures, as\ninterpretation of the intersection constructor set-theoretic inclusion, and by\ntaking the interpretation of the arrow constructor a' la Scott, with respect to\neither any possible functionality set, or the largest one, or the least one.\n  These results strengthen and generalize significantly all earlier results in\nthe literature, to our knowledge, in at least three respects. First of all the\ninference semantics had not been considered before. Secondly, the\ncharacterizations are all given just in terms of simple closure conditions on\nthe preorder relation on the types, rather than on the typing judgments\nthemselves. The task of checking the condition is made therefore considerably\nmore tractable. Lastly, we do not restrict attention just to lambda-models, but\nto arbitrary applicative structures which admit an interpretation function.\nThus we allow also for the treatment of models of restricted lambda-calculi.\nNevertheless the characterizations we give can be tailored just to the case of\nlambda-models."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0012015v2", 
    "title": "Well-Typed Logic Programs Are not Wrong", 
    "arxiv-id": "cs/0012015v2", 
    "author": "Jan-Georg Smaus", 
    "publish": "2000-12-20T15:45:32Z", 
    "summary": "We consider prescriptive type systems for logic programs (as in Goedel or\nMercury). In such systems, the typing is static, but it guarantees an\noperational property: if a program is \"well-typed\", then all derivations\nstarting in a \"well-typed\" query are again \"well-typed\". This property has been\ncalled subject reduction. We show that this property can also be phrased as a\nproperty of the proof-theoretic semantics of logic programs, thus abstracting\nfrom the usual operational (top-down) semantics. This proof-theoretic view\nleads us to questioning a condition which is usually considered necessary for\nsubject reduction, namely the head condition. It states that the head of each\nclause must have a type which is a variant (and not a proper instance) of the\ndeclared type. We provide a more general condition, thus reestablishing a\ncertain symmetry between heads and body atoms. The condition ensures that in a\nderivation, the types of two unified terms are themselves unifiable. We discuss\npossible implications of this result. We also discuss the relationship between\nthe head condition and polymorphic recursion, a concept known in functional\nprogramming."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0012018v1", 
    "title": "Resource-distribution via Boolean constraints", 
    "arxiv-id": "cs/0012018v1", 
    "author": "David Pym", 
    "publish": "2000-12-21T00:24:42Z", 
    "summary": "We consider the problem of searching for proofs in sequential presentations\nof logics with multiplicative (or intensional) connectives. Specifically, we\nstart with the multiplicative fragment of linear logic and extend, on the one\nhand, to linear logic with its additives and, on the other, to the additives of\nthe logic of bunched implications, BI. We give an algebraic method for\ncalculating the distribution of the side-formulae in multiplicative rules which\nallows the occurrence or non-occurrence of a formula on a branch of a proof to\nbe determined once sufficient information is available. Each formula in the\nconclusion of such a rule is assigned a Boolean expression. As a search\nproceeds, a set of Boolean constraint equations is generated. We show that a\nsolution to such a set of equations determines a proof corresponding to the\ngiven search. We explain a range of strategies, from the lazy to the eager, for\nsolving sets of constraint equations. We indicate how to apply our methods\nsystematically to large family of relevant systems."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0101013v1", 
    "title": "A Classification of Symbolic Transition Systems", 
    "arxiv-id": "cs/0101013v1", 
    "author": "Jean-Francois Raskin", 
    "publish": "2001-01-16T20:17:30Z", 
    "summary": "We define five increasingly comprehensive classes of infinite-state systems,\ncalled STS1--5, whose state spaces have finitary structure. For four of these\nclasses, we provide examples from hybrid systems."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0101017v1", 
    "title": "Checking Properties within Fairness and Behavior Abstractions", 
    "arxiv-id": "cs/0101017v1", 
    "author": "Pierre Wolper", 
    "publish": "2001-01-19T09:35:10Z", 
    "summary": "This paper is motivated by the fact that verifying liveness properties under\na fairness condition is often problematic, especially when abstraction is used.\nIt shows that using a more abstract notion than truth under fairness,\nspecifically the concept of a property being satisfied within fairness can lead\nto interesting possibilities. Technically, it is first established that\ndeciding satisfaction within fairness is a PSPACE-complete problem and it is\nshown that properties satisfied within fairness can always be satisfied by some\nfair implementation. Thereafter, the interaction between behavior abstraction\nand satisfaction within fairness is studied and it is proved that satisfaction\nof properties within fairness can be verified on behavior abstractions, if the\nabstraction homomorphism is weakly continuation-closed."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0104021v2", 
    "title": "Disjunction and modular goal-directed proof search", 
    "arxiv-id": "cs/0104021v2", 
    "author": "Matthew Stone", 
    "publish": "2001-04-30T14:23:50Z", 
    "summary": "This paper explores goal-directed proof search in first-order multi-modal\nlogic. The key issue is to design a proof system that respects the modularity\nand locality of assumptions of many modal logics. By forcing ambiguities to be\nconsidered independently, modular disjunctions in particular can be used to\nconstruct efficiently executable specifications in reasoning tasks involving\npartial information that otherwise might require prohibitive search. To achieve\nthis behavior requires prior proof-theoretic justifications of logic\nprogramming to be extended, strengthened, and combined with proof-theoretic\nanalyses of modal deduction in a novel way."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0105007v1", 
    "title": "Analysis of Polymorphically Typed Logic Programs Using ACI-Unification", 
    "arxiv-id": "cs/0105007v1", 
    "author": "Jan-Georg Smaus", 
    "publish": "2001-05-04T10:33:39Z", 
    "summary": "Analysis of (partial) groundness is an important application of abstract\ninterpretation. There are several proposals for improving the precision of such\nan analysis by exploiting type information, icluding our own work with Hill and\nKing, where we had shown how the information present in the type declarations\nof a program can be used to characterise the degree of instantiation of a term\nin a precise and yet inherently finite way. This approach worked for\npolymorphically typed programs as in Goedel or HAL. Here, we recast this\napproach following works by Codish, Lagoon and Stuckey. To formalise which\nproperties of terms we want to characterise, we use labelling functions, which\nare functions that extract subterms from a term along certain paths. An\nabstract term collects the results of all labelling functions of a term. For\nthe analysis, programs are executed on abstract terms instead of the concrete\nones, and usual unification is replaced by unification modulo an equality\ntheory which includes the well-known ACI-theory. Thus we generalise the works\nby Codish, Lagoon and Stuckey w.r.t. the type systems considered and relate the\nworks among each other."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0108007v1", 
    "title": "Abstract versus Concrete Computation on Metric Partial Algebras", 
    "arxiv-id": "cs/0108007v1", 
    "author": "J. I. Zucker", 
    "publish": "2001-08-12T21:25:13Z", 
    "summary": "A model of computation is abstract if, when applied to any algebra, the\nresulting programs for computable functions and sets on that algebra are\ninvariant under isomorphisms, and hence do not depend on a representation for\nthe algebra. Otherwise it is concrete. Intuitively, concrete models depend on\nthe implementation of the algebra.\n  The difference is particularly striking in the case of topological partial\nalgebras, and notably in algebras over the reals. We investigate the\nrelationship between abstract and concrete models of partial metric algebras.\nIn the course of this investigation, interesting aspects of continuity,\nextensionality and non-determinism are uncovered."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0109001v1", 
    "title": "Abstract Computability, Algebraic Specification and Initiality", 
    "arxiv-id": "cs/0109001v1", 
    "author": "J. I. Zucker", 
    "publish": "2001-09-02T18:52:51Z", 
    "summary": "computable functions are defined by abstract finite deterministic algorithms\non many-sorted algebras. We show that there exist finite universal algebraic\nspecifications that specify uniquely (up to isomorphism) (i) all abstract\ncomputable functions on any many-sorted algebra; and (ii) all functions\neffectively approximable by abstract computable functions on any metric\nalgebra.\n  We show that there exist universal algebraic specifications for all the\nclassically computable functions on the set R of real numbers. The algebraic\nspecifications used are mainly bounded universal equations and conditional\nequations. We investigate the initial algebra semantics of these\nspecifications, and derive situations where algebraic specifications define\nprecisely the computable functions."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0110010v1", 
    "title": "Pushdown Timed Automata: a Binary Reachability Characterization and   Safety Verification", 
    "arxiv-id": "cs/0110010v1", 
    "author": "Zhe Dang", 
    "publish": "2001-10-02T22:47:41Z", 
    "summary": "We consider pushdown timed automata (PTAs) that are timed automata (with\ndense clocks) augmented with a pushdown stack. A configuration of a PTA\nincludes a control state, dense clock values and a stack word. By using the\npattern technique, we give a decidable characterization of the binary\nreachability (i.e., the set of all pairs of configurations such that one can\nreach the other) of a PTA. Since a timed automaton can be treated as a PTA\nwithout the pushdown stack, we can show that the binary reachability of a timed\nautomaton is definable in the additive theory of reals and integers. The\nresults can be used to verify a class of properties containing linear relations\nover both dense variables and unbounded discrete variables. The properties\npreviously could not be verified using the classic region technique nor\nexpressed by timed temporal logics for timed automata and CTL$^*$ for pushdown\nsystems. The results are also extended to other generalizations of timed\nautomata."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0110028v1", 
    "title": "On Equivalence and Canonical Forms in the LF Type Theory", 
    "arxiv-id": "cs/0110028v1", 
    "author": "Frank Pfenning", 
    "publish": "2001-10-11T16:36:18Z", 
    "summary": "Decidability of definitional equality and conversion of terms into canonical\nform play a central role in the meta-theory of a type-theoretic logical\nframework. Most studies of definitional equality are based on a confluent,\nstrongly-normalizing notion of reduction. Coquand has considered a different\napproach, directly proving the correctness of a practical equivalance algorithm\nbased on the shape of terms. Neither approach appears to scale well to richer\nlanguages with unit types or subtyping, and neither directly addresses the\nproblem of conversion to canonical.\n  In this paper we present a new, type-directed equivalence algorithm for the\nLF type theory that overcomes the weaknesses of previous approaches. The\nalgorithm is practical, scales to richer languages, and yields a new notion of\ncanonical form sufficient for adequate encodings of logical systems. The\nalgorithm is proved complete by a Kripke-style logical relations argument\nsimilar to that suggested by Coquand. Crucially, both the algorithm itself and\nthe logical relations rely only on the shapes of types, ignoring dependencies\non terms."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0110060v1", 
    "title": "Selected Topics in Asynchronous Automata", 
    "arxiv-id": "cs/0110060v1", 
    "author": "Serban E. Vlad", 
    "publish": "2001-10-31T10:35:32Z", 
    "summary": "The paper is concerned with defining the electrical signals and their models.\nThe delays are discussed, the asynchronous automata - which are the models of\nthe asynchronous circuits - and the examples of the clock generator and of the\nR-S latch are given. We write the equations of the asynchronous automata, which\ncombine the pure delay model and the inertial delay model; the simple gate\nmodel and the complex gate model; the fixed, bounded and unbounded delay model.\nWe give the solutions of these equations, which are written on R->{0,1}\nfunctions, where R is the time set. The connection between the real time and\nthe discrete time is discussed. The stability, the fundamental mode of\noperation, the combinational automata, the semi-modularity are defined and\ncharacterized. Some connections are suggested with the linear time and the\nbranching time temporal logic of the propositions."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0110061v1", 
    "title": "An Asynchronous Automata Approach to the Semantics of Temporal Logic", 
    "arxiv-id": "cs/0110061v1", 
    "author": "Serban E. Vlad", 
    "publish": "2001-10-31T10:44:55Z", 
    "summary": "The paper presents the differential equations that characterize an\nasynchronous automaton and gives their solution x:R->{0,1}x...x{0,1}. Remarks\nare made on the connection between the continuous time and the discrete time of\nthe approach. The continuous and the discrete time, the linear and the\nbranching temporal logics have the semantics depending on x and their formulas\ngive the properties of the automaton."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0110062v1", 
    "title": "The Delay-Insensitivity, the Hazard-Freedom, the Semi-Modularity and the   Technical Condition of Good Running of the Discrete Time Asynchronous   Automata", 
    "arxiv-id": "cs/0110062v1", 
    "author": "Serban E. Vlad", 
    "publish": "2001-10-31T10:53:34Z", 
    "summary": "The paper studies some important properties of the asynchronous (=timed)\nautomata: the delay-insensitivity, the hazard-freedom, the semi-modularity and\nthe technical condition of good running. Time is discrete."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0110063v2", 
    "title": "The Existence of $\u03c9$-Chains for Transitive Mixed Linear Relations   and Its Applications", 
    "arxiv-id": "cs/0110063v2", 
    "author": "Oscar Ibarra", 
    "publish": "2001-10-31T10:56:32Z", 
    "summary": "We show that it is decidable whether a transitive mixed linear relation has\nan $\\omega$-chain. Using this result, we study a number of liveness\nverification problems for generalized timed automata within a unified\nframework. More precisely, we prove that (1) the mixed linear liveness problem\nfor a timed automaton with dense clocks, reversal-bounded counters, and a free\ncounter is decidable, and (2) the Presburger liveness problem for a timed\nautomaton with discrete clocks, reversal-bounded counters, and a pushdown stack\nis decidable."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0110064v1", 
    "title": "Applications of the Differential Calculus in the Study of the Timed   Automata: the Inertial Delay Buffer", 
    "arxiv-id": "cs/0110064v1", 
    "author": "Serban E. Vlad", 
    "publish": "2001-10-31T10:59:16Z", 
    "summary": "We write the relations that characterize the simpliest timed automaton, the\ninertial delay buffer, in two versions: the non-deterministic and the\ndeterministic one, by making use of the derivatives of the R->{0,1} functions."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0111010v1", 
    "title": "Abduction with Penalization in Logic Programming", 
    "arxiv-id": "cs/0111010v1", 
    "author": "Francesco Scarcello", 
    "publish": "2001-11-06T16:33:29Z", 
    "summary": "Abduction, first proposed in the setting of classical logics, has been\nstudied with growing interest in the logic programming area during the last\nyears.\n  In this paper we study {\\em abduction with penalization} in logic\nprogramming. This form of abductive reasoning, which has not been previously\nanalyzed in logic programming, turns out to represent several relevant\nproblems, including optimization problems, very naturally. We define a formal\nmodel for abduction with penalization from logic programs, which extends the\nabductive framework proposed by Kakas and Mancarella. We show the high\nexpressiveness of this formalism, by encoding a couple of relevant problems,\nincluding the well-know Traveling Salesman Problem from optimization theory, in\nthis abductive framework. The resulting encodings are very simple and elegant.\nWe analyze the complexity of the main decisional problems arising in this\nframework. An interesting result in this course is that ``negation comes for\nfree.'' Indeed, the addition of (even unstratified) negation does not cause any\nfurther increase to the complexity of the abductive reasoning tasks (which\nremains the same as for not-free programs)."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0111011v1", 
    "title": "Sintesi di algoritmi con SKY", 
    "arxiv-id": "cs/0111011v1", 
    "author": "Giovambattista Ianni", 
    "publish": "2001-11-06T17:02:25Z", 
    "summary": "This paper describes the semantics and ideas about SKY, a logic programming\nlanguage intended in order to specify algorithmic strategies for the evaluation\nof problems."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0111059v1", 
    "title": "Hypotheses Founded Semantics of Logic Programs for Information   Integration in Multi-Valued Logics", 
    "arxiv-id": "cs/0111059v1", 
    "author": "Daniel Stamate", 
    "publish": "2001-11-27T17:43:20Z", 
    "summary": "We address the problem of integrating information coming from different\nsources. The information consists of facts that a central server collects and\ntries to combine using (a) a set of logical rules, i.e. a logic program, and\n(b) a hypothesis representing the server's own estimates. In such a setting\nincomplete information from a source or contradictory information from\ndifferent sources necessitate the use of many-valued logics in which programs\ncan be evaluated and hypotheses can be tested. To carry out such activities we\npropose a formal framework based on bilattices such as Belnap's four-valued\nlogics. In this framework we work with the class of programs defined by Fitting\nand we develop a theory for information integration.\n  We also establish an intuitively appealing connection between our hypothesis\ntesting mechanism on the one hand, and the well-founded semantics and\nKripke-Kleene semantics of Datalog programs with negation, on the other hand."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0204039v1", 
    "title": "Precongruence Formats for Decorated Trace Semantics", 
    "arxiv-id": "cs/0204039v1", 
    "author": "R. J. van Glabbeek", 
    "publish": "2002-04-17T00:35:04Z", 
    "summary": "This paper explores the connection between semantic equivalences and\npreorders for concrete sequential processes, represented by means of labelled\ntransition systems, and formats of transition system specifications using\nPlotkin's structural approach. For several preorders in the linear time -\nbranching time spectrum a format is given, as general as possible, such that\nthis preorder is a precongruence for all operators specifiable in that format.\nThe formats are derived using the modal characterizations of the corresponding\npreorders."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0204045v1", 
    "title": "Some applications of logic to feasibility in higher types", 
    "arxiv-id": "cs/0204045v1", 
    "author": "Arun Sharma", 
    "publish": "2002-04-22T06:58:56Z", 
    "summary": "In this paper we demonstrate that the class of basic feasible functionals has\nrecursion theoretic properties which naturally generalize the corresponding\nproperties of the class of feasible functions. We also improve the Kapron -\nCook result on mashine representation of basic feasible functionals. Our proofs\nare based on essential applications of logic. We introduce a weak fragment of\nsecond order arithmetic with second order variables ranging over functions from\nN into N which suitably characterizes basic feasible functionals, and show that\nit is a useful tool for investigating the properties of basic feasible\nfunctionals. In particular, we provide an example how one can extract feasible\n\"programs\" from mathematical proofs which use non-feasible functionals (like\nsecond order polynomials)."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0205003v1", 
    "title": "The prospects for mathematical logic in the twenty-first century", 
    "arxiv-id": "cs/0205003v1", 
    "author": "Richard A. Shore", 
    "publish": "2002-05-03T22:36:23Z", 
    "summary": "The four authors present their speculations about the future developments of\nmathematical logic in the twenty-first century. The areas of recursion theory,\nproof theory and logic for computer science, model theory, and set theory are\ndiscussed independently."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0206005v1", 
    "title": "Characterization of Strongly Equivalent Logic Programs in Intermediate   Logics", 
    "arxiv-id": "cs/0206005v1", 
    "author": "Lex Hendriks", 
    "publish": "2002-06-03T14:48:41Z", 
    "summary": "The non-classical, nonmonotonic inference relation associated with the answer\nset semantics for logic programs gives rise to a relationship of 'strong\nequivalence' between logical programs that can be verified in 3-valued Goedel\nlogic, G3, the strongest non-classical intermediate propositional logic\n(Lifschitz, Pearce and Valverde, 2001). In this paper we will show that KC (the\nlogic obtained by adding axiom ~A v ~~A to intuitionistic logic), is the\nweakest intermediate logic for which strongly equivalent logic programs, in a\nlanguage allowing negations, are logically equivalent."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0207068v1", 
    "title": "Knuth-Bendix constraint solving is NP-complete", 
    "arxiv-id": "cs/0207068v1", 
    "author": "Andrei Voronkov", 
    "publish": "2002-07-17T18:34:45Z", 
    "summary": "We show the NP-completeness of the existential theory of term algebras with\nthe Knuth-Bendix order by giving a nondeterministic polynomial-time algorithm\nfor solving Knuth-Bendix ordering constraints."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0207074v1", 
    "title": "Paraconsistency of Interactive Computation", 
    "arxiv-id": "cs/0207074v1", 
    "author": "Peter Wegner", 
    "publish": "2002-07-21T06:19:23Z", 
    "summary": "The goal of computational logic is to allow us to model computation as well\nas to reason about it. We argue that a computational logic must be able to\nmodel interactive computation. We show that first-order logic cannot model\ninteractive computation due to the incompleteness of interaction. We show that\ninteractive computation is necessarily paraconsistent, able to model both a\nfact and its negation, due to the role of the world (environment) in\ndetermining the course of the computation. We conclude that paraconsistency is\na necessary property for a logic that can model interactive computation."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0207086v1", 
    "title": "A Model-Theoretic Semantics for Defeasible Logic", 
    "arxiv-id": "cs/0207086v1", 
    "author": "Michael J. Maher", 
    "publish": "2002-07-25T15:39:01Z", 
    "summary": "Defeasible logic is an efficient logic for defeasible reasoning. It is\ndefined through a proof theory and, until now, has had no model theory. In this\npaper a model-theoretic semantics is given for defeasible logic. The logic is\nsound and complete with respect to the semantics. We also briefly outline how\nthis approach extends to a wide range of defeasible logics."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0207087v1", 
    "title": "Axiomatic Aspects of Default Inference", 
    "arxiv-id": "cs/0207087v1", 
    "author": "Guo-Qiang Zhang", 
    "publish": "2002-07-25T16:19:51Z", 
    "summary": "This paper studies axioms for nonmonotonic consequences from a\nsemantics-based point of view, focusing on a class of mathematical structures\nfor reasoning about partial information without a predefined syntax/logic. This\nstructure is called a default structure. We study axioms for the nonmonotonic\nconsequence relation derived from extensions as in Reiter's default logic,\nusing skeptical reasoning, but extensions are now used for the construction of\npossible worlds in a default information structure.\n  In previous work we showed that skeptical reasoning arising from\ndefault-extensions obeys a well-behaved set of axioms including the axiom of\ncautious cut. We show here that, remarkably, the converse is also true: any\nconsequence relation obeying this set of axioms can be represented as one\nconstructed from skeptical reasoning. We provide representation theorems to\nrelate axioms for nonmonotonic consequence relation and properties about\nextensions, and provide one-to-one correspondence between nonmonotonic systems\nwhich satisfies the law of cautious monotony and default structures with unique\nextensions. Our results give a theoretical justification for a set of basic\nrules governing the update of nonmonotonic knowledge bases, demonstrating the\nderivation of them from the more concrete and primitive construction of\nextensions. It is also striking to note that proofs of the representation\ntheorems show that only shallow extensions are necessary, in the sense that the\nnumber of iterations needed to achieve an extension is at most three. All of\nthese developments are made possible by taking a more liberal view of\nconsistency: consistency is a user defined predicate, satisfying some basic\nproperties."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0207090v1", 
    "title": "On a Partial Decision Method for Dynamic Proofs", 
    "arxiv-id": "cs/0207090v1", 
    "author": "Diderik Batens", 
    "publish": "2002-07-25T17:14:16Z", 
    "summary": "This paper concerns a goal directed proof procedure for the propositional\nfragment of the adaptive logic ACLuN1. At the propositional level, it forms an\nalgorithm for final derivability. If extended to the predicative level, it\nprovides a criterion for final derivability. This is essential in view of the\nabsence of a positive test. The procedure may be generalized to all flat\nadaptive logics."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0207091v1", 
    "title": "An Almost Classical Logic for Logic Programming and Nonmonotonic   Reasoning", 
    "arxiv-id": "cs/0207091v1", 
    "author": "Fran\u00e7ois Bry", 
    "publish": "2002-07-25T17:40:14Z", 
    "summary": "The model theory of a first-order logic called N^4 is introduced. N^4 does\nnot eliminate double negations, as classical logic does, but instead reduces\nfourfold negations. N^4 is very close to classical logic: N^4 has two truth\nvalues; implications in N^4 are material, like in classical logic; and negation\ndistributes over compound formulas in N^4 as it does in classical logic.\nResults suggest that the semantics of normal logic programs is conveniently\nformalized in N^4: Classical logic Herbrand interpretations generalize\nstraightforwardly to N^4; the classical minimal Herbrand model of a positive\nlogic program coincides with its unique minimal N^4 Herbrand model; the stable\nmodels of a normal logic program and its so-called complete minimal N^4\nHerbrand models coincide."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0208032v2", 
    "title": "First-order Logic as a Constraint Programming Language", 
    "arxiv-id": "cs/0208032v2", 
    "author": "C. F. M. Vermeulen", 
    "publish": "2002-08-20T14:53:37Z", 
    "summary": "We provide a denotational semantics for first-order logic that captures the\ntwo-level view of the computation process typical for constraint programming.\nAt one level we have the usual program execution. At the other level an\nautomatic maintenance of the constraint store takes place. We prove that the\nresulting semantics is sound with respect to the truth definition. By\ninstantiating it by specific forms of constraint management policies we obtain\nseveral sound evaluation policies of first-order formulas. This semantics can\nalso be used a basis for sound implementation of constraint maintenance in\npresence of block declarations and conditionals."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0210022v3", 
    "title": "An Elementary Fragment of Second-Order Lambda Calculus", 
    "arxiv-id": "cs/0210022v3", 
    "author": "Jan Johannsen", 
    "publish": "2002-10-25T10:31:39Z", 
    "summary": "A fragment of second-order lambda calculus (System F) is defined that\ncharacterizes the elementary recursive functions. Type quantification is\nrestricted to be non-interleaved and stratified, i.e., the types are assigned\nlevels, and a quantified variable can only be instantiated by a type of smaller\nlevel, with a slightly liberalized treatment of the level zero."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0211011v1", 
    "title": "Intersection Types and Lambda Theories", 
    "arxiv-id": "cs/0211011v1", 
    "author": "S. Lusin", 
    "publish": "2002-11-12T21:33:33Z", 
    "summary": "We illustrate the use of intersection types as a semantic tool for showing\nproperties of the lattice of lambda theories. Relying on the notion of easy\nintersection type theory we successfully build a filter model in which the\ninterpretation of an arbitrary simple easy term is any filter which can be\ndescribed in an uniform way by a predicate. This allows us to prove the\nconsistency of a well-know lambda theory: this consistency has interesting\nconsequences on the algebraic structure of the lattice of lambda theories."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0211021v1", 
    "title": "Sequent and Hypersequent Calculi for Abelian and Lukasiewicz Logics", 
    "arxiv-id": "cs/0211021v1", 
    "author": "D. Gabbay", 
    "publish": "2002-11-18T12:08:17Z", 
    "summary": "We present two embeddings of infinite-valued Lukasiewicz logic L into Meyer\nand Slaney's abelian logic A, the logic of lattice-ordered abelian groups. We\ngive new analytic proof systems for A and use the embeddings to derive\ncorresponding systems for L. These include: hypersequent calculi for A and L\nand terminating versions of these calculi; labelled single sequent calculi for\nA and L of complexity co-NP; unlabelled single sequent calculi for A and L."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0211022v1", 
    "title": "Arithmetic, First-Order Logic, and Counting Quantifiers", 
    "arxiv-id": "cs/0211022v1", 
    "author": "Nicole Schweikardt", 
    "publish": "2002-11-19T19:15:51Z", 
    "summary": "This paper gives a thorough overview of what is known about first-order logic\nwith counting quantifiers and with arithmetic predicates. As a main theorem we\nshow that Presburger arithmetic is closed under unary counting quantifiers.\nPrecisely, this means that for every first-order formula phi(y,z_1,...,z_k)\nover the signature {<,+} there is a first-order formula psi(x,z_1,...,z_k)\nwhich expresses over the structure <Nat,<,+> (respectively, over initial\nsegments of this structure) that the variable x is interpreted exactly by the\nnumber of possible interpretations of the variable y for which the formula\nphi(y,z_1,...,z_k) is satisfied. Applying this theorem, we obtain an easy proof\nof Ruhl's result that reachability (and similarly, connectivity) in finite\ngraphs is not expressible in first-order logic with unary counting quantifiers\nand addition. Furthermore, the above result on Presburger arithmetic helps to\nshow the failure of a particular version of the Crane Beach conjecture."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0212005v1", 
    "title": "Retractions of Types with Many Atoms", 
    "arxiv-id": "cs/0212005v1", 
    "author": "Pawel Urzyczyn", 
    "publish": "2002-12-05T17:29:12Z", 
    "summary": "We define a sound and complete proof system for affine beta-eta-retractions\nin simple types built over many atoms, and we state simple necessary conditions\nfor arbitrary beta-eta-retractions in simple and polymorphic types."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0212026v1", 
    "title": "A Generalization of the Lifting Lemma for Logic Programming", 
    "arxiv-id": "cs/0212026v1", 
    "author": "Fred Mesnard", 
    "publish": "2002-12-11T09:48:39Z", 
    "summary": "Since the seminal work of J. A. Robinson on resolution, many lifting lemmas\nfor simplifying proofs of completeness of resolution have been proposed in the\nliterature. In the logic programming framework, they may also help to detect\nsome infinite derivations while proving goals under the SLD-resolution. In this\npaper, we first generalize a version of the lifting lemma, by extending the\nrelation \"is more general than\" so that it takes into account only some\narguments of the atoms. The other arguments, which we call neutral arguments,\nare disregarded. Then we propose two syntactic conditions of increasing power\nfor identifying neutral arguments from mere inspection of the text of a logic\nprogram."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0301026v1", 
    "title": "Double-Negation Elimination in Some Propositional Logics", 
    "arxiv-id": "cs/0301026v1", 
    "author": "Larry Wos", 
    "publish": "2003-01-24T20:25:50Z", 
    "summary": "This article answers two questions (posed in the literature), each concerning\nthe guaranteed existence of proofs free of double negation. A proof is free of\ndouble negation if none of its deduced steps contains a term of the form\nn(n(t)) for some term t, where n denotes negation. The first question asks for\nconditions on the hypotheses that, if satisfied, guarantee the existence of a\ndouble-negation-free proof when the conclusion is free of double negation. The\nsecond question asks about the existence of an axiom system for classical\npropositional calculus whose use, for theorems with a conclusion free of double\nnegation, guarantees the existence of a double-negation-free proof. After\ngiving conditions that answer the first question, we answer the second question\nby focusing on the Lukasiewicz three-axiom system. We then extend our studies\nto infinite-valued sentential calculus and to intuitionistic logic and\ngeneralize the notion of being double-negation free. The double-negation proofs\nof interest rely exclusively on the inference rule condensed detachment, a rule\nthat combines modus ponens with an appropriately general rule of substitution.\nThe automated reasoning program OTTER played an indispensable role in this\nstudy."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0303019v1", 
    "title": "An Effective Decision Procedure for Linear Arithmetic with Integer and   Real Variables", 
    "arxiv-id": "cs/0303019v1", 
    "author": "Pierre Wolper", 
    "publish": "2003-03-20T17:05:24Z", 
    "summary": "This paper considers finite-automata based algorithms for handling linear\narithmetic with both real and integer variables. Previous work has shown that\nthis theory can be dealt with by using finite automata on infinite words, but\nthis involves some difficult and delicate to implement algorithms. The\ncontribution of this paper is to show, using topological arguments, that only a\nrestricted class of automata on infinite words are necessary for handling real\nand integer linear arithmetic. This allows the use of substantially simpler\nalgorithms, which have been successfully implemented."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0304017v1", 
    "title": "Ground Canonicity", 
    "arxiv-id": "cs/0304017v1", 
    "author": "Nachum Dershowitz", 
    "publish": "2003-04-10T20:08:18Z", 
    "summary": "We explore how different proof orderings induce different notions of\nsaturation. We relate completion, paramodulation, saturation, redundancy\nelimination, and rewrite system reduction to proof orderings."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0304021v1", 
    "title": "Model Checking for a Class of Weighted Automata", 
    "arxiv-id": "cs/0304021v1", 
    "author": "Peter Kemper", 
    "publish": "2003-04-15T19:08:00Z", 
    "summary": "A large number of different model checking approaches has been proposed\nduring the last decade. The different approaches are applicable to different\nmodel types including untimed, timed, probabilistic and stochastic models. This\npaper presents a new framework for model checking techniques which includes\nsome of the known approaches, but enlarges the class of models for which model\nchecking can be applied to the general class of weighted automata. The approach\nallows an easy adaption of model checking to models which have not been\nconsidered yet for this purpose. Examples for those new model types for which\nmodel checking can be applied are max/plus or min/plus automata which are well\nestablished models to describe different forms of dynamic systems and\noptimization problems. In this context, model checking can be used to verify\ntemporal or quantitative properties of a system. The paper first presents\nbriefly our class of weighted automata, as a very general model type. Then\nValued Computational Tree Logic (CTL$) is introduced as a natural extension of\nthe well known branching time logic CTL. Afterwards, algorithms to check a\nweighted automaton according to a CTL$ formula are presented. As a last result,\na bisimulation is presented for weighted automata and for CTL$."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0304046v1", 
    "title": "Distributed States Temporal Logic", 
    "arxiv-id": "cs/0304046v1", 
    "author": "Laura Semini", 
    "publish": "2003-04-30T18:54:59Z", 
    "summary": "We introduce a temporal logic to reason on global applications in an\nasynchronous setting. First, we define the Distributed States Logic (DSL), a\nmodal logic for localities that embeds the local theories of each component\ninto a theory of the distributed states of the system. We provide the logic\nwith a sound and complete axiomatization. The contribution is that it is\npossible to reason about properties that involve several components, even in\nthe absence of a global clock. Then, we define the Distributed States Temporal\nLogic (DSTL) by introducing temporal operators a' la Unity. We support our\nproposal by working out a pair of examples: a simple secure communication\nsystem, and an algorithm for distributed leader election.\n  The motivation for this work is that the existing logics for distributed\nsystems do not have the right expressive power to reason on the systems\nbehaviour, when the communication is based on asynchronous message passing. On\nthe other side, asynchronous communication is the most used abstraction when\nmodelling global applications."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0305007v1", 
    "title": "Computing only minimal answers in disjunctive deductive databases", 
    "arxiv-id": "cs/0305007v1", 
    "author": "C. A. Johnson", 
    "publish": "2003-05-13T08:27:45Z", 
    "summary": "A method is presented for computing minimal answers in disjunctive deductive\ndatabases under the disjunctive stable model semantics. Such answers are\nconstructed by repeatedly extending partial answers. Our method is complete (in\nthat every minimal answer can be computed) and does not admit redundancy (in\nthe sense that every partial answer generated can be extended to a minimal\nanswer), whence no non-minimal answer is generated. For stratified databases,\nthe method does not (necessarily) require the computation of models of the\ndatabase in their entirety. Compilation is proposed as a tool by which problems\nrelating to computational efficiency and the non-existence of disjunctive\nstable models can be overcome. The extension of our method to other semantics\nis also considered."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0305011v1", 
    "title": "Optimizing Optimal Reduction: A Type Inference Algorithm for Elementary   Affine Logic", 
    "arxiv-id": "cs/0305011v1", 
    "author": "Simone Martini", 
    "publish": "2003-05-15T10:46:00Z", 
    "summary": "We present a type inference algorithm for lambda-terms in Elementary Affine\nLogic using linear constraints. We prove that the algorithm is correct and\ncomplete."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0305046v1", 
    "title": "Applications of Intuitionistic Logic in Answer Set Programming", 
    "arxiv-id": "cs/0305046v1", 
    "author": "Jose Arrazola", 
    "publish": "2003-05-27T16:40:30Z", 
    "summary": "We present some applications of intermediate logics in the field of Answer\nSet Programming (ASP). A brief, but comprehensive introduction to the answer\nset semantics, intuitionistic and other intermediate logics is given. Some\nequivalence notions and their applications are discussed. Some results on\nintermediate logics are shown, and applied later to prove properties of answer\nsets. A characterization of answer sets for logic programs with nested\nexpressions is provided in terms of intuitionistic provability, generalizing a\nrecent result given by Pearce.\n  It is known that the answer set semantics for logic programs with nested\nexpressions may select non-minimal models. Minimal models can be very important\nin some applications, therefore we studied them; in particular we obtain a\ncharacterization, in terms of intuitionistic logic, of answer sets which are\nalso minimal models. We show that the logic G3 characterizes the notion of\nstrong equivalence between programs under the semantic induced by these models.\nFinally we discuss possible applications and consequences of our results. They\nclearly state interesting links between ASP and intermediate logics, which\nmight bring research in these two areas together."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0306041v1", 
    "title": "Monodic temporal resolution", 
    "arxiv-id": "cs/0306041v1", 
    "author": "Boris Konev", 
    "publish": "2003-06-10T10:02:03Z", 
    "summary": "Until recently, First-Order Temporal Logic (FOTL) has been little understood.\nWhile it is well known that the full logic has no finite axiomatisation, a more\ndetailed analysis of fragments of the logic was not previously available.\nHowever, a breakthrough by Hodkinson et.al., identifying a finitely\naxiomatisable fragment, termed the monodic fragment, has led to improved\nunderstanding of FOTL. Yet, in order to utilise these theoretical advances, it\nis important to have appropriate proof techniques for the monodic fragment.\n  In this paper, we modify and extend the clausal temporal resolution\ntechnique, originally developed for propositional temporal logics, to enable\nits use in such monodic fragments. We develop a specific normal form for\nformulae in FOTL, and provide a complete resolution calculus for formulae in\nthis form. Not only is this clausal resolution technique useful as a practical\nproof technique for certain monodic classes, but the use of this approach\nprovides us with increased understanding of the monodic fragment. In\nparticular, we here show how several features of monodic FOTL are established\nas corollaries of the completeness result for the clausal temporal resolution\nmethod. These include definitions of new decidable monodic classes,\nsimplification of existing monodic classes by reductions, and completeness of\nclausal temporal resolution in the case of monodic logics with expanding\ndomains, a case with much significance in both theory and practice."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0306117v2", 
    "title": "Deciding regular grammar logics with converse through first-order logic", 
    "arxiv-id": "cs/0306117v2", 
    "author": "Hans de Nivelle", 
    "publish": "2003-06-20T08:26:57Z", 
    "summary": "We provide a simple translation of the satisfiability problem for regular\ngrammar logics with converse into GF2, which is the intersection of the guarded\nfragment and the 2-variable fragment of first-order logic. This translation is\ntheoretically interesting because it translates modal logics with certain frame\nconditions into first-order logic, without explicitly expressing the frame\nconditions.\n  A consequence of the translation is that the general satisfiability problem\nfor regular grammar logics with converse is in EXPTIME. This extends a previous\nresult of the first author for grammar logics without converse. Using the same\nmethod, we show how some other modal logics can be naturally translated into\nGF2, including nominal tense logics and intuitionistic logic.\n  In our view, the results in this paper show that the natural first-order\nfragment corresponding to regular grammar logics is simply GF2 without extra\nmachinery such as fixed point-operators."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0306118v1", 
    "title": "On coalgebra based on classes", 
    "arxiv-id": "cs/0306118v1", 
    "author": "J. Velebil", 
    "publish": "2003-06-20T09:43:58Z", 
    "summary": "Every endofunctor of the category of classes is proved to be set-based in the\nsense of Aczel and Mendler, therefore, it has a final coalgebra. Other basic\nproperties of these endofunctors are proved, e.g. the existence of a free\ncompletely iterative theory."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0307067v1", 
    "title": "Sound search in a denotational semantics for first order logic", 
    "arxiv-id": "cs/0307067v1", 
    "author": "C. F. M. Vermeulen", 
    "publish": "2003-07-30T13:57:55Z", 
    "summary": "In this paper we adapt the definitions and results from Apt and Vermeulen on\n`First order logic as a constraint programming language' (in: Proceedings of\nLPAR2001, Baaz and Voronkov (eds.), Springer LNAI 2514) to include important\nideas about search and choice into the system. We give motivating examples.\nThen we set up denotational semantics for first order logic as follows: the\nsemantic universe includes states that consist of two components: a\nsubstitution, which can be seen as the computed answer; and a constraint\nsatisfaction problem, which can be seen as the residue of the original problem,\nyet to be handled by constraint programming. The interaction between these\ncomponents is regulated by an operator called: infer. In this paper we regard\ninfer as an operator on sets of states to enable us to analyze ideas about\nsearch among states and choice between states.\n  The precise adaptations of definitions and results are able to deal with the\nexamples and we show that, given several reasonable conditions, the new\ndefinitions ensure soundness of the system with respect to the standard\ninterpretation of first order logic. In this way the `reasonable conditions'\ncan be read as conditions for sound search.\n  We indicate briefly how to investigate efficiency of search in future\nresearch."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0308029v1", 
    "title": "On Decidability of Expressive Description Logics with Composition of   Roles in Number Restrictions", 
    "arxiv-id": "cs/0308029v1", 
    "author": "Fabio Grandi", 
    "publish": "2003-08-19T12:50:02Z", 
    "summary": "Description Logics are knowledge representation formalisms which have been\nused in a wide range of application domains. Owing to their appealing\nexpressiveness, we consider in this paper extensions of the well-known concept\nlanguage ALC allowing for number restrictions on complex role expressions.\nThese have been first introduced by Baader and Sattler as ALCN(M) languages,\nwith the adoption of role constructors M subset-of {o,-,And,Or}. In particular,\nthey showed in 1999 that, although ALCN(o) is decidable, the addition of other\noperators may easily lead to undecidability: in fact, ALCN(o,And) and\nALCN(o,-,Or) were proved undecidable.\n  In this work, we further investigate the computational properties of the ALCN\nfamily, aiming at narrowing the decidability gap left open by Baader and\nSattler's results. In particular, we will show that ALCN(o) extended with\ninverse roles both in number and in value restrictions becomes undecidable,\nwhereas it can be safely extended with qualified number restrictions without\nlosing decidability."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0309004v1", 
    "title": "The Structure of Information", 
    "arxiv-id": "cs/0309004v1", 
    "author": "Bruce Long", 
    "publish": "2003-09-02T10:10:51Z", 
    "summary": "A formal model of the structure of information is presented in five axioms\nwhich define identity, containment, and joins of infons. Joins are shown to be\ncommutative, associative, provide inverses of infons, and, potentially, have\nmany identity elements, two of which are multiplicative and additive. Those two\ntypes of join are distributive. The other identity elements are for operators\non entwined states. Multiplicative joins correspond to adding or removing new\nbits to a system while additive joins correspond to a change of state. The\norder or size of an infon is defined. This groundwork is intended to be used to\nmodel continuous and discreet information structures through time, especially\nin closed systems."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0309046v1", 
    "title": "The Liar and Related Paradoxes: Fuzzy Truth Value Assignment for   Collections of Self-Referential Sentences", 
    "arxiv-id": "cs/0309046v1", 
    "author": "Ath. Kehagias", 
    "publish": "2003-09-24T11:50:00Z", 
    "summary": "We study self-referential sentences of the type related to the Liar paradox.\nIn particular, we consider the problem of assigning consistent fuzzy truth\nvalues to collections of self-referential sentences. We show that the problem\ncan be reduced to the solution of a system of nonlinear equations. Furthermore,\nwe prove that, under mild conditions, such a system always has a solution (i.e.\na consistent truth value assignment) and that, for a particular implementation\nof logical ``and'', ``or'' and ``negation'', the ``mid-point'' solution is\nalways consistent. Next we turn to computational issues and present several\ntruth-value assignment algorithms; we argue that these algorithms can be\nunderstood as generalized sequential reasoning. In an Appendix we present a\nlarge number of examples of self-referential collections (including the Liar\nand the Strengthened Liar), we formulate the corresponding truth value\nequations and solve them analytically and/ or numerically."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0310054v1", 
    "title": "Kleene algebra with domain", 
    "arxiv-id": "cs/0310054v1", 
    "author": "G. Struth", 
    "publish": "2003-10-28T16:09:48Z", 
    "summary": "We propose Kleene algebra with domain (KAD), an extension of Kleene algebra\nwith two equational axioms for a domain and a codomain operation, respectively.\nKAD considerably augments the expressiveness of Kleene algebra, in particular\nfor the specification and analysis of state transition systems. We develop the\nbasic calculus, discuss some related theories and present the most important\nmodels of KAD. We demonstrate applicability by two examples: First, an\nalgebraic reconstruction of Noethericity and well-foundedness; second, an\nalgebraic reconstruction of propositional Hoare logic."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0310063v1", 
    "title": "Logic programs with monotone cardinality atoms", 
    "arxiv-id": "cs/0310063v1", 
    "author": "Miroslaw Truszczynski", 
    "publish": "2003-10-31T16:56:18Z", 
    "summary": "We investigate mca-programs, that is, logic programs with clauses built of\nmonotone cardinality atoms of the form kX, where k is a non-negative integer\nand X is a finite set of propositional atoms. We develop a theory of\nmca-programs. We demonstrate that the operational concept of the one-step\nprovability operator generalizes to mca-programs, but the generalization\ninvolves nondeterminism. Our main results show that the formalism of\nmca-programs is a common generalization of (1) normal logic programming with\nits semantics of models, supported models and stable models, (2) logic\nprogramming with cardinality atoms and with the semantics of stable models, as\ndefined by Niemela, Simons and Soininen, and (3) of disjunctive logic\nprogramming with the possible-model semantics of Sakama and Inoue."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0310064v1", 
    "title": "Satisfiability and computing van der Waerden numbers", 
    "arxiv-id": "cs/0310064v1", 
    "author": "Miroslaw Truszczynski", 
    "publish": "2003-10-31T17:05:58Z", 
    "summary": "In this paper we bring together the areas of combinatorics and propositional\nsatisfiability. Many combinatorial theorems establish, often constructively,\nthe existence of positive integer functions, without actually providing their\nclosed algebraic form or tight lower and upper bounds. The area of Ramsey\ntheory is especially rich in such results. Using the problem of computing van\nder Waerden numbers as an example, we show that these problems can be\nrepresented by parameterized propositional theories in such a way that\ndecisions concerning their satisfiability determine the numbers (function) in\nquestion. We show that by using general-purpose complete and local-search\ntechniques for testing propositional satisfiability, this approach becomes\neffective -- competitive with specialized approaches. By following it, we were\nable to obtain several new results pertaining to the problem of computing van\nder Waerden numbers. We also note that due to their properties, especially\ntheir structural simplicity and computational hardness, propositional theories\nthat arise in this research can be of use in development, testing and\nbenchmarking of SAT solvers."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0311022v1", 
    "title": "Temporalized logics and automata for time granularity", 
    "arxiv-id": "cs/0311022v1", 
    "author": "A. Montanari", 
    "publish": "2003-11-17T14:11:20Z", 
    "summary": "Suitable extensions of the monadic second-order theory of k successors have\nbeen proposed in the literature to capture the notion of time granularity. In\nthis paper, we provide the monadic second-order theories of downward unbounded\nlayered structures, which are infinitely refinable structures consisting of a\ncoarsest domain and an infinite number of finer and finer domains, and of\nupward unbounded layered structures, which consist of a finest domain and an\ninfinite number of coarser and coarser domains, with expressively complete and\nelementarily decidable temporal logic counterparts.\n  We obtain such a result in two steps. First, we define a new class of\ncombined automata, called temporalized automata, which can be proved to be the\nautomata-theoretic counterpart of temporalized logics, and show that relevant\nproperties, such as closure under Boolean operations, decidability, and\nexpressive equivalence with respect to temporal logics, transfer from component\nautomata to temporalized ones. Then, we exploit the correspondence between\ntemporalized logics and automata to reduce the task of finding the temporal\nlogic counterparts of the given theories of time granularity to the easier one\nof finding temporalized automata counterparts of them."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0311046v1", 
    "title": "Algebras for Agent Norm-Regulation", 
    "arxiv-id": "cs/0311046v1", 
    "author": "Magnus Boman", 
    "publish": "2003-11-27T13:03:55Z", 
    "summary": "An abstract architecture for idealized multi-agent systems whose behaviour is\nregulated by normative systems is developed and discussed. Agent choices are\ndetermined partially by the preference ordering of possible states and\npartially by normative considerations: The agent chooses that act which leads\nto the best outcome of all permissible actions. If an action is non-permissible\ndepends on if the result of performing that action leads to a state satisfying\na condition which is forbidden, according to the norms regulating the\nmulti-agent system. This idea is formalized by defining set-theoretic\npredicates characterizing multi-agent systems. The definition of the predicate\nuses decision theory, the Kanger-Lindahl theory of normative positions, and an\nalgebraic representation of normative systems."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0312002v1", 
    "title": "On Structuring Proof Search for First Order Linear Logic", 
    "arxiv-id": "cs/0312002v1", 
    "author": "Alessio Guglielmi", 
    "publish": "2003-12-01T14:33:06Z", 
    "summary": "Full first order linear logic can be presented as an abstract logic\nprogramming language in Miller's system Forum, which yields a sensible\noperational interpretation in the 'proof search as computation' paradigm.\nHowever, Forum still has to deal with syntactic details that would normally be\nignored by a reasonable operational semantics. In this respect, Forum improves\non Gentzen systems for linear logic by restricting the language and the form of\ninference rules. We further improve on Forum by restricting the class of\nformulae allowed, in a system we call G-Forum, which is still equivalent to\nfull first order linear logic. The only formulae allowed in G-Forum have the\nsame shape as Forum sequents: the restriction does not diminish expressiveness\nand makes G-Forum amenable to proof theoretic analysis. G-Forum consists of two\n(big) inference rules, for which we show a cut elimination procedure. This does\nnot need to appeal to finer detail in formulae and sequents than is provided by\nG-Forum, thus successfully testing the internal symmetries of our system."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0312013v2", 
    "title": "Fuzziness versus probability again", 
    "arxiv-id": "cs/0312013v2", 
    "author": "F. Jurkovic", 
    "publish": "2003-12-06T18:37:06Z", 
    "summary": "A construction of a fuzzy logic controller based on an analogy between fuzzy\nconditional rule of inference and marginal probability in terms of the\nconditional probability function has been proposed."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0312014v3", 
    "title": "Logical Characterizations of Heap Abstractions", 
    "arxiv-id": "cs/0312014v3", 
    "author": "R. Wilhelm", 
    "publish": "2003-12-07T20:31:23Z", 
    "summary": "Shape analysis concerns the problem of determining \"shape invariants\" for\nprograms that perform destructive updating on dynamically allocated storage. In\nrecent work, we have shown how shape analysis can be performed, using an\nabstract interpretation based on 3-valued first-order logic. In that work,\nconcrete stores are finite 2-valued logical structures, and the sets of stores\nthat can possibly arise during execution are represented (conservatively) using\na certain family of finite 3-valued logical structures. In this paper, we show\nhow 3-valued structures that arise in shape analysis can be characterized using\nformulas in first-order logic with transitive closure.\n  We also define a non-standard (\"supervaluational\") semantics for 3-valued\nfirst-order logic that is more precise than a conventional 3-valued semantics,\nand demonstrate that the supervaluational semantics can be effectively\nimplemented using existing theorem provers."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0312019v1", 
    "title": "Verification of recursive parallel systems", 
    "arxiv-id": "cs/0312019v1", 
    "author": "Adriano Peron", 
    "publish": "2003-12-11T14:54:06Z", 
    "summary": "In this paper we consider the problem of proving properties of infinite\nbehaviour of formalisms suitable to describe (infinite state) systems with\nrecursion and parallelism. As a formal setting, we consider the framework of\nProcess Rewriting Systems (PRSs). For a meaningfull fragment of PRSs, allowing\nto accommodate both Pushdown Automata and Petri Nets, we state decidability\nresults for a class of properties about infinite derivations (infinite term\nrewritings). The given results can be exploited for the automatic verification\nof some classes of linear time properties of infinite state systems described\nby PRSs. In order to exemplify the assessed results, we introduce a meaningful\nautomaton based formalism which allows to express both recursion and\nmulti--treading."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0312032v1", 
    "title": "Learning in a Compiler for MINSAT Algorithms", 
    "arxiv-id": "cs/0312032v1", 
    "author": "Klaus Truemper", 
    "publish": "2003-12-16T17:24:18Z", 
    "summary": "This paper describes learning in a compiler for algorithms solving classes of\nthe logic minimization problem MINSAT, where the underlying propositional\nformula is in conjunctive normal form (CNF) and where costs are associated with\nthe True/False values of the variables. Each class consists of all instances\nthat may be derived from a given propositional formula and costs for True/False\nvalues by fixing or deleting variables, and by deleting clauses. The learning\nstep begins once the compiler has constructed a solution algorithm for a given\nclass. The step applies that algorithm to comparatively few instances of the\nclass, analyses the performance of the algorithm on these instances, and\nmodifies the underlying propositional formula, with the goal that the algorithm\nwill perform much better on all instances of the class."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0402002v1", 
    "title": "Deciding Disjunctive Linear Arithmetic with SAT", 
    "arxiv-id": "cs/0402002v1", 
    "author": "Ofer Strichman", 
    "publish": "2004-02-01T12:42:20Z", 
    "summary": "Disjunctive Linear Arithmetic (DLA) is a major decidable theory that is\nsupported by almost all existing theorem provers. The theory consists of\nBoolean combinations of predicates of the form $\\Sigma_{j=1}^{n}a_j\\cdot x_j\n\\le b$, where the coefficients $a_j$, the bound $b$ and the variables $x_1 >...\nx_n$ are of type Real ($\\mathbb{R}$). We show a reduction to propositional\nlogic from disjunctive linear arithmetic based on Fourier-Motzkin elimination.\nWhile the complexity of this procedure is not better than competing techniques,\nit has practical advantages in solving verification problems. It also promotes\nthe option of deciding a combination of theories by reducing them to this\nlogic. Results from experiments show that this method has a strong advantage\nover existing techniques when there are many disjunctions in the formula."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0402010v1", 
    "title": "Encapsulation for Practical Simplification Procedures", 
    "arxiv-id": "cs/0402010v1", 
    "author": "William McCune", 
    "publish": "2004-02-03T19:04:02Z", 
    "summary": "ACL2 was used to prove properties of two simplification procedures. The\nprocedures differ in complexity but solve the same programming problem that\narises in the context of a resolution/paramodulation theorem proving system.\nTerm rewriting is at the core of the two procedures, but details of the\nrewriting procedure itself are irrelevant. The ACL2 encapsulate construct was\nused to assert the existence of the rewriting function and to state some of its\nproperties. Termination, irreducibility, and soundness properties were\nestablished for each procedure. The availability of the encapsulation mechanism\nin ACL2 is considered essential to rapid and efficient verification of this\nkind of algorithm."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0402038v1", 
    "title": "Towards a Mathematical Theory of the Delays of the Asynchronous Circuits", 
    "arxiv-id": "cs/0402038v1", 
    "author": "Serban E. Vlad", 
    "publish": "2004-02-17T12:11:56Z", 
    "summary": "The inequations of the delays of the asynchronous circuits are written, by\nmaking use of pseudo-Boolean differential calculus. We consider these efforts\nto be a possible starting point in the semi-formalized reconstruction of the\ndigital electrical engineering (which is a non-formalized theory)."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0402039v1", 
    "title": "On the Inertia of the Asynchronous Circuits", 
    "arxiv-id": "cs/0402039v1", 
    "author": "Serban E. Vlad", 
    "publish": "2004-02-17T12:54:00Z", 
    "summary": "We present the bounded delays, the absolute inertia and the relative inertia."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0402040v1", 
    "title": "Defining the Delays of the Asynchronous Circuits", 
    "arxiv-id": "cs/0402040v1", 
    "author": "Serban E. Vlad", 
    "publish": "2004-02-17T13:01:05Z", 
    "summary": "We define the delays of a circuit, as well as the properties of determinism,\norder, time invariance, constancy, symmetry and the serial connection."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0402041v1", 
    "title": "Examples of Models of the Asynchronous Circuits", 
    "arxiv-id": "cs/0402041v1", 
    "author": "Serban E. Vlad", 
    "publish": "2004-02-17T13:07:24Z", 
    "summary": "We define the delays of a circuit, as well as the properties of determinism,\norder, time invariance, constancy, symmetry and the serial connection."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0402059v2", 
    "title": "Light types for polynomial time computation in lambda-calculus", 
    "arxiv-id": "cs/0402059v2", 
    "author": "Kazushige Terui", 
    "publish": "2004-02-26T15:47:36Z", 
    "summary": "We propose a new type system for lambda-calculus ensuring that well-typed\nprograms can be executed in polynomial time: Dual light affine logic (DLAL).\n  DLAL has a simple type language with a linear and an intuitionistic type\narrow, and one modality. It corresponds to a fragment of Light affine logic\n(LAL). We show that contrarily to LAL, DLAL ensures good properties on\nlambda-terms: subject reduction is satisfied and a well-typed term admits a\npolynomial bound on the reduction by any strategy. We establish that as LAL,\nDLAL allows to represent all polytime functions. Finally we give a type\ninference procedure for propositional DLAL."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0403041v1", 
    "title": "A Theory of Computation Based on Quantum Logic (I)", 
    "arxiv-id": "cs/0403041v1", 
    "author": "Mingsheng Ying", 
    "publish": "2004-03-29T15:20:32Z", 
    "summary": "The (meta)logic underlying classical theory of computation is Boolean\n(two-valued) logic. Quantum logic was proposed by Birkhoff and von Neumann as a\nlogic of quantum mechanics more than sixty years ago. The major difference\nbetween Boolean logic and quantum logic is that the latter does not enjoy\ndistributivity in general. The rapid development of quantum computation in\nrecent years stimulates us to establish a theory of computation based on\nquantum logic. The present paper is the first step toward such a new theory and\nit focuses on the simplest models of computation, namely finite automata. It is\nfound that the universal validity of many properties of automata depend heavily\nupon the distributivity of the underlying logic. This indicates that these\nproperties does not universally hold in the realm of quantum logic. On the\nother hand, we show that a local validity of them can be recovered by imposing\na certain commutativity to the (atomic) statements about the automata under\nconsideration. This reveals an essential difference between the classical\ntheory of computation and the computation theory based on quantum logic."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182614", 
    "link": "http://arxiv.org/pdf/cs/0404048v2", 
    "title": "Incompleteness of States w.r.t. Traces in Model Checking", 
    "arxiv-id": "cs/0404048v2", 
    "author": "Francesco Ranzato", 
    "publish": "2004-04-23T08:49:18Z", 
    "summary": "Cousot and Cousot introduced and studied a general past/future-time\nspecification language, called mu*-calculus, featuring a natural time-symmetric\ntrace-based semantics. The standard state-based semantics of the mu*-calculus\nis an abstract interpretation of its trace-based semantics, which turns out to\nbe incomplete (i.e., trace-incomplete), even for finite systems. As a\nconsequence, standard state-based model checking of the mu*-calculus is\nincomplete w.r.t. trace-based model checking. This paper shows that any\nrefinement or abstraction of the domain of sets of states induces a\ncorresponding semantics which is still trace-incomplete for any propositional\nfragment of the mu*-calculus. This derives from a number of results, one for\neach incomplete logical/temporal connective of the mu*-calculus, that\ncharacterize the structure of models, i.e. transition systems, whose\ncorresponding state-based semantics of the mu*-calculus is trace-complete."
},{
    "category": "cs.LO", 
    "doi": "10.1007/11417170_26", 
    "link": "http://arxiv.org/pdf/cs/0404056v2", 
    "title": "A lambda calculus for quantum computation with classical control", 
    "arxiv-id": "cs/0404056v2", 
    "author": "Benoit Valiron", 
    "publish": "2004-04-27T21:33:52Z", 
    "summary": "The objective of this paper is to develop a functional programming language\nfor quantum computers. We develop a lambda calculus for the classical control\nmodel, following the first author's work on quantum flow-charts. We define a\ncall-by-value operational semantics, and we give a type system using affine\nintuitionistic linear logic. The main results of this paper are the safety\nproperties of the language and the development of a type inference algorithm."
},{
    "category": "cs.LO", 
    "doi": "10.1007/11417170_26", 
    "link": "http://arxiv.org/pdf/cs/0405081v1", 
    "title": "An Analysis of Lambek's Production Machines", 
    "arxiv-id": "cs/0405081v1", 
    "author": "Riccardo Pucella", 
    "publish": "2004-05-23T19:22:10Z", 
    "summary": "Lambek's production machines may be used to generate and recognize sentences\nin a subset of the language described by a production grammar. We determine in\nthis paper the subset of the language of a grammar generated and recognized by\nsuch machines."
},{
    "category": "cs.LO", 
    "doi": "10.1007/11417170_26", 
    "link": "http://arxiv.org/pdf/cs/0405103v1", 
    "title": "On model checking data-independent systems with arrays without reset", 
    "arxiv-id": "cs/0405103v1", 
    "author": "A. W. Roscoe", 
    "publish": "2004-05-27T03:25:52Z", 
    "summary": "A system is data-independent with respect to a data type X iff the operations\nit can perform on values of type X are restricted to just equality testing. The\nsystem may also store, input and output values of type X. We study model\nchecking of systems which are data-independent with respect to two distinct\ntype variables X and Y, and may in addition use arrays with indices from X and\nvalues from Y . Our main interest is the following parameterised model-checking\nproblem: whether a given program satisfies a given temporal-logic formula for\nall non-empty nite instances of X and Y . Initially, we consider instead the\nabstraction where X and Y are infinite and where partial functions with finite\ndomains are used to model arrays. Using a translation to data-independent\nsystems without arrays, we show that the u-calculus model-checking problem is\ndecidable for these systems. From this result, we can deduce properties of all\nsystems with finite instances of X and Y . We show that there is a procedure\nfor the above parameterised model-checking problem of the universal fragment of\nthe u-calculus, such that it always terminates but may give false negatives. We\nalso deduce that the parameterised model-checking problem of the universal\ndisjunction-free fragment of the u-calculus is decidable. Practical motivations\nfor model checking data-independent systems with arrays include verification of\nmemory and cache systems, where X is the type of memory addresses, and Y the\ntype of storable values. As an example we verify a fault-tolerant memory\ninterface over a set of unreliable memories."
},{
    "category": "cs.LO", 
    "doi": "10.1007/11417170_26", 
    "link": "http://arxiv.org/pdf/cs/0406013v1", 
    "title": "Optimization of Bound Disjunctive Queries with Constraints", 
    "arxiv-id": "cs/0406013v1", 
    "author": "E. Zumpano", 
    "publish": "2004-06-07T12:13:58Z", 
    "summary": "\"To Appear in Theory and Practice of Logic Programming (TPLP)\" This paper\npresents a technique for the optimization of bound queries over disjunctive\ndeductive databases with constraints. The proposed approach is an extension of\nthe well-known Magic-Set technique and is well-suited for being integrated in\ncurrent bottom-up (stable) model inference engines. More specifically, it is\nbased on the exploitation of binding propagation techniques which reduce the\nsize of the data relevant to answer the query and, consequently, reduces both\nthe complexity of computing a single model and the number of models to be\nconsidered. The motivation of this work stems from the observation that\ntraditional binding propagation optimization techniques for bottom-up model\ngenerator systems, simulating the goal driven evaluation of top-down engines,\nare only suitable for positive (disjunctive) queries, while hard problems are\nexpressed using unstratified negation. The main contribution of the paper\nconsists in the extension of a previous technique, defined for positive\ndisjunctive queries, to queries containing both disjunctive heads and\nconstraints (a simple and expressive form of unstratified negation). As the\nusual way of expressing declaratively hard problems is based on the\nguess-and-check technique, where the guess part is expressed by means of\ndisjunctive rules and the check part is expressed by means of constraints, the\ntechnique proposed here is highly relevant for the optimization of queries\nexpressing hard problems. The value of the technique has been proved by several\nexperiments."
},{
    "category": "cs.LO", 
    "doi": "10.1007/11417170_26", 
    "link": "http://arxiv.org/pdf/cs/0407006v1", 
    "title": "Predicate Abstraction with Indexed Predicates", 
    "arxiv-id": "cs/0407006v1", 
    "author": "Randal E. Bryant", 
    "publish": "2004-07-02T06:17:13Z", 
    "summary": "Predicate abstraction provides a powerful tool for verifying properties of\ninfinite-state systems using a combination of a decision procedure for a subset\nof first-order logic and symbolic methods originally developed for finite-state\nmodel checking. We consider models containing first-order state variables,\nwhere the system state includes mutable functions and predicates. Such a model\ncan describe systems containing arbitrarily large memories, buffers, and arrays\nof identical processes. We describe a form of predicate abstraction that\nconstructs a formula over a set of universally quantified variables to describe\ninvariant properties of the first-order state variables. We provide a formal\njustification of the soundness of our approach and describe how it has been\nused to verify several hardware and software designs, including a\ndirectory-based cache coherence protocol."
},{
    "category": "cs.LO", 
    "doi": "10.1007/11417170_26", 
    "link": "http://arxiv.org/pdf/cs/0407031v1", 
    "title": "On Modal Logics of Partial Recursive Functions", 
    "arxiv-id": "cs/0407031v1", 
    "author": "Pavel Naumov", 
    "publish": "2004-07-12T22:53:33Z", 
    "summary": "The classical propositional logic is known to be sound and complete with\nrespect to the set semantics that interprets connectives as set operations. The\npaper extends propositional language by a new binary modality that corresponds\nto partial recursive function type constructor under the above interpretation.\nThe cases of deterministic and non-deterministic functions are considered and\nfor both of them semantically complete modal logics are described and\ndecidability of these logics is established."
},{
    "category": "cs.LO", 
    "doi": "10.1007/11417170_26", 
    "link": "http://arxiv.org/pdf/cs/0409052v1", 
    "title": "Better Quasi-Ordered Transition Systems", 
    "arxiv-id": "cs/0409052v1", 
    "author": "Aletta Nylen", 
    "publish": "2004-09-26T21:54:12Z", 
    "summary": "Many existing algorithms for model checking of infinite-state systems operate\non constraints which are used to represent (potentially infinite) sets of\nstates. A general powerful technique which can be employed for proving\ntermination of these algorithms is that of well quasi-orderings. Several\nmethodologies have been proposed for derivation of new well quasi-ordered\nconstraint systems. However, many of these constraint systems suffer from a\n\"constraint explosion problem\", as the number of the generated constraints\ngrows exponentially with the size of the problem. In this paper, we demonstrate\nthat a refinement of the theory of well quasi-orderings, called the theory of\nbetter quasi-orderings, is more appropriate for symbolic model checking, since\nit allows inventing constraint systems which are both well quasi-ordered and\ncompact. As a main application, we introduce existential zones, a constraint\nsystem for verification of systems with unboundedly many clocks and use our\nmethodology to prove that existential zones are better quasi-ordered. We show\nhow to use existential zones in verification of timed Petri nets and present\nsome experimental results. Also, we apply our methodology to derive new\nconstraint systems for verification of broadcast protocols, lossy channel\nsystems, and integral relational automata. The new constraint systems are\nexponentially more succinct than existing ones, and their well quasi-ordering\ncannot be shown by previous methods in the literature."
},{
    "category": "cs.LO", 
    "doi": "10.1007/11417170_26", 
    "link": "http://arxiv.org/pdf/cs/0410029v1", 
    "title": "Nondeterministic Linear Logic", 
    "arxiv-id": "cs/0410029v1", 
    "author": "Satoshi Matsuoka", 
    "publish": "2004-10-14T05:28:06Z", 
    "summary": "In this paper, we introduce Linear Logic with a nondeterministic facility,\nwhich has a self-dual additive connective. In the system the proof net\ntechnology is available in a natural way. The important point is that\nnondeterminism in the system is expressed by the process of normalization, not\nby proof search. Moreover we can incorporate the system into Light Linear Logic\nand Elementary Linear Logic developed by J.-Y.Girard recently: Nondeterministic\nLight Linear Logic and Nondeterministic Elementary Linear Logic are defined in\na very natural way."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.apal.2006.06.001", 
    "link": "http://arxiv.org/pdf/cs/0410030v12", 
    "title": "Weak Typed Boehm Theorem on IMLL", 
    "arxiv-id": "cs/0410030v12", 
    "author": "Satoshi Matsuoka", 
    "publish": "2004-10-14T07:20:40Z", 
    "summary": "In the Boehm theorem workshop on Crete island, Zoran Petric called Statman's\n``Typical Ambiguity theorem'' typed Boehm theorem. Moreover, he gave a new\nproof of the theorem based on set-theoretical models of the simply typed lambda\ncalculus. In this paper, we study the linear version of the typed Boehm theorem\non a fragment of Intuitionistic Linear Logic. We show that in the\nmultiplicative fragment of intuitionistic linear logic without the\nmultiplicative unit 1 (for short IMLL) weak typed Boehm theorem holds. The\nsystem IMLL exactly corresponds to the linear lambda calculus without\nexponentials, additives and logical constants. The system IMLL also exactly\ncorresponds to the free symmetric monoidal closed category without the unit\nobject. As far as we know, our separation result is the first one with regard\nto these systems in a purely syntactical manner."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.apal.2006.06.001", 
    "link": "http://arxiv.org/pdf/cs/0410034v2", 
    "title": "P-time Completeness of Light Linear Logic and its Nondeterministic   Extension", 
    "arxiv-id": "cs/0410034v2", 
    "author": "Satoshi Matsuoka", 
    "publish": "2004-10-15T13:43:51Z", 
    "summary": "In CSL'99 Roversi pointed out that the Turing machine encoding of Girard's\nseminal paper \"Light Linear Logic\" has a flaw. Moreover he presented a working\nversion of the encoding in Light Affine Logic, but not in Light Linear Logic.\nIn this paper we present a working version of the encoding in Light Linear\nLogic. The idea of the encoding is based on a remark of Girard's tutorial paper\non Linear Logic. The encoding is also an example which shows usefulness of\nadditive connectives. Moreover we also consider a nondeterministic extension of\nLight Linear Logic. We show that the extended system is NP-complete in the same\nmeaning as P-completeness of Light Linear Logic."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.apal.2006.06.001", 
    "link": "http://arxiv.org/pdf/cs/0410051v1", 
    "title": "Turing Machine with Faults, Failures and Recovery", 
    "arxiv-id": "cs/0410051v1", 
    "author": "Alex Vinokur", 
    "publish": "2004-10-20T12:43:35Z", 
    "summary": "A Turing machine with faults, failures and recovery (TMF) is described. TMF\nis (weakly) non-deterministic Turing machine consisting of five semi-infinite\ntapes (Master Tape, Synchro Tape, Backup Tape, Backup Synchro Tape, User Tape)\nand four controlling components (Program, Daemon, Apparatus, User).\nComputational process consists of three phases (Program Phase, Failure Phase,\nRepair Phase). C++ Simulator of a Turing machine with faults, failures and\nrecovery has been developed."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.apal.2006.06.001", 
    "link": "http://arxiv.org/pdf/cs/0410056v2", 
    "title": "Interval Neutrosophic Logics: Theory and Applications", 
    "arxiv-id": "cs/0410056v2", 
    "author": "Rajshekhar Sunderraman", 
    "publish": "2004-10-21T20:24:28Z", 
    "summary": "In this paper, we present the interval neutrosophic logics which generalizes\nthe fuzzy logic, paraconsistent logic, intuitionistic fuzzy logic and many\nother non-classical and non-standard logics. We will give the formal definition\nof interval neutrosophic propositional calculus and interval neutrosophic\npredicate calculus. Then we give one application of interval neutrosophic\nlogics to do approximate reasoning."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.apal.2006.06.001", 
    "link": "http://arxiv.org/pdf/cs/0410065v1", 
    "title": "A Categorical View on Algebraic Lattices in Formal Concept Analysis", 
    "arxiv-id": "cs/0410065v1", 
    "author": "Guo-Qiang Zhang", 
    "publish": "2004-10-25T15:01:33Z", 
    "summary": "Formal concept analysis has grown from a new branch of the mathematical field\nof lattice theory to a widely recognized tool in Computer Science and\nelsewhere. In order to fully benefit from this theory, we believe that it can\nbe enriched with notions such as approximation by computation or\nrepresentability. The latter are commonly studied in denotational semantics and\ndomain theory and captured most prominently by the notion of algebraicity, e.g.\nof lattices. In this paper, we explore the notion of algebraicity in formal\nconcept analysis from a category-theoretical perspective. To this end, we build\non the the notion of approximable concept with a suitable category and show\nthat the latter is equivalent to the category of algebraic lattices. At the\nsame time, the paper provides a relatively comprehensive account of the\nrepresentation theory of algebraic lattices in the framework of Stone duality,\nrelating well-known structures such as Scott information systems with further\nformalisms from logic, topology, domains and lattice theory."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.apal.2006.06.001", 
    "link": "http://arxiv.org/pdf/cs/0411029v1", 
    "title": "Modules and Logic Programming", 
    "arxiv-id": "cs/0411029v1", 
    "author": "Virgile Mogbil", 
    "publish": "2004-11-10T14:01:34Z", 
    "summary": "We study conditions for a concurrent construction of proof-nets in the\nframework developed by Andreoli in recent papers. We define specific\ncorrectness criteria for that purpose. We first study closed modules (i.e.\nvalidity of the execution of a logic program), then extend the criterion to\nopen modules (i.e. validity during the execution) distinguishing criteria for\nacyclicity and connectability in order to allow incremental verification."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.apal.2006.06.001", 
    "link": "http://arxiv.org/pdf/cs/0411031v1", 
    "title": "Complexity of the Two-Variable Fragment with (Binary-Coded) Counting   Quantifiers", 
    "arxiv-id": "cs/0411031v1", 
    "author": "Ian Pratt-Hartmann", 
    "publish": "2004-11-10T18:53:54Z", 
    "summary": "We show that the satisfiability and finite satisfiability problems for the\ntwo-variable fragment of first-order logic with counting quantifiers are both\nin NEXPTIME, even when counting quantifiers are coded succinctly."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.apal.2006.06.001", 
    "link": "http://arxiv.org/pdf/cs/0411032v1", 
    "title": "Logic Column 10: Specifying Confidentiality", 
    "arxiv-id": "cs/0411032v1", 
    "author": "Riccardo Pucella", 
    "publish": "2004-11-11T19:09:59Z", 
    "summary": "This article illustrates the use of a logical specification language to\ncapture various forms of confidentiality properties used in the security\nliterature."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.apal.2006.06.001", 
    "link": "http://arxiv.org/pdf/cs/0411100v2", 
    "title": "A Decidable Probability Logic for Timed Probabilistic Systems", 
    "arxiv-id": "cs/0411100v2", 
    "author": "Daniele Beauquier", 
    "publish": "2004-11-30T10:42:35Z", 
    "summary": "In this paper we extend the predicate logic introduced in [Beauquier et al.\n2002] in order to deal with Semi-Markov Processes. We prove that with respect\nto qualitative probabilistic properties, model checking is decidable for this\nlogic applied to Semi-Markov Processes. Furthermore we apply our logic to\nProbabilistic Timed Automata considering classical and urgent semantics, and\nconsidering also predicates on clock. We prove that results on Semi Markov\nProcesses hold also for Probabilistic Timed Automata for both the two semantics\nconsidered. Moreover, we prove that results for Markov Processes shown in\n[Beauquier et al. 2002] are extensible to Probabilistic Timed Automata where\nurgent semantics is considered."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.apal.2006.06.001", 
    "link": "http://arxiv.org/pdf/cs/0412028v1", 
    "title": "A feasible algorithm for typing in Elementary Affine Logic", 
    "arxiv-id": "cs/0412028v1", 
    "author": "Kazushige Terui", 
    "publish": "2004-12-08T08:33:08Z", 
    "summary": "We give a new type inference algorithm for typing lambda-terms in Elementary\nAffine Logic (EAL), which is motivated by applications to complexity and\noptimal reduction. Following previous references on this topic, the variant of\nEAL type system we consider (denoted EAL*) is a variant without sharing and\nwithout polymorphism. Our algorithm improves over the ones already known in\nthat it offers a better complexity bound: if a simple type derivation for the\nterm t is given our algorithm performs EAL* type inference in polynomial time."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-1(1:1)2005", 
    "link": "http://arxiv.org/pdf/cs/0412063v5", 
    "title": "Labelled transition systems as a Stone space", 
    "arxiv-id": "cs/0412063v5", 
    "author": "Michael Huth", 
    "publish": "2004-12-15T14:34:43Z", 
    "summary": "A fully abstract and universal domain model for modal transition systems and\nrefinement is shown to be a maximal-points space model for the bisimulation\nquotient of labelled transition systems over a finite set of events. In this\ndomain model we prove that this quotient is a Stone space whose compact,\nzero-dimensional, and ultra-metrizable Hausdorff topology measures the degree\nof bisimilarity such that image-finite labelled transition systems are dense.\nUsing this compactness we show that the set of labelled transition systems that\nrefine a modal transition system, its ''set of implementations'', is compact\nand derive a compactness theorem for Hennessy-Milner logic on such\nimplementation sets. These results extend to systems that also have partially\nspecified state propositions, unify existing denotational, operational, and\nmetric semantics on partial processes, render robust consistency measures for\nmodal transition systems, and yield an abstract interpretation of compact sets\nof labelled transition systems as Scott-closed sets of modal transition\nsystems."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-1(1:1)2005", 
    "link": "http://arxiv.org/pdf/cs/0412101v1", 
    "title": "The Inverse Method Implements the Automata Approach for Modal   Satisfiability", 
    "arxiv-id": "cs/0412101v1", 
    "author": "Stephan Tobies", 
    "publish": "2004-12-22T14:17:48Z", 
    "summary": "Tableaux-based decision procedures for satisfiability of modal and\ndescription logics behave quite well in practice, but it is sometimes hard to\nobtain exact worst-case complexity results using these approaches, especially\nfor EXPTIME-complete logics. In contrast, automata-based approaches often yield\nalgorithms for which optimal worst-case complexity can easily be proved.\nHowever, the algorithms obtained this way are usually not only worst-case, but\nalso best-case exponential: they first construct an automaton that is always\nexponential in the size of the input, and then apply the (polynomial) emptiness\ntest to this large automaton. To overcome this problem, one must try to\nconstruct the automaton \"on-the-fly\" while performing the emptiness test.\n  In this paper we will show that Voronkov's inverse method for the modal logic\nK can be seen as an on-the-fly realization of the emptiness test done by the\nautomata approach for K. The benefits of this result are two-fold. First, it\nshows that Voronkov's implementation of the inverse method, which behaves quite\nwell in practice, is an optimized on-the-fly implementation of the\nautomata-based satisfiability procedure for K. Second, it can be used to give a\nsimpler proof of the fact that Voronkov's optimizations do not destroy\ncompleteness of the procedure. We will also show that the inverse method can\neasily be extended to handle global axioms, and that the correspondence to the\nautomata approach still holds in this setting. In particular, the inverse\nmethod yields an EXPTIME-algorithm for satisfiability in K w.r.t. global\naxioms."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.jco.2006.05.002", 
    "link": "http://arxiv.org/pdf/cs/0501024v2", 
    "title": "Effectively Open Real Functions", 
    "arxiv-id": "cs/0501024v2", 
    "author": "Martin Ziegler", 
    "publish": "2005-01-12T12:16:48Z", 
    "summary": "A function f is continuous iff the PRE-image f^{-1}[V] of any open set V is\nopen again. Dual to this topological property, f is called OPEN iff the IMAGE\nf[U] of any open set U is open again. Several classical Open Mapping Theorems\nin Analysis provide a variety of sufficient conditions for openness.\n  By the Main Theorem of Recursive Analysis, computable real functions are\nnecessarily continuous. In fact they admit a well-known characterization in\nterms of the mapping V+->f^{-1}[V] being EFFECTIVE: Given a list of open\nrational balls exhausting V, a Turing Machine can generate a corresponding list\nfor f^{-1}[V]. Analogously, EFFECTIVE OPENNESS requires the mapping U+->f[U] on\nopen real subsets to be effective.\n  By effectivizing classical Open Mapping Theorems as well as from application\nof Tarski's Quantifier Elimination, the present work reveals several rich\nclasses of functions to be effectively open."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.jco.2006.05.002", 
    "link": "http://arxiv.org/pdf/cs/0501032v1", 
    "title": "On Partially Additive Kleene Algebras", 
    "arxiv-id": "cs/0501032v1", 
    "author": "Riccardo Pucella", 
    "publish": "2005-01-16T20:39:20Z", 
    "summary": "We define the notion of a partially additive Kleene algebra, which is a\nKleene algebra where the + operation need only be partially defined. These\nstructures formalize a number of examples that cannot be handled directly by\nKleene algebras. We relate partially additive Kleene algebras to existing\nalgebraic structures, by exhibiting categorical connections with Kleene\nalgebras, partially additive categories, and closed semirings."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.jco.2006.05.002", 
    "link": "http://arxiv.org/pdf/cs/0501033v1", 
    "title": "Playful, streamlike computation", 
    "arxiv-id": "cs/0501033v1", 
    "author": "Pierre-Louis Curien", 
    "publish": "2005-01-18T07:39:09Z", 
    "summary": "We offer a short tour into the interactive interpretation of sequential\nprograms. We emphasize streamlike computation -- that is, computation of\nsuccessive bits of information upon request. The core of the approach surveyed\nhere dates back to the work of Berry and the author on sequential algorithms on\nconcrete data structures in the late seventies, culminating in the design of\nthe programming language CDS, in which the semantics of programs of any type\ncan be explored interactively. Around one decade later, two major insights of\nCartwright and Felleisen on one hand, and of Lamarche on the other hand gave\nnew, decisive impulses to the study of sequentiality. Cartwright and Felleisen\nobserved that sequential algorithms give a direct semantics to control\noperators like \\\"call-cc\\\" and proposed to include explicit errors both in the\nsyntax and in the semantics of the language PCF. Lamarche (unpublished)\nconnected sequential algorithms to linear logic and games. The successful\nprogram of games semantics has spanned over the nineties until now, starting\nwith syntax-independent characterizations of the term model of PCF by Abramsky,\nJagadeesan, and Malacaria on one hand, and by Hyland and Ong on the other hand."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.jco.2006.05.002", 
    "link": "http://arxiv.org/pdf/cs/0501034v1", 
    "title": "Symmetry and interactivity in Programming", 
    "arxiv-id": "cs/0501034v1", 
    "author": "Pierre-Louis Curien", 
    "publish": "2005-01-18T07:41:48Z", 
    "summary": "We recall some of the early occurrences of the notions of interactivity and\nsymmetry in the operational and denotational semantics of programming\nlanguages. We suggest some connections with ludics."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.jco.2006.05.002", 
    "link": "http://arxiv.org/pdf/cs/0501035v1", 
    "title": "Introduction to linear logic and ludics, part I", 
    "arxiv-id": "cs/0501035v1", 
    "author": "Pierre-Louis Curien", 
    "publish": "2005-01-18T07:42:33Z", 
    "summary": "This two-parts paper offers a survey of linear logic and ludics, which were\nintroduced by Girard in 1986 and 2001, respectively. Both theories revisit\nmathematical logic from first principles, with inspiration from and\napplications to computer science. The present part I covers an introduction to\nthe connectives and proof rules of linear logic, to its decidability\nproperties, and to its models. Part II will deal with proof nets, a graph-like\nrepresentation of proofs which is one of the major innovations of linear logic,\nand will present an introduction to ludics."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.jco.2006.05.002", 
    "link": "http://arxiv.org/pdf/cs/0501039v1", 
    "title": "Introduction to linear logic and ludics, part II", 
    "arxiv-id": "cs/0501039v1", 
    "author": "Pierre-Louis Curien", 
    "publish": "2005-01-19T15:00:46Z", 
    "summary": "This paper is the second part of an introduction to linear logic and ludics,\nboth due to Girard. It is devoted to proof nets, in the limited, yet central,\nframework of multiplicative linear logic and to ludics, which has been recently\ndevelopped in an aim of further unveiling the fundamental interactive nature of\ncomputation and logic. We hope to offer a few computer science insights into\nthis new theory."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-1(1:3)2005", 
    "link": "http://arxiv.org/pdf/cs/0501040v4", 
    "title": "Split-2 Bisimilarity has a Finite Axiomatization over CCS with<br>   Hennessy&#39;s Merge", 
    "arxiv-id": "cs/0501040v4", 
    "author": "Bas Luttik", 
    "publish": "2005-01-19T17:55:45Z", 
    "summary": "This note shows that split-2 bisimulation equivalence (also known as timed\nequivalence) affords a finite equational axiomatization over the process\nalgebra obtained by adding an auxiliary operation proposed by Hennessy in 1981\nto the recursion, relabelling and restriction free fragment of Milner's\nCalculus of Communicating Systems. Thus the addition of a single binary\noperation, viz. Hennessy's merge, is sufficient for the finite equational\naxiomatization of parallel composition modulo this non-interleaving\nequivalence. This result is in sharp contrast to a theorem previously obtained\nby the same authors to the effect that the same language is not finitely based\nmodulo bisimulation equivalence."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-1(1:3)2005", 
    "link": "http://arxiv.org/pdf/cs/0502031v2", 
    "title": "Logic Column 11: The Finite and the Infinite in Temporal Logic", 
    "arxiv-id": "cs/0502031v2", 
    "author": "Riccardo Pucella", 
    "publish": "2005-02-05T21:00:13Z", 
    "summary": "This article examines the interpretation of the LTL temporal operators over\nfinite and infinite sequences. This is used as the basis for deriving a sound\nand complete axiomatization for Caret, a recent temporal logic for reasoning\nabout programs with nested procedure calls and returns."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-1(1:3)2005", 
    "link": "http://arxiv.org/pdf/cs/0502046v1", 
    "title": "Proof obligations for specification and refinement of liveness   properties under weak fairness", 
    "arxiv-id": "cs/0502046v1", 
    "author": "Didier Bert", 
    "publish": "2005-02-09T09:23:30Z", 
    "summary": "In this report, we present a formal model of fair iteration of events for B\nevent systems. The model is used to justify proof obligations for basic\nliveness properties and preservation under refinement of general liveness\nproperties. The model of fair iteration of events uses the dovetail operator,\nan operator proposed by Broy and Nelson to model fair choice. The proofs are\nmainly founded in fixpoint calculations of fair iteration of events and weakest\nprecondition calculus."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-1(1:6)2005", 
    "link": "http://arxiv.org/pdf/cs/0502047v3", 
    "title": "The succinctness of first-order logic on linear orders", 
    "arxiv-id": "cs/0502047v3", 
    "author": "Nicole Schweikardt", 
    "publish": "2005-02-09T11:00:12Z", 
    "summary": "Succinctness is a natural measure for comparing the strength of different\nlogics. Intuitively, a logic L_1 is more succinct than another logic L_2 if all\nproperties that can be expressed in L_2 can be expressed in L_1 by formulas of\n(approximately) the same size, but some properties can be expressed in L_1 by\n(significantly) smaller formulas.\n  We study the succinctness of logics on linear orders. Our first theorem is\nconcerned with the finite variable fragments of first-order logic. We prove\nthat:\n  (i) Up to a polynomial factor, the 2- and the 3-variable fragments of\nfirst-order logic on linear orders have the same succinctness. (ii) The\n4-variable fragment is exponentially more succinct than the 3-variable\nfragment. Our second main result compares the succinctness of first-order logic\non linear orders with that of monadic second-order logic. We prove that the\nfragment of monadic second-order logic that has the same expressiveness as\nfirst-order logic on linear orders is non-elementarily more succinct than\nfirst-order logic."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-1(1:6)2005", 
    "link": "http://arxiv.org/pdf/cs/0505014v1", 
    "title": "Interval Neutrosophic Sets and Logic: Theory and Applications in   Computing", 
    "arxiv-id": "cs/0505014v1", 
    "author": "Rajshekhar Sunderraman", 
    "publish": "2005-05-06T13:57:13Z", 
    "summary": "This book presents the advancements and applications of neutrosophics.\nChapter 1 first introduces the interval neutrosophic sets which is an instance\nof neutrosophic sets. In this chapter, the definition of interval neutrosophic\nsets and set-theoretic operators are given and various properties of interval\nneutrosophic set are proved. Chapter 2 defines the interval neutrosophic logic\nbased on interval neutrosophic sets including the syntax and semantics of first\norder interval neutrosophic propositional logic and first order interval\nneutrosophic predicate logic. The interval neutrosophic logic can reason and\nmodel fuzzy, incomplete and inconsistent information. In this chapter, we also\ndesign an interval neutrosophic inference system based on first order interval\nneutrosophic predicate logic. The interval neutrosophic inference system can be\napplied to decision making. Chapter 3 gives one application of interval\nneutrosophic sets and logic in the field of relational databases. Neutrosophic\ndata model is the generalization of fuzzy data model and paraconsistent data\nmodel. Here, we generalize various set-theoretic and relation-theoretic\noperations of fuzzy data model to neutrosophic data model. Chapter 4 gives\nanother application of interval neutrosophic logic. A soft semantic Web\nServices agent framework is proposed to faciliate the registration and\ndiscovery of high quality semantic Web Services agent. The intelligent\ninference engine module of soft Semantic Web Services agent is implemented\nusing interval neutrosophic logic."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-1(1:6)2005", 
    "link": "http://arxiv.org/pdf/cs/0505023v1", 
    "title": "State Space Computation and Analysis of Time Petri Nets", 
    "arxiv-id": "cs/0505023v1", 
    "author": "Olivier F. Roux", 
    "publish": "2005-05-10T13:30:16Z", 
    "summary": "The theory of Petri Nets provides a general framework to specify the\nbehaviors of real-time reactive systems and Time Petri Nets were introduced to\ntake also temporal specifications into account. We present in this paper a\nforward zone-based algorithm to compute the state space of a bounded Time Petri\nNet: the method is different and more efficient than the classical State Class\nGraph. We prove the algorithm to be exact with respect to the reachability\nproblem. Furthermore, we propose a translation of the computed state space into\na Timed Automaton, proved to be timed bisimilar to the original Time Petri Net.\nAs the method produce a single Timed Automaton, syntactical clocks reduction\nmethods (Daws and Yovine for instance) may be applied to produce an automaton\nwith fewer clocks. Then, our method allows to model-check TTPN by the use of\nefficient Timed Automata tools.\n  To appear in Theory and Practice of Logic Programming (TPLP)."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-1(1:6)2005", 
    "link": "http://arxiv.org/pdf/cs/0505024v1", 
    "title": "Logic Column 12: Logical Verification and Equational Verification", 
    "arxiv-id": "cs/0505024v1", 
    "author": "Riccardo Pucella", 
    "publish": "2005-05-10T14:49:13Z", 
    "summary": "This article examines two approaches to verification, one based on using a\nlogic for expressing properties of a system, and one based on showing the\nsystem equivalent to a simpler system that obviously has whatever property is\nof interest. Using examples such as process calculi and regular programs, the\nrelationship between these two approaches is explored."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-1(1:6)2005", 
    "link": "http://arxiv.org/pdf/cs/0505025v1", 
    "title": "Equivalence-Checking on Infinite-State Systems: Techniques and Results", 
    "arxiv-id": "cs/0505025v1", 
    "author": "Petr Jancar", 
    "publish": "2005-05-10T16:47:11Z", 
    "summary": "The paper presents a selection of recently developed and/or used techniques\nfor equivalence-checking on infinite-state systems, and an up-to-date overview\nof existing results (as of September 2004)."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-1(1:6)2005", 
    "link": "http://arxiv.org/pdf/cs/0505026v1", 
    "title": "Automatic Verification of Timed Concurrent Constraint Programs", 
    "arxiv-id": "cs/0505026v1", 
    "author": "Alicia Villanueva", 
    "publish": "2005-05-11T11:33:52Z", 
    "summary": "The language Timed Concurrent Constraint (tccp) is the extension over time of\nthe Concurrent Constraint Programming (cc) paradigm that allows us to specify\nconcurrent systems where timing is critical, for example reactive systems.\nSystems which may have an infinite number of states can be specified in tccp.\nModel checking is a technique which is able to verify finite-state systems with\na huge number of states in an automatic way. In the last years several studies\nhave investigated how to extend model checking techniques to systems with an\ninfinite number of states. In this paper we propose an approach which exploits\nthe computation model of tccp. Constraint based computations allow us to define\na methodology for applying a model checking algorithm to (a class of)\ninfinite-state systems. We extend the classical algorithm of model checking for\nLTL to a specific logic defined for the verification of tccp and to the tccp\nStructure which we define in this work for modeling the program behavior. We\ndefine a restriction on the time in order to get a finite model and then we\ndevelop some illustrative examples. To the best of our knowledge this is the\nfirst approach that defines a model checking methodology for tccp."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-1(1:6)2005", 
    "link": "http://arxiv.org/pdf/cs/0505033v1", 
    "title": "Parametric Verification of a Group Membership Algorithm", 
    "arxiv-id": "cs/0505033v1", 
    "author": "Agathe Merceron", 
    "publish": "2005-05-12T07:52:36Z", 
    "summary": "We address the problem of verifying clique avoidance in the TTP protocol. TTP\nallows several stations embedded in a car to communicate. It has many\nmechanisms to ensure robustness to faults. In particular, it has an algorithm\nthat allows a station to recognize itself as faulty and leave the\ncommunication. This algorithm must satisfy the crucial 'non-clique' property:\nit is impossible to have two or more disjoint groups of stations communicating\nexclusively with stations in their own group.\n  In this paper, we propose an automatic verification method for an arbitrary\nnumber of stations $N$ and a given number of faults $k$. We give an abstraction\nthat allows to model the algorithm by means of unbounded (parametric) counter\nautomata. We have checked the non-clique property on this model in the case of\none fault, using the ALV tool as well as the LASH tool."
},{
    "category": "cs.LO", 
    "doi": "10.1007/11541868_16", 
    "link": "http://arxiv.org/pdf/cs/0505034v2", 
    "title": "Essential Incompleteness of Arithmetic Verified by Coq", 
    "arxiv-id": "cs/0505034v2", 
    "author": "Russell O'Connor", 
    "publish": "2005-05-12T17:31:25Z", 
    "summary": "A constructive proof of the Goedel-Rosser incompleteness theorem has been\ncompleted using the Coq proof assistant. Some theory of classical first-order\nlogic over an arbitrary language is formalized. A development of primitive\nrecursive functions is given, and all primitive recursive functions are proved\nto be representable in a weak axiom system. Formulas and proofs are encoded as\nnatural numbers, and functions operating on these codes are proved to be\nprimitive recursive. The weak axiom system is proved to be essentially\nincomplete. In particular, Peano arithmetic is proved to be consistent in Coq's\ntype theory and therefore is incomplete."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-1(2:1)2005", 
    "link": "http://arxiv.org/pdf/cs/0505037v6", 
    "title": "General Recursion via Coinductive Types", 
    "arxiv-id": "cs/0505037v6", 
    "author": "Venanzio Capretta", 
    "publish": "2005-05-13T15:22:57Z", 
    "summary": "A fertile field of research in theoretical computer science investigates the\nrepresentation of general recursive functions in intensional type theories.\nAmong the most successful approaches are: the use of wellfounded relations,\nimplementation of operational semantics, formalization of domain theory, and\ninductive definition of domain predicates. Here, a different solution is\nproposed: exploiting coinductive types to model infinite computations. To every\ntype A we associate a type of partial elements Partial(A), coinductively\ngenerated by two constructors: the first, return(a) just returns an element\na:A; the second, step(x), adds a computation step to a recursive element\nx:Partial(A). We show how this simple device is sufficient to formalize all\nrecursive functions between two given types. It allows the definition of fixed\npoints of finitary, that is, continuous, operators. We will compare this\napproach to different ones from the literature. Finally, we mention that the\nformalization, with appropriate structural maps, defines a strong monad."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(1:4)2006", 
    "link": "http://arxiv.org/pdf/cs/0505063v4", 
    "title": "Approximate reasoning for real-time probabilistic processes", 
    "arxiv-id": "cs/0505063v4", 
    "author": "Prakash Panangaden", 
    "publish": "2005-05-24T14:05:01Z", 
    "summary": "We develop a pseudo-metric analogue of bisimulation for generalized\nsemi-Markov processes. The kernel of this pseudo-metric corresponds to\nbisimulation; thus we have extended bisimulation for continuous-time\nprobabilistic processes to a much broader class of distributions than\nexponential distributions. This pseudo-metric gives a useful handle on\napproximate reasoning in the presence of numerical information -- such as\nprobabilities and time -- in the model. We give a fixed point characterization\nof the pseudo-metric. This makes available coinductive reasoning principles for\nreasoning about distances. We demonstrate that our approach is insensitive to\npotentially ad hoc articulations of distance by showing that it is intrinsic to\nan underlying uniformity. We provide a logical characterization of this\nuniformity using a real-valued modal logic. We show that several quantitative\nproperties of interest are continuous with respect to the pseudo-metric. Thus,\nif two processes are metrically close, then observable quantitative properties\nof interest are indeed close."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(1:4)2006", 
    "link": "http://arxiv.org/pdf/cs/0505087v1", 
    "title": "Feasible Proofs of Matrix Properties with Csanky's Algorithm", 
    "arxiv-id": "cs/0505087v1", 
    "author": "Michael Soltys", 
    "publish": "2005-05-31T11:13:59Z", 
    "summary": "We show that Csanky's fast parallel algorithm for computing the\ncharacteristic polynomial of a matrix can be formalized in the logical theory\nLAP, and can be proved correct in LAP from the principle of linear\nindependence. LAP is a natural theory for reasoning about linear algebra\nintroduced by Cook and Soltys. Further, we show that several principles of\nmatrix algebra, such as linear independence or the Cayley-Hamilton Theorem, can\nbe shown equivalent in the logical theory QLA. Applying the separation between\ncomplexity classes AC^0[2] contained in DET(GF(2)), we show that these\nprinciples are in fact not provable in QLA. In a nutshell, we show that linear\nindependence is ``all there is'' to elementary linear algebra (from a proof\ncomplexity point of view), and furthermore, linear independence cannot be\nproved trivially (again, from a proof complexity point of view)."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(1:4)2006", 
    "link": "http://arxiv.org/pdf/cs/0506008v1", 
    "title": "Bounds on the Automata Size for Presburger Arithmetic", 
    "arxiv-id": "cs/0506008v1", 
    "author": "Felix Klaedtke", 
    "publish": "2005-06-02T15:11:58Z", 
    "summary": "Automata provide a decision procedure for Presburger arithmetic. However,\nuntil now only crude lower and upper bounds were known on the sizes of the\nautomata produced by this approach. In this paper, we prove an upper bound on\nthe the number of states of the minimal deterministic automaton for a\nPresburger arithmetic formula. This bound depends on the length of the formula\nand the quantifiers occurring in the formula. The upper bound is established by\ncomparing the automata for Presburger arithmetic formulas with the formulas\nproduced by a quantifier elimination method. We also show that our bound is\ntight, even for nondeterministic automata. Moreover, we provide optimal\nautomata constructions for linear equations and inequations."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(1:4)2006", 
    "link": "http://arxiv.org/pdf/cs/0506014v1", 
    "title": "The Equivalence Problem for Deterministic MSO Tree Transducers is   Decidable", 
    "arxiv-id": "cs/0506014v1", 
    "author": "Sebastian Maneth", 
    "publish": "2005-06-06T07:05:11Z", 
    "summary": "It is decidable for deterministic MSO definable graph-to-string or\ngraph-to-tree transducers whether they are equivalent on a context-free set of\ngraphs."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(1:4)2006", 
    "link": "http://arxiv.org/pdf/cs/0506060v2", 
    "title": "Yet another normalisation proof for Martin-Lof's logical   framework--Terms with correct arities are strongly normalising", 
    "arxiv-id": "cs/0506060v2", 
    "author": "Yong Luo", 
    "publish": "2005-06-14T12:13:22Z", 
    "summary": "In this paper, we prove the strong normalisation for Martin-L\\\"{o}f's Logical\nFramework, and suggest that {}``correct arity'', a condition weaker than\nwell-typedness, will also guarantee the strong normalisation."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(1:4)2006", 
    "link": "http://arxiv.org/pdf/cs/0506084v1", 
    "title": "The One Page Model Checker", 
    "arxiv-id": "cs/0506084v1", 
    "author": "Jason E. Holt", 
    "publish": "2005-06-22T20:54:08Z", 
    "summary": "We show how standard IPC mechanisms can be used with the fork() system call\nto perform explicit state model checking on all interleavings of a\nmultithreaded application. We specifically show how to check for deadlock and\nrace conditions in programs with two threads. Our techniques are easy to apply\nto other languages, and require only the most rudimentary parsing of the target\nlanguage. Our fundamental system fits in one page of C code."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(1:4)2006", 
    "link": "http://arxiv.org/pdf/cs/0507064v1", 
    "title": "Termination of rewriting strategies: a generic approach", 
    "arxiv-id": "cs/0507064v1", 
    "author": "Helene Kirchner", 
    "publish": "2005-07-26T20:18:14Z", 
    "summary": "We propose a generic termination proof method for rewriting under strategies,\nbased on an explicit induction on the termination property. Rewriting trees on\nground terms are modeled by proof trees, generated by alternatively applying\nnarrowing and abstracting steps. The induction principle is applied through the\nabstraction mechanism, where terms are replaced by variables representing any\nof their normal forms. The induction ordering is not given a priori, but\ndefined with ordering constraints, incrementally set during the proof.\nAbstraction constraints can be used to control the narrowing mechanism, well\nknown to easily diverge. The generic method is then instantiated for the\ninnermost, outermost and local strategies."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(1:2)2006", 
    "link": "http://arxiv.org/pdf/cs/0508003v5", 
    "title": "Model Checking Probabilistic Pushdown Automata", 
    "arxiv-id": "cs/0508003v5", 
    "author": "Richard Mayr", 
    "publish": "2005-07-31T18:33:43Z", 
    "summary": "We consider the model checking problem for probabilistic pushdown automata\n(pPDA) and properties expressible in various probabilistic logics. We start\nwith properties that can be formulated as instances of a generalized random\nwalk problem. We prove that both qualitative and quantitative model checking\nfor this class of properties and pPDA is decidable. Then we show that model\nchecking for the qualitative fragment of the logic PCTL and pPDA is also\ndecidable. Moreover, we develop an error-tolerant model checking algorithm for\nPCTL and the subclass of stateless pPDA. Finally, we consider the class of\nomega-regular properties and show that both qualitative and quantitative model\nchecking for pPDA is decidable."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(1:2)2006", 
    "link": "http://arxiv.org/pdf/cs/0508004v1", 
    "title": "A three-valued semantics for logic programmers", 
    "arxiv-id": "cs/0508004v1", 
    "author": "Lee Naish", 
    "publish": "2005-08-01T05:23:44Z", 
    "summary": "This paper describes a simpler way for programmers to reason about the\ncorrectness of their code. The study of semantics of logic programs has shown\nstrong links between the model theoretic semantics (truth and falsity of atoms\nin the programmer's interpretation of a program), procedural semantics (for\nexample, SLD resolution) and fixpoint semantics (which is useful for program\nanalysis and alternative execution mechanisms). Most of this work assumes that\nintended interpretations are two-valued: a ground atom is true (and should\nsucceed according to the procedural semantics) or false (and should not\nsucceed). In reality, intended interpretations are less precise. Programmers\nconsider that some atoms \"should not occur\" or are \"ill-typed\" or\n\"inadmissible\". Programmers don't know and don't care whether such atoms\nsucceed. In this paper we propose a three-valued semantics for (essentially)\npure Prolog programs with (ground) negation as failure which reflects this. The\nsemantics of Fitting is similar but only associates the third truth value with\nnon-termination. We provide tools to reason about correctness of programs\nwithout the need for unnatural precision or undue restrictions on programming\nstyle. As well as theoretical results, we provide a programmer-oriented\nsynopsis. This work has come out of work on declarative debugging, where it has\nbeen recognised that inadmissible calls are important. This paper has been\naccepted to appear in Theory and Practice of Logic Programming."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(1:2)2006", 
    "link": "http://arxiv.org/pdf/cs/0508005v1", 
    "title": "Logic Column 13: Reasoning Formally about Quantum Systems: An Overview", 
    "arxiv-id": "cs/0508005v1", 
    "author": "Nick Papanikolaou", 
    "publish": "2005-08-01T14:34:27Z", 
    "summary": "This article is intended as an introduction to the subject of quantum logic,\nand as a brief survey of the relevant literature. Also discussed here are\nlogics for specification and analysis of quantum information systems, in\nparticular, recent work by P. Mateus and A. Sernadas, and also by R. van der\nMeyden and M. Patra. Overall, our objective is to provide a high-level\npresentation of the logical aspects of quantum theory. Mateus' and Sernadas'\nEQPL logic is illustrated with a small example, namely the state of an\nentangled pair of qubits. The \"KT\" logic of van der Meyden and Patra is\ndemonstrated briefly in the context of the B92 protocol for quantum key\ndistribution."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-1(2:6)2005", 
    "link": "http://arxiv.org/pdf/cs/0508044v5", 
    "title": "Deciding Quantifier-Free Presburger Formulas Using Parameterized   Solution Bounds", 
    "arxiv-id": "cs/0508044v5", 
    "author": "Randal E. Bryant", 
    "publish": "2005-08-05T11:09:32Z", 
    "summary": "Given a formula in quantifier-free Presburger arithmetic, if it has a\nsatisfying solution, there is one whose size, measured in bits, is polynomially\nbounded in the size of the formula. In this paper, we consider a special class\nof quantifier-free Presburger formulas in which most linear constraints are\ndifference (separation) constraints, and the non-difference constraints are\nsparse. This class has been observed to commonly occur in software\nverification. We derive a new solution bound in terms of parameters\ncharacterizing the sparseness of linear constraints and the number of\nnon-difference constraints, in addition to traditional measures of formula\nsize. In particular, we show that the number of bits needed per integer\nvariable is linear in the number of non-difference constraints and logarithmic\nin the number and size of non-zero coefficients in them, but is otherwise\nindependent of the total number of linear constraints in the formula. The\nderived bound can be used in a decision procedure based on instantiating\ninteger variables over a finite domain and translating the input\nquantifier-free Presburger formula to an equi-satisfiable Boolean formula,\nwhich is then checked using a Boolean satisfiability solver. In addition to our\nmain theoretical result, we discuss several optimizations for deriving tighter\nbounds in practice. Empirical evidence indicates that our decision procedure\ncan greatly outperform other decision procedures."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-1(2:6)2005", 
    "link": "http://arxiv.org/pdf/cs/0508112v1", 
    "title": "A study of set-sharing analysis via cliques", 
    "arxiv-id": "cs/0508112v1", 
    "author": "Manuel Hermenegildo", 
    "publish": "2005-08-25T04:10:56Z", 
    "summary": "We study the problem of efficient, scalable set-sharing analysis of logic\nprograms. We use the idea of representing sharing information as a pair of\nabstract substitutions, one of which is a worst-case sharing representation\ncalled a clique set, which was previously proposed for the case of inferring\npair-sharing. We use the clique-set representation for (1) inferring actual\nset-sharing information, and (2) analysis within a top-down framework. In\nparticular, we define the abstract functions required by standard top-down\nanalyses, both for sharing alone and also for the case of including freeness in\naddition to sharing. Our experimental evaluation supports the conclusion that,\nfor inferring set-sharing, as it was the case for inferring pair-sharing,\nprecision losses are limited, while useful efficiency gains are obtained. At\nthe limit, the clique-set representation allowed analyzing some programs that\nexceeded memory capacity using classical sharing representations."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-1(2:4)2005", 
    "link": "http://arxiv.org/pdf/cs/0509019v3", 
    "title": "Comparing hierarchies of total functionals", 
    "arxiv-id": "cs/0509019v3", 
    "author": "Dag Normann", 
    "publish": "2005-09-07T08:32:32Z", 
    "summary": "In this paper we consider two hierarchies of hereditarily total and\ncontinuous functionals over the reals based on one extensional and one\nintensional representation of real numbers, and we discuss under which\nasumptions these hierarchies coincide. This coincidense problem is equivalent\nto a statement about the topology of the Kleene-Kreisel continuous functionals.\nAs a tool of independent interest, we show that the Kleene-Kreisel functionals\nmay be embedded into both these hierarchies."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-1(2:4)2005", 
    "link": "http://arxiv.org/pdf/cs/0509024v2", 
    "title": "Well-founded and Stable Semantics of Logic Programs with Aggregates", 
    "arxiv-id": "cs/0509024v2", 
    "author": "Maurice Bruynooghe", 
    "publish": "2005-09-08T19:54:53Z", 
    "summary": "In this paper, we present a framework for the semantics and the computation\nof aggregates in the context of logic programming. In our study, an aggregate\ncan be an arbitrary interpreted second order predicate or function. We define\nextensions of the Kripke-Kleene, the well-founded and the stable semantics for\naggregate programs. The semantics is based on the concept of a three-valued\nimmediate consequence operator of an aggregate program. Such an operator\napproximates the standard two-valued immediate consequence operator of the\nprogram, and induces a unique Kripke-Kleene model, a unique well-founded model\nand a collection of stable models. We study different ways of defining such\noperators and thus obtain a framework of semantics, offering different\ntrade-offs between precision and tractability. In particular, we investigate\nconditions on the operator that guarantee that the computation of the three\ntypes of semantics remains on the same level as for logic programs without\naggregates. Other results show that, in practice, even efficient three-valued\nimmediate consequence operators which are very low in the precision hierarchy,\nstill provide optimal precision."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(2:3)2006", 
    "link": "http://arxiv.org/pdf/cs/0510010v2", 
    "title": "On the Expressiveness of the Ambient Logic", 
    "arxiv-id": "cs/0510010v2", 
    "author": "Davide Sangiorgi", 
    "publish": "2005-10-04T08:47:55Z", 
    "summary": "The Ambient Logic (AL) has been proposed for expressing properties of process\nmobility in the calculus of Mobile Ambients (MA), and as a basis for query\nlanguages on semistructured data. In this paper, we study the expressiveness of\nAL. We define formulas for capabilities and for communication in MA. We also\nderive some formulas that capture finitess of a term, name occurrences and\npersistence. We study extensions of the calculus involving more complex forms\nof communications, and we define characteristic formulas for the equivalence\ninduced by the logic on a subcalculus of MA. This subcalculus is defined by\nimposing an image-finiteness condition on the reducts of a MA process."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(2:3)2006", 
    "link": "http://arxiv.org/pdf/cs/0510012v2", 
    "title": "On relating CTL to Datalog", 
    "arxiv-id": "cs/0510012v2", 
    "author": "Irene Guessarian", 
    "publish": "2005-10-04T17:29:48Z", 
    "summary": "CTL is the dominant temporal specification language in practice mainly due to\nthe fact that it admits model checking in linear time. Logic programming and\nthe database query language Datalog are often used as an implementation\nplatform for logic languages. In this paper we present the exact relation\nbetween CTL and Datalog and moreover we build on this relation and known\nefficient algorithms for CTL to obtain efficient algorithms for fragments of\nstratified Datalog. The contributions of this paper are: a) We embed CTL into\nSTD which is a proper fragment of stratified Datalog. Moreover we show that STD\nexpresses exactly CTL -- we prove that by embedding STD into CTL. Both\nembeddings are linear. b) CTL can also be embedded to fragments of Datalog\nwithout negation. We define a fragment of Datalog with the successor build-in\npredicate that we call TDS and we embed CTL into TDS in linear time. We build\non the above relations to answer open problems of stratified Datalog. We prove\nthat query evaluation is linear and that containment and satisfiability\nproblems are both decidable. The results presented in this paper are the first\nfor fragments of stratified Datalog that are more general than those containing\nonly unary EDBs."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(2:3)2006", 
    "link": "http://arxiv.org/pdf/cs/0510061v1", 
    "title": "Nonmonotonic Trust Management for P2P Applications", 
    "arxiv-id": "cs/0510061v1", 
    "author": "J. den Hartog", 
    "publish": "2005-10-21T11:46:56Z", 
    "summary": "Community decisions about access control in virtual communities are\nnon-monotonic in nature. This means that they cannot be expressed in current,\nmonotonic trust management languages such as the family of Role Based Trust\nManagement languages (RT). To solve this problem we propose RT-, which adds a\nrestricted form of negation to the standard RT language, thus admitting a\ncontrolled form of non-monotonicity. The semantics of RT- is discussed and\npresented in terms of the well-founded semantics for Logic Programs. Finally we\ndiscuss how chain discovery can be accomplished for RT-."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(2:2)2006", 
    "link": "http://arxiv.org/pdf/cs/0510066v3", 
    "title": "The monadic second-order logic of graphs XVI : Canonical graph<br>   decompositions", 
    "arxiv-id": "cs/0510066v3", 
    "author": "Bruno Courcelle", 
    "publish": "2005-10-22T13:09:38Z", 
    "summary": "This article establishes that the split decomposition of graphs introduced by\nCunnigham, is definable in Monadic Second-Order Logic.This result is actually\nan instance of a more general result covering canonical graph decompositions\nlike the modular decomposition and the Tutte decomposition of 2-connected\ngraphs into 3-connected components. As an application, we prove that the set of\ngraphs having the same cycle matroid as a given 2-connected graph can be\ndefined from this graph by Monadic Second-Order formulas."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(2:2)2006", 
    "link": "http://arxiv.org/pdf/cs/0510069v1", 
    "title": "Comparing Computational Power", 
    "arxiv-id": "cs/0510069v1", 
    "author": "Nachum Dershowitz", 
    "publish": "2005-10-23T16:51:02Z", 
    "summary": "It is common practice to compare the computational power of different models\nof computation. For example, the recursive functions are strictly more powerful\nthan the primitive recursive functions, because the latter are a proper subset\nof the former (which includes Ackermann's function). Side-by-side with this\n\"containment\" method of measuring power, it is standard to use an approach\nbased on \"simulation\". For example, one says that the (untyped) lambda calculus\nis as powerful--computationally speaking--as the partial recursive functions,\nbecause the lambda calculus can simulate all partial recursive functions by\nencoding the natural numbers as Church numerals.\n  The problem is that unbridled use of these two ways of comparing power allows\none to show that some computational models are strictly stronger than\nthemselves! We argue that a better definition is that model A is strictly\nstronger than B if A can simulate B via some encoding, whereas B cannot\nsimulate A under any encoding. We then show that the recursive functions are\nstrictly stronger in this sense than the primitive recursive. We also prove\nthat the recursive functions, partial recursive functions, and Turing machines\nare \"complete\", in the sense that no injective encoding can make them\nequivalent to any \"hypercomputational\" model."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(2:2)2006", 
    "link": "http://arxiv.org/pdf/cs/0510073v1", 
    "title": "Semantic Embedding of Petri Nets into Event-B", 
    "arxiv-id": "cs/0510073v1", 
    "author": "Christian Attiogbe", 
    "publish": "2005-10-24T09:17:30Z", 
    "summary": "We present an embedding of Petri nets into B abstract systems. The embedding\nis achieved by translating both the static structure (modelling aspect) and the\nevolution semantics of Petri nets. The static structure of a Petri-net is\ncaptured within a B abstract system through a graph structure. This abstract\nsystem is then included in another abstract system which captures the evolution\nsemantics of Petri-nets. The evolution semantics results in some B events\ndepending on the chosen policies: basic nets or high level Petri nets. The\ncurrent embedding enables one to use conjointly Petri nets and Event-B in the\nsame system development, but at different steps and for various analysis."
},{
    "category": "cs.LO", 
    "doi": "10.1017/S0960129508007172", 
    "link": "http://arxiv.org/pdf/cs/0511006v2", 
    "title": "Logical Relations for Monadic Types", 
    "arxiv-id": "cs/0511006v2", 
    "author": "David Nowak", 
    "publish": "2005-11-02T01:45:56Z", 
    "summary": "Logical relations and their generalizations are a fundamental tool in proving\nproperties of lambda-calculi, e.g., yielding sound principles for observational\nequivalence. We propose a natural notion of logical relations able to deal with\nthe monadic types of Moggi's computational lambda-calculus. The treatment is\ncategorical, and is based on notions of subsconing, mono factorization systems,\nand monad morphisms. Our approach has a number of interesting applications,\nincluding cases for lambda-calculi with non-determinism (where being in logical\nrelation means being bisimilar), dynamic name creation, and probabilistic\nsystems."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1297658.1297663", 
    "link": "http://arxiv.org/pdf/cs/0511023v3", 
    "title": "Verifying nondeterministic probabilistic channel systems against   $\u03c9$-regular linear-time properties", 
    "arxiv-id": "cs/0511023v3", 
    "author": "Philippe Schnoebelen", 
    "publish": "2005-11-04T17:03:45Z", 
    "summary": "Lossy channel systems (LCSs) are systems of finite state automata that\ncommunicate via unreliable unbounded fifo channels. In order to circumvent the\nundecidability of model checking for nondeterministic\n  LCSs, probabilistic models have been introduced, where it can be decided\nwhether a linear-time property holds almost surely. However, such fully\nprobabilistic systems are not a faithful model of nondeterministic protocols.\n  We study a hybrid model for LCSs where losses of messages are seen as faults\noccurring with some given probability, and where the internal behavior of the\nsystem remains nondeterministic. Thus the semantics is in terms of\ninfinite-state Markov decision processes. The purpose of this article is to\ndiscuss the decidability of linear-time properties formalized by formulas of\nlinear temporal logic (LTL). Our focus is on the qualitative setting where one\nasks, e.g., whether a LTL-formula holds almost surely or with zero probability\n(in case the formula describes the bad behaviors). Surprisingly, it turns out\nthat -- in contrast to finite-state Markov decision processes -- the\nsatisfaction relation for LTL formulas depends on the chosen type of schedulers\nthat resolve the nondeterminism. While all variants of the qualitative LTL\nmodel checking problem for the full class of history-dependent schedulers are\nundecidable, the same questions for finite-memory scheduler can be solved\nalgorithmically. However, the restriction to reachability properties and\nspecial kinds of recurrent reachability properties yields decidable\nverification problems for the full class of schedulers, which -- for this\nrestricted class of properties -- are as powerful as finite-memory schedulers,\nor even a subclass of them."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1297658.1297663", 
    "link": "http://arxiv.org/pdf/cs/0511025v1", 
    "title": "Logic Column 14: Nominal Logic and Abstract Syntax", 
    "arxiv-id": "cs/0511025v1", 
    "author": "James Cheney", 
    "publish": "2005-11-05T02:47:50Z", 
    "summary": "Formalizing syntactic proofs of properties of logics, programming languages,\nsecurity protocols, and other formal systems is a significant challenge, in\nlarge part because of the obligation to handle name-binding correctly. We\npresent an approach called nominal abstract syntax that has attracted\nconsiderable interest since its introduction approximately six years ago. After\nan overview of other approaches, we describe nominal abstract syntax and\nnominal logic, a logic for reasoning about nominal abstract syntax. We also\ndiscuss applications of nominal techniques to programming, automated reasoning,\nand identify some future directions."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1297658.1297663", 
    "link": "http://arxiv.org/pdf/cs/0511041v1", 
    "title": "Logic Programming with Default, Weak and Strict Negations", 
    "arxiv-id": "cs/0511041v1", 
    "author": "Susumu Yamasaki", 
    "publish": "2005-11-10T06:29:46Z", 
    "summary": "This paper treats logic programming with three kinds of negation: default,\nweak and strict negations. A 3-valued logic model theory is discussed for logic\nprograms with three kinds of negation. The procedure is constructed for\nnegations so that a soundness of the procedure is guaranteed in terms of\n3-valued logic model theory."
},{
    "category": "cs.LO", 
    "doi": "10.1017/S147106840600277", 
    "link": "http://arxiv.org/pdf/cs/0511055v1", 
    "title": "Embedding Defeasible Logic into Logic Programming", 
    "arxiv-id": "cs/0511055v1", 
    "author": "Michael J. Maher", 
    "publish": "2005-11-15T10:39:38Z", 
    "summary": "Defeasible reasoning is a simple but efficient approach to nonmonotonic\nreasoning that has recently attracted considerable interest and that has found\nvarious applications. Defeasible logic and its variants are an important family\nof defeasible reasoning methods. So far no relationship has been established\nbetween defeasible logic and mainstream nonmonotonic reasoning approaches.\n  In this paper we establish close links to known semantics of logic programs.\nIn particular, we give a translation of a defeasible theory D into a\nmeta-program P(D). We show that under a condition of decisiveness, the\ndefeasible consequences of D correspond exactly to the sceptical conclusions of\nP(D) under the stable model semantics. Without decisiveness, the result holds\nonly in one direction (all defeasible consequences of D are included in all\nstable models of P(D)). If we wish a complete embedding for the general case,\nwe need to use the Kunen semantics of P(D), instead."
},{
    "category": "cs.LO", 
    "doi": "10.1017/S147106840600277", 
    "link": "http://arxiv.org/pdf/cs/0511061v1", 
    "title": "Truly On-The-Fly LTL Model Checking", 
    "arxiv-id": "cs/0511061v1", 
    "author": "Stephan Merz", 
    "publish": "2005-11-16T12:56:17Z", 
    "summary": "We propose a novel algorithm for automata-based LTL model checking that\ninterleaves the construction of the generalized B\\\"{u}chi automaton for the\nnegation of the formula and the emptiness check. Our algorithm first converts\nthe LTL formula into a linear weak alternating automaton; configurations of the\nalternating automaton correspond to the locations of a generalized B\\\"{u}chi\nautomaton, and a variant of Tarjan's algorithm is used to decide the existence\nof an accepting run of the product of the transition system and the automaton.\nBecause we avoid an explicit construction of the B\\\"{u}chi automaton, our\napproach can yield significant improvements in runtime and memory, for large\nLTL formulas. The algorithm has been implemented within the SPIN model checker,\nand we present experimental results for some benchmark examples."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-1(3:4)2005", 
    "link": "http://arxiv.org/pdf/cs/0511097v3", 
    "title": "Modularizing the Elimination of r=0 in Kleene Algebra", 
    "arxiv-id": "cs/0511097v3", 
    "author": "Christopher Hardin", 
    "publish": "2005-11-28T19:15:39Z", 
    "summary": "Given a universal Horn formula of Kleene algebra with hypotheses of the form\nr = 0, it is already known that we can efficiently construct an equation which\nis valid if and only if the Horn formula is valid. This is an example of\n<i>elimination of hypotheses</i>, which is useful because the equational theory\nof Kleene algebra is decidable while the universal Horn theory is not. We show\nthat hypotheses of the form r = 0 can still be eliminated in the presence of\nother hypotheses. This lets us extend any technique for eliminating hypotheses\nto include hypotheses of the form r = 0."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-1(3:3)2005", 
    "link": "http://arxiv.org/pdf/cs/0512009v3", 
    "title": "Almost periodic functions, constructively", 
    "arxiv-id": "cs/0512009v3", 
    "author": "Bas Spitters", 
    "publish": "2005-12-02T11:30:12Z", 
    "summary": "The almost periodic functions form a natural example of a non-separable\nnormed space. As such, it has been a challenge for constructive mathematicians\nto find a natural treatment of them. Here we present a simple proof of Bohr's\nfundamental theorem for almost periodic functions which we then generalize to\nalmost periodic functions on general topological groups."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(1:6)2006", 
    "link": "http://arxiv.org/pdf/cs/0512012v3", 
    "title": "Extending the theory of Owicki and Gries with a logic of progress", 
    "arxiv-id": "cs/0512012v3", 
    "author": "Doug Goldson", 
    "publish": "2005-12-03T01:04:16Z", 
    "summary": "This paper describes a logic of progress for concurrent programs. The logic\nis based on that of UNITY, molded to fit a sequential programming model.\nIntegration of the two is achieved by using auxiliary variables in a systematic\nway that incorporates program counters into the program text. The rules for\nprogress in UNITY are then modified to suit this new system. This modification\nis however subtle enough to allow the theory of Owicki and Gries to be used\nwithout change."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(1:6)2006", 
    "link": "http://arxiv.org/pdf/cs/0512031v2", 
    "title": "Alternating Timed Automata", 
    "arxiv-id": "cs/0512031v2", 
    "author": "Igor Walukiewicz", 
    "publish": "2005-12-08T08:50:35Z", 
    "summary": "A notion of alternating timed automata is proposed. It is shown that such\nautomata with only one clock have decidable emptiness problem over finite\nwords. This gives a new class of timed languages which is closed under boolean\noperations and which has an effective presentation. We prove that the\ncomplexity of the emptiness problem for alternating timed automata with one\nclock is non-primitive recursive. The proof gives also the same lower bound for\nthe universality problem for nondeterministic timed automata with one clock. We\ninvestigate extension of the model with epsilon-transitions and prove that\nemptiness is undecidable. Over infinite words, we show undecidability of the\nuniversality problem."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(2:4)2006", 
    "link": "http://arxiv.org/pdf/cs/0512036v2", 
    "title": "A System of Interaction and Structure II: The Need for Deep Inference", 
    "arxiv-id": "cs/0512036v2", 
    "author": "Alwen Tiu", 
    "publish": "2005-12-09T16:36:54Z", 
    "summary": "This paper studies properties of the logic BV, which is an extension of\nmultiplicative linear logic (MLL) with a self-dual non-commutative operator. BV\nis presented in the calculus of structures, a proof theoretic formalism that\nsupports deep inference, in which inference rules can be applied anywhere\ninside logical expressions. The use of deep inference results in a simple\nlogical system for MLL extended with the self-dual non-commutative operator,\nwhich has been to date not known to be expressible in sequent calculus. In this\npaper, deep inference is shown to be crucial for the logic BV, that is, any\nrestriction on the ``depth'' of the inference rules of BV would result in a\nstrictly less expressive logical system."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(2:4)2006", 
    "link": "http://arxiv.org/pdf/cs/0512082v1", 
    "title": "A Fixpoint Semantics of Event Systems with and without Fairness   Assumptions", 
    "arxiv-id": "cs/0512082v1", 
    "author": "Didier Bert", 
    "publish": "2005-12-21T08:23:05Z", 
    "summary": "We present a fixpoint semantics of event systems. The semantics is presented\nin a general framework without concerns of fairness. Soundness and completeness\nof rules for deriving \"leads-to\" properties are proved in this general\nframework. The general framework is instantiated to minimal progress and weak\nfairness assumptions and similar results are obtained. We show the power of\nthese results by deriving sufficient conditions for \"leads-to\" under minimal\nprogress proving soundness of proof obligations without reasoning over\nstate-traces."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(2:4)2006", 
    "link": "http://arxiv.org/pdf/cs/0512086v3", 
    "title": "On the Axiomatisation of Boolean Categories with and without Medial", 
    "arxiv-id": "cs/0512086v3", 
    "author": "Lutz Strassburger", 
    "publish": "2005-12-22T17:43:53Z", 
    "summary": "The term ``Boolean category'' should be used for describing an object that is\nto categories what a Boolean algebra is to posets. More specifically, a Boolean\ncategory should provide the abstract algebraic structure underlying the proofs\nin Boolean Logic, in the same sense as a Cartesian closed category captures the\nproofs in intuitionistic logic and a *-autonomous category captures the proofs\nin linear logic. However, recent work has shown that there is no canonical\naxiomatisation of a Boolean category. In this work, we will see a series (with\nincreasing strength) of possible such axiomatisations, all based on the notion\nof *-autonomous category. We will particularly focus on the medial map, which\nhas its origin in an inference rule in KS, a cut-free deductive system for\nBoolean logic in the calculus of structures. Finally, we will present a\ncategory of proof nets as a particularly well-behaved example of a Boolean\ncategory."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(2:4)2006", 
    "link": "http://arxiv.org/pdf/cs/0601008v2", 
    "title": "A Hierarchical Analysis of Propositional Temporal Logic Based on   Intervals", 
    "arxiv-id": "cs/0601008v2", 
    "author": "Ben Moszkowski", 
    "publish": "2006-01-05T18:35:38Z", 
    "summary": "We present a hierarchical framework for analysing propositional linear-time\ntemporal logic (PTL) to obtain standard results such as a small model property,\ndecision procedures and axiomatic completeness. Both finite time and infinite\ntime are considered and one consequent benefit of the framework is the ability\nto systematically reduce infinite-time reasoning to finite-time reasoning. The\ntreatment of PTL with both the operator Until and past time naturally reduces\nto that for PTL without either one. Our method utilises a low-level normal form\nfor PTL called a \"transition configuration\". In addition, we employ reasoning\nabout intervals of time. Besides being hierarchical and interval-based, the\napproach differs from other analyses of PTL typically based on sets of formulas\nand sequences of such sets. Instead we describe models using time intervals\nrepresented as finite and infinite sequences of states. The analysis relates\nlarger intervals with smaller ones. Steps involved are expressed in\nPropositional Interval Temporal Logic (PITL) which is better suited than PTL\nfor sequentially combining and decomposing formulas. Consequently, we can\narticulate issues in PTL model construction of equal relevance in more\nconventional analyses but normally only considered at the metalevel. We also\ndescribe a decision procedure based on Binary Decision Diagrams."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(2:4)2006", 
    "link": "http://arxiv.org/pdf/cs/0601018v1", 
    "title": "A comparison between two logical formalisms for rewriting", 
    "arxiv-id": "cs/0601018v1", 
    "author": "Miguel Palomino", 
    "publish": "2006-01-06T12:01:55Z", 
    "summary": "Meseguer's rewriting logic and the rewriting logic CRWL are two well-known\napproaches to rewriting as logical deduction that, despite some clear\nsimilarities, were designed with different objectives. Here we study the\nrelationships between them, both at a syntactic and at a semantic level. Even\nthough it is not possible to establish an entailment system map between them,\nboth can be naturally simulated in each other. Semantically, there is no\nembedding between the corresponding institutions. Along the way, the notions of\nentailment and satisfaction in Meseguer's rewriting logic are generalized. We\nalso use the syntactic results to prove reflective properties of CRWL."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(2:4)2006", 
    "link": "http://arxiv.org/pdf/cs/0601096v1", 
    "title": "On timed automata with input-determined guards", 
    "arxiv-id": "cs/0601096v1", 
    "author": "Nicolas Tabareau", 
    "publish": "2006-01-23T10:45:25Z", 
    "summary": "We consider a general notion of timed automata with input-determined guards\nand show that they admit a robust logical framework along the lines of [D\n'Souza03], in terms of a monadic second order logic characterisation and an\nexpressively complete timed temporal logic. We then generalize these automata\nusing the notion of recursive operators introduced by Henzinger, Raskin, and\nSchobbens, and show that they admit a similar logical framework. These results\nhold in the ``pointwise'' semantics. We finally use this framework to show that\nthe real-time logic MITL of Alur et al is expressively complete with respect to\nan MSO corresponding to an appropriate input-determined operator."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(4:4)2006", 
    "link": "http://arxiv.org/pdf/cs/0601134v4", 
    "title": "Combining decision procedures for the reals", 
    "arxiv-id": "cs/0601134v4", 
    "author": "Harvey Friedman", 
    "publish": "2006-01-31T14:48:05Z", 
    "summary": "<p>We address the general problem of determining the validity of boolean\ncombinations of equalities and inequalities between real-valued expressions. In\nparticular, we consider methods of establishing such assertions using only\nrestricted forms of distributivity. At the same time, we explore ways in which\n\"local\" decision or heuristic procedures for fragments of the theory of the\nreals can be amalgamated into global ones. </p> <p>Let <em>Tadd[Q]</em> be the\nfirst-order theory of the real numbers in the language of ordered groups, with\nnegation, a constant <em>1</em>, and function symbols for multiplication by\nrational constants. Let <em>Tmult[Q]</em> be the analogous theory for the\nmultiplicative structure, and let <em>T[Q]</em> be the union of the two. We\nshow that although <em>T[Q]</em> is undecidable, the universal fragment of\n<em>T[Q]</em> is decidable. We also show that terms of <em>T[Q]</em>can\nfruitfully be put in a normal form. We prove analogous results for theories in\nwhich <em>Q</em> is replaced, more generally, by suitable subfields <em>F</em>\nof the reals. Finally, we consider practical methods of establishing\nquantifier-free validities that approximate our (impractical) decidability\nresults.</p>"
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(1:5)2006", 
    "link": "http://arxiv.org/pdf/cs/0602024v4", 
    "title": "Algorithmic correspondence and completeness in modal logic. I. The core   algorithm SQEMA", 
    "arxiv-id": "cs/0602024v4", 
    "author": "Dimiter Vakarelov", 
    "publish": "2006-02-07T10:10:12Z", 
    "summary": "Modal formulae express monadic second-order properties on Kripke frames, but\nin many important cases these have first-order equivalents. Computing such\nequivalents is important for both logical and computational reasons. On the\nother hand, canonicity of modal formulae is important, too, because it implies\nframe-completeness of logics axiomatized with canonical formulae.\n  Computing a first-order equivalent of a modal formula amounts to elimination\nof second-order quantifiers. Two algorithms have been developed for\nsecond-order quantifier elimination: SCAN, based on constraint resolution, and\nDLS, based on a logical equivalence established by Ackermann.\n  In this paper we introduce a new algorithm, SQEMA, for computing first-order\nequivalents (using a modal version of Ackermann's lemma) and, moreover, for\nproving canonicity of modal formulae. Unlike SCAN and DLS, it works directly on\nmodal formulae, thus avoiding Skolemization and the subsequent problem of\nunskolemization. We present the core algorithm and illustrate it with some\nexamples. We then prove its correctness and the canonicity of all formulae on\nwhich the algorithm succeeds. We show that it succeeds not only on all\nSahlqvist formulae, but also on the larger class of inductive formulae,\nintroduced in our earlier papers. Thus, we develop a purely algorithmic\napproach to proving canonical completeness in modal logic and, in particular,\nestablish one of the most general completeness results in modal logic so far."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1067915.1067918", 
    "link": "http://arxiv.org/pdf/cs/0602040v1", 
    "title": "PLTL Partitioned Model Checking for Reactive Systems under Fairness   Assumptions", 
    "arxiv-id": "cs/0602040v1", 
    "author": "Fran\u00e7oise Bellegarde", 
    "publish": "2006-02-10T14:48:29Z", 
    "summary": "We are interested in verifying dynamic properties of finite state reactive\nsystems under fairness assumptions by model checking. The systems we want to\nverify are specified through a top-down refinement process. In order to deal\nwith the state explosion problem, we have proposed in previous works to\npartition the reachability graph, and to perform the verification on each part\nseparately. Moreover, we have defined a class, called Bmod, of dynamic\nproperties that are verifiable by parts, whatever the partition. We decide if a\nproperty P belongs to Bmod by looking at the form of the Buchi automaton that\naccepts the negation of P. However, when a property P belongs to Bmod, the\nproperty f => P, where f is a fairness assumption, does not necessarily belong\nto Bmod. In this paper, we propose to use the refinement process in order to\nbuild the parts on which the verification has to be performed. We then show\nthat with such a partition, if a property P is verifiable by parts and if f is\nthe expression of the fairness assumptions on a system, then the property f =>\nP is still verifiable by parts. This approach is illustrated by its application\nto the chip card protocol T=1 using the B engineering design language."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1067915.1067918", 
    "link": "http://arxiv.org/pdf/cs/0602077v1", 
    "title": "Bisimulations of enrichments", 
    "arxiv-id": "cs/0602077v1", 
    "author": "Krzysztof Worytkiewicz", 
    "publish": "2006-02-21T17:27:27Z", 
    "summary": "In this paper we show that classical notions from automata theory such as\nsimulation and bisimulation can be lifted to the context of enriched\ncategories. The usual properties of bisimulation are nearly all preserved in\nthis new context. The class of enriched functors that correspond to functionnal\nbisimulations surjective on objects is investigated and appears \"nearly\" open\nin the sense of Joyal and Moerdijk. Seeing the change of base techniques as a\nconvenient means to define process refinement/abstractions, we give sufficient\nconditions for the change of base categories to preserve bisimularity. We apply\nthese concepts to Betti's generalized automata, categorical transition systems,\nand other exotic categories."
},{
    "category": "cs.LO", 
    "doi": "10.1093/logcom/exi030", 
    "link": "http://arxiv.org/pdf/cs/0603006v4", 
    "title": "Pivotal and Pivotal-discriminative Consequence Relations", 
    "arxiv-id": "cs/0603006v4", 
    "author": "Jonathan Ben-Naim", 
    "publish": "2006-03-01T15:15:46Z", 
    "summary": "In the present paper, we investigate consequence relations that are both\nparaconsistent and plausible (but still monotonic). More precisely, we put the\nfocus on pivotal consequence relations, i.e. those relations that can be\ndefined by a pivot (in the style of e.g. D. Makinson). A pivot is a fixed\nsubset of valuations which are considered to be the important ones in the\nabsolute sense. We worked with a general notion of valuation that covers e.g.\nthe classical valuations as well as certain kinds of many-valued valuations. In\nthe many-valued cases, pivotal consequence relations are paraconsistant (in\naddition to be plausible), i.e. they are capable of drawing reasonable\nconclusions which contain contradictions. We will provide in our general\nframework syntactic characterizations of several families of pivotal relations.\nIn addition, we will provide, again in our general framework, characterizations\nof several families of pivotal discriminative consequence relations. The latter\nare defined exactly as the plain version, but contradictory conclusions are\nrejected. We will also answer negatively a representation problem that was left\nopen by Makinson. Finally, we will put in evidence a connexion with X-logics\nfrom Forget, Risch, and Siegel. The motivations and the framework of the\npresent paper are very close to those of a previous paper of the author which\nis about preferential consequence relations."
},{
    "category": "cs.LO", 
    "doi": "10.1093/logcom/exi030", 
    "link": "http://arxiv.org/pdf/cs/0603104v1", 
    "title": "Verification of Ptime reducibility for system F terms via Dual Light   Affine Logic", 
    "arxiv-id": "cs/0603104v1", 
    "author": "Kazushige Terui", 
    "publish": "2006-03-27T09:14:01Z", 
    "summary": "In a previous work we introduced Dual Light Affine Logic (DLAL)\n([BaillotTerui04]) as a variant of Light Linear Logic suitable for guaranteeing\ncomplexity properties on lambda-calculus terms: all typable terms can be\nevaluated in polynomial time and all Ptime functions can be represented. In the\npresent work we address the problem of typing lambda-terms in second-order\nDLAL. For that we give a procedure which, starting with a term typed in system\nF, finds all possible ways to decorate it into a DLAL typed term. We show that\nour procedure can be run in time polynomial in the size of the original Church\ntyped system F term."
},{
    "category": "cs.LO", 
    "doi": "10.1093/logcom/exi030", 
    "link": "http://arxiv.org/pdf/cs/0603117v2", 
    "title": "Affine functions and series with co-inductive real numbers", 
    "arxiv-id": "cs/0603117v2", 
    "author": "Yves Bertot", 
    "publish": "2006-03-29T19:36:03Z", 
    "summary": "We extend the work of A. Ciaffaglione and P. Di Gianantonio on mechanical\nverification of algorithms for exact computation on real numbers, using\ninfinite streams of digits implemented as co-inductive types. Four aspects are\nstudied: the first aspect concerns the proof that digit streams can be related\nto the axiomatized real numbers that are already axiomatized in the proof\nsystem (axiomatized, but with no fixed representation). The second aspect\nre-visits the definition of an addition function, looking at techniques to let\nthe proof search mechanism perform the effective construction of an algorithm\nthat is correct by construction. The third aspect concerns the definition of a\nfunction to compute affine formulas with positive rational coefficients. This\nshould be understood as a testbed to describe a technique to combine\nco-recursion and recursion to obtain a model for an algorithm that appears at\nfirst sight to be outside the expressive power allowed by the proof system. The\nfourth aspect concerns the definition of a function to compute series, with an\napplication on the series that is used to compute Euler's number e. All these\nexperiments should be reproducible in any proof system that supports\nco-inductive types, co-recursion and general forms of terminating recursion,\nbut we performed with the Coq system [12, 3, 14]."
},{
    "category": "cs.LO", 
    "doi": "10.1093/logcom/exi030", 
    "link": "http://arxiv.org/pdf/cs/0603118v3", 
    "title": "Coq in a Hurry", 
    "arxiv-id": "cs/0603118v3", 
    "author": "Yves Bertot", 
    "publish": "2006-03-29T19:38:33Z", 
    "summary": "These notes provide a quick introduction to the Coq system and show how it\ncan be used to define logical concepts and functions and reason about them. It\nis designed as a tutorial, so that readers can quickly start their own\nexperiments, learning only a few of the capabilities of the system. A much more\ncomprehensive study is provided in [1], which also provides an extensive\ncollection of exercises to train on."
},{
    "category": "cs.LO", 
    "doi": "10.1093/logcom/exi030", 
    "link": "http://arxiv.org/pdf/cs/0603119v1", 
    "title": "CoInduction in Coq", 
    "arxiv-id": "cs/0603119v1", 
    "author": "Yves Bertot", 
    "publish": "2006-03-29T19:39:37Z", 
    "summary": "We describe the basic notions of co-induction as they are available in the\ncoq system. As an application, we describe arithmetic properties for simple\nrepresentations of real numbers."
},{
    "category": "cs.LO", 
    "doi": "10.1093/logcom/exi030", 
    "link": "http://arxiv.org/pdf/cs/0605008v1", 
    "title": "The complexity of acyclic conjunctive queries revisited", 
    "arxiv-id": "cs/0605008v1", 
    "author": "Etienne Grandjean", 
    "publish": "2006-05-02T09:31:58Z", 
    "summary": "In this paper, we consider first-order logic over unary functions and study\nthe complexity of the evaluation problem for conjunctive queries described by\nsuch kind of formulas. A natural notion of query acyclicity for this language\nis introduced and we study the complexity of a large number of variants or\ngeneralizations of acyclic query problems in that context (Boolean or not\nBoolean, with or without inequalities, comparisons, etc...). Our main results\nshow that all those problems are \\textit{fixed-parameter linear} i.e. they can\nbe evaluated in time $f(|Q|).|\\textbf{db}|.|Q(\\textbf{db})|$ where $|Q|$ is the\nsize of the query $Q$, $|\\textbf{db}|$ the database size, $|Q(\\textbf{db})|$ is\nthe size of the output and $f$ is some function whose value depends on the\nspecific variant of the query problem (in some cases, $f$ is the identity\nfunction). Our results have two kinds of consequences. First, they can be\neasily translated in the relational (i.e., classical) setting. Previously known\nbounds for some query problems are improved and new tractable cases are then\nexhibited. Among others, as an immediate corollary, we improve a result of\n\\~\\cite{PapadimitriouY-99} by showing that any (relational) acyclic conjunctive\nquery with inequalities can be evaluated in time\n$f(|Q|).|\\textbf{db}|.|Q(\\textbf{db})|$. A second consequence of our method is\nthat it provides a very natural descriptive approach to the complexity of\nwell-known algorithmic problems. A number of examples (such as acyclic subgraph\nproblems, multidimensional matching, etc...) are considered for which new\ninsights of their complexity are given."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(4:3)2006", 
    "link": "http://arxiv.org/pdf/cs/0605054v3", 
    "title": "From Proof Nets to the Free *-Autonomous Category", 
    "arxiv-id": "cs/0605054v3", 
    "author": "Lutz Strassburger", 
    "publish": "2006-05-12T12:03:16Z", 
    "summary": "In the first part of this paper we present a theory of proof nets for full\nmultiplicative linear logic, including the two units. It naturally extends the\nwell-known theory of unit-free multiplicative proof nets. A linking is no\nlonger a set of axiom links but a tree in which the axiom links are subtrees.\nThese trees will be identified according to an equivalence relation based on a\nsimple form of graph rewriting. We show the standard results of\nsequentialization and strong normalization of cut elimination. In the second\npart of the paper we show that the identifications enforced on proofs are such\nthat the class of two-conclusion proof nets defines the free *-autonomous\ncategory."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(4:3)2006", 
    "link": "http://arxiv.org/pdf/cs/0605074v1", 
    "title": "SAT Solving for Argument Filterings", 
    "arxiv-id": "cs/0605074v1", 
    "author": "J\u00fcrgen Giesl", 
    "publish": "2006-05-17T12:47:18Z", 
    "summary": "This paper introduces a propositional encoding for lexicographic path orders\nin connection with dependency pairs. This facilitates the application of SAT\nsolvers for termination analysis of term rewrite systems based on the\ndependency pair method. We address two main inter-related issues and encode\nthem as satisfiability problems of propositional formulas that can be\nefficiently handled by SAT solving: (1) the combined search for a lexicographic\npath order together with an \\emph{argument filtering} to orient a set of\ninequalities; and (2) how the choice of the argument filtering influences the\nset of inequalities that have to be oriented. We have implemented our\ncontributions in the termination prover AProVE. Extensive experiments show that\nby our encoding and the application of SAT solvers one obtains speedups in\norders of magnitude as well as increased termination proving power."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(4:3)2006", 
    "link": "http://arxiv.org/pdf/cs/0605085v2", 
    "title": "A Scalable Algorithm for Minimal Unsatisfiable Core Extraction", 
    "arxiv-id": "cs/0605085v2", 
    "author": "Alexander Nadel", 
    "publish": "2006-05-19T08:19:37Z", 
    "summary": "We propose a new algorithm for minimal unsatisfiable core extraction, based\non a deeper exploration of resolution-refutation properties. We provide\nexperimental results on formal verification benchmarks confirming that our\nalgorithm finds smaller cores than suboptimal algorithms; and that it runs\nfaster than those algorithms that guarantee minimality of the core."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(4:3)2006", 
    "link": "http://arxiv.org/pdf/cs/0605107v3", 
    "title": "Fuzzy Discrete Event Systems under Fuzzy Observability and a   test-algorithm", 
    "arxiv-id": "cs/0605107v3", 
    "author": "Fuchun Liu", 
    "publish": "2006-05-24T15:41:00Z", 
    "summary": "In order to more effectively cope with the real-world problems of vagueness,\nimpreciseness, and subjectivity, fuzzy discrete event systems (FDESs) were\nproposed recently. Notably, FDESs have been applied to biomedical control for\nHIV/AIDS treatment planning and sensory information processing for robotic\ncontrol. Qiu, Cao and Ying independently developed supervisory control theory\nof FDESs. We note that the controllability of events in Qiu's work is fuzzy but\nthe observability of events is crisp, and, the observability of events in Cao\nand Ying's work is also crisp although the controllability is not completely\ncrisp since the controllable events can be disabled with any degrees. Motivated\nby the necessity to consider the situation that the events may be observed or\ncontrolled with some membership degrees, in this paper, we establish the\nsupervisory control theory of FDESs with partial observations, in which both\nthe observability and controllability of events are fuzzy instead. We formalize\nthe notions of fuzzy controllability condition and fuzzy observability\ncondition. And Controllability and Observability Theorem of FDESs is set up in\na more generic framework. In particular, we present a detailed computing flow\nto verify whether the controllability and observability conditions hold. Thus,\nthis result can decide the existence of supervisors. Also, we use this\ncomputing method to check the existence of supervisors in the Controllability\nand Observability Theorem of classical discrete event systems (DESs), which is\na new method and different from classical case. A number of examples are\nelaborated on to illustrate the presented results."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(4:3)2006", 
    "link": "http://arxiv.org/pdf/cs/0605128v1", 
    "title": "Logic Column 15: Coalgebras and Their Logics", 
    "arxiv-id": "cs/0605128v1", 
    "author": "Alexander Kurz", 
    "publish": "2006-05-28T19:30:12Z", 
    "summary": "This article describes recent work on the topic of specifying properties of\ntransition systems. By giving a suitably abstract description of transition\nsystems as coalgebras, it is possible to derive logics for capturing properties\nof these transition systems in an elegant way."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(2:6)2006", 
    "link": "http://arxiv.org/pdf/cs/0606053v2", 
    "title": "Context-Sensitive Languages, Rational Graphs and Determinism", 
    "arxiv-id": "cs/0606053v2", 
    "author": "Antoine Meyer", 
    "publish": "2006-06-12T09:35:18Z", 
    "summary": "We investigate families of infinite automata for context-sensitive languages.\nAn infinite automaton is an infinite labeled graph with two sets of initial and\nfinal vertices. Its language is the set of all words labelling a path from an\ninitial vertex to a final vertex. In 2001, Morvan and Stirling proved that\nrational graphs accept the context-sensitive languages between rational sets of\ninitial and final vertices. This result was later extended to sub-families of\nrational graphs defined by more restricted classes of transducers.\nlanguages.<br><br>\n  Our contribution is to provide syntactical and self-contained proofs of the\nabove results, when earlier constructions relied on a non-trivial normal form\nof context-sensitive grammars defined by Penttonen in the 1970's. These new\nproof techniques enable us to summarize and refine these results by considering\nseveral sub-families defined by restrictions on the type of transducers, the\ndegree of the graph or the size of the set of initial vertices."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(2:6)2006", 
    "link": "http://arxiv.org/pdf/cs/0606082v1", 
    "title": "Lack of Finite Characterizations for the Distance-based Revision", 
    "arxiv-id": "cs/0606082v1", 
    "author": "Jonathan Ben-Naim", 
    "publish": "2006-06-19T09:34:27Z", 
    "summary": "Lehmann, Magidor, and Schlechta developed an approach to belief revision\nbased on distances between any two valuations. Suppose we are given such a\ndistance D. This defines an operator |D, called a distance operator, which\ntransforms any two sets of valuations V and W into the set V |D W of all\nelements of W that are closest to V. This operator |D defines naturally the\nrevision of K by A as the set of all formulas satisfied in M(K) |D M(A) (i.e.\nthose models of A that are closest to the models of K). This constitutes a\ndistance-based revision operator. Lehmann et al. characterized families of them\nusing a loop condition of arbitrarily big size. An interesting question is\nwhether this loop condition can be replaced by a finite one. Extending the\nresults of Schlechta, we will provide elements of negative answer. In fact, we\nwill show that for families of distance operators, there is no \"normal\"\ncharacterization. Approximatively, a normal characterization contains only\nfinite and universally quantified conditions. These results have an interest of\ntheir own for they help to understand the limits of what is possible in this\narea. Now, we are quite confident that this work can be continued to show\nsimilar impossibility results for distance-based revision operators, which\nsuggests that the big loop condition cannot be simplified."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(2:6)2006", 
    "link": "http://arxiv.org/pdf/cs/0606086v1", 
    "title": "Uniform Random Sampling of Traces in Very Large Models", 
    "arxiv-id": "cs/0606086v1", 
    "author": "the RaST Collaboration", 
    "publish": "2006-06-20T09:53:41Z", 
    "summary": "This paper presents some first results on how to perform uniform random walks\n(where every trace has the same probability to occur) in very large models. The\nmodels considered here are described in a succinct way as a set of\ncommunicating reactive modules. The method relies upon techniques for counting\nand drawing uniformly at random words in regular languages. Each module is\nconsidered as an automaton defining such a language. It is shown how it is\npossible to combine local uniform drawings of traces, and to obtain some global\nuniform random sampling, without construction of the global model."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(2:6)2006", 
    "link": "http://arxiv.org/pdf/cs/0607058v1", 
    "title": "Craig's Interpolation Theorem formalised and mechanised in Isabelle/HOL", 
    "arxiv-id": "cs/0607058v1", 
    "author": "Tom Ridge", 
    "publish": "2006-07-12T17:26:29Z", 
    "summary": "We formalise and mechanise a construtive, proof theoretic proof of Craig's\nInterpolation Theorem in Isabelle/HOL. We give all the definitions and lemma\nstatements both formally and informally. We also transcribe informally the\nformal proofs. We detail the main features of our mechanisation, such as the\nformalisation of binding for first order formulae. We also give some\napplications of Craig's Interpolation Theorem."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(2:6)2006", 
    "link": "http://arxiv.org/pdf/cs/0607141v1", 
    "title": "Logic Column 16: Higher-Order Abstract Syntax: Setting the Record   Straight", 
    "arxiv-id": "cs/0607141v1", 
    "author": "Robert Harper", 
    "publish": "2006-07-31T14:15:23Z", 
    "summary": "This article responds to a critique of higher-order abstract syntax appearing\nin Logic Column 14, ``Nominal Logic and Abstract Syntax'', cs.LO/0511025."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(2:6)2006", 
    "link": "http://arxiv.org/pdf/cs/0608001v2", 
    "title": "A Finite Equational Base for CCS with Left Merge and Communication Merge", 
    "arxiv-id": "cs/0608001v2", 
    "author": "Bas Luttik", 
    "publish": "2006-08-01T10:45:29Z", 
    "summary": "Using the left merge and communication merge from ACP, we present an\nequational base (i.e., a ground-complete and $\\omega$-complete set of valid\nequations) for the fragment of CCS without recursion, restriction and\nrelabelling. Our equational base is finite if the set of actions is finite."
},{
    "category": "cs.LO", 
    "doi": "10.1002/malq.200610015", 
    "link": "http://arxiv.org/pdf/cs/0608039v1", 
    "title": "The weak pigeonhole principle for function classes in S^1_2", 
    "arxiv-id": "cs/0608039v1", 
    "author": "Chris Pollett", 
    "publish": "2006-08-07T19:44:02Z", 
    "summary": "It is well known that S^1_2 cannot prove the injective weak pigeonhole\nprinciple for polynomial time functions unless RSA is insecure. In this note we\ninvestigate the provability of the surjective (dual) weak pigeonhole principle\nin S^1_2 for provably weaker function classes."
},{
    "category": "cs.LO", 
    "doi": "10.1002/malq.200610015", 
    "link": "http://arxiv.org/pdf/cs/0608040v1", 
    "title": "An Embedding of the BSS Model of Computation in Light Affine   Lambda-Calculus", 
    "arxiv-id": "cs/0608040v1", 
    "author": "Marco Pedicini", 
    "publish": "2006-08-08T07:13:58Z", 
    "summary": "This paper brings together two lines of research: implicit characterization\nof complexity classes by Linear Logic (LL) on the one hand, and computation\nover an arbitrary ring in the Blum-Shub-Smale (BSS) model on the other. Given a\nfixed ring structure K we define an extension of Terui's light affine\nlambda-calculus typed in LAL (Light Affine Logic) with a basic type for K. We\nshow that this calculus captures the polynomial time function class FP(K):\nevery typed term can be evaluated in polynomial time and conversely every\npolynomial time BSS machine over K can be simulated in this calculus."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:4)2008", 
    "link": "http://arxiv.org/pdf/cs/0608059v5", 
    "title": "A Distribution Law for CCS and a New Congruence Result for the   pi-calculus", 
    "arxiv-id": "cs/0608059v5", 
    "author": "Damien Pous", 
    "publish": "2006-08-14T18:55:53Z", 
    "summary": "We give an axiomatisation of strong bisimilarity on a small fragment of CCS\nthat does not feature the sum operator. This axiomatisation is then used to\nderive congruence of strong bisimilarity in the finite pi-calculus in absence\nof sum. To our knowledge, this is the only nontrivial subcalculus of the\npi-calculus that includes the full output prefix and for which strong\nbisimilarity is a congruence."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:4)2008", 
    "link": "http://arxiv.org/pdf/cs/0608110v1", 
    "title": "Calculating modules in contextual logic program refinement", 
    "arxiv-id": "cs/0608110v1", 
    "author": "Paul Strooper", 
    "publish": "2006-08-29T05:31:11Z", 
    "summary": "The refinement calculus for logic programs is a framework for deriving logic\nprograms from specifications. It is based on a wide-spectrum language that can\nexpress both specifications and code, and a refinement relation that models the\nnotion of correct implementation. In this paper we extend and generalise\nearlier work on contextual refinement. Contextual refinement simplifies the\nrefinement process by abstractly capturing the context of a subcomponent of a\nprogram, which typically includes information about the values of the free\nvariables. This paper also extends and generalises module refinement. A module\nis a collection of procedures that operate on a common data type; module\nrefinement between a specification module A and an implementation module C\nallows calls to the procedures of A to be systematically replaced with calls to\nthe corresponding procedures of C. Based on the conditions for module\nrefinement, we present a method for calculating an implementation module from a\nspecification module. Both contextual and module refinement within the\nrefinement calculus have been generalised from earlier work and the results are\npresented in a unified framework."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:4)2008", 
    "link": "http://arxiv.org/pdf/cs/0609013v2", 
    "title": "Combining typing and size constraints for checking the termination of   higher-order conditional rewrite systems", 
    "arxiv-id": "cs/0609013v2", 
    "author": "Colin Riba", 
    "publish": "2006-09-05T14:23:38Z", 
    "summary": "In a previous work, the first author extended to higher-order rewriting and\ndependent types the use of size annotations in types, a termination proof\ntechnique called type or size based termination and initially developed for\nML-like programs. Here, we go one step further by considering conditional\nrewriting and explicit quantifications and constraints on size annotations.\nThis allows to describe more precisely how the size of the output of a function\ndepends on the size of its inputs. Hence, we can check the termination of more\nfunctions. We first give a general type-checking algorithm based on constraint\nsolving. Then, we give a termination criterion with constraints in Presburger\narithmetic. To our knowledge, this is the first termination criterion for\nhigher-order conditional rewriting taking into account the conditions in\ntermination."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:4)2008", 
    "link": "http://arxiv.org/pdf/cs/0609021v1", 
    "title": "Non uniform (hyper/multi)coherence spaces", 
    "arxiv-id": "cs/0609021v1", 
    "author": "Pierre Boudes", 
    "publish": "2006-09-06T12:14:25Z", 
    "summary": "In (hyper)coherence semantics, proofs/terms are cliques in (hyper)graphs.\nIntuitively, vertices represent results of computations and the edge relation\nwitnesses the ability of being assembled into a same piece of data or a same\n(strongly) stable function, at arrow types. In (hyper)coherence semantics, the\nargument of a (strongly) stable functional is always a (strongly) stable\nfunction. As a consequence, comparatively to the relational semantics, where\nthere is no edge relation, some vertices are missing. Recovering these vertices\nis essential for the purpose of reconstructing proofs/terms from their\ninterpretations. It shall also be useful for the comparison with other\nsemantics, like game semantics. In [BE01], Bucciarelli and Ehrhard introduced a\nso called non uniform coherence space semantics where no vertex is missing. By\nconstructing the co-free exponential we set a new version of this last\nsemantics, together with non uniform versions of hypercoherences and\nmulticoherences, a new semantics where an edge is a finite multiset. Thanks to\nthe co-free construction, these non uniform semantics are deterministic in the\nsense that the intersection of a clique and of an anti-clique contains at most\none vertex, a result of interaction, and extensionally collapse onto the\ncorresponding uniform semantics."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:4)2008", 
    "link": "http://arxiv.org/pdf/cs/0609037v1", 
    "title": "(HO)RPO Revisited", 
    "arxiv-id": "cs/0609037v1", 
    "author": "Fr\u00e9d\u00e9ric Blanqui", 
    "publish": "2006-09-08T07:35:35Z", 
    "summary": "The notion of computability closure has been introduced for proving the\ntermination of the combination of higher-order rewriting and beta-reduction. It\nis also used for strengthening the higher-order recursive path ordering. In the\npresent paper, we study in more details the relations between the computability\nclosure and the (higher-order) recursive path ordering. We show that the\nfirst-order recursive path ordering is equal to an ordering naturally defined\nfrom the computability closure. In the higher-order case, we get an ordering\ncontaining the higher-order recursive path ordering whose well-foundedness\nrelies on the correctness of the computability closure. This provides a simple\nway to extend the higher-order recursive path ordering to richer type systems."
},{
    "category": "cs.LO", 
    "doi": "10.1007/11916277_1", 
    "link": "http://arxiv.org/pdf/cs/0609039v2", 
    "title": "Higher-Order Termination: from Kruskal to Computability", 
    "arxiv-id": "cs/0609039v2", 
    "author": "Albert Rubio", 
    "publish": "2006-09-08T07:48:08Z", 
    "summary": "Termination is a major question in both logic and computer science. In logic,\ntermination is at the heart of proof theory where it is usually called strong\nnormalization (of cut elimination). In computer science, termination has always\nbeen an important issue for showing programs correct. In the early days of\nlogic, strong normalization was usually shown by assigning ordinals to\nexpressions in such a way that eliminating a cut would yield an expression with\na smaller ordinal. In the early days of verification, computer scientists used\nsimilar ideas, interpreting the arguments of a program call by a natural\nnumber, such as their size. Showing the size of the arguments to decrease for\neach recursive call gives a termination proof of the program, which is however\nrather weak since it can only yield quite small ordinals. In the sixties, Tait\ninvented a new method for showing cut elimination of natural deduction, based\non a predicate over the set of terms, such that the membership of an expression\nto the predicate implied the strong normalization property for that expression.\nThe predicate being defined by induction on types, or even as a fixpoint, this\nmethod could yield much larger ordinals. Later generalized by Girard under the\nname of reducibility or computability candidates, it showed very effective in\nproving the strong normalization property of typed lambda-calculi..."
},{
    "category": "cs.LO", 
    "doi": "10.1007/11916277_1", 
    "link": "http://arxiv.org/pdf/cs/0609048v1", 
    "title": "On the logical definability of certain graph and poset languages", 
    "arxiv-id": "cs/0609048v1", 
    "author": "Pascal Weil", 
    "publish": "2006-09-11T08:25:10Z", 
    "summary": "We show that it is equivalent, for certain sets of finite graphs, to be\ndefinable in CMS (counting monadic second-order logic, a natural extension of\nmonadic second-order logic), and to be recognizable in an algebraic framework\ninduced by the notion of modular decomposition of a finite graph. More\nprecisely, we consider the set $F\\_\\infty$ of composition operations on graphs\nwhich occur in the modular decomposition of finite graphs. If $F$ is a subset\nof $F\\_{\\infty}$, we say that a graph is an $\\calF$-graph if it can be\ndecomposed using only operations in $F$. A set of $F$-graphs is recognizable if\nit is a union of classes in a finite-index equivalence relation which is\npreserved by the operations in $F$. We show that if $F$ is finite and its\nelements enjoy only a limited amount of commutativity -- a property which we\ncall weak rigidity, then recognizability is equivalent to CMS-definability.\nThis requirement is weak enough to be satisfied whenever all $F$-graphs are\nposets, that is, transitive dags. In particular, our result generalizes Kuske's\nrecent result on series-parallel poset languages."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(4:5)2006", 
    "link": "http://arxiv.org/pdf/cs/0609080v2", 
    "title": "Solution of a Problem of Barendregt on Sensible lambda-Theories", 
    "arxiv-id": "cs/0609080v2", 
    "author": "Richard Statman", 
    "publish": "2006-09-14T16:01:52Z", 
    "summary": "<i>H</i> is the theory extending &#946;-conversion by identifying all closed\nunsolvables. <i>H</i>&#969; is the closure of this theory under the &#969;-rule\n(and &#946;-conversion). A long-standing conjecture of H. Barendregt states\nthat the provable equations of <i>H</i>&#969; form\n&#928;<sub>1</sub><sup>1</sup>-complete set. Here we prove that conjecture."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(4:5)2006", 
    "link": "http://arxiv.org/pdf/cs/0609095v2", 
    "title": "Free Choice Petri Nets without frozen tokens and Bipolar Synchronization   Systems", 
    "arxiv-id": "cs/0609095v2", 
    "author": "Joachim Wehler", 
    "publish": "2006-09-17T17:42:41Z", 
    "summary": "Bipolar synchronization systems (BP-systems) constitute a class of coloured\nPetri nets, well suited for modeling the control flow of discrete, dynamical\nsystems. Every BP-system has an underlying ordinary Petri net, which is a\nT-system. Moreover, it has a second ordinary net attached, which is a\nfree-choice system. We prove that a BP-system is live and safe if the T-system\nand the free-choice system are live and safe and if the free-choice system has\nno frozen tokens. This result is the converse of a theorem of Genrich and\nThiagarajan and proves an elder conjecture. The proof compares the different\nPetri nets by Petri net morphisms and makes use of the classical theory of\nfree-choice systems"
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(4:5)2006", 
    "link": "http://arxiv.org/pdf/cs/0609102v1", 
    "title": "Using groups for investigating rewrite systems", 
    "arxiv-id": "cs/0609102v1", 
    "author": "Patrick Dehornoy", 
    "publish": "2006-09-18T12:34:47Z", 
    "summary": "We describe several technical tools that prove to be efficient for\ninvestigating the rewrite systems associated with a family of algebraic laws,\nand might be useful for more general rewrite systems. These tools consist in\nintroducing a monoid of partial operators, listing the monoid relations\nexpressing the possible local confluence of the rewrite system, then\nintroducing the group presented by these relations, and finally replacing the\ninitial rewrite system with a internal process entirely sitting in the latter\ngroup. When the approach can be completed, one typically obtains a practical\nmethod for constructing algebras satisfying prescribed laws and for solving the\nassociated word problem."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(4:5)2006", 
    "link": "http://arxiv.org/pdf/cs/0609110v1", 
    "title": "Algebraic recognizability of languages", 
    "arxiv-id": "cs/0609110v1", 
    "author": "Pascal Weil", 
    "publish": "2006-09-19T15:21:08Z", 
    "summary": "Recognizable languages of finite words are part of every computer science\ncursus, and they are routinely described as a cornerstone for applications and\nfor theory. We would like to briefly explore why that is, and how this\nword-related notion extends to more complex models, such as those developed for\nmodeling distributed or timed behaviors."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(4:5)2006", 
    "link": "http://arxiv.org/pdf/cs/0609124v1", 
    "title": "The Three Gap Theorem (Steinhauss Conjecture)", 
    "arxiv-id": "cs/0609124v1", 
    "author": "Micaela Mayero", 
    "publish": "2006-09-22T11:30:34Z", 
    "summary": "We deal with the distribution of N points placed consecutively around the\ncircle by a fixed angle of a. From the proof of Tony van Ravenstein, we propose\na detailed proof of the Steinhaus conjecture whose result is the following: the\nN points partition the circle into gaps of at most three different lengths. We\nstudy the mathematical notions required for the proof of this theorem revealed\nduring a formal proof carried out in Coq."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(4:5)2006", 
    "link": "http://arxiv.org/pdf/cs/0609167v1", 
    "title": "Updates in Answer Set Programming: An Approach Based on Basic Structural   Properties", 
    "arxiv-id": "cs/0609167v1", 
    "author": "V\u00edctor Cuevas", 
    "publish": "2006-09-29T17:00:52Z", 
    "summary": "We have studied the update operator defined for update sequences by Eiter et\nal. without tautologies and we have observed that it satisfies an interesting\nproperty This property, which we call Weak Independence of Syntax (WIS), is\nsimilar to one of the postulates proposed by Alchourron, Gardenfors, and\nMakinson (AGM); only that in this case it applies to nonmonotonic logic. In\naddition, we consider other five additional basic properties about update\nprograms and we show that the operator of Eiter et al. satisfies them. This\nwork continues the analysis of the AGM postulates under a refined view that\nconsiders nelson logic as a monotonic logic which allows us to expand our\nunderstanding of answer sets. Moreover, nelson logic helped us to derive an\nalternative definition of the operator defined by Eiter et al. avoiding the use\nof unnecessary extra atoms."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(4:5)2006", 
    "link": "http://arxiv.org/pdf/cs/0610038v1", 
    "title": "Church's thesis is questioned by new calculation paradigm", 
    "arxiv-id": "cs/0610038v1", 
    "author": "Hannes Hutzelmeyer", 
    "publish": "2006-10-07T12:53:04Z", 
    "summary": "Church's thesis claims that all effecticely calculable functions are\nrecursive. A shortcoming of the various definitions of recursive functions lies\nin the fact that it is not a matter of a syntactical check to find out if an\nentity gives rise to a function. Eight new ideas for a precise setup of\narithmetical logic and its metalanguage give the proper environment for the\nconstruction of a special computer, the ARBACUS computer. Computers do not come\nto a necessary halt; it is requested that calculators are constructed on the\nbasis of computers in a way that they always come to a halt, then all\ncalculations are effective. The ARBATOR is defined as a calculator with\ntwo-layer-computation. It allows for the calculation of all primitive recursive\nfunctions, but multi-level-arbation also allows for the calculation of other\narbative functions that are not primitive recursive. The new paradigm of\ncalculation does not have the above mentioned shortcoming. The defenders of\nChurch's thesis are challenged to show that exotic arbative functions are\nrecursive and to put forward a recursive function that is not arbative. A\nconstruction with three-tier-multi-level-arbation that includes a\ndiagonalisation leads to the extravagant yet calculable Snark-function that is\nnot arbative. As long as it is not shown that all exotic arbative functions and\nparticularily the Snark-function are arithmetically representable Goedel's\nfirst incompleteness sentence is in limbo."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(4:5)2006", 
    "link": "http://arxiv.org/pdf/cs/0610055v1", 
    "title": "Extending the Calculus of Constructions with Tarski's fix-point theorem", 
    "arxiv-id": "cs/0610055v1", 
    "author": "Yves Bertot", 
    "publish": "2006-10-11T12:50:32Z", 
    "summary": "We propose to use Tarski's least fixpoint theorem as a basis to define\nrecursive functions in the calculus of inductive constructions. This widens the\nclass of functions that can be modeled in type-theory based theorem proving\ntool to potentially non-terminating functions. This is only possible if we\nextend the logical framework by adding the axioms that correspond to classical\nlogic. We claim that the extended framework makes it possible to reason about\nterminating and non-terminating computations and we show that common facilities\nof the calculus of inductive construction, like program extraction can be\nextended to also handle the new functions."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(4:5)2006", 
    "link": "http://arxiv.org/pdf/cs/0610063v2", 
    "title": "The Calculus of Algebraic Constructions", 
    "arxiv-id": "cs/0610063v2", 
    "author": "Mitsuhiro Okada", 
    "publish": "2006-10-11T13:45:46Z", 
    "summary": "This paper is concerned with the foundations of the Calculus of Algebraic\nConstructions (CAC), an extension of the Calculus of Constructions by inductive\ndata types. CAC generalizes inductive types equipped with higher-order\nprimitive recursion, by providing definitions of functions by pattern-matching\nwhich capture recursor definitions for arbitrary non-dependent and\nnon-polymorphic inductive types satisfying a strictly positivity condition. CAC\nalso generalizes the first-order framework of abstract data types by providing\ndependent types and higher-order rewrite rules."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(4:5)2006", 
    "link": "http://arxiv.org/pdf/cs/0610064v1", 
    "title": "Termination and Confluence of Higher-Order Rewrite Systems", 
    "arxiv-id": "cs/0610064v1", 
    "author": "Fr\u00e9d\u00e9ric Blanqui", 
    "publish": "2006-10-11T13:47:47Z", 
    "summary": "In the last twenty years, several approaches to higher-order rewriting have\nbeen proposed, among which Klop's Combinatory Rewrite Systems (CRSs), Nipkow's\nHigher-order Rewrite Systems (HRSs) and Jouannaud and Okada's higher-order\nalgebraic specification languages, of which only the last one considers typed\nterms. The later approach has been extended by Jouannaud, Okada and the present\nauthor into Inductive Data Type Systems (IDTSs). In this paper, we extend IDTSs\nwith the CRS higher-order pattern-matching mechanism, resulting in simply-typed\nCRSs. Then, we show how the termination criterion developed for IDTSs with\nfirst-order pattern-matching, called the General Schema, can be extended so as\nto prove the strong normalization of IDTSs with higher-order pattern-matching.\nNext, we compare the unified approach with HRSs. We first prove that the\nextended General Schema can also be applied to HRSs. Second, we show how\nNipkow's higher-order critical pair analysis technique for proving local\nconfluence can be applied to IDTSs."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(4:5)2006", 
    "link": "http://arxiv.org/pdf/cs/0610065v1", 
    "title": "Definitions by Rewriting in the Calculus of Constructions", 
    "arxiv-id": "cs/0610065v1", 
    "author": "Fr\u00e9d\u00e9ric Blanqui", 
    "publish": "2006-10-11T13:48:36Z", 
    "summary": "The main novelty of this paper is to consider an extension of the Calculus of\nConstructions where predicates can be defined with a general form of rewrite\nrules. We prove the strong normalization of the reduction relation generated by\nthe beta-rule and the user-defined rules under some general syntactic\nconditions including confluence. As examples, we show that two important\nsystems satisfy these conditions: a sub-system of the Calculus of Inductive\nConstructions which is the basis of the proof assistant Coq, and the Natural\nDeduction Modulo a large class of equational theories."
},{
    "category": "cs.LO", 
    "doi": "10.1016/S0304-3975(00)00347-9", 
    "link": "http://arxiv.org/pdf/cs/0610066v2", 
    "title": "Inductive-data-type Systems", 
    "arxiv-id": "cs/0610066v2", 
    "author": "Mitsuhiro Okada", 
    "publish": "2006-10-11T13:54:42Z", 
    "summary": "In a previous work (\"Abstract Data Type Systems\", TCS 173(2), 1997), the last\ntwo authors presented a combined language made of a (strongly normalizing)\nalgebraic rewrite system and a typed lambda-calculus enriched by\npattern-matching definitions following a certain format, called the \"General\nSchema\", which generalizes the usual recursor definitions for natural numbers\nand similar \"basic inductive types\". This combined language was shown to be\nstrongly normalizing. The purpose of this paper is to reformulate and extend\nthe General Schema in order to make it easily extensible, to capture a more\ngeneral class of inductive types, called \"strictly positive\", and to ease the\nstrong normalization proof of the resulting system. This result provides a\ncomputation model for the combination of an algebraic specification language\nbased on abstract data types and of a strongly typed functional language with\nstrictly positive inductive types."
},{
    "category": "cs.LO", 
    "doi": "10.1016/S0304-3975(00)00347-9", 
    "link": "http://arxiv.org/pdf/cs/0610068v2", 
    "title": "Type theory and rewriting", 
    "arxiv-id": "cs/0610068v2", 
    "author": "Fr\u00e9d\u00e9ric Blanqui", 
    "publish": "2006-10-11T14:09:16Z", 
    "summary": "We study the properties, in particular termination, of dependent types\nsystems for lambda calculus and rewriting."
},{
    "category": "cs.LO", 
    "doi": "10.1016/S0304-3975(00)00347-9", 
    "link": "http://arxiv.org/pdf/cs/0610069v1", 
    "title": "An Isabelle formalization of protocol-independent secrecy with an   application to e-commerce", 
    "arxiv-id": "cs/0610069v1", 
    "author": "Fr\u00e9d\u00e9ric Blanqui", 
    "publish": "2006-10-11T14:20:28Z", 
    "summary": "A protocol-independent secrecy theorem is established and applied to several\nnon-trivial protocols. In particular, it is applied to protocols proposed for\nprotecting the computation results of free-roaming mobile agents doing\ncomparison shopping. All the results presented here have been formally proved\nin Isabelle by building on Larry Paulson's inductive approach. This therefore\nprovides a library of general theorems that can be applied to other protocols."
},{
    "category": "cs.LO", 
    "doi": "10.1016/S0304-3975(00)00347-9", 
    "link": "http://arxiv.org/pdf/cs/0610070v1", 
    "title": "Inductive types in the Calculus of Algebraic Constructions", 
    "arxiv-id": "cs/0610070v1", 
    "author": "Fr\u00e9d\u00e9ric Blanqui", 
    "publish": "2006-10-11T15:18:13Z", 
    "summary": "In a previous work, we proved that almost all of the Calculus of Inductive\nConstructions (CIC), which is the basis of the proof assistant Coq, can be seen\nas a Calculus of Algebraic Constructions (CAC), an extension of the Calculus of\nConstructions with functions and predicates defined by higher-order rewrite\nrules. In this paper, we not only prove that CIC as a whole can be seen as a\nCAC, but also that it can be extended with non-free constructors,\npattern-matching on defined symbols, non-strictly positive types and\ninductive-recursive types."
},{
    "category": "cs.LO", 
    "doi": "10.1016/S0304-3975(00)00347-9", 
    "link": "http://arxiv.org/pdf/cs/0610071v1", 
    "title": "Rewriting modulo in Deduction modulo", 
    "arxiv-id": "cs/0610071v1", 
    "author": "Fr\u00e9d\u00e9ric Blanqui", 
    "publish": "2006-10-11T15:21:50Z", 
    "summary": "We study the termination of rewriting modulo a set of equations in the\nCalculus of Algebraic Constructions, an extension of the Calculus of\nConstructions with functions and predicates defined by higher-order rewrite\nrules. In a previous work, we defined general syntactic conditions based on the\nnotion of computable closure for ensuring the termination of the combination of\nrewriting and beta-reduction. Here, we show that this result is preserved when\nconsidering rewriting modulo a set of equations if the equivalence classes\ngenerated by these equations are finite, the equations are linear and satisfy\ngeneral syntactic conditions also based on the notion of computable closure.\nThis includes equations like associativity and commutativity, and provides an\noriginal treatment of termination modulo equations."
},{
    "category": "cs.LO", 
    "doi": "10.1017/S0960129504004426", 
    "link": "http://arxiv.org/pdf/cs/0610072v1", 
    "title": "Definitions by rewriting in the Calculus of Constructions", 
    "arxiv-id": "cs/0610072v1", 
    "author": "Fr\u00e9d\u00e9ric Blanqui", 
    "publish": "2006-10-12T11:47:54Z", 
    "summary": "This paper presents general syntactic conditions ensuring the strong\nnormalization and the logical consistency of the Calculus of Algebraic\nConstructions, an extension of the Calculus of Constructions with functions and\npredicates defined by higher-order rewrite rules. On the one hand, the Calculus\nof Constructions is a powerful type system in which one can formalize the\npropositions and natural deduction proofs of higher-order logic. On the other\nhand, rewriting is a simple and powerful computation paradigm. The combination\nof both allows, among other things, to develop formal proofs with a reduced\nsize and more automation compared with more traditional proof assistants. The\nmain novelty is to consider a general form of rewriting at the predicate-level\nwhich generalizes the strong elimination of the Calculus of Inductive\nConstructions."
},{
    "category": "cs.LO", 
    "doi": "10.1017/S0960129504004426", 
    "link": "http://arxiv.org/pdf/cs/0610073v1", 
    "title": "Inductive types in the Calculus of Algebraic Constructions", 
    "arxiv-id": "cs/0610073v1", 
    "author": "Fr\u00e9d\u00e9ric Blanqui", 
    "publish": "2006-10-12T11:48:39Z", 
    "summary": "In a previous work, we proved that an important part of the Calculus of\nInductive Constructions (CIC), the basis of the Coq proof assistant, can be\nseen as a Calculus of Algebraic Constructions (CAC), an extension of the\nCalculus of Constructions with functions and predicates defined by higher-order\nrewrite rules. In this paper, we prove that almost all CIC can be seen as a\nCAC, and that it can be further extended with non-strictly positive types and\ninductive-recursive types together with non-free constructors and\npattern-matching on defined symbols."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(5:1)2006", 
    "link": "http://arxiv.org/pdf/cs/0610081v2", 
    "title": "Semantics of Separation-Logic Typing and Higher-order Frame Rules   for<br> Algol-like Languages", 
    "arxiv-id": "cs/0610081v2", 
    "author": "Hongseok Yang", 
    "publish": "2006-10-13T08:21:31Z", 
    "summary": "We show how to give a coherent semantics to programs that are well-specified\nin a version of separation logic for a language with higher types: idealized\nalgol extended with heaps (but with immutable stack variables). In particular,\nwe provide simple sound rules for deriving higher-order frame rules, allowing\nfor local reasoning."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(5:1)2006", 
    "link": "http://arxiv.org/pdf/cs/0610117v1", 
    "title": "Quantifier elimination for the reals with a predicate for the powers of   two", 
    "arxiv-id": "cs/0610117v1", 
    "author": "Yimu Yin", 
    "publish": "2006-10-19T17:39:49Z", 
    "summary": "In 1985, van den Dries showed that the theory of the reals with a predicate\nfor the integer powers of two admits quantifier elimination in an expanded\nlanguage, and is hence decidable. He gave a model-theoretic argument, which\nprovides no apparent bounds on the complexity of a decision procedure. We\nprovide a syntactic argument that yields a procedure that is primitive\nrecursive, although not elementary. In particular, we show that it is possible\nto eliminate a single block of existential quantifiers in time $2^0_{O(n)}$,\nwhere $n$ is the length of the input formula and $2_k^x$ denotes $k$-fold\niterated exponentiation."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(5:1)2006", 
    "link": "http://arxiv.org/pdf/cs/0610123v2", 
    "title": "Proof Nets and the Identity of Proofs", 
    "arxiv-id": "cs/0610123v2", 
    "author": "Lutz Strassburger", 
    "publish": "2006-10-20T11:35:05Z", 
    "summary": "These are the notes for a 5-lecture-course given at ESSLLI 2006 in Malaga,\nSpain. The URL of the school is http://esslli2006.lcc.uma.es/ . This version\nslightly differs from the one which has been distributed at the school because\ntypos have been removed and comments and suggestions by students have been\nworked in. The course is intended to be introductory. That means no prior\nknowledge of proof nets is required. However, the student should be familiar\nwith the basics of propositional logic, and should have seen formal proofs in\nsome formal deductive system (e.g., sequent calculus, natural deduction,\nresolution, tableaux, calculus of structures, Frege-Hilbert-systems, ...). It\nis probably helpful if the student knows already what cut elimination is, but\nthis is not strictly necessary. In these notes, I will introduce the concept of\n``proof nets'' from the viewpoint of the problem of the identity of proofs. I\nwill proceed in a rather informal way. The focus will be more on presenting\nideas than on presenting technical details. The goal of the course is to give\nthe student an overview of the theory of proof nets and make the vast amount of\nliterature on the topic easier accessible to the beginner. For introducing the\nbasic concepts of the theory, I will in the first part of the course stick to\nthe unit-free multiplicative fragment of linear logic because of its rather\nsimple notion of proof nets. In the second part of the course we will see proof\nnets for more sophisticated logics. This is a basic introduction into proof\nnets from the perspective of the identity of proofs. We discuss how deductive\nproofs can be translated into proof nets and what a correctness criterion is."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(5:1)2006", 
    "link": "http://arxiv.org/pdf/cs/0610149v3", 
    "title": "Canonical decomposition of catenation of factorial languages", 
    "arxiv-id": "cs/0610149v3", 
    "author": "A. Frid", 
    "publish": "2006-10-26T06:38:30Z", 
    "summary": "According to a previous result by S. V. Avgustinovich and the author, each\nfactorial language admits a unique canonical decomposition to a catenation of\nfactorial languages. In this paper, we analyze the appearance of the canonical\ndecomposition of a catenation of two factorial languages whose canonical\ndecompositions are given."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(5:2)2006", 
    "link": "http://arxiv.org/pdf/cs/0611004v3", 
    "title": "Linear Abadi and Plotkin Logic", 
    "arxiv-id": "cs/0611004v3", 
    "author": "Rasmus Lerchedahl Petersen", 
    "publish": "2006-11-01T08:50:11Z", 
    "summary": "We present a formalization of a version of Abadi and\n  Plotkin's logic for parametricity for a polymorphic dual\nintuitionistic/linear type theory with fixed points, and show, following\nPlotkin's suggestions, that it can be used to define a wide collection of\ntypes, including existential types, inductive types, coinductive types and\ngeneral recursive types. We show that the recursive types satisfy a universal\nproperty called dinaturality, and we develop reasoning principles for the\nconstructed types. In the case of recursive types, the reasoning principle is a\nmixed induction/coinduction principle, with the curious property that\ncoinduction holds for general relations, but induction only for a limited\ncollection of ``admissible'' relations. A similar property was observed in\nPitts' 1995 analysis of recursive types in domain theory. In a future paper we\nwill develop a category theoretic notion of models of the logic presented here,\nand show how the results developed in the logic can be transferred to the\nmodels."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(5:2)2006", 
    "link": "http://arxiv.org/pdf/cs/0611018v1", 
    "title": "Logic Column 17: A Rendezvous of Logic, Complexity, and Algebra", 
    "arxiv-id": "cs/0611018v1", 
    "author": "Hubie Chen", 
    "publish": "2006-11-03T21:51:16Z", 
    "summary": "This article surveys recent advances in applying algebraic techniques to\nconstraint satisfaction problems."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(5:5)2006", 
    "link": "http://arxiv.org/pdf/cs/0611029v3", 
    "title": "Linear Encodings of Bounded LTL Model Checking", 
    "arxiv-id": "cs/0611029v3", 
    "author": "Viktor Schuppan", 
    "publish": "2006-11-07T00:07:26Z", 
    "summary": "We consider the problem of bounded model checking (BMC) for linear temporal\nlogic (LTL). We present several efficient encodings that have size linear in\nthe bound. Furthermore, we show how the encodings can be extended to LTL with\npast operators (PLTL). The generalised encoding is still of linear size, but\ncannot detect minimal length counterexamples. By using the virtual unrolling\ntechnique minimal length counterexamples can be captured, however, the size of\nthe encoding is quadratic in the specification. We also extend virtual\nunrolling to Buchi automata, enabling them to accept minimal length\ncounterexamples.\n  Our BMC encodings can be made incremental in order to benefit from\nincremental SAT technology. With fairly small modifications the incremental\nencoding can be further enhanced with a termination check, allowing us to prove\nproperties with BMC. Experiments clearly show that our new encodings improve\nperformance of BMC considerably, particularly in the case of the incremental\nencoding, and that they are very competitive for finding bugs. An analysis of\nthe liveness-to-safety transformation reveals many similarities to the BMC\nencodings in this paper. Using the liveness-to-safety translation with\nBDD-based invariant checking results in an efficient method to find shortest\ncounterexamples that complements the BMC-based approach."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-2(5:5)2006", 
    "link": "http://arxiv.org/pdf/cs/0611040v10", 
    "title": "The Formal System lambda-delta", 
    "arxiv-id": "cs/0611040v10", 
    "author": "F. Guidi", 
    "publish": "2006-11-09T11:36:58Z", 
    "summary": "The formal system lambda-delta is a typed lambda calculus that pursues the\nunification of terms, types, environments and contexts as the main goal.\nlambda-delta takes some features from the Automath-related lambda calculi and\nsome from the pure type systems, but differs from both in that it does not\ninclude the Pi construction while it provides for an abbreviation mechanism at\nthe level of terms. lambda-delta enjoys some important desirable properties\nsuch as the confluence of reduction, the correctness of types, the uniqueness\nof types up to conversion, the subject reduction of the type assignment, the\nstrong normalization of the typed terms and, as a corollary, the decidability\nof type inference problem."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(1:1)2007", 
    "link": "http://arxiv.org/pdf/cs/0611048v2", 
    "title": "Dense-Timed Petri Nets: Checking Zenoness, Token liveness and   Boundedness", 
    "arxiv-id": "cs/0611048v2", 
    "author": "Richard Mayr", 
    "publish": "2006-11-11T00:08:46Z", 
    "summary": "We consider Dense-Timed Petri Nets (TPN), an extension of Petri nets in which\neach token is equipped with a real-valued clock and where the semantics is lazy\n(i.e., enabled transitions need not fire; time can pass and disable\ntransitions). We consider the following verification problems for TPNs. (i)\nZenoness: whether there exists a zeno-computation from a given marking, i.e.,\nan infinite computation which takes only a finite amount of time. We show\ndecidability of zenoness for TPNs, thus solving an open problem from [Escrig et\nal.]. Furthermore, the related question if there exist arbitrarily fast\ncomputations from a given marking is also decidable. On the other hand,\nuniversal zenoness, i.e., the question if all infinite computations from a\ngiven marking are zeno, is undecidable. (ii) Token liveness: whether a token is\nalive in a marking, i.e., whether there is a computation from the marking which\neventually consumes the token. We show decidability of the problem by reducing\nit to the coverability problem, which is decidable for TPNs. (iii) Boundedness:\nwhether the size of the reachable markings is bounded. We consider two versions\nof the problem; namely semantic boundedness where only live tokens are taken\ninto consideration in the markings, and syntactic boundedness where also dead\ntokens are considered. We show undecidability of semantic boundedness, while we\nprove that syntactic boundedness is decidable through an extension of the\nKarp-Miller algorithm."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(1:1)2007", 
    "link": "http://arxiv.org/pdf/cs/0611051v1", 
    "title": "Numerical Simulation guided Lazy Abstraction Refinement for Nonlinear   Hybrid Automata", 
    "arxiv-id": "cs/0611051v1", 
    "author": "Sumit Kumar Jha", 
    "publish": "2006-11-13T17:28:24Z", 
    "summary": "This draft suggests a new counterexample guided abstraction refinement\n(CEGAR) framework that uses the combination of numerical simulation for\nnonlinear differential equations with linear programming for linear hybrid\nautomata (LHA) to perform reachability analysis on nonlinear hybrid automata. A\nnotion of $\\epsilon-$ structural robustness is also introduced which allows the\nalgorithm to validate counterexamples using numerical simulations.\n  Keywords: verification, model checking, hybrid systems, hybrid automata,\nrobustness, robust hybrid systems, numerical simulation, cegar, abstraction\nrefinement."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(1:1)2007", 
    "link": "http://arxiv.org/pdf/cs/0611057v1", 
    "title": "Formalising Sylow's theorems in Coq", 
    "arxiv-id": "cs/0611057v1", 
    "author": "Laurent Thery", 
    "publish": "2006-11-14T12:58:27Z", 
    "summary": "This report presents a formalisation of Sylow's theorems done in {\\sc Coq}.\nThe formalisation has been done in a couple of weeks on top of Georges\nGonthier's {\\sc ssreflect} \\cite{ssreflect}. There were two ideas behind\nformalising Sylow's theorems. The first one was to get familiar with Georges\nway of doing proofs. The second one was to contribute to the collective effort\nto formalise a large subset of group theory in {\\sc Coq} with some non-trivial\nproofs.}"
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(1:1)2007", 
    "link": "http://arxiv.org/pdf/cs/0611100v1", 
    "title": "Model Theory of Ultrafinitism I: Fuzzy Initial Segments of Arithmetics", 
    "arxiv-id": "cs/0611100v1", 
    "author": "Rose M. Cherubin", 
    "publish": "2006-11-21T03:05:30Z", 
    "summary": "This article is the first of an intended series of works on the model theory\nof Ultrafinitism. It is roughly divided into two parts. The first one addresses\nsome of the issues related to ultrafinitistic programs, as well as some of the\ncore ideas proposed thus far. The second part of the paper presents a model of\nultrafinitistic arithmetics based on the notion of fuzzy initial segments of\nthe standard natural numbers series. We also introduce a proof theory and a\nsemantics for ultrafinitism through which feasibly consistent theories can be\ntreated on the same footing as their classically consistent counterparts. We\nconclude with a brief sketch of a foundational program, that aims at\nreproducing the transfinite within the finite realm."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(1:3)2007", 
    "link": "http://arxiv.org/pdf/cs/0611119v2", 
    "title": "Expressiveness of Metric modalities for continuous time", 
    "arxiv-id": "cs/0611119v2", 
    "author": "Alexander Rabinovich", 
    "publish": "2006-11-22T21:03:26Z", 
    "summary": "We prove a conjecture by A. Pnueli and strengthen it showing a sequence of\n\"counting modalities\" none of which is expressible in the temporal logic\ngenerated by the previous modalities, over the real line, or over the positive\nreals. Moreover, there is no finite temporal logic that can express all of them\nover the real line, so that no finite metric temporal logic is expressively\ncomplete."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(1:2)2007", 
    "link": "http://arxiv.org/pdf/cs/0612069v2", 
    "title": "Cores of Countably Categorical Structures", 
    "arxiv-id": "cs/0612069v2", 
    "author": "Manuel Bodirsky", 
    "publish": "2006-12-13T09:59:56Z", 
    "summary": "A relational structure is a core, if all its endomorphisms are embeddings.\nThis notion is important for computational complexity classification of\nconstraint satisfaction problems. It is a fundamental fact that every finite\nstructure has a core, i.e., has an endomorphism such that the structure induced\nby its image is a core; moreover, the core is unique up to isomorphism. Weprove\nthat every \\omega -categorical structure has a core. Moreover, every\n\\omega-categorical structure is homomorphically equivalent to a model-complete\ncore, which is unique up to isomorphism, and which is finite or \\omega\n-categorical. We discuss consequences for constraint satisfaction with \\omega\n-categorical templates."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(1:2)2007", 
    "link": "http://arxiv.org/pdf/cs/0612120v2", 
    "title": "Generalizing the Paige-Tarjan Algorithm by Abstract Interpretation", 
    "arxiv-id": "cs/0612120v2", 
    "author": "Francesco Tapparo", 
    "publish": "2006-12-22T19:45:34Z", 
    "summary": "The Paige and Tarjan algorithm (PT) for computing the coarsest refinement of\na state partition which is a bisimulation on some Kripke structure is well\nknown. It is also well known in model checking that bisimulation is equivalent\nto strong preservation of CTL, or, equivalently, of Hennessy-Milner logic.\nDrawing on these observations, we analyze the basic steps of the PT algorithm\nfrom an abstract interpretation perspective, which allows us to reason on\nstrong preservation in the context of generic inductively defined (temporal)\nlanguages and of possibly non-partitioning abstract models specified by\nabstract interpretation. This leads us to design a generalized Paige-Tarjan\nalgorithm, called GPT, for computing the minimal refinement of an abstract\ninterpretation-based model that strongly preserves some given language. It\nturns out that PT is a straight instance of GPT on the domain of state\npartitions for the case of strong preservation of Hennessy-Milner logic. We\nprovide a number of examples showing that GPT is of general use. We first show\nhow a well-known efficient algorithm for computing stuttering equivalence can\nbe viewed as a simple instance of GPT. We then instantiate GPT in order to\ndesign a new efficient algorithm for computing simulation equivalence that is\ncompetitive with the best available algorithms. Finally, we show how GPT allows\nto compute new strongly preserving abstract models by providing an efficient\nalgorithm that computes the coarsest refinement of a given partition that\nstrongly preserves the language generated by the reachability operator."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(1:2)2007", 
    "link": "http://arxiv.org/pdf/cs/0701022v1", 
    "title": "Definable functions in the simply typed lambda-calculus", 
    "arxiv-id": "cs/0701022v1", 
    "author": "Mateusz Zakrzewski", 
    "publish": "2007-01-04T17:50:01Z", 
    "summary": "It is a common knowledge that the integer functions definable in simply typed\nlambda-calculus are exactly the extended polynomials. This is indeed the case\nwhen one interprets integers over the type (p->p)->p->p where p is a base type\nand/or equality is taken as beta-conversion. It is commonly believed that the\nsame holds for beta-eta equality and for integers represented over any fixed\ntype of the form (t->t)->t->t. In this paper we show that this opinion is not\nquite true.\n  We prove that the class of functions strictly definable in simply typed\nlambda-calculus is considerably larger than the extended polynomials. Namely,\nwe define F as the class of strictly definable functions and G as a class that\ncontains extended polynomials and two additional functions, or more precisely,\ntwo function schemas, and is closed under composition. We prove that G is a\nsubset of F.\n  We conjecture that G exactly characterizes strictly definable functions, i.e.\nG=F, and we gather some evidence for this conjecture proving, for example, that\nevery skewly representable finite range function is strictly representable over\n(t->t)->t->t for some t."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(1:2)2007", 
    "link": "http://arxiv.org/pdf/cs/0701029v1", 
    "title": "The Inhabitation Problem for Rank Two Intersection Types", 
    "arxiv-id": "cs/0701029v1", 
    "author": "Dariusz Kusmierek", 
    "publish": "2007-01-05T08:38:14Z", 
    "summary": "We prove that the inhabitation problem for rank two intersection types is\ndecidable, but (contrary to common belief) EXPTIME-hard. The exponential time\nhardness is shown by reduction from the in-place acceptance problem for\nalternating Turing machines."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(1:2)2007", 
    "link": "http://arxiv.org/pdf/cs/0701073v1", 
    "title": "A decision procedure for linear \"big O\" equations", 
    "arxiv-id": "cs/0701073v1", 
    "author": "Kevin Donnelly", 
    "publish": "2007-01-10T19:46:21Z", 
    "summary": "Let $F$ be the set of functions from an infinite set, $S$, to an ordered\nring, $R$. For $f$, $g$, and $h$ in $F$, the assertion $f = g + O(h)$ means\nthat for some constant $C$, $|f(x) - g(x)| \\leq C |h(x)|$ for every $x$ in $S$.\nLet $L$ be the first-order language with variables ranging over such functions,\nsymbols for $0, +, -, \\min, \\max$, and absolute value, and a ternary relation\n$f = g + O(h)$. We show that the set of quantifier-free formulas in this\nlanguage that are valid in the intended class of interpretations is decidable,\nand does not depend on the underlying set, $S$, or the ordered ring, $R$. If\n$R$ is a subfield of the real numbers, we can add a constant 1 function, as\nwell as multiplication by constants from any computable subfield. We obtain\nfurther decidability results for certain situations in which one adds symbols\ndenoting the elements of a fixed sequence of functions of strictly increasing\nrates of growth."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(1:2)2007", 
    "link": "http://arxiv.org/pdf/cs/0701076v2", 
    "title": "Time-complexity semantics for feasible affine recursions (extended   abstract)", 
    "arxiv-id": "cs/0701076v2", 
    "author": "James S. Royer", 
    "publish": "2007-01-11T16:22:11Z", 
    "summary": "The authors' ATR programming formalism is a version of call-by-value PCF\nunder a complexity-theoretically motivated type system. ATR programs run in\ntype-2 polynomial-time and all standard type-2 basic feasible functionals are\nATR-definable (ATR types are confined to levels 0, 1, and 2). A limitation of\nthe original version of ATR is that the only directly expressible recursions\nare tail-recursions. Here we extend ATR so that a broad range of affine\nrecursions are directly expressible. In particular, the revised ATR can fairly\nnaturally express the classic insertion- and selection-sort algorithms, thus\novercoming a sticking point of most prior implicit-complexity-based formalisms.\nThe paper's main work is in extending and simplifying the original\ntime-complexity semantics for ATR to develop a set of tools for extracting and\nsolving the higher-type recurrences arising from feasible affine recursions."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(1:2)2007", 
    "link": "http://arxiv.org/pdf/cs/0701113v1", 
    "title": "On factorisation forests", 
    "arxiv-id": "cs/0701113v1", 
    "author": "Thomas Colcombet", 
    "publish": "2007-01-17T16:48:28Z", 
    "summary": "The theorem of factorisation forests shows the existence of nested\nfactorisations -- a la Ramsey -- for finite words. This theorem has important\napplications in semigroup theory, and beyond. The purpose of this paper is to\nillustrate the importance of this approach in the context of automata over\ninfinite words and trees. We extend the theorem of factorisation forest in two\ndirections: we show that it is still valid for any word indexed by a linear\nordering; and we show that it admits a deterministic variant for words indexed\nby well-orderings. A byproduct of this work is also an improvement on the known\nbounds for the original result. We apply the first variant for giving a\nsimplified proof of the closure under complementation of rational sets of words\nindexed by countable scattered linear orderings. We apply the second variant in\nthe analysis of monadic second-order logic over trees, yielding new results on\nmonadic interpretations over trees. Consequences of it are new caracterisations\nof prefix-recognizable structures and of the Caucal hierarchy."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(1:7)2007", 
    "link": "http://arxiv.org/pdf/cs/0701138v2", 
    "title": "Real-Time Model-Checking: Parameters everywhere", 
    "arxiv-id": "cs/0701138v2", 
    "author": "Jean-Francois Raskin", 
    "publish": "2007-01-22T15:20:20Z", 
    "summary": "In this paper, we study the model-checking and parameter synthesis problems\nof the logic TCTL over discrete-timed automata where parameters are allowed\nboth in the model (timed automaton) and in the property (temporal formula). Our\nresults are as follows. On the negative side, we show that the model-checking\nproblem of TCTL extended with parameters is undecidable over discrete-timed\nautomata with only one parametric clock. The undecidability result needs\nequality in the logic. On the positive side, we show that the model-checking\nand the parameter synthesis problems become decidable for a fragment of the\nlogic where equality is not allowed. Our method is based on automata theoretic\nprinciples and an extension of our method to express durations of runs in timed\nautomata using Presburger arithmetic."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(1:4)2007", 
    "link": "http://arxiv.org/pdf/cs/0701154v2", 
    "title": "Logic Meets Algebra: the Case of Regular Languages", 
    "arxiv-id": "cs/0701154v2", 
    "author": "Denis Therien", 
    "publish": "2007-01-25T20:46:36Z", 
    "summary": "The study of finite automata and regular languages is a privileged meeting\npoint of algebra and logic. Since the work of Buchi, regular languages have\nbeen classified according to their descriptive complexity, i.e. the type of\nlogical formalism required to define them. The algebraic point of view on\nautomata is an essential complement of this classification: by providing\nalternative, algebraic characterizations for the classes, it often yields the\nonly opportunity for the design of algorithms that decide expressibility in\nsome logical fragment.\n  We survey the existing results relating the expressibility of regular\nlanguages in logical fragments of MSO[S] with algebraic properties of their\nminimal automata. In particular, we show that many of the best known results in\nthis area share the same underlying mechanics and rely on a very strong\nrelation between logical substitutions and block-products of pseudovarieties of\nmonoid. We also explain the impact of these connections on circuit complexity\ntheory."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(1:4)2007", 
    "link": "http://arxiv.org/pdf/cs/0702036v1", 
    "title": "Efficient First-Order Temporal Logic for Infinite-State Systems", 
    "arxiv-id": "cs/0702036v1", 
    "author": "Alexei Lisitsa", 
    "publish": "2007-02-06T15:10:51Z", 
    "summary": "In this paper we consider the specification and verification of\ninfinite-state systems using temporal logic. In particular, we describe\nparameterised systems using a new variety of first-order temporal logic that is\nboth powerful enough for this form of specification and tractable enough for\npractical deductive verification. Importantly, the power of the temporal\nlanguage allows us to describe (and verify) asynchronous systems, communication\ndelays and more complex properties such as liveness and fairness properties.\nThese aspects appear difficult for many other approaches to infinite-state\nverification."
},{
    "category": "cs.LO", 
    "doi": "10.1007/s00236-008-0074-3", 
    "link": "http://arxiv.org/pdf/cs/0702041v1", 
    "title": "The Fibers and Range of Reduction Graphs in Ciliates", 
    "arxiv-id": "cs/0702041v1", 
    "author": "Hendrik Jan Hoogeboom", 
    "publish": "2007-02-07T12:59:22Z", 
    "summary": "The biological process of gene assembly has been modeled based on three types\nof string rewriting rules, called string pointer rules, defined on so-called\nlegal strings. It has been shown that reduction graphs, graphs that are based\non the notion of breakpoint graph in the theory of sorting by reversal, for\nlegal strings provide valuable insights into the gene assembly process. We\ncharacterize which legal strings obtain the same reduction graph (up to\nisomorphism), and moreover we characterize which graphs are (isomorphic to)\nreduction graphs."
},{
    "category": "cs.LO", 
    "doi": "10.1007/s00236-008-0074-3", 
    "link": "http://arxiv.org/pdf/cs/0702069v1", 
    "title": "Feasible reactivity in a synchronous pi-calculus", 
    "arxiv-id": "cs/0702069v1", 
    "author": "Frederique Dabrowski", 
    "publish": "2007-02-11T15:43:26Z", 
    "summary": "Reactivity is an essential property of a synchronous program. Informally, it\nguarantees that at each instant the program fed with an input will `react'\nproducing an output. In the present work, we consider a refined property that\nwe call ` feasible reactivity'. Beyond reactivity, this property guarantees\nthat at each instant both the size of the program and its reaction time are\nbounded by a polynomial in the size of the parameters at the beginning of the\ncomputation and the size of the largest input. We propose a method to annotate\nprograms and we develop related static analysis techniques that guarantee\nfeasible reactivity for programs expressed in the S-pi-calculus. The latter is\na synchronous version of the pi-calculus based on the SL synchronous\nprogramming model."
},{
    "category": "cs.LO", 
    "doi": "10.1007/s00236-008-0074-3", 
    "link": "http://arxiv.org/pdf/cs/0702089v2", 
    "title": "Mapping the Object-Role Modeling language ORM2 into Description Logic   language DLRifd", 
    "arxiv-id": "cs/0702089v2", 
    "author": "C. Maria Keet", 
    "publish": "2007-02-15T23:45:46Z", 
    "summary": "In recent years, several efforts have been made to enhance conceptual data\nmodelling with automated reasoning to improve the model's quality and derive\nimplicit information. One approach to achieve this in implementations, is to\nconstrain the language. Advances in Description Logics can help choosing the\nright language to have greatest expressiveness yet to remain within the\ndecidable fragment of first order logic to realise a workable implementation\nwith good performance using DL reasoners. The best fit DL language appears to\nbe the ExpTime-complete DLRifd. To illustrate trade-offs and highlight features\nof the modelling languages, we present a precise transformation of the mappable\nfeatures of the very expressive (undecidable) ORM/ORM2 conceptual data\nmodelling languages to exactly DLRifd. Although not all ORM2 features can be\nmapped, this is an interesting fragment because it has been shown that DLRifd\ncan also encode UML Class Diagrams and EER, and therefore can foster\ninteroperation between conceptual data models and research into ontological\naspects of the modelling languages."
},{
    "category": "cs.LO", 
    "doi": "10.1007/s00236-008-0074-3", 
    "link": "http://arxiv.org/pdf/cs/0702116v2", 
    "title": "The Bedwyr system for model checking over syntactic expressions", 
    "arxiv-id": "cs/0702116v2", 
    "author": "Alwen Tiu", 
    "publish": "2007-02-20T10:08:24Z", 
    "summary": "Bedwyr is a generalization of logic programming that allows model checking\ndirectly on syntactic expressions possibly containing bindings. This system,\nwritten in OCaml, is a direct implementation of two recent advances in the\ntheory of proof search. The first is centered on the fact that both finite\nsuccess and finite failure can be captured in the sequent calculus by\nincorporating inference rules for definitions that allow fixed points to be\nexplored. As a result, proof search in such a sequent calculus can capture\nsimple model checking problems as well as may and must behavior in operational\nsemantics. The second is that higher-order abstract syntax is directly\nsupported using term-level $\\lambda$-binders and the $\\nabla$ quantifier. These\nfeatures allow reasoning directly on expressions containing bound variables."
},{
    "category": "cs.LO", 
    "doi": "10.1007/s00236-008-0074-3", 
    "link": "http://arxiv.org/pdf/cs/0702152v1", 
    "title": "A Simplified Suspension Calculus and its Relationship to Other Explicit   Substitution Calculi", 
    "arxiv-id": "cs/0702152v1", 
    "author": "Gopalan Nadathur", 
    "publish": "2007-02-26T02:16:57Z", 
    "summary": "This paper concerns the explicit treatment of substitutions in the lambda\ncalculus. One of its contributions is the simplification and rationalization of\nthe suspension calculus that embodies such a treatment. The earlier version of\nthis calculus provides a cumbersome encoding of substitution composition, an\noperation that is important to the efficient realization of reduction. This\nencoding is simplified here, resulting in a treatment that is easy to use\ndirectly in applications. The rationalization consists of the elimination of a\npractically inconsequential flexibility in the unravelling of substitutions\nthat has the inadvertent side effect of losing contextual information in terms;\nthe modified calculus now has a structure that naturally supports logical\nanalyses, such as ones related to the assignment of types, over lambda terms.\nThe overall calculus is shown to have pleasing theoretical properties such as a\nstrongly terminating sub-calculus for substitution and confluence even in the\npresence of term meta variables that are accorded a grafting interpretation.\nAnother contribution of the paper is the identification of a broad set of\nproperties that are desirable for explicit substitution calculi to support and\na classification of a variety of proposed systems based on these. The\nsuspension calculus is used as a tool in this study. In particular, mappings\nare described between it and the other calculi towards understanding the\ncharacteristics of the latter."
},{
    "category": "cs.LO", 
    "doi": "10.1007/s00236-008-0074-3", 
    "link": "http://arxiv.org/pdf/cs/0702171v1", 
    "title": "How Overlap Determines the Macronuclear Genes in Ciliates", 
    "arxiv-id": "cs/0702171v1", 
    "author": "Grzegorz Rozenberg", 
    "publish": "2007-02-28T15:51:26Z", 
    "summary": "Formal models for gene assembly in ciliates have been developed, in\nparticular the string pointer reduction system (SPRS) and the graph pointer\nreduction system (GPRS). The reduction graph is a valuable tool within the\nSPRS, revealing much information about how gene assembly is performed for a\ngiven gene. The GPRS is more abstract than the SPRS and not all information\npresent in the SPRS is retained in the GPRS. As a consequence the reduction\ngraph cannot be defined for the GPRS in general, but we show that it can be\ndefined (in an equivalent manner as defined for the SPRS) if we restrict\nourselves to so-called realistic overlap graphs. Fortunately, only these graphs\ncorrespond to genes occurring in nature. Defining the reduction graph within\nthe GPRS allows one to carry over several results within the SPRS that rely on\nthe reduction graph."
},{
    "category": "cs.LO", 
    "doi": "10.1007/s00236-008-0074-3", 
    "link": "http://arxiv.org/pdf/cs/0703015v1", 
    "title": "Graph representation of context-free grammars", 
    "arxiv-id": "cs/0703015v1", 
    "author": "Alex Shkotin", 
    "publish": "2007-03-03T13:12:51Z", 
    "summary": "In modern mathematics, graphs figure as one of the better-investigated class\nof mathematical objects. Various properties of graphs, as well as\ngraph-processing algorithms, can be useful if graphs of a certain kind are used\nas denotations for CF-grammars. Furthermore, graph are well adapted to various\nextensions (one kind of such extensions being attributes)."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(2:4)2007", 
    "link": "http://arxiv.org/pdf/cs/0703039v2", 
    "title": "Transforming structures by set interpretations", 
    "arxiv-id": "cs/0703039v2", 
    "author": "Christof L\u00f6ding", 
    "publish": "2007-03-08T12:52:55Z", 
    "summary": "We consider a new kind of interpretation over relational structures: finite\nsets interpretations. Those interpretations are defined by weak monadic\nsecond-order (WMSO) formulas with free set variables. They transform a given\nstructure into a structure with a domain consisting of finite sets of elements\nof the orignal structure. The definition of these interpretations directly\nimplies that they send structures with a decidable WMSO theory to structures\nwith a decidable first-order theory. In this paper, we investigate the\nexpressive power of such interpretations applied to infinite deterministic\ntrees. The results can be used in the study of automatic and tree-automatic\nstructures."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(2:4)2007", 
    "link": "http://arxiv.org/pdf/cs/0703051v3", 
    "title": "An ExpTime Procedure for Description Logic $\\mathcal{ALCQI}$ (Draft)", 
    "arxiv-id": "cs/0703051v3", 
    "author": "Yu Ding", 
    "publish": "2007-03-12T01:55:23Z", 
    "summary": "A worst-case ExpTime tableau-based decision procedure is outlined for the\nsatisfiability problem in $\\mathcal{ALCQI}$ w.r.t. general axioms."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(2:3)2007", 
    "link": "http://arxiv.org/pdf/cs/0703079v2", 
    "title": "Automata with Nested Pebbles Capture First-Order Logic with Transitive   Closure", 
    "arxiv-id": "cs/0703079v2", 
    "author": "Hendrik Jan Hoogeboom", 
    "publish": "2007-03-15T10:27:05Z", 
    "summary": "String languages recognizable in (deterministic) log-space are characterized\neither by two-way (deterministic) multi-head automata, or following Immerman,\nby first-order logic with (deterministic) transitive closure. Here we elaborate\nthis result, and match the number of heads to the arity of the transitive\nclosure. More precisely, first-order logic with k-ary deterministic transitive\nclosure has the same power as deterministic automata walking on their input\nwith k heads, additionally using a finite set of nested pebbles. This result is\nvalid for strings, ordered trees, and in general for families of graphs having\na fixed automaton that can be used to traverse the nodes of each of the graphs\nin the family. Other examples of such families are grids, toruses, and\nrectangular mazes. For nondeterministic automata, the logic is restricted to\npositive occurrences of transitive closure.\n  The special case of k=1 for trees, shows that single-head deterministic\ntree-walking automata with nested pebbles are characterized by first-order\nlogic with unary deterministic transitive closure. This refines our earlier\nresult that placed these automata between first-order and monadic second-order\nlogic on trees."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(2:3)2007", 
    "link": "http://arxiv.org/pdf/cs/0703152v1", 
    "title": "Quantum Lambda Calculi with Classical Control: Syntax and Expressive   Power", 
    "arxiv-id": "cs/0703152v1", 
    "author": "Margherita Zorzi", 
    "publish": "2007-03-30T08:59:43Z", 
    "summary": "We study an untyped lambda calculus with quantum data and classical control.\nThis work stems from previous proposals by Selinger and Valiron and by Van\nTonder. We focus on syntax and expressiveness, rather than (denotational)\nsemantics. We prove subject reduction, confluence and a standardization\ntheorem. Moreover, we prove the computational equivalence of the proposed\ncalculus with a suitable class of quantum circuit families."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(2:3)2007", 
    "link": "http://arxiv.org/pdf/0704.1707v2", 
    "title": "A Cut-free Sequent Calculus for Bi-Intuitionistic Logic: Extended   Version", 
    "arxiv-id": "0704.1707v2", 
    "author": "Rajeev Gor\u00e9", 
    "publish": "2007-04-13T07:29:31Z", 
    "summary": "Bi-intuitionistic logic is the extension of intuitionistic logic with a\nconnective dual to implication. Bi-intuitionistic logic was introduced by\nRauszer as a Hilbert calculus with algebraic and Kripke semantics. But her\nsubsequent ``cut-free'' sequent calculus for BiInt has recently been shown by\nUustalu to fail cut-elimination. We present a new cut-free sequent calculus for\nBiInt, and prove it sound and complete with respect to its Kripke semantics.\nEnsuring completeness is complicated by the interaction between implication and\nits dual, similarly to future and past modalities in tense logic. Our calculus\nhandles this interaction using extended sequents which pass information from\npremises to conclusions using variables instantiated at the leaves of failed\nderivation trees. Our simple termination argument allows our calculus to be\nused for automated deduction, although this is not its main purpose."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(2:3)2007", 
    "link": "http://arxiv.org/pdf/0704.2900v2", 
    "title": "Higher-order theories", 
    "arxiv-id": "0704.2900v2", 
    "author": "Marco Maggesi", 
    "publish": "2007-04-22T18:19:46Z", 
    "summary": "We extend our approach to abstract syntax (with binding constructions)\nthrough modules and linearity. First we give a new general definition of arity,\nyielding the companion notion of signature. Then we obtain a modularity result\nas requested by Ghani and Uustalu (2003): in our setting, merging two\nextensions of syntax corresponds to building an amalgamated sum. Finally we\ndefine a natural notion of equation concerning a signature and prove the\nexistence of an initial semantics for a so-called representable signature\nequipped with a set of equations."
},{
    "category": "cs.LO", 
    "doi": "10.1007/s10992-007-9078-7", 
    "link": "http://arxiv.org/pdf/0704.3238v1", 
    "title": "Alternative axiomatics and complexity of deliberative STIT theories", 
    "arxiv-id": "0704.3238v1", 
    "author": "Nicolas Troquard", 
    "publish": "2007-04-24T16:36:13Z", 
    "summary": "We propose two alternatives to Xu's axiomatization of the Chellas STIT. The\nfirst one also provides an alternative axiomatization of the deliberative STIT.\nThe second one starts from the idea that the historic necessity operator can be\ndefined as an abbreviation of operators of agency, and can thus be eliminated\nfrom the logic of the Chellas STIT. The second axiomatization also allows us to\nestablish that the problem of deciding the satisfiability of a STIT formula\nwithout temporal operators is NP-complete in the single-agent case, and is\nNEXPTIME-complete in the multiagent case, both for the deliberative and the\nChellas' STIT."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(2:7)2007", 
    "link": "http://arxiv.org/pdf/0704.3931v2", 
    "title": "The Complexity of Model Checking Higher-Order Fixpoint Logic", 
    "arxiv-id": "0704.3931v2", 
    "author": "Rafal Somla", 
    "publish": "2007-04-30T13:09:20Z", 
    "summary": "Higher-Order Fixpoint Logic (HFL) is a hybrid of the simply typed\n\\lambda-calculus and the modal \\lambda-calculus. This makes it a highly\nexpressive temporal logic that is capable of expressing various interesting\ncorrectness properties of programs that are not expressible in the modal\n\\lambda-calculus.\n  This paper provides complexity results for its model checking problem. In\nparticular we consider those fragments of HFL built by using only types of\nbounded order k and arity m. We establish k-fold exponential time completeness\nfor model checking each such fragment. For the upper bound we use fixpoint\nelimination to obtain reachability games that are singly-exponential in the\nsize of the formula and k-fold exponential in the size of the underlying\ntransition system. These games can be solved in deterministic linear time. As a\nsimple consequence, we obtain an exponential time upper bound on the expression\ncomplexity of each such fragment.\n  The lower bound is established by a reduction from the word problem for\nalternating (k-1)-fold exponential space bounded Turing Machines. Since there\nare fixed machines of that type whose word problems are already hard with\nrespect to k-fold exponential time, we obtain, as a corollary, k-fold\nexponential time completeness for the data complexity of our fragments of HFL,\nprovided m exceeds 3. This also yields a hierarchy result in expressive power."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(2:7)2007", 
    "link": "http://arxiv.org/pdf/0705.1367v1", 
    "title": "Logic Column 18: Alternative Logics: A Book Review", 
    "arxiv-id": "0705.1367v1", 
    "author": "Riccardo Pucella", 
    "publish": "2007-05-09T21:56:15Z", 
    "summary": "This article discusses two books on the topic of alternative logics in\nscience: \"Deviant Logic\", by Susan Haack, and \"Alternative Logics: Do Sciences\nNeed Them?\", edited by Paul Weingartner."
},{
    "category": "cs.LO", 
    "doi": "10.1007/s00236-006-0022-z", 
    "link": "http://arxiv.org/pdf/0705.3487v1", 
    "title": "Linearly bounded infinite graphs", 
    "arxiv-id": "0705.3487v1", 
    "author": "Antoine Meyer", 
    "publish": "2007-05-24T15:29:21Z", 
    "summary": "Linearly bounded Turing machines have been mainly studied as acceptors for\ncontext-sensitive languages. We define a natural class of infinite automata\nrepresenting their observable computational behavior, called linearly bounded\ngraphs. These automata naturally accept the same languages as the linearly\nbounded machines defining them. We present some of their structural properties\nas well as alternative characterizations in terms of rewriting systems and\ncontext-sensitive transductions. Finally, we compare these graphs to rational\ngraphs, which are another class of automata accepting the context-sensitive\nlanguages, and prove that in the bounded-degree case, rational graphs are a\nstrict sub-class of linearly bounded graphs."
},{
    "category": "cs.LO", 
    "doi": "10.1007/11690634_7", 
    "link": "http://arxiv.org/pdf/0705.3610v1", 
    "title": "A Logic of Reachable Patterns in Linked Data-Structures", 
    "arxiv-id": "0705.3610v1", 
    "author": "Ahmed Bouajjani", 
    "publish": "2007-05-24T16:10:52Z", 
    "summary": "We define a new decidable logic for expressing and checking invariants of\nprograms that manipulate dynamically-allocated objects via pointers and\ndestructive pointer updates. The main feature of this logic is the ability to\nlimit the neighborhood of a node that is reachable via a regular expression\nfrom a designated node. The logic is closed under boolean operations\n(entailment, negation) and has a finite model property. The key technical\nresult is the proof of decidability. We show how to express precondition,\npostconditions, and loop invariants for some interesting programs. It is also\npossible to express properties such as disjointness of data-structures, and\nlow-level heap mutations. Moreover, our logic can express properties of\narbitrary data-structures and of an arbitrary number of pointer fields. The\nlatter provides a way to naturally specify postconditions that relate the\nfields on entry to a procedure to the fields on exit. Therefore, it is possible\nto use the logic to automatically prove partial correctness of programs\nperforming low-level heap mutations."
},{
    "category": "cs.LO", 
    "doi": "10.1007/b104325", 
    "link": "http://arxiv.org/pdf/0705.3888v1", 
    "title": "Symbolic Reachability Analysis of Higher-Order Context-Free Processes", 
    "arxiv-id": "0705.3888v1", 
    "author": "Antoine Meyer", 
    "publish": "2007-05-28T16:31:04Z", 
    "summary": "We consider the problem of symbolic reachability analysis of higher-order\ncontext-free processes. These models are generalizations of the context-free\nprocesses (also called BPA processes) where each process manipulates a data\nstructure which can be seen as a nested stack of stacks. Our main result is\nthat, for any higher-order context-free process, the set of all predecessors of\na given regular set of configurations is regular and effectively constructible.\nThis result generalizes the analogous result which is known for level 1\ncontext-free processes. We show that this result holds also in the case of\nbackward reachability analysis under a regular constraint on configurations. As\na corollary, we obtain a symbolic model checking algorithm for the temporal\nlogic E(U,X) with regular atomic predicates, i.e., the fragment of CTL\nrestricted to the EU and EX modalities."
},{
    "category": "cs.LO", 
    "doi": "10.1007/b95995", 
    "link": "http://arxiv.org/pdf/0705.4064v1", 
    "title": "On Term Rewriting Systems Having a Rational Derivation", 
    "arxiv-id": "0705.4064v1", 
    "author": "Antoine Meyer", 
    "publish": "2007-05-28T16:30:27Z", 
    "summary": "Several types of term rewriting systems can be distinguished by the way their\nrules overlap. In particular, we define the classes of prefix, suffix,\nbottom-up and top-down systems, which generalize similar classes on words. Our\naim is to study the derivation relation of such systems (i.e. the reflexive and\ntransitive closure of their rewriting relation) and, if possible, to provide a\nfinite mechanism characterizing it. Using a notion of rational relations based\non finite graph grammars, we show that the derivation of any bottom-up,\ntop-down or suffix systems is rational, while it can be non recursive for\nprefix systems."
},{
    "category": "cs.LO", 
    "doi": "10.1007/b95995", 
    "link": "http://arxiv.org/pdf/0705.4226v1", 
    "title": "Second-Order Type Isomorphisms Through Game Semantics", 
    "arxiv-id": "0705.4226v1", 
    "author": "Joachim De Lataillade", 
    "publish": "2007-05-29T14:26:26Z", 
    "summary": "The characterization of second-order type isomorphisms is a purely\nsyntactical problem that we propose to study under the enlightenment of game\nsemantics. We study this question in the case of second-order\n&#955;$\\mu$-calculus, which can be seen as an extension of system F to\nclassical logic, and for which we de&#64257;ne a categorical framework: control\nhyperdoctrines. Our game model of &#955;$\\mu$-calculus is based on polymorphic\narenas (closely related to Hughes' hyperforests) which evolve during the play\n(following the ideas of Murawski-Ong). We show that type isomorphisms coincide\nwith the \"equality\" on arenas associated with types. Finally we deduce the\nequational characterization of type isomorphisms from this equality. We also\nrecover from the same model Roberto Di Cosmo's characterization of type\nisomorphisms for system F. This approach leads to a geometrical comprehension\non the question of second order type isomorphisms, which can be easily extended\nto some other polymorphic calculi including additional programming features."
},{
    "category": "cs.LO", 
    "doi": "10.1007/b95995", 
    "link": "http://arxiv.org/pdf/0705.4228v1", 
    "title": "Curry-style type Isomorphisms and Game Semantics", 
    "arxiv-id": "0705.4228v1", 
    "author": "Joachim De Lataillade", 
    "publish": "2007-05-29T14:31:02Z", 
    "summary": "Curry-style system F, ie. system F with no explicit types in terms, can be\nseen as a core presentation of polymorphism from the point of view of\nprogramming languages. This paper gives a characterisation of type isomorphisms\nfor this language, by using a game model whose intuitions come both from the\nsyntax and from the game semantics universe. The model is composed of: an\nuntyped part to interpret terms, a notion of game to interpret types, and a\ntyped part to express the fact that an untyped strategy plays on a game. By\nanalysing isomorphisms in the model, we prove that the equational system\ncorresponding to type isomorphisms for Curry-style system F is the extension of\nthe equational system for Church-style isomorphisms with a new, non-trivial\nequation: forall X.A = A[forall Y.Y/X] if X appears only positively in A."
},{
    "category": "cs.LO", 
    "doi": "10.1007/b95995", 
    "link": "http://arxiv.org/pdf/0705.4604v1", 
    "title": "Temporal Runtime Verification using Monadic Difference Logic", 
    "arxiv-id": "0705.4604v1", 
    "author": "Kaare J. Kristoffersen", 
    "publish": "2007-05-31T13:22:02Z", 
    "summary": "In this paper we present an algorithm for performing runtime verification of\na bounded temporal logic over timed runs. The algorithm consists of three\nelements. First, the bounded temporal formula to be verified is translated into\na monadic first-order logic over difference inequalities, which we call monadic\ndifference logic. Second, at each step of the timed run, the monadic difference\nformula is modified by computing a quotient with the state and time of that\nstep. Third, the resulting formula is checked for being a tautology or being\nunsatisfiable by a decision procedure for monadic difference logic.\n  We further provide a simple decision procedure for monadic difference logic\nbased on the data structure Difference Decision Diagrams. The algorithm is\ncomplete in a very strong sense on a subclass of temporal formulae\ncharacterized as homogeneously monadic and it is approximate on other formulae.\nThe approximation comes from the fact that not all unsatisfiable or\ntautological formulae are recognised at the earliest possible time of the\nruntime verification.\n  Contrary to existing approaches, the presented algorithms do not work by\nsyntactic rewriting but employ efficient decision structures which make them\napplicable in real applications within for instance business software."
},{
    "category": "cs.LO", 
    "doi": "10.1007/b95995", 
    "link": "http://arxiv.org/pdf/0706.0692v2", 
    "title": "Probabilistic Interval Temporal Logic and Duration Calculus with   Infinite Intervals: Complete Proof Systems", 
    "arxiv-id": "0706.0692v2", 
    "author": "Dimitar P. Guelev", 
    "publish": "2007-06-05T15:46:09Z", 
    "summary": "The paper presents probabilistic extensions of interval temporal logic (ITL)\nand duration calculus (DC) with infinite intervals and complete Hilbert-style\nproof systems for them. The completeness results are a strong completeness\ntheorem for the system of probabilistic ITL with respect to an abstract\nsemantics and a relative completeness theorem for the system of probabilistic\nDC with respect to real-time semantics. The proposed systems subsume\nprobabilistic real-time DC as known from the literature. A correspondence\nbetween the proposed systems and a system of probabilistic interval temporal\nlogic with finite intervals and expanding modalities is established too."
},{
    "category": "cs.LO", 
    "doi": "10.1007/b95995", 
    "link": "http://arxiv.org/pdf/0706.1118v1", 
    "title": "Asynchronous games: innocence without alternation", 
    "arxiv-id": "0706.1118v1", 
    "author": "Samuel Mimram", 
    "publish": "2007-06-08T06:56:31Z", 
    "summary": "The notion of innocent strategy was introduced by Hyland and Ong in order to\ncapture the interactive behaviour of lambda-terms and PCF programs. An innocent\nstrategy is defined as an alternating strategy with partial memory, in which\nthe strategy plays according to its view. Extending the definition to\nnon-alternating strategies is problematic, because the traditional definition\nof views is based on the hypothesis that Opponent and Proponent alternate\nduring the interaction. Here, we take advantage of the diagrammatic\nreformulation of alternating innocence in asynchronous games, in order to\nprovide a tentative definition of innocence in non-alternating games. The task\nis interesting, and far from easy. It requires the combination of true\nconcurrency and game semantics in a clean and organic way, clarifying the\nrelationship between asynchronous games and concurrent games in the sense of\nAbramsky and Melli\\`es. It also requires an interactive reformulation of the\nusual acyclicity criterion of linear logic, as well as a directed variant, as a\nscheduling criterion."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(3:1)2007", 
    "link": "http://arxiv.org/pdf/0706.2076v3", 
    "title": "A Finite Semantics of Simply-Typed Lambda Terms for Infinite Runs of<br>   Automata", 
    "arxiv-id": "0706.2076v3", 
    "author": "Klaus Aehlig", 
    "publish": "2007-06-14T09:57:27Z", 
    "summary": "Model checking properties are often described by means of finite automata.\nAny particular such automaton divides the set of infinite trees into finitely\nmany classes, according to which state has an infinite run. Building the full\ntype hierarchy upon this interpretation of the base type gives a finite\nsemantics for simply-typed lambda-trees.\n  A calculus based on this semantics is proven sound and complete. In\nparticular, for regular infinite lambda-trees it is decidable whether a given\nautomaton has a run or not. As regular lambda-trees are precisely recursion\nschemes, this decidability result holds for arbitrary recursion schemes of\narbitrary level, without any syntactical restriction."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(3:1)2007", 
    "link": "http://arxiv.org/pdf/0706.2544v1", 
    "title": "Abstract machines for dialogue games", 
    "arxiv-id": "0706.2544v1", 
    "author": "Hugo Herbelin", 
    "publish": "2007-06-18T08:01:12Z", 
    "summary": "The notion of abstract Boehm tree has arisen as an operationally-oriented\ndistillation of works on game semantics, and has been investigated in two\npapers. This paper revisits the notion, providing more syntactic support and\nmore examples (like call-by-value evaluation) illustrating the generality of\nthe underlying computing device. Precise correspondences between various\nformulations of the evaluation mechanism of abstract Boehm trees are\nestablished."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(3:1)2007", 
    "link": "http://arxiv.org/pdf/0706.3341v1", 
    "title": "A Sequent Calculus for Modelling Interferences", 
    "arxiv-id": "0706.3341v1", 
    "author": "Christophe Fouquer\u00e9", 
    "publish": "2007-06-22T14:24:34Z", 
    "summary": "A logic calculus is presented that is a conservative extension of linear\nlogic. The motivation beneath this work concerns lazy evaluation, true\nconcurrency and interferences in proof search. The calculus includes two new\nconnectives to deal with multisequent structures and has the cut-elimination\nproperty. Extensions are proposed that give first results concerning our\nobjectives."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(3:1)2007", 
    "link": "http://arxiv.org/pdf/0706.3723v2", 
    "title": "Order-Invariant MSO is Stronger than Counting MSO in the Finite", 
    "arxiv-id": "0706.3723v2", 
    "author": "Sasha Rubin", 
    "publish": "2007-06-26T12:16:18Z", 
    "summary": "We compare the expressiveness of two extensions of monadic second-order logic\n(MSO) over the class of finite structures. The first, counting monadic\nsecond-order logic (CMSO), extends MSO with first-order modulo-counting\nquantifiers, allowing the expression of queries like ``the number of elements\nin the structure is even''. The second extension allows the use of an\nadditional binary predicate, not contained in the signature of the queried\nstructure, that must be interpreted as an arbitrary linear order on its\nuniverse, obtaining order-invariant MSO.\n  While it is straightforward that every CMSO formula can be translated into an\nequivalent order-invariant MSO formula, the converse had not yet been settled.\nCourcelle showed that for restricted classes of structures both order-invariant\nMSO and CMSO are equally expressive, but conjectured that, in general,\norder-invariant MSO is stronger than CMSO.\n  We affirm this conjecture by presenting a class of structures that is\norder-invariantly definable in MSO but not definable in CMSO."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(3:1)2007", 
    "link": "http://arxiv.org/pdf/0707.0556v2", 
    "title": "Determinacy in a synchronous pi-calculus", 
    "arxiv-id": "0707.0556v2", 
    "author": "Mehdi Dogguy", 
    "publish": "2007-07-04T08:12:17Z", 
    "summary": "The S-pi-calculus is a synchronous pi-calculus which is based on the SL\nmodel. The latter is a relaxation of the Esterel model where the reaction to\nthe absence of a signal within an instant can only happen at the next instant.\nIn the present work, we present and characterise a compositional semantics of\nthe S-pi-calculus based on suitable notions of labelled transition system and\nbisimulation. Based on this semantic framework, we explore the notion of\ndeterminacy and the related one of (local) confluence."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(3:1)2007", 
    "link": "http://arxiv.org/pdf/0707.0562v2", 
    "title": "On a Non-Context-Free Extension of PDL", 
    "arxiv-id": "0707.0562v2", 
    "author": "Dirk Nowotka", 
    "publish": "2007-07-04T09:33:21Z", 
    "summary": "Over the last 25 years, a lot of work has been done on seeking for decidable\nnon-regular extensions of Propositional Dynamic Logic (PDL). Only recently, an\nexpressive extension of PDL, allowing visibly pushdown automata (VPAs) as a\nformalism to describe programs, was introduced and proven to have a\nsatisfiability problem complete for deterministic double exponential time.\nLately, the VPA formalism was extended to so called k-phase multi-stack visibly\npushdown automata (k-MVPAs). Similarly to VPAs, it has been shown that the\nlanguage of k-MVPAs have desirable effective closure properties and that the\nemptiness problem is decidable. On the occasion of introducing k-MVPAs, it has\nbeen asked whether the extension of PDL with k-MVPAs still leads to a decidable\nlogic. This question is answered negatively here. We prove that already for the\nextension of PDL with 2-phase MVPAs with two stacks satisfiability becomes\n\\Sigma_1^1-complete."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(3:1)2007", 
    "link": "http://arxiv.org/pdf/0707.0744v1", 
    "title": "A process algebra based framework for promise theory", 
    "arxiv-id": "0707.0744v1", 
    "author": "Mark Burgess", 
    "publish": "2007-07-05T09:39:14Z", 
    "summary": "We present a process algebra based approach to formalize the interactions of\ncomputing devices such as the representation of policies and the resolution of\nconflicts. As an example we specify how promises may be used in coming to an\nagreement regarding a simple though practical transportation problem."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(1:1)2008", 
    "link": "http://arxiv.org/pdf/0707.0890v2", 
    "title": "Are there Hilbert-style Pure Type Systems?", 
    "arxiv-id": "0707.0890v2", 
    "author": "W. M. J. Dekkers", 
    "publish": "2007-07-06T00:22:59Z", 
    "summary": "For many a natural deduction style logic there is a Hilbert-style logic that\nis equivalent to it in that it has the same theorems (i.e. valid judgements\nwith empty contexts). For intuitionistic logic, the axioms of the equivalent\nHilbert-style logic can be propositions which are also known as the types of\nthe combinators I, K and S. Hilbert-style versions of illative combinatory\nlogic have formulations with axioms that are actual type statements for I, K\nand S. As pure type systems (PTSs)are, in a sense, equivalent to systems of\nillative combinatory logic, it might be thought that Hilbert-style PTSs (HPTSs)\ncould be based in a similar way. This paper shows that some PTSs have very\ntrivial equivalent HPTSs, with only the axioms as theorems and that for many\nPTSs no equivalent HPTS can exist. Most commonly used PTSs belong to these two\nclasses. For some PTSs however, including lambda* and the PTS at the basis of\nthe proof assistant Coq, there is a nontrivial equivalent HPTS, with axioms\nthat are type statements for I, K and S."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(1:1)2008", 
    "link": "http://arxiv.org/pdf/0707.1266v1", 
    "title": "Building Decision Procedures in the Calculus of Inductive Constructions", 
    "arxiv-id": "0707.1266v1", 
    "author": "Pierre-Yves Strub", 
    "publish": "2007-07-09T14:35:14Z", 
    "summary": "It is commonly agreed that the success of future proof assistants will rely\non their ability to incorporate computations within deduction in order to mimic\nthe mathematician when replacing the proof of a proposition P by the proof of\nan equivalent proposition P' obtained from P thanks to possibly complex\ncalculations. In this paper, we investigate a new version of the calculus of\ninductive constructions which incorporates arbitrary decision procedures into\ndeduction via the conversion rule of the calculus. The novelty of the problem\nin the context of the calculus of inductive constructions lies in the fact that\nthe computation mechanism varies along proof-checking: goals are sent to the\ndecision procedure together with the set of user hypotheses available from the\ncurrent context. Our main result shows that this extension of the calculus of\nconstructions does not compromise its main properties: confluence, subject\nreduction, strong normalization and consistency are all preserved."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(1:1)2008", 
    "link": "http://arxiv.org/pdf/0707.1372v1", 
    "title": "Computability Closure: Ten Years Later", 
    "arxiv-id": "0707.1372v1", 
    "author": "Fr\u00e9d\u00e9ric Blanqui", 
    "publish": "2007-07-10T06:33:52Z", 
    "summary": "The notion of computability closure has been introduced for proving the\ntermination of higher-order rewriting with first-order matching by Jean-Pierre\nJouannaud and Mitsuhiro Okada in a 1997 draft which later served as a basis for\nthe author's PhD. In this paper, we show how this notion can also be used for\ndealing with beta-normalized rewriting with matching modulo beta-eta (on\npatterns \\`a la Miller), rewriting with matching modulo some equational theory,\nand higher-order data types (types with constructors having functional\nrecursive arguments). Finally, we show how the computability closure can easily\nbe turned into a reduction ordering which, in the higher-order case, contains\nJean-Pierre Jouannaud and Albert Rubio's higher-order recursive path ordering\nand, in the first-order case, is equal to the usual first-order recursive path\nordering."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(3:6)2007", 
    "link": "http://arxiv.org/pdf/0707.1981v3", 
    "title": "A Normalizing Intuitionistic Set Theory with Inaccessible Sets", 
    "arxiv-id": "0707.1981v3", 
    "author": "Wojciech Moczydlowski", 
    "publish": "2007-07-13T12:02:10Z", 
    "summary": "We propose a set theory strong enough to interpret powerful type theories\nunderlying proof assistants such as LEGO and also possibly Coq, which at the\nsame time enables program extraction from its constructive proofs. For this\npurpose, we axiomatize an impredicative constructive version of\nZermelo-Fraenkel set theory IZF with Replacement and $\\omega$-many\ninaccessibles, which we call \\izfio. Our axiomatization utilizes set terms, an\ninductive definition of inaccessible sets and the mutually recursive nature of\nequality and membership relations. It allows us to define a weakly-normalizing\ntyped lambda calculus corresponding to proofs in \\izfio according to the\nCurry-Howard isomorphism principle. We use realizability to prove the\nnormalization theorem, which provides a basis for program extraction\ncapability."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(3:7)2007", 
    "link": "http://arxiv.org/pdf/0707.3170v3", 
    "title": "Inductive Definition and Domain Theoretic Properties of Fully Abstract", 
    "arxiv-id": "0707.3170v3", 
    "author": "Vladimir Sazonov", 
    "publish": "2007-07-21T00:29:38Z", 
    "summary": "A construction of fully abstract typed models for PCF and PCF^+ (i.e., PCF +\n\"parallel conditional function\"), respectively, is presented. It is based on\ngeneral notions of sequential computational strategies and wittingly consistent\nnon-deterministic strategies introduced by the author in the seventies.\nAlthough these notions of strategies are old, the definition of the fully\nabstract models is new, in that it is given level-by-level in the finite type\nhierarchy. To prove full abstraction and non-dcpo domain theoretic properties\nof these models, a theory of computational strategies is developed. This is\nalso an alternative and, in a sense, an analogue to the later game strategy\nsemantics approaches of Abramsky, Jagadeesan, and Malacaria; Hyland and Ong;\nand Nickau. In both cases of PCF and PCF^+ there are definable universal\n(surjective) functionals from numerical functions to any given type,\nrespectively, which also makes each of these models unique up to isomorphism.\nAlthough such models are non-omega-complete and therefore not continuous in the\ntraditional terminology, they are also proved to be sequentially complete (a\nweakened form of omega-completeness), \"naturally\" continuous (with respect to\nexisting directed \"pointwise\", or \"natural\" lubs) and also \"naturally\"\nomega-algebraic and \"naturally\" bounded complete -- appropriate generalisation\nof the ordinary notions of domain theory to the case of non-dcpos."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(4:3)2007", 
    "link": "http://arxiv.org/pdf/0707.3782v2", 
    "title": "Interactive Small-Step Algorithms I: Axiomatization", 
    "arxiv-id": "0707.3782v2", 
    "author": "Benjamin Rossman", 
    "publish": "2007-07-25T17:04:26Z", 
    "summary": "In earlier work, the Abstract State Machine Thesis -- that arbitrary\nalgorithms are behaviorally equivalent to abstract state machines -- was\nestablished for several classes of algorithms, including ordinary, interactive,\nsmall-step algorithms. This was accomplished on the basis of axiomatizations of\nthese classes of algorithms. Here we extend the axiomatization and, in a\ncompanion paper, the proof, to cover interactive small-step algorithms that are\nnot necessarily ordinary. This means that the algorithms (1) can complete a\nstep without necessarily waiting for replies to all queries from that step and\n(2) can use not only the environment's replies but also the order in which the\nreplies were received."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(4:4)2007", 
    "link": "http://arxiv.org/pdf/0707.3789v2", 
    "title": "Interactive Small-Step Algorithms II: Abstract State Machines and   the<br> Characterization Theorem", 
    "arxiv-id": "0707.3789v2", 
    "author": "Benjamin Rossman", 
    "publish": "2007-07-25T17:35:46Z", 
    "summary": "In earlier work, the Abstract State Machine Thesis -- that arbitrary\nalgorithms are behaviorally equivalent to abstract state machines -- was\nestablished for several classes of algorithms, including ordinary, interactive,\nsmall-step algorithms. This was accomplished on the basis of axiomatizations of\nthese classes of algorithms. In Part I (Interactive Small-Step Algorithms I:\nAxiomatization), the axiomatization was extended to cover interactive\nsmall-step algorithms that are not necessarily ordinary. This means that the\nalgorithms (1) can complete a step without necessarily waiting for replies to\nall queries from that step and (2) can use not only the environment's replies\nbut also the order in which the replies were received. In order to prove the\nthesis for algorithms of this generality, we extend here the definition of\nabstract state machines to incorporate explicit attention to the relative\ntiming of replies and to the possible absence of replies. We prove the\ncharacterization theorem for extended abstract state machines with respect to\ngeneral algorithms as axiomatized in Part I."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(4:2)2007", 
    "link": "http://arxiv.org/pdf/0708.0200v2", 
    "title": "A Note on Shortest Developments", 
    "arxiv-id": "0708.0200v2", 
    "author": "Morten Heine S\u00f8rensen", 
    "publish": "2007-08-01T17:22:48Z", 
    "summary": "De Vrijer has presented a proof of the finite developments theorem which, in\naddition to showing that all developments are finite, gives an effective\nreduction strategy computing longest developments as well as a simple formula\ncomputing their length.\n  We show that by applying a rather simple and intuitive principle of duality\nto de Vrijer's approach one arrives at a proof that some developments are\nfinite which in addition yields an effective reduction strategy computing\nshortest developments as well as a simple formula computing their length. The\nduality fails for general beta-reduction.\n  Our results simplify previous work by Khasidashvili."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(4:2)2007", 
    "link": "http://arxiv.org/pdf/0708.0713v1", 
    "title": "Edit and verify", 
    "arxiv-id": "0708.0713v1", 
    "author": "Micha\u0142 Moskal", 
    "publish": "2007-08-06T07:47:34Z", 
    "summary": "Automated theorem provers are used in extended static checking, where they\nare the performance bottleneck. Extended static checkers are run typically\nafter incremental changes to the code. We propose to exploit this usage pattern\nto improve performance. We present two approaches of how to do so and a full\nsolution."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(4:2)2007", 
    "link": "http://arxiv.org/pdf/0708.1480v2", 
    "title": "Valid formulas, games and network protocols", 
    "arxiv-id": "0708.1480v2", 
    "author": "Yves Legrandg\u00e9rard", 
    "publish": "2007-08-10T16:17:00Z", 
    "summary": "We describe a remarkable relation between the notion of valid formula of\npredicate logic and the specification of network protocols. We give several\nexamples such as the acknowledgement of one packet or of a sequence of packets.\nWe show how to specify the composition of protocols."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(4:2)2007", 
    "link": "http://arxiv.org/pdf/0708.2230v1", 
    "title": "Collection analysis for Horn clause programs", 
    "arxiv-id": "0708.2230v1", 
    "author": "Dale Miller", 
    "publish": "2007-08-16T15:45:06Z", 
    "summary": "We consider approximating data structures with collections of the items that\nthey contain. For examples, lists, binary trees, tuples, etc, can be\napproximated by sets or multisets of the items within them. Such approximations\ncan be used to provide partial correctness properties of logic programs. For\nexample, one might wish to specify than whenever the atom $sort(t,s)$ is proved\nthen the two lists $t$ and $s$ contain the same multiset of items (that is, $s$\nis a permutation of $t$). If sorting removes duplicates, then one would like to\ninfer that the sets of items underlying $t$ and $s$ are the same. Such results\ncould be useful to have if they can be determined statically and automatically.\nWe present a scheme by which such collection analysis can be structured and\nautomated. Central to this scheme is the use of linear logic as a omputational\nlogic underlying the logic of Horn clauses."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(4:2)2007", 
    "link": "http://arxiv.org/pdf/0708.2252v1", 
    "title": "Focusing and Polarization in Intuitionistic Logic", 
    "arxiv-id": "0708.2252v1", 
    "author": "Dale Miller", 
    "publish": "2007-08-16T17:36:28Z", 
    "summary": "A focused proof system provides a normal form to cut-free proofs that\nstructures the application of invertible and non-invertible inference rules.\nThe focused proof system of Andreoli for linear logic has been applied to both\nthe proof search and the proof normalization approaches to computation. Various\nproof systems in literature exhibit characteristics of focusing to one degree\nor another. We present a new, focused proof system for intuitionistic logic,\ncalled LJF, and show how other proof systems can be mapped into the new system\nby inserting logical connectives that prematurely stop focusing. We also use\nLJF to design a focused proof system for classical logic. Our approach to the\ndesign and analysis of these systems is based on the completeness of focusing\nin linear logic and on the notion of polarity that appears in Girard's LC and\nLU proof systems."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(4:9)2007", 
    "link": "http://arxiv.org/pdf/0708.3477v2", 
    "title": "The Church Synthesis Problem with Parameters", 
    "arxiv-id": "0708.3477v2", 
    "author": "Alexander Rabinovich", 
    "publish": "2007-08-26T12:08:30Z", 
    "summary": "For a two-variable formula &psi;(X,Y) of Monadic Logic of Order (MLO) the\nChurch Synthesis Problem concerns the existence and construction of an operator\nY=F(X) such that &psi;(X,F(X)) is universally valid over Nat.\n  B\\\"{u}chi and Landweber proved that the Church synthesis problem is\ndecidable; moreover, they showed that if there is an operator F that solves the\nChurch Synthesis Problem, then it can also be solved by an operator defined by\na finite state automaton or equivalently by an MLO formula. We investigate a\nparameterized version of the Church synthesis problem. In this version &psi;\nmight contain as a parameter a unary predicate P. We show that the Church\nsynthesis problem for P is computable if and only if the monadic theory of\n<Nat,<,P> is decidable. We prove that the B\\\"{u}chi-Landweber theorem can be\nextended only to ultimately periodic parameters. However, the MLO-definability\npart of the B\\\"{u}chi-Landweber theorem holds for the parameterized version of\nthe Church synthesis problem."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(4:9)2007", 
    "link": "http://arxiv.org/pdf/0708.3582v1", 
    "title": "HORPO with Computability Closure : A Reconstruction", 
    "arxiv-id": "0708.3582v1", 
    "author": "Albert Rubio", 
    "publish": "2007-08-27T12:23:16Z", 
    "summary": "This paper provides a new, decidable definition of the higher- order\nrecursive path ordering in which type comparisons are made only when needed,\ntherefore eliminating the need for the computability clo- sure, and bound\nvariables are handled explicitly, making it possible to handle recursors for\narbitrary strictly positive inductive types."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(4:9)2007", 
    "link": "http://arxiv.org/pdf/0709.0446v1", 
    "title": "Logic Column 19: Symbolic Model Checking for Temporal-Epistemic Logics", 
    "arxiv-id": "0709.0446v1", 
    "author": "Wojciech Penczek", 
    "publish": "2007-09-04T14:38:10Z", 
    "summary": "This article surveys some of the recent work in verification of temporal\nepistemic logic via symbolic model checking, focusing on OBDD-based and\nSAT-based approaches for epistemic logics built on discrete and real-time\nbranching time temporal logics."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(4:9)2007", 
    "link": "http://arxiv.org/pdf/0709.4118v2", 
    "title": "An efficient simulation algorithm based on abstract interpretation", 
    "arxiv-id": "0709.4118v2", 
    "author": "Francesco Tapparo", 
    "publish": "2007-09-26T09:54:31Z", 
    "summary": "A number of algorithms for computing the simulation preorder are available.\nLet Sigma denote the state space, -> the transition relation and Psim the\npartition of Sigma induced by simulation equivalence. The algorithms by\nHenzinger, Henzinger, Kopke and by Bloom and Paige run in O(|Sigma||->|)-time\nand, as far as time-complexity is concerned, they are the best available\nalgorithms. However, these algorithms have the drawback of a space complexity\nthat is more than quadratic in the size of the state space. The algorithm by\nGentilini, Piazza, Policriti--subsequently corrected by van Glabbeek and\nPloeger--appears to provide the best compromise between time and space\ncomplexity. Gentilini et al.'s algorithm runs in O(|Psim|^2|->|)-time while the\nspace complexity is in O(|Psim|^2 + |Sigma|log|Psim|). We present here a new\nefficient simulation algorithm that is obtained as a modification of Henzinger\net al.'s algorithm and whose correctness is based on some techniques used in\napplications of abstract interpretation to model checking. Our algorithm runs\nin O(|Psim||->|)-time and O(|Psim||Sigma|log|Sigma|)-space. Thus, this\nalgorithm improves the best known time bound while retaining an acceptable\nspace complexity that is in general less than quadratic in the size of the\nstate space. An experimental evaluation showed good comparative results with\nrespect to Henzinger, Henzinger and Kopke's algorithm."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(4:11)2007", 
    "link": "http://arxiv.org/pdf/0710.2505v2", 
    "title": "Generic Trace Semantics via Coinduction", 
    "arxiv-id": "0710.2505v2", 
    "author": "Ana Sokolova", 
    "publish": "2007-10-12T16:28:43Z", 
    "summary": "Trace semantics has been defined for various kinds of state-based systems,\nnotably with different forms of branching such as non-determinism vs.\nprobability. In this paper we claim to identify one underlying mathematical\nstructure behind these \"trace semantics,\" namely coinduction in a Kleisli\ncategory. This claim is based on our technical result that, under a suitably\norder-enriched setting, a final coalgebra in a Kleisli category is given by an\ninitial algebra in the category Sets. Formerly the theory of coalgebras has\nbeen employed mostly in Sets where coinduction yields a finer process semantics\nof bisimilarity. Therefore this paper extends the application field of\ncoalgebras, providing a new instance of the principle \"process semantics via\ncoinduction.\""
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(4:11)2007", 
    "link": "http://arxiv.org/pdf/0710.3332v4", 
    "title": "Model and Program Repair via SAT Solving", 
    "arxiv-id": "0710.3332v4", 
    "author": "Jad Saklawi", 
    "publish": "2007-10-17T16:56:56Z", 
    "summary": "We consider the following \\emph{model repair problem}: given a finite Kripke\nstructure $M$ and a specification formula $\\eta$ in some modal or temporal\nlogic, determine if $M$ contains a substructure $M'$ (with the same initial\nstate) that satisfies $\\eta$. Thus, $M$ can be ``repaired'' to satisfy the\nspecification $\\eta$ by deleting some transitions.\n  We map an instance $(M, \\eta)$ of model repair to a boolean formula\n$\\repfor(M,\\eta)$ such that $(M, \\eta)$ has a solution iff $\\repfor(M,\\eta)$ is\nsatisfiable. Furthermore, a satisfying assignment determines which transitions\nmust be removed from $M$ to generate a model $M'$ of $\\eta$. Thus, we can use\nany SAT solver to repair Kripke structures. Furthermore, using a complete SAT\nsolver yields a complete algorithm: it always finds a repair if one exists.\n  We extend our method to repair finite-state shared memory concurrent\nprograms, to solve the discrete event supervisory control problem\n\\cite{RW87,RW89}, to check for the existence of symmettric solutions\n\\cite{ES93}, and to accomodate any boolean constraint on the existence of\nstates and transitions in the repaired model.\n  Finally, we show that model repair is NP-complete for CTL, and logics with\npolynomial model checking algorithms to which CTL can be reduced in polynomial\ntime. A notable example of such a logic is Alternating-Time Temporal Logic\n(ATL)."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(4:11)2007", 
    "link": "http://arxiv.org/pdf/0710.3764v1", 
    "title": "Design of a Distributed Reachability Algorithm for Analysis of Linear   Hybrid Automata", 
    "arxiv-id": "0710.3764v1", 
    "author": "Sumit Kumar Jha", 
    "publish": "2007-10-19T19:32:39Z", 
    "summary": "This paper presents the design of a novel distributed algorithm d-IRA for the\nreachability analysis of linear hybrid automata. Recent work on iterative\nrelaxation abstraction (IRA) is leveraged to distribute the computational\nproblem among multiple computational nodes in a non-redundant manner by\nperforming careful infeasibility analysis of linear programs corresponding to\nspurious counterexamples. The d-IRA algorithm is resistant to failure of\nmultiple computational nodes. The experimental results provide promising\nevidence for the possible successful application of this technique."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(4:11)2007", 
    "link": "http://arxiv.org/pdf/0710.4499v2", 
    "title": "Remarks on Jurdzinski and Lorys' proof that palindromes are not a   Church-Rosser language", 
    "arxiv-id": "0710.4499v2", 
    "author": "Natalie Schluter", 
    "publish": "2007-10-24T15:40:32Z", 
    "summary": "In 2002 Jurdzinski and Lorys settled a long-standing conjecture that\npalindromes are not a Church-Rosser language. Their proof required a\nsophisticated theory about computation graphs of 2-stack automata. We present\ntheir proof in terms of 1-tape Turing machines.We also provide an alternative\nproof of Buntrock and Otto's result that the set of non-square bitstrings,\nwhich is context-free, is not Church-Rosser."
},{
    "category": "cs.LO", 
    "doi": "10.1109/DATE.2005.276", 
    "link": "http://arxiv.org/pdf/0710.4629v1", 
    "title": "Space-Efficient Bounded Model Checking", 
    "arxiv-id": "0710.4629v1", 
    "author": "Nachum Dershowitz", 
    "publish": "2007-10-25T08:06:59Z", 
    "summary": "Current algorithms for bounded model checking use SAT methods for checking\nsatisfiability of Boolean formulae. These methods suffer from the potential\nmemory explosion problem. Methods based on the validity of Quantified Boolean\nFormulae (QBF) allow an exponentially more succinct representation of formulae\nto be checked, because no \"unrolling\" of the transition relation is required.\nThese methods have not been widely used, because of the lack of an efficient\ndecision procedure for QBF. We evaluate the usage of QBF in bounded model\nchecking (BMC), using general-purpose SAT and QBF solvers. We develop a\nspecial-purpose decision procedure for QBF used in BMC, and compare our\ntechnique with the methods using general-purpose SAT and QBF solvers on\nreal-life industrial benchmarks."
},{
    "category": "cs.LO", 
    "doi": "10.1109/DATE.2005.276", 
    "link": "http://arxiv.org/pdf/0710.4666v1", 
    "title": "Verification of Embedded Memory Systems using Efficient Memory Modeling", 
    "arxiv-id": "0710.4666v1", 
    "author": "Pranav Ashar", 
    "publish": "2007-10-25T08:44:05Z", 
    "summary": "We describe verification techniques for embedded memory systems using\nefficient memory modeling (EMM), without explicitly modeling each memory bit.\nWe extend our previously proposed approach of EMM in Bounded Model Checking\n(BMC) for a single read/write port single memory system, to more commonly\noccurring systems with multiple memories, having multiple read and write ports.\nMore importantly, we augment such EMM to providing correctness proofs, in\naddition to finding real bugs as before. The novelties of our verification\napproach are in a) combining EMM with proof-based abstraction that preserves\nthe correctness of a property up to a certain analysis depth of SAT-based BMC,\nand b) modeling arbitrary initial memory state precisely and thereby, providing\ninductive proofs using SAT-based BMC for embedded memory systems. Similar to\nthe previous approach, we construct a verification model by eliminating memory\narrays, but retaining the memory interface signals with their control logic and\nadding constraints on those signals at every analysis depth to preserve the\ndata forwarding semantics. The size of these EMM constraints depends\nquadratically on the number of memory accesses and the number of read and write\nports; and linearly on the address and data widths and the number of memories.\nWe show the effectiveness of our approach on several industry designs and\nsoftware programs."
},{
    "category": "cs.LO", 
    "doi": "10.1109/DATE.2005.276", 
    "link": "http://arxiv.org/pdf/0710.4689v1", 
    "title": "Functional Equivalence Checking for Verification of Algebraic   Transformations on Array-Intensive Source Code", 
    "arxiv-id": "0710.4689v1", 
    "author": "Gerda Janssens", 
    "publish": "2007-10-25T09:09:59Z", 
    "summary": "Development of energy and performance-efficient embedded software is\nincreasingly relying on application of complex transformations on the critical\nparts of the source code. Designers applying such nontrivial source code\ntransformations are often faced with the problem of ensuring functional\nequivalence of the original and transformed programs. Currently they have to\nrely on incomplete and time-consuming simulation. Formal automatic verification\nof the transformed program against the original is instead desirable. This\ncalls for equivalence checking tools similar to the ones available for\ncomparing digital circuits. We present such a tool to compare array-intensive\nprograms related through a combination of important global transformations like\nexpression propagations, loop and algebraic transformations. When the\ntransformed program fails to pass the equivalence check, the tool provides\nspecific feedback on the possible locations of errors."
},{
    "category": "cs.LO", 
    "doi": "10.1109/DATE.2005.276", 
    "link": "http://arxiv.org/pdf/0710.4694v1", 
    "title": "Exact Synthesis of 3-Qubit Quantum Circuits from Non-Binary Quantum   Gates Using Multiple-Valued Logic and Group Theory", 
    "arxiv-id": "0710.4694v1", 
    "author": "Marek Perkowski", 
    "publish": "2007-10-25T09:14:41Z", 
    "summary": "We propose an approach to optimally synthesize quantum circuits from\nnon-permutative quantum gates such as Controlled-Square-Root-of-Not (i.e.\nControlled-V). Our approach reduces the synthesis problem to multiple-valued\noptimization and uses group theory. We devise a novel technique that transforms\nthe quantum logic synthesis problem from a multi-valued constrained\noptimization problem to a group permutation problem. The transformation enables\nus to utilize group theory to exploit the properties of the synthesis problem.\nAssuming a cost of one for each two-qubit gate, we found all reversible\ncircuits with quantum costs of 4, 5, 6, etc, and give another algorithm to\nrealize these reversible circuits with quantum gates."
},{
    "category": "cs.LO", 
    "doi": "10.1109/DATE.2005.276", 
    "link": "http://arxiv.org/pdf/0710.4695v1", 
    "title": "SAT-Based Complete Don't-Care Computation for Network Optimization", 
    "arxiv-id": "0710.4695v1", 
    "author": "Robert K. Brayton", 
    "publish": "2007-10-25T09:15:10Z", 
    "summary": "This paper describes an improved approach to Boolean network optimization\nusing internal don't-cares. The improvements concern the type of don't-cares\ncomputed, their scope, and the computation method. Instead of the traditionally\nused compatible observability don't-cares (CODCs), we introduce and justify the\nuse of complete don't-cares (CDC). To ensure the robustness of the don't-care\ncomputation for very large industrial networks, a optional windowing scheme is\nimplemented that computes substantial subsets of the CDCs in reasonable time.\nFinally, we give a SAT-based don't-care computation algorithm that is more\nefficient than BDD-based algorithms. Experimental results confirm that these\nimprovements work well in practice. Complete don't-cares allow for a reduction\nin the number of literals compared to the CODCs. Windowing guarantees\nrobustness, even for very large benchmarks on which previous methods could not\nbe applied. SAT reduces the runtime and enhances robustness, making don't-cares\naffordable for a variety of other Boolean methods applied to the network."
},{
    "category": "cs.LO", 
    "doi": "10.1109/DATE.2005.276", 
    "link": "http://arxiv.org/pdf/0710.4698v1", 
    "title": "Automated Synthesis of Assertion Monitors using Visual Specifications", 
    "arxiv-id": "0710.4698v1", 
    "author": "S. Ramesh", 
    "publish": "2007-10-25T09:18:46Z", 
    "summary": "Automated synthesis of monitors from high-level properties plays a\nsignificant role in assertion-based verification. We present here a methodology\nto synthesize assertion monitors from visual specifications given in CESC\n(Clocked Event Sequence Chart). CESC is a visual language designed for\nspecifying system level interactions involving single and multiple clock\ndomains. It has well-defined graphical and textual syntax and formal semantics\nbased on synchronous language paradigm enabling formal analysis of\nspecifications. In this paper we provide an overview of CESC language with few\nillustrative examples. The algorithm for automated synthesis of assertion\nmonitors from CESC specifications is described. A few examples from standard\nbus protocols (OCP-IP and AMBA) are presented to demonstrate the application of\nmonitor synthesis algorithm."
},{
    "category": "cs.LO", 
    "doi": "10.1109/DATE.2005.276", 
    "link": "http://arxiv.org/pdf/0710.4743v1", 
    "title": "Efficient Solution of Language Equations Using Partitioned   Representations", 
    "arxiv-id": "0710.4743v1", 
    "author": "Nina Yevtushenko", 
    "publish": "2007-10-25T09:45:31Z", 
    "summary": "A class of discrete event synthesis problems can be reduced to solving\nlanguage equations f . X &sube; S, where F is the fixed component and S the\nspecification. Sequential synthesis deals with FSMs when the automata for F and\nS are prefix closed, and are naturally represented by multi-level networks with\nlatches. For this special case, we present an efficient computation, using\npartitioned representations, of the most general prefix-closed solution of the\nabove class of language equations. The transition and the output relations of\nthe FSMs for F and S in their partitioned form are represented by the sets of\noutput and next state functions of the corresponding networks. Experimentally,\nwe show that using partitioned representations is much faster than using\nmonolithic representations, as well as applicable to larger problem instances."
},{
    "category": "cs.LO", 
    "doi": "10.1109/DATE.2005.276", 
    "link": "http://arxiv.org/pdf/0710.4753v1", 
    "title": "Verifying Safety-Critical Timing and Memory-Usage Properties of Embedded   Software by Abstract Interpretation", 
    "arxiv-id": "0710.4753v1", 
    "author": "Christian Ferdinand", 
    "publish": "2007-10-25T09:52:50Z", 
    "summary": "Static program analysis by abstract interpretation is an efficient method to\ndetermine properties of embedded software. One example is value analysis, which\ndetermines the values stored in the processor registers. Its results are used\nas input to more advanced analyses, which ultimately yield information about\nthe stack usage and the timing behavior of embedded software."
},{
    "category": "cs.LO", 
    "doi": "10.1109/DATE.2005.276", 
    "link": "http://arxiv.org/pdf/0710.4848v1", 
    "title": "A Formal Verification Methodology for Checking Data Integrity", 
    "arxiv-id": "0710.4848v1", 
    "author": "Takeshi Shimizu", 
    "publish": "2007-10-25T12:24:36Z", 
    "summary": "Formal verification techniques have been playing an important role in\npre-silicon validation processes. One of the most important points considered\nin performing formal verification is to define good verification scopes; we\nshould define clearly what to be verified formally upon designs under tests. We\nconsidered the following three practical requirements when we defined the scope\nof formal verification. They are (a) hard to verify (b) small to handle, and\n(c) easy to understand. Our novel approach is to break down generic properties\nfor system into stereotype properties in block level and to define requirements\nfor Verifiable RTL. Consequently, each designer instead of verification experts\ncan describe properties of the design easily, and formal model checking can be\napplied systematically and thoroughly to all the leaf modules. During the\ndevelopment of a component chip for server platforms, we focused on RAS\n(Reliability, Availability, and Serviceability) features and described more\nthan 2000 properties in PSL. As a result of the formal verification, we found\nseveral critical logic bugs in a short time with limited resources, and\nsuccessfully verified all of them. This paper presents a study of the\nfunctional verification methodology."
},{
    "category": "cs.LO", 
    "doi": "10.1109/DATE.2005.276", 
    "link": "http://arxiv.org/pdf/0710.4851v1", 
    "title": "Common Reusable Verification Environment for BCA and RTL Models", 
    "arxiv-id": "0710.4851v1", 
    "author": "Nizar Romdhane", 
    "publish": "2007-10-25T12:25:32Z", 
    "summary": "This paper deals with a common verification methodology and environment for\nSystemC BCA and RTL models. The aim is to save effort by avoiding the same work\ndone twice by different people and to reuse the same environment for the two\ndesign views. Applying this methodology the verification task starts as soon as\nthe functional specification is signed off and it runs in parallel to the\nmodels and design development. The verification environment is modeled with the\naid of dedicated verification languages and it is applied to both the models.\nThe test suite is exactly the same and thus it's possible to verify the\nalignment between the two models. In fact the final step is to check the\ncycle-by-cycle match of the interface behavior. A regression tool and a bus\nanalyzer have been developed to help the verification and the alignment\nprocess. The former is used to automate the testbench generation and to run the\ntwo test suites. The latter is used to verify the alignment between the two\nmodels comparing the waveforms obtained in each run. The quality metrics used\nto validate the flow are full functional coverage and full alignment at each IP\nport."
},{
    "category": "cs.LO", 
    "doi": "10.1109/DATE.2005.276", 
    "link": "http://arxiv.org/pdf/0710.5130v1", 
    "title": "A Proof of the Factorization Forest Theorem", 
    "arxiv-id": "0710.5130v1", 
    "author": "Manfred Kufleitner", 
    "publish": "2007-10-26T15:59:56Z", 
    "summary": "We show that for every homomorphism $\\Gamma^+ \\to S$ where $S$ is a finite\nsemigroup there exists a factorization forest of height $\\leq 3 \\abs{S}$. The\nproof is based on Green's relations."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(4:5)2007", 
    "link": "http://arxiv.org/pdf/0710.5659v2", 
    "title": "Model Checking Synchronized Products of Infinite Transition Systems", 
    "arxiv-id": "0710.5659v2", 
    "author": "Wolfgang Thomas", 
    "publish": "2007-10-30T14:39:09Z", 
    "summary": "Formal verification using the model checking paradigm has to deal with two\naspects: The system models are structured, often as products of components, and\nthe specification logic has to be expressive enough to allow the formalization\nof reachability properties. The present paper is a study on what can be\nachieved for infinite transition systems under these premises. As models we\nconsider products of infinite transition systems with different synchronization\nconstraints. We introduce finitely synchronized transition systems, i.e.\nproduct systems which contain only finitely many (parameterized) synchronized\ntransitions, and show that the decidability of FO(R), first-order logic\nextended by reachability predicates, of the product system can be reduced to\nthe decidability of FO(R) of the components. This result is optimal in the\nfollowing sense: (1) If we allow semifinite synchronization, i.e. just in one\ncomponent infinitely many transitions are synchronized, the FO(R)-theory of the\nproduct system is in general undecidable. (2) We cannot extend the expressive\npower of the logic under consideration. Already a weak extension of first-order\nlogic with transitive closure, where we restrict the transitive closure\noperators to arity one and nesting depth two, is undecidable for an\nasynchronous (and hence finitely synchronized) product, namely for the infinite\ngrid."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(4:8)2007", 
    "link": "http://arxiv.org/pdf/0711.0194v2", 
    "title": "Coinductive Proof Principles for Stochastic Processes", 
    "arxiv-id": "0711.0194v2", 
    "author": "Dexter Kozen", 
    "publish": "2007-11-01T19:25:13Z", 
    "summary": "We give an explicit coinduction principle for recursively-defined stochastic\nprocesses. The principle applies to any closed property, not just equality, and\nworks even when solutions are not unique. The rule encapsulates low-level\nanalytic arguments, allowing reasoning about such processes at a higher\nalgebraic level. We illustrate the use of the rule in deriving properties of a\nsimple coin-flip process."
},{
    "category": "cs.LO", 
    "doi": "10.3233/FI-2010-254", 
    "link": "http://arxiv.org/pdf/0711.0834v2", 
    "title": "An interface group for process components", 
    "arxiv-id": "0711.0834v2", 
    "author": "C. A. Middelburg", 
    "publish": "2007-11-06T10:45:02Z", 
    "summary": "We take a process component as a pair of an interface and a behaviour. We\nstudy the composition of interacting process components in the setting of\nprocess algebra. We formalize the interfaces of interacting process components\nby means of an interface group. An interesting feature of the interface group\nis that it allows for distinguishing between expectations and promises in\ninterfaces of process components. This distinction comes into play in case\ncomponents with both client and server behaviour are involved."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.ic.2010.01.004", 
    "link": "http://arxiv.org/pdf/0711.0840v2", 
    "title": "A thread calculus with molecular dynamics", 
    "arxiv-id": "0711.0840v2", 
    "author": "C. A. Middelburg", 
    "publish": "2007-11-06T11:25:20Z", 
    "summary": "We present a theory of threads, interleaving of threads, and interaction\nbetween threads and services with features of molecular dynamics, a model of\ncomputation that bears on computations in which dynamic data structures are\ninvolved. Threads can interact with services of which the states consist of\nstructured data objects and computations take place by means of actions which\nmay change the structure of the data objects. The features introduced include\nrestriction of the scope of names used in threads to refer to data objects.\nBecause that feature makes it troublesome to provide a model based on\nstructural operational semantics and bisimulation, we construct a projective\nlimit model for the theory."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.ic.2010.01.004", 
    "link": "http://arxiv.org/pdf/0711.1016v2", 
    "title": "An On-the-fly Tableau-based Decision Procedure for PDL-Satisfiability", 
    "arxiv-id": "0711.1016v2", 
    "author": "Florian Widmann", 
    "publish": "2007-11-07T06:11:13Z", 
    "summary": "We present a tableau-based algorithm for deciding satisfiability for\npropositional dynamic logic (PDL) which builds a finite rooted tree with\nancestor loops and passes extra information from children to parents to\nseparate good loops from bad loops during backtracking. It is easy to\nimplement, with potential for parallelisation, because it constructs a\npseudo-model ``on the fly'' by exploring each tableau branch independently. But\nits worst-case behaviour is 2EXPTIME rather than EXPTIME. A prototype\nimplementation in the TWB (http://twb.rsise.anu.edu.au) is available."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.ic.2010.01.004", 
    "link": "http://arxiv.org/pdf/0711.2155v1", 
    "title": "Guarded Hybrid Knowledge Bases", 
    "arxiv-id": "0711.2155v1", 
    "author": "Davy Van Nieuwenborgh", 
    "publish": "2007-11-14T10:49:56Z", 
    "summary": "Recently, there has been a lot of interest in the integration of Description\nLogics and rules on the Semantic Web.We define guarded hybrid knowledge bases\n(or g-hybrid knowledge bases) as knowledge bases that consist of a Description\nLogic knowledge base and a guarded logic program, similar to the DL+log\nknowledge bases from (Rosati 2006). G-hybrid knowledge bases enable an\nintegration of Description Logics and Logic Programming where, unlike in other\napproaches, variables in the rules of a guarded program do not need to appear\nin positive non-DL atoms of the body, i.e. DL atoms can act as guards as well.\nDecidability of satisfiability checking of g-hybrid knowledge bases is shown\nfor the particular DL DLRO, which is close to OWL DL, by a reduction to guarded\nprograms under the open answer set semantics. Moreover, we show\n2-EXPTIME-completeness for satisfiability checking of such g-hybrid knowledge\nbases. Finally, we discuss advantages and disadvantages of our approach\ncompared with DL+log knowledge bases."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.ic.2010.01.004", 
    "link": "http://arxiv.org/pdf/0711.2546v2", 
    "title": "Normalization of IZF with Replacement", 
    "arxiv-id": "0711.2546v2", 
    "author": "Wojciech Moczydlowski", 
    "publish": "2007-11-16T02:44:05Z", 
    "summary": "ZF is a well investigated impredicative constructive version of\nZermelo-Fraenkel set theory. Using set terms, we axiomatize IZF with\nReplacement, which we call \\izfr, along with its intensional counterpart\n\\iizfr. We define a typed lambda calculus $\\li$ corresponding to proofs in\n\\iizfr according to the Curry-Howard isomorphism principle. Using realizability\nfor \\iizfr, we show weak normalization of $\\li$. We use normalization to prove\nthe disjunction, numerical existence and term existence properties. An inner\nextensional model is used to show these properties, along with the set\nexistence property, for full, extensional \\izfr."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.ic.2010.01.004", 
    "link": "http://arxiv.org/pdf/0712.1279v1", 
    "title": "Kleene, Rogers and Rice Theorems Revisited in C and in Bash", 
    "arxiv-id": "0712.1279v1", 
    "author": "Nicola Corriero", 
    "publish": "2007-12-08T12:05:40Z", 
    "summary": "The recursion theorem in the weak form {e}(z)=x(e,z) (universal function not\nneeded) and in Rogers form {n}(z)={{x}(n)}(z) and Rice theorem are proved a\nfirst time using programs in C, and a second time with scripts in Bash."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.ic.2010.01.004", 
    "link": "http://arxiv.org/pdf/0712.3380v1", 
    "title": "Extending the Overlap Graph for Gene Assembly in Ciliates", 
    "arxiv-id": "0712.3380v1", 
    "author": "Hendrik Jan Hoogeboom", 
    "publish": "2007-12-20T12:08:33Z", 
    "summary": "Gene assembly is an intricate biological process that has been studied\nformally and modeled through string and graph rewriting systems. Recently, a\nrestriction of the general (intramolecular) model, called simple gene assembly,\nhas been introduced. This restriction has subsequently been defined as a string\nrewriting system. We show that by extending the notion of overlap graph it is\npossible to define a graph rewriting system for two of the three types of rules\nthat make up simple gene assembly. It turns out that this graph rewriting\nsystem is less involved than its corresponding string rewriting system.\nFinally, we give characterizations of the `power' of both types of graph\nrewriting rules. Because of the equivalence of these string and graph rewriting\nsystems, the given characterizations can be carried over to the string\nrewriting system."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.ic.2010.01.004", 
    "link": "http://arxiv.org/pdf/0712.4222v2", 
    "title": "Weak Affine Light Typing: Polytime intensional expressivity, soundness   and completeness", 
    "arxiv-id": "0712.4222v2", 
    "author": "Luca Roversi", 
    "publish": "2007-12-27T14:35:16Z", 
    "summary": "Weak affine light typing (WALT) assigns light affine linear formulae as types\nto a subset of lambda-terms in System F. WALT is poly-time sound: if a\nlambda-term M has type in WALT, M can be evaluated with a polynomial cost in\nthe dimension of the derivation that gives it a type. In particular, the\nevaluation can proceed under any strategy of a rewriting relation, obtained as\na mix of both call-by-name/call-by-value beta-reductions. WALT is poly-time\ncomplete since it can represent any poly-time Turing machine. WALT weakens,\nnamely generalizes, the notion of stratification of deductions common to some\nLight Systems -- we call as such those logical systems, derived from Linear\nlogic, to characterize FP, the set of Polynomial functions -- . A weaker\nstratification allows to define a compositional embedding of the Quasi-linear\nfragment QlSRN of Safe recursion on notation (SRN) into WALT. QlSRN is SRN,\nwhich is a recursive-theoretical system characterizing FP, where only the\ncomposition scheme is restricted to linear safe variables. So, the expressivity\nof WALT is stronger, as compared to the known Light Systems. In particular,\nusing the types, the embedding puts in evidence the stratification of normal\nand safe arguments hidden in QlSRN: the less an argument is impredicative, the\ndeeper, in a formal, proof-theoretical sense, gets its representation in WALT."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.ic.2010.01.004", 
    "link": "http://arxiv.org/pdf/0712.4341v1", 
    "title": "Finite Automata Based on Quantum Logic and Their Determinization", 
    "arxiv-id": "0712.4341v1", 
    "author": "Yongming Li", 
    "publish": "2007-12-28T11:48:44Z", 
    "summary": "We give the quantum subset construction of orthomodular lattice-valued finite\nautomata, then we show the equivalence between orthomodular lattice-valued\nfinite automata, orthomodular lattice-valued deterministic finite automata and\northomodular lattice-valued finite automata with empty string-moves. Based on\nthese equivalences, we study the algebraic operations on orthomodular\nlattice-valued regular languages, then we establish Kleene theorem in the frame\nof quantum logic."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-03745-0_25", 
    "link": "http://arxiv.org/pdf/0801.0649v1", 
    "title": "A logical analysis of entanglement and separability in quantum   higher-order functions", 
    "arxiv-id": "0801.0649v1", 
    "author": "C. Zerrari", 
    "publish": "2008-01-04T10:12:59Z", 
    "summary": "We present a logical separability analysis for a functional quantum\ncomputation language. This logic is inspired by previous works on logical\nanalysis of aliasing for imperative functional programs. Both analyses share\nsimilarities notably because they are highly non-compositional. Quantum setting\nis harder to deal with since it introduces non determinism and thus\nconsiderably modifies semantics and validity of logical assertions. This logic\nis the first proposal of entanglement/separability analysis dealing with a\nfunctional quantum programming language with higher-order functions."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-03745-0_25", 
    "link": "http://arxiv.org/pdf/0801.0677v1", 
    "title": "Finite-state concurrent programs can be expressed pairwise", 
    "arxiv-id": "0801.0677v1", 
    "author": "Paul C. Attie", 
    "publish": "2008-01-04T13:14:31Z", 
    "summary": "We present a \\emph{pairwise normal form} for finite-state shared memory\nconcurrent programs: all variables are shared between exactly two processes,\nand the guards on transitions are conjunctions of conditions over this pairwise\nshared state. This representation has been used to efficiently (in polynomial\ntime) synthesize and model-check correctness properties of concurrent programs.\nOur main result is that any finite state concurrent program can be transformed\ninto pairwise normal form. Specifically, if $Q$ is an arbitrary finite-state\nshared memory concurrent program, then there exists a finite-state shared\nmemory concurrent program $P$ expressed in pairwise normal form such that $P$\nis strongly bisimilar to $Q$. Our result is constructive: we give an algorithm\nfor producing $P$, given $Q$."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-03745-0_25", 
    "link": "http://arxiv.org/pdf/0801.0813v1", 
    "title": "A linear-non-linear model for a computational call-by-value lambda   calculus (extended abstract)", 
    "arxiv-id": "0801.0813v1", 
    "author": "Beno\u00eet Valiron", 
    "publish": "2008-01-05T15:21:17Z", 
    "summary": "We give a categorical semantics for a call-by-value linear lambda calculus.\nSuch a lambda calculus was used by Selinger and Valiron as the backbone of a\nfunctional programming language for quantum computation. One feature of this\nlambda calculus is its linear type system, which includes a duplicability\noperator \"!\" as in linear logic. Another main feature is its call-by-value\nreduction strategy, together with a side-effect to model probabilistic\nmeasurements. The \"!\" operator gives rise to a comonad, as in the linear logic\nmodels of Seely, Bierman, and Benton. The side-effects give rise to a monad, as\nin Moggi's computational lambda calculus. It is this combination of a monad and\na comonad that makes the present paper interesting. We show that our\ncategorical semantics is sound and complete."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-03745-0_25", 
    "link": "http://arxiv.org/pdf/0801.0949v1", 
    "title": "On the Refinement of Liveness Properties of Distributed Systems", 
    "arxiv-id": "0801.0949v1", 
    "author": "Paul C. Attie", 
    "publish": "2008-01-07T11:55:03Z", 
    "summary": "We present a new approach for reasoning about liveness properties of\ndistributed systems, represented as automata. Our approach is based on\nsimulation relations, and requires reasoning only over finite execution\nfragments. Current simulation-relation based methods for reasoning about\nliveness properties of automata require reasoning over entire executions, since\nthey involve a proof obligation of the form: if a concrete and abstract\nexecution ``correspond'' via the simulation, and the concrete execution is\nlive, then so is the abstract execution.\n  Our contribution consists of (1) a formalism for defining liveness\nproperties, (2) a proof method for liveness properties based on that formalism,\nand (3) two expressive completeness results: firstly, our formalism can express\nany liveness property which satisfies a natural ``robustness'' condition, and\nsecondly, our formalism can express any liveness property at all, provided that\nhistory variables can be used"
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-03745-0_25", 
    "link": "http://arxiv.org/pdf/0801.1687v1", 
    "title": "Synthesis of Large Dynamic Concurrent Programs from Dynamic   Specifications", 
    "arxiv-id": "0801.1687v1", 
    "author": "Paul C. Attie", 
    "publish": "2008-01-10T21:27:42Z", 
    "summary": "We present a tractable method for synthesizing arbitrarily large concurrent\nprograms, for a shared memory model with common hardware-available primitives\nsuch as atomic registers, compare-and-swap, load-linked/store conditional, etc.\nThe programs we synthesize are dynamic: new processes can be created and added\nat run-time, and so our programs are not finite-state, in general.\nNevertheless, we successfully exploit automatic synthesis and model-checking\nmethods based on propositional temporal logic. Our method is algorithmically\nefficient, with complexity polynomial in the number of component processes (of\nthe program) that are ``alive'' at any time. Our method does not explicitly\nconstruct the automata-theoretic product of all processes that are alive,\nthereby avoiding \\intr{state explosion}. Instead, for each pair of processes\nwhich interact, our method constructs an automata-theoretic product\n(\\intr{pair-machine}) which embodies all the possible interactions of these two\nprocesses. From each pair-machine, we can synthesize a correct\n\\intr{pair-program} which coordinates the two involved processes as needed. We\nallow such pair-programs to be added dynamically at run-time. They are then\n``composed conjunctively'' with the currently alive pair-programs to\nre-synthesize the program as it results after addition of the new pair-program.\nWe are thus able to add new behaviors, which result in new properties being\nsatisfied, at run-time. We establish a ``large model'' theorem which shows that\nthe synthesized large program inherits correctness properties from the\npair-programs."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(1:8)2008", 
    "link": "http://arxiv.org/pdf/0801.2498v2", 
    "title": "An Application of the Feferman-Vaught Theorem to Automata and Logics   for<br> Words over an Infinite Alphabet", 
    "arxiv-id": "0801.2498v2", 
    "author": "Alexis B\u00e8s", 
    "publish": "2008-01-16T14:39:27Z", 
    "summary": "We show that a special case of the Feferman-Vaught composition theorem gives\nrise to a natural notion of automata for finite words over an infinite\nalphabet, with good closure and decidability properties, as well as several\nlogical characterizations. We also consider a slight extension of the\nFeferman-Vaught formalism which allows to express more relations between\ncomponent values (such as equality), and prove related decidability results.\n  From this result we get new classes of decidable logics for words over an\ninfinite alphabet."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(1:8)2008", 
    "link": "http://arxiv.org/pdf/0801.3065v1", 
    "title": "Cut Elimination for a Logic with Generic Judgments and Induction", 
    "arxiv-id": "0801.3065v1", 
    "author": "Alwen Tiu", 
    "publish": "2008-01-20T08:34:22Z", 
    "summary": "This paper presents a cut-elimination proof for the logic $LG^\\omega$, which\nis an extension of a proof system for encoding generic judgments, the logic\n$\\FOLDNb$ of Miller and Tiu, with an induction principle. The logic\n$LG^\\omega$, just as $\\FOLDNb$, features extensions of first-order\nintuitionistic logic with fixed points and a ``generic quantifier'', $\\nabla$,\nwhich is used to reason about the dynamics of bindings in object systems\nencoded in the logic. A previous attempt to extend $\\FOLDNb$ with an induction\nprinciple has been unsuccessful in modeling some behaviours of bindings in\ninductive specifications. It turns out that this problem can be solved by\nrelaxing some restrictions on $\\nabla$, in particular by adding the axiom $B\n\\equiv \\nabla x. B$, where $x$ is not free in $B$. We show that by adopting the\nequivariance principle, the presentation of the extended logic can be much\nsimplified. This paper contains the technical proofs for the results stated in\n\\cite{tiu07entcs}; readers are encouraged to consult \\cite{tiu07entcs} for\nmotivations and examples for $LG^\\omega.$"
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(1:8)2008", 
    "link": "http://arxiv.org/pdf/0801.3117v1", 
    "title": "A hierarchy of behavioral equivalences in the $\u03c0$-calculus with noisy   channels", 
    "arxiv-id": "0801.3117v1", 
    "author": "Yongzhi Cao", 
    "publish": "2008-01-21T00:42:52Z", 
    "summary": "The $\\pi$-calculus is a process algebra where agents interact by sending\ncommunication links to each other via noiseless communication channels. Taking\ninto account the reality of noisy channels, an extension of the $\\pi$-calculus,\ncalled the $\\pi_N$-calculus, has been introduced recently. In this paper, we\npresent an early transitional semantics of the $\\pi_N$-calculus, which is not a\ndirectly translated version of the late semantics of $\\pi_N$, and then extend\nsix kinds of behavioral equivalences consisting of reduction bisimilarity,\nbarbed bisimilarity, barbed equivalence, barbed congruence, bisimilarity, and\nfull bisimilarity into the $\\pi_N$-calculus. Such behavioral equivalences are\ncast in a hierarchy, which is helpful to verify behavioral equivalence of two\nagents. In particular, we show that due to the noisy nature of channels, the\ncoincidence of bisimilarity and barbed equivalence, as well as the coincidence\nof full bisimilarity and barbed congruence, in the $\\pi$-calculus does not hold\nin $\\pi_N$."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(1:8)2008", 
    "link": "http://arxiv.org/pdf/0802.0865v2", 
    "title": "Combining generic judgments with recursive definitions", 
    "arxiv-id": "0802.0865v2", 
    "author": "Gopalan Nadathur", 
    "publish": "2008-02-06T19:18:57Z", 
    "summary": "Many semantical aspects of programming languages, such as their operational\nsemantics and their type assignment calculi, are specified by describing\nappropriate proof systems. Recent research has identified two proof-theoretic\nfeatures that allow direct, logic-based reasoning about such descriptions: the\ntreatment of atomic judgments as fixed points (recursive definitions) and an\nencoding of binding constructs via generic judgments. However, the logics\nencompassing these two features have thus far treated them orthogonally: that\nis, they do not provide the ability to define object-logic properties that\nthemselves depend on an intrinsic treatment of binding. We propose a new and\nsimple integration of these features within an intuitionistic logic enhanced\nwith induction over natural numbers and we show that the resulting logic is\nconsistent. The pivotal benefit of the integration is that it allows recursive\ndefinitions to not just encode simple, traditional forms of atomic judgments\nbut also to capture generic properties pertaining to such judgments. The\nusefulness of this logic is illustrated by showing how it can provide elegant\ntreatments of object-logic contexts that appear in proofs involving typing\ncalculi and of arbitrarily cascading substitutions that play a role in\nreducibility arguments."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(1:5)2008", 
    "link": "http://arxiv.org/pdf/0802.1226v3", 
    "title": "Lower Bounds for Complementation of omega-Automata Via the Full Automata   Technique", 
    "arxiv-id": "0802.1226v3", 
    "author": "Qiqi Yan", 
    "publish": "2008-02-08T23:13:52Z", 
    "summary": "In this paper, we first introduce a lower bound technique for the state\ncomplexity of transformations of automata. Namely we suggest first considering\nthe class of full automata in lower bound analysis, and later reducing the size\nof the large alphabet via alphabet substitutions. Then we apply such technique\nto the complementation of nondeterministic \\omega-automata, and obtain several\nlower bound results. Particularly, we prove an \\omega((0.76n)^n) lower bound\nfor B\\\"uchi complementation, which also holds for almost every complementation\nor determinization transformation of nondeterministic omega-automata, and prove\nan optimal (\\omega(nk))^n lower bound for the complementation of generalized\nB\\\"uchi automata, which holds for Streett automata as well."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(1:5)2008", 
    "link": "http://arxiv.org/pdf/0802.2862v1", 
    "title": "Compatibility of Shelah and Stupp's and Muchnik's iteration with   fragments of monadic second order logic", 
    "arxiv-id": "0802.2862v1", 
    "author": "Dietrich Kuske", 
    "publish": "2008-02-20T14:33:04Z", 
    "summary": "We investigate the relation between the theory of the iterations in the sense\nof Shelah-Stupp and of Muchnik, resp., and the theory of the base structure for\nseveral logics. These logics are obtained from the restriction of set\nquantification in monadic second order logic to certain subsets like, e.g.,\nfinite sets, chains, and finite unions of chains. We show that these theories\nof the Shelah-Stupp iteration can be reduced to corresponding theories of the\nbase structure. This fails for Muchnik's iteration."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(1:5)2008", 
    "link": "http://arxiv.org/pdf/0802.2866v1", 
    "title": "Cardinality and counting quantifiers on omega-automatic structures", 
    "arxiv-id": "0802.2866v1", 
    "author": "Vince B\u00e1r\u00e1ny", 
    "publish": "2008-02-20T14:37:32Z", 
    "summary": "We investigate structures that can be represented by omega-automata, so\ncalled omega-automatic structures, and prove that relations defined over such\nstructures in first-order logic expanded by the first-order quantifiers `there\nexist at most $\\aleph_0$ many', 'there exist finitely many' and 'there exist\n$k$ modulo $m$ many' are omega-regular. The proof identifies certain algebraic\nproperties of omega-semigroups. As a consequence an omega-regular equivalence\nrelation of countable index has an omega-regular set of representatives. This\nimplies Blumensath's conjecture that a countable structure with an\n$\\omega$-automatic presentation can be represented using automata on finite\nwords. This also complements a very recent result of Hj\\\"orth, Khoussainov,\nMontalban and Nies showing that there is an omega-automatic structure which has\nno injective presentation."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(1:5)2008", 
    "link": "http://arxiv.org/pdf/0802.3617v1", 
    "title": "Towards a formalization of budgets", 
    "arxiv-id": "0802.3617v1", 
    "author": "Mark B. van der Zwaag", 
    "publish": "2008-02-25T13:11:32Z", 
    "summary": "We go into the need for, and the requirements on, a formal theory of budgets.\nWe present a simple algebraic theory of rational budgets, i.e., budgets in\nwhich amounts of money are specified by functions on the rational numbers. This\ntheory is based on the tuplix calculus. We go into the importance of using\ntotalized models for the rational numbers. We present a case study on the\neducational budget of a university department offering master programs."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(1:5)2008", 
    "link": "http://arxiv.org/pdf/0802.3626v1", 
    "title": "Color Graphs: An Efficient Model For Two-Dimensional Cellular Automata   Linear Rules", 
    "arxiv-id": "0802.3626v1", 
    "author": "Sushant Kumar Rout", 
    "publish": "2008-02-25T13:54:50Z", 
    "summary": "Two-dimensional nine neighbor hood rectangular Cellular Automata rules can be\nmodeled using many different techniques like Rule matrices, State Transition\nDiagrams, Boolean functions, Algebraic Normal Form etc. In this paper, a new\nmodel is introduced using color graphs to model all the 512 linear rules. The\ngraph theoretic properties therefore studied in this paper simplifies the\nanalysis of all linear rules in comparison with other ways of its study."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(1:5)2008", 
    "link": "http://arxiv.org/pdf/0802.3974v2", 
    "title": "Syntax diagrams as a formalism for representation of syntactic relations   of formal languages", 
    "arxiv-id": "0802.3974v2", 
    "author": "Vladimir Lapshin", 
    "publish": "2008-02-27T08:59:58Z", 
    "summary": "The new approach to representation of syntax of formal languages-- a\nformalism of syntax diagrams is offered. Syntax diagrams look a convenient\nlanguage for the description of syntactic relations in the languages having\nnonlinear representation of texts, for example, for representation of syntax\nlows of the language of structural chemical formulas. The formalism of\nneighbourhood grammar is used to describe the set of correct syntax constructs.\nThe neighbourhood the grammar consists of a set of families of\n\"neighbourhoods\"-- the diagrams defined for each symbol of the language's\nalphabet. The syntax diagram is correct if each symbol is included into this\ndiagram together with some neighbourhood. In other words, correct diagrams are\nneeded to be covered by elements of the neighbourhood grammar. Thus, the\ngrammar of formal language can be represented as system of the covers defined\nfor each correct syntax diagram."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(1:5)2008", 
    "link": "http://arxiv.org/pdf/0802.4057v2", 
    "title": "A Qualitative Modal Representation of Quantum Register Transformations", 
    "arxiv-id": "0802.4057v2", 
    "author": "Margherita Zorzi", 
    "publish": "2008-02-27T17:43:23Z", 
    "summary": "We introduce two modal natural deduction systems that are suitable to\nrepresent and reason about transformations of quantum registers in an abstract,\nqualitative, way. Quantum registers represent quantum systems, and can be\nviewed as the structure of quantum data for quantum operations. Our systems\nprovide a modal framework for reasoning about operations on quantum registers\n(unitary transformations and measurements), in terms of possible worlds (as\nabstractions of quantum registers) and accessibility relations between these\nworlds. We give a Kripke--style semantics that formally describes quantum\nregister transformations and prove the soundness and completeness of our\nsystems with respect to this semantics."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(1:5)2008", 
    "link": "http://arxiv.org/pdf/0802.4131v1", 
    "title": "Language of Boolean functions its Grammar and Machine", 
    "arxiv-id": "0802.4131v1", 
    "author": "Sudhakar Sahoo", 
    "publish": "2008-02-28T06:21:49Z", 
    "summary": "In this paper an algorithm is designed which generates in-equivalent Boolean\nfunctions of any number of variables from the four Boolean functions of single\nvariable. The grammar for such set of Boolean function is provided. The Turing\nMachine that accepts such set is constructed."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(1:5)2008", 
    "link": "http://arxiv.org/pdf/0802.4237v3", 
    "title": "Safety alternating automata on data words", 
    "arxiv-id": "0802.4237v3", 
    "author": "Ranko Lazic", 
    "publish": "2008-02-28T16:54:31Z", 
    "summary": "A data word is a sequence of pairs of a letter from a finite alphabet and an\nelement from an infinite set, where the latter can only be compared for\nequality. Safety one-way alternating automata with one register on infinite\ndata words are considered, their nonemptiness is shown EXPSPACE-complete, and\ntheir inclusion decidable but not primitive recursive. The same complexity\nbounds are obtained for satisfiability and refinement, respectively, for the\nsafety fragment of linear temporal logic with freeze quantification. Dropping\nthe safety restriction, adding past temporal operators, or adding one more\nregister, each causes undecidability."
},{
    "category": "cs.LO", 
    "doi": "10.1007/s00165-011-0178-3", 
    "link": "http://arxiv.org/pdf/0803.0378v2", 
    "title": "Thread algebra for poly-threading", 
    "arxiv-id": "0803.0378v2", 
    "author": "C. A. Middelburg", 
    "publish": "2008-03-04T07:18:46Z", 
    "summary": "Threads as considered in basic thread algebra are primarily looked upon as\nbehaviours exhibited by sequential programs on execution. It is a fact of life\nthat sequential programs are often fragmented. Consequently, fragmented program\nbehaviours are frequently found. In this paper, we consider this phenomenon. We\nextend basic thread algebra with the barest mechanism for sequencing of threads\nthat are taken for fragments. This mechanism, called poly-threading, supports\nboth autonomous and non-autonomous thread selection in sequencing. We relate\nthe resulting theory to the algebraic theory of processes known as ACP and use\nit to describe analytic execution architectures suited for fragmented programs.\nWe also consider the case where the steps of fragmented program behaviours are\ninterleaved in the ways of non-distributed and distributed multi-threading."
},{
    "category": "cs.LO", 
    "doi": "10.1007/s00165-011-0178-3", 
    "link": "http://arxiv.org/pdf/0803.1575v2", 
    "title": "A Quantifier Elimination Algorithm for Linear Real Arithmetic", 
    "arxiv-id": "0803.1575v2", 
    "author": "David Monniaux", 
    "publish": "2008-03-11T12:55:25Z", 
    "summary": "We propose a new quantifier elimination algorithm for the theory of linear\nreal arithmetic. This algorithm uses as subroutine satisfiability modulo this\ntheory, a problem for which there are several implementations available. The\nquantifier elimination algorithm presented in the paper is compared, on\nexamples arising from program analysis problems, to several other\nimplementations, all of which cannot solve some of the examples that our\nalgorithm solves easily."
},{
    "category": "cs.LO", 
    "doi": "10.1007/s00165-011-0178-3", 
    "link": "http://arxiv.org/pdf/0803.3187v2", 
    "title": "Labeled Natural Deduction Systems for a Family of Tense Logics", 
    "arxiv-id": "0803.3187v2", 
    "author": "Marco Volpe", 
    "publish": "2008-03-21T15:53:56Z", 
    "summary": "We give labeled natural deduction systems for a family of tense logics\nextending the basic linear tense logic Kl. We prove that our systems are sound\nand complete with respect to the usual Kripke semantics, and that they possess\na number of useful normalization properties (in particular, derivations reduce\nto a normal form that enjoys a subformula property). We also discuss how to\nextend our systems to capture richer logics like (fragments of) LTL."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:2)2008", 
    "link": "http://arxiv.org/pdf/0803.3796v3", 
    "title": "Approximating a Behavioural Pseudometric without Discount for<br>   Probabilistic Systems", 
    "arxiv-id": "0803.3796v3", 
    "author": "James Worrell", 
    "publish": "2008-03-26T19:08:40Z", 
    "summary": "Desharnais, Gupta, Jagadeesan and Panangaden introduced a family of\nbehavioural pseudometrics for probabilistic transition systems. These\npseudometrics are a quantitative analogue of probabilistic bisimilarity.\nDistance zero captures probabilistic bisimilarity. Each pseudometric has a\ndiscount factor, a real number in the interval (0, 1]. The smaller the discount\nfactor, the more the future is discounted. If the discount factor is one, then\nthe future is not discounted at all. Desharnais et al. showed that the\nbehavioural distances can be calculated up to any desired degree of accuracy if\nthe discount factor is smaller than one. In this paper, we show that the\ndistances can also be approximated if the future is not discounted. A key\ningredient of our algorithm is Tarski's decision procedure for the first order\ntheory over real closed fields. By exploiting the Kantorovich-Rubinstein\nduality theorem we can restrict to the existential fragment for which more\nefficient decision procedures exist."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:2)2008", 
    "link": "http://arxiv.org/pdf/0804.0660v1", 
    "title": "Weak Affine Light Typing is complete with respect to Safe Recursion on   Notation", 
    "arxiv-id": "0804.0660v1", 
    "author": "Luca Roversi", 
    "publish": "2008-04-04T08:14:22Z", 
    "summary": "Weak affine light typing (WALT) assigns light affine linear formulae as types\nto a subset of lambda-terms of System F. WALT is poly-time sound: if a\nlambda-term M has type in WALT, M can be evaluated with a polynomial cost in\nthe dimension of the derivation that gives it a type. The evaluation proceeds\nunder any strategy of a rewriting relation which is a mix of both call-by-name\nand call-by-value beta-reductions. WALT weakens, namely generalizes, the notion\nof \"stratification of deductions\", common to some Light Systems -- those\nlogical systems, derived from Linear logic, to characterize the set of\nPolynomial functions -- . A weaker stratification allows to define a\ncompositional embedding of Safe recursion on notation (SRN) into WALT. It turns\nout that the expressivity of WALT is strictly stronger than the one of the\nknown Light Systems. The embedding passes through the representation of a\nsubsystem of SRN. It is obtained by restricting the composition scheme of SRN\nto one that can only use its safe variables linearly. On one side, this\nsuggests that SRN, in fact, can be redefined in terms of more primitive\nconstructs. On the other, the embedding of SRN into WALT enjoys the two\nfollowing remarkable aspects. Every datatype, required by the embedding, is\nrepresented from scratch, showing the strong structural proof-theoretical roots\nof WALT. Moreover, the embedding highlights a stratification structure of the\nnormal and safe arguments, normally hidden inside the world of SRN-normal/safe\nvariables: the less an argument is \"polyomially impredicative\", the deeper, in\na formal, proof-theoretical sense, it is represented inside WALT. Finally,\nsince WALT is SRN-complete it is also polynomial-time complete since SRN is."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:2)2008", 
    "link": "http://arxiv.org/pdf/0804.1667v3", 
    "title": "Mechanizing the Metatheory of LF", 
    "arxiv-id": "0804.1667v3", 
    "author": "Stefan Berghofer", 
    "publish": "2008-04-10T11:10:26Z", 
    "summary": "LF is a dependent type theory in which many other formal systems can be\nconveniently embedded. However, correct use of LF relies on nontrivial\nmetatheoretic developments such as proofs of correctness of decision procedures\nfor LF's judgments. Although detailed informal proofs of these properties have\nbeen published, they have not been formally verified in a theorem prover. We\nhave formalized these properties within Isabelle/HOL using the Nominal Datatype\nPackage, closely following a recent article by Harper and Pfenning. In the\nprocess, we identified and resolved a gap in one of the proofs and a small\nnumber of minor lacunae in others. We also formally derive a version of the\ntype checking algorithm from which Isabelle/HOL can generate executable code.\nBesides its intrinsic interest, our formalization provides a foundation for\nstudying the adequacy of LF encodings, the correctness of Twelf-style\nmetatheoretic reasoning, and the metatheory of extensions to LF."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:2)2008", 
    "link": "http://arxiv.org/pdf/0804.1729v3", 
    "title": "On affine usages in signal-based communication", 
    "arxiv-id": "0804.1729v3", 
    "author": "Mehdi Dogguy", 
    "publish": "2008-04-10T15:16:06Z", 
    "summary": "We describe a type system for a synchronous pi-calculus formalising the\nnotion of affine usage in signal-based communication. In particular, we\nidentify a limited number of usages that preserve affinity and that can be\ncomposed. As a main application of the resulting system, we show that typable\nprograms are deterministic."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:2)2008", 
    "link": "http://arxiv.org/pdf/0804.1879v2", 
    "title": "Lambda-Free Logical Frameworks", 
    "arxiv-id": "0804.1879v2", 
    "author": "Robin Adams", 
    "publish": "2008-04-11T11:32:51Z", 
    "summary": "We present the definition of the logical framework TF, the Type Framework. TF\nis a lambda-free logical framework; it does not include lambda-abstraction or\nproduct kinds. We give formal proofs of several results in the metatheory of\nTF, and show how it can be conservatively embedded in the logical framework LF:\nits judgements can be seen as the judgements of LF that are in beta-normal,\neta-long normal form. We show how several properties, such as adequacy theorems\nfor object theories and the injectivity of constants, can be proven more easily\nin TF, and then `lifted' to LF."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:2)2008", 
    "link": "http://arxiv.org/pdf/0804.2535v1", 
    "title": "Short proofs of strong normalization", 
    "arxiv-id": "0804.2535v1", 
    "author": "Aleksander Wojdyga", 
    "publish": "2008-04-16T07:09:59Z", 
    "summary": "This paper presents simple, syntactic strong normalization proofs for the\nsimply-typed lambda-calculus and the polymorphic lambda-calculus (system F)\nwith the full set of logical connectives, and all the permutative reductions.\nThe normalization proofs use translations of terms and types to systems, for\nwhich strong normalization property is known."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:8)2008", 
    "link": "http://arxiv.org/pdf/0804.3065v2", 
    "title": "Visibly Tree Automata with Memory and Constraints", 
    "arxiv-id": "0804.3065v2", 
    "author": "Nicolas Perrin", 
    "publish": "2008-04-18T16:27:34Z", 
    "summary": "Tree automata with one memory have been introduced in 2001. They generalize\nboth pushdown (word) automata and the tree automata with constraints of\nequality between brothers of Bogaert and Tison. Though it has a decidable\nemptiness problem, the main weakness of this model is its lack of good closure\nproperties.\n  We propose a generalization of the visibly pushdown automata of Alur and\nMadhusudan to a family of tree recognizers which carry along their (bottom-up)\ncomputation an auxiliary unbounded memory with a tree structure (instead of a\nsymbol stack). In other words, these recognizers, called Visibly Tree Automata\nwith Memory (VTAM) define a subclass of tree automata with one memory enjoying\nBoolean closure properties. We show in particular that they can be determinized\nand the problems like emptiness, membership, inclusion and universality are\ndecidable for VTAM. Moreover, we propose several extensions of VTAM whose\ntransitions may be constrained by different kinds of tests between memories and\nalso constraints a la Bogaert and Tison comparing brother subtrees in the tree\nin input. We show that some of these classes of constrained VTAM keep the good\nclosure and decidability properties, and we demonstrate their expressiveness\nwith relevant examples of tree languages."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:5)2008", 
    "link": "http://arxiv.org/pdf/0804.3105v2", 
    "title": "A lower bound on web services composition", 
    "arxiv-id": "0804.3105v2", 
    "author": "Igor Walukiewicz", 
    "publish": "2008-04-18T21:15:47Z", 
    "summary": "A web service is modeled here as a finite state machine. A composition\nproblem for web services is to decide if a given web service can be constructed\nfrom a given set of web services; where the construction is understood as a\nsimulation of the specification by a fully asynchronous product of the given\nservices. We show an EXPTIME-lower bound for this problem, thus matching the\nknown upper bound. Our result also applies to richer models of web services,\nsuch as the Roman model."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:5)2008", 
    "link": "http://arxiv.org/pdf/0804.3434v2", 
    "title": "Lecture notes on the lambda calculus", 
    "arxiv-id": "0804.3434v2", 
    "author": "Peter Selinger", 
    "publish": "2008-04-22T03:16:03Z", 
    "summary": "This is a set of lecture notes that developed out of courses on the lambda\ncalculus that I taught at the University of Ottawa in 2001 and at Dalhousie\nUniversity in 2007 and 2013. Topics covered in these notes include the untyped\nlambda calculus, the Church-Rosser theorem, combinatory algebras, the\nsimply-typed lambda calculus, the Curry-Howard isomorphism, weak and strong\nnormalization, polymorphism, type inference, denotational semantics, complete\npartial orders, and the language PCF."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:5)2008", 
    "link": "http://arxiv.org/pdf/0804.3762v1", 
    "title": "From formal proofs to mathematical proofs: a safe, incremental way for   building in first-order decision procedures", 
    "arxiv-id": "0804.3762v1", 
    "author": "Pierre-Yves Strub", 
    "publish": "2008-04-23T16:56:46Z", 
    "summary": "We investigate here a new version of the Calculus of Inductive Constructions\n(CIC) on which the proof assistant Coq is based: the Calculus of Congruent\nInductive Constructions, which truly extends CIC by building in arbitrary\nfirst-order decision procedures: deduction is still in charge of the CIC\nkernel, while computation is outsourced to dedicated first-order decision\nprocedures that can be taken from the shelves provided they deliver a proof\ncertificate. The soundness of the whole system becomes an incremental property\nfollowing from the soundness of the certificate checkers and that of the\nkernel. A detailed example shows that the resulting style of proofs becomes\ncloser to that of the working mathematician."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-540-88194-0_19", 
    "link": "http://arxiv.org/pdf/0804.4383v2", 
    "title": "Practical Automated Partial Verification of Multi-Paradigm Real-Time   Models", 
    "arxiv-id": "0804.4383v2", 
    "author": "Matteo Rossi", 
    "publish": "2008-04-28T12:04:12Z", 
    "summary": "This article introduces a fully automated verification technique that permits\nto analyze real-time systems described using a continuous notion of time and a\nmixture of operational (i.e., automata-based) and descriptive (i.e.,\nlogic-based) formalisms. The technique relies on the reduction, under\nreasonable assumptions, of the continuous-time verification problem to its\ndiscrete-time counterpart. This reconciles in a viable and effective way the\ndense/discrete and operational/descriptive dichotomies that are often\nencountered in practice when it comes to specifying and analyzing complex\ncritical systems. The article investigates the applicability of the technique\nthrough a significant example centered on a communication protocol. More\nprecisely, concurrent runs of the protocol are formalized by parallel instances\nof a Timed Automaton, while the synchronization rules between these instances\nare specified through Metric Temporal Logic formulas, thus creating a\nmulti-paradigm model. Verification tests run on this model using a bounded\nvalidity checker implementing the technique show consistent results and\ninteresting performances."
},{
    "category": "cs.LO", 
    "doi": "10.3233/FI-2013-950", 
    "link": "http://arxiv.org/pdf/0804.4565v4", 
    "title": "Data linkage algebra, data linkage dynamics, and priority rewriting", 
    "arxiv-id": "0804.4565v4", 
    "author": "C. A. Middelburg", 
    "publish": "2008-04-29T09:55:33Z", 
    "summary": "We introduce an algebra of data linkages. Data linkages are intended for\nmodelling the states of computations in which dynamic data structures are\ninvolved. We present a simple model of computation in which states of\ncomputations are modelled as data linkages and state changes take place by\nmeans of certain actions. We describe the state changes and replies that result\nfrom performing those actions by means of a term rewriting system with rule\npriorities. The model in question is an upgrade of molecular dynamics. The\nupgrading is mainly concerned with the features to deal with values and the\nfeatures to reclaim garbage."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:6)2008", 
    "link": "http://arxiv.org/pdf/0805.0783v2", 
    "title": "Relational Parametricity and Separation Logic", 
    "arxiv-id": "0805.0783v2", 
    "author": "Hongseok Yang", 
    "publish": "2008-05-06T19:27:14Z", 
    "summary": "Separation logic is a recent extension of Hoare logic for reasoning about\nprograms with references to shared mutable data structures. In this paper, we\nprovide a new interpretation of the logic for a programming language with\nhigher types. Our interpretation is based on Reynolds's relational\nparametricity, and it provides a formal connection between separation logic and\ndata abstraction."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:6)2008", 
    "link": "http://arxiv.org/pdf/0805.1386v3", 
    "title": "A language for mathematical knowledge management", 
    "arxiv-id": "0805.1386v3", 
    "author": "Harvey Friedman", 
    "publish": "2008-05-09T17:16:50Z", 
    "summary": "We argue that the language of Zermelo Fraenkel set theory with definitions\nand partial functions provides the most promising bedrock semantics for\ncommunicating and sharing mathematical knowledge. We then describe a syntactic\nsugaring of that language that provides a way of writing remarkably readable\nassertions without straying far from the set-theoretic semantics. We illustrate\nwith some examples of formalized textbook definitions from elementary set\ntheory and point-set topology. We also present statistics concerning the\ncomplexity of these definitions, under various complexity measures."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:6)2008", 
    "link": "http://arxiv.org/pdf/0805.1391v1", 
    "title": "Linear Time Algorithm for Weak Parity Games", 
    "arxiv-id": "0805.1391v1", 
    "author": "Krishnendu Chatterjee", 
    "publish": "2008-05-09T19:12:30Z", 
    "summary": "We consider games played on graphs with the winning conditions for the\nplayers specified as weak-parity conditions. In weak-parity conditions the\nwinner of a play is decided by looking into the set of states appearing in the\nplay, rather than the set of states appearing infinitely often in the play. A\nnaive analysis of the classical algorithm for weak-parity games yields a\nquadratic time algorithm. We present a linear time algorithm for solving\nweak-parity games."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:6)2008", 
    "link": "http://arxiv.org/pdf/0805.1974v2", 
    "title": "Lower Bound for the Communication Complexity of the Russian Cards   Problem", 
    "arxiv-id": "0805.1974v2", 
    "author": "K. Murali Krishnan", 
    "publish": "2008-05-14T06:31:48Z", 
    "summary": "In this paper it is shown that no public announcement scheme that can be\nmodeled in Dynamic Epistemic Logic (DEL) can solve the Russian Cards Problem\n(RCP) in one announcement. Since DEL is a general model for any public\nannouncement scheme we conclude that there exist no single announcement\nsolution to the RCP. The proof demonstrates the utility of DEL in proving lower\nbounds for communication protocols. It is also shown that a general version of\nRCP has no two announcement solution when the adversary has sufficiently large\nnumber of cards."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:6)2008", 
    "link": "http://arxiv.org/pdf/0805.2063v2", 
    "title": "Replication via Invalidating the Applicability of the Fixed Point   Theorem", 
    "arxiv-id": "0805.2063v2", 
    "author": "Genta Ito", 
    "publish": "2008-05-14T13:45:16Z", 
    "summary": "We present a construction of a certain infinite complete partial order (CPO)\nthat differs from the standard construction used in Scott's denotational\nsemantics. In addition, we construct several other infinite CPO's. For some of\nthose, we apply the usual Fixed Point Theorem (FPT) to yield a fixed point for\nevery continuous function $\\mu:2\\to 2$ (where 2 denotes the set $\\{0,1\\}$),\nwhile for the other CPO's we cannot invoke that theorem to yield such fixed\npoints. Every element of each of these CPO's is a binary string in the\nmonotypic form and we show that invalidation of the applicability of the FPT to\nthe CPO that Scott's constructed yields the concept of replication."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:6)2008", 
    "link": "http://arxiv.org/pdf/0805.2179v4", 
    "title": "Mnesors for databases", 
    "arxiv-id": "0805.2179v4", 
    "author": "Gilles Champenois", 
    "publish": "2008-05-14T22:01:31Z", 
    "summary": "We add commutativity to axioms defining mnesors and substitute a bitrop for\nthe lattice. We show that it can be applied to relational database querying:\nset union, intersection and selection are redifined only from the mnesor\naddition and the granular multiplication. Union-compatibility is not required."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:6)2008", 
    "link": "http://arxiv.org/pdf/0805.2785v3", 
    "title": "Proof Search Specifications of Bisimulation and Modal Logics for the   pi-Calculus", 
    "arxiv-id": "0805.2785v3", 
    "author": "Dale Miller", 
    "publish": "2008-05-19T04:33:28Z", 
    "summary": "We specify the operational semantics and bisimulation relations for the\nfinite pi-calculus within a logic that contains the nabla quantifier for\nencoding generic judgments and definitions for encoding fixed points. Since we\nrestrict to the finite case, the ability of the logic to unfold fixed points\nallows this logic to be complete for both the inductive nature of operational\nsemantics and the coinductive nature of bisimulation. The nabla quantifier\nhelps with the delicate issues surrounding the scope of variables within\npi-calculus expressions and their executions (proofs). We illustrate several\nmerits of the logical specifications permitted by this logic: they are natural\nand declarative; they contain no side-conditions concerning names of variables\nwhile maintaining a completely formal treatment of such variables; differences\nbetween late and open bisimulation relations arise from familar logic\ndistinctions; the interplay between the three quantifiers (for all, exists, and\nnabla) and their scopes can explain the differences between early and late\nbisimulation and between various modal operators based on bound input and\noutput actions; and proof search involving the application of inference rules,\nunification, and backtracking can provide complete proof systems for one-step\ntransitions, bisimulation, and satisfaction in modal logic. We also illustrate\nhow one can encode the pi-calculus with replications, in an extended logic with\ninduction and co-induction."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:6)2008", 
    "link": "http://arxiv.org/pdf/0805.3256v2", 
    "title": "Model Checking Event-B by Encoding into Alloy", 
    "arxiv-id": "0805.3256v2", 
    "author": "Joao Marques-Silva", 
    "publish": "2008-05-21T11:35:25Z", 
    "summary": "As systems become ever more complex, verification becomes more main stream.\nEvent-B and Alloy are two formal specification languages based on fairly\ndifferent methodologies. While Event-B uses theorem provers to prove that\ninvariants hold for a given specification, Alloy uses a SAT-based model finder.\nIn some settings, Event-B invariants may not be proved automatically, and so\nthe often difficult step of interactive proof is required. One solution for\nthis problem is to validate invariants with model checking. This work studies\nthe encoding of Event-B machines and contexts to Alloy in order to perform\ntemporal model checking with Alloy's SAT-based engine."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(2:6)2008", 
    "link": "http://arxiv.org/pdf/0805.3261v2", 
    "title": "k-Hyperarc Consistency for Soft Constraints over Divisible Residuated   Lattices", 
    "arxiv-id": "0805.3261v2", 
    "author": "Simone Bova", 
    "publish": "2008-05-21T11:54:51Z", 
    "summary": "We investigate the applicability of divisible residuated lattices (DRLs) as a\ngeneral evaluation framework for soft constraint satisfaction problems (soft\nCSPs). DRLs are in fact natural candidates for this role, since they form the\nalgebraic semantics of a large family of substructural and fuzzy logics.\n  We present the following results. (i) We show that DRLs subsume important\nvaluation structures for soft constraints, such as commutative idempotent\nsemirings and fair valuation structures, in the sense that the last two are\nmembers of certain subvarieties of DRLs (namely, Heyting algebras and\nBL-algebras respectively). (ii) In the spirit of previous work of J. Larrosa\nand T. Schiex [2004], and S. Bistarelli and F. Gadducci [2006] we describe a\npolynomial-time algorithm that enforces k-hyperarc consistency on soft CSPs\nevaluated over DRLs. Observed that, in general, DRLs are neither idempotent nor\ntotally ordered, this algorithm amounts to a generalization of the available\nalgorithms that enforce k-hyperarc consistency."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(3:1)2008", 
    "link": "http://arxiv.org/pdf/0805.3462v2", 
    "title": "Enriched MU-Calculi Module Checking", 
    "arxiv-id": "0805.3462v2", 
    "author": "Mimmo Parente", 
    "publish": "2008-05-22T13:29:44Z", 
    "summary": "The model checking problem for open systems has been intensively studied in\nthe literature, for both finite-state (module checking) and infinite-state\n(pushdown module checking) systems, with respect to Ctl and Ctl*. In this\npaper, we further investigate this problem with respect to the \\mu-calculus\nenriched with nominals and graded modalities (hybrid graded Mu-calculus), in\nboth the finite-state and infinite-state settings. Using an automata-theoretic\napproach, we show that hybrid graded \\mu-calculus module checking is solvable\nin exponential time, while hybrid graded \\mu-calculus pushdown module checking\nis solvable in double-exponential time. These results are also tight since they\nmatch the known lower bounds for Ctl. We also investigate the module checking\nproblem with respect to the hybrid graded \\mu-calculus enriched with inverse\nprograms (Fully enriched \\mu-calculus): by showing a reduction from the domino\nproblem, we show its undecidability. We conclude with a short overview of the\nmodel checking problem for the Fully enriched Mu-calculus and the fragments\nobtained by dropping at least one of the additional constructs."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(3:2)2008", 
    "link": "http://arxiv.org/pdf/0806.0081v4", 
    "title": "Canonical calculi with (n,k)-ary quantifiers", 
    "arxiv-id": "0806.0081v4", 
    "author": "Anna Zamansky", 
    "publish": "2008-05-31T15:35:40Z", 
    "summary": "Propositional canonical Gentzen-type systems, introduced in 2001 by Avron and\nLev, are systems which in addition to the standard axioms and structural rules\nhave only logical rules in which exactly one occurrence of a connective is\nintroduced and no other connective is mentioned. A constructive coherence\ncriterion for the non-triviality of such systems was defined and it was shown\nthat a system of this kind admits cut-elimination iff it is coherent. The\nsemantics of such systems is provided using two-valued non-deterministic\nmatrices (2Nmatrices). In 2005 Zamansky and Avron extended these results to\nsystems with unary quantifiers of a very restricted form. In this paper we\nsubstantially extend the characterization of canonical systems to (n,k)-ary\nquantifiers, which bind k distinct variables and connect n formulas, and show\nthat the coherence criterion remains constructive for such systems. Then we\nfocus on the case of k&#8712;{0,1} and for a canonical calculus G show that it\nis coherent precisely when it has a strongly characteristic 2Nmatrix, which in\nturn is equivalent to admitting strong cut-elimination."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(3:2)2008", 
    "link": "http://arxiv.org/pdf/0806.0103v2", 
    "title": "A note on clique-width and tree-width for structures", 
    "arxiv-id": "0806.0103v2", 
    "author": "Isolde Adler", 
    "publish": "2008-06-02T10:41:48Z", 
    "summary": "We give a simple proof that the straightforward generalisation of\nclique-width to arbitrary structures can be unbounded on structures of bounded\ntree-width. This can be corrected by allowing fusion of elements."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(3:2)2008", 
    "link": "http://arxiv.org/pdf/0806.0936v2", 
    "title": "On convergence-sensitive bisimulation and the embedding of CCS in timed   CCS", 
    "arxiv-id": "0806.0936v2", 
    "author": "Roberto Amadio", 
    "publish": "2008-06-05T09:32:07Z", 
    "summary": "We propose a notion of convergence-sensitive bisimulation that is built just\nover the notions of (internal) reduction and of (static) context. In the\nframework of timed CCS, we characterise this notion of `contextual'\nbisimulation via the usual labelled transition system. We also remark that it\nprovides a suitable semantic framework for a fully abstract embedding of\nuntimed processes into timed ones. Finally, we show that the notion can be\nrefined to include sensitivity to divergence."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(3:5)2008", 
    "link": "http://arxiv.org/pdf/0806.1281v2", 
    "title": "Extracting Programs from Constructive HOL Proofs via IZF   Set-Theoretic<br> Semantics", 
    "arxiv-id": "0806.1281v2", 
    "author": "Wojciech Moczydlowski", 
    "publish": "2008-06-07T13:43:46Z", 
    "summary": "Church's Higher Order Logic is a basis for influential proof assistants --\nHOL and PVS. Church's logic has a simple set-theoretic semantics, making it\ntrustworthy and extensible. We factor HOL into a constructive core plus axioms\nof excluded middle and choice. We similarly factor standard set theory, ZFC,\ninto a constructive core, IZF, and axioms of excluded middle and choice. Then\nwe provide the standard set-theoretic semantics in such a way that the\nconstructive core of HOL is mapped into IZF. We use the disjunction, numerical\nexistence and term existence properties of IZF to provide a program extraction\ncapability from proofs in the constructive core.\n  We can implement the disjunction and numerical existence properties in two\ndifferent ways: one using Rathjen's realizability for IZF and the other using a\nnew direct weak normalization result for IZF by Moczydlowski. The latter can\nalso be used for the term existence property."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(3:5)2008", 
    "link": "http://arxiv.org/pdf/0806.1827v1", 
    "title": "Full Abstraction for a Recursively Typed Lambda Calculus with Parallel   Conditional", 
    "arxiv-id": "0806.1827v1", 
    "author": "Fritz M\u00fcller", 
    "publish": "2008-06-11T15:29:47Z", 
    "summary": "We define the syntax and reduction relation of a recursively typed lambda\ncalculus with a parallel case-function (a parallel conditional). The reduction\nis shown to be confluent. We interpret the recursive types as information\nsystems in a restricted form, which we call prime systems. A denotational\nsemantics is defined with this interpretation. We define the syntactical normal\nform approximations of a term and prove the Approximation Theorem: The\nsemantics of a term equals the limit of the semantics of its approximations.\nThe proof uses inclusive predicates (logical relations). The semantics is\nadequate with respect to the observation of Boolean values. It is also fully\nabstract in the presence of the parallel case-function."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(3:5)2008", 
    "link": "http://arxiv.org/pdf/0806.2517v1", 
    "title": "The computability path ordering: the end of a quest", 
    "arxiv-id": "0806.2517v1", 
    "author": "Albert Rubio", 
    "publish": "2008-06-16T11:39:25Z", 
    "summary": "In this paper, we first briefly survey automated termination proof methods\nfor higher-order calculi. We then concentrate on the higher-order recursive\npath ordering, for which we provide an improved definition, the Computability\nPath Ordering. This new definition appears indeed to capture the essence of\ncomputability arguments \\`a la Tait and Girard, therefore explaining the name\nof the improved ordering."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(3:5)2008", 
    "link": "http://arxiv.org/pdf/0806.2802v1", 
    "title": "A logic with temporally accessible iteration", 
    "arxiv-id": "0806.2802v1", 
    "author": "Alexei Lisitsa", 
    "publish": "2008-06-17T14:36:43Z", 
    "summary": "Deficiency in expressive power of the first-order logic has led to developing\nits numerous extensions by fixed point operators, such as Least Fixed-Point\n(LFP), inflationary fixed-point (IFP), partial fixed-point (PFP), etc. These\nlogics have been extensively studied in finite model theory, database theory,\ndescriptive complexity. In this paper we introduce unifying framework, the\nlogic with iteration operator, in which iteration steps may be accessed by\ntemporal logic formulae. We show that proposed logic FO+TAI subsumes all\nmentioned fixed point extensions as well as many other fixed point logics as\nnatural fragments. On the other hand we show that over finite structures FO+TAI\nis no more expressive than FO+PFP. Further we show that adding the same\nmachinery to the logic of monotone inductions (FO+LFP) does not increase its\nexpressive power either."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(3:5)2008", 
    "link": "http://arxiv.org/pdf/0806.2947v8", 
    "title": "The Kleene-Rosser Paradox, The Liar's Paradox & A Fuzzy Logic   Programming Paradox Imply SAT is (NOT) NP-complete", 
    "arxiv-id": "0806.2947v8", 
    "author": "Rafee Ebrahim Kamouna", 
    "publish": "2008-06-18T10:00:38Z", 
    "summary": "After examining the {\\bf P} versus {\\bf NP} problem against the Kleene-Rosser\nparadox of the $\\lambda$-calculus [94], it was found that it represents a\ncounter-example to NP-completeness. We prove that it contradicts the proof of\nCook's theorem. A logical formalization of the liar's paradox leads to the same\nresult. This formalization of the liar's paradox into a computable form is a\n2-valued instance of a fuzzy logic programming paradox discovered in the system\nof [90]. Three proofs that show that {\\bf SAT} is (NOT) NP-complete are\npresented. The counter-example classes to NP-completeness are also\ncounter-examples to Fagin's theorem [36] and the Immermann-Vardi theorem\n[89,110], the fundamental results of descriptive complexity. All these results\nshow that {\\bf ZF$\\not$C} is inconsistent."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(3:5)2008", 
    "link": "http://arxiv.org/pdf/0806.3209v1", 
    "title": "A Computer Verified Theory of Compact Sets", 
    "arxiv-id": "0806.3209v1", 
    "author": "Russell O'Connor", 
    "publish": "2008-06-19T18:09:01Z", 
    "summary": "Compact sets in constructive mathematics capture our intuition of what\ncomputable subsets of the plane (or any other complete metric space) ought to\nbe. A good representation of compact sets provides an efficient means of\ncreating and displaying images with a computer. In this paper, I build upon\nexisting work about complete metric spaces to define compact sets as the\ncompletion of the space of finite sets under the Hausdorff metric. This\ndefinition allowed me to quickly develop a computer verified theory of compact\nsets. I applied this theory to compute provably correct plots of uniformly\ncontinuous functions."
},{
    "category": "cs.LO", 
    "doi": "10.3233/FI-2010-317", 
    "link": "http://arxiv.org/pdf/0806.4034v2", 
    "title": "Data linkage dynamics with shedding", 
    "arxiv-id": "0806.4034v2", 
    "author": "C. A. Middelburg", 
    "publish": "2008-06-25T07:15:35Z", 
    "summary": "We study shedding in the setting of data linkage dynamics, a simple model of\ncomputation that bears on the use of dynamic data structures in programming.\nShedding is complementary to garbage collection. With shedding, each time a\nlink to a data object is updated by a program, it is determined whether or not\nthe link will possibly be used once again by the program, and if not the link\nis automatically removed. Thus, everything is made garbage as soon as it can be\nviewed as garbage. By that, the effectiveness of garbage collection becomes\nmaximal."
},{
    "category": "cs.LO", 
    "doi": "10.3233/FI-2010-317", 
    "link": "http://arxiv.org/pdf/0806.4130v1", 
    "title": "Complexity of Hybrid Logics over Transitive Frames", 
    "arxiv-id": "0806.4130v1", 
    "author": "Volker Weber", 
    "publish": "2008-06-25T15:38:43Z", 
    "summary": "This paper examines the complexity of hybrid logics over transitive frames,\ntransitive trees, and linear frames. We show that satisfiability over\ntransitive frames for the hybrid language extended with the downarrow operator\nis NEXPTIME-complete. This is in contrast to undecidability of satisfiability\nover arbitrary frames for this language (Areces, Blackburn, Marx 1999). It is\nalso shown that adding the @ operator or the past modality leads to\nundecidability over transitive frames. This is again in contrast to the case of\ntransitive trees and linear frames, where we show these languages to be\nnonelementarily decidable. Moreover, we establish 2EXPTIME and EXPTIME upper\nbounds for satisfiability over transitive frames and transitive trees,\nrespectively, for the hybrid Until/Since language. An EXPTIME lower bound is\nshown to hold for the modal Until language over both frame classes."
},{
    "category": "cs.LO", 
    "doi": "10.3233/FI-2010-317", 
    "link": "http://arxiv.org/pdf/0806.4631v2", 
    "title": "The Heap Lambda Machine", 
    "arxiv-id": "0806.4631v2", 
    "author": "Anton Salikhmetov", 
    "publish": "2008-06-27T23:22:38Z", 
    "summary": "This paper introduces a new machine architecture for evaluating lambda\nexpressions using the normal-order reduction, which guarantees that every\nlambda expression will be evaluated if the expression has its normal form and\nthe system has enough memory. The architecture considered here operates using\nheap memory only. Lambda expressions are represented as graphs, and all\nalgorithms used in the processing unit of this machine are non-recursive."
},{
    "category": "cs.LO", 
    "doi": "10.3233/FI-2010-317", 
    "link": "http://arxiv.org/pdf/0806.4859v2", 
    "title": "Termination of lambda-calculus with the extra Call-By-Value rule known   as assoc", 
    "arxiv-id": "0806.4859v2", 
    "author": "St\u00e9phane Lengrand", 
    "publish": "2008-06-30T11:29:21Z", 
    "summary": "In this paper we prove that any lambda-term that is strongly normalising for\nbeta-reduction is also strongly normalising for beta,assoc-reduction. assoc is\na call-by-value rule that has been used in works by Moggi, Joachimsky, Espirito\nSanto and others. The result has often been justified with incomplete or\nincorrect proofs. Here we give one in full details."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(3:7)2008", 
    "link": "http://arxiv.org/pdf/0806.4956v2", 
    "title": "Game Refinement Relations and Metrics", 
    "arxiv-id": "0806.4956v2", 
    "author": "Mari\u00eblle Stoelinga", 
    "publish": "2008-06-30T17:55:15Z", 
    "summary": "We consider two-player games played over finite state spaces for an infinite\nnumber of rounds. At each state, the players simultaneously choose moves; the\nmoves determine a successor state. It is often advantageous for players to\nchoose probability distributions over moves, rather than single moves. Given a\ngoal, for example, reach a target state, the question of winning is thus a\nprobabilistic one: what is the maximal probability of winning from a given\nstate?\n  On these game structures, two fundamental notions are those of equivalences\nand metrics. Given a set of winning conditions, two states are equivalent if\nthe players can win the same games with the same probability from both states.\nMetrics provide a bound on the difference in the probabilities of winning\nacross states, capturing a quantitative notion of state similarity.\n  We introduce equivalences and metrics for two-player game structures, and we\nshow that they characterize the difference in probability of winning games\nwhose goals are expressed in the quantitative mu-calculus. The quantitative\nmu-calculus can express a large set of goals, including reachability, safety,\nand omega-regular properties. Thus, we claim that our relations and metrics\nprovide the canonical extensions to games, of the classical notion of\nbisimulation for transition systems. We develop our results both for\nequivalences and metrics, which generalize bisimulation, and for asymmetrical\nversions, which generalize simulation."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(3:7)2008", 
    "link": "http://arxiv.org/pdf/0807.0704v1", 
    "title": "Knowledge bases over algebraic models. Some notes about informational   equivalence", 
    "arxiv-id": "0807.0704v1", 
    "author": "Plotkin Tatjana", 
    "publish": "2008-07-04T09:16:13Z", 
    "summary": "The recent advances in knowledge base research and the growing importance of\neffective knowledge management raised an important question of knowledge base\nequivalence verification. This problem has not been stated earlier, at least in\na way that allows speaking about algorithms for verification of informational\nequivalence, because the informal definition of knowledge bases makes formal\nsolution of this problem impossible. In this paper we provide an implementable\nformal algorithm for knowledge base equivalence verification based on the\nformal definition of knowledge base proposed by Plotkin B. and Plotkin T., and\nstudy some important properties of automorphic equivalence of models. We also\ndescribe the concept of equivalence and formulate the criterion for the\nequivalence of knowledge bases defined over finite models. Further we define\nmulti-models and automorphic equivalence of models and multi-models, that is\ngeneralization of automorphic equivalence of algebras."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(3:7)2008", 
    "link": "http://arxiv.org/pdf/0807.1524v1", 
    "title": "Inductive and Coinductive Components of Corecursive Functions in Coq", 
    "arxiv-id": "0807.1524v1", 
    "author": "Ekaterina Komendantskaya", 
    "publish": "2008-07-09T19:16:25Z", 
    "summary": "In Constructive Type Theory, recursive and corecursive definitions are\nsubject to syntactic restrictions which guarantee termination for recursive\nfunctions and productivity for corecursive functions. However, many terminating\nand productive functions do not pass the syntactic tests. Bove proposed in her\nthesis an elegant reformulation of the method of accessibility predicates that\nwidens the range of terminative recursive functions formalisable in\nConstructive Type Theory. In this paper, we pursue the same goal for productive\ncorecursive functions. Notably, our method of formalisation of coinductive\ndefinitions of productive functions in Coq requires not only the use of ad-hoc\npredicates, but also a systematic algorithm that separates the inductive and\ncoinductive parts of functions."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(3:6)2008", 
    "link": "http://arxiv.org/pdf/0807.1669v2", 
    "title": "Coinductive Formal Reasoning in Exact Real Arithmetic", 
    "arxiv-id": "0807.1669v2", 
    "author": "Milad Niqui", 
    "publish": "2008-07-10T14:56:05Z", 
    "summary": "In this article we present a method for formally proving the correctness of\nthe lazy algorithms for computing homographic and quadratic transformations --\nof which field operations are special cases-- on a representation of real\nnumbers by coinductive streams. The algorithms work on coinductive stream of\nM\\\"{o}bius maps and form the basis of the Edalat--Potts exact real arithmetic.\nWe use the machinery of the Coq proof assistant for the coinductive types to\npresent the formalisation. The formalised algorithms are only partially\nproductive, i.e., they do not output provably infinite streams for all possible\ninputs. We show how to deal with this partiality in the presence of syntactic\nrestrictions posed by the constructive type theory of Coq. Furthermore we show\nthat the type theoretic techniques that we develop are compatible with the\nsemantics of the algorithms as continuous maps on real numbers. The resulting\nCoq formalisation is available for public download."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(3:6)2008", 
    "link": "http://arxiv.org/pdf/0807.2543v4", 
    "title": "Two Fuzzy Logic Programming Paradoxes Imply Continuum Hypothesis=\"False\"   & Axiom of Choice=\"False\" Imply ZFC is Inconsistent", 
    "arxiv-id": "0807.2543v4", 
    "author": "Rafee Ebrahim Kamouna", 
    "publish": "2008-07-16T10:58:40Z", 
    "summary": "Two different paradoxes of the fuzzy logic programming system of [29] are\npresented. The first paradox is due to two distinct (contradictory) truth\nvalues for every ground atom of FLP, one is syntactical, the other is\nsemantical. The second paradox concerns the cardinality of the valid FLP\nformulas which is found to have contradictory values: both $\\aleph_0$ the\ncardinality of the natural numbers, and $c$, the cardinality of the continuum.\nThe result is that CH=\"False\" and Axiom of Choice=\"False\". Hence, ZFC is\ninconsistent."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(3:6)2008", 
    "link": "http://arxiv.org/pdf/0807.2636v1", 
    "title": "Topological Observations on Multiplicative Additive Linear Logic", 
    "arxiv-id": "0807.2636v1", 
    "author": "Tom Hirschowitz", 
    "publish": "2008-07-14T16:41:48Z", 
    "summary": "As an attempt to uncover the topological nature of composition of strategies\nin game semantics, we present a ``topological'' game for Multiplicative\nAdditive Linear Logic without propositional variables, including cut moves. We\nrecast the notion of (winning) strategy and the question of cut elimination in\nthis context, and prove a cut elimination theorem. Finally, we prove soundness\nand completeness. The topology plays a crucial role, in particular through the\nfact that strategies form a sheaf."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1929954.1929958", 
    "link": "http://arxiv.org/pdf/0807.3648v5", 
    "title": "Proposition Algebra with Projective Limits", 
    "arxiv-id": "0807.3648v5", 
    "author": "A. Ponse", 
    "publish": "2008-07-23T12:31:11Z", 
    "summary": "Sequential propositional logic deviates from ordinary propositional logic by\ntaking into account that during the sequential evaluation of a propositional\nstatement,atomic propositions may yield different Boolean values at repeated\noccurrences. We introduce `free valuations' to capture this dynamics of a\npropositional statement's environment. The resulting logic is phrased as an\nequationally specified algebra rather than in the form of proof rules, and is\nnamed `proposition algebra'. It is strictly more general than Boolean algebra\nto the extent that the classical connectives fail to be expressively complete\nin the sequential case. The four axioms for free valuation congruence are then\ncombined with other axioms in order define a few more valuation congruences\nthat gradually identify more propositional statements, up to static valuation\ncongruence (which is the setting of conventional propositional logic).\n  Proposition algebra is developed in a fashion similar to the process algebra\nACP and the program algebra PGA, via an algebraic specification which has a\nmeaningful initial algebra for which a range of coarser congruences are\nconsidered important as well. In addition infinite objects (that is\npropositional statements, processes and programs respectively) are dealt with\nby means of an inverse limit construction which allows the transfer of\nknowledge concerning finite objects to facts about infinite ones while reducing\nall facts about infinite objects to an infinity of facts about finite ones in\nreturn."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(3:9)2008", 
    "link": "http://arxiv.org/pdf/0807.4073v2", 
    "title": "Rational streams coalgebraically", 
    "arxiv-id": "0807.4073v2", 
    "author": "J. J. M. M. Rutten", 
    "publish": "2008-07-25T11:36:23Z", 
    "summary": "We study rational streams (over a field) from a coalgebraic perspective.\nExploiting the finality of the set of streams, we present an elementary and\nuniform proof of the equivalence of four notions of representability of\nrational streams: by finite dimensional linear systems; by finite stream\ncircuits; by finite weighted stream automata; and by finite dimensional\nsubsystems of the set of streams."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(3:3)2008", 
    "link": "http://arxiv.org/pdf/0808.0441v2", 
    "title": "Exhaustible sets in higher-type computation", 
    "arxiv-id": "0808.0441v2", 
    "author": "Martin Escardo", 
    "publish": "2008-08-04T13:41:09Z", 
    "summary": "We say that a set is exhaustible if it admits algorithmic universal\nquantification for continuous predicates in finite time, and searchable if\nthere is an algorithm that, given any continuous predicate, either selects an\nelement for which the predicate holds or else tells there is no example. The\nCantor space of infinite sequences of binary digits is known to be searchable.\nSearchable sets are exhaustible, and we show that the converse also holds for\nsets of hereditarily total elements in the hierarchy of continuous functionals;\nmoreover, a selection functional can be constructed uniformly from a\nquantification functional. We prove that searchable sets are closed under\nintersections with decidable sets, and under the formation of computable images\nand of finite and countably infinite products. This is related to the fact,\nestablished here, that exhaustible sets are topologically compact. We obtain a\ncomplete description of exhaustible total sets by developing a computational\nversion of a topological Arzela--Ascoli type characterization of compact\nsubsets of function spaces. We also show that, in the non-empty case, they are\nprecisely the computable images of the Cantor space. The emphasis of this paper\nis on the theory of exhaustible and searchable sets, but we also briefly sketch\napplications."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:6)2008", 
    "link": "http://arxiv.org/pdf/0808.3651v3", 
    "title": "Flow Faster: Efficient Decision Algorithms for Probabilistic Simulations", 
    "arxiv-id": "0808.3651v3", 
    "author": "David N. Jansen", 
    "publish": "2008-08-27T08:35:44Z", 
    "summary": "Strong and weak simulation relations have been proposed for Markov chains,\nwhile strong simulation and strong probabilistic simulation relations have been\nproposed for probabilistic automata. However, decision algorithms for strong\nand weak simulation over Markov chains, and for strong simulation over\nprobabilistic automata are not efficient, which makes it as yet unclear whether\nthey can be used as effectively as their non-probabilistic counterparts. This\npaper presents drastically improved algorithms to decide whether some\n(discrete- or continuous-time) Markov chain strongly or weakly simulates\nanother, or whether a probabilistic automaton strongly simulates another. The\nkey innovation is the use of parametric maximum flow techniques to amortize\ncomputations. We also present a novel algorithm for deciding strong\nprobabilistic simulation preorders on probabilistic automata, which has\npolynomial complexity via a reduction to an LP problem. When extending the\nalgorithms for probabilistic automata to their continuous-time counterpart, we\nretain the same complexity for both strong and strong probabilistic\nsimulations."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(3:13)2008", 
    "link": "http://arxiv.org/pdf/0808.3928v2", 
    "title": "On the strength of proof-irrelevant type theories", 
    "arxiv-id": "0808.3928v2", 
    "author": "Benjamin Werner", 
    "publish": "2008-08-28T15:31:31Z", 
    "summary": "We present a type theory with some proof-irrelevance built into the\nconversion rule. We argue that this feature is useful when type theory is used\nas the logical formalism underlying a theorem prover. We also show a close\nrelation with the subset types of the theory of PVS. We show that in these\ntheories, because of the additional extentionality, the axiom of choice implies\nthe decidability of equality, that is, almost classical logic. Finally we\ndescribe a simple set-theoretic semantics."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(3:11)2008", 
    "link": "http://arxiv.org/pdf/0809.0060v3", 
    "title": "Model Checking Probabilistic Timed Automata with One or Two Clocks", 
    "arxiv-id": "0809.0060v3", 
    "author": "Jeremy Sproston", 
    "publish": "2008-08-30T13:26:48Z", 
    "summary": "Probabilistic timed automata are an extension of timed automata with discrete\nprobability distributions. We consider model-checking algorithms for the\nsubclasses of probabilistic timed automata which have one or two clocks.\nFirstly, we show that PCTL probabilistic model-checking problems (such as\ndetermining whether a set of target states can be reached with probability at\nleast 0.99 regardless of how nondeterminism is resolved) are PTIME-complete for\none-clock probabilistic timed automata, and are EXPTIME-complete for\nprobabilistic timed automata with two clocks. Secondly, we show that, for\none-clock probabilistic timed automata, the model-checking problem for the\nprobabilistic timed temporal logic PCTL is EXPTIME-complete. However, the\nmodel-checking problem for the subclass of PCTL which does not permit both\npunctual timing bounds, which require the occurrence of an event at an exact\ntime point, and comparisons with probability bounds other than 0 or 1, is\nPTIME-complete for one-clock probabilistic timed automata."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:5)2008", 
    "link": "http://arxiv.org/pdf/0809.0195v2", 
    "title": "Light Logics and the Call-by-Value Lambda Calculus", 
    "arxiv-id": "0809.0195v2", 
    "author": "Simona Ronchi Della Rocca", 
    "publish": "2008-09-01T09:46:36Z", 
    "summary": "The so-called light logics have been introduced as logical systems enjoying\nquite remarkable normalization properties. Designing a type assignment system\nfor pure lambda calculus from these logics, however, is problematic. In this\npaper we show that shifting from usual call-by-name to call-by-value lambda\ncalculus allows regaining strong connections with the underlying logic. This\nwill be done in the context of Elementary Affine Logic (EAL), designing a type\nsystem in natural deduction style assigning EAL formulae to lambda terms."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:5)2008", 
    "link": "http://arxiv.org/pdf/0809.0494v1", 
    "title": "Interaction Grammars", 
    "arxiv-id": "0809.0494v1", 
    "author": "Guy Perrier", 
    "publish": "2008-09-02T18:37:01Z", 
    "summary": "Interaction Grammar (IG) is a grammatical formalism based on the notion of\npolarity. Polarities express the resource sensitivity of natural languages by\nmodelling the distinction between saturated and unsaturated syntactic\nstructures. Syntactic composition is represented as a chemical reaction guided\nby the saturation of polarities. It is expressed in a model-theoretic framework\nwhere grammars are constraint systems using the notion of tree description and\nparsing appears as a process of building tree description models satisfying\ncriteria of saturation and minimality."
},{
    "category": "cs.LO", 
    "doi": "10.1007/s10703-011-0136-y", 
    "link": "http://arxiv.org/pdf/0809.1236v4", 
    "title": "Bounded Underapproximations", 
    "arxiv-id": "0809.1236v4", 
    "author": "Benjamin Monmege", 
    "publish": "2008-09-07T22:21:33Z", 
    "summary": "We show a new and constructive proof of the following language-theoretic\nresult: for every context-free language L, there is a bounded context-free\nlanguage L' included in L which has the same Parikh (commutative) image as L.\nBounded languages, introduced by Ginsburg and Spanier, are subsets of regular\nlanguages of the form w1*w2*...wk* for some finite words w1,...,wk. In\nparticular bounded subsets of context-free languages have nice structural and\ndecidability properties. Our proof proceeds in two parts. First, using Newton's\niterations on the language semiring, we construct a context-free subset Ls of L\nthat can be represented as a sequence of substitutions on a linear language and\nhas the same Parikh image as L. Second, we inductively construct a\nParikh-equivalent bounded context-free subset of Ls.\n  We show two applications of this result in model checking: to\nunderapproximate the reachable state space of multithreaded procedural programs\nand to underapproximate the reachable state space of recursive counter\nprograms. The bounded language constructed above provides a decidable\nunderapproximation for the original problems. By iterating the construction, we\nget a semi-algorithm for the original problems that constructs a sequence of\nunderapproximations such that no two underapproximations of the sequence can be\ncompared. This provides a progress guarantee: every word w in L is in some\nunderapproximation of the sequence. In addition, we show that our approach\nsubsumes context-bounded reachability for multithreaded programs."
},{
    "category": "cs.LO", 
    "doi": "10.1007/s10703-011-0136-y", 
    "link": "http://arxiv.org/pdf/0809.1644v1", 
    "title": "Computing with Classical Real Numbers", 
    "arxiv-id": "0809.1644v1", 
    "author": "Russell O'Connor", 
    "publish": "2008-09-09T19:55:03Z", 
    "summary": "There are two incompatible Coq libraries that have a theory of the real\nnumbers; the Coq standard library gives an axiomatic treatment of classical\nreal numbers, while the CoRN library from Nijmegen defines constructively valid\nreal numbers. Unfortunately, this means results about one structure cannot\neasily be used in the other structure. We present a way interfacing these two\nlibraries by showing that their real number structures are isomorphic assuming\nthe classical axioms already present in the standard library reals. This allows\nus to use O'Connor's decision procedure for solving ground inequalities present\nin CoRN to solve inequalities about the reals from the Coq standard library,\nand it allows theorems from the Coq standard library to apply to problem about\nthe CoRN reals."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1656242.1656246", 
    "link": "http://arxiv.org/pdf/0809.2061v3", 
    "title": "Weyl's Predicative Classical Mathematics as a Logic-Enriched Type Theory", 
    "arxiv-id": "0809.2061v3", 
    "author": "Zhaohui Luo", 
    "publish": "2008-09-11T17:25:28Z", 
    "summary": "We construct a logic-enriched type theory LTTW that corresponds closely to\nthe predicative system of foundations presented by Hermann Weyl in Das\nKontinuum. We formalise many results from that book in LTTW, including Weyl's\ndefinition of the cardinality of a set and several results from real analysis,\nusing the proof assistant Plastic that implements the logical framework LF.\nThis case study shows how type theory can be used to represent a\nnon-constructive foundation for mathematics."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1656242.1656246", 
    "link": "http://arxiv.org/pdf/0809.2214v1", 
    "title": "On (Omega-)Regular Model Checking", 
    "arxiv-id": "0809.2214v1", 
    "author": "Pierre Wolper", 
    "publish": "2008-09-12T13:40:37Z", 
    "summary": "Checking infinite-state systems is frequently done by encoding infinite sets\nof states as regular languages. Computing such a regular representation of,\nsay, the set of reachable states of a system requires acceleration techniques\nthat can finitely compute the effect of an unbounded number of transitions.\nAmong the acceleration techniques that have been proposed, one finds both\nspecific and generic techniques. Specific techniques exploit the particular\ntype of system being analyzed, e.g. a system manipulating queues or integers,\nwhereas generic techniques only assume that the transition relation is\nrepresented by a finite-state transducer, which has to be iterated. In this\npaper, we investigate the possibility of using generic techniques in cases\nwhere only specific techniques have been exploited so far. Finding that\nexisting generic techniques are often not applicable in cases easily handled by\nspecific techniques, we have developed a new approach to iterating transducers.\nThis new approach builds on earlier work, but exploits a number of new\nconceptual and algorithmic ideas, often induced with the help of experiments,\nthat give it a broad scope, as well as good performances."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1656242.1656246", 
    "link": "http://arxiv.org/pdf/0809.2394v1", 
    "title": "Structures de r\u00e9alisabilit\u00e9, RAM et ultrafiltre sur N", 
    "arxiv-id": "0809.2394v1", 
    "author": "Jean-Louis Krivine", 
    "publish": "2008-09-14T12:01:24Z", 
    "summary": "We show how to transform into programs the proofs in classical Analysis which\nuse the existence of an ultrafilter on the integers. The method mixes the\nclassical realizability introduced by the author, with the \"forcing\" of P.\nCohen. The programs we obtain, use read and write instructions in random access\nmemory."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:16)2009", 
    "link": "http://arxiv.org/pdf/0809.3960v2", 
    "title": "Formalising the pi-calculus using nominal logic", 
    "arxiv-id": "0809.3960v2", 
    "author": "Joachim Parrow", 
    "publish": "2008-09-23T16:39:03Z", 
    "summary": "We formalise the pi-calculus using the nominal datatype package, based on\nideas from the nominal logic by Pitts et al., and demonstrate an implementation\nin Isabelle/HOL. The purpose is to derive powerful induction rules for the\nsemantics in order to conduct machine checkable proofs, closely following the\nintuitive arguments found in manual proofs. In this way we have covered many of\nthe standard theorems of bisimulation equivalence and congruence, both late and\nearly, and both strong and weak in a uniform manner. We thus provide one of the\nmost extensive formalisations of a process calculus ever done inside a theorem\nprover.\n  A significant gain in our formulation is that agents are identified up to\nalpha-equivalence, thereby greatly reducing the arguments about bound names.\nThis is a normal strategy for manual proofs about the pi-calculus, but that\nkind of hand waving has previously been difficult to incorporate smoothly in an\ninteractive theorem prover. We show how the nominal logic formalism and its\nsupport in Isabelle accomplishes this and thus significantly reduces the tedium\nof conducting completely formal proofs. This improves on previous work using\nweak higher order abstract syntax since we do not need extra assumptions to\nfilter out exotic terms and can keep all arguments within a familiar\nfirst-order logic."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:3)2008", 
    "link": "http://arxiv.org/pdf/0809.4115v2", 
    "title": "Bisimilarity and Behaviour-Preserving Reconfigurations of Open Petri   Nets", 
    "arxiv-id": "0809.4115v2", 
    "author": "Barbara K\u00f6nig", 
    "publish": "2008-09-24T09:28:18Z", 
    "summary": "We propose a framework for the specification of behaviour-preserving\nreconfigurations of systems modelled as Petri nets. The framework is based on\nopen nets, a mild generalisation of ordinary Place/Transition nets suited to\nmodel open systems which might interact with the surrounding environment and\nendowed with a colimit-based composition operation. We show that natural\nnotions of bisimilarity over open nets are congruences with respect to the\ncomposition operation. The considered behavioural equivalences differ for the\nchoice of the observations, which can be single firings or parallel steps.\nAdditionally, we consider weak forms of such equivalences, arising in the\npresence of unobservable actions. We also provide an up-to technique for\nfacilitating bisimilarity proofs. The theory is used to identify suitable\nclasses of reconfiguration rules (in the double-pushout approach to rewriting)\nwhose application preserves the observational semantics of the net."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:3)2008", 
    "link": "http://arxiv.org/pdf/0810.2061v1", 
    "title": "On characterising strong bisimilarity in a fragment of CCS with   replication", 
    "arxiv-id": "0810.2061v1", 
    "author": "Damien Pous", 
    "publish": "2008-10-12T18:54:26Z", 
    "summary": "We provide a characterisation of strong bisimilarity in a fragment of CCS\nthat contains only prefix, parallel composition, synchronisation and a limited\nform of replication. The characterisation is not an axiomatisation, but is\ninstead presented as a rewriting system. We discuss how our method allows us to\nderive a new congruence result in the $\\pi$-calculus: congruence holds in the\nsub-calculus that does not include restriction nor sum, and features a limited\nform of replication. We have not formalised the latter result in all details."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:3)2008", 
    "link": "http://arxiv.org/pdf/0810.2179v2", 
    "title": "Structural abstract interpretation, A formal study using Coq", 
    "arxiv-id": "0810.2179v2", 
    "author": "Yves Bertot", 
    "publish": "2008-10-13T09:07:38Z", 
    "summary": "interpreters are tools to compute approximations for behaviors of a program.\nThese approximations can then be used for optimisation or for error detection.\nIn this paper, we show how to describe an abstract interpreter using the\ntype-theory based theorem prover Coq, using inductive types for syntax and\nstructural recursive programming for the abstract interpreter's kernel. The\nabstract interpreter can then be proved correct with respect to a Hoare logic\nfor the programming language."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:3)2008", 
    "link": "http://arxiv.org/pdf/0810.2877v1", 
    "title": "Sheaves and geometric logic and applications to the modular verification   of complex systems", 
    "arxiv-id": "0810.2877v1", 
    "author": "Viorica Sofronie-Stokkermans", 
    "publish": "2008-10-16T09:38:51Z", 
    "summary": "In this paper we show that states, transitions and behavior of concurrent\nsystems can often be modeled as sheaves over a suitable topological space. In\nthis context, geometric logic can be used to describe which local properties\n(i.e. properties of individual systems) are preserved, at a global level, when\ninterconnecting the systems. The main area of application is to modular\nverification of complex systems. We illustrate the ideas by means of an example\ninvolving a family of interacting controllers for trains on a rail track."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:3)2008", 
    "link": "http://arxiv.org/pdf/0810.2891v2", 
    "title": "Taming Modal Impredicativity: Superlazy Reduction", 
    "arxiv-id": "0810.2891v2", 
    "author": "Luca Vercelli", 
    "publish": "2008-10-16T12:37:26Z", 
    "summary": "Pure, or type-free, Linear Logic proof nets are Turing complete once\ncut-elimination is considered as computation. We introduce modal\nimpredicativity as a new form of impredicativity causing the complexity of\ncut-elimination to be problematic from a complexity point of view. Modal\nimpredicativity occurs when, during reduction, the conclusion of a residual of\na box b interacts with a node that belongs to the proof net inside another\nresidual of b. Technically speaking, superlazy reduction is a new notion of\nreduction that allows to control modal impredicativity. More specifically,\nsuperlazy reduction replicates a box only when all its copies are opened. This\nmakes the overall cost of reducing a proof net finite and predictable.\nSpecifically, superlazy reduction applied to any pure proof nets takes\nprimitive recursive time. Moreover, any primitive recursive function can be\ncomputed by a pure proof net via superlazy reduction."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:3)2008", 
    "link": "http://arxiv.org/pdf/0810.3162v1", 
    "title": "Clone Theory: Its Syntax and Semantics, Applications to Universal   Algebra, Lambda Calculus and Algebraic Logic", 
    "arxiv-id": "0810.3162v1", 
    "author": "Zhaohua Luo", 
    "publish": "2008-10-17T17:46:14Z", 
    "summary": "The primary goal of this paper is to present a unified way to transform the\nsyntax of a logic system into certain initial algebraic structure so that it\ncan be studied algebraically. The algebraic structures which one may choose for\nthis purpose are various clones over a full subcategory of a category. We show\nthat the syntax of equational logic, lambda calculus and first order logic can\nbe represented as clones or right algebras of clones over the set of positive\nintegers. The semantics is then represented by structures derived from left\nalgebras of these clones."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:4)2008", 
    "link": "http://arxiv.org/pdf/0810.3708v2", 
    "title": "Characterising Testing Preorders for Finite Probabilistic Processes", 
    "arxiv-id": "0810.3708v2", 
    "author": "Carroll Morgan", 
    "publish": "2008-10-21T04:48:18Z", 
    "summary": "In 1992 Wang & Larsen extended the may- and must preorders of De Nicola and\nHennessy to processes featuring probabilistic as well as nondeterministic\nchoice. They concluded with two problems that have remained open throughout the\nyears, namely to find complete axiomatisations and alternative\ncharacterisations for these preorders. This paper solves both problems for\nfinite processes with silent moves. It characterises the may preorder in terms\nof simulation, and the must preorder in terms of failure simulation. It also\ngives a characterisation of both preorders using a modal logic. Finally it\naxiomatises both preorders over a probabilistic version of CSP."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:4)2008", 
    "link": "http://arxiv.org/pdf/0810.4904v1", 
    "title": "On Finite Bases for Weak Semantics: Failures versus Impossible Futures", 
    "arxiv-id": "0810.4904v1", 
    "author": "Rob van Glabbeek", 
    "publish": "2008-10-27T18:48:18Z", 
    "summary": "We provide a finite basis for the (in)equational theory of the process\nalgebra BCCS modulo the weak failures preorder and equivalence. We also give\npositive and negative results regarding the axiomatizability of BCCS modulo\nweak impossible futures semantics."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:4)2008", 
    "link": "http://arxiv.org/pdf/0810.5516v1", 
    "title": "Symbolic model checking of tense logics on rational Kripke models", 
    "arxiv-id": "0810.5516v1", 
    "author": "Valentin Goranko", 
    "publish": "2008-10-30T15:59:53Z", 
    "summary": "We introduce the class of rational Kripke models and study symbolic model\nchecking of the basic tense logic Kt and some extensions of it in models from\nthat class. Rational Kripke models are based on (generally infinite) rational\ngraphs, with vertices labeled by the words in some regular language and\ntransitions recognized by asynchronous two-head finite automata, also known as\nrational transducers. Every atomic proposition in a rational Kripke model is\nevaluated in a regular set of states. We show that every formula of Kt has an\neffectively computable regular extension in every rational Kripke model, and\ntherefore local model checking and global model checking of Kt in rational\nKripke models are decidable. These results are lifted to a number of extensions\nof Kt. We study and partly determine the complexity of the model checking\nprocedures."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:4)2008", 
    "link": "http://arxiv.org/pdf/0810.5517v2", 
    "title": "Model checking memoryful linear-time logics over one-counter automata", 
    "arxiv-id": "0810.5517v2", 
    "author": "Arnaud Sangnier", 
    "publish": "2008-10-30T16:04:06Z", 
    "summary": "We study complexity of the model-checking problems for LTL with registers\n(also known as freeze LTL) and for first-order logic with data equality tests\nover one-counter automata. We consider several classes of one-counter automata\n(mainly deterministic vs. nondeterministic) and several logical fragments\n(restriction on the number of registers or variables and on the use of\npropositional variables for control locations). The logics have the ability to\nstore a counter value and to test it later against the current counter value.\nWe show that model checking over deterministic one-counter automata is\nPSPACE-complete with infinite and finite accepting runs. By constrast, we prove\nthat model checking freeze LTL in which the until operator is restricted to the\neventually operator over nondeterministic one-counter automata is undecidable\neven if only one register is used and with no propositional variable. As a\ncorollary of our proof, this also holds for first-order logic with data\nequality tests restricted to two variables. This makes a difference with the\nfacts that several verification problems for one-counter automata are known to\nbe decidable with relatively low complexity, and that finitary satisfiability\nfor the two logics are decidable. Our results pave the way for model-checking\nmemoryful (linear-time) logics over other classes of operational models, such\nas reversal-bounded counter machines."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:11)2008", 
    "link": "http://arxiv.org/pdf/0811.0537v3", 
    "title": "First-Order and Temporal Logics for Nested Words", 
    "arxiv-id": "0811.0537v3", 
    "author": "Leonid Libkin", 
    "publish": "2008-11-04T15:30:12Z", 
    "summary": "Nested words are a structured model of execution paths in procedural\nprograms, reflecting their call and return nesting structure. Finite nested\nwords also capture the structure of parse trees and other tree-structured data,\nsuch as XML. We provide new temporal logics for finite and infinite nested\nwords, which are natural extensions of LTL, and prove that these logics are\nfirst-order expressively-complete. One of them is based on adding a \"within\"\nmodality, evaluating a formula on a subword, to a logic CaRet previously\nstudied in the context of verifying properties of recursive state machines\n(RSMs). The other logic, NWTL, is based on the notion of a summary path that\nuses both the linear and nesting structures. For NWTL we show that\nsatisfiability is EXPTIME-complete, and that model-checking can be done in time\npolynomial in the size of the RSM model and exponential in the size of the NWTL\nformula (and is also EXPTIME-complete). Finally, we prove that first-order\nlogic over nested words has the three-variable property, and we present a\ntemporal logic for nested words which is complete for the two-variable fragment\nof first-order."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:11)2008", 
    "link": "http://arxiv.org/pdf/0811.0964v1", 
    "title": "One useful logic that defines its own truth", 
    "arxiv-id": "0811.0964v1", 
    "author": "Yuri Gurevich", 
    "publish": "2008-11-06T15:09:43Z", 
    "summary": "Existential fixed point logic (EFPL) is a natural fit for some applications,\nand the purpose of this talk is to attract attention to EFPL. The logic is also\ninteresting in its own right as it has attractive properties. One of those\nproperties is rather unusual: truth of formulas can be defined (given\nappropriate syntactic apparatus) in the logic. We mentioned that property\nelsewhere, and we use this opportunity to provide the proof."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:11)2008", 
    "link": "http://arxiv.org/pdf/0811.0977v1", 
    "title": "Two Forms of One Useful Logic: Existential Fixed Point Logic and Liberal   Datalog", 
    "arxiv-id": "0811.0977v1", 
    "author": "Yuri Gurevich", 
    "publish": "2008-11-06T15:58:17Z", 
    "summary": "A natural liberalization of Datalog is used in the Distributed Knowledge\nAuthorization Language (DKAL). We show that the expressive power of this\nliberal Datalog is that of existential fixed-point logic. The exposition is\nself-contained."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:11)2008", 
    "link": "http://arxiv.org/pdf/0811.1914v1", 
    "title": "A TLA+ Proof System", 
    "arxiv-id": "0811.1914v1", 
    "author": "Stephan Merz", 
    "publish": "2008-11-12T15:00:22Z", 
    "summary": "We describe an extension to the TLA+ specification language with constructs\nfor writing proofs and a proof environment, called the Proof Manager (PM), to\nchecks those proofs. The language and the PM support the incremental\ndevelopment and checking of hierarchically structured proofs. The PM translates\na proof into a set of independent proof obligations and calls upon a collection\nof back-end provers to verify them. Different provers can be used to verify\ndifferent obligations. The currently supported back-ends are the tableau prover\nZenon and Isabelle/TLA+, an axiomatisation of TLA+ in Isabelle/Pure. The proof\nobligations for a complete TLA+ proof can also be used to certify the theorem\nin Isabelle/TLA+."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:10)2008", 
    "link": "http://arxiv.org/pdf/0811.1976v2", 
    "title": "Coalgebraic Automata Theory: Basic Results", 
    "arxiv-id": "0811.1976v2", 
    "author": "Y. Venema", 
    "publish": "2008-11-12T18:53:13Z", 
    "summary": "We generalize some of the central results in automata theory to the\nabstraction level of coalgebras and thus lay out the foundations of a universal\ntheory of automata operating on infinite objects.\n  Let F be any set functor that preserves weak pullbacks. We show that the\nclass of recognizable languages of F-coalgebras is closed under taking unions,\nintersections, and projections. We also prove that if a nondeterministic\nF-automaton accepts some coalgebra it accepts a finite one of the size of the\nautomaton. Our main technical result concerns an explicit construction which\ntransforms a given alternating F-automaton into an equivalent nondeterministic\none, whose size is exponentially bound by the size of the original automaton."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:5)2009", 
    "link": "http://arxiv.org/pdf/0811.2198v4", 
    "title": "The Church Problem for Countable Ordinals", 
    "arxiv-id": "0811.2198v4", 
    "author": "Alexander Rabinovich", 
    "publish": "2008-11-13T18:47:27Z", 
    "summary": "A fundamental theorem of Buchi and Landweber shows that the Church synthesis\nproblem is computable. Buchi and Landweber reduced the Church Problem to\nproblems about &#969;-games and used the determinacy of such games as one of\nthe main tools to show its computability. We consider a natural generalization\nof the Church problem to countable ordinals and investigate games of arbitrary\ncountable length. We prove that determinacy and decidability parts of the\nBu}chi and Landweber theorem hold for all countable ordinals and that its full\nextension holds for all ordinals < \\omega\\^\\omega."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:5)2009", 
    "link": "http://arxiv.org/pdf/0811.3400v1", 
    "title": "A Cloning Pushout Approach to Term-Graph Transformation", 
    "arxiv-id": "0811.3400v1", 
    "author": "Fr\u00e9d\u00e9ric Prost", 
    "publish": "2008-11-20T19:39:51Z", 
    "summary": "We address the problem of cyclic termgraph rewriting. We propose a new\nframework where rewrite rules are tuples of the form $(L,R,\\tau,\\sigma)$ such\nthat $L$ and $R$ are termgraphs representing the left-hand and the right-hand\nsides of the rule, $\\tau$ is a mapping from the nodes of $L$ to those of $R$\nand $\\sigma$ is a partial function from nodes of $R$ to nodes of $L$. $\\tau$\ndescribes how incident edges of the nodes in $L$ are connected in $R$. $\\tau$\nis not required to be a graph morphism as in classical algebraic approaches of\ngraph transformation. The role of $\\sigma$ is to indicate the parts of $L$ to\nbe cloned (copied). Furthermore, we introduce a new notion of \\emph{cloning\npushout} and define rewrite steps as cloning pushouts in a given category.\nAmong the features of the proposed rewrite systems, we quote the ability to\nperform local and global redirection of pointers, addition and deletion of\nnodes as well as cloning and collapsing substructures."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:5)2009", 
    "link": "http://arxiv.org/pdf/0811.4367v2", 
    "title": "Hybrid: A Definitional Two-Level Approach to Reasoning with Higher-Order   Abstract Syntax", 
    "arxiv-id": "0811.4367v2", 
    "author": "Alberto Momigliano", 
    "publish": "2008-11-26T17:04:30Z", 
    "summary": "Combining higher-order abstract syntax and (co)induction in a logical\nframework is well known to be problematic. Previous work described the\nimplementation of a tool called Hybrid, within Isabelle HOL, which aims to\naddress many of these difficulties. It allows object logics to be represented\nusing higher-order abstract syntax, and reasoned about using tactical theorem\nproving and principles of (co)induction. In this paper we describe how to use\nit in a multi-level reasoning fashion, similar in spirit to other meta-logics\nsuch as Twelf. By explicitly referencing provability in a middle layer called a\nspecification logic, we solve the problem of reasoning by (co)induction in the\npresence of non-stratifiable hypothetical judgments, which allow very elegant\nand succinct specifications of object logic inference rules."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:5)2009", 
    "link": "http://arxiv.org/pdf/0811.4497v2", 
    "title": "Homomorphism Preservation on Quasi-Wide Classes", 
    "arxiv-id": "0811.4497v2", 
    "author": "Anuj Dawar", 
    "publish": "2008-11-27T09:50:22Z", 
    "summary": "A class of structures is said to have the homomorphism-preservation property\njust in case every first-order formula that is preserved by homomorphisms on\nthis class is equivalent to an existential-positive formula. It is known by a\nresult of Rossman that the class of finite structures has this property and by\nprevious work of Atserias et al. that various of its subclasses do. We extend\nthe latter results by introducing the notion of a quasi-wide class and showing\nthat any quasi-wide class that is closed under taking substructures and\ndisjoint unions has the homomorphism-preservation property. We show, in\nparticular, that classes of structures of bounded expansion and that locally\nexclude minors are quasi-wide. We also construct an example of a class of\nfinite structures which is closed under substructures and disjoint unions but\ndoes not admit the homomorphism-preservation property."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:15)2008", 
    "link": "http://arxiv.org/pdf/0812.1729v2", 
    "title": "The Wadge Hierarchy of Deterministic Tree Languages", 
    "arxiv-id": "0812.1729v2", 
    "author": "Filip Murlak", 
    "publish": "2008-12-09T16:14:05Z", 
    "summary": "We provide a complete description of the Wadge hierarchy for\ndeterministically recognisable sets of infinite trees. In particular we give an\nelementary procedure to decide if one deterministic tree language is\ncontinuously reducible to another. This extends Wagner's results on the\nhierarchy of omega-regular languages of words to the case of trees."
},{
    "category": "cs.LO", 
    "doi": "10.1109/TIME.2008.22", 
    "link": "http://arxiv.org/pdf/0812.1967v1", 
    "title": "Decomposition of Decidable First-Order Logics over Integers and Reals", 
    "arxiv-id": "0812.1967v1", 
    "author": "J\u00e9r\u00f4me Leroux", 
    "publish": "2008-12-10T17:08:45Z", 
    "summary": "We tackle the issue of representing infinite sets of real- valued vectors.\nThis paper introduces an operator for combining integer and real sets. Using\nthis operator, we decompose three well-known logics extending Presburger with\nreals. Our decomposition splits a logic into two parts : one integer, and one\ndecimal (i.e. on the interval [0,1]). We also give a basis for an\nimplementation of our representation."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:16)2008", 
    "link": "http://arxiv.org/pdf/0812.2423v2", 
    "title": "On the Expressive Power of 2-Stack Visibly Pushdown Automata", 
    "arxiv-id": "0812.2423v2", 
    "author": "Benedikt Bollig", 
    "publish": "2008-12-12T16:43:48Z", 
    "summary": "Visibly pushdown automata are input-driven pushdown automata that recognize\nsome non-regular context-free languages while preserving the nice closure and\ndecidability properties of finite automata. Visibly pushdown automata with\nmultiple stacks have been considered recently by La Torre, Madhusudan, and\nParlato, who exploit the concept of visibility further to obtain a rich\nautomata class that can even express properties beyond the class of\ncontext-free languages. At the same time, their automata are closed under\nboolean operations, have a decidable emptiness and inclusion problem, and enjoy\na logical characterization in terms of a monadic second-order logic over words\nwith an additional nesting structure. These results require a restricted\nversion of visibly pushdown automata with multiple stacks whose behavior can be\nsplit up into a fixed number of phases. In this paper, we consider 2-stack\nvisibly pushdown automata (i.e., visibly pushdown automata with two stacks) in\ntheir unrestricted form. We show that they are expressively equivalent to the\nexistential fragment of monadic second-order logic. Furthermore, it turns out\nthat monadic second-order quantifier alternation forms an infinite hierarchy\nwrt words with multiple nestings. Combining these results, we conclude that\n2-stack visibly pushdown automata are not closed under complementation.\nFinally, we discuss the expressive power of B\\\"{u}chi 2-stack visibly pushdown\nautomata running on infinite (nested) words. Extending the logic by an infinity\nquantifier, we can likewise establish equivalence to existential monadic\nsecond-order logic."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:16)2008", 
    "link": "http://arxiv.org/pdf/0812.3068v1", 
    "title": "Branching Bisimilarity with Explicit Divergence", 
    "arxiv-id": "0812.3068v1", 
    "author": "Nikola Trcka", 
    "publish": "2008-12-16T14:36:43Z", 
    "summary": "We consider the relational characterisation of branching bisimilarity with\nexplicit divergence. We prove that it is an equivalence and that it coincides\nwith the original definition of branching bisimilarity with explicit divergence\nin terms of coloured traces. We also establish a correspondence with several\nvariants of an action-based modal logic with until- and divergence modalities."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:16)2008", 
    "link": "http://arxiv.org/pdf/0812.4727v3", 
    "title": "Induction and Co-induction in Sequent Calculus", 
    "arxiv-id": "0812.4727v3", 
    "author": "Alberto Momigliano", 
    "publish": "2008-12-27T09:29:16Z", 
    "summary": "Proof search has been used to specify a wide range of computation systems. In\norder to build a framework for reasoning about such specifications, we make use\nof a sequent calculus involving induction and co-induction. These proof\nprinciples are based on a proof theoretic (rather than set-theoretic) notion of\ndefinition. Definitions are akin to (stratified) logic programs, where the left\nand right rules for defined atoms allow one to view theories as \"closed\" or\ndefining fixed points. The use of definitions makes it possible to reason\nintensionally about syntax, in particular enforcing free equality via\nunification. We add in a consistent way rules for pre and post fixed points,\nthus allowing the user to reason inductively and co-inductively about\nproperties of computational system making full use of higher-order abstract\nsyntax. Consistency is guaranteed via cut-elimination, where we give the first,\nto our knowledge, cut-elimination procedure in the presence of general\ninductive and co-inductive definitions."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(4:16)2008", 
    "link": "http://arxiv.org/pdf/0812.4814v1", 
    "title": "Nominalistic Logic (Extended Abstract)", 
    "arxiv-id": "0812.4814v1", 
    "author": "J\u00f8rgen Villadsen", 
    "publish": "2008-12-28T12:45:05Z", 
    "summary": "Nominalistic Logic (NL) is a new presentation of Paul Gilmore's Intensional\nType Theory (ITT) as a sequent calculus together with a succinct nominalization\naxiom (N) that permits names of predicates as individuals in certain cases. The\nlogic has a flexible comprehension axiom, but no extensionality axiom and no\ninfinity axiom, although axiom N is the key to the derivation of Peano's\npostulates for the natural numbers."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(1:1)2009", 
    "link": "http://arxiv.org/pdf/0812.4848v3", 
    "title": "The Complexity of Generalized Satisfiability for Linear Temporal Logic", 
    "arxiv-id": "0812.4848v3", 
    "author": "Heribert Vollmer", 
    "publish": "2008-12-28T21:10:06Z", 
    "summary": "In a seminal paper from 1985, Sistla and Clarke showed that satisfiability\nfor Linear Temporal Logic (LTL) is either NP-complete or PSPACE-complete,\ndepending on the set of temporal operators used. If, in contrast, the set of\npropositional operators is restricted, the complexity may decrease. This paper\nundertakes a systematic study of satisfiability for LTL formulae over\nrestricted sets of propositional and temporal operators. Since every\npropositional operator corresponds to a Boolean function, there exist\ninfinitely many propositional operators. In order to systematically cover all\npossible sets of them, we use Post's lattice. With its help, we determine the\ncomputational complexity of LTL satisfiability for all combinations of temporal\noperators and all but two classes of propositional functions. Each of these\ninfinitely many problems is shown to be either PSPACE-complete, NP-complete, or\nin P."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:1)2009", 
    "link": "http://arxiv.org/pdf/0901.2518v2", 
    "title": "A Faithful Semantics for Generalised Symbolic Trajectory Evaluation", 
    "arxiv-id": "0901.2518v2", 
    "author": "Jan-Willem Roorda", 
    "publish": "2009-01-16T16:14:48Z", 
    "summary": "Generalised Symbolic Trajectory Evaluation (GSTE) is a high-capacity formal\nverification technique for hardware. GSTE uses abstraction, meaning that\ndetails of the circuit behaviour are removed from the circuit model. A\nsemantics for GSTE can be used to predict and understand why certain circuit\nproperties can or cannot be proven by GSTE. Several semantics have been\ndescribed for GSTE. These semantics, however, are not faithful to the proving\npower of GSTE-algorithms, that is, the GSTE-algorithms are incomplete with\nrespect to the semantics.\n  The abstraction used in GSTE makes it hard to understand why a specific\nproperty can, or cannot, be proven by GSTE. The semantics mentioned above\ncannot help the user in doing so. The contribution of this paper is a faithful\nsemantics for GSTE. That is, we give a simple formal theory that deems a\nproperty to be true if-and-only-if the property can be proven by a GSTE-model\nchecker. We prove that the GSTE algorithm is sound and complete with respect to\nthis semantics."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:1)2009", 
    "link": "http://arxiv.org/pdf/0901.4080v1", 
    "title": "A Framework to Handle Linear Temporal Properties in (\u03c9-)Regular   Model Checking", 
    "arxiv-id": "0901.4080v1", 
    "author": "Pierre Wolper", 
    "publish": "2009-01-26T19:49:43Z", 
    "summary": "Since the topic emerged several years ago, work on regular model checking has\nmostly been devoted to the verification of state reachability and safety\nproperties. Though it was known that linear temporal properties could also be\nchecked within this framework, little has been done about working out the\ncorresponding details. This paper addresses this issue in the context of\nregular model checking based on the encoding of states by finite or infinite\nwords. It works out the exact constructions to be used in both cases, and\nproposes a partial solution to the problem resulting from the fact that\ninfinite computations of unbounded configurations might never contain the same\nconfiguration twice, thus making cycle detection problematic."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:2)2009", 
    "link": "http://arxiv.org/pdf/0901.4430v4", 
    "title": "Neighbourhood Structures: Bisimilarity and Basic Model Theory", 
    "arxiv-id": "0901.4430v4", 
    "author": "Eric Pacuit", 
    "publish": "2009-01-28T10:29:44Z", 
    "summary": "Neighbourhood structures are the standard semantic tool used to reason about\nnon-normal modal logics. The logic of all neighbourhood models is called\nclassical modal logic. In coalgebraic terms, a neighbourhood frame is a\ncoalgebra for the contravariant powerset functor composed with itself, denoted\nby 2^2. We use this coalgebraic modelling to derive notions of equivalence\nbetween neighbourhood structures. 2^2-bisimilarity and behavioural equivalence\nare well known coalgebraic concepts, and they are distinct, since 2^2 does not\npreserve weak pullbacks. We introduce a third, intermediate notion whose\nwitnessing relations we call precocongruences (based on pushouts). We give\nback-and-forth style characterisations for 2^2-bisimulations and\nprecocongruences, we show that on a single coalgebra, precocongruences capture\nbehavioural equivalence, and that between neighbourhood structures,\nprecocongruences are a better approximation of behavioural equivalence than\n2^2-bisimulations. We also introduce a notion of modal saturation for\nneighbourhood models, and investigate its relationship with definability and\nimage-finiteness. We prove a Hennessy-Milner theorem for modally saturated and\nfor image-finite neighbourhood models. Our main results are an analogue of Van\nBenthem's characterisation theorem and a model-theoretic proof of Craig\ninterpolation for classical modal logic."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:2)2009", 
    "link": "http://arxiv.org/pdf/0901.4664v1", 
    "title": "Square root meadows", 
    "arxiv-id": "0901.4664v1", 
    "author": "I. Bethke", 
    "publish": "2009-01-29T12:42:46Z", 
    "summary": "Let Q_0 denote the rational numbers expanded to a meadow by totalizing\ninversion such that 0^{-1}=0. Q_0 can be expanded by a total sign function s\nthat extracts the sign of a rational number. In this paper we discuss an\nextension Q_0(s ,\\sqrt) of the signed rationals in which every number has a\nunique square root."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:2)2009", 
    "link": "http://arxiv.org/pdf/0902.1587v1", 
    "title": "Forward analysis for WSTS, Part I: Completions", 
    "arxiv-id": "0902.1587v1", 
    "author": "Jean Goubault-Larrecq", 
    "publish": "2009-02-10T06:42:24Z", 
    "summary": "Well-structured transition systems provide the right foundation to compute a\nfinite basis of the set of predecessors of the upward closure of a state. The\ndual problem, to compute a finite representation of the set of successors of\nthe downward closure of a state, is harder: Until now, the theoretical\nframework for manipulating downward-closed sets was missing. We answer this\nproblem, using insights from domain theory (dcpos and ideal completions), from\ntopology (sobrifications), and shed new light on the notion of adequate domains\nof limits."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:2)2009", 
    "link": "http://arxiv.org/pdf/0902.2072v1", 
    "title": "Strong Completeness of Coalgebraic Modal Logics", 
    "arxiv-id": "0902.2072v1", 
    "author": "Dirk Pattinson", 
    "publish": "2009-02-12T16:03:10Z", 
    "summary": "Canonical models are of central importance in modal logic, in particular as\nthey witness strong completeness and hence compactness. While the canonical\nmodel construction is well understood for Kripke semantics, non-normal modal\nlogics often present subtle difficulties - up to the point that canonical\nmodels may fail to exist, as is the case e.g. in most probabilistic logics.\nHere, we present a generic canonical model construction in the semantic\nframework of coalgebraic modal logic, which pinpoints coherence conditions\nbetween syntax and semantics of modal logics that guarantee strong\ncompleteness. We apply this method to reconstruct canonical model theorems that\nare either known or folklore, and moreover instantiate our method to obtain new\nstrong completeness results. In particular, we prove strong completeness of\ngraded modal logic with finite multiplicities, and of the modal logic of exact\nprobabilities."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:2)2009", 
    "link": "http://arxiv.org/pdf/0902.3616v1", 
    "title": "Algorithmic Meta-Theorems", 
    "arxiv-id": "0902.3616v1", 
    "author": "Stephan Kreutzer", 
    "publish": "2009-02-20T16:45:04Z", 
    "summary": "Algorithmic meta-theorems are general algorithmic results applying to a whole\nrange of problems, rather than just to a single problem alone. They often have\na \"logical\" and a \"structural\" component, that is they are results of the form:\nevery computational problem that can be formalised in a given logic L can be\nsolved efficiently on every class C of structures satisfying certain\nconditions. This paper gives a survey of algorithmic meta-theorems obtained in\nrecent years and the methods used to prove them. As many meta-theorems use\nresults from graph minor theory, we give a brief introduction to the theory\ndeveloped by Robertson and Seymour for their proof of the graph minor theorem\nand state the main algorithmic consequences of this theory as far as they are\nneeded in the theory of algorithmic meta-theorems."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-540-75560-9", 
    "link": "http://arxiv.org/pdf/0902.3858v1", 
    "title": "Why Would You Trust B?", 
    "arxiv-id": "0902.3858v1", 
    "author": "Catherine Dubois", 
    "publish": "2009-02-23T07:58:03Z", 
    "summary": "The use of formal methods provides confidence in the correctness of\ndevelopments. Yet one may argue about the actual level of confidence obtained\nwhen the method itself -- or its implementation -- is not formally checked. We\naddress this question for the B, a widely used formal method that allows for\nthe derivation of correct programs from specifications. Through a deep\nembedding of the B logic in Coq, we check the B theory but also implement B\ntools. Both aspects are illustrated by the description of a proved prover for\nthe B logic."
},{
    "category": "cs.LO", 
    "doi": "10.1109/HASE.2008.49", 
    "link": "http://arxiv.org/pdf/0902.3861v1", 
    "title": "A Few Remarks About Formal Development of Secure Systems", 
    "arxiv-id": "0902.3861v1", 
    "author": "Th\u00e9r\u00e8se Hardin", 
    "publish": "2009-02-23T08:19:11Z", 
    "summary": "Formal methods provide remarkable tools allowing for high levels of\nconfidence in the correctness of developments. Their use is therefore\nencouraged, when not required, for the development of systems in which safety\nor security is mandatory. But effectively specifying a secure system or\nderiving a secure implementation can be tricky. We propose a review of some\nclassical `gotchas' and other possible sources of concerns with the objective\nto improve the confidence in formal developments, or at least to better assess\nthe actual confidence level."
},{
    "category": "cs.LO", 
    "doi": "10.1109/HASE.2008.49", 
    "link": "http://arxiv.org/pdf/0902.3865v1", 
    "title": "Yet Another Deep Embedding of B:Extending de Bruijn Notations", 
    "arxiv-id": "0902.3865v1", 
    "author": "Th\u00e9r\u00e8se Hardin", 
    "publish": "2009-02-23T08:53:36Z", 
    "summary": "We present Bicoq3, a deep embedding of the B system in Coq, focusing on the\ntechnical aspects of the development. The main subjects discussed are related\nto the representation of sets and maps, the use of induction principles, and\nthe introduction of a new de Bruijn notation providing solutions to various\nproblems related to the mechanisation of languages and logics."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(1:5)2009", 
    "link": "http://arxiv.org/pdf/0902.3958v2", 
    "title": "Antichains for the Automata-Based Approach to Model-Checking", 
    "arxiv-id": "0902.3958v2", 
    "author": "Jean-Francois Raskin", 
    "publish": "2009-02-23T17:17:11Z", 
    "summary": "We propose and evaluate antichain algorithms to solve the universality and\nlanguage inclusion problems for nondeterministic Buechi automata, and the\nemptiness problem for alternating Buechi automata. To obtain those algorithms,\nwe establish the existence of simulation pre-orders that can be exploited to\nefficiently evaluate fixed points on the automata defined during the\ncomplementation step (that we keep implicit in our approach). We evaluate the\nperformance of the algorithm to check the universality of Buechi automata using\nthe random automaton model recently proposed by Tabakov and Vardi. We show that\non the difficult instances of this probabilistic model, our algorithm\noutperforms the standard ones by several orders of magnitude."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(1:5)2009", 
    "link": "http://arxiv.org/pdf/0902.4348v2", 
    "title": "On ground word problem of term equation systems", 
    "arxiv-id": "0902.4348v2", 
    "author": "Sandor Vagvolgyi", 
    "publish": "2009-02-25T11:35:02Z", 
    "summary": "We give semi-decision procedures for the ground word problem of variable\npreserving term equation systems and term equation systems. They are natural\nimprovements of two well known trivial semi-decision procedures. We show the\ncorrectness of our procedures."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(1:5)2009", 
    "link": "http://arxiv.org/pdf/0903.1196v1", 
    "title": "The structure of finite meadows", 
    "arxiv-id": "0903.1196v1", 
    "author": "Arjen Sevenster", 
    "publish": "2009-03-06T12:08:55Z", 
    "summary": "A meadow is a commutative ring with a total inverse operator satisfying\n0^{-1}=0. We show that the class of finite meadows is the closure of the class\nof Galois fields under finite products. As a corollary, we obtain a unique\nrepresentation of minimal finite meadows in terms of finite prime fields."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(1:5)2009", 
    "link": "http://arxiv.org/pdf/0903.1374v2", 
    "title": "The Omega Rule is $\\mathbf{\u03a0_{1}^{1}}$-Complete in the   $\u03bb\u03b2$-Calculus", 
    "arxiv-id": "0903.1374v2", 
    "author": "Richard Statman", 
    "publish": "2009-03-07T23:20:09Z", 
    "summary": "In a functional calculus, the so called \\Omega-rule states that if two terms\nP and Q applied to any closed term <i>N</i> return the same value (i.e. PN =\nQN), then they are equal (i.e. P = Q holds). As it is well known, in the\n\\lambda\\beta-calculus the \\Omega-rule does not hold, even when the \\eta-rule\n(weak extensionality) is added to the calculus. A long-standing problem of H.\nBarendregt (1975) concerns the determination of the logical power of the\n\\Omega-rule when added to the \\lambda\\beta-calculus. In this paper we solve the\nproblem, by showing that the resulting theory is \\Pi\\_{1}^{1}-complete."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:11)2009", 
    "link": "http://arxiv.org/pdf/0903.1822v2", 
    "title": "Continuation-Passing Style and Strong Normalisation for Intuitionistic   Sequent Calculi", 
    "arxiv-id": "0903.1822v2", 
    "author": "Luis Pinto", 
    "publish": "2009-03-10T18:10:52Z", 
    "summary": "The intuitionistic fragment of the call-by-name version of Curien and\nHerbelin's \\lambda\\_mu\\_{\\~mu}-calculus is isolated and proved strongly\nnormalising by means of an embedding into the simply-typed lambda-calculus. Our\nembedding is a continuation-and-garbage-passing style translation, the\ninspiring idea coming from Ikeda and Nakazawa's translation of Parigot's\n\\lambda\\_mu-calculus. The embedding strictly simulates reductions while usual\ncontinuation-passing-style transformations erase permutative reduction steps.\nFor our intuitionistic sequent calculus, we even only need \"units of garbage\"\nto be passed. We apply the same method to other calculi, namely successive\nextensions of the simply-typed &lambda;-calculus leading to our intuitionistic\nsystem, and already for the simplest extension we consider (&lambda;-calculus\nwith generalised application), this yields the first proof of strong\nnormalisation through a reduction-preserving embedding. The results obtained\nextend to second and higher-order calculi."
},{
    "category": "cs.LO", 
    "doi": "10.1002/malq.200910104", 
    "link": "http://arxiv.org/pdf/0903.2177v2", 
    "title": "On the (semi)lattices induced by continuous reducibilities", 
    "arxiv-id": "0903.2177v2", 
    "author": "Arno Pauly", 
    "publish": "2009-03-12T14:34:47Z", 
    "summary": "Continuous reducibilities are a proven tool in computable analysis, and have\napplications in other fields such as constructive mathematics or reverse\nmathematics. We study the order-theoretic properties of several variants of the\ntwo most important definitions, and especially introduce suprema for them. The\nsuprema are shown to commutate with several characteristic numbers."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:7)2009", 
    "link": "http://arxiv.org/pdf/0903.2445v2", 
    "title": "Qualitative Logics and Equivalences for Probabilistic Systems", 
    "arxiv-id": "0903.2445v2", 
    "author": "Axel Legay", 
    "publish": "2009-03-13T17:52:30Z", 
    "summary": "We investigate logics and equivalence relations that capture the qualitative\nbehavior of Markov Decision Processes (MDPs). We present Qualitative Randomized\nCTL (QRCTL): formulas of this logic can express the fact that certain temporal\nproperties hold over all paths, or with probability 0 or 1, but they do not\ndistinguish among intermediate probability values. We present a symbolic,\npolynomial time model-checking algorithm for QRCTL on MDPs.\n  The logic QRCTL induces an equivalence relation over states of an MDP that we\ncall qualitative equivalence: informally, two states are qualitatively\nequivalent if the sets of formulas that hold with probability 0 or 1 at the two\nstates are the same. We show that for finite alternating MDPs, where\nnondeterministic and probabilistic choices occur in different states,\nqualitative equivalence coincides with alternating bisimulation, and can thus\nbe computed via efficient partition-refinement algorithms. On the other hand,\nin non-alternating MDPs the equivalence relations cannot be computed via\npartition-refinement algorithms, but rather, they require non-local\ncomputation. Finally, we consider QRCTL*, that extends QRCTL with nested\ntemporal operators in the same manner in which CTL* extends CTL. We show that\nQRCTL and QRCTL* induce the same qualitative equivalence on alternating MDPs,\nwhile on non-alternating MDPs, the equivalence arising from QRCTL* can be\nstrictly finer. We also provide a full characterization of the relation between\nqualitative equivalence, bisimulation, and alternating bisimulation, according\nto whether the MDPs are finite, and to whether their transition relations are\nfinitely-branching."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:3)2009", 
    "link": "http://arxiv.org/pdf/0903.3126v2", 
    "title": "A Generic Framework for Reasoning about Dynamic Networks of   Infinite-State Processes", 
    "arxiv-id": "0903.3126v2", 
    "author": "Mihaela Sighireanu", 
    "publish": "2009-03-18T10:56:11Z", 
    "summary": "We propose a framework for reasoning about unbounded dynamic networks of\ninfinite-state processes. We propose Constrained Petri Nets (CPN) as generic\nmodels for these networks. They can be seen as Petri nets where tokens\n(representing occurrences of processes) are colored by values over some\npotentially infinite data domain such as integers, reals, etc. Furthermore, we\ndefine a logic, called CML (colored markings logic), for the description of CPN\nconfigurations. CML is a first-order logic over tokens allowing to reason about\ntheir locations and their colors. Both CPNs and CML are parametrized by a color\nlogic allowing to express constraints on the colors (data) associated with\ntokens. We investigate the decidability of the satisfiability problem of CML\nand its applications in the verification of CPNs. We identify a fragment of CML\nfor which the satisfiability problem is decidable (whenever it is the case for\nthe underlying color logic), and which is closed under the computations of post\nand pre images for CPNs. These results can be used for several kinds of\nanalysis such as invariance checking, pre-post condition reasoning, and bounded\nreachability analysis."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:3)2009", 
    "link": "http://arxiv.org/pdf/0903.3850v1", 
    "title": "Using Structural Recursion for Corecursion", 
    "arxiv-id": "0903.3850v1", 
    "author": "Ekaterina Komendantskaya", 
    "publish": "2009-03-23T12:35:27Z", 
    "summary": "We propose a (limited) solution to the problem of constructing stream values\ndefined by recursive equations that do not respect the guardedness condition.\nThe guardedness condition is imposed on definitions of corecursive functions in\nCoq, AGDA, and other higher-order proof assistants. In this paper, we\nconcentrate in particular on those non-guarded equations where recursive calls\nappear under functions. We use a correspondence between streams and functions\nover natural numbers to show that some classes of non-guarded definitions can\nbe modelled through the encoding as structural recursive functions. In\npractice, this work extends the class of stream values that can be defined in a\nconstructive type theory-based theorem prover with inductive and coinductive\ntypes, structural recursion and guarded corecursion"
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:3)2009", 
    "link": "http://arxiv.org/pdf/0903.4366v3", 
    "title": "Complexity of Fractran and Productivity", 
    "arxiv-id": "0903.4366v3", 
    "author": "Dimitri Hendriks", 
    "publish": "2009-03-25T15:14:00Z", 
    "summary": "In functional programming languages the use of infinite structures is common\npractice. For total correctness of programs dealing with infinite structures\none must guarantee that every finite part of the result can be evaluated in\nfinitely many steps. This is known as productivity. For programming with\ninfinite structures, productivity is what termination in well-defined results\nis for programming with finite structures.\n  Fractran is a simple Turing-complete programming language invented by Conway.\nWe prove that the question whether a Fractran program halts on all positive\nintegers is Pi^0_2-complete. In functional programming, productivity typically\nis a property of individual terms with respect to the inbuilt evaluation\nstrategy. By encoding Fractran programs as specifications of infinite lists, we\nestablish that this notion of productivity is Pi^0_2-complete even for the most\nsimple specifications. Therefore it is harder than termination of individual\nterms. In addition, we explore possible generalisations of the notion of\nproductivity in the framework of term rewriting, and prove that their\ncomputational complexity is Pi^1_1-complete, thus exceeding the expressive\npower of first-order logic."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:8)2009", 
    "link": "http://arxiv.org/pdf/0903.4382v4", 
    "title": "Ranking Functions for Size-Change Termination II", 
    "arxiv-id": "0903.4382v4", 
    "author": "Chin Soon Lee", 
    "publish": "2009-03-25T17:47:30Z", 
    "summary": "Size-Change Termination is an increasingly-popular technique for verifying\nprogram termination. These termination proofs are deduced from an abstract\nrepresentation of the program in the form of \"size-change graphs\".\n  We present algorithms that, for certain classes of size-change graphs, deduce\na global ranking function: an expression that ranks program states, and\ndecreases on every transition. A ranking function serves as a witness for a\ntermination proof, and is therefore interesting for program certification. The\nparticular form of the ranking expressions that represent SCT termination\nproofs sheds light on the scope of the proof method. The complexity of the\nexpressions is also interesting, both practicaly and theoretically.\n  While deducing ranking functions from size-change graphs has already been\nshown possible, the constructions in this paper are simpler and more\ntransparent than previously known. They improve the upper bound on the size of\nthe ranking expression from triply exponential down to singly exponential (for\ncertain classes of instances). We claim that this result is, in some sense,\noptimal. To this end, we introduce a framework for lower bounds on the\ncomplexity of ranking expressions and prove exponential lower bounds."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:8)2009", 
    "link": "http://arxiv.org/pdf/0903.5259v2", 
    "title": "A System of Interaction and Structure IV: The Exponentials and   Decomposition", 
    "arxiv-id": "0903.5259v2", 
    "author": "Alessio Guglielmi", 
    "publish": "2009-03-30T16:49:36Z", 
    "summary": "We study a system, called NEL, which is the mixed commutative/non-commutative\nlinear logic BV augmented with linear logic's exponentials. Equivalently, NEL\nis MELL augmented with the non-commutative self-dual connective seq. In this\npaper, we show a basic compositionality property of NEL, which we call\ndecomposition. This result leads to a cut-elimination theorem, which is proved\nin the next paper of this series. To control the induction measure for the\ntheorem, we rely on a novel technique that extracts from NEL proofs the\nstructure of exponentials, into what we call !-?-Flow-Graphs."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:8)2009", 
    "link": "http://arxiv.org/pdf/0904.0034v1", 
    "title": "CCS-Based Dynamic Logics for Communicating Concurrent Programs", 
    "arxiv-id": "0904.0034v1", 
    "author": "L. Menasch\u00e9 Schechter", 
    "publish": "2009-04-01T02:07:44Z", 
    "summary": "This work presents three increasingly expressive Dynamic Logics in which the\nprograms are CCS processes (sCCS-PDL, CCS-PDL and XCCS-PDL). Their goal is to\nreason about properties of concurrent programs and systems described using CCS.\nIn order to accomplish that, CCS's operators and constructions are added to a\nbasic modal logic in order to create dynamic logics that are suitable for the\ndescription and verification of properties of communicating, concurrent and\nnon-deterministic programs and systems, in a similar way as PDL is used for the\nsequential case. We provide complete axiomatizations for the three logics.\nUnlike Peleg's Concurrent PDL with Channels, our logics have a simple Kripke\nsemantics, complete axiomatizations and the finite model property."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:8)2009", 
    "link": "http://arxiv.org/pdf/0904.0578v2", 
    "title": "Efficient Description Logic Reasoning in Prolog: The DLog system", 
    "arxiv-id": "0904.0578v2", 
    "author": "P\u00e9ter Szeredi", 
    "publish": "2009-04-03T13:52:57Z", 
    "summary": "This paper describes a resolution based Description Logic reasoning system\ncalled DLog. DLog transforms Description Logic axioms into a Prolog program and\nuses the standard Prolog execution for efficiently answering instance retrieval\nqueries. From the Description Logic point of view, DLog is an ABox reasoning\nengine for the full SHIQ language. The DLog approach makes it possible to store\nthe individuals in a database instead of memory, which results in better\nscalability and helps using description logic ontologies directly on top of\nexisting information sources.\n  To appear in Theory and Practice of Logic Programming (TPLP)."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:8)2009", 
    "link": "http://arxiv.org/pdf/0904.0589v1", 
    "title": "Fuzzy Linguistic Logic Programming and its Applications", 
    "arxiv-id": "0904.0589v1", 
    "author": "Dinh Khang Tran", 
    "publish": "2009-04-03T14:45:20Z", 
    "summary": "The paper introduces fuzzy linguistic logic programming, which is a\ncombination of fuzzy logic programming, introduced by P. Vojtas, and hedge\nalgebras in order to facilitate the representation and reasoning on human\nknowledge expressed in natural languages. In fuzzy linguistic logic\nprogramming, truth values are linguistic ones, e.g., VeryTrue,\nVeryProbablyTrue, and LittleFalse, taken from a hedge algebra of a linguistic\ntruth variable, and linguistic hedges (modifiers) can be used as unary\nconnectives in formulae. This is motivated by the fact that humans reason\nmostly in terms of linguistic terms rather than in terms of numbers, and\nlinguistic hedges are often used in natural languages to express different\nlevels of emphasis. The paper presents: (i) the language of fuzzy linguistic\nlogic programming; (ii) a declarative semantics in terms of Herbrand\ninterpretations and models; (iii) a procedural semantics which directly\nmanipulates linguistic terms to compute a lower bound to the truth value of a\nquery, and proves its soundness; (iv) a fixpoint semantics of logic programs,\nand based on it, proves the completeness of the procedural semantics; (v)\nseveral applications of fuzzy linguistic logic programming; and (vi) an idea of\nimplementing a system to execute fuzzy linguistic logic programs."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:8)2009", 
    "link": "http://arxiv.org/pdf/0904.1488v1", 
    "title": "Computing Stuttering Simulations", 
    "arxiv-id": "0904.1488v1", 
    "author": "Francesco Tapparo", 
    "publish": "2009-04-09T09:40:33Z", 
    "summary": "Stuttering bisimulation is a well-known behavioral equivalence that preserves\nCTL-X, namely CTL without the next-time operator X. Correspondingly, the\nstuttering simulation preorder induces a coarser behavioral equivalence that\npreserves the existential fragment ECTL-{X,G}, namely ECTL without the\nnext-time X and globally G operators. While stuttering bisimulation equivalence\ncan be computed by the well-known Groote and Vaandrager's [1990] algorithm, to\nthe best of our knowledge, no algorithm for computing the stuttering simulation\npreorder and equivalence is available. This paper presents such an algorithm\nfor finite state systems."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:8)2009", 
    "link": "http://arxiv.org/pdf/0904.2076v2", 
    "title": "On stratified regions", 
    "arxiv-id": "0904.2076v2", 
    "author": "Roberto Amadio", 
    "publish": "2009-04-14T09:22:16Z", 
    "summary": "Type and effect systems are a tool to analyse statically the behaviour of\nprograms with effects. We present a proof based on the so called reducibility\ncandidates that a suitable stratification of the type and effect system entails\nthe termination of the typable programs. The proof technique covers a simply\ntyped, multi-threaded, call-by-value lambda-calculus, equipped with a variety\nof scheduling (preemptive, cooperative) and interaction mechanisms (references,\nchannels, signals)."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(2:15)2009", 
    "link": "http://arxiv.org/pdf/0904.2340v2", 
    "title": "Explicit fairness in testing semantics", 
    "arxiv-id": "0904.2340v2", 
    "author": "C. Palamidessi", 
    "publish": "2009-04-15T15:55:56Z", 
    "summary": "In this paper we investigate fair computations in the pi-calculus. Following\nCosta and Stirling's approach for CCS-like languages, we consider a method to\nlabel process actions in order to filter out unfair computations. We contrast\nthe existing fair-testing notion with those that naturally arise by imposing\nweak and strong fairness. This comparison provides insight about the\nexpressiveness of the various `fair' testing semantics and about their\ndiscriminating power."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(4:7)2010", 
    "link": "http://arxiv.org/pdf/0904.2675v5", 
    "title": "Bounded Linear Logic, Revisited", 
    "arxiv-id": "0904.2675v5", 
    "author": "Martin Hofmann", 
    "publish": "2009-04-17T10:44:18Z", 
    "summary": "We present QBAL, an extension of Girard, Scedrov and Scott's bounded linear\nlogic. The main novelty of the system is the possibility of quantifying over\nresource variables. This generalization makes bounded linear logic considerably\nmore flexible, while preserving soundness and completeness for polynomial time.\nIn particular, we provide compositional embeddings of Leivant's RRW and\nHofmann's LFPL into QBAL."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-03816-7_44", 
    "link": "http://arxiv.org/pdf/0904.2894v1", 
    "title": "On FO2 quantifier alternation over words", 
    "arxiv-id": "0904.2894v1", 
    "author": "Pascal Weil", 
    "publish": "2009-04-19T08:01:34Z", 
    "summary": "We show that each level of the quantifier alternation hierarchy within\nFO^2[<] -- the 2-variable fragment of the first order logic of order on words\n-- is a variety of languages. We then use the notion of condensed rankers, a\nrefinement of the rankers defined by Weis and Immerman, to produce a decidable\nhierarchy of varieties which is interwoven with the quantifier alternation\nhierarchy -- and conjecturally equal to it. It follows that the latter\nhierarchy is decidable within one unit: given a formula alpha in FO^2[<], one\ncan effectively compute an integer m such that alpha is equivalent to a formula\nwith at most m+1 alternating blocks of quantifiers, but not to a formula with\nonly m-1 blocks. This is a much more precise result than what is known about\nthe quantifier alternation hierarchy within FO[<], where no decidability result\nis known beyond the very first levels."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-03816-7_44", 
    "link": "http://arxiv.org/pdf/0904.3036v41", 
    "title": "Inconsistency Robustness in Logic Programs", 
    "arxiv-id": "0904.3036v41", 
    "author": "Carl Hewitt", 
    "publish": "2009-04-20T14:07:18Z", 
    "summary": "Inconsistency robustness is \"information system performance in the face of\ncontinually pervasive inconsistencies.\" A fundamental principle of\nInconsistency Robustness is to make contradictions explicit so that arguments\nfor and against propositions can be formalized. This paper explores the role of\nInconsistency Robustness in the history and theory of Logic Programs.\n  Robert Kowalski put forward a bold thesis: \"Looking back on our early\ndiscoveries, I value most the discovery that computation could be subsumed by\ndeduction.\" However, mathematical logic cannot always infer computational steps\nbecause computational systems make use of arbitration for determining which\nmessage is processed next by a recipient that is sent multiple messages\nconcurrently. Since reception orders are in general indeterminate, they cannot\nbe inferred from prior information by mathematical logic alone. Therefore\nmathematical logic cannot in general implement computation.\n  Over the course of history, the term \"Functional Program\" has grown more\nprecise and technical as the field has matured. \"Logic Program\" should be on a\nsimilar trajectory. Accordingly, \"Logic Program\" should have a general precise\ncharacterization. In the fall of 1972, different characterizations of Logic\nPrograms that have continued to this day:\n  * A Logic Program uses Horn-Clause syntax for forward and backward chaining\n  * Each computational step (according to Actor Model) of a Logic Program is\ndeductively inferred (e.g. in Direct Logic).\n  The above examples are illustrative of how issues of inconsistency robustness\nhave repeatedly arisen in Logic Programs."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-03816-7_44", 
    "link": "http://arxiv.org/pdf/0904.3588v1", 
    "title": "Termination of Linear Programs with Nonlinear Constraints", 
    "arxiv-id": "0904.3588v1", 
    "author": "Zhihai Zhang", 
    "publish": "2009-04-23T02:52:15Z", 
    "summary": "Tiwari proved that termination of linear programs (loops with linear loop\nconditions and updates) over the reals is decidable through Jordan forms and\neigenvectors computation. Braverman proved that it is also decidable over the\nintegers. In this paper, we consider the termination of loops with polynomial\nloop conditions and linear updates over the reals and integers. First, we prove\nthat the termination of such loops over the integers is undecidable. Second,\nwith an assumption, we provide an complete algorithm to decide the termination\nof a class of such programs over the reals. Our method is similar to that of\nTiwari in spirit but uses different techniques. Finally, we conjecture that the\ntermination of linear programs with polynomial loop conditions over the reals\nis undecidable in general by %constructing a loop and reducing the problem to\nanother decision problem related to number theory and ergodic theory, which we\nguess undecidable."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(3:5)2009", 
    "link": "http://arxiv.org/pdf/0904.4119v2", 
    "title": "Two-Way Unary Temporal Logic over Trees", 
    "arxiv-id": "0904.4119v2", 
    "author": "Mikolaj Bojanczyk", 
    "publish": "2009-04-27T09:33:44Z", 
    "summary": "We consider a temporal logic EF+F^-1 for unranked, unordered finite trees.\nThe logic has two operators: EF\\phi, which says \"in some proper descendant \\phi\nholds\", and F^-1\\phi, which says \"in some proper ancestor \\phi holds\". We\npresent an algorithm for deciding if a regular language of unranked finite\ntrees can be expressed in EF+F^-1. The algorithm uses a characterization\nexpressed in terms of forest algebras."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(3:5)2009", 
    "link": "http://arxiv.org/pdf/0904.4756v1", 
    "title": "Models and theories of lambda calculus", 
    "arxiv-id": "0904.4756v1", 
    "author": "Giulio Manzonetto", 
    "publish": "2009-04-30T08:27:38Z", 
    "summary": "In this paper we briefly summarize the contents of Manzonetto's PhD thesis\nwhich concerns denotational semantics and equational/order theories of the pure\nuntyped lambda-calculus. The main research achievements include: (i) a general\nconstruction of lambda-models from reflexive objects in (possibly\nnon-well-pointed) categories; (ii) a Stone-style representation theorem for\ncombinatory algebras; (iii) a proof that no effective lambda-model can have\nlambda-beta or lambda-beta-eta as its equational theory (this can be seen as a\npartial answer to an open problem introduced by Honsell-Ronchi Della Rocca in\n1984)."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(3:5)2009", 
    "link": "http://arxiv.org/pdf/0905.2195v1", 
    "title": "Expressiveness and Closure Properties for Quantitative Languages", 
    "arxiv-id": "0905.2195v1", 
    "author": "Thomas A. Henzinger", 
    "publish": "2009-05-13T20:27:01Z", 
    "summary": "Weighted automata are nondeterministic automata with numerical weights on\ntransitions. They can define quantitative languages $L$ that assign to each\nword $w$ a real number $L(w)$. In the case of infinite words, the value of a\nrun is naturally computed as the maximum, limsup, liminf, limit average, or\ndiscounted sum of the transition weights. We study expressiveness and closure\nquestions about these quantitative languages.\n  We first show that the set of words with value greater than a threshold can\nbe non-$\\omega$-regular for deterministic limit-average and discounted-sum\nautomata, while this set is always $\\omega$-regular when the threshold is\nisolated (i.e., some neighborhood around the threshold contains no word). In\nthe latter case, we prove that the $\\omega$-regular language is robust against\nsmall perturbations of the transition weights.\n  We next consider automata with transition weights 0 or 1 and show that they\nare as expressive as general weighted automata in the limit-average case, but\nnot in the discounted-sum case.\n  Third, for quantitative languages $L_1$ and $L_2$, we consider the operations\n$\\max(L_1,L_2)$, $\\min(L_1,L_2)$, and $1-L_1$, which generalize the boolean\noperations on languages, as well as the sum $L_1 + L_2$. We establish the\nclosure properties of all classes of quantitative languages with respect to\nthese four operations."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(3:3)2009", 
    "link": "http://arxiv.org/pdf/0905.3668v2", 
    "title": "Lindstrom theorems for fragments of first-order logic", 
    "arxiv-id": "0905.3668v2", 
    "author": "Jouko Vaananen", 
    "publish": "2009-05-22T12:10:07Z", 
    "summary": "Lindstr\\\"om theorems characterize logics in terms of model-theoretic\nconditions such as Compactness and the L\\\"owenheim-Skolem property. Most\nexisting characterizations of this kind concern extensions of first-order\nlogic. But on the other hand, many logics relevant to computer science are\nfragments or extensions of fragments of first-order logic, e.g., k-variable\nlogics and various modal logics. Finding Lindstr\\\"om theorems for these\nlanguages can be challenging, as most known techniques rely on coding arguments\nthat seem to require the full expressive power of first-order logic. In this\npaper, we provide Lindstr\\\"om theorems for several fragments of first-order\nlogic, including the k-variable fragments for k>2, Tarski's relation algebra,\ngraded modal logic, and the binary guarded fragment. We use two different proof\ntechniques. One is a modification of the original Lindstr\\\"om proof. The other\ninvolves the modal concepts of bisimulation, tree unraveling, and finite depth.\nOur results also imply semantic preservation theorems."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(3:3)2009", 
    "link": "http://arxiv.org/pdf/0905.4090v1", 
    "title": "Orthomodular lattices, Foulis Semigroups and Dagger Kernel Categories", 
    "arxiv-id": "0905.4090v1", 
    "author": "Bart Jacobs", 
    "publish": "2009-05-25T22:38:41Z", 
    "summary": "This paper is a sequel to arXiv:0902.2355 and continues the study of quantum\nlogic via dagger kernel categories. It develops the relation between these\ncategories and both orthomodular lattices and Foulis semigroups. The relation\nbetween the latter two notions has been uncovered in the 1960s. The current\ncategorical perspective gives a broader context and reconstructs this\nrelationship between orthomodular lattices and Foulis semigroups as special\ninstance."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(3:3)2009", 
    "link": "http://arxiv.org/pdf/0905.4332v1", 
    "title": "On expressive power and class invariance", 
    "arxiv-id": "0905.4332v1", 
    "author": "Francien Dechesne", 
    "publish": "2009-05-27T13:15:37Z", 
    "summary": "In computer science, various logical languages are defined to analyze\nproperties of systems. One way to pinpoint the essential differences between\nthose logics is to compare their expressivity in terms of distinguishing power\nand expressive power. In this paper, we study those two concepts by regarding\nthe latter notion as the former lifted to classes of models. We show some\ngeneral results on lifting an invariance relation on models to one on classes\nof models, such that when the former corresponds to the distinguishing power of\na logic, the latter corresponds to its expressive power, given certain\ncompactness requirements. In particular, we introduce the notion of class\nbisimulation to capture the expressive power of modal logics. We demonstrate\nthe application of our results by revisiting modal definability with our new\ninsights."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(3:3)2009", 
    "link": "http://arxiv.org/pdf/0905.4567v1", 
    "title": "Confluence Results for a Quantum Lambda Calculus with Measurements", 
    "arxiv-id": "0905.4567v1", 
    "author": "Margherita Zorzi", 
    "publish": "2009-05-28T07:46:18Z", 
    "summary": "A strong confluence result for Q*, a quantum lambda-calculus with\nmeasurements, is proved. More precisely, confluence is shown to hold both for\nfinite and infinite computations. The technique used in the confluence proof is\nsyntactical but innovative. This makes Q* different from similar quantum lambda\ncalculi, which are either measurement-free or provided with a reduction\nstrategy."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(3:3)2009", 
    "link": "http://arxiv.org/pdf/0905.4612v2", 
    "title": "Straight-line instruction sequence completeness for total calculation on   cancellation meadows", 
    "arxiv-id": "0905.4612v2", 
    "author": "Inge Bethke", 
    "publish": "2009-05-28T11:13:58Z", 
    "summary": "A combination of program algebra with the theory of meadows is designed\nleading to a theory of computation in algebraic structures which use in\naddition to a zero test and copying instructions the instruction set $\\{x\n\\Leftarrow 0, x \\Leftarrow 1, x\\Leftarrow -x, x\\Leftarrow x^{-1}, x\\Leftarrow\nx+y, x\\Leftarrow x\\cdot y\\}$. It is proven that total functions on cancellation\nmeadows can be computed by straight-line programs using at most 5 auxiliary\nvariables. A similar result is obtained for signed meadows."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(3:3)2009", 
    "link": "http://arxiv.org/pdf/0905.4905v1", 
    "title": "Aspects Regarding Operations with Fuzzy Processes", 
    "arxiv-id": "0905.4905v1", 
    "author": "Lucian L. Luca", 
    "publish": "2009-05-29T15:43:32Z", 
    "summary": "This paper introduces the notion of fuzzy process as a formalism for the idea\nof fuzzy contact between a device and its environment. The notions of absolute\ncorrectness and relative correctness are defined. In order to work with\nconcurrency it has been built an approach to manipulate the interactive\nprocesses as a single process and the resulted behavior has been observed."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(3:3)2009", 
    "link": "http://arxiv.org/pdf/0905.4906v1", 
    "title": "On Some Manipulations with Fuzzy Processes", 
    "arxiv-id": "0905.4906v1", 
    "author": "Lucian L. Luca", 
    "publish": "2009-05-29T15:47:17Z", 
    "summary": "The paper starts from the observation on the complexity of the manipulation\nof fuzzy processes that increases very rapidly with the extents of the\nprocesses representation. Therefore, a productive approach is to divide the\nproblem into smaller parts, treated separately and then the results combined.\nSome algebraic results obtained by the authors are presented."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(3:3)2009", 
    "link": "http://arxiv.org/pdf/0906.2521v1", 
    "title": "On the Complexity of Branching-Time Logics", 
    "arxiv-id": "0906.2521v1", 
    "author": "Volker Weber", 
    "publish": "2009-06-14T09:20:10Z", 
    "summary": "We classify the complexity of the satisfiability problem for extensions of\nCTL and UB. The extensions we consider are Boolean combinations of path\nformulas, fairness properties, past modalities, and forgettable past. Our main\nresult shows that satisfiability for CTL with all these extensions is still in\n2-EXPTIME, which strongly contrasts with the nonelementary complexity of CTL*\nwith forgettable past. We give a complete classification of combinations of\nthese extensions, yielding a dichotomy between extensions with\n2-EXPTIME-complete and those with EXPTIME-complete complexity. In particular,\nwe show that satisfiability for the extension of UB with forgettable past is\ncomplete for 2-EXPTIME, contradicting a claim for a stronger logic in the\nliterature. The upper bounds are established with the help of a new kind of\npebble automata."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-03816-7_37", 
    "link": "http://arxiv.org/pdf/0906.2541v1", 
    "title": "On the Hybrid Extension of CTL and CTL+", 
    "arxiv-id": "0906.2541v1", 
    "author": "Volker Weber", 
    "publish": "2009-06-14T14:35:09Z", 
    "summary": "The paper studies the expressivity, relative succinctness and complexity of\nsatisfiability for hybrid extensions of the branching-time logics CTL and CTL+\nby variables. Previous complexity results show that only fragments with one\nvariable do have elementary complexity. It is shown that H1CTL+ and H1CTL, the\nhybrid extensions with one variable of CTL+ and CTL, respectively, are\nexpressively equivalent but H1CTL+ is exponentially more succinct than H1CTL.\nOn the other hand, HCTL+, the hybrid extension of CTL with arbitrarily many\nvariables does not capture CTL*, as it even cannot express the simple CTL*\nproperty EGFp. The satisfiability problem for H1CTL+ is complete for triply\nexponential time, this remains true for quite weak fragments and quite strong\nextensions of the logic."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-03816-7_37", 
    "link": "http://arxiv.org/pdf/0906.2866v1", 
    "title": "Predicate Transformers, (co)Monads and Resolutions", 
    "arxiv-id": "0906.2866v1", 
    "author": "Pierre Hyvernat", 
    "publish": "2009-06-16T08:33:18Z", 
    "summary": "This short note contains random thoughts about a factorization theorem for\nclosure/interior operators on a powerset which is reminiscent to the notion of\nresolution for a monad/comonad. The question originated from formal topology\nbut is interesting in itself. The result holds constructively (even if it\nclassically has several variations); but usually not predicatively (in the\nsense that the interpolant will no be given by a set). For those not familiar\nwith predicativity issues, we look at a ``classical'' version where we bound\nthe size of the interpolant."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.1.12", 
    "link": "http://arxiv.org/pdf/0906.3257v1", 
    "title": "Busy beavers gone wild", 
    "arxiv-id": "0906.3257v1", 
    "author": "Gr\u00e9gory Lafitte", 
    "publish": "2009-06-17T17:19:05Z", 
    "summary": "We show some incompleteness results a la Chaitin using the busy beaver\nfunctions. Then, with the help of ordinal logics, we show how to obtain a\ntheory in which the values of the busy beaver functions can be provably\nestablished and use this to reveal a structure on the provability of the values\nof these functions."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.1.12", 
    "link": "http://arxiv.org/pdf/0906.3994v1", 
    "title": "Quantitative testing semantics for non-interleaving", 
    "arxiv-id": "0906.3994v1", 
    "author": "Emmanuel Beffara", 
    "publish": "2009-06-22T13:02:27Z", 
    "summary": "This paper presents a non-interleaving denotational semantics for the\n?-calculus. The basic idea is to define a notion of test where the outcome is\nnot only whether a given process passes a given test, but also in how many\ndifferent ways it can pass it. More abstractly, the set of possible outcomes\nfor tests forms a semiring, and the set of process interpretations appears as a\nmodule over this semiring, in which basic syntactic constructs are affine\noperators. This notion of test leads to a trace semantics in which traces are\npartial orders, in the style of Mazurkiewicz traces, extended with readiness\ninformation. Our construction has standard may- and must-testing as special\ncases."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.1.12", 
    "link": "http://arxiv.org/pdf/0906.4173v1", 
    "title": "On the relation between size-based termination and semantic labelling", 
    "arxiv-id": "0906.4173v1", 
    "author": "Cody Roux", 
    "publish": "2009-06-23T06:28:55Z", 
    "summary": "We investigate the relationship between two independently developed\ntermination techniques. On the one hand, sized-types based termination (SBT)\nuses types annotated with size expressions and Girard's reducibility\ncandidates, and applies on systems using constructor matching only. On the\nother hand, semantic labelling transforms a rewrite system by annotating each\nfunction symbol with the semantics of its arguments, and applies to any rewrite\nsystem. First, we introduce a simplified version of SBT for the simply-typed\nlambda-calculus. Then, we give new proofs of the correctness of SBT using\nsemantic labelling, both in the first and in the higher-order case. As a\nconsequence, we show that SBT can be extended to systems using matching on\ndefined symbols (e.g. associative functions)."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(2:14)2011", 
    "link": "http://arxiv.org/pdf/0906.4315v3", 
    "title": "Knowledge-Based Synthesis of Distributed Systems Using Event Structures", 
    "arxiv-id": "0906.4315v3", 
    "author": "Sabina Petride", 
    "publish": "2009-06-23T17:10:42Z", 
    "summary": "To produce a program guaranteed to satisfy a given specification one can\nsynthesize it from a formal constructive proof that a computation satisfying\nthat specification exists. This process is particularly effective if the\nspecifications are written in a high-level language that makes it easy for\ndesigners to specify their goals. We consider a high-level specification\nlanguage that results from adding knowledge to a fragment of Nuprl specifically\ntailored for specifying distributed protocols, called event theory. We then\nshow how high-level knowledge-based programs can be synthesized from the\nknowledge-based specifications using a proof development system such as Nuprl.\nMethods of Halpern and Zuck then apply to convert these knowledge-based\nprotocols to ordinary protocols. These methods can be expressed as heuristic\ntransformation tactics in Nuprl."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(2:14)2011", 
    "link": "http://arxiv.org/pdf/0906.4492v1", 
    "title": "Efficient Generation of Craig Interpolants in Satisfiability Modulo   Theories", 
    "arxiv-id": "0906.4492v1", 
    "author": "Roberto Sebastiani", 
    "publish": "2009-06-24T14:47:01Z", 
    "summary": "The problem of computing Craig Interpolants has recently received a lot of\ninterest. In this paper, we address the problem of efficient generation of\ninterpolants for some important fragments of first order logic, which are\namenable for effective decision procedures, called Satisfiability Modulo Theory\nsolvers.\n  We make the following contributions.\n  First, we provide interpolation procedures for several basic theories of\ninterest: the theories of linear arithmetic over the rationals, difference\nlogic over rationals and integers, and UTVPI over rationals and integers.\n  Second, we define a novel approach to interpolate combinations of theories,\nthat applies to the Delayed Theory Combination approach.\n  Efficiency is ensured by the fact that the proposed interpolation algorithms\nextend state of the art algorithms for Satisfiability Modulo Theories. Our\nexperimental evaluation shows that the MathSAT SMT solver can produce\ninterpolants with minor overhead in search, and much more efficiently than\nother competitor solvers."
},{
    "category": "cs.LO", 
    "doi": "10.1109/TIME.2011.9", 
    "link": "http://arxiv.org/pdf/0906.4711v4", 
    "title": "On Relaxing Metric Information in Linear Temporal Logic", 
    "arxiv-id": "0906.4711v4", 
    "author": "Paola Spoletini", 
    "publish": "2009-06-25T15:04:50Z", 
    "summary": "Metric LTL formulas rely on the next operator to encode time distances,\nwhereas qualitative LTL formulas use only the until operator. This paper shows\nhow to transform any metric LTL formula M into a qualitative formula Q, such\nthat Q is satisfiable if and only if M is satisfiable over words with\nvariability bounded with respect to the largest distances used in M (i.e.,\noccurrences of next), but the size of Q is independent of such distances.\nBesides the theoretical interest, this result can help simplify the\nverification of systems with time-granularity heterogeneity, where large\ndistances are required to express the coarse-grain dynamics in terms of\nfine-grain time units."
},{
    "category": "cs.LO", 
    "doi": "10.1109/TIME.2011.9", 
    "link": "http://arxiv.org/pdf/0907.0403v1", 
    "title": "Common Knowledge in Interaction Structures", 
    "arxiv-id": "0907.0403v1", 
    "author": "Jonathan A. Zvesper", 
    "publish": "2009-07-02T15:19:22Z", 
    "summary": "We consider two simple variants of a framework for reasoning about knowledge\namongst communicating groups of players. Our goal is to clarify the resulting\nepistemic issues. In particular, we investigate what is the impact of common\nknowledge of the underlying hypergraph connecting the players, and under what\nconditions common knowledge distributes over disjunction. We also obtain two\nversions of the classic result that common knowledge cannot be achieved in the\nabsence of a simultaneous event (here a message sent to the whole group)."
},{
    "category": "cs.LO", 
    "doi": "10.1109/TIME.2011.9", 
    "link": "http://arxiv.org/pdf/0907.1357v1", 
    "title": "Graph Based Reduction of Program Verification Conditions", 
    "arxiv-id": "0907.1357v1", 
    "author": "Nicolas Stouls", 
    "publish": "2009-07-08T08:32:57Z", 
    "summary": "Increasing the automaticity of proofs in deductive verification of C programs\nis a challenging task. When applied to industrial C programs known heuristics\nto generate simpler verification conditions are not efficient enough. This is\nmainly due to their size and a high number of irrelevant hypotheses. This work\npresents a strategy to reduce program verification conditions by selecting\ntheir relevant hypotheses. The relevance of a hypothesis is determined by the\ncombination of a syntactic analysis and two graph traversals. The first graph\nis labeled by constants and the second one by the predicates in the axioms. The\napproach is applied on a benchmark arising in industrial program verification."
},{
    "category": "cs.LO", 
    "doi": "10.1109/TIME.2011.9", 
    "link": "http://arxiv.org/pdf/0907.1540v1", 
    "title": "Testing Probabilistic Processes: Can Random Choices Be Unobservable?", 
    "arxiv-id": "0907.1540v1", 
    "author": "Suzana Andova", 
    "publish": "2009-07-09T13:29:25Z", 
    "summary": "A central paradigm behind process semantics based on observability and\ntesting is that the exact moment of occurring of an internal nondeterministic\nchoice is unobservable. It is natural, therefore, for this property to hold\nwhen the internal choice is quantified with probabilities. However, ever since\nprobabilities have been introduced in process semantics, it has been a\nchallenge to preserve the unobservability of the random choice, while not\nviolating the other laws of process theory and probability theory. This paper\naddresses this problem. It proposes two semantics for processes where the\ninternal nondeterminism has been quantified with probabilities. The first one\nis based on the notion of testing, i.e. interaction between the process and its\nenvironment. The second one, the probabilistic ready trace semantics, is based\non the notion of observability. Both are shown to coincide. They are also\npreserved under the standard operators."
},{
    "category": "cs.LO", 
    "doi": "10.1109/TIME.2011.9", 
    "link": "http://arxiv.org/pdf/0907.3123v1", 
    "title": "Verification of Timed Automata Using Rewrite Rules and Strategies", 
    "arxiv-id": "0907.3123v1", 
    "author": "Claude Kirchner", 
    "publish": "2009-07-17T17:40:04Z", 
    "summary": "ELAN is a powerful language and environment for specifying and prototyping\ndeduction systems in a language based on rewrite rules controlled by\nstrategies. Timed automata is a class of continuous real-time models of\nreactive systems for which efficient model-checking algorithms have been\ndevised. In this paper, we show that these algorithms can very easily be\nprototyped in the ELAN system. This paper argues through this example that\nrewriting based systems relying on rules and strategies are a good framework to\nprototype, study and test rather efficiently symbolic model-checking\nalgorithms, i.e. algorithms which involve combination of graph exploration\nrules, deduction rules, constraint solving techniques and decision procedures."
},{
    "category": "cs.LO", 
    "doi": "10.1109/TIME.2011.9", 
    "link": "http://arxiv.org/pdf/0907.3226v2", 
    "title": "From Causal Semantics To Duration Timed Models", 
    "arxiv-id": "0907.3226v2", 
    "author": "Walid Belkhir", 
    "publish": "2009-07-18T15:27:45Z", 
    "summary": "The interleaving semantics is not compatible with both action refinement and\ndurational actions. Since many true concurrency semantics are congruent w.r.t.\naction refinement, notably the causality and the maximality ones, this has\nchallenged us to study the dense time behavior - where the actions are of\narbitrary fixed duration - within the causality semantics of Da Costa.\n  We extend the causal transition systems with the clocks and the timed\nconstraints, and thus we obtain an over class of timed automata where the\nactions need not to be atomic. We define a real time extension of the formal\ndescription technique CSP, called duration-CSP, by attributing the duration to\nactions. We give the operational timed causal semantics of duration-CSP as well\nas its denotational semantics over the class of timed causal transition\nsystems. Afterwards, we prove that the two semantics are equivalent. Finally we\nextend the duration-CSP language with a refinement operator $\\rho$ - that\nallows to replace an action with a process - and prove that it preserves the\ntimed causal bisimulation."
},{
    "category": "cs.LO", 
    "doi": "10.1109/TIME.2011.9", 
    "link": "http://arxiv.org/pdf/0907.3230v1", 
    "title": "Infinite Oracle Queries in Type-2 Machines (Extended Abstract)", 
    "arxiv-id": "0907.3230v1", 
    "author": "Arno Pauly", 
    "publish": "2009-07-20T15:06:12Z", 
    "summary": "We define Oracle-Type-2-Machine capable of writing infinite oracle queries.\nIn contrast to finite oracle queries, this extends the realm of\noracle-computable functions into the discontinuous realm. Our definition is\nconservative; access to a computable oracle does not increase the computational\npower.\n  Other models of real hypercomputation such as Ziegler's (finitely) revising\ncomputation or Type-2-Nondeterminism are shown to be special cases of\nOracle-Type-2-Machines. Our approach offers an intuitive definition of the\nweakest machine model capable to simulate both Type-2-Machines and BSS\nmachines."
},{
    "category": "cs.LO", 
    "doi": "10.1109/TIME.2011.9", 
    "link": "http://arxiv.org/pdf/0907.3599v1", 
    "title": "Gentzen-Prawitz Natural Deduction as a Teaching Tool", 
    "arxiv-id": "0907.3599v1", 
    "author": "Micha\u00ebl P\u00e9rin", 
    "publish": "2009-07-21T09:58:12Z", 
    "summary": "We report a four-years experiment in teaching reasoning to undergraduate\nstudents, ranging from weak to gifted, using Gentzen-Prawitz's style natural\ndeduction. We argue that this pedagogical approach is a good alternative to the\nuse of Boolean algebra for teaching reasoning, especially for computer\nscientists and formal methods practionners."
},{
    "category": "cs.LO", 
    "doi": "10.1109/TIME.2011.9", 
    "link": "http://arxiv.org/pdf/0907.4531v1", 
    "title": "Clone Theory and Algebraic Logic", 
    "arxiv-id": "0907.4531v1", 
    "author": "Zhaohua Luo", 
    "publish": "2009-07-27T17:36:16Z", 
    "summary": "The concept of a clone is central to many branches of mathematics, such as\nuniversal algebra, algebraic logic, and lambda calculus. Abstractly a clone is\na category with two objects such that one is a countably infinite power of the\nother. Left and right algebras over a clone are covariant and contravariant\nfunctors from the category to that of sets respectively. In this paper we show\nthat first-order logic can be studied effectively using the notions of right\nand left algebras over a clone. It is easy to translate the classical treatment\nof logic into our setting and prove all the fundamental theorems of first-order\ntheory algebraically."
},{
    "category": "cs.LO", 
    "doi": "10.1109/SEFM.2009.16", 
    "link": "http://arxiv.org/pdf/0907.5074v1", 
    "title": "Integrated Modeling and Verification of Real-Time Systems through   Multiple Paradigms", 
    "arxiv-id": "0907.5074v1", 
    "author": "Matteo Rossi", 
    "publish": "2009-07-29T09:21:45Z", 
    "summary": "Complex systems typically have many different parts and facets, with\ndifferent characteristics. In a multi-paradigm approach to modeling, formalisms\nwith different natures are used in combination to describe complementary parts\nand aspects of the system. This can have a beneficial impact on the modeling\nactivity, as different paradigms an be better suited to describe different\naspects of the system. While each paradigm provides a different view on the\nmany facets of the system, it is of paramount importance that a coherent\ncomprehensive model emerges from the combination of the various partial\ndescriptions. In this paper we present a technique to model different aspects\nof the same system with different formalisms, while keeping the various models\ntightly integrated with one another. In addition, our approach leverages the\nflexibility provided by a bounded satisfiability checker to encode the\nverification problem of the integrated model in the propositional\nsatisfiability (SAT) problem; this allows users to carry out formal\nverification activities both on the whole model and on parts thereof. The\neffectiveness of the approach is illustrated through the example of a\nmonitoring system."
},{
    "category": "cs.LO", 
    "doi": "10.1109/SEFM.2009.16", 
    "link": "http://arxiv.org/pdf/0907.5125v1", 
    "title": "Rewrite based Verification of XML Updates", 
    "arxiv-id": "0907.5125v1", 
    "author": "Michael Rusinowitch", 
    "publish": "2009-07-29T13:34:50Z", 
    "summary": "We consider problems of access control for update of XML documents. In the\ncontext of XML programming, types can be viewed as hedge automata, and static\ntype checking amounts to verify that a program always converts valid source\ndocuments into also valid output documents. Given a set of update operations we\nare particularly interested by checking safety properties such as preservation\nof document types along any sequence of updates. We are also interested by the\nrelated policy consistency problem, that is detecting whether a sequence of\nauthorized operations can simulate a forbidden one. We reduce these questions\nto type checking problems, solved by computing variants of hedge automata\ncharacterizing the set of ancestors and descendants of the initial document\ntype for the closure of parameterized rewrite rules."
},{
    "category": "cs.LO", 
    "doi": "10.1109/SEFM.2009.16", 
    "link": "http://arxiv.org/pdf/0908.0494v1", 
    "title": "A Formalization of the Semantics of Functional-Logic Programming in   Isabelle", 
    "arxiv-id": "0908.0494v1", 
    "author": "Juan Rodr\u00edguez Hortal\u00e1", 
    "publish": "2009-08-04T17:01:24Z", 
    "summary": "Modern functional-logic programming languages like Toy or Curry feature\nnon-strict non-deterministic functions that behave under call-time choice\nsemantics. A standard formulation for this semantics is the CRWL logic, that\nspecifies a proof calculus for computing the set of possible results for each\nexpression. In this paper we present a formalization of that calculus in the\nIsabelle/HOL proof assistant. We have proved some basic properties of CRWL:\nclosedness under c-substitutions, polarity and compositionality. We also\ndiscuss some insights that have been gained, such as the fact that left\nlinearity of program rules is not needed for any of these results to hold."
},{
    "category": "cs.LO", 
    "doi": "10.1109/SEFM.2009.16", 
    "link": "http://arxiv.org/pdf/0908.1390v3", 
    "title": "Nominal Abstraction", 
    "arxiv-id": "0908.1390v3", 
    "author": "Gopalan Nadathur", 
    "publish": "2009-08-10T20:36:43Z", 
    "summary": "Recursive relational specifications are commonly used to describe the\ncomputational structure of formal systems. Recent research in proof theory has\nidentified two features that facilitate direct, logic-based reasoning about\nsuch descriptions: the interpretation of atomic judgments through recursive\ndefinitions and an encoding of binding constructs via generic judgments.\nHowever, logics encompassing these two features do not currently allow for the\ndefinition of relations that embody dynamic aspects related to binding, a\ncapability needed in many reasoning tasks. We propose a new relation between\nterms called nominal abstraction as a means for overcoming this deficiency. We\nincorporate nominal abstraction into a rich logic also including definitions,\ngeneric quantification, induction, and co-induction that we then prove to be\nconsistent. We present examples to show that this logic can provide elegant\ntreatments of binding contexts that appear in many proofs, such as those\nestablishing properties of typing calculi and of arbitrarily cascading\nsubstitutions that play a role in reducibility arguments."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(3:10)2009", 
    "link": "http://arxiv.org/pdf/0908.2793v2", 
    "title": "Applications of Metric Coinduction", 
    "arxiv-id": "0908.2793v2", 
    "author": "Nicholas Ruozzi", 
    "publish": "2009-08-19T17:59:03Z", 
    "summary": "Metric coinduction is a form of coinduction that can be used to establish\nproperties of objects constructed as a limit of finite approximations. One can\nprove a coinduction step showing that some property is preserved by one step of\nthe approximation process, then automatically infer by the coinduction\nprinciple that the property holds of the limit object. This can often be used\nto avoid complicated analytic arguments involving limits and convergence,\nreplacing them with simpler algebraic arguments. This paper examines the\napplication of this principle in a variety of areas, including infinite\nstreams, Markov chains, Markov decision processes, and non-well-founded sets.\nThese results point to the usefulness of coinduction as a general proof\ntechnique."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.tcs.2010.12.032", 
    "link": "http://arxiv.org/pdf/0909.0171v2", 
    "title": "Canonical extension and canonicity via DCPO presentations", 
    "arxiv-id": "0909.0171v2", 
    "author": "Jacob Vosmaer", 
    "publish": "2009-09-01T12:49:20Z", 
    "summary": "The canonical extension of a lattice is in an essential way a two-sided\ncompletion. Domain theory, on the contrary, is primarily concerned with\none-sided completeness. In this paper, we show two things. Firstly, that the\ncanonical extension of a lattice can be given an asymmetric description in two\nstages: a free co-directed meet completion, followed by a completion by\n\\emph{selected} directed joins. Secondly, we show that the general techniques\nfor dcpo presentations of dcpo algebras used in the second stage of the\nconstruction immediately give us the well-known canonicity result for bounded\nlattices with operators."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(3:11)2009", 
    "link": "http://arxiv.org/pdf/0909.1198v2", 
    "title": "A rich hierarchy of functionals of finite types", 
    "arxiv-id": "0909.1198v2", 
    "author": "Dag Normann", 
    "publish": "2009-09-07T10:16:20Z", 
    "summary": "We are considering typed hierarchies of total, continuous functionals using\ncomplete, separable metric spaces at the base types. We pay special attention\nto the so called Urysohn space constructed by P. Urysohn. One of the properties\nof the Urysohn space is that every other separable metric space can be\nisometrically embedded into it. We discuss why the Urysohn space may be\nconsidered as the universal model of possibly infinitary outputs of algorithms.\nThe main result is that all our typed hierarchies may be topologically\nembedded, type by type, into the corresponding hierarchy over the Urysohn\nspace. As a preparation for this, we prove an effective density theorem that is\nalso of independent interest."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-15155-2_24", 
    "link": "http://arxiv.org/pdf/0909.1645v3", 
    "title": "Qualitative Analysis of Partially-observable Markov Decision Processes", 
    "arxiv-id": "0909.1645v3", 
    "author": "Thomas A. Henzinger", 
    "publish": "2009-09-09T07:47:28Z", 
    "summary": "We study observation-based strategies for partially-observable Markov\ndecision processes (POMDPs) with omega-regular objectives. An observation-based\nstrategy relies on partial information about the history of a play, namely, on\nthe past sequence of observations. We consider the qualitative analysis\nproblem: given a POMDP with an omega-regular objective, whether there is an\nobservation-based strategy to achieve the objective with probability~1\n(almost-sure winning), or with positive probability (positive winning). Our\nmain results are twofold. First, we present a complete picture of the\ncomputational complexity of the qualitative analysis of POMDP s with parity\nobjectives (a canonical form to express omega-regular objectives) and its\nsubclasses. Our contribution consists in establishing several upper and lower\nbounds that were not known in literature. Second, we present optimal bounds\n(matching upper and lower bounds) on the memory required by pure and randomized\nobservation-based strategies for the qualitative analysis of POMDP s with\nparity objectives and its subclasses."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-15155-2_24", 
    "link": "http://arxiv.org/pdf/0909.1647v1", 
    "title": "Probabilistic Weighted Automata", 
    "arxiv-id": "0909.1647v1", 
    "author": "Thomas A. Henzinger", 
    "publish": "2009-09-09T08:12:39Z", 
    "summary": "Nondeterministic weighted automata are finite automata with numerical weights\non transitions. They define quantitative languages L that assign to each word w\na real number L(w). The value of an infinite word w is computed as the maximal\nvalue of all runs over w, and the value of a run as the maximum, limsup,\nliminf, limit average, or discounted sum of the transition weights. We\nintroduce probabilistic weighted automata, in which the transitions are chosen\nin a randomized (rather than nondeterministic) fashion. Under almost-sure\nsemantics (resp. positive semantics), the value of a word w is the largest real\nv such that the runs over w have value at least v with probability 1 (resp.\npositive probability).\n  We study the classical questions of automata theory for probabilistic\nweighted automata: emptiness and universality, expressiveness, and closure\nunder various operations on languages. For quantitative languages, emptiness\nand universality are defined as whether the value of some (resp. every) word\nexceeds a given threshold. We prove some of these questions to be decidable,\nand others undecidable. Regarding expressive power, we show that probabilities\nallow us to define a wide variety of new classes of quantitative languages,\nexcept for discounted-sum automata, where probabilistic choice is no more\nexpressive than nondeterminism. Finally, we give an almost complete picture of\nthe closure of various classes of probabilistic weighted automata for the\nfollowing pointwise operations on quantitative languages: max, min, sum, and\nnumerical complement."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-15155-2_24", 
    "link": "http://arxiv.org/pdf/0909.4637v1", 
    "title": "A Better Reduction Theorem for Store Buffers", 
    "arxiv-id": "0909.4637v1", 
    "author": "Norbert Schirmer", 
    "publish": "2009-09-25T08:45:19Z", 
    "summary": "When verifying a concurrent program, it is usual to assume that memory is\nsequentially consistent. However, most modern multiprocessors depend on store\nbuffering for efficiency, and provide native sequential consistency only at a\nsubstantial performance penalty. To regain sequential consistency, a programmer\nhas to follow an appropriate programming discipline. However, na\\\"ive\ndisciplines, such as protecting all shared accesses with locks, are not\nflexible enough for building high-performance multiprocessor software.\n  We present a new discipline for concurrent programming under TSO (total store\norder, with store buffer forwarding). It does not depend on concurrency\nprimitives, such as locks. Instead, threads use ghost operations to acquire and\nrelease ownership of memory addresses. A thread can write to an address only if\nno other thread owns it, and can read from an address only if it owns it or it\nis shared and the thread has flushed its store buffer since it last wrote to an\naddress it did not own. This discipline covers both coarse-grained concurrency\n(where data is protected by locks) as well as fine-grained concurrency (where\natomic operations race to memory).\n  We formalize this discipline in Isabelle/HOL, and prove that if every\nexecution of a program in a system without store buffers follows the\ndiscipline, then every execution of the program with store buffers is\nsequentially consistent. Thus, we can show sequential consistency under TSO by\nordinary assertional reasoning about the program, without having to consider\nstore buffers at all."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-15155-2_24", 
    "link": "http://arxiv.org/pdf/0909.5045v1", 
    "title": "Deriving SN from PSN: a general proof technique", 
    "arxiv-id": "0909.5045v1", 
    "author": "Emmanuel Polonowski", 
    "publish": "2009-09-28T09:26:11Z", 
    "summary": "In the framework of explicit substitutions there is two termination\nproperties: preservation of strong normalization (PSN), and strong\nnormalization (SN). Since there are not easily proved, only one of them is\nusually established (and sometimes none). We propose here a connection between\nthem which helps to get SN when one already has PSN. For this purpose, we\nformalize a general proof technique of SN which consists in expanding\nsubstitutions into \"pure\" lambda-terms and to inherit SN of the whole calculus\nby SN of the \"pure\" calculus and by PSN. We apply it successfully to a large\nset of calculi with explicit substitutions, allowing us to establish SN, or, at\nleast, to trace back the failure of SN to that of PSN."
},{
    "category": "cs.LO", 
    "doi": "10.1109/ASICON.2009.5351239", 
    "link": "http://arxiv.org/pdf/0909.5393v1", 
    "title": "Formal Verification of Full-Wave Rectifier: A Case Study", 
    "arxiv-id": "0909.5393v1", 
    "author": "H S Jamadagni", 
    "publish": "2009-09-29T17:37:34Z", 
    "summary": "We present a case study of formal verification of full-wave rectifier for\nanalog and mixed signal designs. We have used the Checkmate tool from CMU [1],\nwhich is a public domain formal verification tool for hybrid systems. Due to\nthe restriction imposed by Checkmate it necessitates to make the changes in the\nCheckmate implementation to implement the complex and non-linear system.\nFull-wave rectifier has been implemented by using the Checkmate custom blocks\nand the Simulink blocks from MATLAB from Math works. After establishing the\nrequired changes in the Checkmate implementation we are able to efficiently\nverify the safety properties of the full-wave rectifier."
},{
    "category": "cs.LO", 
    "doi": "10.1109/ASICON.2009.5351239", 
    "link": "http://arxiv.org/pdf/0910.0868v1", 
    "title": "Design of asynchronous supervisors", 
    "arxiv-id": "0910.0868v1", 
    "author": "Jos Baeten", 
    "publish": "2009-10-05T21:55:09Z", 
    "summary": "One of the main drawbacks while implementing the interaction between a plant\nand a supervisor, synthesised by the supervisory control theory of\n\\citeauthor{RW:1987}, is the inexact synchronisation. \\citeauthor{balemiphdt}\nwas the first to consider this problem, and the solutions given in his PhD\nthesis were in the domain of automata theory. Our goal is to address the issue\nof inexact synchronisation in a process algebra setting, because we get\nconcepts like modularity and abstraction for free, which are useful to further\nanalyze the synthesised system. In this paper, we propose four methods to check\na closed loop system in an asynchronous setting such that it is branching\nbisimilar to the modified (asynchronous) closed loop system. We modify a given\nclosed loop system by introducing buffers either in the plant models, the\nsupervisor models, or the output channels of both supervisor and plant models,\nor in the input channels of both supervisor and plant models. A notion of\ndesynchronisable closed loop system is introduced, which is a class of\nsynchronous closed loop systems such that they are branching bisimilar to their\ncorresponding asynchronous versions. Finally we study different case studies in\nan asynchronous setting and then try to summarise the observations (or\nconditions) which will be helpful in order to formulate a theory of\ndesynchronisable closed loop systems."
},{
    "category": "cs.LO", 
    "doi": "10.1109/ASICON.2009.5351239", 
    "link": "http://arxiv.org/pdf/0910.1020v1", 
    "title": "A Formally Specified Type System and Operational Semantics for   Higher-Order Procedural Variables", 
    "arxiv-id": "0910.1020v1", 
    "author": "Emmanuel Polonowski", 
    "publish": "2009-10-06T14:36:18Z", 
    "summary": "We formally specified the type system and operational semantics of LOOPw with\nOtt and Isabelle/HOL proof assistant. Moreover, both the type system and the\nsemantics of LOOPw have been tested using Isabelle/HOL program extraction\nfacility for inductively defined relations. In particular, the program that\ncomputes the Ackermann function type checks and behaves as expected. The main\ndifference (apart from the choice of an Ada-like concrete syntax) with LOOPw\ncomes from the treatment of parameter passing. Indeed, since Ott does not\ncurrently fully support alpha-conversion, we rephrased the operational\nsemantics with explicit aliasing in order to implement the out parameter\npassing mode."
},{
    "category": "cs.LO", 
    "doi": "10.1109/ASICON.2009.5351239", 
    "link": "http://arxiv.org/pdf/0910.1763v1", 
    "title": "A zonotopic framework for functional abstractions", 
    "arxiv-id": "0910.1763v1", 
    "author": "Sylvie Putot", 
    "publish": "2009-10-09T14:43:30Z", 
    "summary": "This article formalizes an abstraction of input/output relations, based on\nparameterized zonotopes, which we call affine sets. We describe the abstract\ntransfer functions and prove their correctness, which allows the generation of\naccurate numerical invariants. Other applications range from compositional\nreasoning to proofs of user-defined complex invariants and test case\ngeneration."
},{
    "category": "cs.LO", 
    "doi": "10.1109/ASICON.2009.5351239", 
    "link": "http://arxiv.org/pdf/0910.3383v4", 
    "title": "Least and Greatest Fixed Points in Linear Logic", 
    "arxiv-id": "0910.3383v4", 
    "author": "David Baelde", 
    "publish": "2009-10-19T19:56:36Z", 
    "summary": "The first-order theory of MALL (multiplicative, additive linear logic) over\nonly equalities is an interesting but weak logic since it cannot capture\nunbounded (infinite) behavior. Instead of accounting for unbounded behavior via\nthe addition of the exponentials (! and ?), we add least and greatest fixed\npoint operators. The resulting logic, which we call muMALL, satisfies two\nfundamental proof theoretic properties: we establish weak normalization for it,\nand we design a focused proof system that we prove complete. That second result\nprovides a strong normal form for cut-free proof structures that can be used,\nfor example, to help automate proof search. We show how these foundations can\nbe applied to intuitionistic logic."
},{
    "category": "cs.LO", 
    "doi": "10.1109/ASICON.2009.5351239", 
    "link": "http://arxiv.org/pdf/0910.3766v1", 
    "title": "Comparison of Algorithms for Checking Emptiness on Buechi Automata", 
    "arxiv-id": "0910.3766v1", 
    "author": "Stefan Schwoon", 
    "publish": "2009-10-20T11:25:20Z", 
    "summary": "We re-investigate the problem of LTL model-checking for finite-state systems.\nTypical solutions, like in Spin, work on the fly, reducing the problem to\nBuechi emptiness. This can be done in linear time, and a variety of algorithms\nwith this property exist. Nonetheless, subtle design decisions can make a great\ndifference to their actual performance in practice, especially when used\non-the-fly. We compare a number of algorithms experimentally on a large\nbenchmark suite, measure their actual run-time performance, and propose\nimprovements. Compared with the algorithm implemented in Spin, our best\nalgorithm is faster by about 33 % on average. We therefore recommend that, for\non-the-fly explicit-state model checking, nested DFS should be replaced by\nbetter solutions."
},{
    "category": "cs.LO", 
    "doi": "10.1109/ASICON.2009.5351239", 
    "link": "http://arxiv.org/pdf/0910.4500v2", 
    "title": "A History of Until", 
    "arxiv-id": "0910.4500v2", 
    "author": "Marco Volpe", 
    "publish": "2009-10-23T15:31:57Z", 
    "summary": "Until is a notoriously difficult temporal operator as it is both existential\nand universal at the same time: A until B holds at the current time instant w\niff either B holds at w or there exists a time instant w' in the future at\nwhich B holds and such that A holds in all the time instants between the\ncurrent one and w'. This \"ambivalent\" nature poses a significant challenge when\nattempting to give deduction rules for until. In this paper, in contrast, we\nmake explicit this duality of until to provide well-behaved natural deduction\nrules for linear-time logics by introducing a new temporal operator that allows\nus to formalize the \"history\" of until, i.e., the \"internal\" universal\nquantification over the time instants between the current one and w'. This\napproach provides the basis for formalizing deduction systems for temporal\nlogics endowed with the until operator. For concreteness, we give here a\nlabeled natural deduction system for a linear-time logic endowed with the new\noperator and show that, via a proper translation, such a system is also sound\nand complete with respect to the linear temporal logic LTL with until."
},{
    "category": "cs.LO", 
    "doi": "10.1109/ASICON.2009.5351239", 
    "link": "http://arxiv.org/pdf/0910.4565v2", 
    "title": "Classification with Tarskian system executions (Bakery Algorithms as an   example)", 
    "arxiv-id": "0910.4565v2", 
    "author": "Uri Abraham", 
    "publish": "2009-10-23T18:39:49Z", 
    "summary": "We argue that predicate languages and their Tarskian structures have an\nimportant place for the study of concurrency. The argument in our paper is\nbased on an example: we show that two seemingly dissimilar algorithms have a\ncommon set of high-level properties, which reveals their affinity. The\nalgorithms are a variant of Lamport's Bakery Algorithm and the Ricart and\nAgrawala algorithm. They seem different because one uses shared memory and the\nother message passing for communication. Yet it is intuitively obvious that\nthey are in some sense very similar, and they belong to the same \"family of\nBakery Algorithms\". The aim of this paper is to express in a formal way this\nintuition that classifies the two algorithms together. For this aim of\nexpressing the abstract high level properties that are shared by the two\nalgorithms we use predicate languages and their Taskian structures. We find a\nset of properties expressed in quantification language which are satisfied by\nevery Tarskian system execution that models a run by either one of the\nprotocols, and which is strong enough to ensure that the mutual exclusion\nproperty holds in these runs."
},{
    "category": "cs.LO", 
    "doi": "10.1109/ASICON.2009.5351239", 
    "link": "http://arxiv.org/pdf/0910.4932v2", 
    "title": "Algorithmic metatheorems for decidable LTL model checking over infinite   systems", 
    "arxiv-id": "0910.4932v2", 
    "author": "Leonid Libkin", 
    "publish": "2009-10-26T19:56:07Z", 
    "summary": "By algorithmic metatheorems for a model checking problem P over\ninfinite-state systems we mean generic results that can be used to infer\ndecidability (possibly complexity) of P not only over a specific class of\ninfinite systems, but over a large family of classes of infinite systems. Such\nresults normally start with a powerful formalism of infinite-state systems,\nover which P is undecidable, and assert decidability when is restricted by\nmeans of an extra \"semantic condition\" C. We prove various algorithmic\nmetatheorems for the problems of model checking LTL and its two common\nfragments LTL(Fs,Gs) and LTLdet over the expressive class of word/tree\nautomatic transition systems, which are generated by synchronized finite-state\ntransducers operating on finite words and trees. We present numerous\napplications, where we derive (in a unified manner) many known and previously\nunknown decidability and complexity results of model checking LTL and its\nfragments over specific classes of infinite-state systems including pushdown\nsystems; prefix-recognizable systems; reversal-bounded counter systems with\ndiscrete clocks and a free counter; concurrent pushdown systems with a bounded\nnumber of context-switches; various subclasses of Petri nets; weakly extended\nPA-processes; and weakly extended ground-tree rewrite systems. In all cases,we\nare able to derive optimal (or near optimal) complexity. Finally, we pinpoint\nthe exact locations in the arithmetic and analytic hierarchies of the problem\nof checking a relevant semantic condition and the LTL model checking problems\nover all word/tree automatic systems."
},{
    "category": "cs.LO", 
    "doi": "10.1109/ASICON.2009.5351239", 
    "link": "http://arxiv.org/pdf/0910.5099v1", 
    "title": "Compiling and securing cryptographic protocols", 
    "arxiv-id": "0910.5099v1", 
    "author": "Michael Rusinowitch", 
    "publish": "2009-10-27T11:46:50Z", 
    "summary": "Protocol narrations are widely used in security as semi-formal notations to\nspecify conversations between roles. We define a translation from a protocol\nnarration to the sequences of operations to be performed by each role. Unlike\nprevious works, we reduce this compilation process to well-known decision\nproblems in formal protocol analysis. This allows one to define a natural\nnotion of prudent translation and to reuse many known results from the\nliterature in order to cover more crypto-primitives. In particular this work is\nthe first one to show how to compile protocols parameterised by the properties\nof the available operations."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(1:2)2010", 
    "link": "http://arxiv.org/pdf/0910.5399v2", 
    "title": "A Graph Model for Imperative Computation", 
    "arxiv-id": "0910.5399v2", 
    "author": "Guy McCusker", 
    "publish": "2009-10-28T15:09:12Z", 
    "summary": "Scott's graph model is a lambda-algebra based on the observation that\ncontinuous endofunctions on the lattice of sets of natural numbers can be\nrepresented via their graphs. A graph is a relation mapping finite sets of\ninput values to output values.\n  We consider a similar model based on relations whose input values are finite\nsequences rather than sets. This alteration means that we are taking into\naccount the order in which observations are made. This new notion of graph\ngives rise to a model of affine lambda-calculus that admits an interpretation\nof imperative constructs including variable assignment, dereferencing and\nallocation.\n  Extending this untyped model, we construct a category that provides a model\nof typed higher-order imperative computation with an affine type system. An\nappropriate language of this kind is Reynolds's Syntactic Control of\nInterference. Our model turns out to be fully abstract for this language. At a\nconcrete level, it is the same as Reddy's object spaces model, which was the\nfirst \"state-free\" model of a higher-order imperative programming language and\nan important precursor of games models. The graph model can therefore be seen\nas a universal domain for Reddy's model."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(1:2)2010", 
    "link": "http://arxiv.org/pdf/0911.0105v1", 
    "title": "Functions Definable by Numerical Set-Expressions", 
    "arxiv-id": "0911.0105v1", 
    "author": "Ivo D\u00fcntsch", 
    "publish": "2009-10-31T23:17:49Z", 
    "summary": "A \"numerical set-expression\" is a term specifying a cascade of arithmetic and\nlogical operations to be performed on sets of non-negative integers. If these\noperations are confined to the usual Boolean operations together with the\nresult of lifting addition to the level of sets, we speak of \"additive\ncircuits\". If they are confined to the usual Boolean operations together with\nthe result of lifting addition and multiplication to the level of sets, we\nspeak of \"arithmetic circuits\". In this paper, we investigate the definability\nof sets and functions by means of additive and arithmetic circuits,\noccasionally augmented with additional operations."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(1:2)2010", 
    "link": "http://arxiv.org/pdf/0911.1009v1", 
    "title": "Unique Normal Forms in Infinitary Weakly Orthogonal Term Rewriting", 
    "arxiv-id": "0911.1009v1", 
    "author": "Jan Willem Klop", 
    "publish": "2009-11-05T10:59:16Z", 
    "summary": "The theory of finite and infinitary term rewriting is extensively developed\nfor orthogonal rewrite systems, but to a lesser degree for weakly orthogonal\nrewrite systems. In this note we present some contributions to the latter case\nof weak orthogonality, where critial pairs are admitted provided they are\ntrivial.\n  We start with a refinement of the by now classical Compression Lemma, as a\ntool for establishing infinitary confluence, and hence the property of unique\ninfinitary normal forms, for the case of weakly orthogonal TRSs that do not\ncontain collapsing rewrite rules.\n  That this restriction of collapse-freeness is crucial, is shown in a\nelaboration of a simple TRS which is weakly orthogonal, but has two collapsing\nrules. It turns out that all the usual theory breaks down dramatically.\n  We conclude with establishing a positive fact: the diamond property for\ninfinitary developments for weakly orthogonal TRSs, by means of a detailed\nanalysis initiated by van Oostrom for the finite case."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.8.1", 
    "link": "http://arxiv.org/pdf/0911.1862v1", 
    "title": "Characteristic Formulae for Fixed-Point Semantics: A General Framework", 
    "arxiv-id": "0911.1862v1", 
    "author": "Joshua Sack", 
    "publish": "2009-11-10T09:14:55Z", 
    "summary": "The literature on concurrency theory offers a wealth of examples of\ncharacteristic-formula constructions for various behavioural relations over\nfinite labelled transition systems and Kripke structures that are defined in\nterms of fixed points of suitable functions. Such constructions and their\nproofs of correctness have been developed independently, but have a common\nunderlying structure. This study provides a general view of characteristic\nformulae that are expressed in terms of logics with a facility for the\nrecursive definition of formulae. It is shown how several examples of\ncharacteristic-formula constructions from the literature can be recovered as\ninstances of the proposed general framework, and how the framework can be used\nto yield novel constructions."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.8.4", 
    "link": "http://arxiv.org/pdf/0911.2035v1", 
    "title": "Modal Logic and the Approximation Induction Principle", 
    "arxiv-id": "0911.2035v1", 
    "author": "Wan Fokkink", 
    "publish": "2009-11-11T00:57:55Z", 
    "summary": "We prove a compactness theorem in the context of Hennessy-Milner logic. It is\nused to derive a sufficient condition on modal characterizations for the\nApproximation Induction Principle to be sound modulo the corresponding process\nequivalence. We show that this condition is necessary when the equivalence in\nquestion is compositional with respect to the projection operators."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.9.2", 
    "link": "http://arxiv.org/pdf/0911.2319v1", 
    "title": "Orthomodular Lattices Induced by the Concurrency Relation", 
    "arxiv-id": "0911.2319v1", 
    "author": "Stefania Rombol\u00e0", 
    "publish": "2009-11-12T08:36:43Z", 
    "summary": "We apply to locally finite partially ordered sets a construction which\nassociates a complete lattice to a given poset; the elements of the lattice are\nthe closed subsets of a closure operator, defined starting from the concurrency\nrelation. We show that, if the partially ordered set satisfies a property of\nlocal density, i.e.: N-density, then the associated lattice is also\northomodular. We then consider occurrence nets, introduced by C.A. Petri as\nmodels of concurrent computations, and define a family of subsets of the\nelements of an occurrence net; we call those subsets \"causally closed\" because\nthey can be seen as subprocesses of the whole net which are, intuitively,\nclosed with respect to the forward and backward local state changes. We show\nthat, when the net is K-dense, the causally closed sets coincide with the\nclosed sets induced by the closure operator defined starting from the\nconcurrency relation. K-density is a property of partially ordered sets\nintroduced by Petri, on the basis of former axiomatizations of special\nrelativity theory."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.8.6", 
    "link": "http://arxiv.org/pdf/0911.2760v1", 
    "title": "Robustness of a bisimulation-type faster-than preorder", 
    "arxiv-id": "0911.2760v1", 
    "author": "Walter Vogler", 
    "publish": "2009-11-15T09:26:28Z", 
    "summary": "TACS is an extension of CCS where upper time bounds for delays can be\nspecified. Luettgen and Vogler defined three variants of bismulation-type\nfaster-than relations and showed that they all three lead to the same preorder,\ndemonstrating the robustness of their approach. In the present paper, the\noperational semantics of TACS is extended; it is shown that two of the variants\nstill give the same preorder as before, underlining robustness. An explanation\nis given why this result fails for the third variant. It is also shown that\nanother variant, which mixes old and new operational semantics, can lead to\nsmaller relations that prove the same preorder."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.8.6", 
    "link": "http://arxiv.org/pdf/0911.2785v1", 
    "title": "NP Datalog: a Logic Language for Expressing NP Search and Optimization   Problems", 
    "arxiv-id": "0911.2785v1", 
    "author": "Ester Zumpano", 
    "publish": "2009-11-14T17:20:30Z", 
    "summary": "This paper presents a logic language for expressing NP search and\noptimization problems. Specifically, first a language obtained by extending\n(positive) Datalog with intuitive and efficient constructs (namely, stratified\nnegation, constraints and exclusive disjunction) is introduced. Next, a further\nrestricted language only using a restricted form of disjunction to define\n(non-deterministically) subsets (or partitions) of relations is investigated.\nThis language, called NP Datalog, captures the power of Datalog with\nunstratified negation in expressing search and optimization problems. A system\nprototype implementing NP Datalog is presented. The system translates NP\nDatalog queries into OPL programs which are executed by the ILOG OPL\nDevelopment Studio. Our proposal combines easy formulation of problems,\nexpressed by means of a declarative logic language, with the efficiency of the\nILOG System. Several experiments show the effectiveness of this approach."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.8", 
    "link": "http://arxiv.org/pdf/0911.3189v1", 
    "title": "Proceedings 16th International Workshop on Expressiveness in Concurrency", 
    "arxiv-id": "0911.3189v1", 
    "author": "Daniele Gorla", 
    "publish": "2009-11-17T00:35:52Z", 
    "summary": "This volume contains the proceedings of the 16th International Workshop on\nExpressiveness in Concurrency (EXPRESS'09), which took place on 5th September\n2009 in Bologna, co-located with CONCUR'09. The EXPRESS workshop series aim at\nbringing together researchers who are interested in the expressiveness and\ncomparison of formal models that broadly relate to concurrency. In particular,\nthis also includes emergent fields such as logic and interaction,\ngame-theoretic models, and service-oriented computing."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.8", 
    "link": "http://arxiv.org/pdf/0911.3299v1", 
    "title": "Some Models and Tools for Open Systems", 
    "arxiv-id": "0911.3299v1", 
    "author": "Marco Faella", 
    "publish": "2009-11-17T13:21:31Z", 
    "summary": "In computer science, there is a distinction between closed systems, whose\nbehavior is totally determined in advance, and open systems, that are systems\nmaintaining a constant interaction with an unspecified environment. Closed\nsystems are naturally modeled by transitions systems. Open systems have been\nmodeled in various ways, including process algebras, I/O automata, ``modules'',\nand interfaces. Games provide a uniform setting in which all these models can\nbe cast and compared. In this paper, we discuss the features and costs related\nto the game-based approach to open systems, referring to some of the existing\nmodels. Finally, we describe a new model of interface, called sociable\ninterface, which is geared towards easier specification, improved reusability\nof models, and efficient symbolic implementation."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.10.1", 
    "link": "http://arxiv.org/pdf/0911.3405v1", 
    "title": "Dense-choice Counter Machines revisited", 
    "arxiv-id": "0911.3405v1", 
    "author": "Pierluigi San Pietro", 
    "publish": "2009-11-17T23:40:50Z", 
    "summary": "This paper clarifies the picture about Dense-choice Counter Machines, which\nhave been less studied than (discrete) Counter Machines. We revisit the\ndefinition of \"Dense Counter Machines\" so that it now extends (discrete)\nCounter Machines, and we provide new undecidability and decidability results.\nUsing the first-order additive mixed theory of reals and integers, we give a\nlogical characterization of the sets of configurations reachable by\nreversal-bounded Dense-choice Counter Machines."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.10.1", 
    "link": "http://arxiv.org/pdf/0911.3786v3", 
    "title": "Graph rewriting with polarized cloning", 
    "arxiv-id": "0911.3786v3", 
    "author": "Fr\u00e9d\u00e9ric Prost", 
    "publish": "2009-11-19T12:54:50Z", 
    "summary": "We tackle the problem of graph transformation with a particular focus on node\ncloning. We propose a new approach to graph rewriting where nodes can be cloned\nzero, one or more times. A node can be cloned together with all its incident\nedges, with only its outgoing edges, with only its incoming edges or with none\nof its incident edges. We thus subsume previous works such as the\nsesqui-pushout, the heterogeneous pushout and the adaptive star grammars\napproaches. A rewrite rule is defined as a span where the right-hand and\nleft-hand sides are graphs while the interface is a polarized graph. A\npolarized graph is a graph endowed with some annotations on nodes. The way a\nnode is cloned is indicated by its polarization annotation. We use these\nannotations for designing graph transformation with polarized cloning. We show\nhow a clone of a node can be built according to the different possible\npolarizations and define a rewrite step as a final pullback complement followed\nby a pushout. This is called the polarized sesqui-pushout approach. We also\nprovide an algorithmic presentation of the proposed graph transformation with\npolarized cloning."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.10.1", 
    "link": "http://arxiv.org/pdf/0911.3799v3", 
    "title": "Capturing Polynomial Time on Interval Graphs", 
    "arxiv-id": "0911.3799v3", 
    "author": "Bastian Laubner", 
    "publish": "2009-11-19T14:29:45Z", 
    "summary": "We prove a characterization of all polynomial-time computable queries on the\nclass of interval graphs by sentences of fixed-point logic with counting. More\nprecisely, it is shown that on the class of unordered interval graphs, any\nquery is polynomial-time computable if and only if it is definable in\nfixed-point logic with counting. This result is one of the first establishing\nthe capturing of polynomial time on a graph class which is defined by forbidden\ninduced subgraphs. For this, we define a canonical form of interval graphs\nusing a type of modular decomposition, which is different from the method of\ntree decomposition that is used in most known capturing results for other graph\nclasses, specifically those defined by forbidden minors. The method might also\nbe of independent interest for its conceptual simplicity. Furthermore, it is\nshown that fixed-point logic with counting is not expressive enough to capture\npolynomial time on the classes of chordal graphs or incomparability graphs."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.10.1", 
    "link": "http://arxiv.org/pdf/0911.4792v1", 
    "title": "Covering of ordinals", 
    "arxiv-id": "0911.4792v1", 
    "author": "Laurent Braud", 
    "publish": "2009-11-25T10:43:38Z", 
    "summary": "The paper focuses on the structure of fundamental sequences of ordinals\nsmaller than $\\epsilon_0$. A first result is the construction of a monadic\nsecond-order formula identifying a given structure, whereas such a formula\ncannot exist for ordinals themselves. The structures are precisely classified\nin the pushdown hierarchy. Ordinals are also located in the hierarchy, and a\ndirect presentation is given."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.10.1", 
    "link": "http://arxiv.org/pdf/0911.5246v2", 
    "title": "Complex Algebras of Arithmetic", 
    "arxiv-id": "0911.5246v2", 
    "author": "Ian Pratt-Hartmann", 
    "publish": "2009-11-27T11:43:04Z", 
    "summary": "An 'arithmetic circuit' is a labeled, acyclic directed graph specifying a\nsequence of arithmetic and logical operations to be performed on sets of\nnatural numbers. Arithmetic circuits can also be viewed as the elements of the\nsmallest subalgebra of the complex algebra of the semiring of natural numbers.\nIn the present paper, we investigate the algebraic structure of complex\nalgebras of natural numbers, and make some observations regarding the\ncomplexity of various theories of such algebras."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.12.2", 
    "link": "http://arxiv.org/pdf/0911.5445v1", 
    "title": "Coordination via Interaction Constraints I: Local Logic", 
    "arxiv-id": "0911.5445v1", 
    "author": "Jos\u00e9 Proen\u00e7a", 
    "publish": "2009-11-29T00:22:21Z", 
    "summary": "Wegner describes coordination as constrained interaction. We take this\napproach literally and define a coordination model based on interaction\nconstraints and partial, iterative and interactive constraint satisfaction. Our\nmodel captures behaviour described in terms of synchronisation and data flow\nconstraints, plus various modes of interaction with the outside world provided\nby external constraint symbols, on-the-fly constraint generation, and\ncoordination variables. Underlying our approach is an engine performing\n(partial) constraint satisfaction of the sets of constraints. Our model extends\nprevious work on three counts: firstly, a more advanced notion of external\ninteraction is offered; secondly, our approach enables local satisfaction of\nconstraints with appropriate partial solutions, avoiding global synchronisation\nover the entire constraints set; and, as a consequence, constraint satisfaction\ncan finally occur concurrently, and multiple parts of a set of constraints can\nbe solved and interact with the outside world in an asynchronous manner, unless\nsynchronisation is required by the constraints. This paper describes the\nunderlying logic, which enables a notion of local solution, and relates this\nlogic to the more global approach of our previous work based on classical\nlogic."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.12.4", 
    "link": "http://arxiv.org/pdf/0911.5447v1", 
    "title": "Integrated Structure and Semantics for Reo Connectors and Petri Nets", 
    "arxiv-id": "0911.5447v1", 
    "author": "Christian Krause", 
    "publish": "2009-11-29T00:27:28Z", 
    "summary": "In this paper, we present an integrated structural and behavioral model of\nReo connectors and Petri nets, allowing a direct comparison of the two\nconcurrency models. For this purpose, we introduce a notion of connectors which\nconsist of a number of interconnected, user-defined primitives with fixed\nbehavior. While the structure of connectors resembles hypergraphs, their\nsemantics is given in terms of so-called port automata. We define both models\nin a categorical setting where composition operations can be elegantly defined\nand integrated. Specifically, we formalize structural gluings of connectors as\npushouts, and joins of port automata as pullbacks. We then define a semantical\nfunctor from the connector to the port automata category which preserves this\ncomposition. We further show how to encode Reo connectors and Petri nets into\nthis model and indicate applications to dynamic reconfigurations modeled using\ndouble pushout graph transformation."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.12.7", 
    "link": "http://arxiv.org/pdf/0911.5525v1", 
    "title": "Towards an embedding of Graph Transformation in Intuitionistic Linear   Logic", 
    "arxiv-id": "0911.5525v1", 
    "author": "Reiko Heckel", 
    "publish": "2009-11-29T23:14:32Z", 
    "summary": "Linear logics have been shown to be able to embed both rewriting-based\napproaches and process calculi in a single, declarative framework. In this\npaper we are exploring the embedding of double-pushout graph transformations\ninto quantified linear logic, leading to a Curry-Howard style isomorphism\nbetween graphs and transformations on one hand, formulas and proof terms on the\nother. With linear implication representing rules and reachability of graphs,\nand the tensor modelling parallel composition of graphs and transformations, we\nobtain a language able to encode graph transformation systems and their\ncomputations as well as reason about their properties."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1838552.1838560", 
    "link": "http://arxiv.org/pdf/0911.5642v2", 
    "title": "A Theory of Sampling for Continuous-time Metric Temporal Logic", 
    "arxiv-id": "0911.5642v2", 
    "author": "Matteo Rossi", 
    "publish": "2009-11-30T13:51:26Z", 
    "summary": "This paper revisits the classical notion of sampling in the setting of\nreal-time temporal logics for the modeling and analysis of systems. The\nrelationship between the satisfiability of Metric Temporal Logic (MTL) formulas\nover continuous-time models and over discrete-time models is studied. It is\nshown to what extent discrete-time sequences obtained by sampling\ncontinuous-time signals capture the semantics of MTL formulas over the two time\ndomains. The main results apply to \"flat\" formulas that do not nest temporal\noperators and can be applied to the problem of reducing the verification\nproblem for MTL over continuous-time models to the same problem over\ndiscrete-time, resulting in an automated partial practically-efficient\ndiscretization technique."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1838552.1838560", 
    "link": "http://arxiv.org/pdf/0912.0228v3", 
    "title": "Cantor's Problem", 
    "arxiv-id": "0912.0228v3", 
    "author": "Charles Sauerbier", 
    "publish": "2009-12-01T18:40:19Z", 
    "summary": "In 1891 a paper by Georg Cantor was published in which he addressed the\nrelative cardinality of two sets, the set of integers and the set of real\nnumbers, in effort to demonstrate that the two sets were of unequal\ncardinality. This paper offers a contrary conclusion to Cantor's argument,\ntogether with implication of such to the theory of computation."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1838552.1838560", 
    "link": "http://arxiv.org/pdf/0912.0419v1", 
    "title": "An affine-intuitionistic system of types and effects: confluence and   termination", 
    "arxiv-id": "0912.0419v1", 
    "author": "Antoine Madet", 
    "publish": "2009-12-02T12:55:11Z", 
    "summary": "We present an affine-intuitionistic system of types and effects which can be\nregarded as an extension of Barber-Plotkin Dual Intuitionistic Linear Logic to\nmulti-threaded programs with effects. In the system, dynamically generated\nvalues such as references or channels are abstracted into a finite set of\nregions. We introduce a discipline of region usage that entails the confluence\n(and hence determinacy) of the typable programs. Further, we show that a\ndiscipline of region stratification guarantees termination."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(2:1)2010", 
    "link": "http://arxiv.org/pdf/0912.0931v3", 
    "title": "Orthomodular lattices, Foulis Semigroups and Dagger Kernel Categories", 
    "arxiv-id": "0912.0931v3", 
    "author": "Bart Jacobs", 
    "publish": "2009-12-04T20:36:49Z", 
    "summary": "This paper is a sequel to arXiv:0902.2355 and continues the study of quantum\nlogic via dagger kernel categories. It develops the relation between these\ncategories and both orthomodular lattices and Foulis semigroups. The relation\nbetween the latter two notions has been uncovered in the 1960s. The current\ncategorical perspective gives a broader context and reconstructs this\nrelationship between orthomodular lattices and Foulis semigroups as special\ninstance."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.13.3", 
    "link": "http://arxiv.org/pdf/0912.1900v1", 
    "title": "Quantitative Safety: Linking Proof-Based Verification with Model   Checking for Probabilistic Systems", 
    "arxiv-id": "0912.1900v1", 
    "author": "Ukachukwu Ndukwu", 
    "publish": "2009-12-10T01:51:26Z", 
    "summary": "This paper presents a novel approach for augmenting proof-based verification\nwith performance-style analysis of the kind employed in state-of-the-art model\nchecking tools for probabilistic systems. Quantitative safety properties\nusually specified as probabilistic system invariants and modeled in proof-based\nenvironments are evaluated using bounded model checking techniques.\n  Our specific contributions include the statement of a theorem that is central\nto model checking safety properties of proof-based systems, the establishment\nof a procedure; and its full implementation in a prototype system (YAGA) which\nreadily transforms a probabilistic model specified in a proof-based environment\nto its equivalent verifiable PRISM model equipped with reward structures. The\nreward structures capture the exact interpretation of the probabilistic\ninvariants and can reveal succinct information about the model during\nexperimental investigations. Finally, we demonstrate the novelty of the\ntechnique on a probabilistic library case study."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(4:5)2009", 
    "link": "http://arxiv.org/pdf/0912.2109v2", 
    "title": "Computation Tree Logic with Deadlock Detection", 
    "arxiv-id": "0912.2109v2", 
    "author": "Nikola Trcka", 
    "publish": "2009-12-10T21:20:20Z", 
    "summary": "We study the equivalence relation on states of labelled transition systems of\nsatisfying the same formulas in Computation Tree Logic without the next state\nmodality (CTL-X). This relation is obtained by De Nicola & Vaandrager by\ntranslating labelled transition systems to Kripke structures, while lifting the\ntotality restriction on the latter. They characterised it as divergence\nsensitive branching bisimulation equivalence.\n  We find that this equivalence fails to be a congruence for interleaving\nparallel composition. The reason is that the proposed application of CTL-X to\nnon-total Kripke structures lacks the expressiveness to cope with deadlock\nproperties that are important in the context of parallel composition. We\npropose an extension of CTL-X, or an alternative treatment of non-totality,\nthat fills this hiatus. The equivalence induced by our extension is\ncharacterised as branching bisimulation equivalence with explicit divergence,\nwhich is, moreover, shown to be the coarsest congruence contained in divergence\nsensitive branching bisimulation equivalence."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-5(4:5)2009", 
    "link": "http://arxiv.org/pdf/0912.3429v2", 
    "title": "Decidability of the interval temporal logic ABBar over the natural   numbers", 
    "arxiv-id": "0912.3429v2", 
    "author": "G. Sciavicco", 
    "publish": "2009-12-17T15:22:45Z", 
    "summary": "In this paper, we focus our attention on the interval temporal logic of the\nAllen's relations \"meets\", \"begins\", and \"begun by\" (ABBar for short),\ninterpreted over natural numbers. We first introduce the logic and we show that\nit is expressive enough to model distinctive interval properties,such as\naccomplishment conditions, to capture basic modalities of point-based temporal\nlogic, such as the until operator, and to encode relevant metric constraints.\nThen, we prove that the satisfiability problem for ABBar over natural numbers\nis decidable by providing a small model theorem based on an original\ncontraction method. Finally, we prove the EXPSPACE-completeness of the problem"
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.tcs.2009.06.014", 
    "link": "http://arxiv.org/pdf/0912.4023v1", 
    "title": "Configuration Structures, Event Structures and Petri Nets", 
    "arxiv-id": "0912.4023v1", 
    "author": "G. D. Plotkin", 
    "publish": "2009-12-20T15:18:05Z", 
    "summary": "In this paper the correspondence between safe Petri nets and event\nstructures, due to Nielsen, Plotkin and Winskel, is extended to arbitrary nets\nwithout self-loops, under the collective token interpretation. To this end we\npropose a more general form of event structure, matching the expressive power\nof such nets. These new event structures and nets are connected by relating\nboth notions with configuration structures, which can be regarded as\nrepresentations of either event structures or nets that capture their behaviour\nin terms of action occurrences and the causal relationships between them, but\nabstract from any auxiliary structure.\n  A configuration structure can also be considered logically, as a class of\npropositional models, or - equivalently - as a propositional theory in\ndisjunctive normal from. Converting this theory to conjunctive normal form is\nthe key idea in the translation of such a structure into a net.\n  For a variety of classes of event structures we characterise the associated\nclasses of configuration structures in terms of their closure properties, as\nwell as in terms of the axiomatisability of the associated propositional\ntheories by formulae of simple prescribed forms, and in terms of structural\nproperties of the associated Petri nets."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.tcs.2009.06.014", 
    "link": "http://arxiv.org/pdf/0912.4184v1", 
    "title": "Scope Logic: Extending Hoare Logic for Pointer Program Verification", 
    "arxiv-id": "0912.4184v1", 
    "author": "Xuandong Li", 
    "publish": "2009-12-21T15:02:41Z", 
    "summary": "This paper presents an extension to Hoare logic for pointer program\nverification. First, the Logic for Partial Function (LPF) used by VDM is\nextended to specify memory access using pointers and memory layout of composite\ntypes. Then, the concepts of data-retrieve functions (DRF) and memory-scope\nfunctions (MSF) are introduced in this paper. People can define DRFs to\nretrieve abstract values from interconnected concrete data objects. The\ndefinition of the corresponding MSF of a DRF can be derived syntactically from\nthe definition of the DRF. This MSF computes the set of memory units accessed\nwhen the DRF retrieves an abstract value. This memory unit set is called the\nmemory scope of the abstract value. Finally, the proof rule of assignment\nstatements in Hoare's logic is modified to deal with pointers. The basic idea\nis that a virtual value keeps unmodified as long as no memory unit in its scope\nis over-written. Another proof rule is added for memory allocation statements.\nThe consequence rule and the rules for control-flow statements are slightly\nmodified. They are essentially same as their original version in Hoare logic.\n  An example is presented to show the efficacy of this logic. We also give some\nheuristics on how to verify pointer programs."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(1:7)2010", 
    "link": "http://arxiv.org/pdf/0912.4947v3", 
    "title": "Infinitary Combinatory Reduction Systems: Normalising Reduction   Strategies", 
    "arxiv-id": "0912.4947v3", 
    "author": "Jakob Grue Simonsen", 
    "publish": "2009-12-30T19:25:59Z", 
    "summary": "We study normalising reduction strategies for infinitary Combinatory\nReduction Systems (iCRSs). We prove that all fair, outermost-fair, and\nneeded-fair strategies are normalising for orthogonal, fully-extended iCRSs.\nThese facts properly generalise a number of results on normalising strategies\nin first-order infinitary rewriting and provide the first examples of\nnormalising strategies for infinitary lambda calculus."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(1:7)2010", 
    "link": "http://arxiv.org/pdf/0912.5014v1", 
    "title": "A User's Guide to Zot", 
    "arxiv-id": "0912.5014v1", 
    "author": "Matteo Pradella", 
    "publish": "2009-12-26T12:40:29Z", 
    "summary": "Zot is an agile and easily extendible bounded model checker, which can be\ndownloaded at http://home.dei.polimi.it/pradella/. The tool supports different\nlogic languages through a multi-layered approach: its core uses PLTL, and on\ntop of it a decidable predicative fragment of TRIO is defined. An interesting\nfeature of Zot is its ability to support different encodings of temporal logic\nas SAT problems by means of plug-ins. This approach encourages experimentation,\nas plug-ins are expected to be quite simple, compact (usually around 500 lines\nof code), easily modifiable, and extendible."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(1:7)2010", 
    "link": "http://arxiv.org/pdf/0912.5515v2", 
    "title": "LoopW Technical Reference v0.3", 
    "arxiv-id": "0912.5515v2", 
    "author": "Emmanuel Polonowski", 
    "publish": "2009-12-30T18:58:19Z", 
    "summary": "This document describes the implementation in SML of the LoopW language, an\nimperative language with higher-order procedural variables and non-local jumps\nequiped with a program logic. It includes the user manual along with some\nimplementation notes and many examples of certified imperative programs. As a\nconcluding example, we show the certification of an imperative program encoding\nshift/reset using callcc/throw and a global meta-continuation."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-15643-4_11", 
    "link": "http://arxiv.org/pdf/1001.2100v2", 
    "title": "What's Decidable About Sequences?", 
    "arxiv-id": "1001.2100v2", 
    "author": "Carlo A. Furia", 
    "publish": "2010-01-13T16:21:06Z", 
    "summary": "We present a first-order theory of sequences with integer elements,\nPresburger arithmetic, and regular constraints, which can model significant\nproperties of data structures such as arrays and lists. We give a decision\nprocedure for the quantifier-free fragment, based on an encoding into the\nfirst-order theory of concatenation; the procedure has PSPACE complexity. The\nquantifier-free fragment of the theory of sequences can express properties such\nas sortedness and injectivity, as well as Boolean combinations of periodic and\narithmetic facts relating the elements of the sequence and their positions\n(e.g., \"for all even i's, the element at position i has value i+3 or 2i\"). The\nresulting expressive power is orthogonal to that of the most expressive\ndecidable logics for arrays. Some examples demonstrate that the fragment is\nalso suitable to reason about sequence-manipulating programs within the\nstandard framework of axiomatic semantics."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(1:5)2010", 
    "link": "http://arxiv.org/pdf/1001.2175v2", 
    "title": "Weighted Logics for Nested Words and Algebraic Formal Power Series", 
    "arxiv-id": "1001.2175v2", 
    "author": "Christian Mathissen", 
    "publish": "2010-01-13T14:21:36Z", 
    "summary": "Nested words, a model for recursive programs proposed by Alur and Madhusudan,\nhave recently gained much interest. In this paper we introduce quantitative\nextensions and study nested word series which assign to nested words elements\nof a semiring. We show that regular nested word series coincide with series\ndefinable in weighted logics as introduced by Droste and Gastin. For this we\nestablish a connection between nested words and the free bisemigroup. Applying\nour result, we obtain characterizations of algebraic formal power series in\nterms of weighted logics. This generalizes results of Lautemann, Schwentick and\nTherien on context-free languages."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(1:5)2010", 
    "link": "http://arxiv.org/pdf/1001.2811v2", 
    "title": "Synthesis of AMBA AHB from Formal Specification", 
    "arxiv-id": "1001.2811v2", 
    "author": "Thomas A. Henzinger", 
    "publish": "2010-01-16T08:32:17Z", 
    "summary": "The standard procedure for hardware design consists of describing circuit in\na hardware description language at logic level followed by extensive\nverification and logic-synthesis. However, this process consumes significant\ntime and needs a lot of effort. An alternative is to use formal specification\nlanguage as a high-level hardware description language and synthesize hardware\nfrom formal specification. Bloem et.al. gave formal specifications and\nsynthesize the AMBA AHB Arbiter. Our contributions are as follows:(1) We\npresent more complete and compact formal specifications for the AMBA AHB\nArbiter, and obtain significant (order of magnitude) improvement in synthesis\nresults (both with respect to time and the number of gates of the synthesize\ncircuit); (2) we present formal specification and synthesize to generate\ncompact circuits for the remaining two components of the AMBA AHB protocol,\nnamely, the AMBA AHB Master and AMBA AHB Slave; and (3) from the lessons learnt\nwe present few principles for writing formal specifications for efficient\nhardware synthesis. Thus with intelligently written complete formal\nspecifications we are able to automatically synthesize an important and widely\nused industrial protocol."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(1:5)2010", 
    "link": "http://arxiv.org/pdf/1001.3219v1", 
    "title": "A finiteness structure on resource terms", 
    "arxiv-id": "1001.3219v1", 
    "author": "Thomas Ehrhard", 
    "publish": "2010-01-19T08:23:54Z", 
    "summary": "In our paper \"Uniformity and the Taylor expansion of ordinary lambda-terms\"\n(with Laurent Regnier), we studied a translation of lambda-terms as infinite\nlinear combinations of resource lambda-terms, from a calculus similar to\nBoudol's lambda-calculus with resources and based on ideas coming from\ndifferential linear logic and differential lambda-calculus. The good properties\nof this translation wrt. beta-reduction were guaranteed by a coherence relation\non resource terms: normalization is \"linear and stable\" (in the sense of the\ncoherence space semantics of linear logic) wrt. this coherence relation. Such\ncoherence properties are lost when one considers non-deterministic or algebraic\nextensions of the lambda-calculus (the algebraic lambda-calculus is an\nextension of the lambda-calculus where terms can be linearly combined). We\nintroduce a \"finiteness structure\" on resource terms which induces a linearly\ntopologized vector space structure on terms and prevents the appearance of\ninfinite coefficients during reduction, in typed settings."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(1:5)2010", 
    "link": "http://arxiv.org/pdf/1001.3464v1", 
    "title": "Formalizing cCSP Synchronous Semantics in PVS", 
    "arxiv-id": "1001.3464v1", 
    "author": "Michael Butler", 
    "publish": "2010-01-20T17:52:02Z", 
    "summary": "Compensating CSP (cCSP) is a language defined to model long running business\ntransactions within the framework of standard CSP process algebra. In earlier\nwork, we have defined both traces and operational semantics of the language. We\nhave shown the consistency between the two semantic models by defining a\nrelationship between them. Synchronization was missing from the earlier\nsemantic definitions which is an important feature for any process algebra. In\nthis paper, we address this issue by extending the syntax and semantics to\nsupport synchronization and define a relationship between the semantic models.\nMoreover, we improve the scalability of our proof technique by mechanically\nverifying the semantic relationship using theorem prover PVS. We show how to\nembed process algebra terms and semantics into PVS and to use these embeddings\nto prove the semantic relationship."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(1:5)2010", 
    "link": "http://arxiv.org/pdf/1001.4021v1", 
    "title": "A Minimal Propositional Type Theory", 
    "arxiv-id": "1001.4021v1", 
    "author": "Gert Smolka", 
    "publish": "2010-01-22T16:05:07Z", 
    "summary": "Propositional type theory, first studied by Henkin, is the restriction of\nsimple type theory to a single base type that is interpreted as the set of the\ntwo truth values. We show that two constants (falsity and implication) suffice\nfor denotational and deductive completeness. Denotational completeness means\nthat every value of the full set-theoretic type hierarchy can be described by a\nclosed term. Deductive completeness is shown for a sequent-based proof system\nthat extends a propositional natural deduction system with lambda conversion\nand Boolean replacement."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.15.2", 
    "link": "http://arxiv.org/pdf/1001.4429v1", 
    "title": "Superdevelopments for Weak Reduction", 
    "arxiv-id": "1001.4429v1", 
    "author": "Pablo Barenbaum", 
    "publish": "2010-01-25T13:59:29Z", 
    "summary": "We study superdevelopments in the weak lambda calculus of Cagman and Hindley,\na confluent variant of the standard weak lambda calculus in which reduction\nbelow lambdas is forbidden. In contrast to developments, a superdevelopment\nfrom a term M allows not only residuals of redexes in M to be reduced but also\nsome newly created ones. In the lambda calculus there are three ways new\nredexes may be created; in the weak lambda calculus a new form of redex\ncreation is possible. We present labeled and simultaneous reduction\nformulations of superdevelopments for the weak lambda calculus and prove them\nequivalent."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.15.5", 
    "link": "http://arxiv.org/pdf/1001.4437v1", 
    "title": "Extending Context-Sensitivity in Term Rewriting", 
    "arxiv-id": "1001.4437v1", 
    "author": "Felix Schernhammer", 
    "publish": "2010-01-25T14:14:03Z", 
    "summary": "We propose a generalized version of context-sensitivity in term rewriting\nbased on the notion of \"forbidden patterns\". The basic idea is that a rewrite\nstep should be forbidden if the redex to be contracted has a certain shape and\nappears in a certain context. This shape and context is expressed through\nforbidden patterns. In particular we analyze the relationships among this novel\napproach and the commonly used notion of context-sensitivity in term rewriting,\nas well as the feasibility of rewriting with forbidden patterns from a\ncomputational point of view. The latter feasibility is characterized by\ndemanding that restricting a rewrite relation yields an improved termination\nbehaviour while still being powerful enough to compute meaningful results.\nSufficient criteria for both kinds of properties in certain classes of rewrite\nsystems with forbidden patterns are presented."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.15.5", 
    "link": "http://arxiv.org/pdf/1002.0172v2", 
    "title": "Optimal and Cut-free Tableaux for Propositional Dynamic Logic with   Converse", 
    "arxiv-id": "1002.0172v2", 
    "author": "Florian Widmann", 
    "publish": "2010-02-01T02:06:47Z", 
    "summary": "We give an optimal (EXPTIME), sound and complete tableau-based algorithm for\ndeciding satisfiability for propositional dynamic logic with converse (CPDL)\nwhich does not require the use of analytic cut. Our main contribution is a\nsound methodto combine our previous optimal method for tracking least\nfix-points in PDL with our previous optimal method for handling converse in the\ndescription logic ALCI. The extension is non-trivial as the two methods cannot\nbe combined naively. We give sufficient details to enable an implementation by\nothers. Our OCaml implementation seems to be the first theorem prover for CPDL."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.15.5", 
    "link": "http://arxiv.org/pdf/1002.1796v1", 
    "title": "Refinement and Verification of Real-Time Systems", 
    "arxiv-id": "1002.1796v1", 
    "author": "Dino Mandrioli", 
    "publish": "2010-02-09T08:46:24Z", 
    "summary": "This paper discusses highly general mechanisms for specifying the refinement\nof a real-time system as a collection of lower level parallel components that\npreserve the timing and functional requirements of the upper level\nspecification. These mechanisms are discussed in the context of ASTRAL, which\nis a formal specification language for real-time systems. Refinement is\naccomplished by mapping all of the elements of an upper level specification\ninto lower level elements that may be split among several parallel components.\nIn addition, actions that can occur in the upper level are mapped to actions of\ncomponents operating at the lower level. This allows several types of\nimplementation strategies to be specified in a natural way, while the price for\ngenerality (in terms of complexity) is paid only when necessary. The refinement\nmechanisms are first illustrated using a simple digital circuit; then, through\na highly complex phone system; finally, design guidelines gleaned from these\nspecifications are presented."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.15.5", 
    "link": "http://arxiv.org/pdf/1002.2578v1", 
    "title": "Modular Construction of Fixed Point Combinators and Clocked Boehm Trees", 
    "arxiv-id": "1002.2578v1", 
    "author": "Jan Willem Klop", 
    "publish": "2010-02-12T15:49:51Z", 
    "summary": "Fixed point combinators (and their generalization: looping combinators) are\nclassic notions belonging to the heart of lambda-calculus and logic. We start\nwith an exploration of the structure of fixed point combinators (fpc's), vastly\ngeneralizing the well-known fact that if Y is an fpc, Y(SI) is again an fpc,\ngenerating the Boehm sequence of fpc's. Using the infinitary lambda-calculus we\ndevise infinitely many other generation schemes for fpc's. In this way we find\nschemes and building blocks to construct new fpc's in a modular way.\n  Having created a plethora of new fixed point combinators, the task is to\nprove that they are indeed new. That is, we have to prove their\nbeta-inconvertibility. Known techniques via Boehm Trees do not apply, because\nall fpc's have the same Boehm Tree (BT). Therefore, we employ `clocked BT's',\nwith annotations that convey information of the tempo in which the data in the\nBT are produced. BT's are thus enriched with an intrinsic clock behaviour,\nleading to a refined discrimination method for lambda-terms. The corresponding\nequality is strictly intermediate between beta-convertibility and BT-equality,\nthe equality in the classical models of lambda-calculus. An analogous approach\npertains to Levy-Longo Berarducci trees. Finally, we increase the\ndiscrimination power by a precision of the clock notion that we call `atomic\nclock'."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.18.1", 
    "link": "http://arxiv.org/pdf/1002.2864v1", 
    "title": "A Bisimulation-based Method for Proving the Validity of Equations in   GSOS Languages", 
    "arxiv-id": "1002.2864v1", 
    "author": "Anna Ingolfsdottir", 
    "publish": "2010-02-15T12:08:08Z", 
    "summary": "This paper presents a bisimulation-based method for establishing the\nsoundness of equations between terms constructed using operations whose\nsemantics is specified by rules in the GSOS format of Bloom, Istrail and Meyer.\nThe method is inspired by de Simone's FH-bisimilarity and uses transition rules\nas schematic transitions in a bisimulation-like relation between open terms.\nThe soundness of the method is proven and examples showing its applicability\nare provided. The proposed bisimulation-based proof method is incomplete, but\nthe article offers some completeness results for restricted classes of GSOS\nspecifications."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.18.2", 
    "link": "http://arxiv.org/pdf/1002.2867v1", 
    "title": "A Fully Abstract Symbolic Semantics for Psi-Calculi", 
    "arxiv-id": "1002.2867v1", 
    "author": "Joachim Parrow", 
    "publish": "2010-02-15T12:30:43Z", 
    "summary": "We present a symbolic transition system and bisimulation equivalence for\npsi-calculi, and show that it is fully abstract with respect to bisimulation\ncongruence in the non-symbolic semantics.\n  A psi-calculus is an extension of the pi-calculus with nominal data types for\ndata structures and for logical assertions representing facts about data. These\ncan be transmitted between processes and their names can be statically scoped\nusing the standard pi-calculus mechanism to allow for scope migrations.\nPsi-calculi can be more general than other proposed extensions of the\npi-calculus such as the applied pi-calculus, the spi-calculus, the fusion\ncalculus, or the concurrent constraint pi-calculus.\n  Symbolic semantics are necessary for an efficient implementation of the\ncalculus in automated tools exploring state spaces, and the full abstraction\nproperty means the semantics of a process does not change from the original."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.18.4", 
    "link": "http://arxiv.org/pdf/1002.2869v1", 
    "title": "On Barbs and Labels in Reactive Systems", 
    "arxiv-id": "1002.2869v1", 
    "author": "Giacoma Valentina Monreale", 
    "publish": "2010-02-15T12:38:56Z", 
    "summary": "Reactive systems (RSs) represent a meta-framework aimed at deriving\nbehavioral congruences for those computational formalisms whose operational\nsemantics is provided by reduction rules. RSs proved a flexible specification\ndevice, yet so far most of the efforts dealing with their behavioural semantics\nfocused on idem pushouts (IPOs) and saturated (also known as dynamic)\nbisimulations. In this paper we introduce a novel, intermediate behavioural\nequivalence: L-bisimilarity, which is able to recast both its IPO and saturated\ncounterparts. The equivalence is parametric with respect to a set L of RSs\nlabels, and it is shown that under mild conditions on L it is indeed a\ncongruence. Furthermore, L-bisimilarity can also recast the notion of barbed\nsemantics for RSs, proposed by the same authors in a previous paper. In order\nto provide a suitable test-bed, we instantiate our proposal by addressing the\nsemantics of (asynchronous) CCS and of the calculus of mobile ambients."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.18.5", 
    "link": "http://arxiv.org/pdf/1002.2871v1", 
    "title": "Reverse Bisimulations on Stable Configuration Structures", 
    "arxiv-id": "1002.2871v1", 
    "author": "Irek Ulidowski", 
    "publish": "2010-02-15T12:43:41Z", 
    "summary": "The relationships between various equivalences on configuration structures,\nincluding interleaving bisimulation (IB), step bisimulation (SB) and hereditary\nhistory-preserving (HH) bisimulation, have been investigated by van Glabbeek\nand Goltz (and later Fecher). Since HH bisimulation may be characterised by the\nuse of reverse as well as forward transitions, it is of interest to investigate\nforms of IB and SB where both forward and reverse transitions are allowed. We\ngive various characterisations of reverse SB, showing that forward steps do not\nadd extra power. We strengthen Bednarczyk's result that, in the absence of\nauto-concurrency, reverse IB is as strong as HH bisimulation, by showing that\nwe need only exclude auto-concurrent events at the same depth in the\nconfiguration."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.18.5", 
    "link": "http://arxiv.org/pdf/1002.3083v1", 
    "title": "L2C2: Logic-based LSC Consistency Checking", 
    "arxiv-id": "1002.3083v1", 
    "author": "Mahadevan Subramaniam", 
    "publish": "2010-02-16T14:09:43Z", 
    "summary": "Live sequence charts (LSCs) have been proposed as an inter-object\nscenario-based specification and visual programming language for reactive\nsystems. In this paper, we introduce a logic-based framework to check the\nconsistency of an LSC specification. An LSC simulator has been implemented in\nlogic programming, utilizing a memoized depth-first search strategy, to show\nhow a reactive system in LSCs would response to a set of external event\nsequences. A formal notation is defined to specify external event sequences,\nextending the regular expression with a parallel operator and a testing\ncontrol. The parallel operator allows interleaved parallel external events to\nbe tested in LSCs simultaneously; while the testing control provides users to a\nnew approach to specify and test certain temporal properties (e.g., CTL\nformula) in a form of LSC. Our framework further provides either a state\ntransition graph or a failure trace to justify the consistency checking\nresults."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.18.5", 
    "link": "http://arxiv.org/pdf/1002.3131v2", 
    "title": "The relational model is injective for Multiplicative Exponential Linear   Logic (without weakenings)", 
    "arxiv-id": "1002.3131v2", 
    "author": "Lorenzo Tortora de Falco", 
    "publish": "2010-02-16T19:20:03Z", 
    "summary": "We show that for Multiplicative Exponential Linear Logic (without weakenings)\nthe syntactical equivalence relation on proofs induced by cut-elimination\ncoincides with the semantic equivalence relation on proofs induced by the\nmultiset based relational model: one says that the interpretation in the model\n(or the semantics) is injective. We actually prove a stronger result: two\ncut-free proofs of the full multiplicative and exponential fragment of linear\nlogic whose interpretations coincide in the multiset based relational model are\nthe same \"up to the connections between the doors of exponential boxes\"."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.18.5", 
    "link": "http://arxiv.org/pdf/1002.3222v1", 
    "title": "Structural Analysis of Boolean Equation Systems", 
    "arxiv-id": "1002.3222v1", 
    "author": "Tim A. C. Willemse", 
    "publish": "2010-02-17T08:15:12Z", 
    "summary": "We analyse the problem of solving Boolean equation systems through the use of\nstructure graphs. The latter are obtained through an elegant set of\nPlotkin-style deduction rules. Our main contribution is that we show that\nequation systems with bisimilar structure graphs have the same solution. We\nshow that our work conservatively extends earlier work, conducted by Keiren and\nWillemse, in which dependency graphs were used to analyse a subclass of Boolean\nequation systems, viz., equation systems in standard recursive form. We\nillustrate our approach by a small example, demonstrating the effect of\nsimplifying an equation system through minimisation of its structure graph."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.18.5", 
    "link": "http://arxiv.org/pdf/1002.4334v2", 
    "title": "On Semantic Generalizations of the Bernays-Sch\u00f6nfinkel-Ramsey Class   with Finite or Co-finite Spectra", 
    "arxiv-id": "1002.4334v2", 
    "author": "Supratik Chakraborty", 
    "publish": "2010-02-23T15:57:36Z", 
    "summary": "Motivated by model-theoretic properties of the BSR class, we present a family\nof semantic classes of FO formulae with finite or co-finite spectra over a\nrelational vocabulary \\Sigma. A class in this family is denoted\nEBS_\\Sigma(\\sigma), where \\sigma is a subset of \\Sigma. Formulae in\nEBS_\\Sigma(\\sigma) are preserved under substructures modulo a bounded core and\nmodulo re-interpretation of predicates outside \\sigma. We study properties of\nthe family EBS_\\Sigma = {EBS_\\Sigma(\\sigma) | \\sigma \\subseteq \\Sigma}, e.g.\nclasses in EBS_\\Sigma are spectrally indistinguishable, EBS_\\Sigma(\\Sigma) is\nsemantically equivalent to BSR over \\Sigma, and EBS_\\Sigma(\\emptyset) is the\nset of all FO formulae over \\Sigma with finite or co-finite spectra.\nFurthermore, (EBS_\\Sigma, \\subseteq) forms a lattice isomorphic to the powerset\nlattice (\\wp({\\Sigma}), \\subseteq). This gives a natural semantic\ngeneralization of BSR as ascending chains in (EBS_\\Sigma, \\subseteq). Many\nwell-known FO classes are semantically subsumed by EBS_\\Sigma(\\Sigma) or\nEBS_\\Sigma(\\emptyset). Our study provides alternative proofs of interesting\nresults like the Lo\\'s-Tarski Theorem and the semantic subsumption of the\nL\\\"owenheim class with equality by BSR. We also present a syntactic sub-class\nof EBS_\\Sigma(\\sigma) called EDP_\\Sigma(\\sigma) and give an expression for the\nsize of the bounded cores of models of EDP_\\Sigma(\\sigma) formulae. We show\nthat the EDP_\\Sigma(\\sigma) classes also form a lattice structure. Finally, we\nstudy some closure properties and applications of the classes presented."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.18.5", 
    "link": "http://arxiv.org/pdf/1002.4535v1", 
    "title": "Proceedings of the 19th Workshop on Logic-based methods in Programming   Environments (WLPE 2009)", 
    "arxiv-id": "1002.4535v1", 
    "author": "John Gallagher", 
    "publish": "2010-02-24T12:27:21Z", 
    "summary": "This volume contains the papers presented at the 19th Workshop on Logic-\nbased methods in Programming Environments (WLPE'09), which was held in\nPasadena, USA, on July 14th, 2009.\n  WLPE aims at providing an informal meeting for researchers working on\nlogic-based methods and tools which support program development and analy- sis.\nThis year, we have continued and consolidated the shift in focus from en-\nvironmental tools for logic programming to logic-based environmental tools for\nprogramming in general, so that this workshop can be possibly interesting for a\nwider scientific community.\n  All the papers submitted to WLPE'09 have gone through a careful process of\npeer reviewing, with at least three reviews for each paper and a subsequent\nin-depth discussion in the Program Committee."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.18.5", 
    "link": "http://arxiv.org/pdf/1002.4616v2", 
    "title": "Robust Vacuity for Branching Temporal Logic", 
    "arxiv-id": "1002.4616v2", 
    "author": "Marsha Chechik", 
    "publish": "2010-02-24T20:33:57Z", 
    "summary": "There is a growing interest in techniques for detecting whether a logic\nspecification is satisfied too easily, or vacuously. For example, the\nspecification \"every request is eventually followed by an acknowledgment\" is\nsatisfied vacuously by a system that never generates any requests. Vacuous\nsatisfaction misleads users of model-checking into thinking that a system is\ncorrect.\n  There are several existing definitions of vacuity. Originally, Beer et al.\nformalized vacuity as insensitivity to syntactic perturbation. However, this\ndefinition is only reasonable for vacuity in a single occurrence. Armoni et al.\nargued that vacuity must be robust -- not affected by semantically invariant\nchanges, such as extending a model with additional atomic propositions. They\nshow that syntactic vacuity is not robust for LTL, and propose an alternative\ndefinition -- trace vacuity.\n  In this article, we continue this line of research. We show that trace\nvacuity is not robust for branching time logic. We refine it to apply uniformly\nto linear and branching time logic and to not suffer from the common pitfalls\nof prior definitions. Our new definition -- bisimulation vacuity -- is a proper\nnon-trivial extension of both syntactic and trace vacuity. We discuss the\ncomplexity of detecting bisimulation vacuity, and give efficient algorithms to\ndetect vacuity for several practically-relevant subsets of CTL*."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.18.5", 
    "link": "http://arxiv.org/pdf/1003.0107v1", 
    "title": "A Concrete Representation of Observational Equivalence for PCF", 
    "arxiv-id": "1003.0107v1", 
    "author": "Guy McCusker", 
    "publish": "2010-02-27T16:27:58Z", 
    "summary": "The full abstraction result for PCF using game semantics requires one to\nidentify all innocent strategies that are innocently indistinguishable. This\ninvolves a quantification over all innocent tests, cf. quantification over all\ninnocent contexts. Here we present a representation of innocent strategies that\nequates innocently indistinguishable ones, yielding a representation of PCF\nterms that equates precisely those terms that are observational equivalent."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.20.5", 
    "link": "http://arxiv.org/pdf/1003.0431v1", 
    "title": "Re-verification of a Lip Synchronization Protocol using Robust   Reachability", 
    "arxiv-id": "1003.0431v1", 
    "author": "Jan Willem Polderman", 
    "publish": "2010-03-01T19:53:00Z", 
    "summary": "The timed automata formalism is an important model for specifying and\nanalysing real-time systems. Robustness is the correctness of the model in the\npresence of small drifts on clocks or imprecision in testing guards. A symbolic\nalgorithm for the analysis of the robustness of timed automata has been\nimplemented. In this paper, we re-analyse an industrial case lip\nsynchronization protocol using the new robust reachability algorithm. This lip\nsynchronization protocol is an interesting case because timing aspects are\ncrucial for the correctness of the protocol. Several versions of the model are\nconsidered: with an ideal video stream, with anchored jitter, and with\nnon-anchored jitter."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.20.5", 
    "link": "http://arxiv.org/pdf/1003.1632v1", 
    "title": "Unification and Matching on Compressed Terms", 
    "arxiv-id": "1003.1632v1", 
    "author": "Manfred Schmidt-Schau\u00df", 
    "publish": "2010-03-08T14:12:51Z", 
    "summary": "Term unification plays an important role in many areas of computer science,\nespecially in those related to logic. The universal mechanism of grammar-based\ncompression for terms, in particular the so-called Singleton Tree Grammars\n(STG), have recently drawn considerable attention. Using STGs, terms of\nexponential size and height can be represented in linear space. Furthermore,\nthe term representation by directed acyclic graphs (dags) can be efficiently\nsimulated. The present paper is the result of an investigation on term\nunification and matching when the terms given as input are represented using\ndifferent compression mechanisms for terms such as dags and Singleton Tree\nGrammars. We describe a polynomial time algorithm for context matching with\ndags, when the number of different context variables is fixed for the problem.\nFor the same problem, NP-completeness is obtained when the terms are\nrepresented using the more general formalism of Singleton Tree Grammars. For\nfirst-order unification and matching polynomial time algorithms are presented,\neach of them improving previous results for those problems."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.20.5", 
    "link": "http://arxiv.org/pdf/1003.1684v2", 
    "title": "Generalised Rabin(1) synthesis", 
    "arxiv-id": "1003.1684v2", 
    "author": "Ruediger Ehlers", 
    "publish": "2010-03-08T17:36:02Z", 
    "summary": "We present a novel method for the synthesis of finite state systems that is a\ngeneralisation of the generalised reactivity(1) synthesis approach by Piterman,\nPnueli and Sa'ar. In particular, we describe an efficient method to synthesize\nsystems from linear-time temporal logic specifications for which all\nassumptions and guarantees have a Rabin index of one. We show how to build a\nparity game with at most five colours that captures all solutions to the\nsynthesis problem from such a specification. This parity game has a structure\nthat is amenable to symbolic implementations. We furthermore show that the\nresults obtained are in some sense tight, i.e., that there does not exist a\nsimilar synthesis method for assumptions and specifications of higher Rabin\nindex, unless P=NP."
},{
    "category": "cs.LO", 
    "doi": "10.3166/jancl.21.375-395", 
    "link": "http://arxiv.org/pdf/1003.2790v1", 
    "title": "Some Remarks on the Model Theory of Epistemic Plausibility Models", 
    "arxiv-id": "1003.2790v1", 
    "author": "Lorenz Demey", 
    "publish": "2010-03-14T15:18:09Z", 
    "summary": "Classical logics of knowledge and belief are usually interpreted on Kripke\nmodels, for which a mathematically well-developed model theory is available.\nHowever, such models are inadequate to capture dynamic phenomena. Therefore,\nepistemic plausibility models have been introduced. Because these are much\nricher structures than Kripke models, they do not straightforwardly inherit the\nmodel-theoretical results of modal logic. Therefore, while epistemic\nplausibility structures are well-suited for modeling purposes, an extensive\ninvestigation of their model theory has been lacking so far. The aim of the\npresent paper is to fill exactly this gap, by initiating a systematic\nexploration of the model theory of epistemic plausibility models. Like in\n'ordinary' modal logic, the focus will be on the notion of bisimulation. We\ndefine various notions of bisimulations (parametrized by a language L) and show\nthat L-bisimilarity implies L-equivalence. We prove a Hennesy-Milner type\nresult, and also two undefinability results. However, our main point is a\nnegative one, viz. that bisimulations cannot straightforwardly be generalized\nto epistemic plausibility models if conditional belief is taken into account.\nWe present two ways of coping with this issue: (i) adding a modality to the\nlanguage, and (ii) putting extra constraints on the models. Finally, we make\nsome remarks about the interaction between bisimulation and dynamic model\nchanges."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.21.8", 
    "link": "http://arxiv.org/pdf/1003.4802v1", 
    "title": "Automatic Generation of Proof Tactics for Finite-Valued Logics", 
    "arxiv-id": "1003.4802v1", 
    "author": "Jo\u00e3o Marcos", 
    "publish": "2010-03-25T04:44:58Z", 
    "summary": "A number of flexible tactic-based logical frameworks are nowadays available\nthat can implement a wide range of mathematical theories using a common\nhigher-order metalanguage. Used as proof assistants, one of the advantages of\nsuch powerful systems resides in their responsiveness to extensibility of their\nreasoning capabilities, being designed over rule-based programming languages\nthat allow the user to build her own `programs to construct proofs' - the\nso-called proof tactics.\n  The present contribution discusses the implementation of an algorithm that\ngenerates sound and complete tableau systems for a very inclusive class of\nsufficiently expressive finite-valued propositional logics, and then\nillustrates some of the challenges and difficulties related to the algorithmic\nformation of automated theorem proving tactics for such logics. The procedure\non whose implementation we will report is based on a generalized notion of\nanalyticity of proof systems that is intended to guarantee termination of the\ncorresponding automated tactics on what concerns theoremhood in our targeted\nlogics."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.21.9", 
    "link": "http://arxiv.org/pdf/1003.4803v1", 
    "title": "Verifying Temporal Regular Properties of Abstractions of Term Rewriting   Systems", 
    "arxiv-id": "1003.4803v1", 
    "author": "Thomas Genet", 
    "publish": "2010-03-25T04:46:12Z", 
    "summary": "The tree automaton completion is an algorithm used for proving safety\nproperties of systems that can be modeled by a term rewriting system. This\nrepresentation and verification technique works well for proving properties of\ninfinite systems like cryptographic protocols or more recently on Java Bytecode\nprograms. This algorithm computes a tree automaton which represents a (regular)\nover approximation of the set of reachable terms by rewriting initial terms.\nThis approach is limited by the lack of information about rewriting relation\nbetween terms. Actually, terms in relation by rewriting are in the same\nequivalence class: there are recognized by the same state in the tree\nautomaton.\n  Our objective is to produce an automaton embedding an abstraction of the\nrewriting relation sufficient to prove temporal properties of the term\nrewriting system.\n  We propose to extend the algorithm to produce an automaton having more\nequivalence classes to distinguish a term or a subterm from its successors\nw.r.t. rewriting. While ground transitions are used to recognize equivalence\nclasses of terms, epsilon-transitions represent the rewriting relation between\nterms. From the completed automaton, it is possible to automatically build a\nKripke structure abstracting the rewriting sequence. States of the Kripke\nstructure are states of the tree automaton and the transition relation is given\nby the set of epsilon-transitions. States of the Kripke structure are labelled\nby the set of terms recognized using ground transitions. On this Kripke\nstructure, we define the Regular Linear Temporal Logic (R-LTL) for expressing\nproperties. Such properties can then be checked using standard model checking\nalgorithms. The only difference between LTL and R-LTL is that predicates are\nreplaced by regular sets of acceptable terms."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.20.1", 
    "link": "http://arxiv.org/pdf/1003.4812v1", 
    "title": "Bisimulation Relations Between Automata, Stochastic Differential   Equations and Petri Nets", 
    "arxiv-id": "1003.4812v1", 
    "author": "Henk A. P. Blom", 
    "publish": "2010-03-25T06:38:50Z", 
    "summary": "Two formal stochastic models are said to be bisimilar if their solutions as a\nstochastic process are probabilistically equivalent. Bisimilarity between two\nstochastic model formalisms means that the strengths of one stochastic model\nformalism can be used by the other stochastic model formalism. The aim of this\npaper is to explain bisimilarity relations between stochastic hybrid automata,\nstochastic differential equations on hybrid space and stochastic hybrid Petri\nnets. These bisimilarity relations make it possible to combine the formal\nverification power of automata with the analysis power of stochastic\ndifferential equations and the compositional specification power of Petri nets.\nThe relations and their combined strengths are illustrated for an air traffic\nexample."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.20.1", 
    "link": "http://arxiv.org/pdf/1003.4905v1", 
    "title": "Feedback control logic synthesis for non safe Petri nets", 
    "arxiv-id": "1003.4905v1", 
    "author": "Hassane Alla", 
    "publish": "2010-03-25T14:21:46Z", 
    "summary": "This paper addresses the problem of forbidden states of non safe Petri Net\n(PN) modelling discrete events systems. To prevent the forbidden states, it is\npossible to use conditions or predicates associated with transitions.\nGenerally, there are many forbidden states, thus many complex conditions are\nassociated with the transitions. A new idea for computing predicates in non\nsafe Petri nets will be presented. Using this method, we can construct a\nmaximally permissive controller if it exists."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(3:7)2010", 
    "link": "http://arxiv.org/pdf/1003.5399v3", 
    "title": "Spatial logics with connectedness predicates", 
    "arxiv-id": "1003.5399v3", 
    "author": "Michael Zakharyaschev", 
    "publish": "2010-03-28T22:00:47Z", 
    "summary": "We consider quantifier-free spatial logics, designed for qualitative spatial\nrepresentation and reasoning in AI, and extend them with the means to represent\ntopological connectedness of regions and restrict the number of their connected\ncomponents. We investigate the computational complexity of these logics and\nshow that the connectedness constraints can increase complexity from NP to\nPSpace, ExpTime and, if component counting is allowed, to NExpTime."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(3:7)2010", 
    "link": "http://arxiv.org/pdf/1003.5447v2", 
    "title": "Relating Nominal and Higher-order Abstract Syntax Specifications", 
    "arxiv-id": "1003.5447v2", 
    "author": "Andrew Gacek", 
    "publish": "2010-03-29T07:54:09Z", 
    "summary": "Nominal abstract syntax and higher-order abstract syntax provide a means for\ndescribing binding structure which is higher-level than traditional techniques.\nThese approaches have spawned two different communities which have developed\nalong similar lines but with subtle differences that make them difficult to\nrelate. The nominal abstract syntax community has devices like names,\nfreshness, name-abstractions with variable capture, and the new-quantifier,\nwhereas the higher-order abstract syntax community has devices like\nlambda-binders, lambda-conversion, raising, and the nabla-quantifier. This\npaper aims to unify these communities and provide a concrete correspondence\nbetween their different devices. In particular, we develop a\nsemantics-preserving translation from alpha-Prolog, a nominal abstract syntax\nbased logic programming language, to G-, a higher-order abstract syntax based\nlogic programming language. We also discuss higher-order judgments, a common\nand powerful tool for specifications with higher-order abstract syntax, and we\nshow how these can be incorporated into G-. This establishes G- as a language\nwith the power of higher-order abstract syntax, the fine-grained variable\ncontrol of nominal specifications, and the desirable properties of higher-order\njudgments."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.22.1", 
    "link": "http://arxiv.org/pdf/1003.5511v1", 
    "title": "Categorical Models for a Semantically Linear Lambda-calculus", 
    "arxiv-id": "1003.5511v1", 
    "author": "Mauro Piccolo", 
    "publish": "2010-03-29T12:01:20Z", 
    "summary": "This paper is about a categorical approach to model a very simple\nSemantically Linear lambda calculus, named Sll-calculus. This is a core\ncalculus underlying the programming language SlPCF. In particular, in this\nwork, we introduce the notion of Sll-Category, which is able to describe a very\nlarge class of sound models of Sll-calculus. Sll-Category extends in the\nnatural way Benton, Bierman, Hyland and de Paiva's Linear Category, in order to\nsoundly interpret all the constructs of Sll-calculus. This category is general\nenough to catch interesting models in Scott Domains and Coherence Spaces."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.22.2", 
    "link": "http://arxiv.org/pdf/1003.5512v1", 
    "title": "Resource-Bound Quantification for Graph Transformation", 
    "arxiv-id": "1003.5512v1", 
    "author": "Reiko Heckel", 
    "publish": "2010-03-29T12:01:34Z", 
    "summary": "Graph transformation has been used to model concurrent systems in software\nengineering, as well as in biochemistry and life sciences. The application of a\ntransformation rule can be characterised algebraically as construction of a\ndouble-pushout (DPO) diagram in the category of graphs. We show how\nintuitionistic linear logic can be extended with resource-bound quantification,\nallowing for an implicit handling of the DPO conditions, and how resource logic\ncan be used to reason about graph transformation systems."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.22.5", 
    "link": "http://arxiv.org/pdf/1003.5515v1", 
    "title": "Labelled Lambda-calculi with Explicit Copy and Erase", 
    "arxiv-id": "1003.5515v1", 
    "author": "Nikolaos Siafakas", 
    "publish": "2010-03-29T12:02:10Z", 
    "summary": "We present two rewriting systems that define labelled explicit substitution\nlambda-calculi. Our work is motivated by the close correspondence between\nLevy's labelled lambda-calculus and paths in proof-nets, which played an\nimportant role in the understanding of the Geometry of Interaction. The\nstructure of the labels in Levy's labelled lambda-calculus relates to the\nmultiplicative information of paths; the novelty of our work is that we design\nlabelled explicit substitution calculi that also keep track of exponential\ninformation present in call-by-value and call-by-name translations of the\nlambda-calculus into linear logic proof-nets."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.22", 
    "link": "http://arxiv.org/pdf/1003.5716v1", 
    "title": "Proceedings First International Workshop on Linearity", 
    "arxiv-id": "1003.5716v1", 
    "author": "Ian Mackie", 
    "publish": "2010-03-30T01:48:23Z", 
    "summary": "This volume contains the proceedings of LINEARITY 2009: the first\nInternational Workshop on Linearity, which took place 12th September 2009 in\nCoimbra, Portugal. The workshop was a satellite event of CSL 2009, the 18th\nEACSL Annual Conference on Computer Science Logic."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.22", 
    "link": "http://arxiv.org/pdf/1003.6096v1", 
    "title": "Expressiveness of Generic Process Shape Types", 
    "arxiv-id": "1003.6096v1", 
    "author": "J. B. Wells", 
    "publish": "2010-03-31T16:55:55Z", 
    "summary": "Shape types are a general concept of process types which work for many\nprocess calculi. We extend the previously published Poly* system of shape types\nto support name restriction. We evaluate the expressiveness of the extended\nsystem by showing that shape types are more expressive than an implicitly typed\npi-calculus and an explicitly typed Mobile Ambients. We demonstrate that the\nextended system makes it easier to enjoy advantages of shape types which\ninclude polymorphism, principal typings, and a type inference implementation."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.22", 
    "link": "http://arxiv.org/pdf/1004.1077v3", 
    "title": "Bounded Reachability for Temporal Logic over Constraint Systems", 
    "arxiv-id": "1004.1077v3", 
    "author": "Pierluigi San Pietro", 
    "publish": "2010-04-07T12:58:32Z", 
    "summary": "We present CLTLB(D), an extension of PLTLB (PLTL with both past and future\noperators) augmented with atomic formulae built over a constraint system D.\nEven for decidable constraint systems, satisfiability and Model Checking\nproblem of such logic can be undecidable. We introduce suitable restrictions\nand assumptions that are shown to make the satisfiability problem for the\nextended logic decidable. Moreover for a large class of constraint systems we\npropose an encoding that realize an effective decision procedure for the\nBounded Reachability problem."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(2:4)2010", 
    "link": "http://arxiv.org/pdf/1004.1947v2", 
    "title": "Analytic Tableaux for Simple Type Theory and its First-Order Fragment", 
    "arxiv-id": "1004.1947v2", 
    "author": "Gert Smolka", 
    "publish": "2010-04-12T13:09:24Z", 
    "summary": "We study simple type theory with primitive equality (STT) and its first-order\nfragment EFO, which restricts equality and quantification to base types but\nretains lambda abstraction and higher-order variables. As deductive system we\nemploy a cut-free tableau calculus. We consider completeness, compactness, and\nexistence of countable models. We prove these properties for STT with respect\nto Henkin models and for EFO with respect to standard models. We also show that\nthe tableau system yields a decision procedure for three EFO fragments."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(2:4)2010", 
    "link": "http://arxiv.org/pdf/1004.2367v1", 
    "title": "GIST: A Solver for Probabilistic Games", 
    "arxiv-id": "1004.2367v1", 
    "author": "Arjun Radhakrishna", 
    "publish": "2010-04-14T10:40:01Z", 
    "summary": "Gist is a tool that (a) solves the qualitative analysis problem of turn-based\nprobabilistic games with {\\omega}-regular objectives; and (b) synthesizes\nreasonable environment assumptions for synthesis of unrealizable\nspecifications. Our tool provides the first and efficient implementations of\nseveral reduction-based techniques to solve turn-based probabilistic games, and\nuses the analysis of turn-based probabilistic games for synthesizing\nenvironment assumptions for unrealizable specifications."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(2:4)2010", 
    "link": "http://arxiv.org/pdf/1004.2436v1", 
    "title": "Some Mathematicians Are Not Turing Machines", 
    "arxiv-id": "1004.2436v1", 
    "author": "Evgeny Chutchev", 
    "publish": "2010-04-13T18:43:00Z", 
    "summary": "A certain mathematician M, considering some hypothesis H, conclusion C and\ntext P, can arrive at one of the following judgments: (1) P does not convince M\nof the fact that since H, it follows that C; (2) P is the proof that since H,\nit follows that C (judgment of the type \"Proved\"). Is it possible to replace\nsuch a mathematician with an arbitrary Turing machine? The paper provides a\nproof that the answer to the question is negative under the two following\nconditions: (1) M is faultless, namely his judgment \"Proved\" always implies\nthat since H, it actually follows that C; (2) M recognizes a certain P' as the\ncorrect proof of the fact that for certain H' and C', if H', then C' (where P',\nH', and C' are stated in the paper)."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-15375-4_36", 
    "link": "http://arxiv.org/pdf/1004.2717v2", 
    "title": "Completeness of Flat Coalgebraic Fixpoint Logics", 
    "arxiv-id": "1004.2717v2", 
    "author": "Yde Venema", 
    "publish": "2010-04-15T21:16:32Z", 
    "summary": "Modal fixpoint logics traditionally play a central role in computer science,\nin particular in artificial intelligence and concurrency. The mu-calculus and\nits relatives are among the most expressive logics of this type. However,\npopular fixpoint logics tend to trade expressivity for simplicity and\nreadability, and in fact often live within the single variable fragment of the\nmu-calculus. The family of such flat fixpoint logics includes, e.g., LTL, CTL,\nand the logic of common knowledge. Extending this notion to the generic\nsemantic framework of coalgebraic logic enables covering a wide range of logics\nbeyond the standard mu-calculus including, e.g., flat fragments of the graded\nmu-calculus and the alternating-time mu-calculus (such as alternating-time\ntemporal logic ATL), as well as probabilistic and monotone fixpoint logics. We\ngive a generic proof of completeness of the Kozen-Park axiomatization for such\nflat coalgebraic fixpoint logics."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-15375-4_10", 
    "link": "http://arxiv.org/pdf/1004.2780v1", 
    "title": "A Geometric Approach to the Problem of Unique Decomposition of Processes", 
    "arxiv-id": "1004.2780v1", 
    "author": "Emmanuel Haucourt", 
    "publish": "2010-04-16T08:21:27Z", 
    "summary": "This paper proposes a geometric solution to the problem of prime\ndecomposability of concurrent processes first explored by R. Milner and F.\nMoller in [MM93]. Concurrent programs are given a geometric semantics using\ncubical areas, for which a unique factorization theorem is proved. An effective\nfactorization method which is correct and complete with respect to the\ngeometric semantics is derived from the factorization theorem. This algorithm\nis implemented in the static analyzer ALCOOL."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-21834-7_4", 
    "link": "http://arxiv.org/pdf/1004.2802v4", 
    "title": "Forward Analysis and Model Checking for Trace Bounded WSTS", 
    "arxiv-id": "1004.2802v4", 
    "author": "Sylvain Schmitz", 
    "publish": "2010-04-16T09:39:33Z", 
    "summary": "We investigate a subclass of well-structured transition systems (WSTS), the\nbounded---in the sense of Ginsburg and Spanier (Trans. AMS 1964)---complete\ndeterministic ones, which we claim provide an adequate basis for the study of\nforward analyses as developed by Finkel and Goubault-Larrecq (Logic. Meth.\nComput. Sci. 2012). Indeed, we prove that, unlike other conditions considered\npreviously for the termination of forward analysis, boundedness is decidable.\nBoundedness turns out to be a valuable restriction for WSTS verification, as we\nshow that it further allows to decide all $\\omega$-regular properties on the\nset of infinite traces of the system."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-21834-7_4", 
    "link": "http://arxiv.org/pdf/1004.4998v1", 
    "title": "Computing in Coq with Infinite Algebraic Data Structures", 
    "arxiv-id": "1004.4998v1", 
    "author": "Julio Rubio", 
    "publish": "2010-04-28T11:04:47Z", 
    "summary": "Computational content encoded into constructive type theory proofs can be\nused to make computing experiments over concrete data structures. In this\npaper, we explore this possibility when working in Coq with chain complexes of\ninfinite type (that is to say, generated by infinite sets) as a part of the\nformalization of a hierarchy of homological algebra structures."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-21834-7_4", 
    "link": "http://arxiv.org/pdf/1004.5382v1", 
    "title": "Interface Building for Software by Modular Three-Valued Abstraction   Refinement", 
    "arxiv-id": "1004.5382v1", 
    "author": "Pritam Roy", 
    "publish": "2010-04-29T20:01:33Z", 
    "summary": "Verification of software systems is a very hard problem due to the large size\nof program state-space. The traditional techniques (like model checking) do not\nscale; since they include the whole state-space by inlining the library\nfunction codes. Current research avoids these problem by creating a lightweight\nrepresentation of the library in form of an \"interface graph\" (call sequence\ngraph). In this paper we introduce a new algorithm to compute a safe,\npermissive interface graph for C-type functions. In this modular analysis, each\nfunction transition is summarized following three-valued abstraction semantics.\nThere are two kinds of abstraction used here. The global abstraction contains\npredicates over global variables only; however the local abstraction inside\neach function may also contain the local variables. The abstract summary needs\nrefinement to guarantee safety and permissiveness. We have implemented the\nalgorithms in TICC tool and compared this algorithm with some related interface\ngeneration algorithms. We also discuss the application of interface as an\noffline test-suite. We create an interface from the model program\n(specification) and the interface will act as a test-suite for the new\nimplementation-under-test (IUT)."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(3:2)2010", 
    "link": "http://arxiv.org/pdf/1005.0253v5", 
    "title": "Size-Change Termination, Monotonicity Constraints and Ranking Functions", 
    "arxiv-id": "1005.0253v5", 
    "author": "Amir M. Ben-Amram", 
    "publish": "2010-05-03T10:58:12Z", 
    "summary": "Size-Change Termination (SCT) is a method of proving program termination\nbased on the impossibility of infinite descent. To this end we may use a\nprogram abstraction in which transitions are described by monotonicity\nconstraints over (abstract) variables. When only constraints of the form x>y'\nand x>=y' are allowed, we have size-change graphs. Both theory and practice are\nnow more evolved in this restricted framework then in the general framework of\nmonotonicity constraints. This paper shows that it is possible to extend and\nadapt some theory from the domain of size-change graphs to the general case,\nthus complementing previous work on monotonicity constraints. In particular, we\npresent precise decision procedures for termination; and we provide a procedure\nto construct explicit global ranking functions from monotonicity constraints in\nsingly-exponential time, which is better than what has been published so far\neven for size-change graphs."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(3:2)2010", 
    "link": "http://arxiv.org/pdf/1005.0349v1", 
    "title": "Smart matching", 
    "arxiv-id": "1005.0349v1", 
    "author": "Enrico Tassi", 
    "publish": "2010-05-03T17:16:32Z", 
    "summary": "One of the most annoying aspects in the formalization of mathematics is the\nneed of transforming notions to match a given, existing result. This kind of\ntransformations, often based on a conspicuous background knowledge in the given\nscientific domain (mostly expressed in the form of equalities or isomorphisms),\nare usually implicit in the mathematical discourse, and it would be highly\ndesirable to obtain a similar behavior in interactive provers. The paper\ndescribes the superposition-based implementation of this feature inside the\nMatita interactive theorem prover, focusing in particular on the so called\nsmart application tactic, supporting smart matching between a goal and a given\nresult."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.23.3", 
    "link": "http://arxiv.org/pdf/1005.0524v1", 
    "title": "Church => Scott = Ptime: an application of resource sensitive   realizability", 
    "arxiv-id": "1005.0524v1", 
    "author": "Kazushige Terui", 
    "publish": "2010-05-04T13:36:11Z", 
    "summary": "We introduce a variant of linear logic with second order quantifiers and type\nfixpoints, both restricted to purely linear formulas. The Church encodings of\nbinary words are typed by a standard non-linear type `Church,' while the Scott\nencodings (purely linear representations of words) are by a linear type\n`Scott.' We give a characterization of polynomial time functions, which is\nderived from (Leivant and Marion 93): a function is computable in polynomial\ntime if and only if it can be represented by a term of type Church => Scott.\n  To prove soundness, we employ a resource sensitive realizability technique\ndeveloped by Hofmann and Dal Lago."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.23.3", 
    "link": "http://arxiv.org/pdf/1005.0835v1", 
    "title": "An affine-intuitionistic system of types and effects: confluence and   termination", 
    "arxiv-id": "1005.0835v1", 
    "author": "Antoine Madet", 
    "publish": "2010-05-05T19:52:17Z", 
    "summary": "We present an affine-intuitionistic system of types and effects which can be\nregarded as an extension of Barber-Plotkin Dual Intuitionistic Linear Logic to\nmulti-threaded programs with effects. In the system, dynamically generated\nvalues such as references or channels are abstracted into a finite set of\nregions. We introduce a discipline of region usage that entails the confluence\n(and hence determinacy) of the typable programs. Further, we show that a\ndiscipline of region stratification guarantees termination."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.23.3", 
    "link": "http://arxiv.org/pdf/1005.1327v1", 
    "title": "Statistical Model Checking : An Overview", 
    "arxiv-id": "1005.1327v1", 
    "author": "Benoit Delahaye", 
    "publish": "2010-05-08T10:14:02Z", 
    "summary": "Quantitative properties of stochastic systems are usually specified in logics\nthat allow one to compare the measure of executions satisfying certain temporal\nproperties with thresholds. The model checking problem for stochastic systems\nwith respect to such logics is typically solved by a numerical approach that\niteratively computes (or approximates) the exact measure of paths satisfying\nrelevant subformulas; the algorithms themselves depend on the class of systems\nbeing analyzed as well as the logic used for specifying the properties. Another\napproach to solve the model checking problem is to \\emph{simulate} the system\nfor finitely many runs, and use \\emph{hypothesis testing} to infer whether the\nsamples provide a \\emph{statistical} evidence for the satisfaction or violation\nof the specification. In this short paper, we survey the statistical approach,\nand outline its main advantages in terms of efficiency, uniformity, and\nsimplicity."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(3:3)2010", 
    "link": "http://arxiv.org/pdf/1005.2340v2", 
    "title": "Classical BI: Its Semantics and Proof Theory", 
    "arxiv-id": "1005.2340v2", 
    "author": "Cristiano Calcagno", 
    "publish": "2010-05-13T15:12:02Z", 
    "summary": "We present Classical BI (CBI), a new addition to the family of bunched logics\nwhich originates in O'Hearn and Pym's logic of bunched implications BI. CBI\ndiffers from existing bunched logics in that its multiplicative connectives\nbehave classically rather than intuitionistically (including in particular a\nmultiplicative version of classical negation). At the semantic level,\nCBI-formulas have the normal bunched logic reading as declarative statements\nabout resources, but its resource models necessarily feature more structure\nthan those for other bunched logics; principally, they satisfy the requirement\nthat every resource has a unique dual. At the proof-theoretic level, a very\nnatural formalism for CBI is provided by a display calculus \\`a la Belnap,\nwhich can be seen as a generalisation of the bunched sequent calculus for BI.\nIn this paper we formulate the aforementioned model theory and proof theory for\nCBI, and prove some fundamental results about the logic, most notably\ncompleteness of the proof theory with respect to the semantics."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(3:2)2011", 
    "link": "http://arxiv.org/pdf/1005.2395v4", 
    "title": "Realizability algebras: a program to well order R", 
    "arxiv-id": "1005.2395v4", 
    "author": "Jean-Louis Krivine", 
    "publish": "2010-05-13T18:55:59Z", 
    "summary": "The theory of classical realizability is a framework in which we can develop\nthe proof-program correspondence. Using this framework, we show how to\ntransform into programs the proofs in classical analysis with dependent choice\nand the existence of a well ordering of the real line. The principal tools are:\nThe notion of realizability algebra, which is a three-sorted variant of the\nwell known combinatory algebra of Curry. An adaptation of the method of forcing\nused in set theory to prove consistency results. Here, it is used in another\nway, to obtain programs associated with a well ordering of R and the existence\nof a non trivial ultrafilter on N."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-10(4:8)2014", 
    "link": "http://arxiv.org/pdf/1005.2897v7", 
    "title": "Call-by-value, call-by-name and the vectorial behaviour of the algebraic   \u03bb-calculus", 
    "arxiv-id": "1005.2897v7", 
    "author": "Beno\u00ee t Valiron", 
    "publish": "2010-05-17T12:07:08Z", 
    "summary": "We examine the relationship between the algebraic lambda-calculus, a fragment\nof the differential lambda-calculus and the linear-algebraic lambda-calculus, a\ncandidate lambda-calculus for quantum computation. Both calculi are algebraic:\neach one is equipped with an additive and a scalar-multiplicative structure,\nand their set of terms is closed under linear combinations. However, the two\nlanguages were built using different approaches: the former is a call-by-name\nlanguage whereas the latter is call-by-value; the former considers algebraic\nequalities whereas the latter approaches them through rewrite rules. In this\npaper, we analyse how these different approaches relate to one another. To this\nend, we propose four canonical languages based on each of the possible choices:\ncall-by-name versus call-by-value, algebraic equality versus algebraic\nrewriting. We show that the various languages simulate one another. Due to\nsubtle interaction between beta-reduction and algebraic rewriting, to make the\nlanguages consistent some additional hypotheses such as confluence or\nnormalisation might be required. We carefully devise the required properties\nfor each proof, making them general enough to be valid for any sub-language\nsatisfying the corresponding properties."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-10(4:8)2014", 
    "link": "http://arxiv.org/pdf/1005.2907v1", 
    "title": "Interactive Realizers and Monads", 
    "arxiv-id": "1005.2907v1", 
    "author": "Ugo de'Liguoro", 
    "publish": "2010-05-17T12:39:44Z", 
    "summary": "We propose a realizability interpretation of a system for quantifier free\narithmetic which is equivalent to the fragment of classical arithmetic without\n\"nested\" quantifiers, called here EM1-arithmetic. We interpret classical proofs\nas interactive learning strategies, namely as processes going through several\nstages of knowledge and learning by interacting with the \"environment\" and with\neach other. We give a categorical presentation of the interpretation through\nthe construction of two suitable monads."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-10(4:8)2014", 
    "link": "http://arxiv.org/pdf/1005.3199v3", 
    "title": "A Survey on Temporal Logics", 
    "arxiv-id": "1005.3199v3", 
    "author": "Savas Konur", 
    "publish": "2010-05-18T13:39:36Z", 
    "summary": "This paper surveys main and recent studies on temporal logics in a broad\nsense by presenting various logic systems, dealing with various time\nstructures, and discussing important features, such as decidability (or\nundecidability) results, expressiveness and proof systems."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-10(4:8)2014", 
    "link": "http://arxiv.org/pdf/1005.3200v3", 
    "title": "Real-time and Probabilistic Temporal Logics: An Overview", 
    "arxiv-id": "1005.3200v3", 
    "author": "Savas Konur", 
    "publish": "2010-05-18T13:41:16Z", 
    "summary": "Over the last two decades, there has been an extensive study on logical\nformalisms for specifying and verifying real-time systems. Temporal logics have\nbeen an important research subject within this direction. Although numerous\nlogics have been introduced for the formal specification of real-time and\ncomplex systems, an up to date comprehensive analysis of these logics does not\nexist in the literature. In this paper we analyse real-time and probabilistic\ntemporal logics which have been widely used in this field. We extrapolate the\nnotions of decidability, axiomatizability, expressiveness, model checking, etc.\nfor each logic analysed. We also provide a comparison of features of the\ntemporal logics discussed."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-10(4:8)2014", 
    "link": "http://arxiv.org/pdf/1005.4379v1", 
    "title": "A Meta-Programming Approach to Realizing Dependently Typed Logic   Programming", 
    "arxiv-id": "1005.4379v1", 
    "author": "Gopalan Nadathur", 
    "publish": "2010-05-24T17:03:47Z", 
    "summary": "Dependently typed lambda calculi such as the Logical Framework (LF) can\nencode relationships between terms in types and can naturally capture\ncorrespondences between formulas and their proofs. Such calculi can also be\ngiven a logic programming interpretation: the Twelf system is based on such an\ninterpretation of LF. We consider here whether a conventional logic programming\nlanguage can provide the benefits of a Twelf-like system for encoding type and\nproof-and-formula dependencies. In particular, we present a simple mapping from\nLF specifications to a set of formulas in the higher-order hereditary Harrop\n(hohh) language, that relates derivations and proof-search between the two\nframeworks. We then show that this encoding can be improved by exploiting\nknowledge of the well-formedness of the original LF specifications to elide\nmuch redundant type-checking information. The resulting logic program has a\nstructure that closely resembles the original specification, thereby allowing\nLF specifications to be viewed as hohh meta-programs. Using the Teyjus\nimplementation of lambdaProlog, we show that our translation provides an\nefficient means for executing LF specifications, complementing the ability that\nthe Twelf system provides for reasoning about them."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-10(4:8)2014", 
    "link": "http://arxiv.org/pdf/1005.5142v3", 
    "title": "Unprovability of the Logical Characterization of Bisimulation", 
    "arxiv-id": "1005.5142v3", 
    "author": "Pedro S\u00e1nchez Terraf", 
    "publish": "2010-05-27T18:13:27Z", 
    "summary": "We quickly review labelled Markov processes (LMP) and provide a\ncounterexample showing that in general measurable spaces, event bisimilarity\nand state bisimilarity differ in LMP. This shows that the logic in Desharnais\n[*] does not characterize state bisimulation in non-analytic measurable spaces.\nFurthermore we show that, under current foundations of Mathematics, such\nlogical characterization is unprovable for spaces that are projections of a\ncoanalytic set. Underlying this construction there is a proof that stationary\nMarkov processes over general measurable spaces do not have semi-pullbacks.\n([*] J. Desharnais, Labelled Markov Processes. School of Computer Science.\nMcGill University, Montr\\'eal (1999))"
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-10(4:8)2014", 
    "link": "http://arxiv.org/pdf/1005.5623v1", 
    "title": "A Tree Logic with Graded Paths and Nominals", 
    "arxiv-id": "1005.5623v1", 
    "author": "Alan Schmitt", 
    "publish": "2010-05-31T08:52:06Z", 
    "summary": "Regular tree grammars and regular path expressions constitute core constructs\nwidely used in programming languages and type systems. Nevertheless, there has\nbeen little research so far on reasoning frameworks for path expressions where\nnode cardinality constraints occur along a path in a tree. We present a logic\ncapable of expressing deep counting along paths which may include arbitrary\nrecursive forward and backward navigation. The counting extensions can be seen\nas a generalization of graded modalities that count immediate successor nodes.\nWhile the combination of graded modalities, nominals, and inverse modalities\nyields undecidable logics over graphs, we show that these features can be\ncombined in a tree logic decidable in exponential time."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(2:5)2010", 
    "link": "http://arxiv.org/pdf/1005.5648v2", 
    "title": "Transforming Outermost into Context-Sensitive Rewriting", 
    "arxiv-id": "1005.5648v2", 
    "author": "Dimitri Hendriks", 
    "publish": "2010-05-31T09:57:45Z", 
    "summary": "We define two transformations from term rewriting systems (TRSs) to\ncontext-sensitive TRSs in such a way that termination of the target system\nimplies outermost termination of the original system. In the transformation\nbased on 'context extension', each outermost rewrite step is modeled by exactly\none step in the transformed system. This transformation turns out to be\ncomplete for the class of left-linear TRSs. The second transformation is called\n`dynamic labeling' and results in smaller sized context-sensitive TRSs. Here\neach modeled step is adjoined with a small number of auxiliary steps. As a\nresult state-of-the-art termination methods for context-sensitive rewriting\nbecome available for proving termination of outermost rewriting. Both\ntransformations have been implemented in Jambox, making it the most successful\ntool in the category of outermost rewriting of the last edition of the annual\ntermination competition."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(2:5)2010", 
    "link": "http://arxiv.org/pdf/1005.5662v1", 
    "title": "On the contribution of backward jumps to instruction sequence   expressiveness", 
    "arxiv-id": "1005.5662v1", 
    "author": "Inge Bethke", 
    "publish": "2010-05-31T11:46:43Z", 
    "summary": "We investigate the expressiveness of backward jumps in a framework of\nformalized sequential programming called program algebra. We show that - if\nexpressiveness is measured in terms of the computability of partial Boolean\nfunctions - then backward jumps are superfluous. If we, however, want to\nprevent explosion of the length of programs, then backward jumps are essential."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.24.9", 
    "link": "http://arxiv.org/pdf/1006.0395v1", 
    "title": "Computation with Advice", 
    "arxiv-id": "1006.0395v1", 
    "author": "Arno Pauly", 
    "publish": "2010-06-02T14:30:13Z", 
    "summary": "Computation with advice is suggested as generalization of both computation\nwith discrete advice and Type-2 Nondeterminism. Several embodiments of the\ngeneric concept are discussed, and the close connection to Weihrauch\nreducibility is pointed out. As a novel concept, computability with random\nadvice is studied; which corresponds to correct solutions being guessable with\npositive probability. In the framework of computation with advice, it is\npossible to define computational complexity for certain concepts of\nhypercomputation. Finally, some examples are given which illuminate the\ninterplay of uniform and non-uniform techniques in order to investigate both\ncomputability with advice and the Weihrauch lattice."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.24.10", 
    "link": "http://arxiv.org/pdf/1006.0396v1", 
    "title": "The Cardinality of an Oracle in Blum-Shub-Smale Computation", 
    "arxiv-id": "1006.0396v1", 
    "author": "Russell Miller", 
    "publish": "2010-06-02T14:30:17Z", 
    "summary": "We examine the relation of BSS-reducibility on subsets of the real numbers.\nThe question was asked recently (and anonymously) whether it is possible for\nthe halting problem H in BSS-computation to be BSS-reducible to a countable\nset. Intuitively, it seems that a countable set ought not to contain enough\ninformation to decide membership in a reasonably complex (uncountable) set such\nas H. We confirm this intuition, and prove a more general theorem linking the\ncardinality of the oracle set to the cardinality, in a local sense, of the set\nwhich it computes. We also mention other recent results on BSS-computation and\nalgebraic real numbers."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(3:8)2010", 
    "link": "http://arxiv.org/pdf/1006.0706v3", 
    "title": "Termination of Rewriting with Right-Flat Rules Modulo Permutative   Theories", 
    "arxiv-id": "1006.0706v3", 
    "author": "Ashish Tiwari", 
    "publish": "2010-06-03T17:46:20Z", 
    "summary": "We present decidability results for termination of classes of term rewriting\nsystems modulo permutative theories. Termination and innermost termination\nmodulo permutative theories are shown to be decidable for term rewrite systems\n(TRS) whose right-hand side terms are restricted to be shallow (variables occur\nat depth at most one) and linear (each variable occurs at most once). Innermost\ntermination modulo permutative theories is also shown to be decidable for\nshallow TRS. We first show that a shallow TRS can be transformed into a flat\n(only variables and constants occur at depth one) TRS while preserving\ntermination and innermost termination. The decidability results are then proved\nby showing that (a) for right-flat right-linear (flat) TRS, non-termination\n(respectively, innermost non-termination) implies non-termination starting from\nflat terms, and (b) for right-flat TRS, the existence of non-terminating\nderivations starting from a given term is decidable. On the negative side, we\nshow PSPACE-hardness of termination and innermost termination for shallow\nright-linear TRS, and undecidability of termination for flat TRS."
},{
    "category": "cs.LO", 
    "doi": "10.5121/ijmit.2010.2203", 
    "link": "http://arxiv.org/pdf/1006.0880v1", 
    "title": "Expressiveness of a Provenance-Enabled Authorization Logic", 
    "arxiv-id": "1006.0880v1", 
    "author": "Jinwei Hu", 
    "publish": "2010-06-04T12:42:09Z", 
    "summary": "In distributed environments, access control decisions depend on statements of\nmultiple agents rather than only one central trusted party. However, existing\npolicy languages put few emphasis on authorization provenances. The capability\nof managing these provenances is important and useful in various security areas\nsuch as computer auditing and authorization recycling. Based on our previously\nproposed logic, we present several case studies of this logic. By doing this,\nwe show its expressiveness and usefulness in security arena."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.25.11", 
    "link": "http://arxiv.org/pdf/1006.1408v1", 
    "title": "Exploiting the Temporal Logic Hierarchy and the Non-Confluence Property   for Efficient LTL Synthesis", 
    "arxiv-id": "1006.1408v1", 
    "author": "Klaus Schneider", 
    "publish": "2010-06-08T00:42:53Z", 
    "summary": "The classic approaches to synthesize a reactive system from a linear temporal\nlogic (LTL) specification first translate the given LTL formula to an\nequivalent omega-automaton and then compute a winning strategy for the\ncorresponding omega-regular game. To this end, the obtained omega-automata have\nto be (pseudo)-determinized where typically a variant of Safra's\ndeterminization procedure is used. In this paper, we show that this\ndeterminization step can be significantly improved for tool implementations by\nreplacing Safra's determinization by simpler determinization procedures. In\nparticular, we exploit (1) the temporal logic hierarchy that corresponds to the\nwell-known automata hierarchy consisting of safety, liveness, Buechi, and\nco-Buechi automata as well as their boolean closures, (2) the non-confluence\nproperty of omega-automata that result from certain translations of LTL\nformulas, and (3) symbolic implementations of determinization procedures for\nthe Rabin-Scott and the Miyano-Hayashi breakpoint construction. In particular,\nwe present convincing experimental results that demonstrate the practical\napplicability of our new synthesis procedure."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.25.19", 
    "link": "http://arxiv.org/pdf/1006.1412v1", 
    "title": "On the Expressiveness of Markovian Process Calculi with Durational and   Durationless Actions", 
    "arxiv-id": "1006.1412v1", 
    "author": "Marco Bernardo", 
    "publish": "2010-06-08T00:43:19Z", 
    "summary": "Several Markovian process calculi have been proposed in the literature, which\ndiffer from each other for various aspects. With regard to the action\nrepresentation, we distinguish between integrated-time Markovian process\ncalculi, in which every action has an exponentially distributed duration\nassociated with it, and orthogonal-time Markovian process calculi, in which\naction execution is separated from time passing. Similar to deterministically\ntimed process calculi, we show that these two options are not irreconcilable by\nexhibiting three mappings from an integrated-time Markovian process calculus to\nan orthogonal-time Markovian process calculus that preserve the behavioral\nequivalence of process terms under different interpretations of action\nexecution: eagerness, laziness, and maximal progress. The mappings are limited\nto classes of process terms of the integrated-time Markovian process calculus\nwith restrictions on parallel composition and do not involve the full\ncapability of the orthogonal-time Markovian process calculus of expressing\nnondeterministic choices, thus elucidating the only two important differences\nbetween the two calculi: their synchronization disciplines and their ways of\nsolving choices."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.25.17", 
    "link": "http://arxiv.org/pdf/1006.1416v1", 
    "title": "Efficient Symmetry Reduction and the Use of State Symmetries for   Symbolic Model Checking", 
    "arxiv-id": "1006.1416v1", 
    "author": "Christian Appold", 
    "publish": "2010-06-08T00:45:07Z", 
    "summary": "One technique to reduce the state-space explosion problem in temporal logic\nmodel checking is symmetry reduction. The combination of symmetry reduction and\nsymbolic model checking by using BDDs suffered a long time from the\nprohibitively large BDD for the orbit relation. Dynamic symmetry reduction\ncalculates representatives of equivalence classes of states dynamically and\nthus avoids the construction of the orbit relation. In this paper, we present a\nnew efficient model checking algorithm based on dynamic symmetry reduction. Our\nexperiments show that the algorithm is very fast and allows the verification of\nlarger systems. We additionally implemented the use of state symmetries for\nsymbolic symmetry reduction. To our knowledge we are the first who investigated\nstate symmetries in combination with BDD based symbolic model checking."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.26.7", 
    "link": "http://arxiv.org/pdf/1006.1430v1", 
    "title": "Equilibrium and Termination", 
    "arxiv-id": "1006.1430v1", 
    "author": "Nicolas Oury", 
    "publish": "2010-06-08T01:16:36Z", 
    "summary": "We present a reduction of the termination problem for a Turing machine (in\nthe simplified form of the Post correspondence problem) to the problem of\ndetermining whether a continuous-time Markov chain presented as a set of Kappa\ngraph-rewriting rules has an equilibrium. It follows that the problem of\nwhether a computable CTMC is dissipative (ie does not have an equilibrium) is\nundecidable."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.26.12", 
    "link": "http://arxiv.org/pdf/1006.1432v1", 
    "title": "The space of measurement outcomes as a spectrum for non-commutative   algebras", 
    "arxiv-id": "1006.1432v1", 
    "author": "Bas Spitters", 
    "publish": "2010-06-08T01:16:45Z", 
    "summary": "Bohrification defines a locale of hidden variables internal in a topos. We\nfind that externally this is the space of partial measurement outcomes. By\nconsidering the double negation sheafification, we obtain the space of\nmeasurement outcomes which coincides with the spectrum for commutative\nC*-algebras."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.26.14", 
    "link": "http://arxiv.org/pdf/1006.1433v1", 
    "title": "Semantics of a Typed Algebraic Lambda-Calculus", 
    "arxiv-id": "1006.1433v1", 
    "author": "Beno\u00eet Valiron", 
    "publish": "2010-06-08T01:16:56Z", 
    "summary": "Algebraic lambda-calculi have been studied in various ways, but their\nsemantics remain mostly untouched. In this paper we propose a semantic analysis\nof a general simply-typed lambda-calculus endowed with a structure of vector\nspace. We sketch the relation with two established vectorial lambda-calculi.\nThen we study the problems arising from the addition of a fixed point\ncombinator and how to modify the equational theory to solve them. We sketch an\nalgebraic vectorial PCF and its possible denotational interpretations."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-15375-4_19", 
    "link": "http://arxiv.org/pdf/1006.1492v1", 
    "title": "Mean-payoff Automaton Expressions", 
    "arxiv-id": "1006.1492v1", 
    "author": "Philippe Rannou", 
    "publish": "2010-06-08T09:11:28Z", 
    "summary": "Quantitative languages are an extension of boolean languages that assign to\neach word a real number. Mean-payoff automata are finite automata with\nnumerical weights on transitions that assign to each infinite path the long-run\naverage of the transition weights. When the mode of branching of the automaton\nis deterministic, nondeterministic, or alternating, the corresponding class of\nquantitative languages is not robust as it is not closed under the pointwise\noperations of max, min, sum, and numerical complement. Nondeterministic and\nalternating mean-payoff automata are not decidable either, as the quantitative\ngeneralization of the problems of universality and language inclusion is\nundecidable.\n  We introduce a new class of quantitative languages, defined by mean-payoff\nautomaton expressions, which is robust and decidable: it is closed under the\nfour pointwise operations, and we show that all decision problems are decidable\nfor this class. Mean-payoff automaton expressions subsume deterministic\nmean-payoff automata, and we show that they have expressive power incomparable\nto nondeterministic and alternating mean-payoff automata. We also present for\nthe first time an algorithm to compute distance between two quantitative\nlanguages, and in our case the quantitative languages are given as mean-payoff\nautomaton expressions."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-15375-4_19", 
    "link": "http://arxiv.org/pdf/1006.2283v1", 
    "title": "The duality of computation under focus", 
    "arxiv-id": "1006.2283v1", 
    "author": "Guillaume Munch-Maccagnoni", 
    "publish": "2010-06-11T12:44:00Z", 
    "summary": "We review the close relationship between abstract machines for (call-by-name\nor call-by-value) lambda-calculi (extended with Felleisen's C) and sequent\ncalculus, reintroducing on the way Curien-Herbelin's syntactic kit expressing\nthe duality of computation. We use this kit to provide a term language for a\npresentation of LK (with conjunction, disjunction, and negation), and to\ntranscribe cut elimination as (non confluent) rewriting. A key slogan here,\nwhich may appear here in print for the first time, is that commutative cut\nelimination rules are explicit substitution propagation rules. We then describe\nthe focalised proof search discipline (in the classical setting), and narrow\ndown the language and the rewriting rules to a confluent calculus (a variant of\nthe second author's focalising system L). We then define a game of patterns and\ncounterpatterns, leading us to a fully focalised finitary syntax for a\nsynthetic presentation of classical logic, that provides a quotient on\n(focalised) proofs, abstracting out the order of decomposition of negative\nconnectives."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-15375-4_19", 
    "link": "http://arxiv.org/pdf/1006.2772v1", 
    "title": "Controlling program extraction in Elementary Linear Logic", 
    "arxiv-id": "1006.2772v1", 
    "author": "Marc Lasson", 
    "publish": "2010-06-14T17:01:15Z", 
    "summary": "We present an adaptation, based on program extraction in elementary linear\nlogic, of Krivine & Leivant's system FA_2. This system allows to write\nhigher-order equations in order to specify the computational content of\nextracted programs. The user can then prove a generic formula, using these\nequations as axioms, whose proof can be extracted into programs that normalize\nin elementary time and satisfy the specifications. Finally, we show that every\nelementary recursive functions can be implemented in this system."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-15375-4_19", 
    "link": "http://arxiv.org/pdf/1006.2867v2", 
    "title": "Internalized realizability in pure type systems", 
    "arxiv-id": "1006.2867v2", 
    "author": "Marc Lasson", 
    "publish": "2010-06-15T00:27:17Z", 
    "summary": "Let P be any pure type system, we are going to show how we can extend P into\na PTS P' which will be used as a proof system whose formulas express properties\nabout sets of terms of P. We will show that P' is strongly normalizable if and\nonly if P is. Given a term t in P and a formula F in P', P' is expressive\nenough to construct a formula \"t ||- F\" that is interpreted as \"t is a realizer\nof F\". We then prove the following adequacy theorem: if F is provable then by\nprojecting its proof back to a term t in P we obtain a proof that \"t ||- F\"."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-15375-4_19", 
    "link": "http://arxiv.org/pdf/1006.2921v1", 
    "title": "Instantiation of SMT problems modulo Integers", 
    "arxiv-id": "1006.2921v1", 
    "author": "Nicolas Peltier", 
    "publish": "2010-06-15T08:11:39Z", 
    "summary": "Many decision procedures for SMT problems rely more or less implicitly on an\ninstantiation of the axioms of the theories under consideration, and differ by\nmaking use of the additional properties of each theory, in order to increase\nefficiency. We present a new technique for devising complete instantiation\nschemes on SMT problems over a combination of linear arithmetic with another\ntheory T. The method consists in first instantiating the arithmetic part of the\nformula, and then getting rid of the remaining variables in the problem by\nusing an instantiation strategy which is complete for T. We provide examples\nevidencing that not only is this technique generic (in the sense that it\napplies to a wide range of theories) but it is also efficient, even compared to\nstate-of-the-art instantiation schemes for specific theories."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-15375-4_19", 
    "link": "http://arxiv.org/pdf/1006.3134v1", 
    "title": "Classical and Intuitionistic Subexponential Logics are Equally   Expressive", 
    "arxiv-id": "1006.3134v1", 
    "author": "Kaustuv Chaudhuri", 
    "publish": "2010-06-16T06:00:23Z", 
    "summary": "It is standard to regard the intuitionistic restriction of a classical logic\nas increasing the expressivity of the logic because the classical logic can be\nadequately represented in the intuitionistic logic by double-negation, while\nthe other direction has no truth-preserving propositional encodings. We show\nhere that subexponential logic, which is a family of substructural refinements\nof classical logic, each parametric over a preorder over the subexponential\nconnectives, does not suffer from this asymmetry if the preorder is\nsystematically modified as part of the encoding. Precisely, we show a bijection\nbetween synthetic (i.e., focused) partial sequent derivations modulo a given\nencoding. Particular instances of our encoding for particular subexponential\npreorders give rise to both known and novel adequacy theorems for substructural\nlogics."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-16242-8_6", 
    "link": "http://arxiv.org/pdf/1006.3709v1", 
    "title": "Extended Computation Tree Logic", 
    "arxiv-id": "1006.3709v1", 
    "author": "Markus Latte", 
    "publish": "2010-06-18T14:38:18Z", 
    "summary": "We introduce a generic extension of the popular branching-time logic CTL\nwhich refines the temporal until and release operators with formal languages.\nFor instance, a language may determine the moments along a path that an until\nproperty may be fulfilled. We consider several classes of languages leading to\nlogics with different expressive power and complexity, whose importance is\nmotivated by their use in model checking, synthesis, abstract interpretation,\netc.\n  We show that even with context-free languages on the until operator the logic\nstill allows for polynomial time model-checking despite the significant\nincrease in expressive power. This makes the logic a promising candidate for\napplications in verification.\n  In addition, we analyse the complexity of satisfiability and compare the\nexpressive power of these logics to CTL* and extensions of PDL."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-16242-8_6", 
    "link": "http://arxiv.org/pdf/1006.4621v1", 
    "title": "The Question of Expressiveness in the Generation of Referring   Expressions", 
    "arxiv-id": "1006.4621v1", 
    "author": "Daniel Gor\u00edn", 
    "publish": "2010-06-23T19:30:52Z", 
    "summary": "We study the problem of generating referring expressions modulo different\nnotions of expressive power. We define the notion of $\\+L$-referring\nexpression, for a formal language $\\+L$ equipped with a semantics in terms of\nrelational models. We show that the approach is independent of the particular\nalgorithm used to generate the referring expression by providing examples using\nthe frameworks of \\cite{AKS08} and \\cite{Krahmer2003}. We provide some new\ncomplexity bounds, discuss the issue of the length of the generated\ndescriptions, and propose ways in which the two approaches can be combined."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-16242-8_6", 
    "link": "http://arxiv.org/pdf/1006.4793v2", 
    "title": "Cut-Elimination and Proof Search for Bi-Intuitionistic Tense Logic", 
    "arxiv-id": "1006.4793v2", 
    "author": "Alwen Tiu", 
    "publish": "2010-06-24T13:51:34Z", 
    "summary": "We consider an extension of bi-intuitionistic logic with the traditional\nmodalities from tense logic Kt. Proof theoretically, this extension is obtained\nsimply by extending an existing sequent calculus for bi-intuitionistic logic\nwith typical inference rules for the modalities used in display logics. As it\nturns out, the resulting calculus, LBiKt, seems to be more basic than most\nintuitionistic tense or modal logics considered in the literature, in\nparticular, those studied by Ewald and Simpson, as it does not assume any a\npriori relationship between the diamond and the box modal operators. We recover\nEwald's intuitionistic tense logic and Simpson's intuitionistic modal logic by\nmodularly extending LBiKt with additional structural rules. The calculus LBiKt\nis formulated in a variant of display calculus, using a form of sequents called\nnested sequents. Cut elimination is proved for LBiKt, using a technique similar\nto that used in display calculi. As in display calculi, the inference rules of\nLBiKt are ``shallow'' rules, in the sense that they act on top-level formulae\nin a nested sequent. The calculus LBiKt is ill-suited for backward proof search\ndue to the presence of certain structural rules called ``display postulates''\nand the contraction rules on arbitrary structures. We show that these\nstructural rules can be made redundant in another calculus, DBiKt, which uses\ndeep inference, allowing one to apply inference rules at an arbitrary depth in\na nested sequent. We prove the equivalence between LBiKt and DBiKt and outline\na proof search strategy for DBiKt. We also give a Kripke semantics and prove\nthat LBiKt is sound with respect to the semantics, but completeness is still an\nopen problem. We then discuss various extensions of LBiKt."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(3:20)2010", 
    "link": "http://arxiv.org/pdf/1006.4955v2", 
    "title": "Local Termination: theory and practice", 
    "arxiv-id": "1006.4955v2", 
    "author": "Johannes Waldmann", 
    "publish": "2010-06-25T10:30:09Z", 
    "summary": "The characterisation of termination using well-founded monotone algebras has\nbeen a milestone on the way to automated termination techniques, of which we\nhave seen an extensive development over the past years. Both the semantic\ncharacterisation and most known termination methods are concerned with global\ntermination, uniformly of all the terms of a term rewriting system (TRS). In\nthis paper we consider local termination, of specific sets of terms within a\ngiven TRS. The principal goal of this paper is generalising the semantic\ncharacterisation of global termination to local termination. This is made\npossible by admitting the well-founded monotone algebras to be partial. We also\nextend our approach to local relative termination. The interest in local\ntermination naturally arises in program verification, where one is probably\ninterested only in sensible inputs, or just wants to characterise the set of\ninputs for which a program terminates. Local termination will be also be of\ninterest when dealing with a specific class of terms within a TRS that is known\nto be non-terminating, such as combinatory logic (CL) or a TRS encoding\nrecursive program schemes or Turing machines. We show how some of the\nwell-known techniques for proving global termination, such as stepwise removal\nof rewrite rules and semantic labelling, can be adapted to the local case. We\nalso describe transformations reducing local to global termination problems.\nThe resulting techniques for proving local termination have in some cases\nalready been automated. One of our applications concerns the characterisation\nof the terminating S-terms in CL as regular language. Previously this language\nhad already been found via a tedious analysis of the reduction behaviour of\nS-terms. These findings have now been vindicated by a fully automated and\nverified proof."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.28.1", 
    "link": "http://arxiv.org/pdf/1006.5094v1", 
    "title": "Approximate Testing Equivalence Based on Time, Probability, and Observed   Behavior", 
    "arxiv-id": "1006.5094v1", 
    "author": "Alessandro Aldini", 
    "publish": "2010-06-26T03:02:59Z", 
    "summary": "Several application domains require formal but flexible approaches to the\ncomparison problem. Different process models that cannot be related by\nbehavioral equivalences should be compared via a quantitative notion of\nsimilarity, which is usually achieved through approximation of some\nequivalence. While in the literature the classical equivalence subject to\napproximation is bisimulation, in this paper we propose a novel approach based\non testing equivalence. As a step towards flexibility and usability, we study\ndifferent relaxations taking into account orthogonal aspects of the process\nobservations: execution time, event probability, and observed behavior. In this\nunifying framework, both interpretation of the measures and decidability of the\nverification algorithms are discussed."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.28.7", 
    "link": "http://arxiv.org/pdf/1006.5100v1", 
    "title": "Testing Reactive Probabilistic Processes", 
    "arxiv-id": "1006.5100v1", 
    "author": "Suzana Andova", 
    "publish": "2010-06-26T03:03:32Z", 
    "summary": "We define a testing equivalence in the spirit of De Nicola and Hennessy for\nreactive probabilistic processes, i.e. for processes where the internal\nnondeterminism is due to random behaviour. We characterize the testing\nequivalence in terms of ready-traces. From the characterization it follows that\nthe equivalence is insensitive to the exact moment in time in which an internal\nprobabilistic choice occurs, which is inherent from the original testing\nequivalence of De Nicola and Hennessy. We also show decidability of the testing\nequivalence for finite systems for which the complete model may not be known."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.28.8", 
    "link": "http://arxiv.org/pdf/1006.5101v1", 
    "title": "Probabilistic Model-Based Safety Analysis", 
    "arxiv-id": "1006.5101v1", 
    "author": "Frank Ortmeier", 
    "publish": "2010-06-26T03:03:37Z", 
    "summary": "Model-based safety analysis approaches aim at finding critical failure\ncombinations by analysis of models of the whole system (i.e. software,\nhardware, failure modes and environment). The advantage of these methods\ncompared to traditional approaches is that the analysis of the whole system\ngives more precise results. Only few model-based approaches have been applied\nto answer quantitative questions in safety analysis, often limited to analysis\nof specific failure propagation models, limited types of failure modes or\nwithout system dynamics and behavior, as direct quantitative analysis is uses\nlarge amounts of computing resources. New achievements in the domain of\n(probabilistic) model-checking now allow for overcoming this problem.\n  This paper shows how functional models based on synchronous parallel\nsemantics, which can be used for system design, implementation and qualitative\nsafety analysis, can be directly re-used for (model-based) quantitative safety\nanalysis. Accurate modeling of different types of probabilistic failure\noccurrence is shown as well as accurate interpretation of the results of the\nanalysis. This allows for reliable and expressive assessment of the safety of a\nsystem in early design stages."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.28.9", 
    "link": "http://arxiv.org/pdf/1006.5102v1", 
    "title": "An expectation transformer approach to predicate abstraction and data   independence for probabilistic programs", 
    "arxiv-id": "1006.5102v1", 
    "author": "Annabelle McIver", 
    "publish": "2010-06-26T03:03:45Z", 
    "summary": "In this paper we revisit the well-known technique of predicate abstraction to\ncharacterise performance attributes of system models incorporating probability.\nWe recast the theory using expectation transformers, and identify transformer\nproperties which correspond to abstractions that yield nevertheless exact bound\non the performance of infinite state probabilistic systems. In addition, we\nextend the developed technique to the special case of \"data independent\"\nprograms incorporating probability. Finally, we demonstrate the subtleness of\nthe extended technique by using the PRISM model checking tool to analyse an\ninfinite state protocol, obtaining exact bounds on its performance."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(3:9)2010", 
    "link": "http://arxiv.org/pdf/1006.5561v2", 
    "title": "Domain Representable Spaces Defined by Strictly Positive Induction", 
    "arxiv-id": "1006.5561v2", 
    "author": "Petter Kristian K\u00f8ber", 
    "publish": "2010-06-29T10:40:29Z", 
    "summary": "Recursive domain equations have natural solutions. In particular there are\ndomains defined by strictly positive induction. The class of countably based\ndomains gives a computability theory for possibly non-countably based\ntopological spaces. A $ qcb_{0} $ space is a topological space characterized by\nits strong representability over domains. In this paper, we study strictly\npositive inductive definitions for $ qcb_{0} $ spaces by means of domain\nrepresentations, i.e. we show that there exists a canonical fixed point of\nevery strictly positive operation on $qcb_{0} $ spaces."
},{
    "category": "cs.LO", 
    "doi": "10.1017/S0960129511000132", 
    "link": "http://arxiv.org/pdf/1008.1213v2", 
    "title": "Classical Mathematics for a Constructive World", 
    "arxiv-id": "1008.1213v2", 
    "author": "Russell O'Connor", 
    "publish": "2010-08-03T15:42:42Z", 
    "summary": "Interactive theorem provers based on dependent type theory have the\nflexibility to support both constructive and classical reasoning. Constructive\nreasoning is supported natively by dependent type theory and classical\nreasoning is typically supported by adding additional non-constructive axioms.\nHowever, there is another perspective that views constructive logic as an\nextension of classical logic. This paper will illustrate how classical\nreasoning can be supported in a practical manner inside dependent type theory\nwithout additional axioms. We will see several examples of how classical\nresults can be applied to constructive mathematics. Finally, we will see how to\nextend this perspective from logic to mathematics by representing classical\nfunction spaces using a weak value monad."
},{
    "category": "cs.LO", 
    "doi": "10.1017/S0960129511000132", 
    "link": "http://arxiv.org/pdf/1008.1809v1", 
    "title": "Symmetry-breaking Answer Set Solving", 
    "arxiv-id": "1008.1809v1", 
    "author": "Toby Walsh", 
    "publish": "2010-08-10T21:29:13Z", 
    "summary": "In the context of Answer Set Programming, this paper investigates\nsymmetry-breaking to eliminate symmetric parts of the search space and,\nthereby, simplify the solution process. We propose a reduction of disjunctive\nlogic programs to a coloured digraph such that permutational symmetries can be\nconstructed from graph automorphisms. Symmetries are then broken by introducing\nsymmetry-breaking constraints. For this purpose, we formulate a preprocessor\nthat integrates a graph automorphism system. Experiments demonstrate its\ncomputational impact."
},{
    "category": "cs.LO", 
    "doi": "10.1017/S0960129511000132", 
    "link": "http://arxiv.org/pdf/1008.2021v1", 
    "title": "A Single-Instance Incremental SAT Formulation of Proof- and   Counterexample-Based Abstraction", 
    "arxiv-id": "1008.2021v1", 
    "author": "Nina Amla", 
    "publish": "2010-08-11T22:10:46Z", 
    "summary": "This paper presents an efficient, combined formulation of two widely used\nabstraction methods for bit-level verification: counterexample-based\nabstraction (CBA) and proof-based abstraction (PBA). Unlike previous work, this\nnew method is formulated as a single, incremental SAT-problem, interleaving CBA\nand PBA to develop the abstraction in a bottom-up fashion. It is argued that\nthe new method is simpler conceptually and implementation-wise than previous\napproaches. As an added bonus, proof-logging is not required for the PBA part,\nwhich allows for a wider set of SAT-solvers to be used."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.32.2", 
    "link": "http://arxiv.org/pdf/1008.2109v1", 
    "title": "Congruence from the Operator's Point of View: Compositionality   Requirements on Process Semantics", 
    "arxiv-id": "1008.2109v1", 
    "author": "Wan Fokkink", 
    "publish": "2010-08-12T13:42:26Z", 
    "summary": "One of the basic sanity properties of a behavioural semantics is that it\nconstitutes a congruence with respect to standard process operators. This issue\nhas been traditionally addressed by the development of rule formats for\ntransition system specifications that define process algebras. In this paper we\nsuggest a novel, orthogonal approach. Namely, we focus on a number of process\noperators, and for each of them attempt to find the widest possible class of\ncongruences. To this end, we impose restrictions on sublanguages of\nHennessy-Milner logic, so that a semantics whose modal characterization\nsatisfies a given criterion is guaranteed to be a congruence with respect to\nthe operator in question. We investigate action prefix, alternative\ncomposition, two restriction operators, and parallel composition."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.32.3", 
    "link": "http://arxiv.org/pdf/1008.2111v1", 
    "title": "Structural Decomposition of Reactions of Graph-Like Objects", 
    "arxiv-id": "1008.2111v1", 
    "author": "Tobias Heindel", 
    "publish": "2010-08-12T13:42:44Z", 
    "summary": "Inspired by decomposition problems in rule-based formalisms in Computational\nSystems Biology and recent work on compositionality in graph transformation,\nthis paper proposes to use arbitrary colimits to \"deconstruct\" models of\nreactions in which states are represented as objects of adhesive categories.\nThe fundamental problem is the decomposition of complex reactions of large\nstates into simpler reactions of smaller states.\n  The paper defines the local decomposition problem for transformations. To\nsolve this problem means to \"reconstruct\" a given transformation as the colimit\nof \"smaller\" ones where the shape of the colimit and the decomposition of the\nsource object of the transformation are fixed in advance. The first result is\nthe soundness of colimit decomposition for arbitrary double pushout\ntransformations in any category, which roughly means that several \"local\"\ntransformations can be combined into a single \"global\" one. Moreover, a\nsolution for a certain class of local decomposition problems is given, which\ngeneralizes and clarifies recent work on compositionality in graph\ntransformation."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.32.3", 
    "link": "http://arxiv.org/pdf/1008.5029v1", 
    "title": "Reformulation of Global Constraints in Answer Set Programming", 
    "arxiv-id": "1008.5029v1", 
    "author": "Toby Walsh", 
    "publish": "2010-08-30T09:21:53Z", 
    "summary": "We show that global constraints on finite domains like all-different can be\nreformulated into answer set programs on which we achieve arc, bound or range\nconsistency. These reformulations offer a number of other advantages beyond\nproviding the power of global propagators to answer set programming. For\nexample, they provide other constraints with access to the state of the\npropagator by sharing variables. Such sharing can be used to improve\npropagation between constraints. Experiments with these encodings demonstrate\ntheir promise."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.32.3", 
    "link": "http://arxiv.org/pdf/1008.5033v1", 
    "title": "Symmetry Breaking for Answer Set Programming", 
    "arxiv-id": "1008.5033v1", 
    "author": "Christian Drescher", 
    "publish": "2010-08-30T09:45:14Z", 
    "summary": "In the context of answer set programming, this work investigates symmetry\ndetection and symmetry breaking to eliminate symmetric parts of the search\nspace and, thereby, simplify the solution process. We contribute a reduction of\nsymmetry detection to a graph automorphism problem which allows to extract\nsymmetries of a logic program from the symmetries of the constructed coloured\ngraph. We also propose an encoding of symmetry-breaking constraints in terms of\npermutation cycles and use only generators in this process which implicitly\nrepresent symmetries and always with exponential compression. These ideas are\nformulated as preprocessing and implemented in a completely automated flow that\nfirst detects symmetries from a given answer set program, adds\nsymmetry-breaking constraints, and can be applied to any existing answer set\nsolver. We demonstrate computational impact on benchmarks versus direct\napplication of the solver.\n  Furthermore, we explore symmetry breaking for answer set programming in two\ndomains: first, constraint answer set programming as a novel approach to\nrepresent and solve constraint satisfaction problems, and second, distributed\nnonmonotonic multi-context systems. In particular, we formulate a\ntranslation-based approach to constraint answer set solving which allows for\nthe application of our symmetry detection and symmetry breaking methods. To\ncompare their performance with a-priori symmetry breaking techniques, we also\ncontribute a decomposition of the global value precedence constraint that\nenforces domain consistency on the original constraint via the unit-propagation\nof an answer set solver. We evaluate both options in an empirical analysis. In\nthe context of distributed nonmonotonic multi-context system, we develop an\nalgorithm for distributed symmetry detection and also carry over\nsymmetry-breaking constraints for distributed answer set programming."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(3:22)2010", 
    "link": "http://arxiv.org/pdf/1009.1076v2", 
    "title": "The General Vector Addition System Reachability Problem by Presburger   Inductive Invariants", 
    "arxiv-id": "1009.1076v2", 
    "author": "leroux jerome", 
    "publish": "2010-09-06T15:08:07Z", 
    "summary": "The reachability problem for Vector Addition Systems (VASs) is a central\nproblem of net theory. The general problem is known to be decidable by\nalgorithms exclusively based on the classical\nKosaraju-Lambert-Mayr-Sacerdote-Tenney decomposition. This decomposition is\nused in this paper to prove that the Parikh images of languages recognized by\nVASs are semi-pseudo-linear; a class that extends the semi-linear sets, a.k.a.\nthe sets definable in Presburger arithmetic. We provide an application of this\nresult; we prove that a final configuration is not reachable from an initial\none if and only if there exists a semi-linear inductive invariant that contains\nthe initial configuration but not the final one. Since we can decide if a\nPresburger formula denotes an inductive invariant, we deduce that there exist\ncheckable certificates of non-reachability. In particular, there exists a\nsimple algorithm for deciding the general VAS reachability problem based on two\nsemi-algorithms. A first one that tries to prove the reachability by\nenumerating finite sequences of actions and a second one that tries to prove\nthe non-reachability by enumerating Presburger formulas."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(3:22)2010", 
    "link": "http://arxiv.org/pdf/1009.2259v1", 
    "title": "Theory of processes", 
    "arxiv-id": "1009.2259v1", 
    "author": "Andrew M. Mironov", 
    "publish": "2010-09-12T19:11:05Z", 
    "summary": "The book gives a detailed exposition of basic concepts and results of a\ntheory of processes. The presentation of theoretical concepts and results is\naccompanied with illustrations of their application to solving various problems\nof verification of processes. Along with well-known results there are presented\nauthor's results related to verification of processes with message passing, and\nthere are given examples of an application of these results."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.34.4", 
    "link": "http://arxiv.org/pdf/1009.2790v1", 
    "title": "Generating Bijections between HOAS and the Natural Numbers", 
    "arxiv-id": "1009.2790v1", 
    "author": "John Tang Boyland", 
    "publish": "2010-09-14T21:33:30Z", 
    "summary": "A provably correct bijection between higher-order abstract syntax (HOAS) and\nthe natural numbers enables one to define a \"not equals\" relationship between\nterms and also to have an adequate encoding of sets of terms, and maps from one\nterm family to another. Sets and maps are useful in many situations and are\npreferably provided in a library of some sort. I have released a map and set\nlibrary for use with Twelf which can be used with any type for which a\nbijection to the natural numbers exists.\n  Since creating such bijections is tedious and error-prone, I have created a\n\"bijection generator\" that generates such bijections automatically together\nwith proofs of correctness, all in the context of Twelf."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.34.6", 
    "link": "http://arxiv.org/pdf/1009.2792v1", 
    "title": "Pure Type Systems without Explicit Contexts", 
    "arxiv-id": "1009.2792v1", 
    "author": "Freek Wiedijk", 
    "publish": "2010-09-14T21:33:39Z", 
    "summary": "We present an approach to type theory in which the typing judgments do not\nhave explicit contexts. Instead of judgments of shape \"Gamma |- A : B\", our\nsystems just have judgments of shape \"A : B\". A key feature is that we\ndistinguish free and bound variables even in pseudo-terms.\n  Specifically we give the rules of the \"Pure Type System\" class of type\ntheories in this style. We prove that the typing judgments of these systems\ncorrespond in a natural way with those of Pure Type Systems as traditionally\nformulated. I.e., our systems have exactly the same well-typed terms as\ntraditional presentations of type theory.\n  Our system can be seen as a type theory in which all type judgments share an\nidentical, infinite, typing context that has infinitely many variables for each\npossible type. For this reason we call our system \"Gamma_infinity\". This name\nmeans to suggest that our type judgment \"A : B\" should be read as\n\"Gamma_infinity |- A : B\", with a fixed infinite type context called\n\"Gamma_infinity\"."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.34.8", 
    "link": "http://arxiv.org/pdf/1009.2794v1", 
    "title": "Representing Isabelle in LF", 
    "arxiv-id": "1009.2794v1", 
    "author": "Florian Rabe", 
    "publish": "2010-09-14T21:33:49Z", 
    "summary": "LF has been designed and successfully used as a meta-logical framework to\nrepresent and reason about object logics. Here we design a representation of\nthe Isabelle logical framework in LF using the recently introduced module\nsystem for LF. The major novelty of our approach is that we can naturally\nrepresent the advanced Isabelle features of type classes and locales.\n  Our representation of type classes relies on a feature so far lacking in the\nLF module system: morphism variables and abstraction over them. While\nconservative over the present system in terms of expressivity, this feature is\nneeded for a representation of type classes that preserves the modular\nstructure. Therefore, we also design the necessary extension of the LF module\nsystem."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.34.9", 
    "link": "http://arxiv.org/pdf/1009.2795v1", 
    "title": "Pattern Unification for the Lambda Calculus with Linear and Affine Types", 
    "arxiv-id": "1009.2795v1", 
    "author": "Carsten Sch\u00fcrmann", 
    "publish": "2010-09-14T21:33:54Z", 
    "summary": "We define the pattern fragment for higher-order unification problems in\nlinear and affine type theory and give a deterministic unification algorithm\nthat computes most general unifiers."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(3:25)2010", 
    "link": "http://arxiv.org/pdf/1009.2893v2", 
    "title": "On Second-Order Monadic Monoidal and Groupoidal Quantifiers", 
    "arxiv-id": "1009.2893v2", 
    "author": "Heribert Vollmer", 
    "publish": "2010-09-15T10:30:50Z", 
    "summary": "We study logics defined in terms of second-order monadic monoidal and\ngroupoidal quantifiers. These are generalized quantifiers defined by monoid and\ngroupoid word-problems, equivalently, by regular and context-free languages. We\ngive a computational classification of the expressive power of these logics\nover strings with varying built-in predicates. In particular, we show that\nATIME(n) can be logically characterized in terms of second-order monadic\nmonoidal quantifiers."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(3:25)2010", 
    "link": "http://arxiv.org/pdf/1009.3391v3", 
    "title": "Fuzzy Ontology Representation using OWL 2", 
    "arxiv-id": "1009.3391v3", 
    "author": "Umberto Straccia", 
    "publish": "2010-09-17T10:30:14Z", 
    "summary": "The need to deal with vague information in Semantic Web languages is rising\nin importance and, thus, calls for a standard way to represent such\ninformation. We may address this issue by either extending current Semantic Web\nlanguages to cope with vagueness, or by providing a procedure to represent such\ninformation within current standard languages and tools. In this work, we\nfollow the latter approach, by identifying the syntactic differences that a\nfuzzy ontology language has to cope with, and by proposing a concrete\nmethodology to represent fuzzy ontologies using OWL 2 annotation properties. We\nalso report on the prototypical implementations."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(4:11)2010", 
    "link": "http://arxiv.org/pdf/1009.3429v3", 
    "title": "Semantics of Typed Lambda-Calculus with Constructors", 
    "arxiv-id": "1009.3429v3", 
    "author": "Barbara Petit", 
    "publish": "2010-09-17T14:09:12Z", 
    "summary": "We present a Curry-style second-order type system with union and intersection\ntypes for the lambda-calculus with constructors of Arbiser, Miquel and Rios, an\nextension of lambda-calculus with a pattern matching mechanism for variadic\nconstructors. We then prove the strong normalisation and the absence of match\nfailure for a restriction of this system, by adapting the standard reducibility\nmethod."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(4:11)2010", 
    "link": "http://arxiv.org/pdf/1009.3765v1", 
    "title": "A Test Automation Framework for Mercury", 
    "arxiv-id": "1009.3765v1", 
    "author": "Wim Vanhoof", 
    "publish": "2010-09-20T10:43:19Z", 
    "summary": "This paper presents a test automation framework for Mercury programs. We\ndeveloped a method that generates runnable Mercury code from a formalized test\nsuite, and which code provides a report on execution about the success of test\ncases. We also developed a coverage tool for the framework, which identifies\nand provide a visualization of the reached parts of the program when executing\na given test suite."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(4:11)2010", 
    "link": "http://arxiv.org/pdf/1009.3798v2", 
    "title": "DNF Sampling for ProbLog Inference", 
    "arxiv-id": "1009.3798v2", 
    "author": "Gerda Janssens", 
    "publish": "2010-09-20T12:45:09Z", 
    "summary": "Inference in probabilistic logic languages such as ProbLog, an extension of\nProlog with probabilistic facts, is often based on a reduction to a\npropositional formula in DNF. Calculating the probability of such a formula\ninvolves the disjoint-sum-problem, which is computationally hard. In this work\nwe introduce a new approximation method for ProbLog inference which exploits\nthe DNF to focus sampling. While this DNF sampling technique has been applied\nto a variety of tasks before, to the best of our knowledge it has not been used\nfor inference in probabilistic logic systems. The paper also presents an\nexperimental comparison with another sampling based inference method previously\nintroduced for ProbLog."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.36", 
    "link": "http://arxiv.org/pdf/1009.3982v1", 
    "title": "Proceedings First International Workshop on Rewriting Techniques for   Real-Time Systems", 
    "arxiv-id": "1009.3982v1", 
    "author": "Peter Csaba \u00d6lveczky", 
    "publish": "2010-09-21T02:19:53Z", 
    "summary": "This volume contains the proceedings of the First International Workshop on\nRewriting Techniques for Real-Time Systems (RTRTS 2010), held in Longyearbyen,\nSpitsbergen, on April 6-9, 2010.\n  The aim of the workshop is to bring together researchers with an interest in\nthe use of rewriting-based techniques (including rewriting logic) and tools for\nthe modeling, analysis, and/or implementation of real-time and hybrid systems,\nand to give them the opportunity to present their recent works, discuss future\nresearch directions, and exchange ideas. The topics of the workshop comprise,\nbut are not limited to: methods and tools supporting rewriting-based modeling\nand analysis of real-time and hybrid systems, and extensions of such systems;\nuse of rewriting techniques to provide rigorous support for model-based\nsoftware engineering of timed systems; applications and case studies; and\ncomparison with other formalisms and tools."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.36.7", 
    "link": "http://arxiv.org/pdf/1009.4264v1", 
    "title": "Model Checking Classes of Metric LTL Properties of Object-Oriented   Real-Time Maude Specifications", 
    "arxiv-id": "1009.4264v1", 
    "author": "Erika \u00c1brah\u00e1m", 
    "publish": "2010-09-22T04:02:44Z", 
    "summary": "This paper presents a transformational approach for model checking two\nimportant classes of metric temporal logic (MTL) properties, namely, bounded\nresponse and minimum separation, for nonhierarchical object-oriented Real-Time\nMaude specifications. We prove the correctness of our model checking\nalgorithms, which terminate under reasonable non-Zeno-ness assumptions when the\nreachable state space is finite. These new model checking features have been\nintegrated into Real-Time Maude, and are used to analyze a network of medical\ndevices and a 4-way traffic intersection system."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.36.8", 
    "link": "http://arxiv.org/pdf/1009.4265v1", 
    "title": "Specification and Verification of Distributed Embedded Systems: A   Traffic Intersection Product Family", 
    "arxiv-id": "1009.4265v1", 
    "author": "Jos\u00e9 Meseguer", 
    "publish": "2010-09-22T04:02:51Z", 
    "summary": "Distributed embedded systems (DESs) are no longer the exception; they are the\nrule in many application areas such as avionics, the automotive industry,\ntraffic systems, sensor networks, and medical devices. Formal DES specification\nand verification is challenging due to state space explosion and the need to\nsupport real-time features. This paper reports on an extensive industry-based\ncase study involving a DES product family for a pedestrian and car 4-way\ntraffic intersection in which autonomous devices communicate by asynchronous\nmessage passing without a centralized controller. All the safety requirements\nand a liveness requirement informally specified in the requirements document\nhave been formally verified using Real-Time Maude and its model checking\nfeatures."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(4:3)2010", 
    "link": "http://arxiv.org/pdf/1009.4400v2", 
    "title": "Game semantics for first-order logic", 
    "arxiv-id": "1009.4400v2", 
    "author": "Olivier Laurent", 
    "publish": "2010-09-22T15:59:53Z", 
    "summary": "We refine HO/N game semantics with an additional notion of pointer\n(mu-pointers) and extend it to first-order classical logic with completeness\nresults. We use a Church style extension of Parigot's lambda-mu-calculus to\nrepresent proofs of first-order classical logic. We present some relations with\nKrivine's classical realizability and applications to type isomorphisms."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.36.6", 
    "link": "http://arxiv.org/pdf/1009.4601v1", 
    "title": "Using the PALS Architecture to Verify a Distributed Topology Control   Protocol for Wireless Multi-Hop Networks in the Presence of Node Failures", 
    "arxiv-id": "1009.4601v1", 
    "author": "Jos\u00e9 Meseguer", 
    "publish": "2010-09-22T04:02:38Z", 
    "summary": "The PALS architecture reduces distributed, real-time asynchronous system\ndesign to the design of a synchronous system under reasonable requirements.\nAssuming logical synchrony leads to fewer system behaviors and provides a\nconceptually simpler paradigm for engineering purposes. One of the current\nlimitations of the framework is that from a set of independent \"synchronous\nmachines\", one must compose the entire synchronous system by hand, which is\ntedious and error-prone. We use Maude's meta-level to automatically generate a\nsynchronous composition from user-provided component machines and a description\nof how the machines communicate with each other. We then use the new\ncapabilities to verify the correctness of a distributed topology control\nprotocol for wireless networks in the presence of nodes that may fail."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(4:9)2010", 
    "link": "http://arxiv.org/pdf/1009.5206v2", 
    "title": "The complexity of linear-time temporal logic over the class of ordinals", 
    "arxiv-id": "1009.5206v2", 
    "author": "Alexander Rabinovich", 
    "publish": "2010-09-27T09:58:46Z", 
    "summary": "We consider the temporal logic with since and until modalities. This temporal\nlogic is expressively equivalent over the class of ordinals to first-order\nlogic by Kamp's theorem. We show that it has a PSPACE-complete satisfiability\nproblem over the class of ordinals. Among the consequences of our proof, we\nshow that given the code of some countable ordinal alpha and a formula, we can\ndecide in PSPACE whether the formula has a model over alpha. In order to show\nthese results, we introduce a class of simple ordinal automata, as expressive\nas B\\\"uchi ordinal automata. The PSPACE upper bound for the satisfiability\nproblem of the temporal logic is obtained through a reduction to the\nnonemptiness problem for the simple ordinal automata."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(4:9)2010", 
    "link": "http://arxiv.org/pdf/1009.6171v1", 
    "title": "Cut Elimination for a Logic with Induction and Co-induction", 
    "arxiv-id": "1009.6171v1", 
    "author": "Alberto Momigliano", 
    "publish": "2010-09-30T15:41:34Z", 
    "summary": "Proof search has been used to specify a wide range of computation systems. In\norder to build a framework for reasoning about such specifications, we make use\nof a sequent calculus involving induction and co-induction. These proof\nprinciples are based on a proof theoretic (rather than set-theoretic) notion of\ndefinition. Definitions are akin to logic programs, where the left and right\nrules for defined atoms allow one to view theories as \"closed\" or defining\nfixed points. The use of definitions and free equality makes it possible to\nreason intentionally about syntax. We add in a consistent way rules for pre and\npost fixed points, thus allowing the user to reason inductively and\nco-inductively about properties of computational system making full use of\nhigher-order abstract syntax. Consistency is guaranteed via cut-elimination,\nwhere we give the first, to our knowledge, cut-elimination procedure in the\npresence of general inductive and co-inductive definitions."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(4:4)2010", 
    "link": "http://arxiv.org/pdf/1010.0201v2", 
    "title": "The complexity of global cardinality constraints", 
    "arxiv-id": "1010.0201v2", 
    "author": "Daniel Marx", 
    "publish": "2010-10-01T16:34:32Z", 
    "summary": "In a constraint satisfaction problem (CSP) the goal is to find an assignment\nof a given set of variables subject to specified constraints. A global\ncardinality constraint is an additional requirement that prescribes how many\nvariables must be assigned a certain value. We study the complexity of the\nproblem CCSP(G), the constraint satisfaction problem with global cardinality\nconstraints that allows only relations from the set G. The main result of this\npaper characterizes sets G that give rise to problems solvable in polynomial\ntime, and states that the remaining such problems are NP-complete."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(4:4)2010", 
    "link": "http://arxiv.org/pdf/1010.0225v2", 
    "title": "Characterizing perfect recall using next-step temporal operators in S5   and sub-S5 Epistemic Temporal Logic", 
    "arxiv-id": "1010.0225v2", 
    "author": "Andreas Witzel", 
    "publish": "2010-10-01T18:02:05Z", 
    "summary": "We review the notion of perfect recall in the literature on interpreted\nsystems, game theory, and epistemic logic. In the context of Epistemic Temporal\nLogic (ETL), we give a (to our knowledge) novel frame condition for perfect\nrecall, which is local and can straightforwardly be translated to a defining\nformula in a language that only has next-step temporal operators. This frame\ncondition also gives rise to a complete axiomatization for S5 ETL frames with\nperfect recall. We then consider how to extend and consolidate the notion of\nperfect recall in sub-S5 settings, where the various notions discussed are no\nlonger equivalent."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(4:6)2010", 
    "link": "http://arxiv.org/pdf/1010.1066v2", 
    "title": "An Explicit Framework for Interaction Nets", 
    "arxiv-id": "1010.1066v2", 
    "author": "Marc de Falco", 
    "publish": "2010-10-06T05:33:18Z", 
    "summary": "Interaction nets are a graphical formalism inspired by Linear Logic\nproof-nets often used for studying higher order rewriting e.g. \\Beta-reduction.\nTraditional presentations of interaction nets are based on graph theory and\nrely on elementary properties of graph theory. We give here a more explicit\npresentation based on notions borrowed from Girard's Geometry of Interaction:\ninteraction nets are presented as partial permutations and a composition of\nnets, the gluing, is derived from the execution formula. We then define\ncontexts and reduction as the context closure of rules. We prove strong\nconfluence of the reduction within our framework and show how interaction nets\ncan be viewed as the quotient of some generalized proof-nets."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(4:6)2010", 
    "link": "http://arxiv.org/pdf/1010.1139v1", 
    "title": "Temporal Logics on Words with Multiple Data Values", 
    "arxiv-id": "1010.1139v1", 
    "author": "Thomas Zeume", 
    "publish": "2010-10-06T12:46:33Z", 
    "summary": "The paper proposes and studies temporal logics for attributed words, that is,\ndata words with a (finite) set of (attribute,value)-pairs at each position. It\nconsiders a basic logic which is a semantical fragment of the logic\n$LTL^\\downarrow_1$ of Demri and Lazic with operators for navigation into the\nfuture and the past. By reduction to the emptiness problem for data automata it\nis shown that this basic logic is decidable. Whereas the basic logic only\nallows navigation to positions where a fixed data value occurs, extensions are\nstudied that also allow navigation to positions with different data values.\nBesides some undecidable results it is shown that the extension by a certain\nUNTIL-operator with an inequality target condition remains decidable."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(4:10)2010", 
    "link": "http://arxiv.org/pdf/1010.1872v2", 
    "title": "Backward Reachability of Array-based Systems by SMT solving: Termination   and Invariant Synthesis", 
    "arxiv-id": "1010.1872v2", 
    "author": "Silvio Ranise", 
    "publish": "2010-10-09T21:04:26Z", 
    "summary": "The safety of infinite state systems can be checked by a backward\nreachability procedure. For certain classes of systems, it is possible to prove\nthe termination of the procedure and hence conclude the decidability of the\nsafety problem. Although backward reachability is property-directed, it can\nunnecessarily explore (large) portions of the state space of a system which are\nnot required to verify the safety property under consideration. To avoid this,\ninvariants can be used to dramatically prune the search space. Indeed, the\nproblem is to guess such appropriate invariants. In this paper, we present a\nfully declarative and symbolic approach to the mechanization of backward\nreachability of infinite state systems manipulating arrays by Satisfiability\nModulo Theories solving. Theories are used to specify the topology and the data\nmanipulated by the system. We identify sufficient conditions on the theories to\nensure the termination of backward reachability and we show the completeness of\na method for invariant synthesis (obtained as the dual of backward\nreachability), again, under suitable hypotheses on the theories. We also\npresent a pragmatic approach to interleave invariant synthesis and backward\nreachability so that a fix-point for the set of backward reachable states is\nmore easily obtained. Finally, we discuss heuristics that allow us to derive an\nimplementation of the techniques in the model checker MCMT, showing remarkable\nspeed-ups on a significant set of safety problems extracted from a variety of\nsources."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(3:3)2012", 
    "link": "http://arxiv.org/pdf/1010.4422v3", 
    "title": "Efficient Interpolant Generation in Satisfiability Modulo Linear Integer   Arithmetic", 
    "arxiv-id": "1010.4422v3", 
    "author": "Roberto Sebastiani", 
    "publish": "2010-10-21T10:54:34Z", 
    "summary": "The problem of computing Craig interpolants in SAT and SMT has recently\nreceived a lot of interest, mainly for its applications in formal verification.\nEfficient algorithms for interpolant generation have been presented for some\ntheories of interest ---including that of equality and uninterpreted functions,\nlinear arithmetic over the rationals, and their combination--- and they are\nsuccessfully used within model checking tools. For the theory of linear\narithmetic over the integers (LA(Z)), however, the problem of finding an\ninterpolant is more challenging, and the task of developing efficient\ninterpolant generators for the full theory LA(Z) is still the objective of\nongoing research. In this paper we try to close this gap. We build on previous\nwork and present a novel interpolation algorithm for SMT(LA(Z)), which exploits\nthe full power of current state-of-the-art SMT(LA(Z)) solvers. We demonstrate\nthe potential of our approach with an extensive experimental evaluation of our\nimplementation of the proposed algorithm in the MathSAT SMT solver."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(3:3)2012", 
    "link": "http://arxiv.org/pdf/1010.4529v1", 
    "title": "The Last Paper on the Halpern-Shoham Interval Temporal Logic", 
    "arxiv-id": "1010.4529v1", 
    "author": "Jakub Michaliszyn", 
    "publish": "2010-10-21T17:30:06Z", 
    "summary": "The Halpern-Shoham logic is a modal logic of time intervals. Some effort has\nbeen put in last ten years to classify fragments of this beautiful logic with\nrespect to decidability of its satisfiability problem. We contribute to this\neffort by showing - what we believe is quite an unexpected result - that the\nlogic of subintervals, the fragment of the Halpern-Shoham where only the\noperator \"during\", or D, is allowed, is undecidable over discrete structures.\nThis is surprising as this logic is decidable over dense orders and its\nreflexive variant is known to be decidable over discrete structures."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.38.3", 
    "link": "http://arxiv.org/pdf/1010.5565v1", 
    "title": "Port Protocols for Deadlock-Freedom of Component Systems", 
    "arxiv-id": "1010.5565v1", 
    "author": "Mila Majster-Cederbaum", 
    "publish": "2010-10-27T05:04:07Z", 
    "summary": "In component-based development, approaches for property verification exist\nthat avoid building the global system behavior of the component model.\nTypically, these approaches rely on the analysis of the local behavior of fixed\nsized subsystems of components. In our approach, we want to avoid not only the\nanalysis of the global behavior but also of the local behaviors of the\ncomponents. Instead, we consider very small parts of the local behaviors called\nport protocols that suffice to verify properties."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.38.10", 
    "link": "http://arxiv.org/pdf/1010.5572v1", 
    "title": "A theory of desynchronisable closed loop system", 
    "arxiv-id": "1010.5572v1", 
    "author": "Pieter Cuijpers", 
    "publish": "2010-10-27T05:04:44Z", 
    "summary": "The task of implementing a supervisory controller is non-trivial, even though\ndifferent theories exist that allow automatic synthesis of these controllers in\nthe form of automata. One of the reasons for this discord is due to the\nasynchronous interaction between a plant and its controller in implementations,\nwhereas the existing supervisory control theories assume synchronous\ninteraction. As a consequence the implementation suffer from the so-called\ninexact synchronisation problem. In this paper we address the issue of inexact\nsynchronisation in a process algebraic setting, by solving a more general\nproblem of refinement. We construct an asynchronous closed loop system by\nintroducing a communication medium in a given synchronous closed loop system.\nOur goal is to find sufficient conditions under which a synchronous closed loop\nsystem is branching bisimilar to its corresponding asynchronous closed loop\nsystem."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.38.10", 
    "link": "http://arxiv.org/pdf/1010.5665v1", 
    "title": "Safety-Guarantee Controller Synthesis for Cyber-Physical Systems", 
    "arxiv-id": "1010.5665v1", 
    "author": "Rupak Majumdar", 
    "publish": "2010-10-27T12:12:12Z", 
    "summary": "The verification and validation of cyber-physical systems is known to be a\ndifficult problem due to the different modeling abstractions used for control\ncomponents and for software components. A recent trend to address this\ndifficulty is to reduce the need for verification by adopting correct-by-design\nmethodologies. According to the correct-by-design paradigm, one seeks to\nautomatically synthesize a controller that can be refined into code and that\nenforces temporal specifications on the cyber-physical system. In this paper we\nconsider an instance of this problem where the specifications are given by a\nfragment of Linear Temporal Logic (LTL) and the physical environment is\ndescribed by a smooth differential equation. The contribution of this paper is\nto show that synthesis for cyber-physical systems is viable by considering a\nfragment of LTL that is expressive enough to describe interesting properties\nbut simple enough to avoid Safra's construction. We report on two examples\nillustrating a preliminary implementation of these techniques on the tool\nPESSOALTL."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.38.10", 
    "link": "http://arxiv.org/pdf/1011.0399v1", 
    "title": "Functional Dependence of Secrets in a Collaboration Network", 
    "arxiv-id": "1011.0399v1", 
    "author": "Pavel Naumov", 
    "publish": "2010-11-01T18:06:29Z", 
    "summary": "A collaboration network is a graph formed by communication channels between\nparties. Parties communicate over these channels to establish secrets,\nsimultaneously enforcing interdependencies between the secrets. The paper\nstudies properties of these interdependencies that are induced by the topology\nof the network. In previous work, the authors developed a complete logical\nsystem for one such property, independence, also known in the information flow\nliterature as nondeducibility. This work describes a complete and decidable\nlogical system for the functional dependence relation between sets of secrets\nover a collaboration network. The system extends Armstrong's system of axioms\nfor functional dependency in databases."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.38.10", 
    "link": "http://arxiv.org/pdf/1011.0447v2", 
    "title": "Finite Model Finding for Parameterized Verification", 
    "arxiv-id": "1011.0447v2", 
    "author": "Alexei Lisitsa", 
    "publish": "2010-11-01T20:50:14Z", 
    "summary": "In this paper we investigate to which extent a very simple and natural\n\"reachability as deducibility\" approach, originated in the research in formal\nmethods in security, is applicable to the automated verification of large\nclasses of infinite state and parameterized systems. The approach is based on\nmodeling the reachability between (parameterized) states as deducibility\nbetween suitable encodings of states by formulas of first-order predicate\nlogic. The verification of a safety property is reduced to a pure logical\nproblem of finding a countermodel for a first-order formula. The later task is\ndelegated then to the generic automated finite model building procedures. In\nthis paper we first establish the relative completeness of the finite\ncountermodel finding method (FCM) for a class of parameterized linear arrays of\nfinite automata. The method is shown to be at least as powerful as known\nmethods based on monotonic abstraction and symbolic backward reachability.\nFurther, we extend the relative completeness of the approach and show that it\ncan solve all safety verification problems which can be solved by the\ntraditional regular model checking."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(4:08)2011", 
    "link": "http://arxiv.org/pdf/1011.0688v2", 
    "title": "Timed Parity Games: Complexity and Robustness", 
    "arxiv-id": "1011.0688v2", 
    "author": "Vinayak S. Prabhu", 
    "publish": "2010-11-02T18:01:15Z", 
    "summary": "We consider two-player games played in real time on game structures with\nclocks where the objectives of players are described using parity conditions.\nThe games are \\emph{concurrent} in that at each turn, both players\nindependently propose a time delay and an action, and the action with the\nshorter delay is chosen. To prevent a player from winning by blocking time, we\nrestrict each player to play strategies that ensure that the player cannot be\nresponsible for causing a zeno run. First, we present an efficient reduction of\nthese games to \\emph{turn-based} (i.e., not concurrent) \\emph{finite-state}\n(i.e., untimed) parity games. Our reduction improves the best known complexity\nfor solving timed parity games. Moreover, the rich class of algorithms for\nclassical parity games can now be applied to timed parity games. The states of\nthe resulting game are based on clock regions of the original game, and the\nstate space of the finite game is linear in the size of the region graph.\n  Second, we consider two restricted classes of strategies for the player that\nrepresents the controller in a real-time synthesis problem, namely,\n\\emph{limit-robust} and \\emph{bounded-robust} winning strategies. Using a\nlimit-robust winning strategy, the controller cannot choose an exact\nreal-valued time delay but must allow for some nonzero jitter in each of its\nactions. If there is a given lower bound on the jitter, then the strategy is\nbounded-robust winning. We show that exact strategies are more powerful than\nlimit-robust strategies, which are more powerful than bounded-robust winning\nstrategies for any bound. For both kinds of robust strategies, we present\nefficient reductions to standard timed automaton games. These reductions\nprovide algorithms for the synthesis of robust real-time controllers."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-18275-4_8", 
    "link": "http://arxiv.org/pdf/1011.1036v1", 
    "title": "Beyond Quantifier-Free Interpolation in Extensions of Presburger   Arithmetic (Extended Technical Report)", 
    "arxiv-id": "1011.1036v1", 
    "author": "Thomas Wahl", 
    "publish": "2010-11-03T23:49:15Z", 
    "summary": "Craig interpolation has emerged as an effective means of generating candidate\nprogram invariants. We present interpolation procedures for the theories of\nPresburger arithmetic combined with (i) uninterpreted predicates (QPA+UP), (ii)\nuninterpreted functions (QPA+UF) and (iii) extensional arrays (QPA+AR). We\nprove that none of these combinations can be effectively interpolated without\nthe use of quantifiers, even if the input formulae are quantifier-free. We go\non to identify fragments of QPA+UP and QPA+UF with restricted forms of guarded\nquantification that are closed under interpolation. Formulae in these fragments\ncan easily be mapped to quantifier-free expressions with integer division. For\nQPA+AR, we formulate a sound interpolation procedure that potentially produces\ninterpolants with unrestricted quantifiers."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-18275-4_8", 
    "link": "http://arxiv.org/pdf/1011.1172v1", 
    "title": "Logics and Games for True Concurrency", 
    "arxiv-id": "1011.1172v1", 
    "author": "Julian Gutierrez", 
    "publish": "2010-11-04T14:31:46Z", 
    "summary": "We study the underlying mathematical properties of various partial order\nmodels of concurrency based on transition systems, Petri nets, and event\nstructures, and show that the concurrent behaviour of these systems can be\ncaptured in a uniform way by two simple and general dualities of local\nbehaviour. Such dualities are used to define new mu-calculi and logic games for\nthe analysis of concurrent systems with partial order semantics. Some results\nof this work are: the definition of a number of mu-calculi which, in some\nclasses of systems, induce the same identifications as some of the best known\nbisimulation equivalences for concurrency; and the definition of (infinite)\nhigher-order logic games for bisimulation and model-checking, where the players\nof the games are given (local) monadic second-order power on the sets of\nelements they are allowed to play. More specifically, we show that our games\nare sound and complete, and therefore, determined; moreover, they are decidable\nin the finite case and underpin novel decision procedures for bisimulation and\nmodel-checking. Since these mu-calculi and logic games generalise well-known\nfixpoint logics and game-theoretic decision procedures for concurrent systems\nwith interleaving semantics, the results herein give some of the groundwork for\nthe design of a logic-based, game-theoretic framework for studying, in a\nuniform way, several concurrent systems regardless of whether they have an\ninterleaving or a partial order semantics."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-18275-4_8", 
    "link": "http://arxiv.org/pdf/1011.1321v1", 
    "title": "Probabilistic Model Checking for Propositional Projection Temporal Logic", 
    "arxiv-id": "1011.1321v1", 
    "author": "Xiaoxiao Yang", 
    "publish": "2010-11-05T04:28:32Z", 
    "summary": "Propositional Projection Temporal Logic (PPTL) is a useful formalism for\nreasoning about period of time in hardware and software systems and can handle\nboth sequential and parallel compositions. In this paper, based on discrete\ntime Markov chains, we investigate the probabilistic model checking approach\nfor PPTL towards verifying arbitrary linear-time properties. We first define a\nnormal form graph, denoted by NFG_inf, to capture the infinite paths of PPTL\nformulas. Then we present an algorithm to generate the NFG_inf. Since\ndiscrete-time Markov chains are the deterministic probabilistic models, we\nfurther give an algorithm to determinize and minimize the nondeterministic\nNFG_inf following the Safra's construction."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.tcs.2010.10.048", 
    "link": "http://arxiv.org/pdf/1011.1335v1", 
    "title": "A short proof that adding some permutation rules to $\u03b2$ preserves   $SN$", 
    "arxiv-id": "1011.1335v1", 
    "author": "Rene David", 
    "publish": "2010-11-05T07:54:47Z", 
    "summary": "I show that, if a term is $SN$ for $\\beta$, it remains $SN$ when some\npermutation rules are added."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(4:11)2010", 
    "link": "http://arxiv.org/pdf/1011.1625v2", 
    "title": "On the meaning of logical completeness", 
    "arxiv-id": "1011.1625v2", 
    "author": "Kazushige Terui", 
    "publish": "2010-11-07T09:01:17Z", 
    "summary": "Goedel's completeness theorem is concerned with provability, while Girard's\ntheorem in ludics (as well as full completeness theorems in game semantics) are\nconcerned with proofs. Our purpose is to look for a connection between these\ntwo disciplines. Following a previous work [3], we consider an extension of the\noriginal ludics with contraction and universal nondeterminism, which play dual\nroles, in order to capture a polarized fragment of linear logic and thus a\nconstructive variant of classical propositional logic. We then prove a\ncompleteness theorem for proofs in this extended setting: for any behaviour\n(formula) A and any design (proof attempt) P, either P is a proof of A or there\nis a model M of the orthogonal of A which defeats P. Compared with proofs of\nfull completeness in game semantics, ours exhibits a striking similarity with\nproofs of Goedel's completeness, in that it explicitly constructs a\ncountermodel essentially using Koenig's lemma, proceeds by induction on\nformulas, and implies an analogue of Loewenheim-Skolem theorem."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(4:11)2010", 
    "link": "http://arxiv.org/pdf/1011.2307v1", 
    "title": "What is a categorical model of the differential and the resource   lambda-calculi?", 
    "arxiv-id": "1011.2307v1", 
    "author": "Manzonetto Giulio", 
    "publish": "2010-11-10T08:28:06Z", 
    "summary": "In this paper we provide an abstract model theory for the untyped\ndifferential lambda-calculus and the resource calculus. In particular we\npropose a general definition of model of these calculi, namely the notion of\nlinear reflexive object in a Cartesian closed differential category. Examples\nof models based on relations are provided."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-14203-1_12", 
    "link": "http://arxiv.org/pdf/1011.2560v1", 
    "title": "Verifying Safety Properties With the TLA+ Proof System", 
    "arxiv-id": "1011.2560v1", 
    "author": "Stephan Merz", 
    "publish": "2010-11-11T05:45:44Z", 
    "summary": "TLAPS, the TLA+ proof system, is a platform for the development and\nmechanical verification of TLA+ proofs written in a declarative style requiring\nlittle background beyond elementary mathematics. The language supports\nhierarchical and non-linear proof construction and verification, and it is\nindependent of any verification tool or strategy. A Proof Manager uses backend\nverifiers such as theorem provers, proof assistants, SMT solvers, and decision\nprocedures to check TLA+ proofs. This paper documents the first public release\nof TLAPS, distributed with a BSD-like license. It handles almost all the\nnon-temporal part of TLA+ as well as the temporal reasoning needed to prove\nstandard safety properties, in particular invariance and step simulation, but\nnot liveness properties."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-14203-1_12", 
    "link": "http://arxiv.org/pdf/1011.2896v2", 
    "title": "Reducing Higher Order Pi-Calculus to Spatial Logics", 
    "arxiv-id": "1011.2896v2", 
    "author": "Zining Cao", 
    "publish": "2010-11-12T12:41:28Z", 
    "summary": "In this paper, we show that theory of processes can be reduced to the theory\nof spatial logic. Firstly, we propose a spatial logic SL for higher order\npi-calculus, and give an inference system of SL. The soundness and\nincompleteness of SL are proved. Furthermore, we show that the structure\ncongruence relation and one-step transition relation can be described as the\nlogical relation of SL formulae. We also extend bisimulations for processes to\nthat for SL formulae. Then we extend all definitions and results of SL to a\nweak semantics version of SL, called WL. At last, we add mu-operator to SL.\nThis new logic is named muSL. We show that WL is a sublogic of muSL and\nreplication operator can be expressed in muSL."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-14203-1_12", 
    "link": "http://arxiv.org/pdf/1011.2973v1", 
    "title": "The Hamiltonian Syllogistic", 
    "arxiv-id": "1011.2973v1", 
    "author": "Ian Pratt-Hartmann", 
    "publish": "2010-11-12T16:18:41Z", 
    "summary": "This paper undertakes a re-examination of Sir William Hamilton's doctrine of\nthe quantification of the predicate. Hamilton's doctrine comprises two theses.\nFirst, the predicates of traditional syllogistic sentence-forms contain\nimplicit existential quantifiers, so that, for example, \"All p are q\" is to be\nunderstood as \"All p are some q\". Second, these implicit quantifiers can be\nmeaningfully dualized to yield novel sentence-forms, such as, for example, \"All\np are all q\". Hamilton attempted to provide a deductive system for his\nlanguage, along the lines of the classical syllogisms. We show, using\ntechniques unavailable to Hamilton, that such a system does exist, though with\nqualifications that distinguish it from its classical counterpart."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-14203-1_12", 
    "link": "http://arxiv.org/pdf/1011.3362v1", 
    "title": "Bisimulations for Nondeterministic Labeled Markov Processes", 
    "arxiv-id": "1011.3362v1", 
    "author": "Nicol\u00e1s Wolovick", 
    "publish": "2010-11-15T12:39:26Z", 
    "summary": "We extend the theory of labeled Markov processes with internal\nnondeterminism, a fundamental concept for the further development of a process\ntheory with abstraction on nondeterministic continuous probabilistic systems.\nWe define nondeterministic labeled Markov processes (NLMP) and provide three\ndefinition of bisimulations: a bisimulation following a traditional\ncharacterization, a state based bisimulation tailored to our \"measurable\"\nnon-determinism, and an event based bisimulation. We show the relation between\nthem, including that the largest state bisimulation is also an event\nbisimulation. We also introduce a variation of the Hennessy-Milner logic that\ncharacterizes event bisimulation and that is sound w.r.t. the other\nbisimulations for arbitrary NLMP. This logic, however, is infinitary as it\ncontains a denumerable $\\lor$. We then introduce a finitary sublogic that\ncharacterize all bisimulations for image finite NLMP whose underlying measure\nspace is also analytic. Hence, in this setting, all notions of bisimulation we\ndeal with turn out to be equal. Finally, we show that all notions of\nbisimulations are different in the general case. The counterexamples that\nseparate them turn to be non-probabilistic NLMP."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(1:4)2011", 
    "link": "http://arxiv.org/pdf/1011.3479v2", 
    "title": "Generic Modal Cut Elimination Applied to Conditional Logics", 
    "arxiv-id": "1011.3479v2", 
    "author": "Lutz Schr\u00f6der", 
    "publish": "2010-11-15T19:22:18Z", 
    "summary": "We develop a general criterion for cut elimination in sequent calculi for\npropositional modal logics, which rests on absorption of cut, contraction,\nweakening and inversion by the purely modal part of the rule system. Our\ncriterion applies also to a wide variety of logics outside the realm of normal\nmodal logic. We give extensive example instantiations of our framework to\nvarious conditional logics. For these, we obtain fully internalised calculi\nwhich are substantially simpler than those known in the literature, along with\nleaner proofs of cut elimination and complexity. In one case, conditional logic\nwith modus ponens and conditional excluded middle, cut elimination and\ncomplexity were explicitly stated as open in the literature."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-32621-9_16", 
    "link": "http://arxiv.org/pdf/1011.3542v3", 
    "title": "Linearity in the non-deterministic call-by-value setting", 
    "arxiv-id": "1011.3542v3", 
    "author": "Barbara Petit", 
    "publish": "2010-11-15T22:44:05Z", 
    "summary": "We consider the non-deterministic extension of the call-by-value lambda\ncalculus, which corresponds to the additive fragment of the linear-algebraic\nlambda-calculus. We define a fine-grained type system, capturing the right\nlinearity present in such formalisms. After proving the subject reduction and\nthe strong normalisation properties, we propose a translation of this calculus\ninto the System F with pairs, which corresponds to a non linear fragment of\nlinear logic. The translation provides a deeper understanding of the linearity\nin our setting."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-32621-9_16", 
    "link": "http://arxiv.org/pdf/1011.3668v4", 
    "title": "Linear lambda Calculus with Explicit Substitutions as Proof-Search in   Deep Inference", 
    "arxiv-id": "1011.3668v4", 
    "author": "Luca Roversi", 
    "publish": "2010-11-16T12:13:16Z", 
    "summary": "SBV is a deep inference system that extends the set of logical operators of\nmultiplicative linear logic with the non commutative operator Seq. We introduce\nthe logical system SBVr which extends SBV by adding a self-dual atom-renaming\noperator to it. We prove that the cut elimination holds on SBVr. SBVr and its\ncut free subsystem BVr are complete and sound with respect to linear lambda\ncalculus with explicit substitutions. Under any strategy, a sequence of\nevaluation steps of any linear lambda-term M becomes a process of proof-search\nin SBVr (BVr) once M is mapped into a formula of SBVr. Completeness and\nsoundness follow from simulating linear beta-reduction with explicit\nsubstitutions as processes. The role of the new renaming operator of SBVr is to\nrename channel-names on-demand. This simulates the substitution that occurs in\na beta-reduction. Despite SBVr is a minimal extension of SBV its proof-search\ncan compute all boolean functions, as linear lambda-calculus with explicit\nsubstitutions can compute all boolean functions as well. So, proof search of\nSBVr and BVr is at least ptime-complete."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-32621-9_16", 
    "link": "http://arxiv.org/pdf/1011.3964v1", 
    "title": "Decision Problems for Petri Nets with Names", 
    "arxiv-id": "1011.3964v1", 
    "author": "David de Frutos-Escrig", 
    "publish": "2010-11-17T14:11:53Z", 
    "summary": "We prove several decidability and undecidability results for nu-PN, an\nextension of P/T nets with pure name creation and name management. We give a\nsimple proof of undecidability of reachability, by reducing reachability in\nnets with inhibitor arcs to it. Thus, the expressive power of nu-PN strictly\nsurpasses that of P/T nets. We prove that nu-PN are Well Structured Transition\nSystems. In particular, we obtain decidability of coverability and termination,\nso that the expressive power of Turing machines is not reached. Moreover, they\nare strictly Well Structured, so that the boundedness problem is also\ndecidable. We consider two properties, width-boundedness and depth-boundedness,\nthat factorize boundedness. Width-boundedness has already been proven to be\ndecidable. We prove here undecidability of depth-boundedness. Finally, we\nobtain Ackermann-hardness results for all our decidable decision problems."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-32621-9_16", 
    "link": "http://arxiv.org/pdf/1011.4377v1", 
    "title": "Dynamic Magic Sets for Super-Consistent Answer Set Programs", 
    "arxiv-id": "1011.4377v1", 
    "author": "Wolfgang Faber", 
    "publish": "2010-11-19T10:01:17Z", 
    "summary": "For many practical applications of ASP, for instance data integration or\nplanning, query answering is important, and therefore query optimization\ntechniques for ASP are of great interest. Magic Sets are one of these\ntechniques, originally defined for Datalog queries (ASP without disjunction and\nnegation). Dynamic Magic Sets (DMS) are an extension of this technique, which\nhas been proved to be sound and complete for query answering over ASP programs\nwith stratified negation.\n  A distinguishing feature of DMS is that the optimization can be exploited\nalso during the nondeterministic phase of ASP engines. In particular, after\nsome assumptions have been made during the computation, parts of the program\nmay become irrelevant to a query under these assumptions. This allows for\ndynamic pruning of the search space, which may result in exponential\nperformance gains.\n  In this paper, the correctness of DMS is formally established and proved for\nbrave and cautious reasoning over the class of super-consistent ASP programs\n(ASP^{sc} programs). ASP^{sc} programs guarantee consistency (i.e., have answer\nsets) when an arbitrary set of facts is added to them. This result generalizes\nthe applicability of DMS, since the class of ASP^{sc} programs is richer than\nASP programs with stratified negation, and in particular includes all\nodd-cycle-free programs. DMS has been implemented as an extension of DLV, and\nthe effectiveness of DMS for ASP^{sc} programs is empirically confirmed by\nexperimental results with this system."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(4:12)2010", 
    "link": "http://arxiv.org/pdf/1011.4384v2", 
    "title": "On Constructive Connectives and Systems", 
    "arxiv-id": "1011.4384v2", 
    "author": "Ori Lahav", 
    "publish": "2010-11-19T10:26:36Z", 
    "summary": "Canonical inference rules and canonical systems are defined in the framework\nof non-strict single-conclusion sequent systems, in which the succeedents of\nsequents can be empty. Important properties of this framework are investigated,\nand a general non-deterministic Kripke-style semantics is provided. This\ngeneral semantics is then used to provide a constructive (and very natural),\nsufficient and necessary coherence criterion for the validity of the strong\ncut-elimination theorem in such a system. These results suggest new syntactic\nand semantic characterizations of basic constructive connectives."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-6(4:12)2010", 
    "link": "http://arxiv.org/pdf/1011.5894v1", 
    "title": "An Optimization for Reasoning with Forest Logic Programs", 
    "arxiv-id": "1011.5894v1", 
    "author": "Stijn Heymans", 
    "publish": "2010-11-25T22:04:45Z", 
    "summary": "Open Answer Set Programming (OASP) is an attractive framework for integrating\nontologies and rules. In general OASP is undecidable. In previous work we\nprovided a tableau-based algorithm for satisfiability checking w.r.t. forest\nlogic programs, a decidable fragment of OASP, which has the forest model\nproperty. In this paper we introduce an optimized version of that algorithm\nachieved by means of a knowledge compilation technique. So-called unit\ncompletion structures, which are possible building blocks of a forest model, in\nthe form of trees of depth 1, are computed in an initial step of the algorithm.\nRepeated computations are avoided by using these structures in a\npattern-matching style when constructing a model. Furthermore we identify and\ndiscard redundant unit completion structures: a structure is redundant if there\nis another structure which can always replace the original structure in a\nforest model."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.41", 
    "link": "http://arxiv.org/pdf/1011.6012v1", 
    "title": "Proceedings 17th International Workshop on Expressiveness in Concurrency", 
    "arxiv-id": "1011.6012v1", 
    "author": "Frank D. Valencia", 
    "publish": "2010-11-28T03:07:57Z", 
    "summary": "This volume contains the proceedings of the 17th International Workshop on\nExpressiveness in Concurrency (EXPRESS'10), which took place on 30th August\n2010 in Paris, co-located with CONCUR'10. The EXPRESS workshop series aim at\nbringing together researchers who are interested in the expressiveness and\ncomparison of formal models that broadly relate to concurrency. In particular,\nthis also includes emergent fields such as logic and interaction,\ngame-theoretic models, and service-oriented computing."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.41.6", 
    "link": "http://arxiv.org/pdf/1011.6433v1", 
    "title": "A Process Calculus for Expressing Finite Place/Transition Petri Nets", 
    "arxiv-id": "1011.6433v1", 
    "author": "Cristian Versari", 
    "publish": "2010-11-30T01:37:56Z", 
    "summary": "We introduce the process calculus Multi-CCS, which extends conservatively CCS\nwith an operator of strong prefixing able to model atomic sequences of actions\nas well as multiparty synchronization. Multi-CCS is equipped with a labeled\ntransition system semantics, which makes use of a minimal structural\ncongruence. Multi-CCS is also equipped with an unsafe P/T Petri net semantics\nby means of a novel technique. This is the first rich process calculus,\nincluding CCS as a subcalculus, which receives a semantics in terms of unsafe,\nlabeled P/T nets. The main result of the paper is that a class of Multi-CCS\nprocesses, called finite-net processes, is able to represent all finite\n(reduced) P/T nets."
},{
    "category": "cs.LO", 
    "doi": "10.1017/S0960129514000334", 
    "link": "http://arxiv.org/pdf/1011.6434v1", 
    "title": "Models for CSP with availability information", 
    "arxiv-id": "1011.6434v1", 
    "author": "Gavin Lowe", 
    "publish": "2010-11-30T01:37:59Z", 
    "summary": "We consider models of CSP based on recording what events are available as\npossible alternatives to the events that are actually performed. We present\nmany different varieties of such models. For each, we give a compositional\nsemantics, congruent to the operational semantics, and prove full abstraction\nand no-junk results. We compare the expressiveness of the different models."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.41.8", 
    "link": "http://arxiv.org/pdf/1011.6435v1", 
    "title": "Robustness of Equations Under Operational Extensions", 
    "arxiv-id": "1011.6435v1", 
    "author": "Michel A. Reniers", 
    "publish": "2010-11-30T01:38:03Z", 
    "summary": "Sound behavioral equations on open terms may become unsound after\nconservative extensions of the underlying operational semantics. Providing\ncriteria under which such equations are preserved is extremely useful; in\nparticular, it can avoid the need to repeat proofs when extending the specified\nlanguage.\n  This paper investigates preservation of sound equations for several notions\nof bisimilarity on open terms: closed-instance (ci-)bisimilarity and\nformal-hypothesis (fh-)bisimilarity, both due to Robert de Simone, and\nhypothesis-preserving (hp-)bisimilarity, due to Arend Rensink. For both\nfh-bisimilarity and hp-bisimilarity, we prove that arbitrary sound equations on\nopen terms are preserved by all disjoint extensions which do not add labels. We\nalso define slight variations of fh- and hp-bisimilarity such that all sound\nequations are preserved by arbitrary disjoint extensions. Finally, we give two\nsets of syntactic criteria (on equations, resp. operational extensions) and\nprove each of them to be sufficient for preserving ci-bisimilarity."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.41.10", 
    "link": "http://arxiv.org/pdf/1011.6437v1", 
    "title": "Breaking Symmetries", 
    "arxiv-id": "1011.6437v1", 
    "author": "Uwe Nestmann", 
    "publish": "2010-11-30T01:38:14Z", 
    "summary": "A well-known result by Palamidessi tells us that \\pimix (the \\pi-calculus\nwith mixed choice) is more expressive than \\pisep (its subset with only\nseparate choice). The proof of this result argues with their different\nexpressive power concerning leader election in symmetric networks. Later on,\nGorla offered an arguably simpler proof that, instead of leader election in\nsymmetric networks, employed the reducibility of incestual processes (mixed\nchoices that include both enabled senders and receivers for the same channel)\nwhen running two copies in parallel. In both proofs, the role of breaking\n(initial) symmetries is more or less apparent. In this paper, we shed more\nlight on this role by re-proving the above result - based on a proper\nformalization of what it means to break symmetries without referring to another\nlayer of the distinguishing problem domain of leader election. Both Palamidessi\nand Gorla rephrased their results by stating that there is no uniform and\nreasonable encoding from \\pimix into \\pisep. We indicate how the respective\nproofs can be adapted and exhibit the consequences of varying notions of\nuniformity and reasonableness. In each case, the ability to break initial\nsymmetries turns out to be essential."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.41.3", 
    "link": "http://arxiv.org/pdf/1011.6438v1", 
    "title": "Process Behaviour: Formulae vs. Tests (Extended Abstract)", 
    "arxiv-id": "1011.6438v1", 
    "author": "Matthew Hennessy", 
    "publish": "2010-11-30T01:39:19Z", 
    "summary": "Process behaviour is often defined either in terms of the tests they satisfy,\nor in terms of the logical properties they enjoy. Here we compare these two\napproaches, using extensional testing in the style of DeNicola, Hennessy, and a\nrecursive version of the property logic HML. We first characterise subsets of\nthis property logic which can be captured by tests. Then we show that those\nsubsets of the property logic capture precisely the power of tests."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.41.3", 
    "link": "http://arxiv.org/pdf/1011.6496v1", 
    "title": "A Calculus of Consistent Component-based Software Updates", 
    "arxiv-id": "1011.6496v1", 
    "author": "Junqing Chen", 
    "publish": "2010-11-30T09:34:28Z", 
    "summary": "It is important to enable reasoning about the meaning and possible effects of\nupdates to ensure that the updated system operates correctly. A formal,\nmathematical model of dynamic update should be developed, in order to\nunderstand by both users and implementors of update technology what design\nchoices can be considered. In this paper, we define a formal calculus\n$update\\pi$, a variant extension of higher-order $\\pi$ calculus, to model\ndynamic updates of component-based software, which is language and technology\nindependent. The calculus focuses on following main concepts: proper\ngranularity of update, timing of dynamic update, state transformation between\nversions, update failure check and recovery. We describe a series of rule on\nsafe component updates to model some general processes of dynamic update and\ndiscuss its reduction semantics coincides with a labelled transition system\nsemantics that illustrate the expressive power of these calculi."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(1:5)2011", 
    "link": "http://arxiv.org/pdf/1012.0746v3", 
    "title": "Terminating Tableaux for Graded Hybrid Logic with Global Modalities and   Role Hierarchies", 
    "arxiv-id": "1012.0746v3", 
    "author": "Gert Smolka", 
    "publish": "2010-12-03T14:19:17Z", 
    "summary": "We present a terminating tableau calculus for graded hybrid logic with global\nmodalities, reflexivity, transitivity and role hierarchies. Termination of the\nsystem is achieved through pattern-based blocking. Previous approaches to\nrelated logics all rely on chain-based blocking. Besides being conceptually\nsimple and suitable for efficient implementation, the pattern-based approach\ngives us a NExpTime complexity bound for the decision procedure."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(1:9)2011", 
    "link": "http://arxiv.org/pdf/1012.1174v2", 
    "title": "Functional Interpretations of Intuitionistic Linear Logic", 
    "arxiv-id": "1012.1174v2", 
    "author": "Paulo Oliva", 
    "publish": "2010-12-06T14:10:29Z", 
    "summary": "We present three different functional interpretations of intuitionistic\nlinear logic ILL and show how these correspond to well-known functional\ninterpretations of intuitionistic logic IL via embeddings of IL into ILL. The\nmain difference from previous work of the second author is that in\nintuitionistic linear logic (as opposed to classical linear logic) the\ninterpretations of !A are simpler and simultaneous quantifiers are no longer\nneeded for the characterisation of the interpretations. We then compare our\napproach in developing these three proof interpretations with the one of de\nPaiva around the Dialectica category model of linear logic."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(1:9)2011", 
    "link": "http://arxiv.org/pdf/1012.2553v1", 
    "title": "Scope Logic with Local Reasoning and Pre/Post-State Properties", 
    "arxiv-id": "1012.2553v1", 
    "author": "Xuandong Li", 
    "publish": "2010-12-12T16:12:57Z", 
    "summary": "This paper presents an extension to Hoare logic for pointer program\nverification. Logic formulas with user-defined recursive functions are used to\nspecify properties on the program states before/after program executions.\n  Three basic functions are introduced to represents memory access,\nrecord-field access and array-element access. Some axioms are introduced to\nspecify these basic functions in our logic.\n  The concept Memory Scope Function (MSF) is introduced in our logic. Given a\nrecursive function $f$, the MSF of $f$ computes the set of memory units\naccessed during the evaluation of $f$. A set of rules are given to derive the\ndefinition of this MSF syntactically from the definition of $f$. As MSFs are\nalso recursive functions, they also have their MSFs. An axiom is given to\nspecify that an MSF contains its MSF. Based on this axiom, local reasoning is\nsupported with predicate variables.\n  Pre-state terms are used to specify the relations between pre-states and\npost-states. People can use pre-state terms in post-conditions to represents\nthe values on the pre-state.\n  The axiom of assignment statements in Hoare's logic is modified to deal with\npointers. The basic idea is that during the program execution, a recursive\nfunction is evaluated to the same value as long as no memory unit in its memory\nscope is modified. Another proof rule is added for memory allocation\nstatements.\n  We use a simple example to show that our logic can deal with pointer programs\nin this paper. In the appendix, the Shorre-Waite algorithm is proved using our\nlogic. We also use the selection-sort program to show that our logic can be\nused to prove program with indirectly-specified components."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(1:9)2011", 
    "link": "http://arxiv.org/pdf/1012.2995v1", 
    "title": "A Proof Carrying Code Framework for Inlined Reference Monitors in Java   Bytecode", 
    "arxiv-id": "1012.2995v1", 
    "author": "Andreas Lundblad", 
    "publish": "2010-12-14T11:12:36Z", 
    "summary": "We propose a light-weight approach for certification of monitor inlining for\nsequential Java bytecode using proof-carrying code. The goal is to enable the\nuse of monitoring for quality assurance at development time, while minimizing\nthe need for post-shipping code rewrites as well as changes to the end-host\nTCB. Standard automaton-based security policies express constraints on allowed\nAPI call/return sequences. Proofs are represented as JML-style program\nannotations. This is adequate in our case as all proofs generated in our\nframework are recognized in time polynomial in the size of the program. Policy\nadherence is proved by comparing the transitions of an inlined monitor with\nthose of a trusted \"ghost\" monitor represented using JML-style annotations. At\ntime of receiving a program with proof annotations, it is sufficient for the\nreceiver to plug in its own trusted ghost monitor and check the resulting\nverification conditions, to verify that inlining has been performed correctly,\nof the correct policy. We have proved correctness of the approach at the Java\nbytecode level and formalized the proof of soundness in Coq. An implementation,\nincluding an application loader running on a mobile device, is available, and\nwe conclude by giving benchmarks for two sample applications."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(1:9)2011", 
    "link": "http://arxiv.org/pdf/1012.3040v1", 
    "title": "Numerically Representing A Stochastic Process Algebra", 
    "arxiv-id": "1012.3040v1", 
    "author": "Jane Hillston", 
    "publish": "2010-12-13T05:43:51Z", 
    "summary": "The syntactic nature and compositionality characteristic of stochastic\nprocess algebras make models to be easily understood by human beings, but not\nconvenient for machines as well as people to directly carry out mathematical\nanalysis and stochastic simulation. This paper presents a numerical\nrepresentation schema for the stochastic process algebra PEPA, which can\nprovide a platform to directly and conveniently employ a variety of\ncomputational approaches to both qualitatively and quantitatively analyse the\nmodels. Moreover, these approaches developed on the basis of the schema are\ndemonstrated and discussed. In particular, algorithms for automatically\nderiving the schema from a general PEPA model and simulating the model based on\nthe derived schema to derive performance measures are presented."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(1:6)2011", 
    "link": "http://arxiv.org/pdf/1012.3372v2", 
    "title": "A Focused Sequent Calculus Framework for Proof Search in Pure Type   Systems", 
    "arxiv-id": "1012.3372v2", 
    "author": "James McKinna", 
    "publish": "2010-12-15T16:04:02Z", 
    "summary": "Basic proof-search tactics in logic and type theory can be seen as the\nroot-first applications of rules in an appropriate sequent calculus, preferably\nwithout the redundancies generated by permutation of rules. This paper\naddresses the issues of defining such sequent calculi for Pure Type Systems\n(PTS, which were originally presented in natural deduction style) and then\norganizing their rules for effective proof-search. We introduce the idea of\nPure Type Sequent Calculus with meta-variables (PTSCalpha), by enriching the\nsyntax of a permutation-free sequent calculus for propositional logic due to\nHerbelin, which is strongly related to natural deduction and already well\nadapted to proof-search. The operational semantics is adapted from Herbelin's\nand is defined by a system of local rewrite rules as in cut-elimination, using\nexplicit substitutions. We prove confluence for this system. Restricting our\nattention to PTSC, a type system for the ground terms of this system, we obtain\nthe Subject Reduction property and show that each PTSC is logically equivalent\nto its corresponding PTS, and the former is strongly normalising iff the latter\nis. We show how to make the logical rules of PTSC into a syntax-directed system\nPS for proof-search, by incorporating the conversion rules as in\nsyntax-directed presentations of the PTS rules for type-checking. Finally, we\nconsider how to use the explicitly scoped meta-variables of PTSCalpha to\nrepresent partial proof-terms, and use them to analyse interactive proof\nconstruction. This sets up a framework PE in which we are able to study\nproof-search strategies, type inhabitant enumeration and (higher-order)\nunification."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(1:6)2011", 
    "link": "http://arxiv.org/pdf/1012.3704v1", 
    "title": "A Decidable Timeout based Extension of Propositional Linear Temporal   Logic", 
    "arxiv-id": "1012.3704v1", 
    "author": "Suman Roy", 
    "publish": "2010-12-16T18:10:26Z", 
    "summary": "We develop a timeout based extension of propositional linear temporal logic\n(which we call TLTL) to specify timing properties of timeout based models of\nreal time systems. TLTL formulas explicitly refer to a running global clock\ntogether with static timing variables as well as a dynamic variable abstracting\nthe timeout behavior. We extend LTL with the capability to express timeout\nconstraints. From the expressiveness view point, TLTL is not comparable with\nimportant known clock based real-time logics including TPTL, XCTL, and MTL,\ni.e., TLTL can specify certain properties, which cannot be specified in these\nlogics (also vice-versa). We define a corresponding timeout tableau for\nsatisfiability checking of the TLTL formulas. Also a model checking algorithm\nover timeout Kripke structure is presented. Further we prove that the validity\nchecking for such an extended logic remains PSPACE-complete even in the\npresence of timeout constraints and infinite state models. Under discrete time\nsemantics, with bounded timeout increments, the model-checking problem that if\na TLTL-formula holds in a timeout Kripke structure is also PSPACE complete. We\nfurther prove that when TLTL is interpreted over discrete time, it can be\nembedded in the monadic second order logic with time, and when TLTL is\ninterpreted over dense time without the condition of non-zenoness, the\nresulting logic becomes $\\Sigma_1^1$-complete."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.88.1", 
    "link": "http://arxiv.org/pdf/1012.4032v4", 
    "title": "A Type System for the Vectorial Aspect of the Linear-Algebraic   Lambda-Calculus", 
    "arxiv-id": "1012.4032v4", 
    "author": "Beno\u00eet Valiron", 
    "publish": "2010-12-17T23:09:28Z", 
    "summary": "We describe a type system for the linear-algebraic lambda-calculus. The type\nsystem accounts for the part of the language emulating linear operators and\nvectors, i.e. it is able to statically describe the linear combinations of\nterms resulting from the reduction of programs. This gives rise to an original\ntype theory where types, in the same way as terms, can be superposed into\nlinear combinations. We show that the resulting typed lambda-calculus is\nstrongly normalizing and features a weak subject-reduction."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.43", 
    "link": "http://arxiv.org/pdf/1012.4555v1", 
    "title": "Proceedings Workshop on Partiality and Recursion in Interactive Theorem   Provers", 
    "arxiv-id": "1012.4555v1", 
    "author": "Milad Niqui", 
    "publish": "2010-12-21T07:10:03Z", 
    "summary": "This volume contains the proceedings of the Workshop on Partiality and\nRecursion in Interactive Theorem Provers (PAR 2010) which took place on July 15\nin Edinburgh, UK. This workshop was held as a satellite workshop of the\nInternational Conference on Interactive Theorem Proving (ITP 2010), itself part\nof the Federated Logic Conference 2010 (FLoC 2010).\n  This workshop is a venue for researchers working on new approaches to cope\nwith partial functions and terminating general (co)recursion in theorem\nprovers."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.42.3", 
    "link": "http://arxiv.org/pdf/1012.4892v1", 
    "title": "A Machine Checked Model of Idempotent MGU Axioms For Lists of Equational   Constraints", 
    "arxiv-id": "1012.4892v1", 
    "author": "James Caldwell", 
    "publish": "2010-12-22T07:07:52Z", 
    "summary": "We present formalized proofs verifying that the first-order unification\nalgorithm defined over lists of satisfiable constraints generates a most\ngeneral unifier (MGU), which also happens to be idempotent. All of our proofs\nhave been formalized in the Coq theorem prover. Our proofs show that finite\nmaps produced by the unification algorithm provide a model of the axioms\ncharacterizing idempotent MGUs of lists of constraints. The axioms that serve\nas the basis for our verification are derived from a standard set by extending\nthem to lists of constraints. For us, constraints are equalities between terms\nin the language of simple types. Substitutions are formally modeled as finite\nmaps using the Coq library Coq.FSets.FMapInterface. Coq's method of functional\ninduction is the main proof technique used in proving many of the axioms."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.43.1", 
    "link": "http://arxiv.org/pdf/1012.4895v1", 
    "title": "Recursive Definitions of Monadic Functions", 
    "arxiv-id": "1012.4895v1", 
    "author": "Alexander Krauss", 
    "publish": "2010-12-22T07:09:04Z", 
    "summary": "Using standard domain-theoretic fixed-points, we present an approach for\ndefining recursive functions that are formulated in monadic style. The method\nworks both in the simple option monad and the state-exception monad of\nIsabelle/HOL's imperative programming extension, which results in a convenient\ndefinition principle for imperative programs, which were previously hard to\ndefine.\n  For such monadic functions, the recursion equation can always be derived\nwithout preconditions, even if the function is partial. The construction is\neasy to automate, and convenient induction principles can be derived\nautomatically."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.43.4", 
    "link": "http://arxiv.org/pdf/1012.4897v1", 
    "title": "Rewriting and Well-Definedness within a Proof System", 
    "arxiv-id": "1012.4897v1", 
    "author": "Michael Butler", 
    "publish": "2010-12-22T07:09:25Z", 
    "summary": "Term rewriting has a significant presence in various areas, not least in\nautomated theorem proving where it is used as a proof technique. Many theorem\nprovers employ specialised proof tactics for rewriting. This results in an\ninterleaving between deduction and computation (i.e., rewriting) steps. If the\nlogic of reasoning supports partial functions, it is necessary that rewriting\ncopes with potentially ill-defined terms. In this paper, we provide a basis for\nintegrating rewriting with a deductive proof system that deals with\nwell-definedness. The definitions and theorems presented in this paper are the\ntheoretical foundations for an extensible rewriting-based prover that has been\nimplemented for the set theoretical formalism Event-B."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.43.5", 
    "link": "http://arxiv.org/pdf/1012.4899v1", 
    "title": "General Recursion and Formal Topology", 
    "arxiv-id": "1012.4899v1", 
    "author": "Silvio Valentini", 
    "publish": "2010-12-22T07:09:32Z", 
    "summary": "It is well known that general recursion cannot be expressed within\nMartin-Loef's type theory and various approaches have been proposed to overcome\nthis problem still maintaining the termination of the computation of the\ntypable terms. In this work we propose a new approach to this problem based on\nthe use of inductively generated formal topologies."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.44", 
    "link": "http://arxiv.org/pdf/1012.5337v1", 
    "title": "Proceedings International Workshop on Strategies in Rewriting, Proving,   and Programming", 
    "arxiv-id": "1012.5337v1", 
    "author": "C\u00e9sar Mu\u00f1oz", 
    "publish": "2010-12-24T03:28:30Z", 
    "summary": "This volume contains selected papers from the proceedings of the First\nInternational Workshop on Strategies in Rewriting, Proving, and Programming\n(IWS 2010), which was held on July 9, 2010, in Edinburgh, UK. Strategies are\nubiquitous in programming languages, automated deduction and reasoning systems.\nIn the two communities of Rewriting and Programming on one side, and of\nDeduction and Proof engines (Provers, Assistants, Solvers) on the other side,\nworkshops have been launched to make progress towards a deeper understanding of\nthe nature of strategies, their descriptions, their properties, and their\nusage, in all kinds of computing and reasoning systems. Since more recently,\nstrategies are also playing an important role in rewrite-based programming\nlanguages, verification tools and techniques like SAT/SMT engines or\ntermination provers. Moreover strategies have come to be viewed more generally\nas expressing complex designs for control in computing, modeling, proof search,\nprogram transformation, and access control. IWS 2010 was organized as a\nsatellite workshop of FLoC 2010. FLoC 2010 provided an excellent opportunity to\nfoster exchanges between the communities of Rewriting and Programming on one\nside, and of Deduction and Proof engines on the other side. IWS2010 was a joint\nfollow-up of two series of worshops, held since 1997: the Strategies workshops\nheld by the CADE-IJCAR community and the Workshops on Reduction Strategies\n(WRS) held by the RTA-RDP community."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.44", 
    "link": "http://arxiv.org/pdf/1012.5439v2", 
    "title": "Extending B\u00fcchi Automata with Constraints on Data Values", 
    "arxiv-id": "1012.5439v2", 
    "author": "Tony Tan", 
    "publish": "2010-12-24T22:33:10Z", 
    "summary": "Recently data trees and data words have received considerable amount of\nattention in connection with XML reasoning and system verification. These are\ntrees or words that, in addition to labels from a finite alphabet, carry data\nvalues from an infinite alphabet (data). In general it is rather hard to obtain\nlogics for data words and trees that are sufficiently expressive, but still\nhave reasonable complexity for the satisfiability problem. In this paper we\nextend and study the notion of B\\\"uchi automata for omega-words with data. We\nprove that the emptiness problem for such extension is decidable in elementary\ncomplexity. We then apply our result to show the decidability of two kinds of\nlogics for omega-words with data: the two-variable fragment of first-order\nlogic and some extensions of classical linear temporal logic for omega-words\nwith data."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.44.3", 
    "link": "http://arxiv.org/pdf/1012.5562v1", 
    "title": "Termination of Rewriting with and Automated Synthesis of Forbidden   Patterns", 
    "arxiv-id": "1012.5562v1", 
    "author": "Felix Schernhammer", 
    "publish": "2010-12-27T06:30:17Z", 
    "summary": "We introduce a modified version of the well-known dependency pair framework\nthat is suitable for the termination analysis of rewriting under forbidden\npattern restrictions. By attaching contexts to dependency pairs that represent\nthe calling contexts of the corresponding recursive function calls, it is\npossible to incorporate the forbidden pattern restrictions in the (adapted)\nnotion of dependency pair chains, thus yielding a sound and complete approach\nto termination analysis. Building upon this contextual dependency pair\nframework we introduce a dependency pair processor that simplifies problems by\nanalyzing the contextual information of the dependency pairs. Moreover, we show\nhow this processor can be used to synthesize forbidden patterns suitable for a\ngiven term rewriting system on-the-fly during the termination analysis."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(1:1)2011", 
    "link": "http://arxiv.org/pdf/1012.5803v3", 
    "title": "Algebraic Notions of Termination", 
    "arxiv-id": "1012.5803v3", 
    "author": "Struth Georg", 
    "publish": "2010-12-28T17:33:09Z", 
    "summary": "Five algebraic notions of termination are formalised, analysed and compared:\nwellfoundedness or Noetherity, L\\\"ob's formula, absence of infinite iteration,\nabsence of divergence and normalisation. The study is based on modal semirings,\nwhich are additively idempotent semirings with forward and backward modal\noperators. To model infinite behaviours, idempotent semirings are extended to\ndivergence semirings, divergence Kleene algebras and omega algebras. The\nresulting notions and techniques are used in calculational proofs of classical\ntheorems of rewriting theory. These applications show that modal semirings are\npowerful tools for reasoning algebraically about the finite and infinite\ndynamics of programs and transition systems."
},{
    "category": "cs.LO", 
    "doi": "10.1109/IJCNN.2010.5596833", 
    "link": "http://arxiv.org/pdf/1101.0082v1", 
    "title": "Probabilistic Dynamic Logic of Phenomena and Cognition", 
    "arxiv-id": "1101.0082v1", 
    "author": "Stanislav Smerdov", 
    "publish": "2010-12-30T13:15:15Z", 
    "summary": "The purpose of this paper is to develop further the main concepts of\nPhenomena Dynamic Logic (P-DL) and Cognitive Dynamic Logic (C-DL), presented in\nthe previous paper. The specific character of these logics is in matching\nvagueness or fuzziness of similarity measures to the uncertainty of models.\nThese logics are based on the following fundamental notions: generality\nrelation, uncertainty relation, simplicity relation, similarity maximization\nproblem with empirical content and enhancement (learning) operator. We develop\nthese notions in terms of logic and probability and developed a Probabilistic\nDynamic Logic of Phenomena and Cognition (P-DL-PC) that relates to the scope of\nprobabilistic models of brain. In our research the effectiveness of suggested\nformalization is demonstrated by approximation of the expert model of breast\ncancer diagnostic decisions. The P-DL-PC logic was previously successfully\napplied to solving many practical tasks and also for modelling of some\ncognitive processes."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-9(2:2)2013", 
    "link": "http://arxiv.org/pdf/1101.0112v4", 
    "title": "The degree structure of Weihrauch-reducibility", 
    "arxiv-id": "1101.0112v4", 
    "author": "Arno Pauly", 
    "publish": "2010-12-30T16:47:56Z", 
    "summary": "We answer a question by Vasco Brattka and Guido Gherardi by proving that the\nWeihrauch-lattice is not a Brouwer algebra. The computable Weihrauch-lattice is\nalso not a Heyting algebra, but the continuous Weihrauch-lattice is. We further\ninvestigate the existence of infinite infima and suprema, as well as embeddings\nof the Medvedev-degrees into the Weihrauch-degrees."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-9(2:2)2013", 
    "link": "http://arxiv.org/pdf/1101.0968v2", 
    "title": "Refinement Types as Higher Order Dependency Pairs", 
    "arxiv-id": "1101.0968v2", 
    "author": "Cody Roux", 
    "publish": "2011-01-05T13:45:07Z", 
    "summary": "Refinement types are a well-studied manner of performing in-depth analysis on\nfunctional programs. The dependency pair method is a very powerful method used\nto prove termination of rewrite systems; however its extension to higher order\nrewrite systems is still the object of active research. We observe that a\nvariant of refinement types allow us to express a form of higher-order\ndependency pair criterion that only uses information at the type level, and we\nprove the correctness of this criterion."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-9(2:2)2013", 
    "link": "http://arxiv.org/pdf/1101.1379v1", 
    "title": "A Probabilistic Variant of Projection Temporal Logic", 
    "arxiv-id": "1101.1379v1", 
    "author": "Xiaoxiao Yang", 
    "publish": "2011-01-07T08:43:36Z", 
    "summary": "In this paper, we propose Probabilistic discrete-time Projection Temporal\nLogic (PrPTL), which extends Projection Temporal Logic (PTL) with probability.\nTo this end, some useful formulas are derived and some logic laws are given.\nFurther, we define Time Normal Form (TNF) for PrPTL as the standard form and\nprove that any PrPTL formulas can be rewritten to TNF. According to the TNF, we\nconstruct the time normal form graph which can be used for the probabilistic\nmodel checking on PrPTL."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:25)2012", 
    "link": "http://arxiv.org/pdf/1101.1449v4", 
    "title": "Formal Theories for Linear Algebra", 
    "arxiv-id": "1101.1449v4", 
    "author": "Lila A Fontes", 
    "publish": "2011-01-07T15:19:10Z", 
    "summary": "We introduce two-sorted theories in the style of [CN10] for the complexity\nclasses \\oplusL and DET, whose complete problems include determinants over Z2\nand Z, respectively. We then describe interpretations of Soltys' linear algebra\ntheory LAp over arbitrary integral domains, into each of our new theories. The\nresult shows equivalences of standard theorems of linear algebra over Z2 and Z\ncan be proved in the corresponding theory, but leaves open the interesting\nquestion of whether the theorems themselves can be proved."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(1:8)2011", 
    "link": "http://arxiv.org/pdf/1101.2162v3", 
    "title": "From coinductive proofs to exact real arithmetic: theory and   applications", 
    "arxiv-id": "1101.2162v3", 
    "author": "Ulrich Berger", 
    "publish": "2011-01-11T16:54:22Z", 
    "summary": "Based on a new coinductive characterization of continuous functions we\nextract certified programs for exact real number computation from constructive\nproofs. The extracted programs construct and combine exact real number\nalgorithms with respect to the binary signed digit representation of real\nnumbers. The data type corresponding to the coinductive definition of\ncontinuous functions consists of finitely branching non-wellfounded trees\ndescribing when the algorithm writes and reads digits. We discuss several\nexamples including the extraction of programs for polynomials up to degree two\nand the definite integral of continuous maps."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(1:8)2011", 
    "link": "http://arxiv.org/pdf/1101.2777v2", 
    "title": "Powermonads and Tensors of Unranked Effects", 
    "arxiv-id": "1101.2777v2", 
    "author": "Lutz Schr\u00f6der", 
    "publish": "2011-01-14T11:54:31Z", 
    "summary": "In semantics and in programming practice, algebraic concepts such as monads\nor, essentially equivalently, (large) Lawvere theories are a well-established\ntool for modelling generic side-effects. An important issue in this context are\ncombination mechanisms for such algebraic effects, which allow for the modular\ndesign of programming languages and verification logics. The most basic\ncombination operators are sum and tensor: while the sum of effects is just\ntheir non-interacting union, the tensor imposes commutation of effects.\nHowever, for effects with unbounded arity, such as continuations or unbounded\nnondeterminism, it is not a priori clear whether these combinations actually\nexist in all cases. Here, we introduce the class of uniform effects, which\nincludes unbounded nondeterminism and continuations, and prove that the tensor\ndoes always exist if one of the component effects is uniform, thus in\nparticular improving on previous results on tensoring with continuations. We\nthen treat the case of nondeterminism in more detail, and give an\norder-theoretic characterization of effects for which tensoring with\nnondeterminism is conservative, thus enabling nondeterministic arguments such\nas a generic version of the Fischer-Ladner encoding of control operators."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(1:8)2011", 
    "link": "http://arxiv.org/pdf/1101.2798v1", 
    "title": "On Logical Extension of Algebraic Division", 
    "arxiv-id": "1101.2798v1", 
    "author": "Mohammed Abubakr", 
    "publish": "2011-01-11T17:42:08Z", 
    "summary": "Basic arithmetic is the cornerstone of mathematics and computer sciences. In\narithmetic, 'division by zero' is an undefined operation and any attempt at\nextending logic for algebraic division to incorporate division by zero has\nresulted in paradoxes and fallacies. However, there is no proven theorem or\nmathematical logic that suggests that, defining logic for division by zero\nwould result in break-down of theory. Basing on this motivation, in this paper,\nwe attempt at logically defining a solution for 'division by zero' problem."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(1:8)2011", 
    "link": "http://arxiv.org/pdf/1101.2999v1", 
    "title": "Generalizing Topology via Chu Spaces", 
    "arxiv-id": "1101.2999v1", 
    "author": "Apostolos Syropoulos", 
    "publish": "2011-01-15T16:09:06Z", 
    "summary": "By using the representational power of Chu spaces we define the notion of a\ngeneralized topological space (or GTS, for short), i.e., a mathematical\nstructure that generalizes the notion of a topological space. We demonstrate\nthat these topological spaces have as special cases known topological spaces.\nFurthermore, we develop the various topological notions and concepts for GTS.\nMoreover, since the logic of Chu spaces is linear logic, we give an\ninterpretation of most linear logic connectives as operators that yield\ntopological spaces."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(1:8)2011", 
    "link": "http://arxiv.org/pdf/1101.3132v1", 
    "title": "Reactive Valuations", 
    "arxiv-id": "1101.3132v1", 
    "author": "Chris Regenboog", 
    "publish": "2011-01-17T07:21:04Z", 
    "summary": "In sequential logic there is an order in which the atomic propositions in an\nexpression are evaluated. This order allows the same atomic proposition to have\ndifferent values depending on which atomic propositions have already been\nevaluated. In the sequential propositional logic discussed in this thesis, such\nvaluations are called \"reactive\" valuations, in contrast to \"static\" valuations\nas are common in e.g. ordinary propositional logic. There are many classes of\nthese reactive valuations e.g., we can define a class of reactive valuations\nsuch that the value for each atomic proposition remains the same until another\natomic proposition is evaluated. This Master of Logic thesis consists of a\nstudy of some of the properties of this logic. We take a closer look at some of\nthe classes of reactive valuations. We particularly focus on the relation\nbetween the axiomatization and the semantics. Consequently, the main part of\nthis thesis focuses on proving soundness and completeness. Furthermore, we show\nthat the axioms in the provided axiomatizations are independent i.e., there are\nno redundant axioms present. Finally, we show {\\omega}-completeness for two\nclasses of reactive valuations."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(1:11)2011", 
    "link": "http://arxiv.org/pdf/1101.3262v3", 
    "title": "Psi-calculi: a framework for mobile processes with nominal data and   logic", 
    "arxiv-id": "1101.3262v3", 
    "author": "Bj\u00c3\u00b6rn Victor", 
    "publish": "2011-01-17T16:47:54Z", 
    "summary": "The framework of psi-calculi extends the pi-calculus with nominal datatypes\nfor data structures and for logical assertions and conditions. These can be\ntransmitted between processes and their names can be statically scoped as in\nthe standard pi-calculus. Psi-calculi can capture the same phenomena as other\nproposed extensions of the pi-calculus such as the applied pi-calculus, the\nspi-calculus, the fusion calculus, the concurrent constraint pi-calculus, and\ncalculi with polyadic communication channels or pattern matching. Psi-calculi\ncan be even more general, for example by allowing structured channels,\nhigher-order formalisms such as the lambda calculus for data structures, and\npredicate logic for assertions. We provide ample comparisons to related calculi\nand discuss a few significant applications. Our labelled operational semantics\nand definition of bisimulation is straightforward, without a structural\ncongruence. We establish minimal requirements on the nominal data and logic in\norder to prove general algebraic properties of psi-calculi, all of which have\nbeen checked in the interactive theorem prover Isabelle. Expressiveness of\npsi-calculi significantly exceeds that of other formalisms, while the purity of\nthe semantics is on par with the original pi-calculus."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(1:11)2011", 
    "link": "http://arxiv.org/pdf/1101.3417v3", 
    "title": "Categorical Abstract Rewriting Systems and Functoriality of Graph   Transformation", 
    "arxiv-id": "1101.3417v3", 
    "author": "Fr\u00e9d\u00e9ric Prost", 
    "publish": "2011-01-18T10:37:37Z", 
    "summary": "Rewriting systems are often defined as binary relations over a given set of\nobjects. This simple definition is used to describe various properties of\nrewriting such as termination, confluence, normal forms etc. In this paper, we\nintroduce a new notion of abstract rewriting in the framework of categories.\nThen, we define the functoriality property of rewriting systems. This property\nis sometimes called vertical composition. We show that most of graph\ntransformation systems are functorial and provide a counter-example of graph\ntransformation systems which is not functorial."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(1:12)2011", 
    "link": "http://arxiv.org/pdf/1101.3694v2", 
    "title": "Model Checking of Continuous-Time Markov Chains Against Timed Automata   Specifications", 
    "arxiv-id": "1101.3694v2", 
    "author": "Alexandru Mereacre", 
    "publish": "2011-01-19T14:19:57Z", 
    "summary": "We study the verification of a finite continuous-time Markov chain (CTMC) C\nagainst a linear real-time specification given as a deterministic timed\nautomaton (DTA) A with finite or Muller acceptance conditions. The central\nquestion that we address is: what is the probability of the set of paths of C\nthat are accepted by A, i.e., the likelihood that C satisfies A? It is shown\nthat under finite acceptance criteria this equals the reachability probability\nin a finite piecewise deterministic Markov process (PDP), whereas for Muller\nacceptance criteria it coincides with the reachability probability of terminal\nstrongly connected components in such a PDP. Qualitative verification is shown\nto amount to a graph analysis of the PDP. Reachability probabilities in our\nPDPs are then characterized as the least solution of a system of Volterra\nintegral equations of the second type and are shown to be approximated by the\nsolution of a system of partial differential equations. For single-clock DTA,\nthis integral equation system can be transformed into a system of linear\nequations where the coefficients are solutions of ordinary differential\nequations. As the coefficients are in fact transient probabilities in CTMCs,\nthis result implies that standard algorithms for CTMC analysis suffice to\nverify single-clock DTA specifications."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(1:13)2011", 
    "link": "http://arxiv.org/pdf/1101.4223v4", 
    "title": "Relating coalgebraic notions of bisimulation", 
    "arxiv-id": "1101.4223v4", 
    "author": "Sam Staton", 
    "publish": "2011-01-21T20:10:30Z", 
    "summary": "The theory of coalgebras, for an endofunctor on a category, has been proposed\nas a general theory of transition systems. We investigate and relate four\ngeneralizations of bisimulation to this setting, providing conditions under\nwhich the four different generalizations coincide. We study transfinite\nsequences whose limits are the greatest bisimulations."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(2:2)2011", 
    "link": "http://arxiv.org/pdf/1101.4364v2", 
    "title": "Existential witness extraction in classical realizability and via a   negative translation", 
    "arxiv-id": "1101.4364v2", 
    "author": "Alexandre Miquel", 
    "publish": "2011-01-23T12:21:44Z", 
    "summary": "We show how to extract existential witnesses from classical proofs using\nKrivine's classical realizability---where classical proofs are interpreted as\nlambda-terms with the call/cc control operator. We first recall the basic\nframework of classical realizability (in classical second-order arithmetic) and\nshow how to extend it with primitive numerals for faster computations. Then we\nshow how to perform witness extraction in this framework, by discussing several\ntechniques depending on the shape of the existential formula. In particular, we\nshow that in the Sigma01-case, Krivine's witness extraction method reduces to\nFriedman's through a well-suited negative translation to intuitionistic\nsecond-order arithmetic. Finally we discuss the advantages of using call/cc\nrather than a negative translation, especially from the point of view of an\nimplementation."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.45.3", 
    "link": "http://arxiv.org/pdf/1101.4425v1", 
    "title": "Sound and Complete Typing for lambda-mu", 
    "arxiv-id": "1101.4425v1", 
    "author": "Steffen van Bakel", 
    "publish": "2011-01-24T01:39:31Z", 
    "summary": "In this paper we define intersection and union type assignment for Parigot's\ncalculus lambda-mu. We show that this notion is complete (i.e. closed under\nsubject-expansion), and show also that it is sound (i.e. closed under\nsubject-reduction). This implies that this notion of intersection-union type\nassignment is suitable to define a semantics."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.45.3", 
    "link": "http://arxiv.org/pdf/1101.4465v1", 
    "title": "Extensional Collapse Situations I: non-termination and unrecoverable   errors", 
    "arxiv-id": "1101.4465v1", 
    "author": "Antonio Bucciarelli", 
    "publish": "2011-01-24T08:48:43Z", 
    "summary": "We consider a simple model of higher order, functional computation over the\nbooleans. Then, we enrich the model in order to encompass non-termination and\nunrecoverable errors, taken separately or jointly. We show that the models so\ndefined form a lattice when ordered by the extensional collapse situation\nrelation, introduced in order to compare models with respect to the amount of\n\"intensional information\" that they provide on computation. The proofs are\ncarried out by exhibiting suitable applied {\\lambda}-calculi, and by exploiting\nthe fundamental lemma of logical relations."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.45.3", 
    "link": "http://arxiv.org/pdf/1101.4554v1", 
    "title": "Team-building with Answer Set Programming in the Gioia-Tauro Seaport", 
    "arxiv-id": "1101.4554v1", 
    "author": "Nicola Leone", 
    "publish": "2011-01-24T14:50:57Z", 
    "summary": "(To appear in Theory and Practice of Logic Programming (TPLP).)\n  The seaport of Gioia Tauro is the largest transshipment terminal of the\nMediterranean coast. A crucial management task for the companies operating in\nthe seaport is team building: the problem of properly allocating the available\npersonnel for serving the incoming ships. Teams have to be carefully arranged\nin order to meet several constraints, such as allocation of the employees with\nthe appropriate skills, fair distribution of the working load, and turnover of\nthe heavy/dangerous roles. This makes team building a hard and expensive task\nrequiring several hours per day of manual preparation.\n  In this paper we present a system based on Answer Set Programming (ASP) for\nthe automatic generation of the teams of employees in the seaport of Gioia\nTauro. The system is currently exploited in the Gioia Tauro seaport by ICO BLG,\na company specialized in automobile logistics."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.46.4", 
    "link": "http://arxiv.org/pdf/1101.4734v1", 
    "title": "A Few Considerations on Structural and Logical Composition in   Specification Theories", 
    "arxiv-id": "1101.4734v1", 
    "author": "Andrzej W\u0105sowski", 
    "publish": "2011-01-25T06:57:56Z", 
    "summary": "Over the last 20 years a large number of automata-based specification\ntheories have been proposed for modeling of discrete,real-time and\nprobabilistic systems. We have observed a lot of shared algebraic structure\nbetween these formalisms. In this short abstract, we collect results of our\nwork in progress on describing and systematizing the algebraic assumptions in\nspecification theories."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.47", 
    "link": "http://arxiv.org/pdf/1101.5200v1", 
    "title": "Proceedings Third International Workshop on Classical Logic and   Computation", 
    "arxiv-id": "1101.5200v1", 
    "author": "Ulrich Berger", 
    "publish": "2011-01-27T03:03:07Z", 
    "summary": "The fact that classical mathematical proofs of simply existential statements\ncan be read as programs was established by Goedel and Kreisel half a century\nago. But the possibility of extracting useful computational content from\nclassical proofs was taken seriously only from the 1990s on when it was\ndiscovered that proof interpretations based on Goedel's and Kreisel's ideas can\nprovide new nontrivial algorithms and numerical results, and the Curry-Howard\ncorrespondence can be extended to classical logic via programming concepts such\nas continuations and control operators.\n  The workshop series \"Classical Logic and Computation\" aims to support a\nfruitful exchange of ideas between the various lines of research on\ncomputational aspects of classical logic. This volume contains the abstracts of\nthe invited lectures and the accepted contributed papers of the third CL&C\nworkshop which was held jointly with the workshop \"Program Extraction and\nConstructive Mathematics\" at the University of Brno in August 21-22, 2010, as a\nsatellite of CSL and MFCS. The workshops were held in honour of Helmut\nSchwichtenberg who became \"professor emeritus\" in September 2010.\n  The topics of the papers include the foundations, optimizations and\napplications of proof interpretations such as Hilbert's epsilon substitution\nmethod, Goedel's functional interpretation, learning based realizability and\nnegative translations as well as special calculi and theories capturing\ncomputational and complexity-theoretic aspects of classical logic such as the\nlambda-mu-calculus, applicative theories, sequent-calculi, resolution and\ncut-elimination"
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.47.3", 
    "link": "http://arxiv.org/pdf/1101.5441v1", 
    "title": "Interactive Learning Based Realizability and 1-Backtracking Games", 
    "arxiv-id": "1101.5441v1", 
    "author": "Federico Aschieri", 
    "publish": "2011-01-28T04:25:25Z", 
    "summary": "We prove that interactive learning based classical realizability (introduced\nby Aschieri and Berardi for first order arithmetic) is sound with respect to\nCoquand game semantics. In particular, any realizer of an\nimplication-and-negation-free arithmetical formula embodies a winning recursive\nstrategy for the 1-Backtracking version of Tarski games. We also give examples\nof realizer and winning strategy extraction for some classical proofs. We also\nsketch some ongoing work about how to extend our notion of realizability in\norder to obtain completeness with respect to Coquand semantics, when it is\nrestricted to 1-Backtracking games."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.47.4", 
    "link": "http://arxiv.org/pdf/1101.5442v1", 
    "title": "On Various Negative Translations", 
    "arxiv-id": "1101.5442v1", 
    "author": "Paulo Oliva", 
    "publish": "2011-01-28T04:25:33Z", 
    "summary": "Several proof translations of classical mathematics into intuitionistic\nmathematics have been proposed in the literature over the past century. These\nare normally referred to as negative translations or double-negation\ntranslations. Among those, the most commonly cited are translations due to\nKolmogorov, Godel, Gentzen, Kuroda and Krivine (in chronological order). In\nthis paper we propose a framework for explaining how these different\ntranslations are related to each other. More precisely, we define a notion of a\n(modular) simplification starting from Kolmogorov translation, which leads to a\npartial order between different negative translations. In this derived\nordering, Kuroda and Krivine are minimal elements. Two new minimal translations\nare introduced, with Godel and Gentzen translations sitting in between\nKolmogorov and one of these new translations."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.47.5", 
    "link": "http://arxiv.org/pdf/1101.5443v1", 
    "title": "Superdeduction in Lambda-Bar-Mu-Mu-Tilde", 
    "arxiv-id": "1101.5443v1", 
    "author": "Cl\u00e9ment Houtmann", 
    "publish": "2011-01-28T04:25:40Z", 
    "summary": "Superdeduction is a method specially designed to ease the use of first-order\ntheories in predicate logic. The theory is used to enrich the deduction system\nwith new deduction rules in a systematic, correct and complete way.\n  A proof-term language and a cut-elimination reduction already exist for\nsuperdeduction, both based on Christian Urban's work on classical sequent\ncalculus. However the computational content of Christian Urban's calculus is\nnot directly related to the (lambda-calculus based) Curry-Howard\ncorrespondence. In contrast the Lambda bar mu mu tilde calculus is a\nlambda-calculus for classical sequent calculus.\n  This short paper is a first step towards a further exploration of the\ncomputational content of superdeduction proofs, for we extend the Lambda bar mu\nmu tilde calculus in order to obtain a proofterm langage together with a\ncut-elimination reduction for superdeduction. We also prove strong\nnormalisation for this extension of the Lambda bar mu mu tilde calculus."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.47.7", 
    "link": "http://arxiv.org/pdf/1101.5445v1", 
    "title": "Relating Sequent Calculi for Bi-intuitionistic Propositional Logic", 
    "arxiv-id": "1101.5445v1", 
    "author": "Tarmo Uustalu", 
    "publish": "2011-01-28T04:25:55Z", 
    "summary": "Bi-intuitionistic logic is the conservative extension of intuitionistic logic\nwith a connective dual to implication. It is sometimes presented as a symmetric\nconstructive subsystem of classical logic.\n  In this paper, we compare three sequent calculi for bi-intuitionistic\npropositional logic: (1) a basic standard-style sequent calculus that restricts\nthe premises of implication-right and exclusion-left inferences to be\nsingle-conclusion resp. single-assumption and is incomplete without the cut\nrule, (2) the calculus with nested sequents by Gore et al., where a complete\nclass of cuts is encapsulated into special \"unnest\" rules and (3) a cut-free\nlabelled sequent calculus derived from the Kripke semantics of the logic. We\nshow that these calculi can be translated into each other and discuss the\nineliminable cuts of the standard-style sequent calculus."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.47.8", 
    "link": "http://arxiv.org/pdf/1101.5446v1", 
    "title": "Dialectica Interpretation with Marked Counterexamples", 
    "arxiv-id": "1101.5446v1", 
    "author": "Trifon Trifonov", 
    "publish": "2011-01-28T04:26:02Z", 
    "summary": "Goedel's functional \"Dialectica\" interpretation can be used to extract\nfunctional programs from non-constructive proofs in arithmetic by employing two\nsorts of higher-order witnessing terms: positive realisers and negative\ncounterexamples. In the original interpretation decidability of atoms is\nrequired to compute the correct counterexample from a set of candidates. When\ncombined with recursion, this choice needs to be made for every step in the\nextracted program, however, in some special cases the decision on negative\nwitnesses can be calculated only once. We present a variant of the\ninterpretation in which the time complexity of extracted programs can be\nimproved by marking the chosen witness and thus avoiding recomputation. The\nachieved effect is similar to using an abortive control operator to interpret\ncomputational content of non-constructive principles."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.81.2", 
    "link": "http://arxiv.org/pdf/1102.0749v3", 
    "title": "Confluence via strong normalisation in an algebraic \u03bb-calculus   with rewriting", 
    "arxiv-id": "1102.0749v3", 
    "author": "Mauro Jaskelioff", 
    "publish": "2011-02-03T18:54:30Z", 
    "summary": "The linear-algebraic lambda-calculus and the algebraic lambda-calculus are\nuntyped lambda-calculi extended with arbitrary linear combinations of terms.\nThe former presents the axioms of linear algebra in the form of a rewrite\nsystem, while the latter uses equalities. When given by rewrites, algebraic\nlambda-calculi are not confluent unless further restrictions are added. We\nprovide a type system for the linear-algebraic lambda-calculus enforcing strong\nnormalisation, which gives back confluence. The type system allows an abstract\ninterpretation in System F."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.81.2", 
    "link": "http://arxiv.org/pdf/1102.1323v1", 
    "title": "Type Classes for Mathematics in Type Theory", 
    "arxiv-id": "1102.1323v1", 
    "author": "Eelis van der Weegen", 
    "publish": "2011-02-07T14:37:14Z", 
    "summary": "The introduction of first-class type classes in the Coq system calls for\nre-examination of the basic interfaces used for mathematical formalization in\ntype theory. We present a new set of type classes for mathematics and take full\nadvantage of their unique features to make practical a particularly flexible\napproach formerly thought infeasible. Thus, we address both traditional proof\nengineering challenges as well as new ones resulting from our ambition to build\nupon this development a library of constructive analysis in which abstraction\npenalties inhibiting efficient computation are reduced to a minimum.\n  The base of our development consists of type classes representing a standard\nalgebraic hierarchy, as well as portions of category theory and universal\nalgebra. On this foundation we build a set of mathematically sound abstract\ninterfaces for different kinds of numbers, succinctly expressed using\ncategorical language and universal algebra constructions. Strategic use of type\nclasses lets us support these high-level theory-friendly definitions while\nstill enabling efficient implementations unhindered by gratuitous indirection,\nconversion or projection.\n  Algebra thrives on the interplay between syntax and semantics. The\nProlog-like abilities of type class instance resolution allow us to\nconveniently define a quote function, thus facilitating the use of reflective\ntechniques."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.81.2", 
    "link": "http://arxiv.org/pdf/1102.1935v1", 
    "title": "On Paraconsistent Weakening of Intuitionistic Negation", 
    "arxiv-id": "1102.1935v1", 
    "author": "Zoran Majkic", 
    "publish": "2011-02-09T18:42:32Z", 
    "summary": "In [1], systems of weakening of intuitionistic negation logic called Z_n and\nCZ_n were developed in the spirit of da Costa's approach(c.f. [2]) by\npreserving, differently from da Costa, its fundamental properties:\nantitonicity, inversion and additivity for distributive lattices. However,\naccording to [3], those systems turned out to be not paraconsistent but\nextensions of intuitionistic logic. Taking into account of this result, we\nshall here make some observations on the modified systems of Z_n and CZ_n, that\nare paraconsistent as well."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.81.2", 
    "link": "http://arxiv.org/pdf/1102.2079v1", 
    "title": "Erratum to: Model-checking continuous-time Markov chains by Aziz et al", 
    "arxiv-id": "1102.2079v1", 
    "author": "David N. Jansen", 
    "publish": "2011-02-10T11:05:29Z", 
    "summary": "This note corrects a discrepancy between the semantics and the algorithm of\nthe multiple until operator of CSL, like in Pr_{> 0.0025} (a until[1,2] b\nuntil[3,4] c), of the article: Model-checking continuous-time Markov chains by\nAziz, Sanwal, Singhal and Brayton, TOCL 1(1), July 2000, pp. 162-170."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.81.2", 
    "link": "http://arxiv.org/pdf/1102.2366v1", 
    "title": "Stuttering Equivalence for Parity Games", 
    "arxiv-id": "1102.2366v1", 
    "author": "Tim A. C. Willemse", 
    "publish": "2011-02-11T15:24:56Z", 
    "summary": "We study the process theoretic notion of stuttering equivalence in the\nsetting of parity games. We demonstrate that stuttering equivalent vertices\nhave the same winner in the parity game. This means that solving a parity game\ncan be accelerated by minimising the game graph with respect to stuttering\nequivalence. While, at the outset, it might not be clear that this strategy\nshould pay off, our experiments using typical verification problems illustrate\nthat stuttering equivalence speeds up solving parity games in many cases."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(2:4)2011", 
    "link": "http://arxiv.org/pdf/1102.2405v3", 
    "title": "A Modular Type-checking algorithm for Type Theory with Singleton Types   and Proof Irrelevance", 
    "arxiv-id": "1102.2405v3", 
    "author": "Miguel Pagano", 
    "publish": "2011-02-11T18:06:53Z", 
    "summary": "We define a logical framework with singleton types and one universe of small\ntypes. We give the semantics using a PER model; it is used for constructing a\nnormalisation-by-evaluation algorithm. We prove completeness and soundness of\nthe algorithm; and get as a corollary the injectivity of type constructors.\nThen we give the definition of a correct and complete type-checking algorithm\nfor terms in normal form. We extend the results to proof-irrelevant\npropositions."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(2:4)2011", 
    "link": "http://arxiv.org/pdf/1102.2489v1", 
    "title": "Co-ordering and Type 2 co-ordering", 
    "arxiv-id": "1102.2489v1", 
    "author": "Farzad Didehvar", 
    "publish": "2011-02-12T09:44:56Z", 
    "summary": "In [arXiv:1006.4939] the enumeration order reducibility is defined on natural\nnumbers. For a c.e. set A, [A] denoted the class of all subsets of natural\nnumbers which are co-order with A. In definition 5 we redefine co-ordering for\nrational numbers. One of the main questions there, was: \"For a specific c.e.\nset A, consider set of all enumerations of it which is generated by some Turing\nmachine {TM_A} what are the associated order types in [A]?\" Here, we propose\nthe same question for rational numbers, and we try to investigate the varieties\nof c.e. sets on Q. The theories here are hold for R_c and we could repeat the\nsame theories in this domain, in a parallel way."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.48.3", 
    "link": "http://arxiv.org/pdf/1102.2651v1", 
    "title": "Term Graph Rewriting and Parallel Term Rewriting", 
    "arxiv-id": "1102.2651v1", 
    "author": "Frank Drewes", 
    "publish": "2011-02-14T01:09:17Z", 
    "summary": "The relationship between Term Graph Rewriting and Term Rewriting is well\nunderstood: a single term graph reduction may correspond to several term\nreductions, due to sharing. It is also known that if term graphs are allowed to\ncontain cycles, then one term graph reduction may correspond to infinitely many\nterm reductions. We stress that this fact can be interpreted in two ways.\nAccording to the \"sequential interpretation\", a term graph reduction\ncorresponds to an infinite sequence of term reductions, as formalized by\nKennaway et.al. using strongly converging derivations over the complete metric\nspace of infinite terms. Instead according to the \"parallel interpretation\" a\nterm graph reduction corresponds to the parallel reduction of an infinite set\nof redexes in a rational term. We formalize the latter notion by exploiting the\ncomplete partial order of infinite and possibly partial terms, and we stress\nthat this interpretation allows to explain the result of reducing circular\nredexes in several approaches to term graph rewriting."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.48.8", 
    "link": "http://arxiv.org/pdf/1102.2655v1", 
    "title": "A new graphical calculus of proofs", 
    "arxiv-id": "1102.2655v1", 
    "author": "Ian Mackie", 
    "publish": "2011-02-14T01:09:45Z", 
    "summary": "We offer a simple graphical representation for proofs of intuitionistic\nlogic, which is inspired by proof nets and interaction nets (two formalisms\noriginating in linear logic). This graphical calculus of proofs inherits good\nfeatures from each, but is not constrained by them. By the Curry-Howard\nisomorphism, the representation applies equally to the lambda calculus,\noffering an alternative diagrammatic representation of functional computations."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.49.4", 
    "link": "http://arxiv.org/pdf/1102.3733v1", 
    "title": "Uncurrying for Innermost Termination and Derivational Complexity", 
    "arxiv-id": "1102.3733v1", 
    "author": "Aart Middeldorp", 
    "publish": "2011-02-18T01:44:38Z", 
    "summary": "First-order applicative term rewriting systems provide a natural framework\nfor modeling higher-order aspects. In earlier work we introduced an uncurrying\ntransformation which is termination preserving and reflecting. In this paper we\ninvestigate how this transformation behaves for innermost termination and\n(innermost) derivational complexity. We prove that it reflects innermost\ntermination and innermost derivational complexity and that it preserves and\nreflects polynomial derivational complexity. For the preservation of innermost\ntermination and innermost derivational complexity we give counterexamples.\nHence uncurrying may be used as a preprocessing transformation for innermost\ntermination proofs and establishing polynomial upper and lower bounds on the\nderivational complexity. Additionally it may be used to establish upper bounds\non the innermost derivational complexity while it neither is sound for proving\ninnermost non-termination nor for obtaining lower bounds on the innermost\nderivational complexity."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.50.1", 
    "link": "http://arxiv.org/pdf/1102.4117v1", 
    "title": "Experimental Aspects of Synthesis", 
    "arxiv-id": "1102.4117v1", 
    "author": "R\u00fcdiger Ehlers", 
    "publish": "2011-02-21T02:30:25Z", 
    "summary": "We discuss the problem of experimentally evaluating linear-time temporal\nlogic (LTL) synthesis tools for reactive systems. We first survey previous such\nwork for the currently publicly available synthesis tools, and then draw\nconclusions by deriving useful schemes for future such evaluations.\n  In particular, we explain why previous tools have incompatible scopes and\nsemantics and provide a framework that reduces the impact of this problem for\nfuture experimental comparisons of such tools. Furthermore, we discuss which\ndifficulties the complex workflows that begin to appear in modern synthesis\ntools induce on experimental evaluations and give answers to the question how\nconvincing such evaluations can still be performed in such a setting."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.50.2", 
    "link": "http://arxiv.org/pdf/1102.4118v1", 
    "title": "Synthesizing Systems with Optimal Average-Case Behavior for Ratio   Objectives", 
    "arxiv-id": "1102.4118v1", 
    "author": "Barbara Jobstmann", 
    "publish": "2011-02-21T02:30:32Z", 
    "summary": "We show how to automatically construct a system that satisfies a given\nlogical specification and has an optimal average behavior with respect to a\nspecification with ratio costs.\n  When synthesizing a system from a logical specification, it is often the case\nthat several different systems satisfy the specification. In this case, it is\nusually not easy for the user to state formally which system she prefers. Prior\nwork proposed to rank the correct systems by adding a quantitative aspect to\nthe specification. A desired preference relation can be expressed with (i) a\nquantitative language, which is a function assigning a value to every possible\nbehavior of a system, and (ii) an environment model defining the desired\noptimization criteria of the system, e.g., worst-case or average-case optimal.\n  In this paper, we show how to synthesize a system that is optimal for (i) a\nquantitative language given by an automaton with a ratio cost function, and\n(ii) an environment model given by a labeled Markov decision process. The\nobjective of the system is to minimize the expected (ratio) costs. The solution\nis based on a reduction to Markov Decision Processes with ratio cost functions\nwhich do not require that the costs in the denominator are strictly positive.\nWe find an optimal strategy for these using a fractional linear program."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.50.3", 
    "link": "http://arxiv.org/pdf/1102.4119v1", 
    "title": "A LTL Fragment for GR(1)-Synthesis", 
    "arxiv-id": "1102.4119v1", 
    "author": "Klaus Schneider", 
    "publish": "2011-02-21T02:30:38Z", 
    "summary": "The idea of automatic synthesis of reactive programs starting from temporal\nlogic (LTL) specifications is quite old, but was commonly thought to be\ninfeasible due to the known double exponential complexity of the problem.\nHowever, new ideas have recently renewed the interest in LTL synthesis: One\nmajor new contribution in this area is the recent work of Piterman et al. who\nshowed how polynomial time synthesis can be achieved for a large class of LTL\nspecifications that is expressive enough to cover many practical examples.\nThese LTL specifications are equivalent to omega-automata having a so-called\nGR(1) acceptance condition. This approach has been used to automatically\nsynthesize implementations of real-world applications. To this end, manually\nwritten deterministic omega-automata having GR(1) conditions were used instead\nof the original LTL specifications. However, manually generating deterministic\nmonitors is, of course, a hard and error-prone task. In this paper, we\ntherefore present algorithms to automatically translate specifications of a\nremarkable large fragment of LTL to deterministic monitors having a GR(1)\nacceptance condition so that the synthesis algorithms can start with more\nreadable LTL specifications."
},{
    "category": "cs.LO", 
    "doi": "10.1007/s10849-012-9165-1", 
    "link": "http://arxiv.org/pdf/1102.4496v5", 
    "title": "A system of relational syllogistic incorporating full Boolean reasoning", 
    "arxiv-id": "1102.4496v5", 
    "author": "Dimiter Vakarelov", 
    "publish": "2011-02-22T13:25:32Z", 
    "summary": "We present a system of relational syllogistic, based on classical\npropositional logic, having primitives of the following form:\n  Some A are R-related to some B;\n  Some A are R-related to all B;\n  All A are R-related to some B;\n  All A are R-related to all B.\n  Such primitives formalize sentences from natural language like `All students\nread some textbooks'. Here A and B denote arbitrary sets (of objects), and R\ndenotes an arbitrary binary relation between objects. The language of the logic\ncontains only variables denoting sets, determining the class of set terms, and\nvariables denoting binary relations between objects, determining the class of\nrelational terms. Both classes of terms are closed under the standard Boolean\noperations. The set of relational terms is also closed under taking the\nconverse of a relation. The results of the paper are the completeness theorem\nwith respect to the intended semantics and the computational complexity of the\nsatisfiability problem."
},{
    "category": "cs.LO", 
    "doi": "10.1007/s10849-012-9165-1", 
    "link": "http://arxiv.org/pdf/1102.4636v1", 
    "title": "Modal Calculus of Illocutionary Logic", 
    "arxiv-id": "1102.4636v1", 
    "author": "Andrew Schumann", 
    "publish": "2011-02-22T22:36:05Z", 
    "summary": "The aim of illocutionary logic is to explain how context can affect the\nmeaning of certain special kinds of performative utterances. Recall that\nperformative utterances are understood as follows: a speaker performs the\nillocutionary act (e.g. act of assertion, of conjecture, of promise) with the\nillocutionary force (resp. assertion, conjecture, promise) named by an\nappropriate performative verb in the way of representing himself as performing\nthat act. In the paper I proposed many-valued interpretation of illocutionary\nforces understood as modal operators. As a result, I built up a non-Archimedean\nvalued logic for formalizing illocutionary acts. A formal many-valued approach\nto illocutionary logic was offered for the first time."
},{
    "category": "cs.LO", 
    "doi": "10.1007/s10849-012-9165-1", 
    "link": "http://arxiv.org/pdf/1102.5638v2", 
    "title": "On Expressive Powers of Timed Logics: Comparing Boundedness,   Non-punctuality and Deterministic Freezing", 
    "arxiv-id": "1102.5638v2", 
    "author": "Simoni S. Shah", 
    "publish": "2011-02-28T11:10:58Z", 
    "summary": "Timed temporal logics exhibit a bewildering diversity of operators and the\nresulting decidability and expressiveness properties also vary considerably. We\nstudy the expressive power of timed logics TPTL[U,S] and MTL[U,S] as well as of\ntheir several fragments. Extending the LTL EF games of Etessami and Wilke, we\ndefine MTL Ehrenfeucht-Fraisse games on a pair of timed words. Using the\nassociated EF theorem, we show that, expressively, the timed logics\nBoundedMTL[U,S], MTL[F,P] and MITL[U,S] (respectively incorporating the\nrestrictions of boundedness, unary modalities and non-punctuality), are all\npairwise incomparable. As our first main result, we show that MTL[U,S] is\nstrictly contained within the freeze logic TPTL[U,S] for both weakly and\nstrictly monotonic timed words, thereby extending the result of Bouyer et al\nand completing the proof of the original conjecture of Alur and Henziger from\n1990. We also relate the expressiveness of a recently proposed deterministic\nfreeze logic TTL[X,Y] (with NP-complete satisfiability) to MTL. As our second\nmain result, we show by an explicit reduction that TTL[X,Y] lies strictly\nwithin the unary, non-punctual logic MITL[F,P]. This shows that deterministic\nfreezing with punctuality is expressible in the non-punctual MITL[F,P]."
},{
    "category": "cs.LO", 
    "doi": "10.1007/s10849-012-9165-1", 
    "link": "http://arxiv.org/pdf/1103.0217v1", 
    "title": "A New Representation Theorem for Many-valued Modal Logics", 
    "arxiv-id": "1103.0217v1", 
    "author": "Zoran Majkic", 
    "publish": "2011-03-01T16:56:57Z", 
    "summary": "We propose a new definition of the representation theorem for many-valued\nlogics, with modal operators as well, and define the stronger relationship\nbetween algebraic models of a given logic and relational structures used to\ndefine the Kripke possible-world semantics for it. Such a new framework offers\na new semantics for many-valued logics based on the truth-invariance\nentailment. Consequently, it is substantially different from current\ndefinitions based on a matrix with a designated subset of logic values, used\nfor the satisfaction relation, often difficult to fix. In the case when the\nmany-valued modal logics are based on the set of truth-values that are complete\ndistributive lattices we obtain a compact autoreferential Kripke-style\ncanonical representation. The Kripke-style semantics for this subclass of modal\nlogics have the joint-irreducible subset of the carrier set of many-valued\nalgebras as set of possible worlds. A significant member of this subclass is\nthe paraconsistent fuzzy logic extended by new logic values in order to also\ndeal with incomplete and inconsistent information. This new theory is applied\nfor the case of autoepistemic intuitionistic many-valued logic, based on\nBelnap's 4-valued bilattice, as a minimal extension of classical logic used to\nmanage incomplete and inconsistent information as well."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(2:7)2011", 
    "link": "http://arxiv.org/pdf/1103.0437v2", 
    "title": "Symbolic and Asynchronous Semantics via Normalized Coalgebras", 
    "arxiv-id": "1103.0437v2", 
    "author": "Ugo Montanari", 
    "publish": "2011-03-02T14:19:42Z", 
    "summary": "The operational semantics of interactive systems is usually described by\nlabeled transition systems. Abstract semantics (that is defined in terms of\nbisimilarity) is characterized by the final morphism in some category of\ncoalgebras. Since the behaviour of interactive systems is for many reasons\ninfinite, symbolic semantics were introduced as a mean to define smaller,\npossibly finite, transition systems, by employing symbolic actions and avoiding\nsome sources of infiniteness. Unfortunately, symbolic bisimilarity has a\ndifferent shape with respect to ordinary bisimilarity, and thus the standard\ncoalgebraic characterization does not work. In this paper, we introduce its\ncoalgebraic models. We will use as motivating examples two asynchronous\nformalisms: open Petri nets and asynchronous pi-calculus. Indeed, as we have\nshown in a previous paper, asynchronous bisimilarity can be seen as an instance\nof symbolic bisimilarity."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(2:7)2011", 
    "link": "http://arxiv.org/pdf/1103.0676v1", 
    "title": "Probabilistic Logic: Many-valuedness and Intensionality", 
    "arxiv-id": "1103.0676v1", 
    "author": "Zoran Majkic", 
    "publish": "2011-03-03T13:03:15Z", 
    "summary": "The probability theory is a well-studied branch of mathematics, in order to\ncarry out formal reasoning about probability. Thus, it is important to have a\nlogic, both for computation of probabilities and for reasoning about\nprobabilities, with a well-defined syntax and semantics. Both current\napproaches, based on Nilsson's probability structures/logics, and on linear\ninequalities in order to reason about probabilities, have some weak points. In\nthis paper we have presented the complete revision of both approaches. We have\nshown that the full embedding of Nilsson'probabilistic structure into\npropositional logic results in a truth-functional many-valued logic,\ndifferently from Nilsson's intuition and current considerations about\npropositional probabilistic logic. Than we have shown that the logic for\nreasoning about probabilities can be naturally embedded into a 2-valued\nintensional FOL with intensional abstraction, by avoiding current ad-hoc system\ncomposed of two different 2-valued logics: one for the classical propositional\nlogic at lower-level, and a new one at higher-level for probabilistic\nconstraints with probabilistic variables. The obtained theoretical results are\napplied to Probabilistic Logic Programming."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(2:7)2011", 
    "link": "http://arxiv.org/pdf/1103.1061v1", 
    "title": "Temporal Probabilistic Logic Programs: State and Revision", 
    "arxiv-id": "1103.1061v1", 
    "author": "Zoran Majkic", 
    "publish": "2011-03-05T15:21:58Z", 
    "summary": "There are numerous applications where we have to deal with temporal\nuncertainty associated with events. The Temporal Probabilistic (TP) Logic\nPrograms should provide support for valid-time indeterminacy of events, by\nproposing the concept of an indeterminate instant, that is, an interval of\ntime-points (event's time-window) with an associated, lower and upper,\nprobability distribution. In particular, we propose the new semantics, for the\nTP Logic Programs of Dekhtyar and Subrahmanian. Our semantics, based on the\npossible world semantics is a generalization of the possible world semantics\nfor (non temporal) Probabilistic Logic Programming, and we define the new\nsyntax for PT-programs, with time variable explicitly represented in all atoms,\nand show how the standard role of Herbrand interpretations used as possible\nworlds for probability distributions is coherently extended to Temporal\nProbabilistic Logic Programming."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(2:7)2011", 
    "link": "http://arxiv.org/pdf/1103.1334v1", 
    "title": "Binary Sequent Calculi for Truth-invariance Entailment of Finite   Many-valued Logics", 
    "arxiv-id": "1103.1334v1", 
    "author": "Zoran Majkic", 
    "publish": "2011-03-07T19:03:44Z", 
    "summary": "In this paper we consider the class of truth-functional many-valued logics\nwith a finite set of truth-values. The main result of this paper is the\ndevelopment of a new \\emph{binary} sequent calculi (each sequent is a pair of\nformulae) for many valued logic with a finite set of truth values, and of\nKripke-like semantics for it that is both sound and complete. We did not use\nthe logic entailment based on matrix with a strict subset of designated truth\nvalues, but a different new kind of semantics based on the generalization of\nthe classic 2-valued truth-invariance entailment. In order to define this\nnon-matrix based sequent calculi, we transform many-valued logic into positive\n2-valued multi-modal logic with classic conjunction, disjunction and finite set\nof modal connectives. In this algebraic framework we define an uniquely\ndetermined axiom system, by extending the classic 2-valued distributive lattice\nlogic (DLL) by a new set of sequent axioms for many-valued logic connectives.\nDually, in an autoreferential Kripke-style framework we obtain a uniquely\ndetermined frame, where each possible world is an equivalence class of\nLindenbaum algebra for a many-valued logic as well, represented by a truth\nvalue."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(2:7)2011", 
    "link": "http://arxiv.org/pdf/1103.2246v1", 
    "title": "Formal verification of a time-triggered hardware interface", 
    "arxiv-id": "1103.2246v1", 
    "author": "Julien Schmaltz", 
    "publish": "2011-03-11T11:11:13Z", 
    "summary": "We present a formal proof of a time-triggered hardware interface. The design\nimplements the bit-clock synchronization mechanism specified by the FlexRay\nstandard for automotive embedded systems. The design is described at the\ngate-level. It can be translated to Verilog and synthesized on FPGA. The proof\nis based on a general model of asynchronous communications and combines\ninteractive theorem proving in Isabelle/HOL and automatic model-checking using\nNuSMV together with a model-reduction procedure, IHaVeIt. Our general model of\nasynchronous communications defines a clear separation between analog and\ndigital concerns. This separation enables the combination of theorem proving\nand model-checking for an efficient methodology. The analog phenomena are\nformalized in the logic of Isabelle/HOL. The gate-level hardware is\nautomatically analyzed using IHaVeIt. Our proof reveals the correct values of a\ncrucial parameter of the bit-clock synchronization mechanism. Our main theorem\nproves the functional correctness as well as the maximum number of cycles of\nthe transmission."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(2:7)2011", 
    "link": "http://arxiv.org/pdf/1103.3239v1", 
    "title": "Generic Trace Logics", 
    "arxiv-id": "1103.3239v1", 
    "author": "Alexander Kurz", 
    "publish": "2011-03-16T17:32:42Z", 
    "summary": "We combine previous work on coalgebraic logic with the coalgebraic traces\nsemantics of Hasuo, Jacobs, and Sokolova."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.53.1", 
    "link": "http://arxiv.org/pdf/1103.3319v1", 
    "title": "Superposition as a logical glue", 
    "arxiv-id": "1103.3319v1", 
    "author": "Enrico Tassi", 
    "publish": "2011-03-17T00:19:29Z", 
    "summary": "The typical mathematical language systematically exploits notational and\nlogical abuses whose resolution requires not just the knowledge of domain\nspecific notation and conventions, but not trivial skills in the given\nmathematical discipline. A large part of this background knowledge is expressed\nin form of equalities and isomorphisms, allowing mathematicians to freely move\nbetween different incarnations of the same entity without even mentioning the\ntransformation. Providing ITP-systems with similar capabilities seems to be a\nmajor way to improve their intelligence, and to ease the communication between\nthe user and the machine. The present paper discusses our experience of\nintegration of a superposition calculus within the Matita interactive prover,\nproviding in particular a very flexible, \"smart\" application tactic, and a\nsimple, innovative approach to automation."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.53.2", 
    "link": "http://arxiv.org/pdf/1103.3320v1", 
    "title": "Nonuniform Coercions via Unification Hints", 
    "arxiv-id": "1103.3320v1", 
    "author": "Enrico Tassi", 
    "publish": "2011-03-17T00:19:35Z", 
    "summary": "We introduce the notion of nonuniform coercion, which is the promotion of a\nvalue of one type to an enriched value of a different type via a nonuniform\nprocedure. Nonuniform coercions are a generalization of the (uniform) coercions\nknown in the literature and they arise naturally when formalizing mathematics\nin an higher order interactive theorem prover using convenient devices like\ncanonical structures, type classes or unification hints. We also show how\nnonuniform coercions can be naturally implemented at the user level in an\ninteractive theorem prover that allows unification hints."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.53.3", 
    "link": "http://arxiv.org/pdf/1103.3321v1", 
    "title": "Typed Operational Semantics for Dependent Record Types", 
    "arxiv-id": "1103.3321v1", 
    "author": "Zhaohui Luo", 
    "publish": "2011-03-17T00:19:42Z", 
    "summary": "Typed operational semantics is a method developed by H. Goguen to prove\nmeta-theoretic properties of type systems. This paper studies the metatheory of\na type system with dependent record types, using the approach of typed\noperational semantics. In particular, the metatheoretical properties we have\nproved include strong normalisation, Church-Rosser and subject reduction."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.53.4", 
    "link": "http://arxiv.org/pdf/1103.3322v1", 
    "title": "Stateless HOL", 
    "arxiv-id": "1103.3322v1", 
    "author": "Freek Wiedijk", 
    "publish": "2011-03-17T00:19:48Z", 
    "summary": "We present a version of the HOL Light system that supports undoing\ndefinitions in such a way that this does not compromise the soundness of the\nlogic. In our system the code that keeps track of the constants that have been\ndefined thus far has been moved out of the kernel. This means that the kernel\nnow is purely functional.\n  The changes to the system are small. All existing HOL Light developments can\nbe run by the stateless system with only minor changes.\n  The basic principle behind the system is not to name constants by strings,\nbut by pairs consisting of a string and a definition. This means that the data\nstructures for the terms are all merged into one big graph. OCaml - the\nimplementation language of the system - can use pointer equality to establish\nequality of data structures fast. This allows the system to run at acceptable\nspeeds. Our system runs at about 85% of the speed of the stateful version of\nHOL Light."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.53.4", 
    "link": "http://arxiv.org/pdf/1103.4515v1", 
    "title": "Real Islamic Logic", 
    "arxiv-id": "1103.4515v1", 
    "author": "Jan Aldert Bergstra", 
    "publish": "2011-03-23T13:43:03Z", 
    "summary": "Four options for assigning a meaning to Islamic Logic are surveyed including\na new proposal for an option named \"Real Islamic Logic\" (RIL). That approach to\nIslamic Logic should serve modern Islamic objectives in a way comparable to the\nfunctionality of Islamic Finance. The prospective role of RIL is analyzed from\nseveral perspectives: (i) parallel distributed systems design, (ii) reception\nby a community structured audience, (iii) informal logic and applied\nnon-classical logics, and (iv) (in)tractability and artificial intelligence."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.53.4", 
    "link": "http://arxiv.org/pdf/1103.4577v1", 
    "title": "Logical, Metric, and Algorithmic Characterisations of Probabilistic   Bisimulation", 
    "arxiv-id": "1103.4577v1", 
    "author": "Wenjie Du", 
    "publish": "2011-03-23T17:16:50Z", 
    "summary": "Many behavioural equivalences or preorders for probabilistic processes\ninvolve a lifting operation that turns a relation on states into a relation on\ndistributions of states. We show that several existing proposals for lifting\nrelations can be reconciled to be different presentations of essentially the\nsame lifting operation. More interestingly, this lifting operation nicely\ncorresponds to the Kantorovich metric, a fundamental concept used in\nmathematics to lift a metric on states to a metric on distributions of states,\nbesides the fact the lifting operation is related to the maximum flow problem\nin optimisation theory.\n  The lifting operation yields a neat notion of probabilistic bisimulation, for\nwhich we provide logical, metric, and algorithmic characterisations.\nSpecifically, we extend the Hennessy-Milner logic and the modal mu-calculus\nwith a new modality, resulting in an adequate and an expressive logic for\nprobabilistic bisimilarity, respectively. The correspondence of the lifting\noperation and the Kantorovich metric leads to a natural characterisation of\nbisimulations as pseudometrics which are post-fixed points of a monotone\nfunction. We also present an \"on the fly\" algorithm to check if two states in a\nfinitary system are related by probabilistic bisimilarity, exploiting the close\nrelationship between the lifting operation and the maximum flow problem."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.53.4", 
    "link": "http://arxiv.org/pdf/1103.4694v1", 
    "title": "Cyclic and Inductive Calculi are equivalent", 
    "arxiv-id": "1103.4694v1", 
    "author": "Mengran Li", 
    "publish": "2011-03-24T08:07:01Z", 
    "summary": "Brotherston and Simpson [citation] have formalized and investigated cyclic\nreasoning, reaching the important conclusion that it is at least as powerful as\ninductive reasoning (specifically, they showed that each inductive proof can be\ntranslated into a cyclic proof). We add to their investigation by proving the\nconverse of this result, namely that each inductive proof can be translated\ninto an inductive one. This, in effect, establishes the equivalence between\nfirst order cyclic and inductive calculi."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.53.4", 
    "link": "http://arxiv.org/pdf/1103.5082v1", 
    "title": "Termination Proofs in the Dependency Pair Framework May Induce Multiple   Recursive Derivational Complexity", 
    "arxiv-id": "1103.5082v1", 
    "author": "Andreas Schnabl", 
    "publish": "2011-03-25T21:00:46Z", 
    "summary": "We study the derivational complexity of rewrite systems whose termination is\nprovable in the dependency pair framework using the processors for reduction\npairs, dependency graphs, or the subterm criterion. We show that the\nderivational complexity of such systems is bounded by a multiple recursive\nfunction, provided the derivational complexity induced by the employed base\ntechniques is at most multiple recursive. Moreover we show that this upper\nbound is tight."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(2:8)2011", 
    "link": "http://arxiv.org/pdf/1103.5286v2", 
    "title": "On the Correspondence between Display Postulates and Deep Inference in   Nested Sequent Calculi for Tense Logics", 
    "arxiv-id": "1103.5286v2", 
    "author": "Alwen F Tiu", 
    "publish": "2011-03-28T06:49:31Z", 
    "summary": "We consider two styles of proof calculi for a family of tense logics,\npresented in a formalism based on nested sequents. A nested sequent can be seen\nas a tree of traditional single-sided sequents. Our first style of calculi is\nwhat we call \"shallow calculi\", where inference rules are only applied at the\nroot node in a nested sequent. Our shallow calculi are extensions of Kashima's\ncalculus for tense logic and share an essential characteristic with display\ncalculi, namely, the presence of structural rules called \"display postulates\".\nShallow calculi enjoy a simple cut elimination procedure, but are unsuitable\nfor proof search due to the presence of display postulates and other structural\nrules. The second style of calculi uses deep-inference, whereby inference rules\ncan be applied at any node in a nested sequent. We show that, for a range of\nextensions of tense logic, the two styles of calculi are equivalent, and there\nis a natural proof theoretic correspondence between display postulates and deep\ninference. The deep inference calculi enjoy the subformula property and have no\ndisplay postulates or other structural rules, making them a better framework\nfor proof search."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.ipl.2011.03.013", 
    "link": "http://arxiv.org/pdf/1103.5916v1", 
    "title": "Abstract Processes of Place/Transition Systems", 
    "arxiv-id": "1103.5916v1", 
    "author": "Jens-Wolfhard Schicke", 
    "publish": "2011-03-30T13:14:03Z", 
    "summary": "A well-known problem in Petri net theory is to formalise an appropriate\ncausality-based concept of process or run for place/transition systems. The\nso-called individual token interpretation, where tokens are distinguished\naccording to their causal history, giving rise to the processes of Goltz and\nReisig, is often considered too detailed. The problem of defining a fully\nsatisfying more abstract concept of process for general place/transition\nsystems has so-far not been solved. In this paper, we recall the proposal of\ndefining an abstract notion of process, here called BD-process, in terms of\nequivalence classes of Goltz-Reisig processes, using an equivalence proposed by\nBest and Devillers. It yields a fully satisfying solution for at least all\none-safe nets. However, for certain nets which intuitively have different\nconflicting behaviours, it yields only one maximal abstract process. Here we\nidentify a class of place/transition systems, called structural conflict nets,\nwhere conflict and concurrency due to token multiplicity are clearly separated.\nWe show that, in the case of structural conflict nets, the equivalence proposed\nby Best and Devillers yields a unique maximal abstract process only for\nconflict-free nets. Thereby BD-processes constitute a simple and fully\nsatisfying solution in the class of structural conflict nets."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.ipl.2011.03.013", 
    "link": "http://arxiv.org/pdf/1105.0548v1", 
    "title": "A Scalable Module System", 
    "arxiv-id": "1105.0548v1", 
    "author": "Michael Kohlhase", 
    "publish": "2011-05-03T11:05:34Z", 
    "summary": "Symbolic and logic computation systems ranging from computer algebra systems\nto theorem provers are finding their way into science, technology, mathematics\nand engineering. But such systems rely on explicitly or implicitly represented\nmathematical knowledge that needs to be managed to use such systems\neffectively.\n  While mathematical knowledge management (MKM) \"in the small\" is well-studied,\nscaling up to large, highly interconnected corpora remains difficult. We hold\nthat in order to realize MKM \"in the large\", we need representation languages\nand software architectures that are designed systematically with large-scale\nprocessing in mind.\n  Therefore, we have designed and implemented the MMT language -- a module\nsystem for mathematical theories. MMT is designed as the simplest possible\nlanguage that combines a module system, a foundationally uncommitted formal\nsemantics, and web-scalable implementations. Due to a careful choice of\nrepresentational primitives, MMT allows us to integrate existing representation\nlanguages for formal mathematical knowledge in a simple, scalable formalism. In\nparticular, MMT abstracts from the underlying mathematical and logical\nfoundations so that it can serve as a standardized representation format for a\nformal digital library. Moreover, MMT systematically separates logic-dependent\nand logic-independent concerns so that it can serve as an interface layer\nbetween computation systems and MKM systems."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.ipl.2011.03.013", 
    "link": "http://arxiv.org/pdf/1105.0653v1", 
    "title": "Model Checking of Boolean Process Models", 
    "arxiv-id": "1105.0653v1", 
    "author": "Joachim Wehler", 
    "publish": "2011-05-03T18:49:18Z", 
    "summary": "In the field of Business Process Management formal models for the control\nflow of business processes have been designed since more than 15 years. Which\nmethods are best suited to verify the bulk of these models? The first step is\nto select a formal language which fixes the semantics of the models. We adopt\nthe language of Boolean systems as reference language for Boolean process\nmodels. Boolean systems form a simple subclass of coloured Petri nets. Their\ncharacteristics are low tokens to model explicitly states with a subsequent\nskipping of activations and arbitrary logical rules of type AND, XOR, OR etc.\nto model the split and join of the control flow. We apply model checking as a\nverification method for the safeness and liveness of Boolean systems. Model\nchecking of Boolean systems uses the elementary theory of propositional logic,\nno modal operators are needed. Our verification builds on a finite complete\nprefix of a certain T-system attached to the Boolean system. It splits the\nprocesses of the Boolean system into a finite set of base processes of bounded\nlength. Their behaviour translates to formulas from propositional logic. Our\nverification task consists in checking the satisfiability of these formulas. In\naddition we have implemented our model checking algorithm as a java program.\nThe time needed to verify a given Boolean system depends critically on the\nnumber of initial tokens. Because the algorithm has to solve certain\nSAT-problems, polynomial complexity cannot be expected. The paper closes with\nthe model checking of some Boolean process models which have been designed as\nEvent-driven Process Chains."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.ipl.2011.03.013", 
    "link": "http://arxiv.org/pdf/1105.1369v1", 
    "title": "Evaluating the Efficiency of Asynchronous Systems with FASE", 
    "arxiv-id": "1105.1369v1", 
    "author": "Walter Vogler", 
    "publish": "2011-05-06T10:16:36Z", 
    "summary": "In this paper, we present FASE (Faster Asynchronous Systems Evaluation), a\ntool for evaluating the worst-case efficiency of asynchronous systems. The tool\nis based on some well-established results in the setting of a timed process\nalgebra (PAFAS: a Process Algebra for Faster Asynchronous Systems). To show the\napplicability of FASE to concrete meaningful examples, we consider three\nimplementations of a bounded buffer and use FASE to automatically evaluate\ntheir worst-case efficiency. We finally contrast our results with previous ones\nwhere the efficiency of the same implementations has already been considered."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.ipl.2011.03.013", 
    "link": "http://arxiv.org/pdf/1105.1376v1", 
    "title": "Finitary Deduction Systems", 
    "arxiv-id": "1105.1376v1", 
    "author": "Yannick Chevalier", 
    "publish": "2011-05-06T20:01:26Z", 
    "summary": "Cryptographic protocols are the cornerstone of security in distributed\nsystems. The formal analysis of their properties is accordingly one of the\nfocus points of the security community, and is usually split among two groups.\nIn the first group, one focuses on trace-based security properties such as\nconfidentiality and authentication, and provides decision procedures for the\nexistence of attacks for an on-line attackers. In the second group, one focuses\non equivalence properties such as privacy and guessing attacks, and provides\ndecision procedures for the existence of attacks for an offline attacker. In\nall cases the attacker is modeled by a deduction system in which his possible\nactions are expressed. We present in this paper a notion of finitary deduction\nsystems that aims at relating both approaches. We prove that for such deduction\nsystems, deciding equivalence properties for on-line attackers can be reduced\nto deciding reachability properties in the same setting."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.ipl.2011.03.013", 
    "link": "http://arxiv.org/pdf/1105.2665v2", 
    "title": "Dynamic Backward Slicing of Rewriting Logic Computations", 
    "arxiv-id": "1105.2665v2", 
    "author": "Daniel Romero", 
    "publish": "2011-05-13T09:12:20Z", 
    "summary": "Trace slicing is a widely used technique for execution trace analysis that is\neffectively used in program debugging, analysis and comprehension. In this\npaper, we present a backward trace slicing technique that can be used for the\nanalysis of Rewriting Logic theories. Our trace slicing technique allows us to\nsystematically trace back rewrite sequences modulo equational axioms (such as\nassociativity and commutativity) by means of an algorithm that dynamically\nsimplifies the traces by detecting control and data dependencies, and dropping\nuseless data that do not influence the final result. Our methodology is\nparticularly suitable for analyzing complex, textually-large system\ncomputations such as those delivered as counter-example traces by Maude\nmodel-checkers."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-22673-1_8", 
    "link": "http://arxiv.org/pdf/1105.2725v1", 
    "title": "A Foundational View on Integration Problems", 
    "arxiv-id": "1105.2725v1", 
    "author": "Claudio Sacerdoti Coen", 
    "publish": "2011-05-13T13:38:08Z", 
    "summary": "The integration of reasoning and computation services across system and\nlanguage boundaries is a challenging problem of computer science. In this\npaper, we use integration for the scenario where we have two systems that we\nintegrate by moving problems and solutions between them. While this scenario is\noften approached from an engineering perspective, we take a foundational view.\nBased on the generic declarative language MMT, we develop a theoretical\nframework for system integration using theories and partial theory morphisms.\nBecause MMT permits representations of the meta-logical foundations themselves,\nthis includes integration across logics. We discuss safe and unsafe integration\nschemes and devise a general form of safe integration."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-22673-1_7", 
    "link": "http://arxiv.org/pdf/1105.2751v1", 
    "title": "Computer certified efficient exact reals in Coq", 
    "arxiv-id": "1105.2751v1", 
    "author": "Bas Spitters", 
    "publish": "2011-05-13T15:13:57Z", 
    "summary": "Floating point operations are fast, but require continuous effort on the part\nof the user in order to ensure that the results are correct. This burden can be\nshifted away from the user by providing a library of exact analysis in which\nthe computer handles the error estimates. We provide an implementation of the\nexact real numbers in the Coq proof assistant. This improves on the earlier\nCoq-implementation by O'Connor in two ways: we use dyadic rationals built from\nthe machine integers and we optimize computation of power series by using\napproximate division. Moreover, we use type classes for clean mathematical\ninterfaces. This appears to be the first time that type classes are used in\nheavy computation. We obtain over a 100 times speed up of the basic operations\nand indications for improving the Coq system."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-22673-1_7", 
    "link": "http://arxiv.org/pdf/1105.3324v1", 
    "title": "Hierarchies in Dependence Logic", 
    "arxiv-id": "1105.3324v1", 
    "author": "Juha Kontinen", 
    "publish": "2011-05-17T09:51:16Z", 
    "summary": "We study fragments of dependence logic defined either by restricting the\nnumber k of universal quantifiers or the width of dependence atoms in formulas.\nWe find the sublogics of existential second-order logic corresponding to these\nfragments of dependence logic. We also show that these both ways of defining\nfragments of dependence logic give rise to a hierarchy in expressive power with\nrespect to k."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(2:20)2011", 
    "link": "http://arxiv.org/pdf/1105.3583v4", 
    "title": "First-order query evaluation on structures of bounded degree", 
    "arxiv-id": "1105.3583v4", 
    "author": "Luc Segoufin", 
    "publish": "2011-05-18T10:17:11Z", 
    "summary": "We consider the enumeration problem of first-order queries over structures of\nbounded degree. It was shown that this problem is in the Constant-Delaylin\nclass. An enumeration problem belongs to Constant-Delaylin if for an input of\nsize n it can be solved by: - an O(n) precomputation phase building an index\nstructure, - followed by a phase enumerating the answers with no repetition and\na constant delay between two consecutive outputs. In this article we give a\ndifferent proof of this result based on Gaifman's locality theorem for\nfirst-order logic. Moreover, the constants we obtain yield a total evaluation\ntime that is triply exponential in the size of the input formula, matching the\ncomplexity of the best known evaluation algorithms."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(2:20)2011", 
    "link": "http://arxiv.org/pdf/1105.4060v1", 
    "title": "Logical Modelling of Physarum Polycephalum", 
    "arxiv-id": "1105.4060v1", 
    "author": "Andrew Adamatzky", 
    "publish": "2011-05-20T11:18:13Z", 
    "summary": "We propose a novel model of unconventional computing where a structural part\nof computation is presented by dynamics of plasmodium of Physarum polycephalum,\na large single cell. We sketch a new logical approach combining conventional\nlogic with process calculus to demonstrate how to employ formal methods in\ndesign of unconventional computing media presented by Physarum polycephalum."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(2:20)2011", 
    "link": "http://arxiv.org/pdf/1105.6210v1", 
    "title": "Generic Traces and Constraints, GenTra4CP revisited", 
    "arxiv-id": "1105.6210v1", 
    "author": "Pierre Deransart", 
    "publish": "2011-05-31T09:12:29Z", 
    "summary": "The generic trace format GenTra4CP has been defined in 2004 with the goal of\nbecoming a standard trace format for the observation of constraint solvers over\nfinite domains. It has not been used since. This paper defines the concept of\ngeneric trace formally, based on simple transformations of traces. It then\nanalyzes, and occasionally corrects, shortcomings of the proposed initial\nformat and shows the interest that a generic tracer may bring to develop\nportable applications or to standardization efforts, in particular in the field\nof constraints."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(3:4)2011", 
    "link": "http://arxiv.org/pdf/1105.6317v2", 
    "title": "Monotonicity Constraints for Termination in the Integer Domain", 
    "arxiv-id": "1105.6317v2", 
    "author": "Amir M. Ben-Amram", 
    "publish": "2011-05-31T15:42:03Z", 
    "summary": "Size-Change Termination (SCT) is a method of proving program termination\nbased on the impossibility of infinite descent. To this end we use a program\nabstraction in which transitions are described by Monotonicity Constraints over\n(abstract) variables. When only constraints of the form x>y' and x\\geq y' are\nallowed, we have size-change graphs. In the last decade, both theory and\npractice have evolved significantly in this restricted framework. The crucial\nunderlying assumption of most of the past work is that the domain of the\nvariables is well-founded. In a recent paper I showed how to extend and adapt\nsome theory from the domain of size-change graphs to general monotonicity\nconstraints, thus complementing previous work, but remaining in the realm of\nwell-founded domains. However, monotonicity constraints are, interestingly,\ncapable of proving termination also in the integer domain, which is not\nwell-founded. The purpose of this paper is to explore the application of\nmonotonicity constraints in this domain. We lay the necessary theoretical\nfoundation, and present precise decision procedures for termination; finally,\nwe provide a procedure to construct explicit global ranking functions from\nmonotonicity constraints in singly-exponential time, and of optimal worst-case\nsize and dimension (ordinal)."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(3:4)2011", 
    "link": "http://arxiv.org/pdf/1106.0399v1", 
    "title": "Focalization and phase models for classical extensions of   non-associative Lambek calculus", 
    "arxiv-id": "1106.0399v1", 
    "author": "Arno Bastenhof", 
    "publish": "2011-06-02T10:51:47Z", 
    "summary": "Lambek's non-associative syntactic calculus (NL) excels in its resource\nconsciousness: the usual structural rules for weakening, contraction, exchange\nand even associativity are all dropped. Recently, there have been proposals for\nconservative extensions dispensing with NL's intuitionistic bias towards\nsequents with single conclusions: De Groote and Lamarche's classical\nnon-associative Lambek calculus (CNL) and the Lambek-Grishin calculus (LG) of\nMoortgat and associates. We demonstrate Andreoli's focalization property for\nsaid proposals: a normalization result for Cut-free sequent derivations\nidentifying to a large extent those differing only by trivial rule\npermutations. In doing so, we proceed from a `uniform' sequent presentation,\nderiving CNL from LG through the addition of structural rules. The\nnormalization proof proceeds by the construction of syntactic phase models\nwherein every `truth' has a focused proof, similar to work of Okada and of\nHerbelin and Lee."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.54", 
    "link": "http://arxiv.org/pdf/1106.0814v1", 
    "title": "Proceedings of Second International Symposium on Games, Automata, Logics   and Formal Verification", 
    "arxiv-id": "1106.0814v1", 
    "author": "Salvatore La Torre", 
    "publish": "2011-06-04T11:51:36Z", 
    "summary": "This volume contains the Proceedings of the Second International Symposium on\nGames, Automata, Languages, and Formal Verification (GandALF 2011). The\nconference was held in Minori (Amalfi Coast, Italy), from the 15th to the 17th\nof June 2011. The aim of the GandALF Symposium is to provide a forum for\nresearchers from different areas and with different background, that share a\ncommon interest in game theory, mathematical logic, automata theory, and their\napplications to the specification, design, and verification of complex systems.\nThis proceedings contain the abstracts of three invited talks and nineteen\nregular papers that have been selected through a rigorous reviewing process\naccording to originality, quality, and relevance to the topics of the\nsymposium."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.54.2", 
    "link": "http://arxiv.org/pdf/1106.1229v1", 
    "title": "Improving BDD Based Symbolic Model Checking with Isomorphism Exploiting   Transition Relations", 
    "arxiv-id": "1106.1229v1", 
    "author": "Christian Appold", 
    "publish": "2011-06-07T01:05:45Z", 
    "summary": "Symbolic model checking by using BDDs has greatly improved the applicability\nof model checking. Nevertheless, BDD based symbolic model checking can still be\nvery memory and time consuming. One main reason is the complex transition\nrelation of systems. Sometimes, it is even not possible to generate the\ntransition relation, due to its exhaustive memory requirements. To diminish\nthis problem, the use of partitioned transition relations has been proposed.\nHowever, there are still systems which can not be verified at all. Furthermore,\nif the granularity of the partitions is too fine, the time required for\nverification may increase. In this paper we target the symbolic verification of\nasynchronous concurrent systems. For such systems we present an approach which\nuses similarities in the transition relation to get further memory reductions\nand runtime improvements. By applying our approach, even the verification of\nsystems with an previously intractable transition relation becomes feasible."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.54.3", 
    "link": "http://arxiv.org/pdf/1106.1230v1", 
    "title": "Computing the Reveals Relation in Occurrence Nets", 
    "arxiv-id": "1106.1230v1", 
    "author": "Stefan Schwoon", 
    "publish": "2011-06-07T01:05:53Z", 
    "summary": "Petri net unfoldings are a useful tool to tackle state-space explosion in\nverification and related tasks. Moreover, their structure allows to access\ndirectly the relations of causal precedence, concurrency, and conflict between\nevents. Here, we explore the data structure further, to determine the following\nrelation: event a is said to reveal event b iff the occurrence of a implies\nthat b inevitably occurs, too, be it before, after, or concurrently with a.\nKnowledge of reveals facilitates in particular the analysis of partially\nobservable systems, in the context of diagnosis, testing or verification; it\ncan also be used to generate more concise representations of behaviours via\nabstractions. The reveals relation was previously introduced in the context of\nfault diagnosis, where it was shown that the reveals relation was decidable:\nfor a given pair a,b in the unfolding U of a safe Petri net N, a finite prefix\nP of U is sufficient to decide whether or not a reveals b. In this paper, we\nfirst considerably improve the bound on |P|. We then show that there exists an\nefficient algorithm for computing the relation on a given prefix. We have\nimplemented the algorithm and report on experiments."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.54.4", 
    "link": "http://arxiv.org/pdf/1106.1231v1", 
    "title": "Automated Analysis of MUTEX Algorithms with FASE", 
    "arxiv-id": "1106.1231v1", 
    "author": "Walter Vogler", 
    "publish": "2011-06-07T01:05:57Z", 
    "summary": "In this paper we study the liveness of several MUTEX solutions by\nrepresenting them as processes in PAFAS s, a CCS-like process algebra with a\nspecific operator for modelling non-blocking reading behaviours. Verification\nis carried out using the tool FASE, exploiting a correspondence between\nviolations of the liveness property and a special kind of cycles (called\ncatastrophic cycles) in some transition system. We also compare our approach\nwith others in the literature. The aim of this paper is twofold: on the one\nhand, we want to demonstrate the applicability of FASE to some concrete,\nmeaningful examples; on the other hand, we want to study the impact of\nintroducing non-blocking behaviours in modelling concurrent systems."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.54.12", 
    "link": "http://arxiv.org/pdf/1106.1239v1", 
    "title": "New results on pushdown module checking with imperfect information", 
    "arxiv-id": "1106.1239v1", 
    "author": "Laura Bozzelli", 
    "publish": "2011-06-07T01:06:54Z", 
    "summary": "Model checking of open pushdown systems (OPD) w.r.t. standard branching\ntemporal logics (pushdown module checking or PMC) has been recently\ninvestigated in the literature, both in the context of environments with\nperfect and imperfect information about the system (in the last case, the\nenvironment has only a partial view of the system's control states and stack\ncontent). For standard CTL, PMC with imperfect information is known to be\nundecidable. If the stack content is assumed to be visible, then the problem is\ndecidable and 2EXPTIME-complete (matching the complexity of PMC with perfect\ninformation against CTL). The decidability status of PMC with imperfect\ninformation against CTL restricted to the case where the depth of the stack\ncontent is visible is open. In this paper, we show that with this restriction,\nPMC with imperfect information against CTL remains undecidable. On the other\nhand, we individuate an interesting subclass of OPDS with visible stack content\ndepth such that PMC with imperfect information against the existential fragment\nof CTL is decidable and in 2EXPTIME. Moreover, we show that the program\ncomplexity of PMC with imperfect information and visible stack content against\nCTL is 2EXPTIME-complete (hence, exponentially harder than the program\ncomplexity of PMC with perfect information, which is known to be\nEXPTIME-complete)."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.54.15", 
    "link": "http://arxiv.org/pdf/1106.1242v1", 
    "title": "Separation of Test-Free Propositional Dynamic Logics over Context-Free   Languages", 
    "arxiv-id": "1106.1242v1", 
    "author": "Markus Latte", 
    "publish": "2011-06-07T01:07:17Z", 
    "summary": "For a class L of languages let PDL[L] be an extension of Propositional\nDynamic Logic which allows programs to be in a language of L rather than just\nto be regular. If L contains a non-regular language, PDL[L] can express\nnon-regular properties, in contrast to pure PDL.\n  For regular, visibly pushdown and deterministic context-free languages, the\nseparation of the respective PDLs can be proven by automata-theoretic\ntechniques. However, these techniques introduce non-determinism on the automata\nside. As non-determinism is also the difference between DCFL and CFL, these\ntechniques seem to be inappropriate to separate PDL[DCFL] from PDL[CFL].\nNevertheless, this separation is shown but for programs without test operators."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.54.16", 
    "link": "http://arxiv.org/pdf/1106.1243v1", 
    "title": "On P-transitive graphs and applications", 
    "arxiv-id": "1106.1243v1", 
    "author": "Giacomo Lenzi", 
    "publish": "2011-06-07T01:07:24Z", 
    "summary": "We introduce a new class of graphs which we call P-transitive graphs, lying\nbetween transitive and 3-transitive graphs. First we show that the analogue of\nde Jongh-Sambin Theorem is false for wellfounded P-transitive graphs; then we\nshow that the mu-calculus fixpoint hierarchy is infinite for P-transitive\ngraphs. Both results contrast with the case of transitive graphs. We give also\nan undecidability result for an enriched mu-calculus on P-transitive graphs.\nFinally, we consider a polynomial time reduction from the model checking\nproblem on arbitrary graphs to the model checking problem on P-transitive\ngraphs. All these results carry over to 3-transitive graphs."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.54.18", 
    "link": "http://arxiv.org/pdf/1106.1245v1", 
    "title": "Deciding Reachability for 3-Dimensional Multi-Linear Systems", 
    "arxiv-id": "1106.1245v1", 
    "author": "Daniel Funke", 
    "publish": "2011-06-07T01:07:39Z", 
    "summary": "This paper deals with the problem of point-to-point reachability in\nmulti-linear systems. These systems consist of a partition of the Euclidean\nspace into a finite number of regions and a constant derivative assigned to\neach region in the partition, which governs the dynamical behavior of the\nsystem within it. The reachability problem for multi-linear systems has been\nproven to be decidable for the two-dimensional case and undecidable for the\ndimension three and higher.\n  Multi-linear systems however exhibit certain properties that make them very\nsuitable for topological analysis. We prove that reachability can be decided\nexactly in the 3-dimensional case when systems satisfy certain conditions. We\nshow with experiments that our approach can be orders of magnitude more\nefficient than simulation."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.54.19", 
    "link": "http://arxiv.org/pdf/1106.1246v1", 
    "title": "Towards Efficient Exact Synthesis for Linear Hybrid Systems", 
    "arxiv-id": "1106.1246v1", 
    "author": "Stefano Minopoli", 
    "publish": "2011-06-07T01:07:47Z", 
    "summary": "We study the problem of automatically computing the controllable region of a\nLinear Hybrid Automaton, with respect to a safety objective. We describe the\ntechniques that are needed to effectively and efficiently implement a\nrecently-proposed solution procedure, based on polyhedral abstractions of the\nstate space. Supporting experimental results are presented, based on an\nimplementation of the proposed techniques on top of the tool PHAVer."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-9(1:6)2013", 
    "link": "http://arxiv.org/pdf/1106.1850v3", 
    "title": "Coarse abstractions make Zeno behaviours difficult to detect", 
    "arxiv-id": "1106.1850v3", 
    "author": "B Srivathsan", 
    "publish": "2011-06-09T16:33:24Z", 
    "summary": "An infinite run of a timed automaton is Zeno if it spans only a finite amount\nof time. Such runs are considered unfeasible and hence it is important to\ndetect them, or dually, find runs that are non-Zeno. Over the years important\nimprovements have been obtained in checking reachability properties for timed\nautomata. We show that some of these very efficient optimizations make testing\nfor Zeno runs costly. In particular we show NP-completeness for the\nLU-extrapolation of Behrmann et al. We analyze the source of this complexity in\ndetail and give general conditions on extrapolation operators that guarantee a\n(low) polynomial complexity of Zenoness checking. We propose a slight weakening\nof the LU-extrapolation that satisfies these conditions."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-9(1:6)2013", 
    "link": "http://arxiv.org/pdf/1106.1875v6", 
    "title": "Ticket Entailment is decidable", 
    "arxiv-id": "1106.1875v6", 
    "author": "Vincent Padovani", 
    "publish": "2011-06-09T18:43:01Z", 
    "summary": "We prove the decidability of Ticket Entailment. Raised by Anderson and Belnap\nwithin the framework of relevance logic, this question is equivalent to the\nquestion of the decidability of type inhabitation in simply-typed combinatory\nlogic with the partial basis BB'IW. We solve the equivalent problem of type\ninhabitation for the restriction of simply-typed lambda-calculus to\nhereditarily right-maximal terms."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-9(2:7)2013", 
    "link": "http://arxiv.org/pdf/1106.2181v5", 
    "title": "Bisimulations Meet PCTL Equivalences for Probabilistic Automata", 
    "arxiv-id": "1106.2181v5", 
    "author": "Flemming Nielson", 
    "publish": "2011-06-10T22:03:53Z", 
    "summary": "Probabilistic automata (PAs) have been successfully applied in formal\nverification of concurrent and stochastic systems. Efficient model checking\nalgorithms have been studied, where the most often used logics for expressing\nproperties are based on probabilistic computation tree logic (PCTL) and its\nextension PCTL^*. Various behavioral equivalences are proposed, as a powerful\ntool for abstraction and compositional minimization for PAs. Unfortunately, the\nequivalences are well-known to be sound, but not complete with respect to the\nlogical equivalences induced by PCTL or PCTL*. The desire of a both sound and\ncomplete behavioral equivalence has been pointed out by Segala in 1995, but\nremains open throughout the years. In this paper we introduce novel notions of\nstrong bisimulation relations, which characterize PCTL and PCTL* exactly. We\nextend weak bisimulations that characterize PCTL and PCTL* without next\noperator, respectively. Further, we also extend the framework to simulation\npreorders. Thus, our paper bridges the gap between logical and behavioral\nequivalences and preorders in this setting."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-9(2:7)2013", 
    "link": "http://arxiv.org/pdf/1106.2272v1", 
    "title": "Soundness and completeness of the cirquent calculus system CL6 for   computability logic", 
    "arxiv-id": "1106.2272v1", 
    "author": "Sanyang Liu", 
    "publish": "2011-06-12T02:20:53Z", 
    "summary": "Computability logic is a formal theory of computability. The earlier article\n\"Introduction to cirquent calculus and abstract resource semantics\" by\nJaparidze proved soundness and completeness for the basic fragment CL5 of\ncomputability logic. The present article extends that result to the more\nexpressive cirquent calculus system CL6, which is a conservative extension of\nboth CL5 and classical propositional logic."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-9(2:7)2013", 
    "link": "http://arxiv.org/pdf/1106.2305v2", 
    "title": "Cut-Free ExpTime Tableaux for Checking Satisfiability of a Knowledge   Base in the Description Logic SHI", 
    "arxiv-id": "1106.2305v2", 
    "author": "Linh Anh Nguyen", 
    "publish": "2011-06-12T12:07:18Z", 
    "summary": "We give the first cut-free ExpTime (optimal) tableau decision procedure for\nchecking satisfiability of a knowledge base in the description logic SHI, which\nextends the description logic ALC with transitive roles, inverse roles and role\nhierarchies."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-9(2:7)2013", 
    "link": "http://arxiv.org/pdf/1106.2320v1", 
    "title": "Verifying Embedded C Software with Timing Constraints using an Untimed   Model Checker", 
    "arxiv-id": "1106.2320v1", 
    "author": "Bernd Fischer", 
    "publish": "2011-06-12T15:54:28Z", 
    "summary": "Embedded systems are everywhere, from home appliances to critical systems\nsuch as medical devices. They usually have associated timing constraints that\nneed to be verified for the implementation. Here, we use an untimed bounded\nmodel checker to verify timing properties of embedded C programs. We propose an\napproach to specify discrete time timing constraints using code annotations.\nThe annotated code is then automatically translated to code that manipulates\nauxiliary timer variables and is thus suitable as input to conventional,\nuntimed software model checker such as ESBMC. Thus, we can check timing\nconstraints in the same way and at the same time as untimed system\nrequirements, and even allow for interaction between them. We applied the\nproposed method in a case study, and verified timing constraints of a pulse\noximeter, a noninvasive medical device that measures the oxygen saturation of\narterial blood."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.55.4", 
    "link": "http://arxiv.org/pdf/1106.4093v1", 
    "title": "Refinement by interpretation in \u03c0-institutions", 
    "arxiv-id": "1106.4093v1", 
    "author": "Luis S. Barbosa", 
    "publish": "2011-06-21T05:24:40Z", 
    "summary": "The paper discusses the role of interpretations, understood as multifunctions\nthat preserve and reflect logical consequence, as refinement witnesses in the\ngeneral setting of pi-institutions. This leads to a smooth generalization of\nthe refinement-by-interpretation approach, recently introduced by the authors\nin more specific contexts. As a second, yet related contribution a basis is\nprovided to build up a refinement calculus of structured specifications in and\nacross arbitrary pi-institutions."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.55.5", 
    "link": "http://arxiv.org/pdf/1106.4094v1", 
    "title": "Refinement-based verification of sequential implementations of Stateflow   charts", 
    "arxiv-id": "1106.4094v1", 
    "author": "Ana Cavalcanti", 
    "publish": "2011-06-21T05:24:48Z", 
    "summary": "Simulink/Stateflow charts are widely used in industry for the specification\nof control systems, which are often safety-critical. This suggests a need for a\nformal treatment of such models. In previous work, we have proposed a technique\nfor automatic generation of formal models of Stateflow blocks to support\nrefinement-based reasoning. In this article, we present a refinement strategy\nthat supports the verification of automatically generated sequential C\nimplementations of Stateflow charts. In particular, we discuss how this\nstrategy can be specialised to take advantage of architectural features in\norder to allow a higher level of automation."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.55.5", 
    "link": "http://arxiv.org/pdf/1106.4102v1", 
    "title": "Decidability of Existence and Construction of a Complement of a given   Function", 
    "arxiv-id": "1106.4102v1", 
    "author": "Ka. Shrinivaasan", 
    "publish": "2011-06-21T05:36:42Z", 
    "summary": "This article defines a complement of a function and conditions for existence\nof such a complement function and presents few algorithms to construct a\ncomplement."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(3:7)2011", 
    "link": "http://arxiv.org/pdf/1106.5128v3", 
    "title": "Permission-Based Separation Logic for Message-Passing Concurrency", 
    "arxiv-id": "1106.5128v3", 
    "author": "Vladimiro Sassone", 
    "publish": "2011-06-25T13:41:16Z", 
    "summary": "We develop local reasoning techniques for message passing concurrent programs\nbased on ideas from separation logics and resource usage analysis. We extend\nprocesses with permission- resources and define a reduction semantics for this\nextended language. This provides a foundation for interpreting separation\nformulas for message-passing concurrency. We also define a sound proof system\npermitting us to infer satisfaction compositionally using local,\nseparation-based reasoning."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(3:7)2011", 
    "link": "http://arxiv.org/pdf/1106.5470v9", 
    "title": "Connection and Dispersion of Computation", 
    "arxiv-id": "1106.5470v9", 
    "author": "Koji Kobayashi", 
    "publish": "2011-06-27T18:36:14Z", 
    "summary": "This paper talk about the influence of Connection and Dispersion on\nComputational Complexity. And talk about the HornCNF's connection and CNF's\ndispersion, and show the difference between CNFSAT and HornSAT. First, I talk\nthe relation between MUC decision problem and classifying the truth value\nassignment. Second, I define the two inner products (\"inner product\" and \"inner\nharmony\") and talk about the influence of orthogonal and correlation to MUC.\nAnd we can not reduce MUC to Orthogonalization MUC by using HornMUC in\npolynomial size because HornMUC have high orthogonal of inner harmony and MUC\ndo not. So DP is not P, and NP is not P."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(3:7)2011", 
    "link": "http://arxiv.org/pdf/1106.5622v1", 
    "title": "Typing a Core Binary Field Arithmetic in a Light Logic", 
    "arxiv-id": "1106.5622v1", 
    "author": "Luca Roversi", 
    "publish": "2011-06-28T10:39:42Z", 
    "summary": "We design a library for binary field arithmetic and we supply a core API\nwhich is completely developed in DLAL, extended with a fix point formula. Since\nDLAL is a restriction of linear logic where only functional programs with\npolynomial evaluation cost can be typed, we obtain the core of a functional\nprogramming setting for binary field arithmetic with built-in polynomial\ncomplexity."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(3:7)2011", 
    "link": "http://arxiv.org/pdf/1106.6267v1", 
    "title": "A Dynamic Algebraic Specification for Social Networks", 
    "arxiv-id": "1106.6267v1", 
    "author": "Petros Stefaneas", 
    "publish": "2011-06-29T10:22:20Z", 
    "summary": "With the help of the Internet, social networks have grown rapidly. This has\nincreased security requirements. We present a formalization of social networks\nas composite behavioral objects, defined using the Observational Transition\nSystem (OTS) approach. Our definition is then translated to the OTS/CafeOBJ\nalgebraic specification methodology. This translation allows the formal\nverification of safety properties for social networks via the Proof Score\nmethod. Finally, using this methodology we formally verify some security\nproperties."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.56.3", 
    "link": "http://arxiv.org/pdf/1107.0065v1", 
    "title": "Typed lambda-terms in categorical attributed graph transformation", 
    "arxiv-id": "1107.0065v1", 
    "author": "Sergei Soloviev", 
    "publish": "2011-06-30T21:44:46Z", 
    "summary": "This paper deals with model transformation based on attributed graph\nrewriting. Our contribution investigates a single pushout approach for applying\nthe rewrite rules. The computation of graph attributes is obtained through the\nuse of typed lambda-calculus with inductive types. In this paper we present\nsolutions to cope with single pushout construction for the graph structure and\nthe computations functions. As this rewrite system uses inductive types, the\nexpressiveness of attribute computations is facilitated and appears more\nefficient than the one based on Sigma-algebras. Some examples showing the\ninterest of our computation approach are described in this paper."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.56.3", 
    "link": "http://arxiv.org/pdf/1107.0278v1", 
    "title": "Completeness of Epistemic Coalition Logic with Group Knowledge", 
    "arxiv-id": "1107.0278v1", 
    "author": "Natasha Alechina", 
    "publish": "2011-07-01T17:20:32Z", 
    "summary": "Coalition logic is one of the most popular logics for multi-agent systems.\nWhile epistemic extensions of coalition logic have received much attention,\nexistence of their complete axiomatisations has so far been an open problem. In\nthis paper we settle several of those problems. We prove completeness for\nepistemic coalition logic with common knowledge, with distributed knowledge,\nand with both common and distributed knowledge, respectively."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.56.3", 
    "link": "http://arxiv.org/pdf/1107.0349v1", 
    "title": "First-order finite satisfiability vs tree automata in safety   verification", 
    "arxiv-id": "1107.0349v1", 
    "author": "Alexei Lisitsa", 
    "publish": "2011-07-02T00:45:24Z", 
    "summary": "In this paper we deal with verification of safety properties of\nterm-rewriting systems. The verification problem is translated to a purely\nlogical problem of finding a finite countermodel for a first-order formula,\nwhich further resolved by a generic finite model finding procedure. A finite\ncountermodel produced during successful verification provides with a concise\ndescription of the system invariant sufficient to demonstrate a specific safety\nproperty.\n  We show the relative completeness of this approach with respect to the tree\nautomata completion technique. On a set of examples taken from the literature\nwe demonstrate the efficiency of finite model finding approach as well as its\nexplanatory power."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.57.5", 
    "link": "http://arxiv.org/pdf/1107.1201v1", 
    "title": "Real-Reward Testing for Probabilistic Processes (Extended Abstract)", 
    "arxiv-id": "1107.1201v1", 
    "author": "Carroll Morgan", 
    "publish": "2011-07-06T17:54:51Z", 
    "summary": "We introduce a notion of real-valued reward testing for probabilistic\nprocesses by extending the traditional nonnegative-reward testing with negative\nrewards. In this richer testing framework, the may and must preorders turn out\nto be inverses. We show that for convergent processes with finitely many states\nand transitions, but not in the presence of divergence, the real-reward\nmust-testing preorder coincides with the nonnegative-reward must-testing\npreorder. To prove this coincidence we characterise the usual resolution-based\ntesting in terms of the weak transitions of processes, without having to\ninvolve policies, adversaries, schedulers, resolutions, or similar structures\nthat are external to the process under investigation. This requires\nestablishing the continuity of our function for calculating testing outcomes."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.57.8", 
    "link": "http://arxiv.org/pdf/1107.1204v1", 
    "title": "Analysis of Non-Linear Probabilistic Hybrid Systems", 
    "arxiv-id": "1107.1204v1", 
    "author": "Jos\u00e9e Desharnais", 
    "publish": "2011-07-06T17:55:11Z", 
    "summary": "This paper shows how to compute, for probabilistic hybrid systems, the clock\napproximation and linear phase-portrait approximation that have been proposed\nfor non probabilistic processes by Henzinger et al. The techniques permit to\ndefine a rectangular probabilistic process from a non rectangular one, hence\nallowing the model-checking of any class of systems. Clock approximation, which\napplies under some restrictions, aims at replacing a non rectangular variable\nby a clock variable. Linear phase-approximation applies without restriction and\nyields an approximation that simulates the original process. The conditions\nthat we need for probabilistic processes are the same as those for the classic\ncase."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.57.10", 
    "link": "http://arxiv.org/pdf/1107.1205v1", 
    "title": "Distances for Weighted Transition Systems: Games and Properties", 
    "arxiv-id": "1107.1205v1", 
    "author": "Kim G. Larsen", 
    "publish": "2011-07-06T17:55:25Z", 
    "summary": "We develop a general framework for reasoning about distances between\ntransition systems with quantitative information. Taking as starting point an\narbitrary distance on system traces, we show how this leads to natural\ndefinitions of a linear and a branching distance on states of such a transition\nsystem. We show that our framework generalizes and unifies a large variety of\npreviously considered system distances, and we develop some general properties\nof our distances. We also show that if the trace distance admits a recursive\ncharacterization, then the corresponding branching distance can be obtained as\na least fixed point to a similar recursive characterization. The central tool\nin our work is a theory of infinite path-building games with quantitative\nobjectives."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.57.9", 
    "link": "http://arxiv.org/pdf/1107.1233v1", 
    "title": "HYPE with stochastic events", 
    "arxiv-id": "1107.1233v1", 
    "author": "Jane Hillston", 
    "publish": "2011-07-06T17:55:18Z", 
    "summary": "The process algebra HYPE was recently proposed as a fine-grained modelling\napproach for capturing the behaviour of hybrid systems. In the original\nproposal, each flow or influence affecting a variable is modelled separately\nand the overall behaviour of the system then emerges as the composition of\nthese flows. The discrete behaviour of the system is captured by instantaneous\nactions which might be urgent, taking effect as soon as some activation\ncondition is satisfied, or non-urgent meaning that they can tolerate some\n(unknown) delay before happening. In this paper we refine the notion of\nnon-urgent actions, to make such actions governed by a probability\ndistribution. As a consequence of this we now give HYPE a semantics in terms of\nTransition-Driven Stochastic Hybrid Automata, which are a subset of a general\nclass of stochastic processes termed Piecewise Deterministic Markov Processes."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(3:8)2011", 
    "link": "http://arxiv.org/pdf/1107.1351v3", 
    "title": "Conway games, algebraically and coalgebraically", 
    "arxiv-id": "1107.1351v3", 
    "author": "Marina Lenisa", 
    "publish": "2011-07-07T11:34:51Z", 
    "summary": "Using coalgebraic methods, we extend Conway's theory of games to possibly\nnon-terminating, i.e. non-wellfounded games (hypergames). We take the view that\na play which goes on forever is a draw, and hence rather than focussing on\nwinning strategies, we focus on non-losing strategies. Hypergames are a\nfruitful metaphor for non-terminating processes, Conway's sum being similar to\nshuffling. We develop a theory of hypergames, which extends in a non-trivial\nway Conway's theory; in particular, we generalize Conway's results on game\ndeterminacy and characterization of strategies. Hypergames have a rather\ninteresting theory, already in the case of impartial hypergames, for which we\ngive a compositional semantics, in terms of a generalized Grundy-Sprague\nfunction and a system of generalized Nim games. Equivalences and congruences on\ngames and hypergames are discussed. We indicate a number of intriguing\ndirections for future work. We briefly compare hypergames with other notions of\ngames used in computer science."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(3:8)2011", 
    "link": "http://arxiv.org/pdf/1107.1901v3", 
    "title": "Propositional equality, identity types, and direct computational paths", 
    "arxiv-id": "1107.1901v3", 
    "author": "Anjolina G. de Oliveira", 
    "publish": "2011-07-10T21:28:26Z", 
    "summary": "In proof theory the notion of canonical proof is rather basic, and it is\nusually taken for granted that a canonical proof of a sentence must be unique\nup to certain minor syntactical details (such as, e.g., change of bound\nvariables). When setting up a proof theory for equality one is faced with a\nrather unexpected situation where there may not be a unique canonical proof of\nan equality statement. Indeed, in a (1994--5) proposal for the formalisation of\nproofs of propositional equality in the Curry--Howard style, we have already\nuncovered such a peculiarity. Totally independently, and in a different\nsetting, Hofmann & Streicher (1994) have shown how to build a model of\nMartin-L\\\"of's Type Theory in which uniqueness of canonical proofs of identity\ntypes does not hold. The intention here is to show that, by considering as\nsequences of rewrites and substitution, it comes a rather natural fact that two\n(or more) distinct proofs may be yet canonical and are none to be preferred\nover one another. By looking at proofs of equality as rewriting (or\ncomputational) paths this approach will be in line with the recently proposed\nconnections between type theory and homotopy theory via identity types, since\nelements of identity types will be, concretely, paths (or homotopies)."
},{
    "category": "cs.LO", 
    "doi": "10.1215/00294527-1731389", 
    "link": "http://arxiv.org/pdf/1107.2284v1", 
    "title": "The parallel versus branching recurrences in computability logic", 
    "arxiv-id": "1107.2284v1", 
    "author": "Sanyang Liu", 
    "publish": "2011-07-12T13:34:50Z", 
    "summary": "This paper shows that the basic logic induced by the parallel recurrence of\nComputability Logic is a proper superset of the basic logic induced by the\nbranching recurrence. The latter is known to be precisely captured by the\ncirquent calculus system CL15, conjectured by Japaridze to remain sound---but\nnot complete---with parallel recurrence instead of branching recurrence. The\npresent result is obtained by positively verifying that conjecture. A secondary\nresult of the paper is showing that parallel recurrence is strictly weaker than\nbranching recurrence in the sense that, while the latter logically implies the\nformer, vice versa does not hold."
},{
    "category": "cs.LO", 
    "doi": "10.1215/00294527-1731389", 
    "link": "http://arxiv.org/pdf/1107.2513v1", 
    "title": "Fuzzy Topological Systems", 
    "arxiv-id": "1107.2513v1", 
    "author": "Valeria de Paiva", 
    "publish": "2011-07-13T10:25:14Z", 
    "summary": "Dialectica categories are a very versatile categorical model of linear logic.\nThese have been used to model many seemingly different things (e.g., Petri nets\nand Lambek's calculus). In this note, we expand our previous work on fuzzy\npetri nets to deal with fuzzy topological systems. One basic idea is to use as\nthe dualizing object in the Dialectica categories construction, the unit real\ninterval [0,1], which has all the properties of a {\\em lineale}. The second\nbasic idea is to generalize Vickers's notion of a topological system."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(3:14)2011", 
    "link": "http://arxiv.org/pdf/1107.3430v2", 
    "title": "Randomisation and Derandomisation in Descriptive Complexity Theory", 
    "arxiv-id": "1107.3430v2", 
    "author": "Martin Grohe", 
    "publish": "2011-07-18T13:26:45Z", 
    "summary": "We study probabilistic complexity classes and questions of derandomisation\nfrom a logical point of view. For each logic L we introduce a new logic BPL,\nbounded error probabilistic L, which is defined from L in a similar way as the\ncomplexity class BPP, bounded error probabilistic polynomial time, is defined\nfrom PTIME. Our main focus lies on questions of derandomisation, and we prove\nthat there is a query which is definable in BPFO, the probabilistic version of\nfirst-order logic, but not in Cinf, finite variable infinitary logic with\ncounting. This implies that many of the standard logics of finite model theory,\nlike transitive closure logic and fixed-point logic, both with and without\ncounting, cannot be derandomised. Similarly, we present a query on ordered\nstructures which is definable in BPFO but not in monadic second-order logic,\nand a query on additive structures which is definable in BPFO but not in FO.\nThe latter of these queries shows that certain uniform variants of AC0\n(bounded-depth polynomial sized circuits) cannot be derandomised. These results\nare in contrast to the general belief that most standard complexity classes can\nbe derandomised. Finally, we note that BPIFP+C, the probabilistic version of\nfixed-point logic with counting, captures the complexity class BPP, even on\nunordered structures."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(3:14)2011", 
    "link": "http://arxiv.org/pdf/1107.3706v1", 
    "title": "The countable versus uncountable branching recurrences in computability   logic", 
    "arxiv-id": "1107.3706v1", 
    "author": "Sanyang Liu", 
    "publish": "2011-07-19T13:01:16Z", 
    "summary": "This paper introduces a new simplified version of the countable branching\nrecurrence of Computability Logic, proves its equivalence to the old one, and\nshows that the basic logic induced by it is a proper superset of the basic\nlogic induced by the uncountable branching recurrence. A further result of this\npaper is showing that the countable branching recurrence is strictly weaker\nthan the uncountable branching recurrence in the sense that the latter\nlogically implies the former but not vice versa."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(3:14)2011", 
    "link": "http://arxiv.org/pdf/1107.4138v2", 
    "title": "Event-Clock Automata: From Theory to Practice", 
    "arxiv-id": "1107.4138v2", 
    "author": "Nathalie Sznajder", 
    "publish": "2011-07-20T23:09:47Z", 
    "summary": "Event clock automata (ECA) are a model for timed languages that has been\nintroduced by Alur, Fix and Henzinger as an alternative to timed automata, with\nbetter theoretical properties (for instance, ECA are determinizable while timed\nautomata are not). In this paper, we revisit and extend the theory of ECA. We\nfirst prove that no finite time abstract language equivalence exists for ECA,\nthereby disproving a claim in the original work on ECA. This means in\nparticular that regions do not form a time abstract bisimulation. Nevertheless,\nwe show that regions can still be used to build a finite automaton recognizing\nthe untimed language of an ECA. Then, we extend the classical notions of zones\nand DBMs to let them handle event clocks instead of plain clocks (as in timed\nautomata) by introducing event zones and Event DBMs (EDBMs). We discuss\nalgorithms to handle event zones represented as EDBMs, as well as (semi-)\nalgorithms based on EDBMs to decide language emptiness of ECA."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(3:14)2011", 
    "link": "http://arxiv.org/pdf/1107.4160v1", 
    "title": "Functions as proofs as processes", 
    "arxiv-id": "1107.4160v1", 
    "author": "Emmanuel Beffara", 
    "publish": "2011-07-21T05:06:48Z", 
    "summary": "This paper presents a logical approach to the translation of functional\ncalculi into concurrent process calculi. The starting point is a type system\nfor the {\\pi}-calculus closely related to linear logic. Decompositions of\nintuitionistic and classical logics into this system provide type-preserving\ntranslations of the \\lambda- and \\lambda\\mu-calculus, both for call-by-name and\ncall-by-value evaluation strategies. Previously known encodings of the\n\\lam-calculus are shown to correspond to particular cases of this logical\nembedding. The realisability interpretation of types in the \\pi-calculus\nprovides systematic soundness arguments for these translations and allows for\nthe definition of type-safe extensions of functional calculi."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(3:14)2011", 
    "link": "http://arxiv.org/pdf/1107.4939v2", 
    "title": "Paraconsistency and Topological Semantics", 
    "arxiv-id": "1107.4939v2", 
    "author": "Can Baskent", 
    "publish": "2011-07-25T13:15:07Z", 
    "summary": "The well-studied notion of deductive explosion describes the situation where\nany formula can be deduced from an inconsistent set of formulas. Paraconsistent\nlogic, on the other hand, is the umbrella term for logical systems where the\nlogical consequence relation is not explosive. In this work, we investigate the\nrelationship between some different topological spaces and paraconsistency."
},{
    "category": "cs.LO", 
    "doi": "10.1017/S147106841100024X", 
    "link": "http://arxiv.org/pdf/1107.5030v2", 
    "title": "On Combining Linear-Based Strategies for Tabled Evaluation of Logic   Programs", 
    "arxiv-id": "1107.5030v2", 
    "author": "Ricardo Rocha", 
    "publish": "2011-07-25T19:44:27Z", 
    "summary": "Tabled evaluation is a recognized and powerful technique that overcomes some\nlimitations of traditional Prolog systems in dealing with recursion and\nredundant sub-computations. We can distinguish two main categories of tabling\nmechanisms: suspension-based tabling and linear tabling. While suspension-based\nmechanisms are considered to obtain better results in general, they have more\nmemory space requirements and are more complex and harder to implement than\nlinear tabling mechanisms. Arguably, the SLDT and DRA strategies are the two\nmost successful extensions to standard linear tabled evaluation. In this work,\nwe propose a new strategy, named DRS, and we present a framework, on top of the\nYap system, that supports the combination of all these three strategies. Our\nimplementation shares the underlying execution environment and most of the data\nstructures used to implement tabling in Yap. We thus argue that all these\ncommon features allows us to make a first and fair comparison between these\ndifferent linear tabling strategies and, therefore, better understand the\nadvantages and weaknesses of each, when used solely or combined with the\nothers."
},{
    "category": "cs.LO", 
    "doi": "10.1017/S147106841100024X", 
    "link": "http://arxiv.org/pdf/1107.5142v1", 
    "title": "Finite countermodels for safety verification of parameterized tree   systems", 
    "arxiv-id": "1107.5142v1", 
    "author": "Alexei Lisitsa", 
    "publish": "2011-07-26T09:25:35Z", 
    "summary": "In this paper we deal with verification of safety properties of parameterized\nsystems with a tree topology. The verification problem is translated to a\npurely logical problem of finding a finite countermodel for a first-order\nformula, which further resolved by a generic finite model finding procedure. A\nfinite countermodel method is shown is at least as powerful as regular tree\nmodel checking and as the methods based on monotonic abstraction and backwards\nsymbolic reachability. The practical efficiency of the method is illustrated on\na set of examples taken from the literature."
},{
    "category": "cs.LO", 
    "doi": "10.1017/S1471068411000238", 
    "link": "http://arxiv.org/pdf/1107.5152v1", 
    "title": "The Magic of Logical Inference in Probabilistic Programming", 
    "arxiv-id": "1107.5152v1", 
    "author": "Luc De Raedt", 
    "publish": "2011-07-26T09:58:08Z", 
    "summary": "Today, many different probabilistic programming languages exist and even more\ninference mechanisms for these languages. Still, most logic programming based\nlanguages use backward reasoning based on SLD resolution for inference. While\nthese methods are typically computationally efficient, they often can neither\nhandle infinite and/or continuous distributions, nor evidence. To overcome\nthese limitations, we introduce distributional clauses, a variation and\nextension of Sato's distribution semantics. We also contribute a novel\napproximate inference method that integrates forward reasoning with importance\nsampling, a well-known technique for probabilistic inference. To achieve\nefficiency, we integrate two logic programming techniques to direct forward\nsampling. Magic sets are used to focus on relevant parts of the program, while\nthe integration of backward reasoning allows one to identify and avoid regions\nof the sample space that are inconsistent with the evidence."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.64.4", 
    "link": "http://arxiv.org/pdf/1107.5722v3", 
    "title": "Termination in a Pi-calculus with Subtyping", 
    "arxiv-id": "1107.5722v3", 
    "author": "Daniel Hirschkoff", 
    "publish": "2011-07-28T14:03:05Z", 
    "summary": "We present a type system to guarantee termination of pi-calculus processes\nthat exploits input/output capabilities and subtyping, as originally introduced\nby Pierce and Sangiorgi, in order to analyse the usage of channels. We show\nthat our system improves over previously existing proposals by accepting more\nprocesses as terminating. This increased expressiveness allows us to capture\nsensible programming idioms. We demonstrate how our system can be extended to\nhandle the encoding of the simply typed lambda-calculus, and discuss questions\nrelated to type inference."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.64.4", 
    "link": "http://arxiv.org/pdf/1107.5897v1", 
    "title": "An Algebraic Specification of the Semantic Web", 
    "arxiv-id": "1107.5897v1", 
    "author": "Panayiotis Frangos", 
    "publish": "2011-07-29T08:48:14Z", 
    "summary": "We present a formal specification of the Semantic Web, as an extension of the\nWorld Wide Web using the well known algebraic specification language CafeOBJ.\nOur approach allows the description of the key elements of the Semantic Web\ntechnologies, in order to give a better understanding of the system, without\ngetting involved with their implementation details that might not yet be\nstandardized. This specification is part of our work in progress concerning the\nmodeling the Social Semantic Web."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.64.4", 
    "link": "http://arxiv.org/pdf/1107.5980v1", 
    "title": "SAT-Based Termination Analysis Using Monotonicity Constraints over the   Integers", 
    "arxiv-id": "1107.5980v1", 
    "author": "J\u00fcrgen Giesl", 
    "publish": "2011-07-29T14:19:14Z", 
    "summary": "We describe an algorithm for proving termination of programs abstracted to\nsystems of monotonicity constraints in the integer domain. Monotonicity\nconstraints are a non-trivial extension of the well-known size-change\ntermination method. While deciding termination for systems of monotonicity\nconstraints is PSPACE complete, we focus on a well-defined and significant\nsubset, which we call MCNP, designed to be amenable to a SAT-based solution.\nOur technique is based on the search for a special type of ranking function\ndefined in terms of bounded differences between multisets of integer values. We\ndescribe the application of our approach as the back-end for the termination\nanalysis of Java Bytecode (JBC). At the front-end, systems of monotonicity\nconstraints are obtained by abstracting information, using two different\ntermination analyzers: AProVE and COSTA. Preliminary results reveal that our\napproach provides a good trade-off between precision and cost of analysis."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.59", 
    "link": "http://arxiv.org/pdf/1108.0144v1", 
    "title": "Proceedings Fourth Interaction and Concurrency Experience", 
    "arxiv-id": "1108.0144v1", 
    "author": "Marco Carbone", 
    "publish": "2011-07-31T06:14:37Z", 
    "summary": "This volume contains the pre-proceedings of ICE'11, the 4th Interaction and\nConcurrency Experience workshop, which was held in Reykjavik, Iceland on the\n9th of June 2011 as a satellite event of DisCoTec'11.\n  The topic of ICE'11 was Reliable and Contract-based Interaction. Reliable\ninteractions are, e.g., those enjoying suitable logical, behavioural, or\nsecurity properties, or adhering to certain QoS standards. Contract-based\ninteractions are, e.g., those where the interacting entities are committed to\ngive certain guarantees whenever certain assumptions are met by their operating\nenvironment.\n  The ICE procedure for paper selection allows for PC members to interact,\nanonymously, with authors. During the review phase, each submitted paper is\npublished on a Wiki and associated with a discussion forum whose access is\nrestricted to the authors and to all the PC members not declaring a conflict of\ninterests. The PC members post comments and questions that the authors reply\nto. Each paper was reviewed by four PC members, and altogether 8 papers (out of\n12) were accepted for publication.\n  We were proud to host three invited talks by Rocco De Nicola (joint with\nPACO), Simon Gay and Prakash Panangaden, whose abstracts are included in this\nvolume together with the regular papers."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.59.2", 
    "link": "http://arxiv.org/pdf/1108.0463v1", 
    "title": "Innocent strategies as presheaves and interactive equivalences for CCS", 
    "arxiv-id": "1108.0463v1", 
    "author": "Damien Pous", 
    "publish": "2011-08-02T02:27:04Z", 
    "summary": "Seeking a general framework for reasoning about and comparing programming\nlanguages, we derive a new view of Milner's CCS. We construct a category E of\nplays, and a subcategory V of views. We argue that presheaves on V adequately\nrepresent innocent strategies, in the sense of game semantics. We then equip\ninnocent strategies with a simple notion of interaction. This results in an\ninterpretation of CCS.\n  Based on this, we propose a notion of interactive equivalence for innocent\nstrategies, which is close in spirit to Beffara's interpretation of testing\nequivalences in concurrency theory. In this framework we prove that the\nanalogues of fair and must testing equivalences coincide, while they differ in\nthe standard setting."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(4:7)2012", 
    "link": "http://arxiv.org/pdf/1108.0556v3", 
    "title": "On Berry's conjectures about the stable order in PCF", 
    "arxiv-id": "1108.0556v3", 
    "author": "Fritz M\u00fcller", 
    "publish": "2011-08-02T12:12:11Z", 
    "summary": "PCF is a sequential simply typed lambda calculus language. There is a unique\norder-extensional fully abstract cpo model of PCF, built up from equivalence\nclasses of terms. In 1979, G\\'erard Berry defined the stable order in this\nmodel and proved that the extensional and the stable order together form a\nbicpo. He made the following two conjectures: 1) \"Extensional and stable order\nform not only a bicpo, but a bidomain.\" We refute this conjecture by showing\nthat the stable order is not bounded complete, already for finitary PCF of\nsecond-order types. 2) \"The stable order of the model has the syntactic order\nas its image: If a is less than b in the stable order of the model, for finite\na and b, then there are normal form terms A and B with the semantics a, resp.\nb, such that A is less than B in the syntactic order.\" We give counter-examples\nto this conjecture, again in finitary PCF of second-order types, and also\nrefute an improved conjecture: There seems to be no simple syntactic\ncharacterization of the stable order. But we show that Berry's conjecture is\ntrue for unary PCF. For the preliminaries, we explain the basic fully abstract\nsemantics of PCF in the general setting of (not-necessarily complete) partial\norder models (f-models.) And we restrict the syntax to \"game terms\", with a\ngraphical representation."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(4:7)2012", 
    "link": "http://arxiv.org/pdf/1108.1482v1", 
    "title": "Applying Algebraic Specifications on Digital Right Management Systems", 
    "arxiv-id": "1108.1482v1", 
    "author": "Panayiotis Frangos", 
    "publish": "2011-08-06T13:54:17Z", 
    "summary": "Digital Right Management (DRM) Systems have been created to meet the need for\ndigital content protection and distribution. In this paper we present some of\nthe directions of our ongoing research to apply algebraic specification\ntechniques on mobile DRM systems."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.60.1", 
    "link": "http://arxiv.org/pdf/1108.1861v1", 
    "title": "Towards reduction of Paradigm coordination models", 
    "arxiv-id": "1108.1861v1", 
    "author": "Erik de Vink", 
    "publish": "2011-08-09T06:38:19Z", 
    "summary": "The coordination modelling language Paradigm addresses collaboration between\ncomponents in terms of dynamic constraints. Within a Paradigm model, component\ndynamics are consistently specified at a detailed and a global level of\nabstraction. To enable automated verification of Paradigm models, a translation\nof Paradigm into process algebra has been defined in previous work. In this\npaper we investigate, guided by a client-server example, reduction of Paradigm\nmodels based on a notion of global inertness. Representation of Paradigm models\nas process algebraic specifications helps to establish a property-preserving\nequivalence relation between the original and the reduced Paradigm model.\nExperiments indicate that in this way larger Paradigm models can be analyzed."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.60.4", 
    "link": "http://arxiv.org/pdf/1108.1864v1", 
    "title": "Parameterized Verification of Safety Properties in Ad Hoc Network   Protocols", 
    "arxiv-id": "1108.1864v1", 
    "author": "Gianluigi Zavattaro", 
    "publish": "2011-08-09T06:38:39Z", 
    "summary": "We summarize the main results proved in recent work on the parameterized\nverification of safety properties for ad hoc network protocols. We consider a\nmodel in which the communication topology of a network is represented as a\ngraph. Nodes represent states of individual processes. Adjacent nodes represent\nsingle-hop neighbors. Processes are finite state automata that communicate via\nselective broadcast messages. Reception of a broadcast is restricted to\nsingle-hop neighbors. For this model we consider a decision problem that can be\nexpressed as the verification of the existence of an initial topology in which\nthe execution of the protocol can lead to a configuration with at least one\nnode in a certain state. The decision problem is parametric both on the size\nand on the form of the communication topology of the initial configurations. We\ndraw a complete picture of the decidability and complexity boundaries of this\nproblem according to various assumptions on the possible topologies."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.60.4", 
    "link": "http://arxiv.org/pdf/1108.3033v6", 
    "title": "Equilibria und weiteres Heiteres II", 
    "arxiv-id": "1108.3033v6", 
    "author": "Karl Schlechta", 
    "publish": "2011-08-15T16:59:07Z", 
    "summary": "We investigate several technical and conceptual questions.\n  Our main subject is the investigation of independence as a ternary relation\nin the context of non-monotonic logic. In the context of probability, this\ninvestigation was started by W.Spohn et al., and then followed by J.Pearl. We\nlook at products of function sets, and thus continue our own investigation of\nindependence in non-monotonic logic. We show that a finite characterization of\nthis relation in our context is impossible, and indicate how to construct all\nvalid rules."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.62.1", 
    "link": "http://arxiv.org/pdf/1108.3124v1", 
    "title": "Axiomatizing GSOS with Predicates", 
    "arxiv-id": "1108.3124v1", 
    "author": "Anna Ingolfsdottir", 
    "publish": "2011-08-16T00:23:36Z", 
    "summary": "In this paper, we introduce an extension of the GSOS rule format with\npredicates such as termination, convergence and divergence. For this format we\ngeneralize the technique proposed by Aceto, Bloom and Vaandrager for the\nautomatic generation of ground-complete axiomatizations of bisimilarity over\nGSOS systems. Our procedure is implemented in a tool that receives SOS\nspecifications as input and derives the corresponding axiomatizations\nautomatically. This paves the way to checking strong bisimilarity over process\nterms by means of theorem-proving techniques."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.62.2", 
    "link": "http://arxiv.org/pdf/1108.3125v1", 
    "title": "Formal Component-Based Semantics", 
    "arxiv-id": "1108.3125v1", 
    "author": "Marko van Eekelen", 
    "publish": "2011-08-16T00:23:42Z", 
    "summary": "One of the proposed solutions for improving the scalability of semantics of\nprogramming languages is Component-Based Semantics, introduced by Peter D.\nMosses. It is expected that this framework can also be used effectively for\nmodular meta theoretic reasoning. This paper presents a formalization of\nComponent-Based Semantics in the theorem prover Coq. It is based on Modular\nSOS, a variant of SOS, and makes essential use of dependent types, while\nprofiting from type classes. This formalization constitutes a contribution\ntowards modular meta theoretic formalizations in theorem provers. As a small\nexample, a modular proof of determinism of a mini-language is developed."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.62.3", 
    "link": "http://arxiv.org/pdf/1108.3126v1", 
    "title": "Regular Expression Matching and Operational Semantics", 
    "arxiv-id": "1108.3126v1", 
    "author": "Hayo Thielecke", 
    "publish": "2011-08-16T00:23:47Z", 
    "summary": "Many programming languages and tools, ranging from grep to the Java String\nlibrary, contain regular expression matchers. Rather than first translating a\nregular expression into a deterministic finite automaton, such implementations\ntypically match the regular expression on the fly. Thus they can be seen as\nvirtual machines interpreting the regular expression much as if it were a\nprogram with some non-deterministic constructs such as the Kleene star. We\nformalize this implementation technique for regular expression matching using\noperational semantics. Specifically, we derive a series of abstract machines,\nmoving from the abstract definition of matching to increasingly realistic\nmachines. First a continuation is added to the operational semantics to\ndescribe what remains to be matched after the current expression. Next, we\nrepresent the expression as a data structure using pointers, which enables\nredundant searches to be eliminated via testing for pointer equality. From\nthere, we arrive both at Thompson's lockstep construction and a machine that\nperforms some operations in parallel, suitable for implementation on a large\nnumber of cores, such as a GPU. We formalize the parallel machine using process\nalgebra and report some preliminary experiments with an implementation on a\ngraphics processor using CUDA."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.62.4", 
    "link": "http://arxiv.org/pdf/1108.3127v1", 
    "title": "On the Unification of Process Semantics: Logical Semantics", 
    "arxiv-id": "1108.3127v1", 
    "author": "David de Frutos-Escrig", 
    "publish": "2011-08-16T00:23:54Z", 
    "summary": "We continue with the task of obtaining a unifying view of process semantics\nby considering in this case the logical characterization of the semantics. We\nstart by considering the classic linear time-branching time spectrum developed\nby R.J. van Glabbeek. He provided a logical characterization of most of the\nsemantics in his spectrum but, without following a unique pattern. In this\npaper, we present a uniform logical characterization of all the semantics in\nthe enlarged spectrum. The common structure of the formulas that constitute all\nthe corresponding logics gives us a much clearer picture of the spectrum,\nclarifying the relations between the different semantics, and allows us to\ndevelop generic proofs of some general properties of the semantics."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.62.4", 
    "link": "http://arxiv.org/pdf/1108.3675v1", 
    "title": "AIG Rewriting Using 5-Input Cuts", 
    "arxiv-id": "1108.3675v1", 
    "author": "Elena Dubrova", 
    "publish": "2011-08-18T08:10:37Z", 
    "summary": "Rewriting is a common approach to logic optimization based on local\ntransformations. Most commercially available logic synthesis tools include a\nrewriting engine that may be used multiple times on the same netlist during\noptimization. This paper presents an And-Inverter graph based rewriting\nalgorithm using 5-input cuts. The best circuits are pre-computed for a subset\nof NPN classes of 5-variable functions. Cut enumeration and Boolean matching\nare used to identify replacement candidates. The presented approach is expected\nto complement existing rewriting approaches which are usually based on 4-input\ncuts. The experimental results show that, by adding the new rewriting algorithm\nto ABC synthesis tool, we can further reduce the area of heavily optimized\nlarge circuits by 5.57% on average."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(4:1)2011", 
    "link": "http://arxiv.org/pdf/1108.3736v2", 
    "title": "Computational Models of Certain Hyperspaces of Quasi-metric Spaces", 
    "arxiv-id": "1108.3736v2", 
    "author": "Mahdi Ali-Akbari", 
    "publish": "2011-08-18T12:21:27Z", 
    "summary": "In this paper, for a given sequentially Yoneda-complete T_1 quasi-metric\nspace (X,d), the domain theoretic models of the hyperspace K_0(X) of nonempty\ncompact subsets of (X,d) are studied. To this end, the $\\omega$-Plotkin domain\nof the space of formal balls BX, denoted by CBX is considered. This domain is\ngiven as the chain completion of the set of all finite subsets of BX with\nrespect to the Egli-Milner relation. Further, a map $\\phi:K_0(X)\\rightarrow\nCBX$ is established and proved that it is an embedding whenever K_0(X) is\nequipped with the Vietoris topology and respectively CBX with the Scott\ntopology. Moreover, if any compact subset of (X,d) is d^{-1}-precompact, \\phi\nis an embedding with respect to the topology of Hausdorff quasi-metric H_d on\nK_0(X). Therefore, it is concluded that (CBX,\\sqsubseteq,\\phi) is an\n$\\omega$-computational model for the hyperspace K_0(X) endowed with the\nVietoris and respectively the Hausdorff topology. Next, an algebraic\nsequentially Yoneda-complete quasi-metric D on CBX$ is introduced in such a way\nthat the specialization order $\\sqsubseteq_D$ is equivalent to the usual\npartial order of CBX and, furthermore, $\\phi:({\\cal\nK}_0(X),H_d)\\rightarrow({\\bf C}{\\bf B}X,D)$ is an isometry. This shows that\n(CBX,\\sqsubseteq,\\phi,D) is a quantitative $\\omega$-computational model for\n(K_(X),H_d)."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(4:1)2011", 
    "link": "http://arxiv.org/pdf/1108.4253v1", 
    "title": "Coquet: a Coq library for verifying hardware", 
    "arxiv-id": "1108.4253v1", 
    "author": "Thomas Braibant", 
    "publish": "2011-08-22T08:14:38Z", 
    "summary": "We propose a new library to model and verify hardware circuits in the Coq\nproof assistant. This library allows one to easily build circuits by following\nthe usual pen-and-paper diagrams. We define a deep-embedding: we use a\n(dependently typed) data-type that models the architecture of circuits, and a\nmeaning function. We propose tactics that ease the reasoning about the behavior\nof the circuits, and we demonstrate that our approach is practicable by proving\nthe correctness of various circuits: a text-book divide and conquer adder of\nparametric size, some higher-order combinators of circuits, and some sequential\ncircuits: a buffer, and a register."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(3:19)2011", 
    "link": "http://arxiv.org/pdf/1108.4368v2", 
    "title": "Formalization of Abstract State Transition Systems for SAT", 
    "arxiv-id": "1108.4368v2", 
    "author": "Predrag Janicic", 
    "publish": "2011-08-22T16:15:00Z", 
    "summary": "We present a formalization of modern SAT solvers and their properties in a\nform of abstract state transition systems. SAT solving procedures are described\nas transition relations over states that represent the values of the solver's\nglobal variables. Several different SAT solvers are formalized, including both\nthe classical DPLL procedure and its state-of-the-art successors. The\nformalization is made within the Isabelle/HOL system and the total correctness\n(soundness, termination, completeness) is shown for each presented system (with\nrespect to a simple notion of satisfiability that can be manually checked). The\nsystems are defined in a general way and cover procedures used in a wide range\nof modern SAT solvers. Our formalization builds up on the previous work on\nstate transition systems for SAT, but it gives machine-verifiable proofs,\nsomewhat more general specifications, and weaker assumptions that ensure the\nkey correctness properties. The presented proofs of formal correctness of the\ntransition systems can be used as a key building block in proving correctness\nof SAT solvers by using other verification approaches."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.64.1", 
    "link": "http://arxiv.org/pdf/1108.4464v1", 
    "title": "Graphical representation of covariant-contravariant modal formulae", 
    "arxiv-id": "1108.4464v1", 
    "author": "Miguel Palomino", 
    "publish": "2011-08-23T01:23:02Z", 
    "summary": "Covariant-contravariant simulation is a combination of standard (covariant)\nsimulation, its contravariant counterpart and bisimulation. We have previously\nstudied its logical characterization by means of the covariant-contravariant\nmodal logic. Moreover, we have investigated the relationships between this\nmodel and that of modal transition systems, where two kinds of transitions (the\nso-called may and must transitions) were combined in order to obtain a simple\nframework to express a notion of refinement over state-transition models. In a\nclassic paper, Boudol and Larsen established a precise connection between the\ngraphical approach, by means of modal transition systems, and the logical\napproach, based on Hennessy-Milner logic without negation, to system\nspecification. They obtained a (graphical) representation theorem proving that\na formula can be represented by a term if, and only if, it is consistent and\nprime. We show in this paper that the formulae from the covariant-contravariant\nmodal logic that admit a \"graphical\" representation by means of processes,\nmodulo the covariant-contravariant simulation preorder, are also the consistent\nand prime ones. In order to obtain the desired graphical representation result,\nwe first restrict ourselves to the case of covariant-contravariant systems\nwithout bivariant actions. Bivariant actions can be incorporated later by means\nof an encoding that splits each bivariant action into its covariant and its\ncontravariant parts."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.64.6", 
    "link": "http://arxiv.org/pdf/1108.4468v1", 
    "title": "Linearization of CIF Through SOS", 
    "arxiv-id": "1108.4468v1", 
    "author": "Michel Reniers", 
    "publish": "2011-08-23T01:23:36Z", 
    "summary": "Linearization is the procedure of rewriting a process term into a linear\nform, which consist only of basic operators of the process language. This\nprocedure is interesting both from a theoretical and a practical point of view.\nIn particular, a linearization algorithm is needed for the Compositional\nInterchange Format (CIF), an automaton based modeling language.\n  The problem of devising efficient linearization algorithms is not trivial,\nand has been already addressed in literature. However, the linearization\nalgorithms obtained are the result of an inventive process, and the proof of\ncorrectness comes as an afterthought. Furthermore, the semantic specification\nof the language does not play an important role on the design of the algorithm.\n  In this work we present a method for obtaining an efficient linearization\nalgorithm, through a step-wise refinement of the SOS rules of CIF. As a result,\nwe show how the semantic specification of the language can guide the\nimplementation of such a procedure, yielding a simple proof of correctness."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.64.7", 
    "link": "http://arxiv.org/pdf/1108.4469v1", 
    "title": "Synchrony vs Causality in the Asynchronous Pi-Calculus", 
    "arxiv-id": "1108.4469v1", 
    "author": "Uwe Nestmann", 
    "publish": "2011-08-23T01:23:43Z", 
    "summary": "We study the relation between process calculi that differ in their either\nsynchronous or asynchronous interaction mechanism. Concretely, we are\ninterested in the conditions under which synchronous interaction can be\nimplemented using just asynchronous interactions in the pi-calculus. We assume\na number of minimal conditions referring to the work of Gorla: a \"good\"\nencoding must be compositional and preserve and reflect computations,\ndeadlocks, divergence, and success. Under these conditions, we show that it is\nnot possible to encode synchronous interactions without introducing additional\ncausal dependencies in the translation."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.64.8", 
    "link": "http://arxiv.org/pdf/1108.4470v1", 
    "title": "A Logic with Reverse Modalities for History-preserving Bisimulations", 
    "arxiv-id": "1108.4470v1", 
    "author": "Irek Ulidowski", 
    "publish": "2011-08-23T01:23:54Z", 
    "summary": "We introduce event identifier logic (EIL) which extends Hennessy-Milner logic\nby the addition of (1) reverse as well as forward modalities, and (2)\nidentifiers to keep track of events. We show that this logic corresponds to\nhereditary history-preserving (HH) bisimulation equivalence within a particular\ntrue-concurrency model, namely stable configuration structures. We furthermore\nshow how natural sublogics of EIL correspond to coarser equivalences. In\nparticular we provide logical characterisations of weak history-preserving (WH)\nand history-preserving (H) bisimulation. Logics corresponding to HH and H\nbisimulation have been given previously, but not to WH bisimulation (when\nautoconcurrency is allowed), as far as we are aware. We also present\ncharacteristic formulas which characterise individual structures with respect\nto history-preserving equivalences."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.64.8", 
    "link": "http://arxiv.org/pdf/1108.5281v1", 
    "title": "Transfer of semantics from argumentation frameworks to logic programming   A preliminary report", 
    "arxiv-id": "1108.5281v1", 
    "author": "Jan Sefranek", 
    "publish": "2011-08-26T11:01:31Z", 
    "summary": "There are various interesting semantics' (extensions) designed for\nargumentation frameworks. They enable to assign a meaning, e.g., to odd-length\ncycles. Our main motivation is to transfer semantics' proposed by Baroni,\nGiacomin and Guida for argumetation frameworks with odd-length cycles to logic\nprograms with odd-length cycles through default negation. The developed\nconstruction is even stronger. For a given logic program an argumentation\nframework is defined. The construction enables to transfer each semantics of\nthe resulting argumentation framework to a semantics of the given logic\nprogram. Weak points of the construction are discussed and some future\ncontinuations of this approach are outlined."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.64.8", 
    "link": "http://arxiv.org/pdf/1108.5766v1", 
    "title": "Each normal logic program has a 2-valued Minimal Hypotheses semantics", 
    "arxiv-id": "1108.5766v1", 
    "author": "Lu\u015b Moniz Pereira", 
    "publish": "2011-08-29T21:46:07Z", 
    "summary": "In this paper we explore a unifying approach --- that of hypotheses\nassumption --- as a means to provide a semantics for all Normal Logic Programs\n(NLPs), the Minimal Hypotheses (MH) semantics. This semantics takes a positive\nhypotheses assumption approach as a means to guarantee the desirable properties\nof model existence, relevance and cumulativity, and of generalizing the Stable\nModels in the process. To do so we first introduce the fundamental semantic\nconcept of minimality of assumed positive hypotheses, define the MH semantics,\nand analyze the semantics' properties and applicability. Indeed, abductive\nLogic Programming can be conceptually captured by a strategy centered on the\nassumption of abducibles (or hypotheses). Likewise, the Argumentation\nperspective of Logic Programs also lends itself to an arguments (or hypotheses)\nassumption approach. Previous works on Abduction have depicted the atoms of\ndefault negated literals in NLPs as abducibles, i.e., assumable hypotheses. We\ntake a complementary and more general view than these works to NLP semantics by\nemploying positive hypotheses instead."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:15)2012", 
    "link": "http://arxiv.org/pdf/1110.1439v3", 
    "title": "Two-Variable Logic with Two Order Relations", 
    "arxiv-id": "1110.1439v3", 
    "author": "Thomas Zeume", 
    "publish": "2011-10-07T06:38:33Z", 
    "summary": "It is shown that the finite satisfiability problem for two-variable logic\nover structures with one total preorder relation, its induced successor\nrelation, one linear order relation and some further unary relations is\nEXPSPACE-complete. Actually, EXPSPACE-completeness already holds for structures\nthat do not include the induced successor relation. As a special case, the\nEXPSPACE upper bound applies to two-variable logic over structures with two\nlinear orders. A further consequence is that satisfiability of two-variable\nlogic over data words with a linear order on positions and a linear order and\nsuccessor relation on the data is decidable in EXPSPACE. As a complementing\nresult, it is shown that over structures with two total preorder relations as\nwell as over structures with one total preorder and two linear order relations,\nthe finite satisfiability problem for two-variable logic is undecidable."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:15)2012", 
    "link": "http://arxiv.org/pdf/1110.1614v3", 
    "title": "Intuitionistic Completeness of First-Order Logic", 
    "arxiv-id": "1110.1614v3", 
    "author": "Mark Bickford", 
    "publish": "2011-10-07T19:23:03Z", 
    "summary": "We establish completeness for intuitionistic first-order logic, iFOL, showing\nthat a formula is provable if and only if its embedding into minimal logic,\nmFOL, is uniformly valid under the Brouwer Heyting Kolmogorov (BHK) semantics,\nthe intended semantics of iFOL and mFOL. Our proof is intuitionistic and\nprovides an effective procedure Prf that converts uniform minimal evidence into\na formal first-order proof. We have implemented Prf. Uniform validity is\ndefined using the intersection operator as a universal quantifier over the\ndomain of discourse and atomic predicates. Formulas of iFOL that are uniformly\nvalid are also intuitionistically valid, but not conversely. Our strongest\nresult requires the Fan Theorem; it can also be proved classically by showing\nthat Prf terminates using Konig's Theorem.\n  The fundamental idea behind our completeness theorem is that a single\nevidence term evd witnesses the uniform validity of a minimal logic formula F.\nFinding even one uniform realizer guarantees intuitionistic validity because\nPrf(F, evd) builds a first-order proof of F, establishing its intuitionistic\nvalidity and providing a purely logical normalized realizer.\n  We establish completeness for iFOL as follows. Friedman showed that iFOL can\nbe embedded in minimal logic (mFOL) by his A-transformation, mapping formula F\nto FA. If F is uniformly valid, then so is FA, and by our completeness theorem,\nwe can find a proof of FA in minimal logic. Then we intuitionistically prove F\nfrom FFalse, i.e. by taking False for A and for \\bot of mFOL. Our result\nresolves an open question posed by Beth in 1947."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:15)2012", 
    "link": "http://arxiv.org/pdf/1110.2773v1", 
    "title": "Reasoning with Forest Logic Programs and f-hybrid Knowledge Bases", 
    "arxiv-id": "1110.2773v1", 
    "author": "Stijn Heymans", 
    "publish": "2011-10-12T10:43:05Z", 
    "summary": "Open Answer Set Programming (OASP) is an undecidable framework for\nintegrating ontologies and rules. Although several decidable fragments of OASP\nhave been identified, few reasoning procedures exist. In this article, we\nprovide a sound, complete, and terminating algorithm for satisfiability\nchecking w.r.t. Forest Logic Programs (FoLPs), a fragment of OASP where rules\nhave a tree shape and allow for inequality atoms and constants. The algorithm\nestablishes a decidability result for FoLPs. Although believed to be decidable,\nso far only the decidability for two small subsets of FoLPs, local FoLPs and\nacyclic FoLPs, has been shown. We further introduce f-hybrid knowledge bases, a\nhybrid framework where \\SHOQ{} knowledge bases and forest logic programs\nco-exist, and we show that reasoning with such knowledge bases can be reduced\nto reasoning with forest logic programs only. We note that f-hybrid knowledge\nbases do not require the usual (weakly) DL-safety of the rule component,\nproviding thus a genuine alternative approach to current integration approaches\nof ontologies and rules."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:15)2012", 
    "link": "http://arxiv.org/pdf/1110.4094v2", 
    "title": "A Logic for True Concurrency", 
    "arxiv-id": "1110.4094v2", 
    "author": "Silvia Crafa", 
    "publish": "2011-10-18T19:30:26Z", 
    "summary": "We propose a logic for true concurrency whose formulae predicate about events\nin computations and their causal dependencies. The induced logical equivalence\nis hereditary history preserving bisimilarity, and fragments of the logic can\nbe identified which correspond to other true concurrent behavioural\nequivalences in the literature: step, pomset and history preserving\nbisimilarity. Standard Hennessy-Milner logic, and thus (interleaving)\nbisimilarity, is also recovered as a fragment. We also propose an extension of\nthe logic with fixpoint operators, thus allowing to describe causal and\nconcurrency properties of infinite computations. We believe that this work\ncontributes to a rational presentation of the true concurrent spectrum and to a\ndeeper understanding of the relations between the involved behavioural\nequivalences."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.70.3", 
    "link": "http://arxiv.org/pdf/1110.4672v1", 
    "title": "Toward the Verification of a Simple Hypervisor", 
    "arxiv-id": "1110.4672v1", 
    "author": "William Young", 
    "publish": "2011-10-21T00:45:30Z", 
    "summary": "Virtualization promises significant benefits in security, efficiency,\ndependability, and cost. Achieving these benefits depends upon the reliability\nof the underlying virtual machine monitors (hypervisors). This paper describes\nan ongoing project to develop and verify MinVisor, a simple but functional\nType-I x86 hypervisor, proving protection properties at the assembly level\nusing ACL2. Originally based on an existing research hypervisor, MinVisor\nprovides protection of its own memory from a malicious guest. Our long-term\ngoal is to fully verify MinVisor, providing a vehicle to investigate the\nmodeling and verification of hypervisors at the implementation level, and also\na basis for further systems research. Functional segments of the MinVisor C\ncode base are translated into Y86 assembly, and verified with respect to the\nY86 model. The inductive assertions (also known as \"compositional cutpoints\")\nmethodology is used to prove the correctness of the code. The proof of the code\nthat sets up the nested page tables is described. We compare this project to\nrelated efforts in systems code verification and outline some useful steps\nforward."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.70.7", 
    "link": "http://arxiv.org/pdf/1110.4676v1", 
    "title": "Bit-Blasting ACL2 Theorems", 
    "arxiv-id": "1110.4676v1", 
    "author": "Jared Davis", 
    "publish": "2011-10-21T00:45:59Z", 
    "summary": "Interactive theorem proving requires a lot of human guidance. Proving a\nproperty involves (1) figuring out why it holds, then (2) coaxing the theorem\nprover into believing it. Both steps can take a long time. We explain how to\nuse GL, a framework for proving finite ACL2 theorems with BDD- or SAT-based\nreasoning. This approach makes it unnecessary to deeply understand why a\nproperty is true, and automates the process of admitting it as a theorem. We\nuse GL at Centaur Technology to verify execution units for x86 integer, MMX,\nSSE, and floating-point arithmetic."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.70.8", 
    "link": "http://arxiv.org/pdf/1110.4677v1", 
    "title": "Formal verification of a deadlock detection algorithm", 
    "arxiv-id": "1110.4677v1", 
    "author": "Julien Schmaltz", 
    "publish": "2011-10-21T00:46:07Z", 
    "summary": "Deadlock detection is a challenging issue in the analysis and design of\non-chip networks. We have designed an algorithm to detect deadlocks\nautomatically in on-chip networks with wormhole switching. The algorithm has\nbeen specified and proven correct in ACL2. To enable a top-down proof\nmethodology, some parts of the algorithm have been left unimplemented. For\nthese parts, the ACL2 specification contains constrained functions introduced\nwith defun-sk. We used single-threaded objects to represent the data structures\nused by the algorithm. In this paper, we present details on the proof of\ncorrectness of the algorithm. The process of formal verification was crucial to\nget the algorithm flawless. Our ultimate objective is to have an efficient\nexecutable, and formally proven correct implementation of the algorithm running\nin ACL2."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.70.8", 
    "link": "http://arxiv.org/pdf/1110.5867v1", 
    "title": "From Total Assignment Enumeration to Modern SAT Solver", 
    "arxiv-id": "1110.5867v1", 
    "author": "Alexander Nadel", 
    "publish": "2011-10-26T18:23:56Z", 
    "summary": "A new framework for presenting and analyzing the functionality of a modern\nDLL-based SAT solver is proposed. Our approach exploits the inherent relation\nbetween backtracking and resolution. We show how to derive the algorithm of a\nmodern SAT solver from DLL step-by-step. We analyze the inference power of\nBoolean Constraint Propagation, Non-Chronological Backtracking and 1UIP-based\nConflict-Directed Backjumping. Our work can serve as an introduction to a\nmodern SAT solver functionality and as a basis for future work on the inference\npower of a modern SAT solver and on practical SAT solver design."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.70.8", 
    "link": "http://arxiv.org/pdf/1110.6738v2", 
    "title": "An Incremental Knowledge Compilation in First Order Logic", 
    "arxiv-id": "1110.6738v2", 
    "author": "Manoj K. Raut", 
    "publish": "2011-10-31T10:16:24Z", 
    "summary": "An algorithm to compute the set of prime implicates of a quantifier-free\nclausal formula X in first order logic had been presented in earlier work. As\nthe knowledge base X is dynamic, new clauses are added to the old knowledge\nbase. In this paper an incremental algorithm is presented to compute the prime\nimplicates of X and a clause C from $\\pi(X)\\cup C$. The correctness of the\nalgorithm is also proved."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.71.2", 
    "link": "http://arxiv.org/pdf/1111.0086v1", 
    "title": "A Bigraph Relational Model", 
    "arxiv-id": "1111.0086v1", 
    "author": "Carsten Sch\u00fcrmann", 
    "publish": "2011-11-01T00:18:04Z", 
    "summary": "In this paper, we present a model based on relations for bigraphical reactive\nsystems [Milner09]. Its defining characteristics are that validity and reaction\nrelations are captured as traces in a multi-set rewriting system. The\nrelational model is derived from Milner's graphical definition and directly\namenable to implementation."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.71.4", 
    "link": "http://arxiv.org/pdf/1111.0088v1", 
    "title": "Nominal Logic with Equations Only", 
    "arxiv-id": "1111.0088v1", 
    "author": "Ranald Clouston", 
    "publish": "2011-11-01T00:18:17Z", 
    "summary": "Many formal systems, particularly in computer science, may be captured by\nequations modulated by side conditions asserting the \"freshness of names\";\nthese can be reasoned about with Nominal Equational Logic (NEL). Like most\nlogics of this sort NEL employs this notion of freshness as a first class\nlogical connective. However, this can become inconvenient when attempting to\ntranslate results from standard equational logic to the nominal setting. This\npaper presents proof rules for a logic whose only connectives are equations,\nwhich we call Nominal Equation-only Logic (NEoL). We prove that NEoL is just as\nexpressive as NEL. We then give a simple description of equality in the empty\nNEoL-theory, then extend that result to describe freshness in the empty\nNEL-theory."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(4:5)2011", 
    "link": "http://arxiv.org/pdf/1111.0123v2", 
    "title": "Proof-irrelevant model of CC with predicative induction and judgmental   equality", 
    "arxiv-id": "1111.0123v2", 
    "author": "Benjamin Werner", 
    "publish": "2011-11-01T05:51:19Z", 
    "summary": "We present a set-theoretic, proof-irrelevant model for Calculus of\nConstructions (CC) with predicative induction and judgmental equality in\nZermelo-Fraenkel set theory with an axiom for countably many inaccessible\ncardinals. We use Aczel's trace encoding which is universally defined for any\nfunction type, regardless of being impredicative. Direct and concrete\ninterpretations of simultaneous induction and mutually recursive functions are\nalso provided by extending Dybjer's interpretations on the basis of Aczel's\nrule sets. Our model can be regarded as a higher-order generalization of the\ntruth-table methods. We provide a relatively simple consistency proof of type\ntheory, which can be used as the basis for a theorem prover."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.72.2", 
    "link": "http://arxiv.org/pdf/1111.0369v1", 
    "title": "Variations on Multi-Core Nested Depth-First Search", 
    "arxiv-id": "1111.0369v1", 
    "author": "Jaco van de Pol", 
    "publish": "2011-11-02T03:04:15Z", 
    "summary": "Recently, two new parallel algorithms for on-the-fly model checking of LTL\nproperties were presented at the same conference: Automated Technology for\nVerification and Analysis, 2011. Both approaches extend Swarmed NDFS, which\nruns several sequential NDFS instances in parallel. While parallel random\nsearch already speeds up detection of bugs, the workers must share some global\ninformation in order to speed up full verification of correct models. The two\nalgorithms differ considerably in the global information shared between\nworkers, and in the way they synchronize.\n  Here, we provide a thorough experimental comparison between the two\nalgorithms, by measuring the runtime of their implementations on a multi-core\nmachine. Both algorithms were implemented in the same framework of the model\nchecker LTSmin, using similar optimizations, and have been subjected to the\nfull BEEM model database.\n  Because both algorithms have complementary advantages, we constructed an\nalgorithm that combines both ideas. This combination clearly has an improved\nspeedup. We also compare the results with the alternative parallel algorithm\nfor accepting cycle detection OWCTY-MAP. Finally, we study a simple statistical\nmodel for input models that do contain accepting cycles. The goal is to\ndistinguish the speedup due to parallel random search from the speedup that can\nbe attributed to clever work sharing schemes."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(4:4)2011", 
    "link": "http://arxiv.org/pdf/1111.1011v3", 
    "title": "Context-Bounded Analysis For Concurrent Programs With Dynamic Creation   of Threads", 
    "arxiv-id": "1111.1011v3", 
    "author": "Shaz Qadeer", 
    "publish": "2011-11-03T23:37:53Z", 
    "summary": "Context-bounded analysis has been shown to be both efficient and effective at\nfinding bugs in concurrent programs. According to its original definition,\ncontext-bounded analysis explores all behaviors of a concurrent program up to\nsome fixed number of context switches between threads. This definition is\ninadequate for programs that create threads dynamically because bounding the\nnumber of context switches in a computation also bounds the number of threads\ninvolved in the computation. In this paper, we propose a more general\ndefinition of context-bounded analysis useful for programs with dynamic thread\ncreation. The idea is to bound the number of context switches for each thread\ninstead of bounding the number of switches of all threads. We consider several\nvariants based on this new definition, and we establish decidability and\ncomplexity results for the analysis induced by them."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(4:4)2011", 
    "link": "http://arxiv.org/pdf/1111.2824v1", 
    "title": "Towards Automated Verification of Web Services", 
    "arxiv-id": "1111.2824v1", 
    "author": "C. Ferreira", 
    "publish": "2011-11-11T19:14:05Z", 
    "summary": "This paper proposes the use of model-checking software technology for the\nverification of workflows and business processes behaviour based on web\nservices, namely the use of the SPIN model checker. Since the specification of\na business process behaviour based on web services can be decomposed into\npatterns, it is proposed a translation of a well known collection of workflow\npatterns into PROMELA, the input specification language of SPIN. The use of\nthis translation is illustrated with one business process example, which\ndemonstrates how its translation to a PROMELA model can be useful in the web\nservice specification and verification."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.73.5", 
    "link": "http://arxiv.org/pdf/1111.3107v1", 
    "title": "Trees over Infinite Structures and Path Logics with Synchronization", 
    "arxiv-id": "1111.3107v1", 
    "author": "Sarah Winter", 
    "publish": "2011-11-14T06:35:15Z", 
    "summary": "We provide decidability and undecidability results on the model-checking\nproblem for infinite tree structures. These tree structures are built from\nsequences of elements of infinite relational structures. More precisely, we\ndeal with the tree iteration of a relational structure M in the sense of\nShelah-Stupp. In contrast to classical results where model-checking is shown\ndecidable for MSO-logic, we show decidability of the tree model-checking\nproblem for logics that allow only path quantifiers and chain quantifiers\n(where chains are subsets of paths), as they appear in branching time logics;\nhowever, at the same time the tree is enriched by the equal-level relation\n(which holds between vertices u, v if they are on the same tree level). We\nseparate cleanly the tree logic from the logic used for expressing properties\nof the underlying structure M. We illustrate the scope of the decidability\nresults by showing that two slight extensions of the framework lead to\nundecidability. In particular, this applies to the (stronger) tree iteration in\nthe sense of Muchnik-Walukiewicz."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.73.7", 
    "link": "http://arxiv.org/pdf/1111.3109v1", 
    "title": "A coinductive semantics of the Unlimited Register Machine", 
    "arxiv-id": "1111.3109v1", 
    "author": "Alberto Ciaffaglione", 
    "publish": "2011-11-14T06:35:31Z", 
    "summary": "We exploit (co)inductive specifications and proofs to approach the evaluation\nof low-level programs for the Unlimited Register Machine (URM) within the Coq\nsystem, a proof assistant based on the Calculus of (Co)Inductive Constructions\ntype theory. Our formalization allows us to certify the implementation of\npartial functions, thus it can be regarded as a first step towards the\ndevelopment of a workbench for the formal analysis and verification of both\nconverging and diverging computations."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.73.9", 
    "link": "http://arxiv.org/pdf/1111.3111v1", 
    "title": "A Probabilistic Temporal Logic with Frequency Operators and Its Model   Checking", 
    "arxiv-id": "1111.3111v1", 
    "author": "Naoki Yonezaki", 
    "publish": "2011-11-14T06:35:46Z", 
    "summary": "Probabilistic Computation Tree Logic (PCTL) and Continuous Stochastic Logic\n(CSL) are often used to describe specifications of probabilistic properties for\ndiscrete time and continuous time, respectively. In PCTL and CSL, the\npossibility of executions satisfying some temporal properties can be\nquantitatively represented by the probabilistic extension of the path\nquantifiers in their basic Computation Tree Logic (CTL), however, path formulae\nof them are expressed via the same operators in CTL. For this reason, both of\nthem cannot represent formulae with quantitative temporal properties, such as\nthose of the form \"some properties hold to more than 80% of time points (in a\ncertain bounded interval) on the path.\" In this paper, we introduce a new\ntemporal operator which expressed the notion of frequency of events, and define\nprobabilistic frequency temporal logic (PFTL) based on CTL\\star. As a result,\nwe can easily represent the temporal properties of behavior in probabilistic\nsystems. However, it is difficult to develop a model checker for the full PFTL,\ndue to rich expressiveness. Accordingly, we develop a model-checking algorithm\nfor the CTL-like fragment of PFTL against finite-state Markov chains, and an\napproximate model-checking algorithm for the bounded Linear Temporal Logic\n(LTL) -like fragment of PFTL against countable-state Markov chains."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.tcs.2012.06.007", 
    "link": "http://arxiv.org/pdf/1111.4611v1", 
    "title": "From nominal sets binding to functions and lambda-abstraction:   connecting the logic of permutation models with the logic of functions", 
    "arxiv-id": "1111.4611v1", 
    "author": "Murdoch Gabbay", 
    "publish": "2011-11-20T06:12:35Z", 
    "summary": "Permissive-Nominal Logic (PNL) extends first-order predicate logic with\nterm-formers that can bind names in their arguments. It takes a semantics in\n(permissive-)nominal sets. In PNL, the forall-quantifier or lambda-binder are\njust term-formers satisfying axioms, and their denotation is functions on\nnominal atoms-abstraction.\n  Then we have higher-order logic (HOL) and its models in ordinary (i.e.\nZermelo-Fraenkel) sets; the denotation of forall or lambda is functions on full\nor partial function spaces.\n  This raises the following question: how are these two models of binding\nconnected? What translation is possible between PNL and HOL, and between\nnominal sets and functions?\n  We exhibit a translation of PNL into HOL, and from models of PNL to certain\nmodels of HOL. It is natural, but also partial: we translate a restricted\nsubsystem of full PNL to HOL. The extra part which does not translate is the\nsymmetry properties of nominal sets with respect to permutations. To use a\nlittle nominal jargon: we can translate names and binding, but not their\nnominal equivariance properties. This seems reasonable since HOL---and ordinary\nsets---are not equivariant.\n  Thus viewed through this translation, PNL and HOL and their models do\ndifferent things, but they enjoy non-trivial and rich subsystems which are\nisomorphic."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:6)2012", 
    "link": "http://arxiv.org/pdf/1111.5652v2", 
    "title": "Ground interpolation for the theory of equality", 
    "arxiv-id": "1111.5652v2", 
    "author": "Cesare Tinelli", 
    "publish": "2011-11-23T23:57:19Z", 
    "summary": "Theory interpolation has found several successful applications in model\nchecking. We present a novel method for computing interpolants for ground\nformulas in the theory of equality. The method produces interpolants from\ncolored congruence graphs representing derivations in that theory. These graphs\ncan be produced by conventional congruence closure algorithms in a\nstraightforward manner. By working with graphs, rather than at the level of\nindividual proof steps, we are able to derive interpolants that are pleasingly\nsimple (conjunctions of Horn clauses) and smaller than those generated by other\ntools. Our interpolation method can be seen as a theory-specific implementation\nof a cooperative interpolation game between two provers. We present a generic\nversion of the interpolation game, parametrized by the theory T, and define a\ngeneral method to extract runs of the game from proofs in T and then generate\ninterpolants from these runs."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:6)2012", 
    "link": "http://arxiv.org/pdf/1111.5885v2", 
    "title": "Type inference in mathematics", 
    "arxiv-id": "1111.5885v2", 
    "author": "Jeremy Avigad", 
    "publish": "2011-11-25T03:18:18Z", 
    "summary": "In the theory of programming languages, type inference is the process of\ninferring the type of an expression automatically, often making use of\ninformation from the context in which the expression appears. Such mechanisms\nturn out to be extremely useful in the practice of interactive theorem proving,\nwhereby users interact with a computational proof assistant to construct formal\naxiomatic derivations of mathematical theorems. This article explains some of\nthe mechanisms for type inference used by the Mathematical Components project,\nwhich is working towards a verification of the Feit-Thompson theorem."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(4:7)2011", 
    "link": "http://arxiv.org/pdf/1111.5901v2", 
    "title": "A note on the expressive power of linear orders", 
    "arxiv-id": "1111.5901v2", 
    "author": "Nicole Schweikardt", 
    "publish": "2011-11-25T06:53:56Z", 
    "summary": "This article shows that there exist two particular linear orders such that\nfirst-order logic with these two linear orders has the same expressive power as\nfirst-order logic with the Bit-predicate FO(Bit). As a corollary we obtain that\nthere also exists a built-in permutation such that first-order logic with a\nlinear order and this permutation is as expressive as FO(Bit)."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(4:7)2011", 
    "link": "http://arxiv.org/pdf/1112.0347v1", 
    "title": "Domain Theory and the Logic of Observable Properties", 
    "arxiv-id": "1112.0347v1", 
    "author": "Samson Abramsky", 
    "publish": "2011-12-01T22:29:23Z", 
    "summary": "The mathematical framework of Stone duality is used to synthesize a number of\nhitherto separate developments in Theoretical Computer Science: - Domain\nTheory, the mathematical theory of computation introduced by Scott as a\nfoundation for denotational semantics. - The theory of concurrency and systems\nbehaviour developed by Milner, Hennessy et al. based on operational semantics.\n- Logics of programs.\n  Stone duality provides a junction between semantics (spaces of points =\ndenotations of computational processes) and logics (lattices of properties of\nprocesses). Moreover, the underlying logic is geometric, which can be\ncomputationally interpreted as the logic of observable properties---i.e.\nproperties which can be determined to hold of a process on the basis of a\nfinite amount of information about its execution.\n  These ideas lead to the following programme:\n  1. A metalanguage is introduced, comprising\n  - types = universes of discourse for various computational situations.\n  - terms = programs = syntactic intensions for models or points.\n  2. A standard denotational interpretation of the metalanguage is given,\nassigning domains to types and domain elements to terms.\n  3. The metalanguage is also given a {\\em logical} interpretation, in which\ntypes are interpreted as propositional theories and terms are interpreted via a\nprogram logic, which axiomatizes the properties they satisfy.\n  4. The two interpretations are related by showing that they are Stone duals\nof each other. Hence, semantics and logic are guaranteed to be in harmony with\neach other, and in fact each determines the other up to isomorphism.\n  This opens the way to a whole range of applications. Given a denotational\ndescription of a computational situation in our meta-language, we can turn the\nhandle to obtain a logic for that situation."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(4:7)2011", 
    "link": "http://arxiv.org/pdf/1112.0643v1", 
    "title": "How big is BCI fragment of BCK logic", 
    "arxiv-id": "1112.0643v1", 
    "author": "Marek Zaionc", 
    "publish": "2011-12-03T11:05:40Z", 
    "summary": "We investigate quantitative properties of BCI and BCK logics. The first part\nof the paper compares the number of formulas provable in BCI versus BCK logics.\nWe consider formulas built on implication and a fixed set of $k$ variables. We\ninvestigate the proportion between the number of such formulas of a given\nlength $n$ provable in BCI logic against the number of formulas of length $n$\nprovable in richer BCK logic. We examine an asymptotic behavior of this\nfraction when length $n$ of formulas tends to infinity. This limit gives a\nprobability measure that randomly chosen BCK formula is also provable in BCI.\nWe prove that this probability tends to zero as the number of variables tends\nto infinity. The second part of the paper is devoted to the number of lambda\nterms representing proofs of BCI and BCK logics. We build a proportion between\nnumber of such proofs of the same length $n$ and we investigate asymptotic\nbehavior of this proportion when length of proofs tends to infinity. We\ndemonstrate that with probability 0 a randomly chosen BCK proof is also a proof\nof a BCI formula."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(4:7)2011", 
    "link": "http://arxiv.org/pdf/1112.1316v1", 
    "title": "Generic Environments in Coq", 
    "arxiv-id": "1112.1316v1", 
    "author": "Emmanuel Polonowski", 
    "publish": "2011-12-06T15:39:48Z", 
    "summary": "We introduce a library which provides an abstract data type of environments,\nas a functor parameterized by a module defining variables, and a function which\nbuilds environments for such variables with any Type of type. Usual operations\nover environments are defined, along with an extensive set of basic and more\nadvanced properties. Moreover, we give an implementation using lists satisfying\nall the required properties."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(4:7)2011", 
    "link": "http://arxiv.org/pdf/1112.1554v1", 
    "title": "A program logic for higher-order procedural variables and non-local   jumps", 
    "arxiv-id": "1112.1554v1", 
    "author": "Emmanuel Polonowski", 
    "publish": "2011-12-07T13:23:37Z", 
    "summary": "Relying on the formulae-as-types paradigm for classical logic, we define a\nprogram logic for an imperative language with higher-order procedural variables\nand non-local jumps. Then, we show how to derive a sound program logic for this\nprogramming language. As a by-product, we obtain a non-dependent type system\nwhich is more permissive than what is usually found in statically typed\nimperative languages. As a generic example, we encode imperative versions of\ndelimited continuations operators shift and reset."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(4:7)2011", 
    "link": "http://arxiv.org/pdf/1112.1848v1", 
    "title": "A Formally Specified Program Logic for Higher-Order Procedural Variables   and non-local Jumps", 
    "arxiv-id": "1112.1848v1", 
    "author": "Tristan Crolard", 
    "publish": "2011-12-08T14:36:59Z", 
    "summary": "We formally specified a program logic for higher-order procedural variables\nand non-local jumps with Ott and Twelf. Moreover, the dependent type systems\nand the translation are both executable specifications thanks to Twelf's logic\nprogramming engine. In particular, relying on Filinski's encoding of\nshift/reset using callcc/throw and a global meta-continuation (simulated in\nstate passing style), we have mechanically checked the correctness of a few\nexamples (all source files are available on request)."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(4:7)2011", 
    "link": "http://arxiv.org/pdf/1112.2313v2", 
    "title": "QBF-Based Boolean Function Bi-Decomposition", 
    "arxiv-id": "1112.2313v2", 
    "author": "Joao Marques-Silva", 
    "publish": "2011-12-11T00:41:04Z", 
    "summary": "Boolean function bi-decomposition is ubiquitous in logic synthesis. It\nentails the decomposition of a Boolean function using two-input simple logic\ngates. Existing solutions for bi-decomposition are often based on BDDs and,\nmore recently, on Boolean Satisfiability. In addition, the partition of the\ninput set of variables is either assumed, or heuristic solutions are considered\nfor finding good partitions. In contrast to earlier work, this paper proposes\nthe use of Quantified Boolean Formulas (QBF) for computing bi- decompositions.\nThese bi-decompositions are optimal in terms of the achieved disjointness and\nbalancedness of the input set of variables. Experimental results, obtained on\nrepresentative benchmarks, demonstrate clear improvements in the quality of\ncomputed decompositions, but also the practical feasibility of QBF-based\nbi-decomposition."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(4:7)2011", 
    "link": "http://arxiv.org/pdf/1112.2950v1", 
    "title": "Deriving a Hoare-Floyd logic for non-local jumps from a   formulae-as-types notion of control", 
    "arxiv-id": "1112.2950v1", 
    "author": "Emmanuel Polonowski", 
    "publish": "2011-12-13T16:44:27Z", 
    "summary": "We derive a Hoare-Floyd logic for non-local jumps and mutable higher-order\nprocedural variables from a formul{\\ae}-as-types notion of control for\nclassical logic. The main contribution of this work is the design of an\nimperative dependent type system for non-local jumps which corresponds to\nclassical logic but where the famous consequence rule is still derivable."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-19805-2_23", 
    "link": "http://arxiv.org/pdf/1112.3053v1", 
    "title": "Estimation of the length of interactions in arena game semantics", 
    "arxiv-id": "1112.3053v1", 
    "author": "Pierre Clairambault", 
    "publish": "2011-12-13T21:47:07Z", 
    "summary": "We estimate the maximal length of interactions between strategies in HO/N\ngame semantics, in the spirit of the work by Schwichtenberg and Beckmann for\nthe length of reduction in simply typed lambdacalculus. Because of the\noperational content of game semantics, the bounds presented here also apply to\nhead linear reduction on lambda-terms and to the execution of programs by\nabstract machines (PAM/KAM), including in presence of computational effects\nsuch as non-determinism or ground type references. The proof proceeds by\nextracting from the games model a combinatorial rewriting rule on trees of\nnatural numbers, which can then be analyzed independently of game semantics or\nlambda-calculus."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:7)2012", 
    "link": "http://arxiv.org/pdf/1201.0557v3", 
    "title": "Absorbing Subalgebras, Cyclic Terms, and the Constraint Satisfaction   Problem", 
    "arxiv-id": "1201.0557v3", 
    "author": "Marcin Kozik", 
    "publish": "2012-01-03T01:27:02Z", 
    "summary": "The Algebraic Dichotomy Conjecture states that the Constraint Satisfaction\nProblem over a fixed template is solvable in polynomial time if the algebra of\npolymorphisms associated to the template lies in a Taylor variety, and is\nNP-complete otherwise. This paper provides two new characterizations of\nfinitely generated Taylor varieties. The first characterization is using\nabsorbing subalgebras and the second one cyclic terms. These new conditions\nallow us to reprove the conjecture of Bang-Jensen and Hell (proved by the\nauthors) and the characterization of locally finite Taylor varieties using weak\nnear-unanimity terms (proved by McKenzie and Mar\\'oti) in an elementary and\nself-contained way."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.75.3", 
    "link": "http://arxiv.org/pdf/1201.1121v1", 
    "title": "Provably Total Functions of Arithmetic with Basic Terms", 
    "arxiv-id": "1201.1121v1", 
    "author": "Evgeny Makarov", 
    "publish": "2012-01-05T11:06:51Z", 
    "summary": "A new characterization of provably recursive functions of first-order\narithmetic is described. Its main feature is using only terms consisting of 0,\nthe successor S and variables in the quantifier rules, namely, universal\nelimination and existential introduction."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.75.3", 
    "link": "http://arxiv.org/pdf/1201.1410v1", 
    "title": "Is it a \"Good\" Encoding of Mixed Choice? (Technical Report)", 
    "arxiv-id": "1201.1410v1", 
    "author": "Uwe Nestmann", 
    "publish": "2012-01-06T13:15:11Z", 
    "summary": "This technical report contains the proofs to the lemmata and theorems of\n[PN12] as well as some additional material. As main contributions [PN12]\npresents an encoding of mixed choice in the context of the pi-calculus and a\ncriterion to measure whether the degree of distribution in process networks is\npreserved."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:3)2012", 
    "link": "http://arxiv.org/pdf/1201.1705v2", 
    "title": "On completeness of reducibility candidates as a semantics of strong   normalization", 
    "arxiv-id": "1201.1705v2", 
    "author": "Denis Cousineau", 
    "publish": "2012-01-09T08:12:29Z", 
    "summary": "This paper defines a sound and complete semantic criterion, based on\nreducibility candidates, for strong normalization of theories expressed in\nminimal deduction modulo \\`a la Curry. The use of Curry-style proof-terms\nallows to build this criterion on the classic notion of pre-Heyting algebras\nand makes that criterion concern all theories expressed in minimal deduction\nmodulo. Compared to using Church-style proof-terms, this method provides both a\nsimpler definition of the criterion and a simpler proof of its completeness."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:4)2012", 
    "link": "http://arxiv.org/pdf/1201.1716v2", 
    "title": "A type reduction theory for systems with replicated components", 
    "arxiv-id": "1201.1716v2", 
    "author": "Gavin Lowe", 
    "publish": "2012-01-09T09:29:12Z", 
    "summary": "The Parameterised Model Checking Problem asks whether an implementation\nImpl(t) satisfies a specification Spec(t) for all instantiations of parameter\nt. In general, t can determine numerous entities: the number of processes used\nin a network, the type of data, the capacities of buffers, etc. The main theme\nof this paper is automation of uniform verification of a subclass of PMCP with\nthe parameter of the first kind, i.e. the number of processes in the network.\nWe use CSP as our formalism. We present a type reduction theory, which, for a\ngiven verification problem, establishes a function \\phi that maps all\n(sufficiently large) instantiations T of the parameter to some fixed type T^\nand allows us to deduce that if Spec(T^) is refined by \\phi(Impl(T)), then\n(subject to certain assumptions) Spec(T) is refined by Impl(T). The theory can\nbe used in practice by combining it with a suitable abstraction method that\nproduces a t-independent process Abstr that is refined by {\\phi}(Impl(T)) for\nall sufficiently large T. Then, by testing (with a model checker) if the\nabstract model Abstr refines Spec(T^), we can deduce a positive answer to the\noriginal uniform verification problem. The type reduction theory relies on\nsymbolic representation of process behaviour. We develop a symbolic operational\nsemantics for CSP processes that satisfy certain normality requirements, and we\nprovide a set of translation rules that allow us to concretise symbolic\ntransition graphs. Based on this, we prove results that allow us to infer\nbehaviours of a process instantiated with uncollapsed types from known\nbehaviours of the same process instantiated with a reduced type. One of the\nmain advantages of our symbolic operational semantics and the type reduction\ntheory is their generality, which makes them applicable in a wide range of\nsettings."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:4)2012", 
    "link": "http://arxiv.org/pdf/1201.2258v1", 
    "title": "Characterisations of Testing Preorders for a Finite Probabilistic   pi-Calculus", 
    "arxiv-id": "1201.2258v1", 
    "author": "Alwen Tiu", 
    "publish": "2012-01-11T08:22:46Z", 
    "summary": "We consider two characterisations of the may and must testing preorders for a\nprobabilistic extension of the finite pi-calculus: one based on notions of\nprobabilistic weak simulations, and the other on a probabilistic extension of a\nfragment of Milner-Parrow-Walker modal logic for the pi-calculus. We base our\nnotions of simulations on the similar concepts used in previous work for\nprobabilistic CSP. However, unlike the case with CSP (or other\nnon-value-passing calculi), there are several possible definitions of\nsimulation for the probabilistic pi-calculus, which arise from different ways\nof scoping the name quantification. We show that in order to capture the\ntesting preorders, one needs to use the \"earliest\" simulation relation (in\nanalogy to the notion of early (bi)simulation in the non-probabilistic case).\nThe key ideas in both characterisations are the notion of a \"characteristic\nformula\" of a probabilistic process, and the notion of a \"characteristic test\"\nfor a formula. As in an earlier work on testing equivalence for the pi-calculus\nby Boreale and De Nicola, we extend the language of the $\\pi$-calculus with a\nmismatch operator, without which the formulation of a characteristic test will\nnot be possible."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:4)2012", 
    "link": "http://arxiv.org/pdf/1201.2956v5", 
    "title": "On paths-based criteria for polynomial time complexity in proof-nets", 
    "arxiv-id": "1201.2956v5", 
    "author": "Matthieu Perrinel", 
    "publish": "2012-01-13T21:21:45Z", 
    "summary": "Girard's Light linear logic (LLL) characterized polynomial time in the\nproof-as-program paradigm with a bound on cut elimination. This logic relied on\na stratification principle and a \"one-door\" principle which were generalized\nlater respectively in the systems L^4 and L^3a. Each system was brought with\nits own complex proof of Ptime soundness.\n  In this paper we propose a broad sufficient criterion for Ptime soundness for\nlinear logic subsystems, based on the study of paths inside the proof-nets,\nwhich factorizes proofs of soundness of existing systems and may be used for\nfuture systems. As an additional gain, our bound stands for any reduction\nstrategy whereas most bounds in the literature only stand for a particular\nstrategy."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:4)2012", 
    "link": "http://arxiv.org/pdf/1201.3251v2", 
    "title": "Automatic Sequences and Zip-Specifications", 
    "arxiv-id": "1201.3251v2", 
    "author": "Lawrence S. Moss", 
    "publish": "2012-01-16T13:29:28Z", 
    "summary": "We consider infinite sequences of symbols, also known as streams, and the\ndecidability question for equality of streams defined in a restricted format.\nThis restricted format consists of prefixing a symbol at the head of a stream,\nof the stream function `zip', and recursion variables. Here `zip' interleaves\nthe elements of two streams in alternating order, starting with the first\nstream. For example, the Thue-Morse sequence is obtained by the\n`zip-specification' {M = 0 : X, X = 1 : zip(X,Y), Y = 0 : zip(Y,X)}. Our\nanalysis of such systems employs both term rewriting and coalgebraic\ntechniques. We establish decidability for these zip-specifications, employing\nbisimilarity of observation graphs based on a suitably chosen cobasis. The\nimportance of zip-specifications resides in their intimate connection with\nautomatic sequences. We establish a new and simple characterization of\nautomatic sequences. Thus we obtain for the binary zip that a stream is\n2-automatic iff its observation graph using the cobasis (hd,even,odd) is\nfinite. The generalization to zip-k specifications and their relation to\nk-automaticity is straightforward. In fact, zip-specifications can be perceived\nas a term rewriting syntax for automatic sequences. Our study of\nzip-specifications is placed in an even wider perspective by employing the\nobservation graphs in a dynamic logic setting, leading to an alternative\ncharacterization of automatic sequences. We further obtain a natural extension\nof the class of automatic sequences, obtained by `zip-mix' specifications that\nuse zips of different arities in one specification. We also show that\nequivalence is undecidable for a simple extension of the zip-mix format with\nprojections like even and odd. However, it remains open whether zip-mix\nspecifications have a decidable equivalence problem."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:30)2012", 
    "link": "http://arxiv.org/pdf/1201.3601v2", 
    "title": "A Synthesis of the Procedural and Declarative Styles of Interactive   Theorem Proving", 
    "arxiv-id": "1201.3601v2", 
    "author": "Freek Wiedijk", 
    "publish": "2012-01-17T19:44:55Z", 
    "summary": "We propose a synthesis of the two proof styles of interactive theorem\nproving: the procedural style (where proofs are scripts of commands, like in\nCoq) and the declarative style (where proofs are texts in a controlled natural\nlanguage, like in Isabelle/Isar). Our approach combines the advantages of the\ndeclarative style - the possibility to write formal proofs like normal\nmathematical text - and the procedural style - strong automation and help with\nshaping the proofs, including determining the statements of intermediate steps.\nOur approach is new, and differs significantly from the ways in which the\nprocedural and declarative proof styles have been combined before in the\nIsabelle, Ssreflect and Matita systems. Our approach is generic and can be\nimplemented on top of any procedural interactive theorem prover, regardless of\nits architecture and logical foundations. To show the viability of our proposed\napproach, we fully implemented it as a proof interface called miz3, on top of\nthe HOL Light interactive theorem prover. The declarative language that this\ninterface uses is a slight variant of the language of the Mizar system, and can\nbe used for any interactive theorem prover regardless of its logical\nfoundations. The miz3 interface allows easy access to the full set of tactics\nand formal libraries of HOL Light, and as such has \"industrial strength\". Our\napproach gives a way to automatically convert any procedural proof to a\ndeclarative counterpart, where the converted proof is similar in size to the\noriginal. As all declarative systems have essentially the same proof language,\nthis gives a straightforward way to port proofs between interactive theorem\nprovers."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:2)2012", 
    "link": "http://arxiv.org/pdf/1201.3731v2", 
    "title": "Formal proofs in real algebraic geometry: from ordered fields to   quantifier elimination", 
    "arxiv-id": "1201.3731v2", 
    "author": "Cyril Cohen", 
    "publish": "2012-01-18T09:30:01Z", 
    "summary": "This paper describes a formalization of discrete real closed fields in the\nCoq proof assistant. This abstract structure captures for instance the theory\nof real algebraic numbers, a decidable subset of real numbers with good\nalgorithmic properties. The theory of real algebraic numbers and more generally\nof semi-algebraic varieties is at the core of a number of effective methods in\nreal analysis, including decision procedures for non linear arithmetic or\noptimization methods for real valued functions. After defining an abstract\nstructure of discrete real closed field and the elementary theory of real roots\nof polynomials, we describe the formalization of an algebraic proof of\nquantifier elimination based on pseudo-remainder sequences following the\nstandard computer algebra literature on the topic. This formalization covers a\nlarge part of the theory which underlies the efficient algorithms implemented\nin practice in computer algebra. The success of this work paves the way for\nformal certification of these efficient methods."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:2)2012", 
    "link": "http://arxiv.org/pdf/1201.4307v2", 
    "title": "Quantitative classical realizability", 
    "arxiv-id": "1201.4307v2", 
    "author": "Alo\u00efs Brunel", 
    "publish": "2012-01-20T14:35:09Z", 
    "summary": "Introduced by Dal Lago and Hofmann, quantitative realizability is a technique\nused to define models for logics based on Multiplicative Linear Logic. A\nparticularity is that functions are interpreted as bounded time computable\nfunctions. It has been used to give new and uniform proofs of soundness of\nseveral type systems with respect to certain time complexity classes. We\npropose a reformulation of their ideas in the setting of Krivine's classical\nrealizability. The framework obtained generalizes Dal Lago and Hofmann's\nrealizability, and reveals deep connections between quantitative realizability\nand a linear variant of Cohen's forcing."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:2)2012", 
    "link": "http://arxiv.org/pdf/1201.4449v2", 
    "title": "Faster Algorithms for Alternating Refinement Relations", 
    "arxiv-id": "1201.4449v2", 
    "author": "Pritish Kamath", 
    "publish": "2012-01-21T08:30:11Z", 
    "summary": "One central issue in the formal design and analysis of reactive systems is\nthe notion of refinement that asks whether all behaviors of the implementation\nis allowed by the specification. The local interpretation of behavior leads to\nthe notion of simulation. Alternating transition systems (ATSs) provide a\ngeneral model for composite reactive systems, and the simulation relation for\nATSs is known as alternating simulation. The simulation relation for fair\ntransition systems is called fair simulation. In this work our main\ncontributions are as follows: (1) We present an improved algorithm for fair\nsimulation with B\\\"uchi fairness constraints; our algorithm requires $O(n^3\n\\cdot m)$ time as compared to the previous known $O(n^6)$-time algorithm, where\n$n$ is the number of states and $m$ is the number of transitions. (2) We\npresent a game based algorithm for alternating simulation that requires\n$O(m^2)$-time as compared to the previous known $O((n \\cdot m)^2)$-time\nalgorithm, where $n$ is the number of states and $m$ is the size of transition\nrelation. (3) We present an iterative algorithm for alternating simulation that\nmatches the time complexity of the game based algorithm, but is more space\nefficient than the game based algorithm."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:2)2012", 
    "link": "http://arxiv.org/pdf/1201.4462v1", 
    "title": "A System-Level Semantics", 
    "arxiv-id": "1201.4462v1", 
    "author": "Nikos Tzevelekos", 
    "publish": "2012-01-21T11:27:10Z", 
    "summary": "Game semantics is a trace-like denotational semantics for programming\nlanguages where the notion of legal observable behaviour of a term is defined\ncombinatorially, by means of rules of a game between the term (the \"Proponent\")\nand its context (the \"Opponent\"). In general, the richer the computational\nfeatures a language has, the less constrained the rules of the semantic game.\nIn this paper we consider the consequences of taking this relaxation of rules\nto the limit, by granting the Opponent omnipotence, that is, permission to play\nany move without combinatorial restrictions. However, we impose an epistemic\nrestriction by not granting Opponent omniscience, so that Proponent can have\nundisclosed secret moves. We introduce a basic C-like programming language and\nwe define such a semantic model for it. We argue that the resulting semantics\nis an appealingly simple combination of operational and game semantics and we\nshow how certain traces explain system-level attacks, i.e. plausible attacks\nthat are realizable outside of the programming language itself. We also show\nhow allowing Proponent to have secrets ensures that some desirable equivalences\nin the programming language are preserved."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:2)2012", 
    "link": "http://arxiv.org/pdf/1201.5070v1", 
    "title": "Word Automaticity of Tree Automatic Scattered Linear Orderings Is   Decidable", 
    "arxiv-id": "1201.5070v1", 
    "author": "Martin Huschenbett", 
    "publish": "2012-01-24T18:03:50Z", 
    "summary": "A tree automatic structure is a structure whose domain can be encoded by a\nregular tree language such that each relation is recognisable by a finite\nautomaton processing tuples of trees synchronously. Words can be regarded as\nspecific simple trees and a structure is word automatic if it is encodable\nusing only these trees. The question naturally arises whether a given tree\nautomatic structure is already word automatic. We prove that this problem is\ndecidable for tree automatic scattered linear orderings. Moreover, we show that\nin case of a positive answer a word automatic presentation is computable from\nthe tree automatic presentation."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:2)2012", 
    "link": "http://arxiv.org/pdf/1201.5653v4", 
    "title": "Quantifier Elimination by Dependency Sequents", 
    "arxiv-id": "1201.5653v4", 
    "author": "Panagiotis Manolios", 
    "publish": "2012-01-26T21:18:29Z", 
    "summary": "We consider the problem of existential quantifier elimination for Boolean\nformulas in Conjunctive Normal Form (CNF). We present a new method for solving\nthis problem called Derivation of Dependency-Sequents (DDS). A\nDependency-sequent (D-sequent) is used to record that a set of quantified\nvariables is redundant under a partial assignment. We introduce a\nresolution-like operation called join that produces a new D-sequent from two\nexisting D-sequents. We also show that DDS is compositional, i.e. if our input\nformula is a conjunction of independent formulas, DDS automatically recognizes\nand exploits this information. We introduce an algorithm based on DDS and\npresent experimental results demonstrating its potential."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:2)2012", 
    "link": "http://arxiv.org/pdf/1201.5719v2", 
    "title": "Deciding Entailment of Implications with Support and Confidence in   Polynomial Space", 
    "arxiv-id": "1201.5719v2", 
    "author": "Daniel Borchmann", 
    "publish": "2012-01-27T08:32:38Z", 
    "summary": "Association Rules are a basic concept of data mining. They are, however, not\nunderstood as logical objects which can be used for reasoning. The purpose of\nthis paper is to investigate a model based semantic for implications with\ncertain constraints on their support and confidence in relational data, which\nthen resemble association rules, and to present a possibility to decide\nentailment for them."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:2)2012", 
    "link": "http://arxiv.org/pdf/1201.5954v1", 
    "title": "A Calculus for Generating Ground Explanations (Technical Report)", 
    "arxiv-id": "1201.5954v1", 
    "author": "Nicolas Peltier", 
    "publish": "2012-01-28T12:35:04Z", 
    "summary": "We present a modification of the superposition calculus that is meant to\ngenerate explanations why a set of clauses is satisfiable. This process is\nrelated to abductive reasoning, and the explanations generated are clauses\nconstructed over so-called abductive constants. We prove the correctness and\ncompleteness of the calculus in the presence of redundancy elimination rules,\nand develop a sufficient condition guaranteeing its termination; this\nsufficient condition is then used to prove that all possible explanations can\nbe generated infinite time for several classes of clause sets, including many\nof interest to the SMT community. We propose a procedure that generates a set\nof explanations that should be useful to a human user and conclude by\nsuggesting several extensions to this novel approach."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:2)2012", 
    "link": "http://arxiv.org/pdf/1201.6028v1", 
    "title": "Turing Impossibility Properties for Stack Machine Programming", 
    "arxiv-id": "1201.6028v1", 
    "author": "C. A. Middelburg", 
    "publish": "2012-01-29T11:14:58Z", 
    "summary": "The strong, intermediate, and weak Turing impossibility properties are\nintroduced. Some facts concerning Turing impossibility for stack machine\nprogramming are trivially adapted from previous work. Several intriguing\nquestions are raised about the Turing impossibility properties concerning\ndifferent method interfaces for stack machine programming."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:2)2012", 
    "link": "http://arxiv.org/pdf/1202.3484v2", 
    "title": "Symbolic bisimulation for quantum processes", 
    "arxiv-id": "1202.3484v2", 
    "author": "Mingsheng Ying", 
    "publish": "2012-02-16T01:11:36Z", 
    "summary": "With the previous notions of bisimulation presented in literature, to check\nif two quantum processes are bisimilar, we have to instantiate the free quantum\nvariables of them with arbitrary quantum states, and verify the bisimilarity of\nresultant configurations. This makes checking bisimilarity infeasible from an\nalgorithmic point of view because quantum states constitute a continuum. In\nthis paper, we introduce a symbolic operational semantics for quantum processes\ndirectly at the quantum operation level, which allows us to describe the\nbisimulation between quantum processes without resorting to quantum states. We\nshow that the symbolic bisimulation defined here is equivalent to the open\nbisimulation for quantum processes in the previous work, when strong\nbisimulations are considered. An algorithm for checking symbolic ground\nbisimilarity is presented. We also give a modal logical characterisation for\nquantum bisimilarity based on an extension of Hennessy-Milner logic to quantum\nprocesses."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.77.3", 
    "link": "http://arxiv.org/pdf/1202.3497v1", 
    "title": "Characteristic Formulae for Relations with Nested Fixed Points", 
    "arxiv-id": "1202.3497v1", 
    "author": "Anna Ing\u00f3lfsd\u00f3ttir", 
    "publish": "2012-02-16T02:41:15Z", 
    "summary": "A general framework for the connection between characteristic formulae and\nbehavioral semantics is described in [2]. This approach does not suitably cover\nsemantics defined by nested fixed points, such as the n-nested simulation\nsemantics for n greater than 2. In this study we address this deficiency and\ngive a description of nested fixed points that extends the approach for single\nfixed points in an intuitive and comprehensive way."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.77.4", 
    "link": "http://arxiv.org/pdf/1202.3498v1", 
    "title": "IO vs OI in Higher-Order Recursion Schemes", 
    "arxiv-id": "1202.3498v1", 
    "author": "Axel Haddad", 
    "publish": "2012-02-16T02:41:23Z", 
    "summary": "We propose a study of the modes of derivation of higher-order recursion\nschemes, proving that value trees obtained from schemes using\ninnermost-outermost derivations (IO) are the same as those obtained using\nunrestricted derivations. Given that higher-order recursion schemes can be used\nas a model of functional programs, innermost-outermost derivations policy\nrepresents a theoretical view point of call by value evaluation strategy."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.77.7", 
    "link": "http://arxiv.org/pdf/1202.3501v1", 
    "title": "Cut-elimination for the mu-calculus with one variable", 
    "arxiv-id": "1202.3501v1", 
    "author": "Thomas Studer", 
    "publish": "2012-02-16T02:41:43Z", 
    "summary": "We establish syntactic cut-elimination for the one-variable fragment of the\nmodal mu-calculus. Our method is based on a recent cut-elimination technique by\nMints that makes use of Buchholz' Omega-rule."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.77.7", 
    "link": "http://arxiv.org/pdf/1202.4175v4", 
    "title": "Average Case Analysis of the Classical Algorithm for Markov Decision   Processes with B\u00fcchi Objectives", 
    "arxiv-id": "1202.4175v4", 
    "author": "Nisarg Shah", 
    "publish": "2012-02-19T18:22:02Z", 
    "summary": "We consider Markov decision processes (MDPs) with $\\omega$-regular\nspecifications given as parity objectives. We consider the problem of computing\nthe set of almost-sure winning vertices from where the objective can be ensured\nwith probability 1. The algorithms for the computation of the almost-sure\nwinning set for parity objectives iteratively use the solutions for the\nalmost-sure winning set for B\\\"uchi objectives (a special case of parity\nobjectives). We study for the first time the average case complexity of the\nclassical algorithm for computing almost-sure winning vertices for MDPs with\nB\\\"uchi objectives. Our contributions are as follows: First, we show that for\nMDPs with constant out-degree the expected number of iterations is at most\nlogarithmic and the average case running time is linear (as compared to the\nworst case linear number of iterations and quadratic time complexity). Second,\nwe show that for general MDPs the expected number of iterations is constant and\nthe average case running time is linear (again as compared to the worst case\nlinear number of iterations and quadratic time complexity). Finally we also\nshow that given all graphs are equally likely, the probability that the\nclassical algorithm requires more than constant number of iterations is\nexponentially small."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.77.7", 
    "link": "http://arxiv.org/pdf/1202.4193v4", 
    "title": "Exponential Lower Bounds and Separation for Query Rewriting", 
    "arxiv-id": "1202.4193v4", 
    "author": "Michael Zakharyaschev", 
    "publish": "2012-02-19T22:28:54Z", 
    "summary": "We establish connections between the size of circuits and formulas computing\nmonotone Boolean functions and the size of first-order and nonrecursive Datalog\nrewritings for conjunctive queries over OWL 2 QL ontologies. We use known lower\nbounds and separation results from circuit complexity to prove similar results\nfor the size of rewritings that do not use non-signature constants. For\nexample, we show that, in the worst case, positive existential and nonrecursive\nDatalog rewritings are exponentially longer than the original queries;\nnonrecursive Datalog rewritings are in general exponentially more succinct than\npositive existential rewritings; while first-order rewritings can be\nsuperpolynomially more succinct than positive existential rewritings."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.77.7", 
    "link": "http://arxiv.org/pdf/1202.4678v2", 
    "title": "A Categorical Model for the Lambda Calculus with Constructors", 
    "arxiv-id": "1202.4678v2", 
    "author": "Barbara Petit", 
    "publish": "2012-02-21T15:48:06Z", 
    "summary": "The lambda calculus with constructors is an extension of the lambda calculus\nwith variadic constructors. It decomposes the pattern-matching a la ML into a\ncase analysis on constants and a commutation rule between case and application\nconstructs. Although this commutation rule does not match with the usual\ncomputing intuitions, it makes the calculus expressive and confluent, with a\nrather simple syntax. In this paper we define a sound notion of categorical\nmodel for the lambda calculus with constructors. We then prove that this\ndefinition is complete for the fragment of the calculus with no match-failure,\nusing the model of partial equivalence relations."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.77.7", 
    "link": "http://arxiv.org/pdf/1202.4824v1", 
    "title": "A General Form of Attribute Exploration", 
    "arxiv-id": "1202.4824v1", 
    "author": "Daniel Borchmann", 
    "publish": "2012-02-22T06:05:06Z", 
    "summary": "We present a general form of attribute exploration, a knowledge completion\nalgorithm from Formal Concept Analysis. The aim of our presentation is not only\nto extend the applicability of attribute exploration by a general description.\nIt may also allow to view different existing variants of attribute exploration\nas instances of a general form, which may simplify theoretical considerations."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.77.7", 
    "link": "http://arxiv.org/pdf/1202.5850v1", 
    "title": "The Cost of Parameterized Reachability in Mobile Ad Hoc Networks", 
    "arxiv-id": "1202.5850v1", 
    "author": "Gianluigi Zavattaro", 
    "publish": "2012-02-27T08:28:11Z", 
    "summary": "We investigate the impact of spontaneous movement in the complexity of\nverification problems for an automata-based protocol model of networks with\nselective broadcast communication. We first consider reachability of an error\nstate and show that parameterized verification is decidable with polynomial\ncomplexity. We then move to richer queries and show how the complexity changes\nwhen considering properties with negation or cardinality constraints."
},{
    "category": "cs.LO", 
    "doi": "10.1007/s13218-010-0002-x", 
    "link": "http://arxiv.org/pdf/1202.6148v1", 
    "title": "Instance Based Methods --- A Brief Overview", 
    "arxiv-id": "1202.6148v1", 
    "author": "Evgenij Thorstensen", 
    "publish": "2012-02-28T08:36:27Z", 
    "summary": "Instance-based methods are a specific class of methods for automated proof\nsearch in first-order logic. This article provides an overview of the major\nmethods in the area and discusses their properties and relations to the more\nestablished resolution methods. It also discusses some recent trends on\nrefinements and applications.\n  This overview is rather brief and informal, but we provide a comprehensive\nliterature list to follow-up on the details."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:20)2012", 
    "link": "http://arxiv.org/pdf/1202.6352v2", 
    "title": "Theorem proving for prenex G\u00f6del logic with Delta: checking validity   and unsatisfiability", 
    "arxiv-id": "1202.6352v2", 
    "author": "Christian G Ferm\u00fcller", 
    "publish": "2012-02-28T20:38:20Z", 
    "summary": "G\\\"odel logic with the projection operator Delta (G_Delta) is an important\nmany-valued as well as intermediate logic. In contrast to classical logic, the\nvalidity and the satisfiability problems of G_Delta are not directly dual to\neach other. We nevertheless provide a uniform, computational treatment of both\nproblems for prenex formulas by describing appropriate translations into sets\nof order clauses that can be subjected to chaining resolution. For validity a\nversion of Herbrand's Theorem allows us to show the soundness of standard\nSkolemization. For satisfiability the translation involves a novel, extended\nSkolemization method."
},{
    "category": "cs.LO", 
    "doi": "10.1017/S0960129511000120", 
    "link": "http://arxiv.org/pdf/1202.6473v1", 
    "title": "CoLoR: a Coq library on well-founded rewrite relations and its   application to the automated verification of termination certificates", 
    "arxiv-id": "1202.6473v1", 
    "author": "Adam Koprowski", 
    "publish": "2012-02-29T07:52:05Z", 
    "summary": "Termination is an important property of programs; notably required for\nprograms formulated in proof assistants. It is a very active subject of\nresearch in the Turing-complete formalism of term rewriting systems, where many\nmethods and tools have been developed over the years to address this problem.\nEnsuring reliability of those tools is therefore an important issue. In this\npaper we present a library formalizing important results of the theory of\nwell-founded (rewrite) relations in the proof assistant Coq. We also present\nits application to the automated verification of termination certificates, as\nproduced by termination tools."
},{
    "category": "cs.LO", 
    "doi": "10.1017/S0960129511000120", 
    "link": "http://arxiv.org/pdf/1203.0587v1", 
    "title": "Expressing Preferences using Preference Set Constraint Atoms", 
    "arxiv-id": "1203.0587v1", 
    "author": "Jeffrey B. Remmel", 
    "publish": "2012-03-02T23:25:07Z", 
    "summary": "This paper introduces an extension of Answer Set Programming called\nPreference Set Constraint Programming which is a convenient and general\nformalism to reason with preferences. PSC programming extends Set Constraint\nProgramming introduced by Marek and Remmel (Marek and Remmel 2004) by\nintroducing two types of preference set constraint atoms, measure preference\nset constraint atoms and pre-ordered preference set constraint atoms, which are\nextensions of set constraint atoms. We show that the question of whether a PSC\nprogram has a preferred stable model is CoNP-complete. We give examples of the\nuses of the preference set constraint atoms and show that Answer Set\nOptimization (Brewka, Niemel\\\"a, and Truszczynski 2003) and General Preference\n(Son and Pontelli 2006) can be expressed using preference set constraint atoms."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:28)2012", 
    "link": "http://arxiv.org/pdf/1203.0670v2", 
    "title": "Preservation of Strong Normalisation modulo permutations for the   structural lambda-calculus", 
    "arxiv-id": "1203.0670v2", 
    "author": "Delia Kesner", 
    "publish": "2012-03-03T17:47:21Z", 
    "summary": "Inspired by a recent graphical formalism for lambda-calculus based on linear\nlogic technology, we introduce an untyped structural lambda-calculus, called\nlambda j, which combines actions at a distance with exponential rules\ndecomposing the substitution by means of weakening, contraction and\nderelicition. First, we prove some fundamental properties of lambda j such as\nconfluence and preservation of beta-strong normalisation. Second, we add a\nstrong bisimulation to lambda j by means of an equational theory which captures\nin particular Regnier's sigma-equivalence. We then complete this bisimulation\nwith two more equations for (de)composition of substitutions and we prove that\nthe resulting calculus still preserves beta-strong normalization. Finally, we\ndiscuss some consequences of our results."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:28)2012", 
    "link": "http://arxiv.org/pdf/1203.2241v2", 
    "title": "Model-Checking of Linear-Time Properties Based on Possibility Measure", 
    "arxiv-id": "1203.2241v2", 
    "author": "Lijun Li", 
    "publish": "2012-03-10T08:26:34Z", 
    "summary": "We study the LTL model-checking in possibilistic Kripke structure using\npossibility measure. First, the notion of possibilistic Kripke structure and\nthe related possibility measure are introduced, then model-checking of\nreachability and repeated reachability linear-time properties in finite\npossibilistic Kripke structure are studied. Standard safety property and\n-regular property in possibilistic Kripke structure are introduced, the\nverification of regular safety property and -regular property using finite\nautomata are thoroughly studied. It has been shown that the verification of\nregular safety property and -regular property in finite possibilistic Kripke\nstructure can be transformed into the verification of reachability property and\nrepeated reachability property in the product possibilistic Kripke structure\nintroduced in this paper. Several examples are given to illustrate the methods\npresented in the paper."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:28)2012", 
    "link": "http://arxiv.org/pdf/1203.2809v1", 
    "title": "Automated Synthesis of a Finite Complexity Ordering for Saturation", 
    "arxiv-id": "1203.2809v1", 
    "author": "Mounira Kourjieh", 
    "publish": "2012-03-11T19:36:46Z", 
    "summary": "We present in this paper a new procedure to saturate a set of clauses with\nrespect to a well-founded ordering on ground atoms such that A < B implies\nVar(A) {\\subseteq} Var(B) for every atoms A and B. This condition is satisfied\nby any atom ordering compatible with a lexicographic, recursive, or multiset\npath ordering on terms. Our saturation procedure is based on a priori ordered\nresolution and its main novelty is the on-the-fly construction of a finite\ncomplexity atom ordering. In contrast with the usual redundancy, we give a new\nredundancy notion and we prove that during the saturation a non-redundant\ninference by a priori ordered resolution is also an inference by a posteriori\nordered resolution. We also prove that if a set S of clauses is saturated with\nrespect to an atom ordering as described above then the problem of whether a\nclause C is entailed from S is decidable."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:27)2012", 
    "link": "http://arxiv.org/pdf/1203.3167v2", 
    "title": "On the Parameterized Intractability of Monadic Second-Order Logic", 
    "arxiv-id": "1203.3167v2", 
    "author": "Stephan Kreutzer", 
    "publish": "2012-03-14T18:23:05Z", 
    "summary": "One of Courcelle's celebrated results states that if C is a class of graphs\nof bounded tree-width, then model-checking for monadic second order logic\n(MSO_2) is fixed-parameter tractable (fpt) on C by linear time parameterized\nalgorithms, where the parameter is the tree-width plus the size of the formula.\nAn immediate question is whether this is best possible or whether the result\ncan be extended to classes of unbounded tree-width. In this paper we show that\nin terms of tree-width, the theorem cannot be extended much further. More\nspecifically, we show that if C is a class of graphs which is closed under\ncolourings and satisfies certain constructibility conditions and is such that\nthe tree-width of C is not bounded by \\log^{84} n then MSO_2-model checking is\nnot fpt unless SAT can be solved in sub-exponential time. If the tree-width of\nC is not poly-logarithmically bounded, then MSO_2-model checking is not fpt\nunless all problems in the polynomial-time hierarchy can be solved in\nsub-exponential time."
},{
    "category": "cs.LO", 
    "doi": "10.3217/jucs-019-06-0729", 
    "link": "http://arxiv.org/pdf/1203.3568v1", 
    "title": "Investigations on a Pedagogical Calculus of Constructions", 
    "arxiv-id": "1203.3568v1", 
    "author": "Vincent Demange", 
    "publish": "2012-03-15T21:16:55Z", 
    "summary": "In the last few years appeared pedagogical propositional natural deduction\nsystems. In these systems, one must satisfy the pedagogical constraint: the\nuser must give an example of any introduced notion. First we expose the reasons\nof such a constraint and properties of these \"pedagogical\" calculi: the absence\nof negation at logical side, and the \"usefulness\" feature of terms at\ncomputational side (through the Curry-Howard correspondence). Then we construct\na simple pedagogical restriction of the calculus of constructions (CC) called\nCCr. We establish logical limitations of this system, and compare its\ncomputational expressiveness to Godel system T. Finally, guided by the logical\nlimitations of CCr, we propose a formal and general definition of what a\npedagogical calculus of constructions should be."
},{
    "category": "cs.LO", 
    "doi": "10.3217/jucs-019-06-0729", 
    "link": "http://arxiv.org/pdf/1203.3706v2", 
    "title": "On the Complexity of Computing Minimal Unsatisfiable LTL formulas", 
    "arxiv-id": "1203.3706v2", 
    "author": "Mohand-Sa\u00efd Hacid", 
    "publish": "2012-03-16T13:53:33Z", 
    "summary": "We show that (1) the Minimal False QCNF search-problem (MF-search) and the\nMinimal Unsatisfiable LTL formula search problem (MU-search) are FPSPACE\ncomplete because of the very expressive power of QBF/LTL, (2) we extend the\nPSPACE-hardness of the MF decision problem to the MU decision problem. As a\nconsequence, we deduce a positive answer to the open question of PSPACE\nhardness of the inherent Vacuity Checking problem. We even show that the\nInherent Non Vacuous formula search problem is also FPSPACE-complete."
},{
    "category": "cs.LO", 
    "doi": "10.3217/jucs-019-06-0729", 
    "link": "http://arxiv.org/pdf/1203.3730v2", 
    "title": "From Strong Amalgamability to Modularity of Quantifier-Free   Interpolation", 
    "arxiv-id": "1203.3730v2", 
    "author": "Silvio Ranise", 
    "publish": "2012-03-16T15:10:52Z", 
    "summary": "The use of interpolants in verification is gaining more and more importance.\nSince theories used in applications are usually obtained as (disjoint)\ncombinations of simpler theories, it is important to modularly re-use\ninterpolation algorithms for the component theories. We show that a sufficient\nand necessary condition to do this for quantifier-free interpolation is that\nthe component theories have the 'strong (sub-)amalgamation' property. Then, we\nprovide an equivalent syntactic characterization, identify a sufficient\ncondition, and design a combined quantifier-free interpolation algorithm\ncapable of handling both convex and non-convex theories, that subsumes and\nextends most existing work on combined interpolation."
},{
    "category": "cs.LO", 
    "doi": "10.3217/jucs-019-06-0729", 
    "link": "http://arxiv.org/pdf/1203.3814v2", 
    "title": "Tree-width for first order formulae", 
    "arxiv-id": "1203.3814v2", 
    "author": "Mark Weyer", 
    "publish": "2012-03-16T20:33:28Z", 
    "summary": "We introduce tree-width for first order formulae \\phi, fotw(\\phi). We show\nthat computing fotw is fixed-parameter tractable with parameter fotw. Moreover,\nwe show that on classes of formulae of bounded fotw, model checking is fixed\nparameter tractable, with parameter the length of the formula. This is done by\ntranslating a formula \\phi\\ with fotw(\\phi)<k into a formula of the k-variable\nfragment L^k of first order logic. For fixed k, the question whether a given\nfirst order formula is equivalent to an L^k formula is undecidable. In\ncontrast, the classes of first order formulae with bounded fotw are fragments\nof first order logic for which the equivalence is decidable.\n  Our notion of tree-width generalises tree-width of conjunctive queries to\narbitrary formulae of first order logic by taking into account the quantifier\ninteraction in a formula. Moreover, it is more powerful than the notion of\nelimination-width of quantified constraint formulae, defined by Chen and Dalmau\n(CSL 2005): for quantified constraint formulae, both bounded elimination-width\nand bounded fotw allow for model checking in polynomial time. We prove that\nfotw of a quantified constraint formula \\phi\\ is bounded by the\nelimination-width of \\phi, and we exhibit a class of quantified constraint\nformulae with bounded fotw, that has unbounded elimination-width. A similar\ncomparison holds for strict tree-width of non-recursive stratified datalog as\ndefined by Flum, Frick, and Grohe (JACM 49, 2002).\n  Finally, we show that fotw has a characterization in terms of a cops and\nrobbers game without monotonicity cost."
},{
    "category": "cs.LO", 
    "doi": "10.3217/jucs-019-06-0729", 
    "link": "http://arxiv.org/pdf/1203.4912v1", 
    "title": "A survey of proof nets and matrices for substructural logics", 
    "arxiv-id": "1203.4912v1", 
    "author": "Sean A. Fulop", 
    "publish": "2012-03-22T08:40:29Z", 
    "summary": "This paper is a survey of two kinds of \"compressed\" proof schemes, the\n\\emph{matrix method} and \\emph{proof nets}, as applied to a variety of logics\nranging along the substructural hierarchy from classical all the way down to\nthe nonassociative Lambek system. A novel treatment of proof nets for the\nlatter is provided. Descriptions of proof nets and matrices are given in a\nuniform notation based on sequents, so that the properties of the schemes for\nthe various logics can be easily compared."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:31)2012", 
    "link": "http://arxiv.org/pdf/1203.5121v2", 
    "title": "A Reduction-Preserving Completion for Proving Confluence of   Non-Terminating Term Rewriting Systems", 
    "arxiv-id": "1203.5121v2", 
    "author": "Yoshihito Toyama", 
    "publish": "2012-03-22T20:41:24Z", 
    "summary": "We give a method to prove confluence of term rewriting systems that contain\nnon-terminating rewrite rules such as commutativity and associativity. Usually,\nconfluence of term rewriting systems containing such rules is proved by\ntreating them as equational term rewriting systems and considering E-critical\npairs and/or termination modulo E. In contrast, our method is based solely on\nusual critical pairs and it also (partially) works even if the system is not\nterminating modulo E. We first present confluence criteria for term rewriting\nsystems whose rewrite rules can be partitioned into a terminating part and a\npossibly non-terminating part. We then give a reduction-preserving completion\nprocedure so that the applicability of the criteria is enhanced. In contrast to\nthe well-known Knuth-Bendix completion procedure which preserves the\nequivalence relation of the system, our completion procedure preserves the\nreduction relation of the system, by which confluence of the original system is\ninferred from that of the completed system."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:31)2012", 
    "link": "http://arxiv.org/pdf/1203.5754v1", 
    "title": "Polynomial Interpretations for Higher-Order Rewriting", 
    "arxiv-id": "1203.5754v1", 
    "author": "Cynthia Kop", 
    "publish": "2012-03-26T18:30:28Z", 
    "summary": "The termination method of weakly monotonic algebras, which has been defined\nfor higher-order rewriting in the HRS formalism, offers a lot of power, but has\nseen little use in recent years. We adapt and extend this method to the\nalternative formalism of algebraic functional systems, where the simply-typed\nlambda-calculus is combined with algebraic reduction. Using this theory, we\ndefine higher-order polynomial interpretations, and show how the implementation\nchallenges of this technique can be tackled. A full implementation is provided\nin the termination tool WANDA."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.81.1", 
    "link": "http://arxiv.org/pdf/1203.6157v1", 
    "title": "A Logical Framework for Set Theories", 
    "arxiv-id": "1203.6157v1", 
    "author": "Arnon Avron", 
    "publish": "2012-03-28T05:05:59Z", 
    "summary": "Axiomatic set theory is almost universally accepted as the basic theory which\nprovides the foundations of mathematics, and in which the whole of present day\nmathematics can be developed. As such, it is the most natural framework for\nMathematical Knowledge Management. However, in order to be used for this task\nit is necessary to overcome serious gaps that exist between the \"official\"\nformulations of set theory (as given e.g. by formal set theory ZF) and actual\nmathematical practice.\n  In this work we present a new unified framework for formalizations of\naxiomatic set theories of different strength, from rudimentary set theory to\nfull ZF. It allows the use of set terms, but provides a static check of their\nvalidity."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.81.4", 
    "link": "http://arxiv.org/pdf/1203.6159v1", 
    "title": "On Graph Refutation for Relational Inclusions", 
    "arxiv-id": "1203.6159v1", 
    "author": "Sheila R. M. Veloso", 
    "publish": "2012-03-28T05:06:25Z", 
    "summary": "We introduce a graphical refutation calculus for relational inclusions: it\nreduces establishing a relational inclusion to establishing that a graph\nconstructed from it has empty extension. This sound and complete calculus is\nconceptually simpler and easier to use than the usual ones."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.81.5", 
    "link": "http://arxiv.org/pdf/1203.6160v1", 
    "title": "A Formalization of the Theorem of Existence of First-Order Most General   Unifiers", 
    "arxiv-id": "1203.6160v1", 
    "author": "Mauricio Ayala-Rinc\u00f3n", 
    "publish": "2012-03-28T05:06:30Z", 
    "summary": "This work presents a formalization of the theorem of existence of most\ngeneral unifiers in first-order signatures in the higher-order proof assistant\nPVS. The distinguishing feature of this formalization is that it remains close\nto the textbook proofs that are based on proving the correctness of the\nwell-known Robinson's first-order unification algorithm. The formalization was\napplied inside a PVS development for term rewriting systems that provides a\ncomplete formalization of the Knuth-Bendix Critical Pair theorem, among other\nrelevant theorems of the theory of rewriting. In addition, the formalization\nmethodology has been proved of practical use in order to verify the correctness\nof unification algorithms in the style of the original Robinson's unification\nalgorithm."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.81.5", 
    "link": "http://arxiv.org/pdf/1203.6278v1", 
    "title": "Fuzzy Time in LTL", 
    "arxiv-id": "1203.6278v1", 
    "author": "Paola Spoletini", 
    "publish": "2012-03-28T14:20:19Z", 
    "summary": "In the last years, the adoption of active systems has increased in many\nfields of computer science, such as databases, sensor networks, and software\nengineering. These systems are able to automatically react to events, by\ncollecting information from outside and internally generating new events.\nHowever, the collection of data is often hampered by uncertainty and vagueness\nthat can arise from the imprecision of the monitoring infrastructure,\nunreliable data sources, and networks. The decision making mechanism used to\nproduce a reaction is also imprecise, and cannot be evaluated in a crisp way.\nIt depends on the evaluation of vague temporal constraints, which are expressed\non the collected data by humans. Despite fuzzy logic has been mainly conceived\nas a mathematical abstraction to express vagueness, no attempt has been made to\nfuzzify the temporal modalities. Existing fuzzy languages do not allow us to\nrepresent temporal properties, such as \"almost always\" and \"soon\". Indeed, the\nsemantics of existing fuzzy temporal operators is based on the idea of\nreplacing classical connectives or propositions with their fuzzy counterparts.\nTo overcome these limitations, we propose a temporal framework, FTL (Fuzzy-time\nTemporal Logic), to express vagueness on time. This framework formally defines\na set of fuzzy temporal modalities, which can be customized by choosing a\nspecific semantics for the connectives. The semantics of the language is sound,\nand the introduced modalities respect a set of expected mutual relations. We\nalso prove that under the assumption that all events are crisp, FTL reduces to\nLTL. Finally, for some of the possible fuzzy interpretations of the\nconnectives, we identify adequate sets of temporal operators, from which it is\npossible to derive all the others."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(2:2)2012", 
    "link": "http://arxiv.org/pdf/1203.6412v2", 
    "title": "Barriers in Concurrent Separation Logic: Now With Tool Support!", 
    "arxiv-id": "1203.6412v2", 
    "author": "Cristian Gherghina", 
    "publish": "2012-03-29T01:58:29Z", 
    "summary": "We develop and prove sound a concurrent separation logic for Pthreads-style\nbarriers. Although Pthreads barriers are widely used in systems, and separation\nlogic is widely used for verification, there has not been any effort to combine\nthe two. Unlike locks and critical sections, Pthreads barriers enable\nsimultaneous resource redistribution between multiple threads and are\ninherently stateful, leading to significant complications in the design of the\nlogic and its soundness proof. We show how our logic can be applied to a\nspecific example program in a modular way. Our proofs are machine-checked in\nCoq. We showcase a program verification toolset that automatically applies the\nlogic rules and discharges the associated proof obligations."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(2:7)2012", 
    "link": "http://arxiv.org/pdf/1205.0126v2", 
    "title": "On the equivalence of game and denotational semantics for the   probabilistic mu-calculus", 
    "arxiv-id": "1205.0126v2", 
    "author": "Matteo Mio", 
    "publish": "2012-05-01T10:34:40Z", 
    "summary": "The probabilistic (or quantitative) modal mu-calculus is a fixed-point logic\nde- signed for expressing properties of probabilistic labeled transition\nsystems (PLTS). Two semantics have been studied for this logic, both assigning\nto every process state a value in the interval [0,1] representing the\nprobability that the property expressed by the formula holds at the state. One\nsemantics is denotational and the other is a game semantics, specified in terms\nof two-player stochastic games. The two semantics have been proved to coincide\non all finite PLTS's, but the equivalence of the two semantics on arbitrary\nmodels has been open in literature. In this paper we prove that the equivalence\nindeed holds for arbitrary infinite models, and thus our result strengthens the\nfruitful connection between denotational and game semantics. Our proof adapts\nthe unraveling or unfolding method, a general proof technique for proving\nresult of parity games by induction on their complexity."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(2:7)2012", 
    "link": "http://arxiv.org/pdf/1205.0913v2", 
    "title": "Pebble games with algebraic rules", 
    "arxiv-id": "1205.0913v2", 
    "author": "Bjarki Holm", 
    "publish": "2012-05-04T10:48:06Z", 
    "summary": "We define a general framework of partition games for formulating two-player\npebble games over finite structures. We show that one particular such game,\nwhich we call the invertible-map game, yields a family of polynomial-time\napproximations of graph isomorphism that is strictly stronger than the\nwell-known Weisfeiler-Lehman method. The general framework we introduce\nincludes as special cases the pebble games for finite-variable logics with and\nwithout counting. It also includes a matrix-equivalence game, introduced here,\nwhich characterises equivalence in the finite-variable fragments of matrix-rank\nlogic. We show that the equivalence defined by the invertible-map game is a\nrefinement of the equivalence defined by each of these games for\nfinite-variable logics."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(2:7)2012", 
    "link": "http://arxiv.org/pdf/1205.0946v2", 
    "title": "Constraint LTL Satisfiability Checking without Automata", 
    "arxiv-id": "1205.0946v2", 
    "author": "Pierluigi San Pietro", 
    "publish": "2012-05-04T12:57:00Z", 
    "summary": "This paper introduces a novel technique to decide the satisfiability of\nformulae written in the language of Linear Temporal Logic with Both future and\npast operators and atomic formulae belonging to constraint system D (CLTLB(D)\nfor short). The technique is based on the concept of bounded satisfiability,\nand hinges on an encoding of CLTLB(D) formulae into QF-EUD, the theory of\nquantifier-free equality and uninterpreted functions combined with D. Similarly\nto standard LTL, where bounded model-checking and SAT-solvers can be used as an\nalternative to automata-theoretic approaches to model-checking, our approach\nallows users to solve the satisfiability problem for CLTLB(D) formulae through\nSMT-solving techniques, rather than by checking the emptiness of the language\nof a suitable automaton A_{\\phi}. The technique is effective, and it has been\nimplemented in our Zot formal verification tool."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(2:7)2012", 
    "link": "http://arxiv.org/pdf/1205.2117v3", 
    "title": "Unique Parallel Decomposition in Branching and Weak Bisimulation   Semantics", 
    "arxiv-id": "1205.2117v3", 
    "author": "Bas Luttik", 
    "publish": "2012-05-09T22:42:02Z", 
    "summary": "We consider the property of unique parallel decomposition modulo branching\nand weak bisimilarity. First, we show that infinite behaviours may fail to have\nparallel decompositions at all. Then, we prove that totally normed behaviours\nalways have parallel decompositions, but that these are not necessarily unique.\nFinally, we establish that weakly bounded behaviours have unique parallel\ndecompositions. We derive the latter result from a general theorem about unique\ndecompositions in partial commutative monoids."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(2:10)2012", 
    "link": "http://arxiv.org/pdf/1205.2519v2", 
    "title": "Dynamic Dependency Pairs for Algebraic Functional Systems", 
    "arxiv-id": "1205.2519v2", 
    "author": "Femke van Raamsdonk", 
    "publish": "2012-05-11T13:35:00Z", 
    "summary": "We extend the higher-order termination method of dynamic dependency pairs to\nAlgebraic Functional Systems (AFSs). In this setting, simply typed lambda-terms\nwith algebraic reduction and separate {\\beta}-steps are considered. For\nleft-linear AFSs, the method is shown to be complete. For so-called local AFSs\nwe define a variation of usable rules and an extension of argument filterings.\nAll these techniques have been implemented in the higher-order termination tool\nWANDA."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(2:13)2012", 
    "link": "http://arxiv.org/pdf/1205.3612v2", 
    "title": "Untyping Typed Algebras and Colouring Cyclic Linear Logic", 
    "arxiv-id": "1205.3612v2", 
    "author": "Damien Pous", 
    "publish": "2012-05-16T09:38:31Z", 
    "summary": "We prove \"untyping\" theorems: in some typed theories (semirings, Kleene\nalgebras, residuated lattices, involutive residuated lattices), typed equations\ncan be derived from the underlying untyped equations. As a consequence, the\ncorresponding untyped decision procedures can be extended for free to the typed\nsettings. Some of these theorems are obtained via a detour through fragments of\ncyclic linear logic, and give rise to a substantial optimisation of standard\nproof search algorithms."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(2:13)2012", 
    "link": "http://arxiv.org/pdf/1205.3803v2", 
    "title": "Necessity as justified truth", 
    "arxiv-id": "1205.3803v2", 
    "author": "Steffen Lewitzka", 
    "publish": "2012-05-16T20:37:34Z", 
    "summary": "We present a logic for the reasoning about necessity and justifications which\nis independent from relational semantics. We choose the concept of\njustification -- coming from a class of \"Justification Logics\" (Artemov 2008,\nFitting 2009) -- as the primitive notion on which the concept of necessity is\nbased. Our axiomatization extends Suszko's non-Fregean logic SCI (Brown, Suszko\n1972) by basic axioms from Justification Logic, axioms for quantification over\npropositions and over justifications, and some further principles. The core\naxiom is: $\\varphi$ is necessarily true iff there is a justification for\n$\\varphi$. That is, necessity is first-order definable by means of\njustifications. Instead of defining purely algebraic models in the style of\n(Brown, Suszko 1972) we extend the semantics investigated in (Lewitzka 2012) by\nsome algebraic structure for dealing with justifications and prove soundness\nand completeness of our deductive system. Moreover, we are able to restore the\nmodal logic principle of Necessitation if we add the axiom schema\n$\\square\\varphi \\to \\square\\square\\varphi$ and a rule of Axiom Necessitation to\nour system. As a main result, we show that the modal logics S4 and S5 can be\ncaptured by our semantics if we impose the corresponding modal logic principles\nas additional semantic constraints. This will follow from proof-theoretic\nconsiderations and from our completeness theorems. For the system S4 we present\nalso a purely model-theoretic proof."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(2:13)2012", 
    "link": "http://arxiv.org/pdf/1205.4802v1", 
    "title": "An effective characterization of the alternation hierarchy in   two-variable logic", 
    "arxiv-id": "1205.4802v1", 
    "author": "Howard Straubing", 
    "publish": "2012-05-22T05:16:30Z", 
    "summary": "We characterize the languages in the individual levels of the quantifier\nalternation hierarchy of first-order logic with two variables by identities.\nThis implies decidability of the individual levels. More generally we show that\nthe two-sided semidirect product of a decidable variety with the variety J is\ndecidable."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(2:13)2012", 
    "link": "http://arxiv.org/pdf/1205.5571v1", 
    "title": "Applications of Quantified Constraint Solving over the Reals -   Bibliography", 
    "arxiv-id": "1205.5571v1", 
    "author": "Stefan Ratschan", 
    "publish": "2012-05-23T09:52:40Z", 
    "summary": "Quantified constraints over the reals appear in numerous contexts. Usually\nexistential quantification occurs when some parameter can be chosen by the user\nof a system, and univeral quantification when the exact value of a parameter is\neither unknown, or when it occurs in infinitely many, similar versions. The\nfollowing is a list of application areas and publications that contain\napplications for solving quantified constraints over the reals. The list is\ncertainly not complete, but grows as the author encounters new items.\nContributions are very welcome!"
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(2:13)2012", 
    "link": "http://arxiv.org/pdf/1205.5838v4", 
    "title": "ExpTime Tableaux for the Description Logic SHIQ Based on Global State   Caching and Integer Linear Feasibility Checking", 
    "arxiv-id": "1205.5838v4", 
    "author": "Linh Anh Nguyen", 
    "publish": "2012-05-25T23:58:40Z", 
    "summary": "We give the first ExpTime (complexity-optimal) tableau decision procedure for\nchecking satisfiability of a knowledge base in the description logic SHIQ when\nnumbers are coded in unary. Our procedure is based on global state caching and\ninteger linear feasibility checking."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(2:13)2012", 
    "link": "http://arxiv.org/pdf/1205.6584v2", 
    "title": "Taming Past LTL and Flat Counter Systems", 
    "arxiv-id": "1205.6584v2", 
    "author": "Arnaud sangnier", 
    "publish": "2012-05-30T08:45:34Z", 
    "summary": "Reachability and LTL model-checking problems for flat counter systems are\nknown to be decidable but whereas the reachability problem can be shown in NP,\nthe best known complexity upper bound for the latter problem is made of a tower\nof several exponentials. Herein, we show that the problem is only NP-complete\neven if LTL admits past-time operators and arithmetical constraints on\ncounters. Actually, the NP upper bound is shown by adequately combining a new\nstuttering theorem for Past LTL and the property of small integer solutions for\nquantifier-free Presburger formulae. Other complexity results are proved, for\ninstance for restricted classes of flat counter systems."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(2:14)2012", 
    "link": "http://arxiv.org/pdf/1206.0136v2", 
    "title": "General Bindings and Alpha-Equivalence in Nominal Isabelle", 
    "arxiv-id": "1206.0136v2", 
    "author": "Cezary Kaliszyk", 
    "publish": "2012-06-01T10:00:31Z", 
    "summary": "Nominal Isabelle is a definitional extension of the Isabelle/HOL theorem\nprover. It provides a proving infrastructure for reasoning about programming\nlanguage calculi involving named bound variables (as opposed to de-Bruijn\nindices). In this paper we present an extension of Nominal Isabelle for dealing\nwith general bindings, that means term constructors where multiple variables\nare bound at once. Such general bindings are ubiquitous in programming language\nresearch and only very poorly supported with single binders, such as\nlambda-abstractions. Our extension includes new definitions of\nalpha-equivalence and establishes automatically the reasoning infrastructure\nfor alpha-equated terms. We also prove strong induction principles that have\nthe usual variable convention already built in."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(2:14)2012", 
    "link": "http://arxiv.org/pdf/1206.0232v1", 
    "title": "Non-Termination Sets of Simple Linear Loops", 
    "arxiv-id": "1206.0232v1", 
    "author": "Bican Xia", 
    "publish": "2012-05-31T11:28:23Z", 
    "summary": "A simple linear loop is a simple while loop with linear assignments and\nlinear loop guards. If a simple linear loop has only two program variables, we\ngive a complete algorithm for computing the set of all the inputs on which the\nloop does not terminate. For the case of more program variables, we show that\nthe non-termination set cannot be described by Tarski formulae in general"
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(2:14)2012", 
    "link": "http://arxiv.org/pdf/1206.0911v1", 
    "title": "Non-null Infinitesimal Micro-steps: a Metric Temporal Logic Approach", 
    "arxiv-id": "1206.0911v1", 
    "author": "Matteo Rossi", 
    "publish": "2012-06-05T12:48:13Z", 
    "summary": "Many systems include components interacting with each other that evolve with\npossibly very different speeds. To deal with this situation many formal models\nadopt the abstraction of \"zero-time transitions\", which do not consume time.\nThese however have several drawbacks in terms of naturalness and logic\nconsistency, as a system is modeled to be in different states at the same time.\nWe propose a novel approach that exploits concepts from non-standard analysis\nto introduce a notion of micro- and macro-steps in an extension of the TRIO\nmetric temporal logic, called X-TRIO. We use X-TRIO to provide a formal\nsemantics and an automated verification technique to Stateflow-like notations\nused in the design of flexible manufacturing systems."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(2:14)2012", 
    "link": "http://arxiv.org/pdf/1206.1936v1", 
    "title": "Completeness for Two Left-Sequential Logics", 
    "arxiv-id": "1206.1936v1", 
    "author": "D. J. C. Staudt", 
    "publish": "2012-06-09T12:58:28Z", 
    "summary": "Left-sequential logics provide a means for reasoning about (closed)\npropositional terms with atomic propositions that may have side effects and\nthat are evaluated sequentially from left to right. Such propositional terms\nare commonly used in programming languages to direct the flow of a program. In\nthis thesis we explore two such left-sequential logics. First we discuss Fully\nEvaluated Left-Sequential Logic, which employs a full evaluation strategy,\ni.e., to evaluate a term every one of its atomic propositions is evaluated\ncausing its possible side effects to occur. We then turn to Short-Circuit\n(Left-Sequential) Logic as presented in [BP10b], where the evaluation may be\n'short-circuited', thus preventing some, if not all, of the atomic propositions\nin a term being evaluated. We propose evaluation trees as a natural semantics\nfor both logics and provide axiomatizations for the least identifying variant\nof each. From this, we define a logic with connectives that prescribe a full\nevaluation strategy as well as connectives that prescribe a short-circuit\nevaluation strategy."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(2:14)2012", 
    "link": "http://arxiv.org/pdf/1206.2037v5", 
    "title": "Programming in logic without Prolog", 
    "arxiv-id": "1206.2037v5", 
    "author": "M. H. van Emden", 
    "publish": "2012-06-10T15:54:39Z", 
    "summary": "Logic can be made useful for programming and for databases independently of\nlogic programming. To be useful in this way, logic has to provide a mechanism\nfor the definition of new functions and new relations on the basis of those\ngiven in the interpretation of a logical theory. We provide this mechanism by\ncreating a compositional semantics on top of the classical semantics. In this\napproach verification of computational results relies on a correspondence\nbetween logic interpretations and a class definition in languages like Java or\nC++. The advantage of this approach is the combination of an expressive medium\nfor the programmer with, in the case of C++, optimal use of computer resources."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(2:14)2012", 
    "link": "http://arxiv.org/pdf/1206.3136v1", 
    "title": "The Glory of the Past and Geometrical Concurrency", 
    "arxiv-id": "1206.3136v1", 
    "author": "Cristian Prisacariu", 
    "publish": "2012-06-14T15:20:38Z", 
    "summary": "This paper contributes to the general understanding of the geometrical model\nof concurrency that was named higher dimensional automata (HDAs) by Pratt. In\nparticular we investigate modal logics for such models and their expressive\npower in terms of the bisimulation that can be captured. The geometric model of\nconcurrency is interesting from two main reasons: its generality and\nexpressiveness, and the natural way in which autoconcurrency and action\nrefinement are captured. Logics for this model, though, are not well\ninvestigated, where a simple, yet adequate, modal logic over HDAs was only\nrecently introduced. As this modal logic, with two existential modalities,\nduring and after, captures only split bisimulation, which is rather low in the\nspectrum of van Glabbeek and Vaandrager, the immediate question was what small\nextension of this logic could capture the more fine-grained hereditary history\npreserving bisimulation (hh)? In response, the work in this paper provides\nseveral insights. One is the fact that the geometrical aspect of HDAs makes it\npossible to use for capturing the hh-bisimulation, a standard modal logic that\ndoes not employ event variables, opposed to the two logics (over less\nexpressive models) that we compare with. The logic that we investigate here\nuses standard past modalities and extends the previously introduced logic\n(called HDML) that had only forward, action-labelled, modalities. Besides, we\ntry to understand better the above issues by introducing a related model that\nwe call ST-configuration structures, which extend the configuration structures\nof van Glabbeek and Plotkin. We relate this model to HDAs, and redefine and\nprove the earlier results in the light of this new model. These offer a\ndifferent view on why the past modalities and geometrical concurrency capture\nthe hereditary history preserving bisimulation. Additional correlating insights\nare also gained."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(2:14)2012", 
    "link": "http://arxiv.org/pdf/1206.3180v1", 
    "title": "Automated Analysis of Scenario-based Specifications of Distributed   Access Control Policies with Non-Mechanizable Activities (Extended Version)", 
    "arxiv-id": "1206.3180v1", 
    "author": "Luca Vigan\u00f2", 
    "publish": "2012-06-14T17:02:05Z", 
    "summary": "The advance of web services technologies promises to have far-reaching\neffects on the Internet and enterprise networks allowing for greater\naccessibility of data. The security challenges presented by the web services\napproach are formidable. In particular, access control solutions should be\nrevised to address new challenges, such as the need of using certificates for\nthe identification of users and their attributes, human intervention in the\ncreation or selection of the certificates, and (chains of) certificates for\ntrust management. With all these features, it is not surprising that analyzing\npolicies to guarantee that a sensitive resource can be accessed only by\nauthorized users becomes very difficult. In this paper, we present an automated\ntechnique to analyze scenario-based specifications of access control policies\nin open and distributed systems. We illustrate our ideas on a case study\narising in the e-government area."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(2:14)2012", 
    "link": "http://arxiv.org/pdf/1206.3883v1", 
    "title": "Compiling Finite Domain Constraints to SAT with BEE", 
    "arxiv-id": "1206.3883v1", 
    "author": "Michael Codish", 
    "publish": "2012-06-18T10:57:13Z", 
    "summary": "We present BEE, a compiler which enables to encode finite domain constraint\nproblems to CNF. Using BEE both eases the encoding process for the user and\nalso performs transformations to simplify constraints and optimize their\nencoding to CNF. These optimizations are based primarily on equi-propagation\nand on partial evaluation, and also on the idea that a given constraint may\nhave various possible CNF encodings. Often, the better encoding choice is made\nafter constraint simplification. BEE is written in Prolog and integrates\ndirectly with a SAT solver through a suitable Prolog interface. We demonstrate\nthat constraint simplification is often highly beneficial when solving hard\nfinite domain constraint problems. A BEE implementation is available with this\npaper."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(2:16)2012", 
    "link": "http://arxiv.org/pdf/1206.4444v2", 
    "title": "Generalized Craig Interpolation for Stochastic Boolean Satisfiability   Problems with Applications to Probabilistic State Reachability and Region   Stability", 
    "arxiv-id": "1206.4444v2", 
    "author": "Martin Fr\u00e4nzle", 
    "publish": "2012-06-20T10:20:14Z", 
    "summary": "The stochastic Boolean satisfiability (SSAT) problem has been introduced by\nPapadimitriou in 1985 when adding a probabilistic model of uncertainty to\npropositional satisfiability through randomized quantification. SSAT has many\napplications, among them probabilistic bounded model checking (PBMC) of\nsymbolically represented Markov decision processes. This article identifies a\nnotion of Craig interpolant for the SSAT framework and develops an algorithm\nfor computing such interpolants based on a resolution calculus for SSAT. As a\npotential application area of this novel concept of Craig interpolation, we\naddress the symbolic analysis of probabilistic systems. We first investigate\nthe use of interpolation in probabilistic state reachability analysis, turning\nthe falsification procedure employing PBMC into a verification technique for\nprobabilistic safety properties. We furthermore propose an interpolation-based\napproach to probabilistic region stability, being able to verify that the\nprobability of stabilizing within some region is sufficiently large."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(2:16)2012", 
    "link": "http://arxiv.org/pdf/1206.4458v1", 
    "title": "Terminating Calculi for Propositional Dummett Logic with Subformula   Property", 
    "arxiv-id": "1206.4458v1", 
    "author": "Guido Fiorino", 
    "publish": "2012-06-20T11:07:47Z", 
    "summary": "In this paper we present two terminating tableau calculi for propositional\nDummett logic obeying the subformula property. The ideas of our calculi rely on\nthe linearly ordered Kripke semantics of Dummett logic. The first calculus\nworks on two semantical levels: the present and the next possible world. The\nsecond calculus employs the usual object language of tableau systems and\nexploits a property of the construction of the completeness theorem to\nintroduce a check which is an alternative to loop check mechanisms."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-32621-9_10", 
    "link": "http://arxiv.org/pdf/1206.4547v1", 
    "title": "Initiality for Typed Syntax and Semantics", 
    "arxiv-id": "1206.4547v1", 
    "author": "Benedikt Ahrens", 
    "publish": "2012-06-20T16:30:06Z", 
    "summary": "We give an algebraic characterization of the syntax and semantics of a class\nof simply-typed languages, such as the language PCF: we characterize\nsimply-typed binding syntax equipped with reduction rules via a universal\nproperty, namely as the initial object of some category. For this purpose, we\nemploy techniques developed in two previous works: in [2], we model syntactic\ntranslations between languages over different sets of types as initial\nmorphisms in a category of models. In [1], we characterize untyped syntax with\nreduction rules as initial object in a category of models. In the present work,\nwe show that those techniques are modular enough to be combined: we thus\ncharacterize simply-typed syntax with reduction rules as initial object in a\ncategory. The universal property yields an operator which allows to specify\ntranslations - that are semantically faithful by construction - between\nlanguages over possibly different sets of types.\n  We specify a language by a 2-signature, that is, a signature on two levels:\nthe syntactic level specifies the types and terms of the language, and\nassociates a type to each term. The semantic level specifies, through\ninequations, reduction rules on the terms of the language. To any given\n2-signature we associate a category of models. We prove that this category has\nan initial object, which integrates the types and terms freely generated by the\n2-signature, and the reduction relation on those terms generated by the given\ninequations. We call this object the (programming) language generated by the\n2-signature.\n  [1] Ahrens, B.: Modules over relative monads for syntax and semantics (2011),\narXiv:1107.5252, to be published in Math. Struct. in Comp. Science\n  [2] Ahrens, B.: Extended Initiality for Typed Abstract Syntax. Logical\nMethods in Computer Science 8(2), 1-35 (2012)"
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-32621-9_10", 
    "link": "http://arxiv.org/pdf/1206.4556v1", 
    "title": "Initiality for Typed Syntax and Semantics", 
    "arxiv-id": "1206.4556v1", 
    "author": "Benedikt Ahrens", 
    "publish": "2012-06-20T16:57:25Z", 
    "summary": "In this thesis we give an algebraic characterization of the syntax and\nsemantics of simply-typed languages. More precisely, we characterize\nsimply-typed binding syntax equipped with reduction rules via a universal\nproperty, namely as the initial object of some category. We specify a language\nby a 2-signature ({\\Sigma}, A), that is, a signature on two levels: the\nsyntactic level {\\Sigma} specifies the sorts and terms of the language, and\nassociates a sort to each term. The semantic level A specifies, through\ninequations, reduction rules on the terms of the language. To any given\n2-signature ({\\Sigma}, A) we associate a category of \"models\" of ({\\Sigma}, A).\nWe prove that this category has an initial object, which integrates the terms\nfreely generated by {\\Sigma} and the reduction relation - on those terms -\ngenerated by A. We call this object the programming language generated by\n({\\Sigma}, A).\n  Initiality provides an iteration principle which allows to specify\ntranslations on the syntax, possibly to a language over different sorts.\nFurthermore, translations specified via the iteration principle are by\nconstruction type-safe and faithful with respect to reduction.\n  To illustrate our results, we consider two examples extensively: firstly, we\nspecify a double negation translation from classical to intuitionistic\npropositional logic via the category-theoretic iteration principle. Secondly,\nwe specify a translation from PCF to the untyped lambda calculus which is\nfaithful with respect to reduction in the source and target languages.\n  In a second part, we formalize some of our initiality theorems in the proof\nassistant Coq. The implementation yields a machinery which, when given a\n2-signature, returns an implementation of its associated abstract syntax\ntogether with certified substitution operation, iteration operator and a\nreduction relation generated by the specified reduction rules."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-642-32621-9_10", 
    "link": "http://arxiv.org/pdf/1206.4860v5", 
    "title": "Asynchronous Multi-Tape Automata Intersection: Undecidability and   Approximation", 
    "arxiv-id": "1206.4860v5", 
    "author": "Carlo A. Furia", 
    "publish": "2012-06-21T13:02:07Z", 
    "summary": "When their reading heads are allowed to move completely asynchronously,\nfinite-state automata with multiple tapes achieve a significant expressive\npower, but also lose useful closure properties---closure under intersection, in\nparticular. This paper investigates to what extent it is still feasible to use\nmulti-tape automata as recognizer of polyadic predicates on words. On the\nnegative side, determining whether the intersection of asynchronous multi-tape\nautomata is expressible is not even semidecidable. On the positive side, we\npresent an algorithm that computes under-approximations of the intersection;\nand discuss simple conditions under which it can construct complete\nintersections. A prototype implementation and a few non-trivial examples\ndemonstrate the algorithm in practice."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(3:4)2012", 
    "link": "http://arxiv.org/pdf/1206.5694v2", 
    "title": "Soundness of Unravelings for Conditional Term Rewriting Systems via   Ultra-Properties Related to Linearity", 
    "arxiv-id": "1206.5694v2", 
    "author": "Toshiki Sakabe", 
    "publish": "2012-06-25T14:20:07Z", 
    "summary": "Unravelings are transformations from a conditional term rewriting system\n(CTRS, for short) over an original signature into an unconditional term\nrewriting systems (TRS, for short) over an extended signature. They are not\nsound w.r.t. reduction for every CTRS, while they are complete w.r.t.\nreduction. Here, soundness w.r.t. reduction means that every reduction sequence\nof the corresponding unraveled TRS, of which the initial and end terms are over\nthe original signature, can be simulated by the reduction of the original CTRS.\nIn this paper, we show that an optimized variant of Ohlebusch's unraveling for\na deterministic CTRS is sound w.r.t. reduction if the corresponding unraveled\nTRS is left-linear or both right-linear and non-erasing. We also show that\nsoundness of the variant implies that of Ohlebusch's unraveling. Finally, we\nshow that soundness of Ohlebusch's unraveling is the weakest in soundness of\nthe other unravelings and a transformation, proposed by Serbanuta and Rosu, for\n(normal) deterministic CTRSs, i.e., soundness of them respectively implies that\nof Ohlebusch's unraveling."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(3:4)2012", 
    "link": "http://arxiv.org/pdf/1206.6295v1", 
    "title": "Pareto Curves for Probabilistic Model Checking", 
    "arxiv-id": "1206.6295v1", 
    "author": "David Parker", 
    "publish": "2012-06-24T15:09:09Z", 
    "summary": "Multi-objective probabilistic model checking provides a way to verify\nseveral, possibly conflicting, quantitative properties of a stochastic system.\nIt has useful applications in controller synthesis and compositional\nprobabilistic verification. However, existing methods are based on linear\nprogramming, which limits the scale of systems that can be analysed and makes\nverification of time-bounded properties very difficult. We present a novel\napproach that addresses both of these shortcomings, based on the generation of\nsuccessive approximations of the Pareto curve for a multi-objective model\nchecking problem. We illustrate dramatic improvements in efficiency on a large\nset of benchmarks and show how the ability to visualise Pareto curves\nsignificantly enhances the quality of results obtained from current\nprobabilistic verification tools."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.ic.2014.10.006", 
    "link": "http://arxiv.org/pdf/1206.6504v2", 
    "title": "An Abstract Approach to Stratification in Linear Logic", 
    "arxiv-id": "1206.6504v2", 
    "author": "Lorenzo Tortora de Falco", 
    "publish": "2012-06-27T20:00:58Z", 
    "summary": "We study the notion of stratification, as used in subsystems of linear logic\nwith low complexity bounds on the cut-elimination procedure (the so-called\nlight logics), from an abstract point of view, introducing a logical system in\nwhich stratification is handled by a separate modality. This modality, which is\na generalization of the paragraph modality of Girard's light linear logic,\narises from a general categorical construction applicable to all models of\nlinear logic. We thus learn that stratification may be formulated independently\nof exponential modalities; when it is forced to be connected to exponential\nmodalities, it yields interesting complexity properties. In particular, from\nour analysis stem three alternative reformulations of Baillot and Mazza's\nlinear logic by levels: one geometric, one interactive, and one semantic."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.ic.2014.10.006", 
    "link": "http://arxiv.org/pdf/1208.1366v1", 
    "title": "A Locale for Minimal Bad Sequences", 
    "arxiv-id": "1208.1366v1", 
    "author": "Christian Sternagel", 
    "publish": "2012-08-07T08:45:28Z", 
    "summary": "We present a locale that abstracts over the necessary ingredients for\nconstructing a minimal bad sequence, as required in classical proofs of\nHigman's lemma and Kruskal's tree theorem."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.ic.2014.10.006", 
    "link": "http://arxiv.org/pdf/1208.1368v2", 
    "title": "Getting Started with Isabelle/jEdit", 
    "arxiv-id": "1208.1368v2", 
    "author": "Christian Sternagel", 
    "publish": "2012-08-07T08:52:26Z", 
    "summary": "We give a beginner-oriented introduction to Isabelle/jEdit, providing\nmotivation for using it as well as pointing at some differences to the\ntraditional Proof General interface and current limitations."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2559947", 
    "link": "http://arxiv.org/pdf/1208.1476v2", 
    "title": "Using Tableau to Decide Description Logics with Full Role Negation and   Identity", 
    "arxiv-id": "1208.1476v2", 
    "author": "Dmitry Tishkovsky", 
    "publish": "2012-08-07T17:41:37Z", 
    "summary": "This paper presents a tableau approach for deciding expressive description\nlogics with full role negation and role identity. We consider the description\nlogic ALBOid, which is the extension of ALC with the Boolean role operators,\ninverse of roles, the identity role, and includes full support for individuals\nand singleton concepts. ALBOid is expressively equivalent to the two-variable\nfragment of first-order logic with equality and subsumes Boolean modal logic.\nIn this paper we define a sound and complete tableau calculus for the ALBOid\nthat provides a basis for decision procedures for this logic and all its\nsublogics. An important novelty of our approach is the use of a generic\nunrestricted blocking mechanism. Being based on a conceptually simple rule,\nunrestricted blocking performs case distinctions over whether two individuals\nare equal or not and equality reasoning to find finite models. The blocking\nmechanism ties the proof of termination of tableau derivations to the finite\nmodel property of ALBOid."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2559947", 
    "link": "http://arxiv.org/pdf/1208.1591v1", 
    "title": "CeTA - A Tool for Certified Termination Analysis", 
    "arxiv-id": "1208.1591v1", 
    "author": "Harald Zankl", 
    "publish": "2012-08-08T06:16:18Z", 
    "summary": "Since the first termination competition in 2004 it is of great interest,\nwhether a proof that has been automatically generated by a termination tool, is\nindeed correct. The increasing number of termination proving techniques as well\nas the increasing complexity of generated proofs (e.g., combinations of several\ntechniques, exhaustive labelings, tree automata, etc.), make certifying (i.e.,\nchecking the correctness of) such proofs more and more tedious for humans.\nHence the interest in automated certification of termination proofs. This led\nto the general approach of using proof assistants (like Coq and Isabelle) for\ncertification. We present the latest developments for IsaFoR/CeTA (version\n1.03) which is the certifier CeTA, based on the Isabelle/HOL formalization of\nrewriting IsaFoR."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2559947", 
    "link": "http://arxiv.org/pdf/1208.1594v1", 
    "title": "Certification extends Termination Techniques", 
    "arxiv-id": "1208.1594v1", 
    "author": "Ren\u00e9 Thiemann", 
    "publish": "2012-08-08T06:27:58Z", 
    "summary": "There are termination proofs that are produced by termination tools for which\ncertifiers are not powerful enough. However, a similar situation also occurs in\nthe other direction. We have formalized termination techniques in a more\ngeneral setting as they have been introduced. Hence, we can certify proofs\nusing techniques that no termination tool supports so far. In this paper we\nshortly present two of these formalizations: Polynomial orders with negative\nconstants and Arctic termination."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2559947", 
    "link": "http://arxiv.org/pdf/1208.1595v1", 
    "title": "A Relative Dependency Pair Framework", 
    "arxiv-id": "1208.1595v1", 
    "author": "Ren\u00e9 Thiemann", 
    "publish": "2012-08-08T06:39:33Z", 
    "summary": "In this paper we generalize the DP framework to a relative DP framework,\nwhere a so called split is possible."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2559947", 
    "link": "http://arxiv.org/pdf/1208.1597v1", 
    "title": "Recording Completion for Finding and Certifying Proofs in Equational   Logic", 
    "arxiv-id": "1208.1597v1", 
    "author": "Christian Sternagel", 
    "publish": "2012-08-08T06:47:28Z", 
    "summary": "When we want to answer/certify whether a given equation is entailed by an\nequational system we face the following problems: (1) It is hard to find a\nconversion (but easy to certify a given one). (2) Under the assumption that\nKnuth-Bendix completion is successful, it is easy to decide the existence of a\nconversion but hard to certify this decision. In this paper we introduce\nrecording completion, which overcomes both problems."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2559947", 
    "link": "http://arxiv.org/pdf/1208.1609v1", 
    "title": "Towards the Certification of Complexity Proofs", 
    "arxiv-id": "1208.1609v1", 
    "author": "Ren\u00e9 Thiemann", 
    "publish": "2012-08-08T08:22:20Z", 
    "summary": "We report on our formalization of matrix-interpretation in Isabelle/HOL.\nMatrices are required to certify termination proofs and we wish to utilize them\nfor complexity proofs, too. For the latter aim, only basic methods have already\nbeen integrated, and we discuss some upcoming problems which arise when\nformalizing more complicated results on matrix-interpretations, which are based\non Cayley-Hamilton's theorem or joint-spectral radius theory."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2559947", 
    "link": "http://arxiv.org/pdf/1208.2457v1", 
    "title": "On Generalized Fuzzy Multisets and their Use in Computation", 
    "arxiv-id": "1208.2457v1", 
    "author": "Apostolos Syropoulos", 
    "publish": "2012-08-12T19:47:09Z", 
    "summary": "An orthogonal approach to the fuzzification of both multisets and hybrid sets\nis presented. In particular, we introduce L-multi-fuzzy and L-fuzzy hybrid\nsets, which are general enough and in spirit with the basic concepts of fuzzy\nset theory. In addition, we study the properties of these structures. Also, the\nusefulness of these structures is examined in the framework of mechanical\nmultiset processing. More specifically, we introduce a variant of fuzzy P\nsystems and, since simple fuzzy membrane systems have been introduced\nelsewhere, we simply extend previously stated results and ideas."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.89.5", 
    "link": "http://arxiv.org/pdf/1208.2748v1", 
    "title": "Expressiveness and Completeness in Abstraction", 
    "arxiv-id": "1208.2748v1", 
    "author": "Tim A. C. Willemse", 
    "publish": "2012-08-14T01:51:51Z", 
    "summary": "We study two notions of expressiveness, which have appeared in abstraction\ntheory for model checking, and find them incomparable in general. In\nparticular, we show that according to the most widely used notion, the class of\nKripke Modal Transition Systems is strictly less expressive than the class of\nGeneralised Kripke Modal Transition Systems (a generalised variant of Kripke\nModal Transition Systems equipped with hypertransitions). Furthermore, we\ninvestigate the ability of an abstraction framework to prove a formula with a\nfinite abstract model, a property known as completeness. We address the issue\nof completeness from a general perspective: the way it depends on certain\nabstraction parameters, as well as its relationship with expressiveness."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.89.7", 
    "link": "http://arxiv.org/pdf/1208.2750v1", 
    "title": "Musings on Encodings and Expressiveness", 
    "arxiv-id": "1208.2750v1", 
    "author": "Rob van Glabbeek", 
    "publish": "2012-08-14T01:52:04Z", 
    "summary": "This paper proposes a definition of what it means for one system description\nlanguage to encode another one, thereby enabling an ordering of system\ndescription languages with respect to expressive power. I compare the proposed\ndefinition with other definitions of encoding and expressiveness found in the\nliterature, and illustrate it on a case study: comparing the expressive power\nof CCS and CSP."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.89.10", 
    "link": "http://arxiv.org/pdf/1208.2753v1", 
    "title": "An Operational Petri Net Semantics for the Join-Calculus", 
    "arxiv-id": "1208.2753v1", 
    "author": "Stephan Mennicke", 
    "publish": "2012-08-14T01:52:31Z", 
    "summary": "We present a concurrent operational Petri net semantics for the\njoin-calculus, a process calculus for specifying concurrent and distributed\nsystems. There often is a gap between system specifications and the actual\nimplementations caused by synchrony assumptions on the specification side and\nasynchronously interacting components in implementations. The join-calculus is\npromising to reduce this gap by providing an abstract specification language\nwhich is asynchronously distributable. Classical process semantics establish an\nimplicit order of actually independent actions, by means of an interleaving. So\ndoes the semantics of the join-calculus. To capture such independent actions,\nstep-based semantics, e.g., as defined on Petri nets, are employed. Our Petri\nnet semantics for the join-calculus induces step-behavior in a natural way. We\nprove our semantics behaviorally equivalent to the original join-calculus\nsemantics by means of a bisimulation. We discuss how join specific assumptions\ninfluence an existing notion of distributability based on Petri nets."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.89.10", 
    "link": "http://arxiv.org/pdf/1208.2921v2", 
    "title": "Quantified preference logic", 
    "arxiv-id": "1208.2921v2", 
    "author": "Scott Weinstein", 
    "publish": "2012-08-14T16:50:21Z", 
    "summary": "The logic of reason-based preference advanced in Osherson and Weinstein\n(2012) is extended to quantifiers. Basic properties of the new system are\ndiscussed."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(4:1)2012", 
    "link": "http://arxiv.org/pdf/1208.3596v2", 
    "title": "First steps in synthetic guarded domain theory: step-indexing in the   topos of trees", 
    "arxiv-id": "1208.3596v2", 
    "author": "Kristian St\u00f8vring", 
    "publish": "2012-08-17T13:40:49Z", 
    "summary": "We present the topos S of trees as a model of guarded recursion. We study the\ninternal dependently-typed higher-order logic of S and show that S models two\nmodal operators, on predicates and types, which serve as guards in recursive\ndefinitions of terms, predicates, and types. In particular, we show how to\nsolve recursive type equations involving dependent types. We propose that the\ninternal logic of S provides the right setting for the synthetic construction\nof abstract versions of step-indexed models of programming languages and\nprogram logics. As an example, we show how to construct a model of a\nprogramming language with higher-order store and recursive types entirely\ninside the internal logic of S. Moreover, we give an axiomatic categorical\ntreatment of models of synthetic guarded domain theory and prove that, for any\ncomplete Heyting algebra A with a well-founded basis, the topos of sheaves over\nA forms a model of synthetic guarded domain theory, generalizing the results\nfor S."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.93", 
    "link": "http://arxiv.org/pdf/1208.4301v1", 
    "title": "Proceedings Seventh ACCAT Workshop on Applied and Computational Category   Theory", 
    "arxiv-id": "1208.4301v1", 
    "author": "Thomas Soboll", 
    "publish": "2012-08-21T16:57:54Z", 
    "summary": "Category Theory is a well-known powerful mathematical modeling language with\na wide area of applications in mathematics and computer science, including\nespecially the semantical foundations of topics in software science and\ndevelopment. Categorical methods are already well established for the\nsemantical foundation of type theory (cartesian closed categories), data type\nspecification frameworks (institutions) and graph transformation (adhesive high\nlevel replacement categories).\n  It is the intention of the ACCAT Workshops on Applied and Computational\nCategory Theory to bring together leading researchers in these areas with those\nin software science and development in order to transfer categorical concepts\nand theories in both directions. The workshops aims to represent a forum for\nresearchers and practitioners who are interested in an exchange of ideas,\nnotions, and techniques for different applications of category theory.\n  The seventh ACCAT workshop on Applied and Computational Category Theory 2012\nwas held in Tallinn, Estonia on the 1st of April 2012 as a satellite event of\nETAPS 2012. This issue contains the full version of one of the invited talks as\nwell as the submitted papers, which cover a wide range of applications of\ncategory theory, from model-driven engineering over transition systems in\nstochastic processes to transformations in M-adhesive categories."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.93", 
    "link": "http://arxiv.org/pdf/1208.4321v1", 
    "title": "Formal Verification of Safety Properties for Ownership Authentication   Transfer Protocol", 
    "arxiv-id": "1208.4321v1", 
    "author": "Sanjay Singh", 
    "publish": "2012-08-21T18:00:36Z", 
    "summary": "In ubiquitous computing devices, users tend to store some valuable\ninformation in their device. Even though the device can be borrowed by the\nother user temporarily, it is not safe for any user to borrow or lend the\ndevice as it may cause private data of the user to be public. To safeguard the\nuser data and also to preserve user privacy we propose and model the technique\nof ownership authentication transfer. The user who is willing to sell the\ndevice has to transfer the ownership of the device under sale. Once the device\nis sold and the ownership has been transferred, the old owner will not be able\nto use that device at any cost. Either of the users will not be able to use the\ndevice if the process of ownership has not been carried out properly. This also\ntakes care of the scenario when the device has been stolen or lost, avoiding\nthe impersonation attack. The aim of this paper is to model basic process of\nproposed ownership authentication transfer protocol and check its safety\nproperties by representing it using CSP and model checking approach. For model\nchecking we have used a symbolic model checker tool called NuSMV. The safety\nproperties of ownership transfer protocol has been modeled in terms of CTL\nspecification and it is observed that the system satisfies all the protocol\nconstraint and is safe to be deployed."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(3:28)2012", 
    "link": "http://arxiv.org/pdf/1208.4549v2", 
    "title": "Forward Analysis for WSTS, Part II: Complete WSTS", 
    "arxiv-id": "1208.4549v2", 
    "author": "Jean Goubault-Larrecq", 
    "publish": "2012-08-22T16:33:16Z", 
    "summary": "We describe a simple, conceptual forward analysis procedure for\ninfinity-complete WSTS S. This computes the so-called clover of a state. When S\nis the completion of a WSTS X, the clover in S is a finite description of the\ndownward closure of the reachability set. We show that such completions are\ninfinity-complete exactly when X is an omega-2-WSTS, a new robust class of\nWSTS. We show that our procedure terminates in more cases than the generalized\nKarp-Miller procedure on extensions of Petri nets and on lossy channel systems.\nWe characterize the WSTS where our procedure terminates as those that are\nclover-flattable. Finally, we apply this to well-structured counter systems."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(3:28)2012", 
    "link": "http://arxiv.org/pdf/1208.4993v4", 
    "title": "Expressive Completeness of Metric Temporal Logic", 
    "arxiv-id": "1208.4993v4", 
    "author": "James Worrell", 
    "publish": "2012-08-24T14:52:57Z", 
    "summary": "Metric Temporal Logic (MTL) is a generalisation of Linear Temporal Logic in\nwhich the Until and Since modalities are annotated with intervals that express\nmetric constraints. A seminal result of Hirshfeld and Rabinovich shows that\nover the reals, first-order logic with binary order relation < and unary\nfunction +1 is strictly more expressive than MTL with integer constants. Indeed\nthey prove that no temporal logic whose modalities are definable by formulas of\nbounded quantifier depth can be expressively complete for FO(<,+1). In this\npaper we show the surprising result that if we allow unary functions +q, (q\nrational), in first-order logic and correspondingly allow rational constants in\nMTL, then the two logics have the same expressive power. This gives the first\ngeneralisation of Kamp's theorem on the expressive completeness of LTL for\nFO(<) to the quantitative setting. The proof of this result involves a\ngeneralisation of Gabbay's notion of separation."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(3:18)2012", 
    "link": "http://arxiv.org/pdf/1208.5909v2", 
    "title": "Weak Alternating Timed Automata", 
    "arxiv-id": "1208.5909v2", 
    "author": "Igor Walukiewicz", 
    "publish": "2012-08-29T13:22:29Z", 
    "summary": "Alternating timed automata on infinite words are considered. The main result\nis a characterization of acceptance conditions for which the emptiness problem\nfor these automata is decidable. This result implies new decidability results\nfor fragments of timed temporal logics. It is also shown that, unlike for MITL,\nthe characterisation remains the same even if no punctual constraints are\nallowed."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(4:6)2012", 
    "link": "http://arxiv.org/pdf/1208.6483v3", 
    "title": "Parameterised Multiparty Session Types", 
    "arxiv-id": "1208.6483v3", 
    "author": "Raymond Hu", 
    "publish": "2012-08-31T13:01:05Z", 
    "summary": "For many application-level distributed protocols and parallel algorithms, the\nset of participants, the number of messages or the interaction structure are\nonly known at run-time. This paper proposes a dependent type theory for\nmultiparty sessions which can statically guarantee type-safe, deadlock-free\nmultiparty interactions among processes whose specifications are parameterised\nby indices. We use the primitive recursion operator from G\\\"odel's System T to\nexpress a wide range of communication patterns while keeping type checking\ndecidable. To type individual distributed processes, a parameterised global\ntype is projected onto a generic generator which represents a class of all\npossible end-point types. We prove the termination of the type-checking\nalgorithm in the full system with both multiparty session types and recursive\ntypes. We illustrate our type theory through non-trivial programming and\nverification examples taken from parallel algorithms and Web services usecases."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(4:6)2012", 
    "link": "http://arxiv.org/pdf/1209.0516v2", 
    "title": "When is Metric Temporal Logic Expressively Complete?", 
    "arxiv-id": "1209.0516v2", 
    "author": "James Worrell", 
    "publish": "2012-09-04T02:30:35Z", 
    "summary": "A seminal result of Kamp is that over the reals Linear Temporal Logic (LTL)\nhas the same expressive power as first-order logic with binary order relation <\nand monadic predicates. A key question is whether there exists an analogue of\nKamp's theorem for Metric Temporal Logic (MTL) -- a generalization of LTL in\nwhich the Until and Since modalities are annotated with intervals that express\nmetric constraints. Hirshfeld and Rabinovich gave a negative answer, showing\nthat first-order logic with binary order relation < and unary function +1 is\nstrictly more expressive than MTL with integer constants. However, a recent\nresult of Hunter, Ouaknine and Worrell shows that with rational timing\nconstants, MTL has the same expressive power as first-order logic, giving a\npositive answer. In this paper we generalize these results by giving a precise\ncharacterization of those sets of constants for which MTL and first-order logic\nhave the same expressive power. We also show that full first-order\nexpressiveness can be recovered with the addition of counting modalities,\nstrongly supporting the assertion of Hirshfeld and Rabinovich that Q2MLO is one\nof the most expressive decidable fragments of FO(<,+1)."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(4:6)2012", 
    "link": "http://arxiv.org/pdf/1209.0518v1", 
    "title": "The expressiveness of MTL with counting", 
    "arxiv-id": "1209.0518v1", 
    "author": "Paul Hunter", 
    "publish": "2012-09-04T02:44:26Z", 
    "summary": "It is well known that MTL with integer endpoints is unable to express all of\nmonadic first-order logic of order and metric (FO(<,+1)). Indeed, MTL is unable\nto express the counting modalities $C_n$ that assert a properties holds $n$\ntimes in the next time interval. We show that MTL with the counting modalities,\nMTL+C, is expressively complete for FO(<,+1). This result strongly supports the\nassertion of Hirshfeld and Rabinovich that Q2MLO is the most expressive\ndecidable fragments of FO(<,+1)."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(4:6)2012", 
    "link": "http://arxiv.org/pdf/1209.0571v2", 
    "title": "Reachability of Communicating Timed Processes", 
    "arxiv-id": "1209.0571v2", 
    "author": "Gr\u00e9goire Sutre", 
    "publish": "2012-09-04T09:08:52Z", 
    "summary": "We study the reachability problem for communicating timed processes, both in\ndiscrete and dense time. Our model comprises automata with local timing\nconstraints communicating over unbounded FIFO channels. Each automaton can only\naccess its set of local clocks; all clocks evolve at the same rate. Our main\ncontribution is a complete characterization of decidable and undecidable\ncommunication topologies, for both discrete and dense time. We also obtain\ncomplexity results, by showing that communicating timed processes are at least\nas hard as Petri nets; in the discrete time, we also show equivalence with\nPetri nets. Our results follow from mutual topology-preserving reductions\nbetween timed automata and (untimed) counter automata."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(4:6)2012", 
    "link": "http://arxiv.org/pdf/1209.1248v1", 
    "title": "Correctness of an Incremental and Worst-Case Optimal Decision Procedure   for Modal Logic with Eventualities", 
    "arxiv-id": "1209.1248v1", 
    "author": "Gert Smolka", 
    "publish": "2012-09-06T10:27:25Z", 
    "summary": "We present a simple theory explaining the construction and the correctness of\nan incremental and worst-case optimal decision procedure for modal logic with\neventualities. The procedure gives an abstract account of important aspects of\nGor\\'e and Widmann's PDL prover. Starting from an input formula, the procedure\ngrows a Pratt-style graph tableau until the tableau proves or disproves the\nsatisfiability of the formula. The procedure provides a basis for practical\nprovers since satisfiability and unsatisfiability of formulas can often be\ndetermined with small tableaux."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.93.2", 
    "link": "http://arxiv.org/pdf/1209.1432v1", 
    "title": "Bisimulation of Labeled State-to-Function Transition Systems of   Stochastic Process Languages", 
    "arxiv-id": "1209.1432v1", 
    "author": "E. P. de Vink", 
    "publish": "2012-09-07T01:15:56Z", 
    "summary": "Labeled state-to-function transition systems, FuTS for short, admit multiple\ntransition schemes from states to functions of finite support over general\nsemirings. As such they constitute a convenient modeling instrument to deal\nwith stochastic process languages. In this paper, the notion of bisimulation\ninduced by a FuTS is proposed and a correspondence result is proven stating\nthat FuTS-bisimulation coincides with the behavioral equivalence of the\nassociated functor. As generic examples, the concrete existing equivalences for\nthe core of the process algebras ACP, PEPA and IMC are related to the\nbisimulation of specific FuTS, providing via the correspondence result\ncoalgebraic justification of the equivalences of these calculi."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.93.5", 
    "link": "http://arxiv.org/pdf/1209.1436v1", 
    "title": "Satisfaction, Restriction and Amalgamation of Constraints in the   Framework of M-Adhesive Categories", 
    "arxiv-id": "1209.1436v1", 
    "author": "Frank Hermann", 
    "publish": "2012-09-07T01:45:54Z", 
    "summary": "Application conditions for rules and constraints for graphs are well-known in\nthe theory of graph transformation and have been extended already to M-adhesive\ntransformation systems. According to the literature we distinguish between two\nkinds of satisfaction for constraints, called general and initial satisfaction\nof constraints, where initial satisfaction is defined for constraints over an\ninitial object of the base category. Unfortunately, the standard definition of\ngeneral satisfaction is not compatible with negation in contrast to initial\nsatisfaction.\n  Based on the well-known restriction of objects along type morphisms, we study\nin this paper restriction and amalgamation of application conditions and\nconstraints together with their solutions. In our main result, we show\ncompatibility of initial satisfaction for positive constraints with restriction\nand amalgamation, while general satisfaction fails in general.\n  Our main result is based on the compatibility of composition via pushouts\nwith restriction, which is ensured by the horizontal van Kampen property in\naddition to the vertical one that is generally satisfied in M-adhesive\ncategories."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(3:21)2012", 
    "link": "http://arxiv.org/pdf/1209.1738v2", 
    "title": "Model Checking the Quantitative mu-Calculus on Linear Hybrid Systems", 
    "arxiv-id": "1209.1738v2", 
    "author": "Lukasz Kaiser", 
    "publish": "2012-09-08T18:22:30Z", 
    "summary": "We study the model-checking problem for a quantitative extension of the modal\nmu-calculus on a class of hybrid systems. Qualitative model checking has been\nproved decidable and implemented for several classes of systems, but this is\nnot the case for quantitative questions that arise naturally in this context.\nRecently, quantitative formalisms that subsume classical temporal logics and\nallow the measurement of interesting quantitative phenomena were introduced. We\nshow how a powerful quantitative logic, the quantitative mu-calculus, can be\nmodel checked with arbitrary precision on initialised linear hybrid systems. To\nthis end, we develop new techniques for the discretisation of continuous state\nspaces based on a special class of strategies in model-checking games and\npresent a reduction to a class of counter parity games."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(3:21)2012", 
    "link": "http://arxiv.org/pdf/1209.1943v1", 
    "title": "On the satisfiability problem for a 4-level quantified syllogistic and   some applications to modal logic (extended version)", 
    "arxiv-id": "1209.1943v1", 
    "author": "Marianna Nicolosi Asmundo", 
    "publish": "2012-09-10T11:05:55Z", 
    "summary": "We introduce a multi-sorted stratified syllogistic, called 4LQSR, admitting\nvariables of four sorts and a restricted form of quantification over variables\nof the first three sorts, and prove that it has a solvable satisfiability\nproblem by showing that it enjoys a small model property. Then, we consider the\nfragments (4LQSR)^h of 4LQSR, consisting of 4LQSR-formulae whose quantifier\nprefixes have length bounded by h > 1 and satisfying certain syntactic\nconstraints, and prove that each of them has an NP-complete satisfiability\nproblem. Finally we show that the modal logic K45 can be expressed in 4LQSR^3."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.94.3", 
    "link": "http://arxiv.org/pdf/1209.2238v1", 
    "title": "Contracts for Interacting Two-Party Systems", 
    "arxiv-id": "1209.2238v1", 
    "author": "Fernando Schapachnik", 
    "publish": "2012-09-11T06:32:08Z", 
    "summary": "This article deals with the interrelation of deontic operators in contracts\n-- an aspect often neglected when considering only one of the involved parties.\nOn top of an automata-based semantics we formalise the onuses that obligations,\npermissions and prohibitions on one party impose on the other. Such\nformalisation allows for a clean notion of contract strictness and a derived\nnotion of contract conflict that is enriched with issues arising from party\ninterdependence."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(4:3)2012", 
    "link": "http://arxiv.org/pdf/1209.2890v2", 
    "title": "Full Abstraction for the Resource Lambda Calculus with Tests, through   Taylor Expansion", 
    "arxiv-id": "1209.2890v2", 
    "author": "Giulio Manzonetto", 
    "publish": "2012-09-13T13:45:55Z", 
    "summary": "We study the semantics of a resource-sensitive extension of the lambda\ncalculus in a canonical reflexive object of a category of sets and relations, a\nrelational version of Scott's original model of the pure lambda calculus. This\ncalculus is related to Boudol's resource calculus and is derived from Ehrhard\nand Regnier's differential extension of Linear Logic and of the lambda\ncalculus. We extend it with new constructions, to be understood as implementing\na very simple exception mechanism, and with a \"must\" parallel composition.\nThese new operations allow to associate a context of this calculus with any\npoint of the model and to prove full abstraction for the finite sub-calculus\nwhere ordinary lambda calculus application is not allowed. The result is then\nextended to the full calculus by means of a Taylor Expansion formula. As an\nintermediate result we prove that the exception mechanism is not essential in\nthe finite sub-calculus."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(4:2)2012", 
    "link": "http://arxiv.org/pdf/1209.4268v2", 
    "title": "Linear-use CPS translations in the Enriched Effect Calculus", 
    "arxiv-id": "1209.4268v2", 
    "author": "Alex Simpson", 
    "publish": "2012-09-19T14:52:23Z", 
    "summary": "The enriched effect calculus (EEC) is an extension of Moggi's computational\nmetalanguage with a selection of primitives from linear logic. This paper\nexplores the enriched effect calculus as a target language for\ncontinuation-passing-style (CPS) translations in which the typing of the\ntranslations enforces the linear usage of continuations. We first observe that\nestablished call-by-value and call-by name linear-use CPS translations of\nsimply-typed lambda-calculus into intuitionistic linear logic (ILL) land in the\nfragment of ILL given by EEC. These two translations are uniformly generalised\nby a single generic translation of the enriched effect calculus into itself. As\nour main theorem, we prove that the generic self-translation of EEC is\ninvolutive up to isomorphism. As corollaries, we obtain full completeness\nresults, both for the generic translation, and for the original call-by-value\nand call-by-name translations."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(4:2)2012", 
    "link": "http://arxiv.org/pdf/1209.4499v2", 
    "title": "Controllable-choice Message Sequence Graphs", 
    "arxiv-id": "1209.4499v2", 
    "author": "Vojt\u011bch \u0158eh\u00e1k", 
    "publish": "2012-09-20T11:45:50Z", 
    "summary": "We focus on the realizability problem of Message Sequence Graphs (MSG), i.e.\nthe problem whether a given MSG specification is correctly distributable among\nparallel components communicating via messages. This fundamental problem of MSG\nis known to be undecidable. We introduce a well motivated restricted class of\nMSG, so called controllable-choice MSG, and show that all its models are\nrealizable and moreover it is decidable whether a given MSG model is a member\nof this class. In more detail, this class of MSG specifications admits a\ndeadlock-free realization by overloading existing messages with additional\nbounded control data. We also show that the presented class is the largest\nknown subclass of MSG that allows for deadlock-free realization."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(4:2)2012", 
    "link": "http://arxiv.org/pdf/1209.5036v5", 
    "title": "Proof of Church's Thesis", 
    "arxiv-id": "1209.5036v5", 
    "author": "Ram\u00f3n Casares", 
    "publish": "2012-09-23T07:26:53Z", 
    "summary": "We prove that if our calculating capability is limited to that of a universal\nTuring machine with a finite tape, then Church's thesis is true. This way we\naccomplish Post (1936) program."
},{
    "category": "cs.LO", 
    "doi": "10.4230/LIPIcs.CSL.2012.399", 
    "link": "http://arxiv.org/pdf/1209.6336v1", 
    "title": "Parametricity in an Impredicative Sort", 
    "arxiv-id": "1209.6336v1", 
    "author": "Marc Lasson", 
    "publish": "2012-09-27T19:22:06Z", 
    "summary": "Reynold's abstraction theorem is now a well-established result for a large\nclass of type systems. We propose here a definition of relational parametricity\nand a proof of the abstraction theorem in the Calculus of Inductive\nConstructions (CIC), the underlying formal language of Coq, in which\nparametricity relations' codomain is the impredicative sort of propositions. To\nproceed, we need to refine this calculus by splitting the sort hierarchy to\nseparate informative terms from non-informative terms. This refinement is very\nclose to CIC, but with the property that typing judgments can distinguish\ninformative terms. Among many applications, this natural encoding of\nparametricity inside CIC serves both theoretical purposes (proving the\nindependence of propositions with respect to the logical system) as well as\npractical aspirations (proving properties of finite algebraic structures). We\nfinally discuss how we can simply build, on top of our calculus, a new\nreflexive Coq tactic that constructs proof terms by parametricity."
},{
    "category": "cs.LO", 
    "doi": "10.1017/S1471068412000397", 
    "link": "http://arxiv.org/pdf/1210.0368v1", 
    "title": "GEM: a Distributed Goal Evaluation Algorithm for Trust Management", 
    "arxiv-id": "1210.0368v1", 
    "author": "Sandro Etalle", 
    "publish": "2012-10-01T12:24:54Z", 
    "summary": "Trust management is an approach to access control in distributed systems\nwhere access decisions are based on policy statements issued by multiple\nprincipals and stored in a distributed manner. In trust management, the policy\nstatements of a principal can refer to other principals' statements; thus, the\nprocess of evaluating an access request (i.e., a goal) consists of finding a\n\"chain\" of policy statements that allows the access to the requested resource.\nMost existing goal evaluation algorithms for trust management either rely on a\ncentralized evaluation strategy, which consists of collecting all the relevant\npolicy statements in a single location (and therefore they do not guarantee the\nconfidentiality of intensional policies), or do not detect the termination of\nthe computation (i.e., when all the answers of a goal are computed). In this\npaper we present GEM, a distributed goal evaluation algorithm for trust\nmanagement systems that relies on function-free logic programming for the\nspecification of policy statements. GEM detects termination in a completely\ndistributed way without disclosing intensional policies, thereby preserving\ntheir confidentiality. We demonstrate that the algorithm terminates and is\nsound and complete with respect to the standard semantics for logic programs."
},{
    "category": "cs.LO", 
    "doi": "10.1017/S1471068412000397", 
    "link": "http://arxiv.org/pdf/1210.0574v2", 
    "title": "Efficient Parallel Path Checking for Linear-Time Temporal Logic With   Past and Bounds", 
    "arxiv-id": "1210.0574v2", 
    "author": "Bernd Finkbeiner", 
    "publish": "2012-10-01T20:54:57Z", 
    "summary": "Path checking, the special case of the model checking problem where the model\nunder consideration is a single path, plays an important role in monitoring,\ntesting, and verification. We prove that for linear-time temporal logic (LTL),\npath checking can be efficiently parallelized. In addition to the core logic,\nwe consider the extensions of LTL with bounded-future (BLTL) and past-time\n(LTL+Past) operators. Even though both extensions improve the succinctness of\nthe logic exponentially, path checking remains efficiently parallelizable: Our\nalgorithm for LTL, LTL+Past, and BLTL+Past is in AC^1(logDCFL) \\subseteq NC."
},{
    "category": "cs.LO", 
    "doi": "10.1017/S1471068412000397", 
    "link": "http://arxiv.org/pdf/1210.1100v2", 
    "title": "Confluence by Decreasing Diagrams -- Formalized", 
    "arxiv-id": "1210.1100v2", 
    "author": "Harald Zankl", 
    "publish": "2012-10-01T18:35:30Z", 
    "summary": "This paper presents a formalization of decreasing diagrams in the theorem\nprover Isabelle. It discusses mechanical proofs showing that any locally\ndecreasing abstract rewrite system is confluent. The valley and the conversion\nversion of decreasing diagrams are considered."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(4:4)2012", 
    "link": "http://arxiv.org/pdf/1210.1200v2", 
    "title": "On streams that are finitely red", 
    "arxiv-id": "1210.1200v2", 
    "author": "Tarmo Uustalu", 
    "publish": "2012-10-03T19:49:31Z", 
    "summary": "Mixing induction and coinduction, we study alternative definitions of streams\nbeing finitely red. We organize our definitions into a hierarchy including also\nsome well-known alternatives in intuitionistic analysis. The hierarchy\ncollapses classically, but is intuitionistically of strictly decreasing\nstrength. We characterize the differences in strength in a precise way by weak\ninstances of the Law of Excluded Middle."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(4:4)2012", 
    "link": "http://arxiv.org/pdf/1210.2039v4", 
    "title": "Partiality and Recursion in Higher-order Logic", 
    "arxiv-id": "1210.2039v4", 
    "author": "\u0141ukasz Czajka", 
    "publish": "2012-10-07T10:34:31Z", 
    "summary": "We present an illative system I_s of classical higher-order logic with\nsubtyping and basic inductive types. The system I_s allows for direct\ndefinitions of partial and general recursive functions, and provides means for\nhandling functions whose termination has not been proven. We give examples of\nhow properties of some recursive functions may be established in our system. In\na technical appendix to the paper we prove consistency of I_s. The proof is by\nmodel construction. We then use this construction to show conservativity of I_s\nover classical first-order logic. Conservativity over higher-order logic is\nconjectured, but not proven."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(4:4)2012", 
    "link": "http://arxiv.org/pdf/1210.2287v1", 
    "title": "ASP modulo CSP: The clingcon system", 
    "arxiv-id": "1210.2287v1", 
    "author": "Torsten Schaub", 
    "publish": "2012-10-05T08:01:37Z", 
    "summary": "We present the hybrid ASP solver clingcon, combining the simple modeling\nlanguage and the high performance Boolean solving capacities of Answer Set\nProgramming (ASP) with techniques for using non-Boolean constraints from the\narea of Constraint Programming (CP). The new clingcon system features an\nextended syntax supporting global constraints and optimize statements for\nconstraint variables. The major technical innovation improves the interaction\nbetween ASP and CP solver through elaborated learning techniques based on\nirreducible inconsistent sets. A broad empirical evaluation shows that these\ntechniques yield a performance improvement of an order of magnitude. To appear\nin Theory and Practice of Logic Programming"
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.96.4", 
    "link": "http://arxiv.org/pdf/1210.2451v1", 
    "title": "Model-Checking Process Equivalences", 
    "arxiv-id": "1210.2451v1", 
    "author": "Manuel Vargas Guzm\u00e1n", 
    "publish": "2012-10-09T00:53:17Z", 
    "summary": "Process equivalences are formal methods that relate programs and system\nwhich, informally, behave in the same way. Since there is no unique notion of\nwhat it means for two dynamic systems to display the same behaviour there are a\nmultitude of formal process equivalences, ranging from bisimulation to trace\nequivalence, categorised in the linear-time branching-time spectrum.\n  We present a logical framework based on an expressive modal fixpoint logic\nwhich is capable of defining many process equivalence relations: for each such\nequivalence there is a fixed formula which is satisfied by a pair of processes\nif and only if they are equivalent with respect to this relation. We explain\nhow to do model checking, even symbolically, for a significant fragment of this\nlogic that captures many process equivalences. This allows model checking\ntechnology to be used for process equivalence checking. We show how partial\nevaluation can be used to obtain decision procedures for process equivalences\nfrom the generic model checking scheme."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.96.17", 
    "link": "http://arxiv.org/pdf/1210.2461v1", 
    "title": "A decidable quantified fragment of set theory with ordered pairs and   some undecidable extensions", 
    "arxiv-id": "1210.2461v1", 
    "author": "Cristiano Longo", 
    "publish": "2012-10-09T00:55:17Z", 
    "summary": "In this paper we address the decision problem for a fragment of set theory\nwith restricted quantification which extends the language studied in [4] with\npair related quantifiers and constructs, in view of possible applications in\nthe field of knowledge representation. We will also show that the decision\nproblem for our language has a non-deterministic exponential time complexity.\nHowever, for the restricted case of formulae whose quantifier prefixes have\nlength bounded by a constant, the decision problem becomes NP-complete. We also\nobserve that in spite of such restriction, several useful set-theoretic\nconstructs, mostly related to maps, are expressible. Finally, we present some\nundecidable extensions of our language, involving any of the operators domain,\nrange, image, and map composition.\n  [4] Michael Breban, Alfredo Ferro, Eugenio G. Omodeo and Jacob T. Schwartz\n(1981): Decision procedures for elementary sublanguages of set theory. II.\nFormulas involving restricted quantifiers, together with ordinal, integer, map,\nand domain notions. Communications on Pure and Applied Mathematics 34, pp.\n177-195"
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.96.12", 
    "link": "http://arxiv.org/pdf/1210.2479v1", 
    "title": "Interval Temporal Logics over Strongly Discrete Linear Orders: the   Complete Picture", 
    "arxiv-id": "1210.2479v1", 
    "author": "Guido Sciavicco", 
    "publish": "2012-10-09T03:43:57Z", 
    "summary": "Interval temporal logics provide a general framework for temporal reasoning\nabout interval structures over linearly ordered domains, where intervals are\ntaken as the primitive ontological entities. In this paper, we identify all\nfragments of Halpern and Shoham's interval temporal logic HS with a decidable\nsatisfiability problem over the class of strongly discrete linear orders. We\nclassify them in terms of both their relative expressive power and their\ncomplexity. We show that there are exactly 44 expressively different decidable\nfragments, whose complexity ranges from NP to EXPSPACE. In addition, we\nidentify some new undecidable fragments (all the remaining HS fragments were\nalready known to be undecidable over strongly discrete linear orders). We\nconclude the paper by an analysis of the specific case of natural numbers,\nwhose behavior slightly differs from that of the whole class of strongly\ndiscrete linear orders. The number of decidable fragments over natural numbers\nraises up to 47: three undecidable fragments become decidable with a\nnon-primitive recursive complexity."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(4:12)2012", 
    "link": "http://arxiv.org/pdf/1210.2620v3", 
    "title": "Complete Axiomatizations of Fragments of Monadic Second-Order Logic on   Finite Trees", 
    "arxiv-id": "1210.2620v3", 
    "author": "Balder ten Cate", 
    "publish": "2012-10-09T14:51:25Z", 
    "summary": "We consider a specific class of tree structures that can represent basic\nstructures in linguistics and computer science such as XML documents, parse\ntrees, and treebanks, namely, finite node-labeled sibling-ordered trees. We\npresent axiomatizations of the monadic second-order logic (MSO), monadic\ntransitive closure logic (FO(TC1)) and monadic least fixed-point logic\n(FO(LFP1)) theories of this class of structures. These logics can express\nimportant properties such as reachability. Using model-theoretic techniques, we\nshow by a uniform argument that these axiomatizations are complete, i.e., each\nformula that is valid on all finite trees is provable using our axioms. As a\nbackdrop to our positive results, on arbitrary structures, the logics that we\nstudy are known to be non-recursively axiomatizable."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.97", 
    "link": "http://arxiv.org/pdf/1210.2890v1", 
    "title": "Proceedings Fourth Workshop on Classical Logic and Computation", 
    "arxiv-id": "1210.2890v1", 
    "author": "Ugo de'Liguoro", 
    "publish": "2012-10-09T09:23:22Z", 
    "summary": "CL&C'12 was the fourth of a conference series on \"Classical Logic and\nComputation\", held as satellite to ICALP'12 on Sunday July 8, 2012 in Warwick,\nEngland.\n  CL&C intends to cover all work aiming to explore computational aspects of\nclassical logic and mathematics, and is focused on the exploration of the\ncomputational content of mathematical and logical principles. The scientific\naim of this workshop is to bring together researchers from both fields and\nexchange ideas. The intention of the organisers is for CL&C to be an informal\nworkshop. Participants are encouraged to present work in progress, overviews of\nmore extensive work, and programmatic/position papers, as well as completed\nprojects. Submission of both short abstracts and of longer papers were invited.\nFour submissions were accepted as full papers and are included in these\nproceedings. Three more were accepted only as communications for the\nconference. Paulo Oliva gave an invited talk on \"Some connections between Game\nTheory and Proof Theory\"."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(4:9)2012", 
    "link": "http://arxiv.org/pdf/1210.2972v2", 
    "title": "Petri Net Reachability Graphs: Decidability Status of First Order   Properties", 
    "arxiv-id": "1210.2972v2", 
    "author": "Christophe Morvan", 
    "publish": "2012-10-10T16:30:08Z", 
    "summary": "We investigate the decidability and complexity status of model-checking\nproblems on unlabelled reachability graphs of Petri nets by considering\nfirst-order and modal languages without labels on transitions or atomic\npropositions on markings. We consider several parameters to separate decidable\nproblems from undecidable ones. Not only are we able to provide precise borders\nand a systematic analysis, but we also demonstrate the robustness of our proof\ntechniques."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.97.1", 
    "link": "http://arxiv.org/pdf/1210.3114v1", 
    "title": "Interactive Realizability and the elimination of Skolem functions in   Peano Arithmetic", 
    "arxiv-id": "1210.3114v1", 
    "author": "Margherita Zorzi", 
    "publish": "2012-10-11T03:52:09Z", 
    "summary": "We present a new syntactical proof that first-order Peano Arithmetic with\nSkolem axioms is conservative over Peano Arithmetic alone for arithmetical\nformulas. This result - which shows that the Excluded Middle principle can be\nused to eliminate Skolem functions - has been previously proved by other\ntechniques, among them the epsilon substitution method and forcing. In our\nproof, we employ Interactive Realizability, a computational semantics for Peano\nArithmetic which extends Kreisel's modified realizability to the classical\ncase."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.97.2", 
    "link": "http://arxiv.org/pdf/1210.3115v1", 
    "title": "A call-by-value lambda-calculus with lists and control", 
    "arxiv-id": "1210.3115v1", 
    "author": "Robbert Krebbers", 
    "publish": "2012-10-11T03:52:15Z", 
    "summary": "Calculi with control operators have been studied to reason about control in\nprogramming languages and to interpret the computational content of classical\nproofs. To make these calculi into a real programming language, one should also\ninclude data types.\n  As a step into that direction, this paper defines a simply typed\ncall-by-value lambda calculus with the control operators catch and throw, a\ndata type of lists, and an operator for primitive recursion (a la Goedel's T).\nWe prove that our system satisfies subject reduction, progress, confluence for\nuntyped terms, and strong normalization for well-typed terms."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.97.3", 
    "link": "http://arxiv.org/pdf/1210.3116v1", 
    "title": "Extensional Models of Untyped Lambda-mu Calculus", 
    "arxiv-id": "1210.3116v1", 
    "author": "Shin-ya Katsumata", 
    "publish": "2012-10-11T03:52:22Z", 
    "summary": "This paper proposes new mathematical models of the untyped Lambda-mu\ncalculus. One is called the stream model, which is an extension of the lambda\nmodel, in which each term is interpreted as a function from streams to\nindividual data. The other is called the stream combinatory algebra, which is\nan extension of the combinatory algebra, and it is proved that the extensional\nequality of the Lambda-mu calculus is equivalent to equality in stream\ncombinatory algebras. In order to define the stream combinatory algebra, we\nintroduce a combinatory calculus SCL, which is an abstraction-free system\ncorresponding to the Lambda-mu calculus. Moreover, it is shown that stream\nmodels are algebraically characterized as a particular class of stream\ncombinatory algebras."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.97.3", 
    "link": "http://arxiv.org/pdf/1210.3599v1", 
    "title": "Decidability of All Minimal Models (Revised Version - 2012)", 
    "arxiv-id": "1210.3599v1", 
    "author": "Vincent Padovani", 
    "publish": "2012-10-12T18:51:27Z", 
    "summary": "This unpublished note is an alternate, shorter (and hopefully more readable)\nproof of the decidability of all minimal models. The decidability follows from\na proof of the existence of a cellular term in each observational equivalence\nclass of a minimal model."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.97.3", 
    "link": "http://arxiv.org/pdf/1210.3761v2", 
    "title": "ILP Modulo Theories", 
    "arxiv-id": "1210.3761v2", 
    "author": "Vasilis Papavasileiou", 
    "publish": "2012-10-14T05:15:20Z", 
    "summary": "We present Integer Linear Programming (ILP) Modulo Theories (IMT). An IMT\ninstance is an Integer Linear Programming instance, where some symbols have\ninterpretations in background theories. In previous work, the IMT approach has\nbeen applied to industrial synthesis and design problems with real-time\nconstraints arising in the development of the Boeing 787. Many other problems\nranging from operations research to software verification routinely involve\nlinear constraints and optimization. Thus, a general ILP Modulo Theories\nframework has the potential to be widely applicable. The logical next step in\nthe development of IMT and the main goal of this paper is to provide\ntheoretical underpinnings. This is accomplished by means of BC(T), the Branch\nand Cut Modulo T abstract transition system. We show that BC(T) provides a\nsound and complete optimization procedure for the ILP Modulo T problem, as long\nas T is a decidable, stably-infinite theory. We compare a prototype of BC(T)\nagainst leading SMT solvers."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.97.3", 
    "link": "http://arxiv.org/pdf/1210.4661v1", 
    "title": "Functions as types or the \"Hoare logic\" of functional dependencies", 
    "arxiv-id": "1210.4661v1", 
    "author": "Jose N. Oliveira", 
    "publish": "2012-10-17T08:07:46Z", 
    "summary": "Inspired by the trend on unifying theories of programming, this paper shows\nhow the algebraic treatment of standard data dependency theory equips\nrelational data with functional types and an associated type system which is\nuseful for type checking database operations and for query optimization.\n  Such a typed approach to database programming is then shown to be of the same\nfamily as other programming logics such as eg. Hoare logic or that of strongest\ninvariant functions which has been used in the analysis of while statements.\n  The prospect of using automated deduction systems such as Prover9 for\ntype-checking and query optimization on top of such an algebraic approach is\nconsidered."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.97.3", 
    "link": "http://arxiv.org/pdf/1210.5659v1", 
    "title": "Weighted Modal Transition Systems", 
    "arxiv-id": "1210.5659v1", 
    "author": "Claus Thrane", 
    "publish": "2012-10-20T21:57:52Z", 
    "summary": "Specification theories as a tool in model-driven development processes of\ncomponent-based software systems have recently attracted a considerable\nattention. Current specification theories are however qualitative in nature,\nand therefore fragile in the sense that the inevitable approximation of systems\nby models, combined with the fundamental unpredictability of hardware\nplatforms, makes it difficult to transfer conclusions about the behavior, based\non models, to the actual system. Hence this approach is arguably unsuited for\nmodern software systems. We propose here the first specification theory which\nallows to capture quantitative aspects during the refinement and implementation\nprocess, thus leveraging the problems of the qualitative setting.\n  Our proposed quantitative specification framework uses weighted modal\ntransition systems as a formal model of specifications. These are labeled\ntransition systems with the additional feature that they can model optional\nbehavior which may or may not be implemented by the system. Satisfaction and\nrefinement is lifted from the well-known qualitative to our quantitative\nsetting, by introducing a notion of distances between weighted modal transition\nsystems. We show that quantitative versions of parallel composition as well as\nquotient (the dual to parallel composition) inherit the properties from the\nBoolean setting."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.97.3", 
    "link": "http://arxiv.org/pdf/1210.5946v1", 
    "title": "Bipolar Proof Nets for MALL", 
    "arxiv-id": "1210.5946v1", 
    "author": "Roberto Maieli", 
    "publish": "2012-10-22T16:11:55Z", 
    "summary": "In this work we present a computation paradigm based on a concurrent and\nincremental construction of proof nets (de-sequentialized or graphical proofs)\nof the pure multiplicative and additive fragment of Linear Logic, a resources\nconscious refinement of Classical Logic. Moreover, we set a correspon- dence\nbetween this paradigm and those more pragmatic ones inspired to transactional\nor distributed systems. In particular we show that the construction of additive\nproof nets can be interpreted as a model for super-ACID (or co-operative)\ntransactions over distributed transactional systems (typi- cally,\nmulti-databases)."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.99.6", 
    "link": "http://arxiv.org/pdf/1210.6413v1", 
    "title": "Graph Subsumption in Abstract State Space Exploration", 
    "arxiv-id": "1210.6413v1", 
    "author": "Arend Rensink", 
    "publish": "2012-10-24T00:33:15Z", 
    "summary": "In this paper we present the extension of an existing method for abstract\ngraph-based state space exploration, called neighbourhood abstraction, with a\nreduction technique based on subsumption. Basically, one abstract state\nsubsumes another when it covers more concrete states; in such a case, the\nsubsumed state need not be included in the state space, thus giving a\nreduction. We explain the theory and especially also report on a number of\nexperiments, which show that subsumption indeed drastically reduces both the\nstate space and the resources (time and memory) needed to compute it."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.99.6", 
    "link": "http://arxiv.org/pdf/1211.0242v3", 
    "title": "Revisiting the proof theory of Classical S4", 
    "arxiv-id": "1211.0242v3", 
    "author": "Marcela Cruz", 
    "publish": "2012-11-01T18:01:45Z", 
    "summary": "In 1965 Dag Prawitz presented an extension of Gentzen-type systems of Natural\nDeduction to modal concepts of S4. Maria da Paz Medeiros showed in 2006 that\nthe proof of normalisation for classical S4 does not hold and proposed a new\nproof of normalisation for a logically equivalent system, the system NS4.\nHowever two problems in the proof of the critical lemma used by Medeiros in her\nproof were pointed out by Yuuki Andou in 2009. This paper presents a proof of\nthe critical lemma, resulting in a proof of normalisation for NS4."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.99.6", 
    "link": "http://arxiv.org/pdf/1211.1276v1", 
    "title": "Time-bounded Reachability for Hybrid Automata: Complexity and Fixpoints", 
    "arxiv-id": "1211.1276v1", 
    "author": "James Worrell", 
    "publish": "2012-11-06T15:54:54Z", 
    "summary": "In this paper, we study thetime-bounded reachability problem for rectangular\nhybrid automata with non-negative rates (RHA+). This problem was recently shown\nto be decidable [Brihaye et al, ICALP11] (even though the unbounded\nreachability problem for even very simple classes of hybrid automata is\nwell-known to be undecidable). However, [Brihaye et al, ICALP11] does not\nprovide a precise characterisation of the complexity of the time-bounded\nreachability problem. The contribution of the present paper is threefold.\nFirst, we provide a new NExpTime algorithm to solve the timed-bounded\nreachability problem on RHA+. This algorithm improves on the one of [Brihaye et\nal, ICALP11] by at least one exponential. Second, we show that this new\nalgorithm is optimal, by establishing a matching lower bound: time-bounded\nreachability for RHA+ is therefore NExpTime-complete. Third, we extend these\nresults in a practical direction, by showing that we can effectively compute\nfixpoints that characterise the sets of states that are reachable (resp.\nco-reachable) within T time units from a given starting state."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(4:18)2012", 
    "link": "http://arxiv.org/pdf/1211.1511v2", 
    "title": "Probabilistic modal \u03bc-calculus with independent product", 
    "arxiv-id": "1211.1511v2", 
    "author": "Matteo Mio", 
    "publish": "2012-11-07T10:50:03Z", 
    "summary": "The probabilistic modal {\\mu}-calculus is a fixed-point logic designed for\nexpressing properties of probabilistic labeled transition systems (PLTS's). Two\nequivalent semantics have been studied for this logic, both assigning to each\nstate a value in the interval [0,1] representing the probability that the\nproperty expressed by the formula holds at the state. One semantics is\ndenotational and the other is a game semantics, specified in terms of\ntwo-player stochastic parity games. A shortcoming of the probabilistic modal\n{\\mu}-calculus is the lack of expressiveness required to encode other important\ntemporal logics for PLTS's such as Probabilistic Computation Tree Logic (PCTL).\nTo address this limitation we extend the logic with a new pair of operators:\nindependent product and coproduct. The resulting logic, called probabilistic\nmodal {\\mu}-calculus with independent product, can encode many properties of\ninterest and subsumes the qualitative fragment of PCTL. The main contribution\nof this paper is the definition of an appropriate game semantics for this\nextended probabilistic {\\mu}-calculus. This relies on the definition of a new\nclass of games which generalize standard two-player stochastic (parity) games\nby allowing a play to be split into concurrent subplays, each continuing their\nevolution independently. Our main technical result is the equivalence of the\ntwo semantics. The proof is carried out in ZFC set theory extended with\nMartin's Axiom at an uncountable cardinal."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(4:18)2012", 
    "link": "http://arxiv.org/pdf/1211.2986v2", 
    "title": "A Strongly Grounded Stable Model Semantics for Full Propositional   Language", 
    "arxiv-id": "1211.2986v2", 
    "author": "Shahab Tasharrofi", 
    "publish": "2012-11-13T13:27:07Z", 
    "summary": "Answer set programming is one of the most praised frameworks for declarative\nprogramming in general and non-monotonic reasoning in particular. There has\nbeen many efforts to extend stable model semantics so that answer set programs\ncan use a more extensive syntax. To such endeavor, the community of\nnon-monotonic reasoning has introduced extensions such as equilibrium models\nand FLP semantics. However, both of these extensions suffer from two problems:\nintended models according to such extensions (1) are not guaranteed to be\nminimal, and (2) more importantly, may have self-justifications (i.e., the\njustification for pertinence of an atom in an intended model may be its own\npertinence). Both of these properties directly violate the spirit of stable\nmodel semantics. Therefore, we believe that we need a new extension of stable\nmodel semantics that guarantees both minimality and being strongly grounded.\n  This paper introduces one such extension using two different approaches:\nfirstly, by extending the goal-reachability interpretation of logic programs to\nthe full propositional language and, secondly, using derivability in\nintuitionistic propositional logic. We show that both these approaches give the\nsame semantics, that we call the supported semantics. Moreover, using the first\napproach, we also extend well-founded semantics to full propositional language.\nFurthermore, we discuss how our supported models relate to other existing\nsemantics for non-monotonic reasoning including the equilibrium models. Last,\nbut not the least, we discuss the complexity of reasoning about supported\nmodels and show that all interesting reasoning tasks (such as brave/cautious\nreasoning) are PSPACE-complete. Therefore, supported model semantics is a much\nmore expressive semantics then the existing semantics such as equlibrium models\n(that have reasoning procedures in $\\Delta^P_3$)."
},lol]