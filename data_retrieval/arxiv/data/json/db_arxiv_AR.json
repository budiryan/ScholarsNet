[{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/9810011v1", 
    "title": "Flysig: Dataflow Oriented Delay-Insensitive Processor for Rapid   Prototyping of Signal Processing", 
    "arxiv-id": "cs/9810011v1", 
    "author": "Bernd Kleinjohann", 
    "publish": "1998-10-12T10:11:05Z", 
    "summary": "As the one-chip integration of HW-modules designed by different companies\nbecomes more and more popular reliability of a HW-design and evaluation of the\ntiming behavior during the prototype stage are absolutely necessary. One way to\nguarantee reliability is the use of robust design styles, e.g.,\ndelay-insensitivity. For early timing evaluation two aspects must be\nconsidered: a) The timing needs to be proportional to technology variations and\nb) the implemented architecture should be identical for prototype and target.\nThe first can be met also by delay-insensitive implementation. The latter one\nis the key point. A unified architecture is needed for prototyping as well as\nimplementation. Our new approach to rapid prototyping of signal processing\ntasks is based on a configurable, delay-insensitive implemented processor\ncalled Flysig. In essence, the Flysig processor can be understood as a complex\nFPGA where the CLBs are substituted by bit-serial operators. In this paper the\ngeneral concept is detailed and first experimental results are given for\ndemonstration of the main advantages: delay-insensitive design style, direct\ncorrespondence between prototyping and target architecture, high performance\nand reasonable shortening of the design cycle."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0111029v1", 
    "title": "Versatile Data Acquisition and Controls for Epics Using Vme-Based Fpgas", 
    "arxiv-id": "cs/0111029v1", 
    "author": "R. Flood", 
    "publish": "2001-11-09T15:08:12Z", 
    "summary": "Field-Programmable Gate Arrays (FPGAs) have provided Thomas Jefferson\nNational Accelerator Facility (Jefferson Lab) with versatile VME-based data\nacquisition and control interfaces with minimal development times. FPGA designs\nhave been used to interface to VME and provide control logic for numerous\nsystems. The building blocks of these logic designs can be tailored to the\nindividual needs of each system and provide system operators with read-backs\nand controls via a VME interface to an EPICS based computer. This versatility\nallows the system developer to choose components and define operating\nparameters and options that are not readily available commercially. Jefferson\nLab has begun developing standard FPGA libraries that result in quick turn\naround times and inexpensive designs."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0111030v1", 
    "title": "A Dual Digital Signal Processor VME Board For Instrumentation And   Control Applications", 
    "arxiv-id": "cs/0111030v1", 
    "author": "J. Musson", 
    "publish": "2001-11-09T16:04:17Z", 
    "summary": "A Dual Digital Signal Processing VME Board was developed for the Continuous\nElectron Beam Accelerator Facility (CEBAF) Beam Current Monitor (BCM) system at\nJefferson Lab. It is a versatile general-purpose digital signal processing\nboard using an open architecture, which allows for adaptation to various\napplications. The base design uses two independent Texas Instrument (TI)\nTMS320C6711, which are 900 MFLOPS floating-point digital signal processors\n(DSP). Applications that require a fixed point DSP can be implemented by\nreplacing the baseline DSP with the pin-for-pin compatible TMS320C6211. The\ndesign can be manufactured with a reduced chip set without redesigning the\nprinted circuit board. For example it can be implemented as a single-channel\nDSP with no analog I/O."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0111032v1", 
    "title": "SNS Timing System", 
    "arxiv-id": "cs/0111032v1", 
    "author": "C. Sibley", 
    "publish": "2001-11-09T19:08:57Z", 
    "summary": "This poster describes the timing system being designed for Spallation Neutron\nSource being built at Oak Ridge National lab."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0207012v1", 
    "title": "Synthesis of Low-Power Digital Circuits Derived from Binary Decision   Diagrams", 
    "arxiv-id": "cs/0207012v1", 
    "author": "Denis V. Popel", 
    "publish": "2002-07-04T04:30:30Z", 
    "summary": "This paper introduces a novel method for synthesizing digital circuits\nderived from Binary Decision Diagrams (BDDs) that can yield to reduction in\npower dissipation. The power reduction is achieved by decreasing the switching\nactivity in a circuit while paying close attention to information measures as\nan optimization criterion. We first present the technique of efficient\nBDD-based computation of information measures which are used to guide the power\noptimization procedures. Using this technique, we have developed an algorithm\nof BDD reordering which leads to reducing the power consumption of the circuits\nderived from BDDs. Results produced by the synthesis on the ISCAS benchmark\ncircuits are very encouraging."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0207014v1", 
    "title": "On the Information Engine of Circuit Design", 
    "arxiv-id": "cs/0207014v1", 
    "author": "Nawar Al-Hakeem", 
    "publish": "2002-07-04T04:55:42Z", 
    "summary": "This paper addresses a new approach to find a spectrum of information\nmeasures for the process of digital circuit synthesis. We consider the problem\nfrom the information engine point of view. The circuit synthesis as a whole and\ndifferent steps of the design process (an example of decision diagram is given)\nare presented via such measurements as entropy, logical work and information\nvitality. We also introduce new information measures to provide better\nestimates of synthesis criteria. We show that the basic properties of\ninformation engine, such as the conservation law of information flow and the\nequilibrium law of information can be formulated."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0405015v1", 
    "title": "A High-Level Reconfigurable Computing Platform Software Frameworks", 
    "arxiv-id": "cs/0405015v1", 
    "author": "Andreas Weisensee", 
    "publish": "2004-05-05T01:56:22Z", 
    "summary": "Reconfigurable computing refers to the use of processors, such as Field\nProgrammable Gate Arrays (FPGAs), that can be modified at the hardware level to\ntake on different processing tasks. A reconfigurable computing platform\ndescribes the hardware and software base on top of which modular extensions can\nbe created, depending on the desired application. Such reconfigurable computing\nplatforms can take on varied designs and implementations, according to the\nconstraints imposed and features desired by the scope of applications. This\npaper introduces a PC-based reconfigurable computing platform software\nframeworks that is flexible and extensible enough to abstract the different\nhardware types and functionality that different PCs may have. The requirements\nof the software platform, architectural issues addressed, rationale behind the\ndecisions made, and frameworks design implemented are discussed."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0407019v2", 
    "title": "Stochastic fuzzy controller", 
    "arxiv-id": "cs/0407019v2", 
    "author": "Franc Jurkovic", 
    "publish": "2004-07-08T06:52:37Z", 
    "summary": "A standard approach to building a fuzzy controller based on stochastic logic\nuses binary random signals with an average (expected value of a random\nvariable) in the range [0, 1]. A different approach is presented, founded on a\nrepresentation of the membership functions with the probability density\nfunctions."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0407032v1", 
    "title": "Exposing Software Defined Radio Functionality To Native Operating System   Applications via Virtual Devices", 
    "arxiv-id": "cs/0407032v1", 
    "author": "Darran Nathan", 
    "publish": "2004-07-13T08:24:37Z", 
    "summary": "Many reconfigurable platforms require that applications be written\nspecifically to take advantage of the reconfigurable hardware. In a PC-based\nenvironment, this presents an undesirable constraint in that the many already\navailable applications cannot leverage on such hardware. Greatest benefit can\nonly be derived from reconfigurable devices if even native OS applications can\ntransparently utilize reconfigurable devices as they would normal full-fledged\nhardware devices. This paper presents how Proteus Virtual Devices are used to\nexpose reconfigurable hardware in a transparent manner for use by typical\nnative OS applications."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0409025v1", 
    "title": "Topics in asynchronous systems", 
    "arxiv-id": "cs/0409025v1", 
    "author": "Serban E. Vlad", 
    "publish": "2004-09-13T11:08:09Z", 
    "summary": "In the paper we define and characterize the asynchronous systems from the\npoint of view of their autonomy, determinism, order, non-anticipation, time\ninvariance, symmetry, stability and other important properties. The study is\ninspired by the models of the asynchronous circuits."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0412040v1", 
    "title": "Data-stationary Architecture to Execute Quantum Algorithms Classically", 
    "arxiv-id": "cs/0412040v1", 
    "author": "J. R. Burger", 
    "publish": "2004-12-09T22:10:48Z", 
    "summary": "This paper presents a data stationary architecture in which each word has an\nattached address field. Address fields massively update in parallel to record\ndata interchanges. Words do not move until memory is read for post processing.\nA sea of such cells can test large-scale quantum algorithms, although other\nprogramming is possible."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0503066v1", 
    "title": "A Practical Approach for Circuit Routing on Dynamic Reconfigurable   Devices", 
    "arxiv-id": "cs/0503066v1", 
    "author": "Jan van der Veen", 
    "publish": "2005-03-24T12:36:07Z", 
    "summary": "Management of communication by on-line routing in new FPGAs with a large\namount of logic resources and partial reconfigurability is a new challenging\nproblem. A Network-on-Chip\n  (NoC) typically uses packet routing mechanism, which has often unsafe data\ntransfers, and network interface overhead. In this paper, circuit routing for\nsuch dynamic NoCs is investigated, and a practical 1-dimensional network with\nan efficient routing algorithm is proposed and implemented. Also, this concept\nhas been extended to the 2-dimensional case. The implementation results show\nthe low area overhead and high performance of this network."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0508038v1", 
    "title": "Quantum Algorithm Processor For Finding Exact Divisors", 
    "arxiv-id": "cs/0508038v1", 
    "author": "John Robert Burger", 
    "publish": "2005-08-04T17:35:38Z", 
    "summary": "Wiring diagrams are given for a quantum algorithm processor in CMOS to\ncompute, in parallel, all divisors of an n-bit integer. Lines required in a\nwiring diagram are proportional to n. Execution time is proportional to the\nsquare of n."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0510039v1", 
    "title": "DyNoC: A Dynamic Infrastructure for Communication in Dynamically   Reconfigurable Devices", 
    "arxiv-id": "cs/0510039v1", 
    "author": "Jan van der Veen", 
    "publish": "2005-10-14T22:03:45Z", 
    "summary": "A new paradigm to support the communication among modules dynamically placed\non a reconfigurable device at run-time is presented. Based on the network on\nchip (NoC) infrastructure, we developed a dynamic communication infrastructure\nas well as routing methodologies capable to handle routing in a NoC with\nobstacles created by dynamically placed components. We prove the unrestricted\nreachability of components and pins, the deadlock-freeness and we finally show\nthe feasibility of our approach by means on real life example applications."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0602096v1", 
    "title": "Difficulties in the Implementation of Quantum Computers", 
    "arxiv-id": "cs/0602096v1", 
    "author": "Abhilash Ponnath", 
    "publish": "2006-02-27T18:59:39Z", 
    "summary": "This paper reviews various engineering hurdles facing the field of quantum\ncomputing. Specifically, problems related to decoherence, state preparation,\nerror correction, and implementability of gates are considered."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0603088v1", 
    "title": "Novel BCD Adders and Their Reversible Logic Implementation for IEEE 754r   Format", 
    "arxiv-id": "cs/0603088v1", 
    "author": "M. B Srinivas", 
    "publish": "2006-03-22T18:11:40Z", 
    "summary": "IEEE 754r is the ongoing revision to the IEEE 754 floating point standard and\na major enhancement to the standard is the addition of decimal format. This\npaper proposes two novel BCD adders called carry skip and carry look-ahead BCD\nadders respectively. Furthermore, in the recent years, reversible logic has\nemerged as a promising technology having its applications in low power CMOS,\nquantum computing, nanotechnology, and optical computing. It is not possible to\nrealize quantum computing without reversible logic. Thus, this paper also paper\nprovides the reversible logic implementation of the conventional BCD adder as\nthe well as the proposed Carry Skip BCD adder using a recently proposed TSG\ngate. Furthermore, a new reversible gate called TS-3 is also being proposed and\nit has been shown that the proposed reversible logic implementation of the BCD\nAdders is much better compared to recently proposed one, in terms of number of\nreversible gates used and garbage outputs produced. The reversible BCD circuits\ndesigned and proposed here form the basis of the decimal ALU of a primitive\nquantum CPU."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0603091v1", 
    "title": "A New Reversible TSG Gate and Its Application For Designing Efficient   Adder Circuits", 
    "arxiv-id": "cs/0603091v1", 
    "author": "M. B Srinivas", 
    "publish": "2006-03-23T06:44:34Z", 
    "summary": "In the recent years, reversible logic has emerged as a promising technology\nhaving its applications in low power CMOS, quantum computing, nanotechnology,\nand optical computing. The classical set of gates such as AND, OR, and EXOR are\nnot reversible. This paper proposes a new 4 * 4 reversible gate called TSG\ngate. The proposed gate is used to design efficient adder units. The most\nsignificant aspect of the proposed gate is that it can work singly as a\nreversible full adder i.e reversible full adder can now be implemented with a\nsingle gate only. The proposed gate is then used to design reversible ripple\ncarry and carry skip adders. It is demonstrated that the adder architectures\ndesigned using the proposed gate are much better and optimized, compared to\ntheir existing counterparts in literature; in terms of number of reversible\ngates and garbage outputs. Thus, this paper provides the initial threshold to\nbuilding of more complex system which can execute more complicated operations\nusing reversible logic."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0603092v1", 
    "title": "An Extension to DNA Based Fredkin Gate Circuits: Design of Reversible   Sequential Circuits using Fredkin Gates", 
    "arxiv-id": "cs/0603092v1", 
    "author": "M. B Srinivas", 
    "publish": "2006-03-23T08:33:08Z", 
    "summary": "In recent years, reversible logic has emerged as a promising computing\nparadigm having its applications in low power computing, quantum computing,\nnanotechnology, optical computing and DNA computing. The classical set of gates\nsuch as AND, OR, and EXOR are not reversible. Recently, it has been shown how\nto encode information in DNA and use DNA amplification to implement Fredkin\ngates. Furthermore, in the past Fredkin gates have been constructed using DNA,\nwhose outputs are used as inputs for other Fredkin gates. Thus, it can be\nconcluded that arbitrary circuits of Fredkin gates can be constructed using\nDNA. This paper provides the initial threshold to building of more complex\nsystem having reversible sequential circuits and which can execute more\ncomplicated operations. The novelty of the paper is the reversible designs of\nsequential circuits using Fredkin gate. Since, Fredkin gate has already been\nrealized using DNA, it is expected that this work will initiate the building of\ncomplex systems using DNA. The reversible circuits designed here are highly\noptimized in terms of number of gates and garbage outputs. The modularization\napproach that is synthesizing small circuits and thereafter using them to\nconstruct bigger circuits is used for designing the optimal reversible\nsequential circuits."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0605004v1", 
    "title": "Novel Reversible Multiplier Architecture Using Reversible TSG Gate", 
    "arxiv-id": "cs/0605004v1", 
    "author": "M. B Srinivas", 
    "publish": "2006-05-01T09:34:32Z", 
    "summary": "In the recent years, reversible logic has emerged as a promising technology\nhaving its applications in low power CMOS, quantum computing, nanotechnology,\nand optical computing. The classical set of gates such as AND, OR, and EXOR are\nnot reversible. Recently a 4 * 4 reversible gate called TSG is proposed. The\nmost significant aspect of the proposed gate is that it can work singly as a\nreversible full adder, that is reversible full adder can now be implemented\nwith a single gate only. This paper proposes a NXN reversible multiplier using\nTSG gate. It is based on two concepts. The partial products can be generated in\nparallel with a delay of d using Fredkin gates and thereafter the addition can\nbe reduced to log2N steps by using reversible parallel adder designed from TSG\ngates. Similar multiplier architecture in conventional arithmetic (using\nconventional logic) has been reported in existing literature, but the proposed\none in this paper is totally based on reversible logic and reversible cells as\nits building block. A 4x4 architecture of the proposed reversible multiplier is\nalso designed. It is demonstrated that the proposed multiplier architecture\nusing the TSG gate is much better and optimized, compared to its existing\ncounterparts in literature; in terms of number of reversible gates and garbage\noutputs. Thus, this paper provides the initial threshold to building of more\ncomplex system which can execute more complicated operations using reversible\nlogic."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0605125v1", 
    "title": "Combinational Logic Circuit Design with the Buchberger Algorithm", 
    "arxiv-id": "cs/0605125v1", 
    "author": "Germain Drolet", 
    "publish": "2006-05-26T18:43:13Z", 
    "summary": "We detail a procedure for the computation of the polynomial form of an\nelectronic combinational circuit from the design equations in a truth table.\nThe method uses the Buchberger algorithm rather than current traditional\nmethods based on search algorithms. We restrict the analysis to a single\noutput, but the procedure can be generalized to multiple outputs. The procedure\nis illustrated with the design of a simple arithmetic and logic unit with two\n3-bit operands and two control bits."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0605142v1", 
    "title": "Int\u00e9gration de la synth\u00e8se m\u00e9moire dans l'outil de   synth\u00e8se d'architecture GAUT Low Power", 
    "arxiv-id": "cs/0605142v1", 
    "author": "Eric Martin", 
    "publish": "2006-05-30T15:04:18Z", 
    "summary": "The systems supporting signal and image applications process large amount of\ndata. That involves an intensive use of the memory which becomes the bottleneck\nof systems. Memory limits performances and represents a significant proportion\nof total consumption. In the development high level synthesis tool called GAUT\nLow Power, we are interested in the synthesis of the memory unit. In this work,\nwe integrate the data storage and data transfert to constraint the high level\nsynthesis of the datapath's execution unit."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0605143v1", 
    "title": "High-level synthesis under I/O Timing and Memory constraints", 
    "arxiv-id": "cs/0605143v1", 
    "author": "Eric Martin", 
    "publish": "2006-05-30T15:07:51Z", 
    "summary": "The design of complex Systems-on-Chips implies to take into account\ncommunication and memory access constraints for the integration of dedicated\nhardware accelerator. In this paper, we present a methodology and a tool that\nallow the High-Level Synthesis of DSP algorithm, under both I/O timing and\nmemory constraints. Based on formal models and a generic architecture, this\ntool helps the designer to find a reasonable trade-off between both the\nrequired I/O timing behavior and the internal memory access parallelism of the\ncircuit. The interest of our approach is demonstrated on the case study of a\nFFT algorithm."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0605144v1", 
    "title": "A Memory Aware High Level Synthesis Too", 
    "arxiv-id": "cs/0605144v1", 
    "author": "Eric Martin", 
    "publish": "2006-05-30T15:09:18Z", 
    "summary": "We introduce a new approach to take into account the memory architecture and\nthe memory mapping in High- Level Synthesis for data intensive applications. We\nformalize the memory mapping as a set of constraints for the synthesis, and\ndefined a Memory Constraint Graph and an accessibility criterion to be used in\nthe scheduling step. We use a memory mapping file to include those memory\nconstraints in our HLS tool GAUT. It is possible, with the help of GAUT, to\nexplore a wide range of solutions, and to reach a good tradeoff between time,\npower-consumption, and area."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0605145v1", 
    "title": "Memory Aware High-Level Synthesis for Embedded Systems", 
    "arxiv-id": "cs/0605145v1", 
    "author": "Eric Martin", 
    "publish": "2006-05-30T15:09:32Z", 
    "summary": "We introduce a new approach to take into account the memory architecture and\nthe memory mapping in the High- Level Synthesis of Real-Time embedded systems.\nWe formalize the memory mapping as a set of constraints used in the scheduling\nstep. We use a memory mapping file to include those memory constraints in our\nHLS tool GAUT. Our scheduling algorithm exhibits a relatively low complexity\nthat permits to tackle complex designs in a reasonable time. Finally, we show\nhow to explore, with the help of GAUT, a wide range of solutions, and to reach\na good tradeoff between time, power-consumption, and area."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IWRSP.1998.676682", 
    "link": "http://arxiv.org/pdf/cs/0605146v1", 
    "title": "Synth\u00e8se Comportementale Sous Contraintes de Communication et de   Placement M\u00e9moire pour les composants du TDSI", 
    "arxiv-id": "cs/0605146v1", 
    "author": "Eric Martin", 
    "publish": "2006-05-30T15:10:57Z", 
    "summary": "The design of complex Digital Signal Processing systems implies to minimize\narchitectural cost and to maximize timing performances while taking into\naccount communication and memory accesses constraints for the integration of\ndedicated hardware accelerator. Unfortunately, the traditional Matlab/ Simulink\ndesign flows gather not very flexible hardware blocs. In this paper, we present\na methodology and a tool that permit the High-Level Synthesis of DSP\napplications, under both I/O timing and memory constraints. Based on formal\nmodels and a generic architecture, our tool GAUT helps the designer in finding\na reasonable trade-off between the circuit's performance and its architectural\ncomplexity. The efficiency of our approach is demonstrated on the case study of\na FFT algorithm."
},{
    "category": "cs.AR", 
    "doi": "10.1016/j.advengsoft.2005.01.010", 
    "link": "http://arxiv.org/pdf/cs/0608075v1", 
    "title": "Design of multimedia processor based on metric computation", 
    "arxiv-id": "cs/0608075v1", 
    "author": "Mohamed Abid", 
    "publish": "2006-08-18T13:12:55Z", 
    "summary": "Media-processing applications, such as signal processing, 2D and 3D graphics\nrendering, and image compression, are the dominant workloads in many embedded\nsystems today. The real-time constraints of those media applications have\ntaxing demands on today's processor performances with low cost, low power and\nreduced design delay. To satisfy those challenges, a fast and efficient\nstrategy consists in upgrading a low cost general purpose processor core. This\napproach is based on the personalization of a general RISC processor core\naccording the target multimedia application requirements. Thus, if the extra\ncost is justified, the general purpose processor GPP core can be enforced with\ninstruction level coprocessors, coarse grain dedicated hardware, ad hoc\nmemories or new GPP cores. In this way the final design solution is tailored to\nthe application requirements. The proposed approach is based on three main\nsteps: the first one is the analysis of the targeted application using\nefficient metrics. The second step is the selection of the appropriate\narchitecture template according to the first step results and recommendations.\nThe third step is the architecture generation. This approach is experimented\nusing various image and video algorithms showing its feasibility."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICICS.2005.1689293", 
    "link": "http://arxiv.org/pdf/cs/0609023v1", 
    "title": "Novel Reversible TSG Gate and Its Application for Designing Components   of Primitive Reversible/Quantum ALU", 
    "arxiv-id": "cs/0609023v1", 
    "author": "M. B. Srinivas", 
    "publish": "2006-09-06T16:09:04Z", 
    "summary": "In recent years, reversible logic has emerged as a promising computing\nparadigm having application in low power CMOS, quantum computing,\nnanotechnology, and optical computing. The classical set of gates such as AND,\nOR, and EXOR are not reversible. This paper utilizes a new 4 * 4 reversible\ngate called TSG gate to build the components of a primitive reversible/quantum\nALU. The most significant aspect of the TSG gate is that it can work singly as\na reversible full adder, that is reversible full adder can now be implemented\nwith a single gate only. A Novel reversible 4:2 compressor is also designed\nfrom the TSG gate which is later used to design a novel 8x8 reversible Wallace\ntree multiplier. It is proved that the adder, 4:2 compressor and multiplier\narchitectures designed using the TSG gate are better than their counterparts\navailable in literature, in terms of number of reversible gates and garbage\noutputs. This is perhaps, the first attempt to design a reversible 4:2\ncompressor and a reversible Wallace tree multiplier as far as existing\nliterature and our knowledge is concerned. Thus, this paper provides an initial\nthreshold to build more complex systems which can execute complicated\noperations using reversible logic."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICICS.2005.1689293", 
    "link": "http://arxiv.org/pdf/cs/0609028v1", 
    "title": "VLSI Implementation of RSA Encryption System Using Ancient Indian Vedic   Mathematics", 
    "arxiv-id": "cs/0609028v1", 
    "author": "M. B Srinivas", 
    "publish": "2006-09-07T14:18:41Z", 
    "summary": "This paper proposes the hardware implementation of RSA encryption/decryption\nalgorithm using the algorithms of Ancient Indian Vedic Mathematics that have\nbeen modified to improve performance. The recently proposed hierarchical\noverlay multiplier architecture is used in the RSA circuitry for multiplication\noperation. The most significant aspect of the paper is the development of a\ndivision architecture based on Straight Division algorithm of Ancient Indian\nVedic Mathematics and embedding it in RSA encryption/decryption circuitry for\nimproved efficiency. The coding is done in Verilog HDL and the FPGA synthesis\nis done using Xilinx Spartan library. The results show that RSA circuitry\nimplemented using Vedic division and multiplication is efficient in terms of\narea/speed compared to its implementation using conventional multiplication and\ndivision architectures"
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICICS.2005.1689293", 
    "link": "http://arxiv.org/pdf/cs/0609029v1", 
    "title": "Reversible Programmable Logic Array (RPLA) using Fredkin & Feynman Gates   for Industrial Electronics and Applications", 
    "arxiv-id": "cs/0609029v1", 
    "author": "Hamid R. Arabnia", 
    "publish": "2006-09-07T14:25:21Z", 
    "summary": "In recent years, reversible logic has emerged as a promising computing\nparadigm having application in low power CMOS, quantum computing,\nnanotechnology, and optical computing. The classical set of gates such as AND,\nOR, and EXOR are not reversible. In this paper, the authors have proposed\nreversible programmable logic array (RPLA) architecture using reversible\nFredkin and Feynman gates. The proposed RPLA has n inputs and m outputs and can\nrealize m functions of n variables. In order to demonstrate the design of RPLA,\na 3 input RPLA is designed which can perform any 28 functions using the\ncombination of 8 min terms (23). Furthermore, the application of the designed 3\ninput RPLA is shown by implementing the full adder and full subtractor\nfunctions through it."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICICS.2005.1689293", 
    "link": "http://arxiv.org/pdf/cs/0609036v1", 
    "title": "Reduced Area Low Power High Throughput BCD Adders for IEEE 754r Format", 
    "arxiv-id": "cs/0609036v1", 
    "author": "M. B Srinivas", 
    "publish": "2006-09-08T05:36:20Z", 
    "summary": "IEEE 754r is the ongoing revision to the IEEE 754 floating point standard and\na major enhancement to the standard is the addition of decimal format. Firstly,\nthis paper proposes novel two transistor AND and OR gates. The proposed AND\ngate has no power supply, thus it can be referred as the Powerless AND gate.\nSimilarly, the proposed two transistor OR gate has no ground and can be\nreferred as Groundless OR. Secondly for IEEE 754r format, two novel BCD adders\ncalled carry skip and carry look-ahead BCD adders are also proposed in this\npaper. In order to design the carry look-ahead BCD adder, a novel 4 bit carry\nlook-ahead adder called NCLA is proposed which forms the basic building block\nof the proposed carry look-ahead BCD adder. Finally, the proposed two\ntransistors AND and OR gates are used to provide the optimized small area low\npower high throughput circuitries of the proposed BCD adders."
},{
    "category": "cs.AR", 
    "doi": "10.1109/MWSCAS.2006.382306", 
    "link": "http://arxiv.org/pdf/cs/0610090v1", 
    "title": "Combined Integer and Floating Point Multiplication Architecture(CIFM)   for FPGAs and Its Reversible Logic Implementation", 
    "arxiv-id": "cs/0610090v1", 
    "author": "A. P Vinod", 
    "publish": "2006-10-14T10:39:42Z", 
    "summary": "In this paper, the authors propose the idea of a combined integer and\nfloating point multiplier(CIFM) for FPGAs. The authors propose the replacement\nof existing 18x18 dedicated multipliers in FPGAs with dedicated 24x24\nmultipliers designed with small 4x4 bit multipliers. It is also proposed that\nfor every dedicated 24x24 bit multiplier block designed with 4x4 bit\nmultipliers, four redundant 4x4 multiplier should be provided to enforce the\nfeature of self repairability (to recover from the faults). In the proposed\nCIFM reconfigurability at run time is also provided resulting in low power. The\nmajor source of motivation for providing the dedicated 24x24 bit multiplier\nstems from the fact that single precision floating point multiplier requires\n24x24 bit integer multiplier for mantissa multiplication. A reconfigurable,\nself-repairable 24x24 bit multiplier (implemented with 4x4 bit multiply\nmodules) will ideally suit this purpose, making FPGAs more suitable for integer\nas well floating point operations. A dedicated 4x4 bit multiplier is also\nproposed in this paper. Moreover, in the recent years, reversible logic has\nemerged as a promising technology having its applications in low power CMOS,\nquantum computing, nanotechnology, and optical computing. It is not possible to\nrealize quantum computing without reversible logic. Thus, this paper also paper\nprovides the reversible logic implementation of the proposed CIFM. The\nreversible CIFM designed and proposed here will form the basis of the\ncompletely reversible FPGAs."
},{
    "category": "cs.AR", 
    "doi": "10.1109/MWSCAS.2006.382306", 
    "link": "http://arxiv.org/pdf/0706.1692v1", 
    "title": "A Methodology for Efficient Space-Time Adapter Design Space Exploration:   A Case Study of an Ultra Wide Band Interleaver", 
    "arxiv-id": "0706.1692v1", 
    "author": "Eric Martin", 
    "publish": "2007-06-12T13:45:50Z", 
    "summary": "This paper presents a solution to efficiently explore the design space of\ncommunication adapters. In most digital signal processing (DSP) applications,\nthe overall architecture of the system is significantly affected by\ncommunication architecture, so the designers need specifically optimized\nadapters. By explicitly modeling these communications within an effective\ngraph-theoretic model and analysis framework, we automatically generate an\noptimized architecture, named Space-Time AdapteR (STAR). Our design flow inputs\na C description of Input/Output data scheduling, and user requirements\n(throughput, latency, parallelism...), and formalizes communication constraints\nthrough a Resource Constraints Graph (RCG). The RCG properties enable an\nefficient architecture space exploration in order to synthesize a STAR\ncomponent. The proposed approach has been tested to design an industrial data\nmixing block example: an Ultra-Wideband interleaver."
},{
    "category": "cs.AR", 
    "doi": "10.1109/MWSCAS.2006.382306", 
    "link": "http://arxiv.org/pdf/0706.2732v1", 
    "title": "A Design Methodology for Space-Time Adapter", 
    "arxiv-id": "0706.2732v1", 
    "author": "Eric Martin", 
    "publish": "2007-06-19T14:18:57Z", 
    "summary": "This paper presents a solution to efficiently explore the design space of\ncommunication adapters. In most digital signal processing (DSP) applications,\nthe overall architecture of the system is significantly affected by\ncommunication architecture, so the designers need specifically optimized\nadapters. By explicitly modeling these communications within an effective\ngraph-theoretic model and analysis framework, we automatically generate an\noptimized architecture, named Space-Time AdapteR (STAR). Our design flow inputs\na C description of Input/Output data scheduling, and user requirements\n(throughput, latency, parallelism...), and formalizes communication constraints\nthrough a Resource Constraints Graph (RCG). The RCG properties enable an\nefficient architecture space exploration in order to synthesize a STAR\ncomponent. The proposed approach has been tested to design an industrial data\nmixing block example: an Ultra-Wideband interleaver."
},{
    "category": "cs.AR", 
    "doi": "10.1109/MWSCAS.2006.382306", 
    "link": "http://arxiv.org/pdf/0706.2824v1", 
    "title": "M\u00e9thodologie de mod\u00e9lisation et d'impl\u00e9mentation d'adaptateurs   spatio-temporels", 
    "arxiv-id": "0706.2824v1", 
    "author": "Eric Martin", 
    "publish": "2007-06-19T15:56:43Z", 
    "summary": "The re-use of pre-designed blocks is a well-known concept of the software\ndevelopment. This technique has been applied to System-on-Chip (SoC) design\nwhose complexity and heterogeneity are growing. The re-use is made thanks to\nhigh level components, called virtual components (IP), available in more or\nless flexible forms. These components are dedicated blocks: digital signal\nprocessing (DCT, FFT), telecommunications (Viterbi, TurboCodes),... These\nblocks rest on a model of fixed architecture with very few degrees of\npersonalization. This rigidity is particularly true for the communication\ninterface whose orders of acquisition and production of data, the temporal\nbehavior and protocols of exchanges are fixed. The successful integration of\nsuch an IP requires that the designer (1) synchronizes the components (2)\nconverts the protocols between \"incompatible\" blocks (3) temporizes the data to\nguarantee the temporal constraints and the order of the data. This phase\nremains however very manual and source of errors. Our approach proposes a\nformal modeling, based on an original Ressource Compatibility Graph. The\nsynthesis flow is based on a set of transformations of the initial graph to\nlead to an interface architecture allowing the space-time adaptation of the\ndata exchanges between several components."
},{
    "category": "cs.AR", 
    "doi": "10.1109/MWSCAS.2006.382306", 
    "link": "http://arxiv.org/pdf/0707.1151v6", 
    "title": "Logic, Design & Organization of PTVD-SHAM; A Parallel Time Varying &   Data Super-helical Access Memory", 
    "arxiv-id": "0707.1151v6", 
    "author": "P. B. Alipour", 
    "publish": "2007-07-09T19:26:06Z", 
    "summary": "This paper encompasses a super helical memory system's design, 'Boolean logic\n& image-logic' as a theoretical concept of an invention-model to 'store\ntime-data' in terms of anticipating the best memory location ever for\ndata/time. A waterfall effect is deemed to assist the process of\npotential-difference output-switch into diverse logic states in quantum dot\ncomputational methods via utilizing coiled carbon nanotubes (CCNTs) and carbon\nnanotube field effect transistors (CNFETs). A 'quantum confinement' is thus\nderived for a flow of particles in a categorized quantum well substrate with a\nnormalized capacitance rectifying high B-field flux into electromagnetic\ninduction. Multi-access of coherent sequences of 'qubit addressing' is gained\nin any magnitude as pre-defined for the orientation of array displacement.\nBriefly, Gaussian curvature of k<0 is debated in aim of specifying the 2D\nelectron gas characteristics in scenarios where data is stored in short\nintervals versus long ones e.g. when k'>(k<0) for greater CCNT diameters,\nspace-time continuum is folded by chance for the particle. This benefits from\nMaxwell-Lorentz theory in Minkowski's space-time viewpoint alike to crystal\noscillators for precise data timing purposes and radar systems e.g., time\nvarying self-clocking devices in diverse geographic locations. This application\ncould also be optional for data depository versus extraction, in the best\nsupercomputer system's locations, autonomously. For best performance in\nminimizing current limiting mechanisms including electromigration, a multilevel\nmetallization and implant process forming elevated sources/drains for the\ncircuit's staircase pyramidal construction, is discussed accordingly."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.124", 
    "link": "http://arxiv.org/pdf/0710.3443v1", 
    "title": "DPA on quasi delay insensitive asynchronous circuits: formalization and   improvement", 
    "arxiv-id": "0710.3443v1", 
    "author": "F. Germain", 
    "publish": "2007-10-18T06:57:52Z", 
    "summary": "The purpose of this paper is to formally specify a flow devoted to the design\nof Differential Power Analysis (DPA) resistant QDI asynchronous circuits. The\npaper first proposes a formal modeling of the electrical signature of QDI\nasynchronous circuits. The DPA is then applied to the formal model in order to\nidentify the source of leakage of this type of circuits. Finally, a complete\ndesign flow is specified to minimize the information leakage. The relevancy and\nefficiency of the approach is demonstrated using the design of an AES\ncrypto-processor."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.124", 
    "link": "http://arxiv.org/pdf/0710.3535v2", 
    "title": "JANUS: an FPGA-based System for High Performance Scientific Computing", 
    "arxiv-id": "0710.3535v2", 
    "author": "J. L. Velasco", 
    "publish": "2007-10-18T15:26:32Z", 
    "summary": "This paper describes JANUS, a modular massively parallel and reconfigurable\nFPGA-based computing system. Each JANUS module has a computational core and a\nhost. The computational core is a 4x4 array of FPGA-based processing elements\nwith nearest-neighbor data links. Processors are also directly connected to an\nI/O node attached to the JANUS host, a conventional PC. JANUS is tailored for,\nbut not limited to, the requirements of a class of hard scientific applications\ncharacterized by regular code structure, unconventional data manipulation\ninstructions and not too large data-base size. We discuss the architecture of\nthis configurable machine, and focus on its use on Monte Carlo simulations of\nstatistical mechanics. On this class of application JANUS achieves impressive\nperformances: in some cases one JANUS processing element outperfoms high-end\nPCs by a factor ~ 1000. We also discuss the role of JANUS on other classes of\nscientific applications."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.124", 
    "link": "http://arxiv.org/pdf/0710.3789v1", 
    "title": "Frequency Analysis of Decoupling Capacitors for Three Voltage Supplies   in SoC", 
    "arxiv-id": "0710.3789v1", 
    "author": "Mohd Abubakr", 
    "publish": "2007-10-19T20:59:53Z", 
    "summary": "Reduction in power consumption has become a major criterion of design in\nmodern ICs. One such scheme to reduce power consumption by an IC is the use of\nmultiple power supplies for critical and non-critical paths. To maintain the\nimpedance of a power distribution system below a specified level, multiple\ndecoupling capacitors are placed at different levels of power grid hierarchy.\nThis paper describes about three-voltage supply power distribution systems. The\nnoise at one power supply can propagate to the other power supply, causing\npower and signal integrity problems in the overall system. Effects such as\nanti-resonance and remedies for these effects are studied. Impedance of the\nthree-voltage supply power distribution system is calculated in terms of\nRLC-model of decoupling capacitors. Further the obtained impedance depends on\nthe frequency; hence brief frequency analysis of impedance is done."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.124", 
    "link": "http://arxiv.org/pdf/0710.4630v1", 
    "title": "CAFFEINE: Template-Free Symbolic Model Generation of Analog Circuits via   Canonical Form Functions and Genetic Programming", 
    "arxiv-id": "0710.4630v1", 
    "author": "Georges Gielen", 
    "publish": "2007-10-25T08:07:11Z", 
    "summary": "This paper presents a method to automatically generate compact symbolic\nperformance models of analog circuits with no prior specification of an\nequation template. The approach takes SPICE simulation data as input, which\nenables modeling of any nonlinear circuits and circuit characteristics. Genetic\nprogramming is applied as a means of traversing the space of possible symbolic\nexpressions. A grammar is specially designed to constrain the search to a\ncanonical form for functions. Novel evolutionary search operators are designed\nto exploit the structure of the grammar. The approach generates a set of\nsymbolic models which collectively provide a tradeoff between error and model\ncomplexity. Experimental results show that the symbolic models generated are\ncompact and easy to understand, making this an effective method for aiding\nunderstanding in analog design. The models also demonstrate better prediction\nquality than posynomials."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.124", 
    "link": "http://arxiv.org/pdf/0710.4632v1", 
    "title": "Hardware Support for Arbitrarily Complex Loop Structures in Embedded   Applications", 
    "arxiv-id": "0710.4632v1", 
    "author": "Spiridon Nikolaidis", 
    "publish": "2007-10-25T08:07:52Z", 
    "summary": "In this paper, the program control unit of an embedded RISC processor is\nenhanced with a novel zero-overhead loop controller (ZOLC) supporting arbitrary\nloop structures with multiple-entry/exit nodes. The ZOLC has been incorporated\nto an open RISC processor core to evaluate the performance of the proposed unit\nfor alternative configurations of the selected processor. It is proven that\nspeed improvements of 8.4% to 48.2% are feasible for the used benchmarks."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4634v1", 
    "title": "A Probabilistic Collocation Method Based Statistical Gate Delay Model   Considering Process Variations and Multiple Input Switching", 
    "arxiv-id": "0710.4634v1", 
    "author": "Janet Wang", 
    "publish": "2007-10-25T08:08:50Z", 
    "summary": "Since the advent of new nanotechnologies, the variability of gate delay due\nto process variations has become a major concern. This paper proposes a new\ngate delay model that includes impact from both process variations and multiple\ninput switching. The proposed model uses orthogonal polynomial based\nprobabilistic collocation method to construct a delay analytical equation from\ncircuit timing performance. From the experimental results, our approach has\nless that 0.2% error on the mean delay of gates and less than 3% error on the\nstandard deviation."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4636v1", 
    "title": "Why Systems-on-Chip Needs More UML like a Hole in the Head", 
    "arxiv-id": "0710.4636v1", 
    "author": "Campbell Mccausland", 
    "publish": "2007-10-25T08:09:23Z", 
    "summary": "Let's be clear from the outset: SoC can most certainly make use of UML; SoC\njust doesn't need more UML, or even all of it. The advent of model mappings,\ncoupled with marks that indicate which mapping rule to apply, enable a major\nsimplification of the use of UML in SoC."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4638v1", 
    "title": "Buffer Insertion for Bridges and Optimal Buffer Sizing for Communication   Sub-System of Systems-on-Chip", 
    "arxiv-id": "0710.4638v1", 
    "author": "Eugene A. Feinberg", 
    "publish": "2007-10-25T08:10:40Z", 
    "summary": "We have presented an optimal buffer sizing and buffer insertion methodology\nwhich uses stochastic models of the architecture and Continuous Time Markov\nDecision Processes CTMDPs. Such a methodology is useful in managing the scarce\nbuffer resources available on chip as compared to network based data\ncommunication which can have large buffer space. The modeling of this problem\nin terms of a CT-MDP framework lead to a nonlinear formulation due to usage of\nbridges in the bus architecture. We present a methodology to split the problem\ninto several smaller though linear systems and we then solve these subsystems."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4639v1", 
    "title": "Modeling the Non-Linear Behavior of Library Cells for an Accurate Static   Noise Analysis", 
    "arxiv-id": "0710.4639v1", 
    "author": "Davide Pandini", 
    "publish": "2007-10-25T08:11:06Z", 
    "summary": "In signal integrity analysis, the joint effect of propagated noise through\nlibrary cells, and of the noise injected on a quiet net by neighboring\nswitching nets through coupling capacitances, must be considered in order to\naccurately estimate the overall noise impact on design functionality and\nperformances. In this work the impact of the cell non-linearity on the noise\nglitch waveform is analyzed in detail, and a new macromodel that allows to\naccurately and efficiently modeling the non-linear effects of the victim driver\nin noise analysis is presented. Experimental results demonstrate the\neffectiveness of our method, and confirm that existing noise analysis\napproaches based on linear superposition of the propagated and\ncrosstalk-injected noise can be highly inaccurate, thus impairing the sign-off\nfunctional verification phase."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4644v1", 
    "title": "Cycle Accurate Binary Translation for Simulation Acceleration in Rapid   Prototyping of SoCs", 
    "arxiv-id": "0710.4644v1", 
    "author": "Wolfgang Rosenstiel", 
    "publish": "2007-10-25T08:18:14Z", 
    "summary": "In this paper, the application of a cycle accurate binary translator for\nrapid prototyping of SoCs will be presented. This translator generates code to\nrun on a rapid prototyping system consisting of a VLIW processor and FPGAs. The\ngenerated code is annotated with information that triggers cycle generation for\nthe hardware in parallel to the execution of the translated program. The VLIW\nprocessor executes the translated program whereas the FPGAs contain the\nhardware for the parallel cycle generation and the bus interface that adapts\nthe bus of the VLIW processor to the SoC bus of the emulated processor core."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4645v1", 
    "title": "At-Speed Logic BIST for IP Cores", 
    "arxiv-id": "0710.4645v1", 
    "author": "S. Wu", 
    "publish": "2007-10-25T08:19:34Z", 
    "summary": "This paper describes a flexible logic BIST scheme that features high fault\ncoverage achieved by fault-simulation guided test point insertion, real\nat-speed test capability for multi-clock designs without clock frequency\nmanipulation, and easy physical implementation due to the use of a low-speed SE\nsignal. Application results of this scheme to two widely used IP cores are also\nreported."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4646v1", 
    "title": "Fast Dynamic Memory Integration in Co-Simulation Frameworks for   Multiprocessor System on-Chip", 
    "arxiv-id": "0710.4646v1", 
    "author": "G. Palermo", 
    "publish": "2007-10-25T08:20:27Z", 
    "summary": "In this paper is proposed a technique to integrate and simulate a dynamic\nmemory in a multiprocessor framework based on C/C++/SystemC. Using host\nmachine's memory management capabilities, dynamic data processing is supported\nwithout compromising speed and accuracy of the simulation. A first prototype in\na shared memory context is presented."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4649v1", 
    "title": "Stochastic Power Grid Analysis Considering Process Variations", 
    "arxiv-id": "0710.4649v1", 
    "author": "Janet Wang", 
    "publish": "2007-10-25T08:24:02Z", 
    "summary": "In this paper, we investigate the impact of interconnect and device process\nvariations on voltage fluctuations in power grids. We consider random\nvariations in the power grid's electrical parameters as spatial stochastic\nprocesses and propose a new and efficient method to compute the stochastic\nvoltage response of the power grid. Our approach provides an explicit\nanalytical representation of the stochastic voltage response using orthogonal\npolynomials in a Hilbert space. The approach has been implemented in a\nprototype software called OPERA (Orthogonal Polynomial Expansions for Response\nAnalysis). Use of OPERA on industrial power grids demonstrated speed-ups of up\nto two orders of magnitude. The results also show a significant variation of\nabout $\\pm$ 35% in the nominal voltage drops at various nodes of the power\ngrids and demonstrate the need for variation-aware power grid analysis."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4652v1", 
    "title": "Locality-Aware Process Scheduling for Embedded MPSoCs", 
    "arxiv-id": "0710.4652v1", 
    "author": "Guilin Chen", 
    "publish": "2007-10-25T08:31:15Z", 
    "summary": "Utilizing on-chip caches in embedded multiprocessor-system-on-a-chip (MPSoC)\nbased systems is critical from both performance and power perspectives. While\nmost of the prior work that targets at optimizing cache behavior are performed\nat hardware and compilation levels, operating system (OS) can also play major\nrole as it sees the global access pattern information across applications. This\npaper proposes a cache-conscious OS process scheduling strategy based on data\nreuse. The proposed scheduler implements two complementary approaches. First,\nthe processes that do not share any data between them are scheduled at\ndifferent cores if it is possible to do so. Second, the processes that could\nnot be executed at the same time (due to dependences) but share data among each\nother are mapped to the same processor core so that they share the cache\ncontents. Our experimental results using this new data locality aware OS\nscheduling strategy are promising, and show significant improvements in task\ncompletion times."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4653v1", 
    "title": "Simultaneous Reduction of Dynamic and Static Power in Scan Structures", 
    "arxiv-id": "0710.4653v1", 
    "author": "Zainalabedin Navabi", 
    "publish": "2007-10-25T08:32:08Z", 
    "summary": "Power dissipation during test is a major challenge in testing integrated\ncircuits. Dynamic power has been the dominant part of power dissipation in CMOS\ncircuits, however, in future technologies the static portion of power\ndissipation will outreach the dynamic portion. This paper proposes an efficient\ntechnique to reduce both dynamic and static power dissipation in scan\nstructures. Scan cell outputs which are not on the critical path(s) are\nmultiplexed to fixed values during scan mode. These constant values and primary\ninputs are selected such that the transitions occurred on non-multiplexed scan\ncells are suppressed and the leakage current during scan mode is decreased. A\nmethod for finding these vectors is also proposed. Effectiveness of this\ntechnique is proved by experiments performed on ISCAS89 benchmark circuits."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4654v1", 
    "title": "Modeling Interconnect Variability Using Efficient Parametric Model Order   Reduction", 
    "arxiv-id": "0710.4654v1", 
    "author": "Sani R. Nassif", 
    "publish": "2007-10-25T08:33:14Z", 
    "summary": "Assessing IC manufacturing process fluctuations and their impacts on IC\ninterconnect performance has become unavoidable for modern DSM designs.\nHowever, the construction of parametric interconnect models is often hampered\nby the rapid increase in computational cost and model complexity. In this paper\nwe present an efficient yet accurate parametric model order reduction algorithm\nfor addressing the variability of IC interconnect performance. The efficiency\nof the approach lies in a novel combination of low-rank matrix approximation\nand multi-parameter moment matching. The complexity of the proposed parametric\nmodel order reduction is as low as that of a standard Krylov subspace method\nwhen applied to a nominal system. Under the projection-based framework, our\nalgorithm also preserves the passivity of the resulting parametric models."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4655v1", 
    "title": "A Fast Diagnosis Scheme for Distributed Small Embedded SRAMs", 
    "arxiv-id": "0710.4655v1", 
    "author": "Andre Ivanov", 
    "publish": "2007-10-25T08:34:09Z", 
    "summary": "This paper proposes a diagnosis scheme aimed at reducing diagnosis time of\ndistributed small embedded SRAMs (e-SRAMs). This scheme improves the one\nproposed in [A parallel built-in self-diagnostic method for embedded memory\nbuffers, A parallel built-in self-diagnostic method for embedded memory\narrays]. The improvements are mainly two-fold. On one hand, the diagnosis of\ntime-consuming Data Retention Faults (DRFs), which is neglected by the\ndiagnosis architecture in [A parallel built-in self-diagnostic method for\nembedded memory buffers, A parallel built-in self-diagnostic method for\nembedded memory arrays], is now considered and performed via a DFT technique\nreferred to as the \"No Write Recovery Test Mode (NWRTM)\". On the other hand, a\npair comprising a Serial to Parallel Converter (SPC) and a Parallel to Serial\nConverter (PSC) is utilized to replace the bi-directional serial interface, to\navoid the problems of serial fault masking and defect rate dependent diagnosis.\nResults from our evaluations show that the proposed diagnosis scheme achieves\nan increased diagnosis coverage and reduces diagnosis time compared to those\nobtained in [A parallel built-in self-diagnostic method for embedded memory\nbuffers, A parallel built-in self-diagnostic method for embedded memory\narrays], with neglectable extra area cost."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4656v1", 
    "title": "A Memory Hierarchical Layer Assigning and Prefetching Technique to   Overcome the Memory Performance/Energy Bottleneck", 
    "arxiv-id": "0710.4656v1", 
    "author": "Antonios Thanailakis", 
    "publish": "2007-10-25T08:34:32Z", 
    "summary": "The memory subsystem has always been a bottleneck in performance as well as\nsignificant power contributor in memory intensive applications. Many\nresearchers have presented multi-layered memory hierarchies as a means to\ndesign energy and performance efficient systems. However, most of the previous\nwork do not explore trade-offs systematically. We fill this gap by proposing a\nformalized technique that takes into consideration data reuse, limited lifetime\nof the arrays of an application and application specific prefetching\nopportunities, and performs a thorough trade-off exploration for different\nmemory layer sizes. This technique has been implemented on a prototype tool,\nwhich was tested successfully using nine real-life applications of industrial\nrelevance. Following this approach we have able to reduce execution time up to\n60%, and energy consumption up to 70%."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4657v1", 
    "title": "New Schemes for Self-Testing RAM", 
    "arxiv-id": "0710.4657v1", 
    "author": "A. Labunetz", 
    "publish": "2007-10-25T08:34:59Z", 
    "summary": "This paper gives an overview of a new technique, named pseudo-ring testing\n(PRT). PRT can be applied for testing wide type of random access memories\n(RAM): bit- or word-oriented and single- or dual-port RAM's. An essential\nparticularity of the proposed methodology is the emulation of a linear\nautomaton over Galois field by memory own components."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4659v1", 
    "title": "Synchronization Processor Synthesis for Latency Insensitive Systems", 
    "arxiv-id": "0710.4659v1", 
    "author": "Emmanuel Boutillon", 
    "publish": "2007-10-25T08:35:37Z", 
    "summary": "In this paper we present our contribution in terms of synchronization\nprocessor for a SoC design methodology based on the theory of the latency\ninsensitive systems (LIS) of Carloni et al. Our contribution consists in IP\nencapsulation into a new wrapper model which speed and area are optimized and\nsynthetizability guarantied. The main benefit of our approach is to preserve\nthe local IP performances when encapsulating them and reduce SoC silicon area."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4660v1", 
    "title": "Thermal-Aware Task Allocation and Scheduling for Embedded Systems", 
    "arxiv-id": "0710.4660v1", 
    "author": "M. J. Irwin", 
    "publish": "2007-10-25T08:36:55Z", 
    "summary": "Temperature affects not only the reliability but also the performance, power,\nand cost of the embedded system. This paper proposes a thermal-aware task\nallocation and scheduling algorithm for embedded systems. The algorithm is used\nas a sub-routine for hardware/software co-synthesis to reduce the peak\ntemperature and achieve a thermally even distribution while meeting real time\nconstraints. The paper investigates both power-aware and thermal-aware\napproaches to task allocation and scheduling. The experimental results show\nthat the thermal-aware approach outperforms the power-aware schemes in terms of\nmaximal and average temperature reductions. To the best of our knowledge, this\nis the first task allocation and scheduling algorithm that takes temperature\ninto consideration."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4661v1", 
    "title": "Bright-Field AAPSM Conflict Detection and Correction", 
    "arxiv-id": "0710.4661v1", 
    "author": "A. Zelikovsky", 
    "publish": "2007-10-25T08:37:31Z", 
    "summary": "As feature sizes shrink, it will be necessary to use AAPSM\n(Alternating-Aperture Phase Shift Masking) to image critical features,\nespecially on the polysilicon layer. This imposes additional constraints on the\nlayouts beyond traditional design rules. Of particular note is the requirement\nthat all critical features be flanked by opposite-phase shifters, while the\nshifters obey minimum width and spacing requirements. A layout is called\nphase-assignable if it satisfies this requirement. If a layout is not\nphase-assignable, the phase conflicts have to removed to enable the use of\nAAPSM for the layout. Previous work has sought to detect a suitable set of\nphase Conflicts to be removed, as well as correct them. The contribution of\nthis paper are the following: (1) a new approach to detect a minimal set of\nphase conflicts (also referred to as AAPSM conflicts), which when corrected\nwill produce a phase-assignable layout; (2) a novel layout modification scheme\nfor correcting these AAPSM conflicts. The proposed approach for conflict\ndetection shows significant improvements in the quality of results and runtime\nfor real industrial circuits, when compared to previous methods. To the best of\nour knowledge, this is the first time layout modification results are presented\nfor bright-field AAPSM. Our experiments show that the percentage area increase\nfor making a layout phase-assignable ranges from 0.7-11.8%."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4663v1", 
    "title": "Statistical Modeling of Pipeline Delay and Design of Pipeline under   Process Variation to Enhance Yield in sub-100nm Technologies", 
    "arxiv-id": "0710.4663v1", 
    "author": "Kaushik Roy", 
    "publish": "2007-10-25T08:41:06Z", 
    "summary": "Operating frequency of a pipelined circuit is determined by the delay of the\nslowest pipeline stage. However, under statistical delay variation in sub-100nm\ntechnology regime, the slowest stage is not readily identifiable and the\nestimation of the pipeline yield with respect to a target delay is a\nchallenging problem. We have proposed analytical models to estimate yield for a\npipelined design based on delay distributions of individual pipe stages. Using\nthe proposed models, we have shown that change in logic depth and imbalance\nbetween the stage delays can improve the yield of a pipeline. A statistical\nmethodology has been developed to optimally design a pipeline circuit for\nenhancing yield. Optimization results show that, proper imbalance among the\nstage delays in a pipeline improves design yield by 9% for the same area and\nperformance (and area reduction by about 8.4% under a yield constraint) over a\nbalanced design."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4665v1", 
    "title": "New Perspectives and Opportunities From the Wild West of Microelectronic   Biochips", 
    "arxiv-id": "0710.4665v1", 
    "author": "Roberto Guerrieri", 
    "publish": "2007-10-25T08:43:31Z", 
    "summary": "Application of Microelectronic to bioanalysis is an emerging field which\nholds great promise. From the standpoint of electronic and system design,\nbiochips imply a radical change of perspective, since new, completely different\nconstraints emerge while other usual constraints can be relaxed. While\nelectronic parts of the system can rely on the usual established design-flow,\nfluidic and packaging design, calls for a new approach which relies\nsignificantly on experiments. We hereby make some general considerations based\non our experience in the development of biochips for cell analysis."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4669v1", 
    "title": "SOC Testing Methodology and Practice", 
    "arxiv-id": "0710.4669v1", 
    "author": "Cheng-Wen Wu", 
    "publish": "2007-10-25T08:45:18Z", 
    "summary": "On a commercial digital still camera (DSC) controller chip we practice a\nnovel SOC test integration platform, solving real problems in test scheduling,\ntest IO reduction, timing of functional test, scan IO sharing, embedded memory\nbuilt-in self-test (BIST), etc. The chip has been fabricated and tested\nsuccessfully by our approach. Test results justify that short test integration\ncost, short test time, and small area overhead can be achieved. To support SOC\ntesting, a memory BIST compiler and an SOC testing integration system have been\ndeveloped."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4670v1", 
    "title": "Evolutionary Optimization in Code-Based Test Compression", 
    "arxiv-id": "0710.4670v1", 
    "author": "Bernd Becker", 
    "publish": "2007-10-25T08:45:52Z", 
    "summary": "We provide a general formulation for the code-based test compression problem\nwith fixed-length input blocks and propose a solution approach based on\nEvolutionary Algorithms. In contrast to existing code-based methods, we allow\nunspecified values in matching vectors, which allows encoding of arbitrary test\nsets using a relatively small number of code-words. Experimental results for\nboth stuck-at and path delay fault test sets for ISCAS circuits demonstrate an\nimprovement compared to existing techniques."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4671v1", 
    "title": "An Application-Specific Design Methodology for STbus Crossbar Generation", 
    "arxiv-id": "0710.4671v1", 
    "author": "Giovanni De Micheli", 
    "publish": "2007-10-25T08:46:59Z", 
    "summary": "As the communication requirements of current and future Multiprocessor\nSystems on Chips (MPSoCs) continue to increase, scalable communication\narchitectures are needed to support the heavy communication demands of the\nsystem. This is reflected in the recent trend that many of the standard bus\nproducts such as STbus, have now introduced the capability of designing a\ncrossbar with multiple buses operating in parallel. The crossbar configuration\nshould be designed to closely match the application traffic characteristics and\nperformance requirements. In this work we address this issue of\napplication-specific design of optimal crossbar (using STbus crossbar\narchitecture), satisfying the performance requirements of the application and\noptimal binding of cores onto the crossbar resources. We present a simulation\nbased design approach that is based on analysis of actual traffic trace of the\napplication, considering local variations in traffic rates, temporal overlap\namong traffic streams and criticality of traffic streams. Our methodology is\napplied to several MPSoC designs and the resulting crossbar platforms are\nvalidated for performance by cycle-accurate SystemC simulation of the designs.\nThe experimental case studies show large reduction in packet latencies (up to\n7x) and large crossbar component savings (up to 3.5x) compared to traditional\ndesign approaches."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4672v1", 
    "title": "Yield Enhancement of Digital Microfluidics-Based Biochips Using Space   Redundancy and Local Reconfiguration", 
    "arxiv-id": "0710.4672v1", 
    "author": "Vamsee K. Pamula", 
    "publish": "2007-10-25T08:47:40Z", 
    "summary": "As microfluidics-based biochips become more complex, manufacturing yield will\nhave significant influence on production volume and product cost. We propose an\ninterstitial redundancy approach to enhance the yield of biochips that are\nbased on droplet-based microfluidics. In this design method, spare cells are\nplaced in the interstitial sites within the microfluidic array, and they\nreplace neighboring faulty cells via local reconfiguration. The proposed design\nmethod is evaluated using a set of concurrent real-life bioassays."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4673v1", 
    "title": "Design of Fault-Tolerant and Dynamically-Reconfigurable Microfluidic   Biochips", 
    "arxiv-id": "0710.4673v1", 
    "author": "Krishnendu Chakrabarty", 
    "publish": "2007-10-25T08:48:12Z", 
    "summary": "Microfluidics-based biochips are soon expected to revolutionize clinical\ndiagnosis, DNA sequencing, and other laboratory procedures involving molecular\nbiology. Most microfluidic biochips are based on the principle of continuous\nfluid flow and they rely on permanently-etched microchannels, micropumps, and\nmicrovalves. We focus here on the automated design of \"digital\" droplet-based\nmicrofluidic biochips. In contrast to continuous-flow systems, digital\nmicrofluidics offers dynamic reconfigurability; groups of cells in a\nmicrofluidics array can be reconfigured to change their functionality during\nthe concurrent execution of a set of bioassays. We present a simulated\nannealing-based technique for module placement in such biochips. The placement\nprocedure not only addresses chip area, but it also considers fault tolerance,\nwhich allows a microfluidic module to be relocated elsewhere in the system when\na single cell is detected to be faulty. Simulation results are presented for a\ncase study involving the polymerase chain reaction."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4678v1", 
    "title": "CMOS-Based Biosensor Arrays", 
    "arxiv-id": "0710.4678v1", 
    "author": "H. -C. Hanke", 
    "publish": "2007-10-25T09:02:53Z", 
    "summary": "CMOS-based sensor array chips provide new and attractive features as compared\nto today's standard tools for medical, diagnostic, and biotechnical\napplications. Examples for molecule- and cell-based approaches and related\ncircuit design issues are discussed."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4679v1", 
    "title": "DVS for On-Chip Bus Designs Based on Timing Error Correction", 
    "arxiv-id": "0710.4679v1", 
    "author": "Todd Austin", 
    "publish": "2007-10-25T09:03:13Z", 
    "summary": "On-chip buses are typically designed to meet performance constraints at\nworst-case conditions, including process corner, temperature, IR-drop, and\nneighboring net switching pattern. This can result in significant performance\nslack at more typical operating conditions. In this paper, we propose a dynamic\nvoltage scaling (DVS) technique for buses, based on a double sampling latch\nwhich can detect and correct for delay errors without the need for\nretransmission. The proposed approach recovers the available slack at\nnon-worst-case operating points through more aggressive voltage scaling and\ntracks changing conditions by monitoring the error recovery rate. Voltage\nmargins needed in traditional designs to accommodate worst-case performance\nconditions are therefore eliminated, resulting in a significant improvement in\nenergy efficiency. The approach was implemented for a 6mm memory read bus\noperating at 1.5GHz (0.13 $\\mu$m technology node) and was simulated for a\nnumber of benchmark programs. Even at the worst-case process and environment\nconditions, energy gains of up to 17% are achieved, with error recovery rates\nunder 2.3%. At more typical process and environment conditions, energy gains\nrange from 35% to 45%, with a performance degradation under 2%. An analysis of\noptimum interconnect architectures for maximizing energy gains with this\napproach shows that the proposed approach performs well with technology\nscaling."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4681v1", 
    "title": "A Quality-of-Service Mechanism for Interconnection Networks in   System-on-Chips", 
    "arxiv-id": "0710.4681v1", 
    "author": "Drew Wingard", 
    "publish": "2007-10-25T09:05:03Z", 
    "summary": "As Moore's Law continues to fuel the ability to build ever increasingly\ncomplex system-on-chips (SoCs), achieving performance goals is rising as a\ncritical challenge to completing designs. In particular, the system\ninterconnect must efficiently service a diverse set of data flows with widely\nranging quality-of-service (QoS) requirements. However, the known solutions for\noff-chip interconnects such as large-scale networks are not necessarily\napplicable to the on-chip environment. Latency and memory constraints for\non-chip interconnects are quite different from larger-scale interconnects. This\npaper introduces a novel on-chip interconnect arbitration scheme. We show how\nthis scheme can be distributed across a chip for high-speed implementation. We\ncompare the performance of the arbitration scheme with other known interconnect\narbitration schemes. Existing schemes typically focus heavily on either low\nlatency of service for some initiators, or alternatively on guaranteed\nbandwidth delivery for other initiators. Our scheme allows service latency on\nsome initiators to be traded off smoothly against jitter bounds on other\ninitiators, while still delivering bandwidth guarantees. This scheme is a\nsubset of the QoS controls that are available in the SonicsMX? (SMX) product."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4684v1", 
    "title": "Reliability-Centric High-Level Synthesis", 
    "arxiv-id": "0710.4684v1", 
    "author": "Yuan Xie", 
    "publish": "2007-10-25T09:07:44Z", 
    "summary": "Importance of addressing soft errors in both safety critical applications and\ncommercial consumer products is increasing, mainly due to ever shrinking\ngeometries, higher-density circuits, and employment of power-saving techniques\nsuch as voltage scaling and component shut-down. As a result, it is becoming\nnecessary to treat reliability as a first-class citizen in system design. In\nparticular, reliability decisions taken early in system design can have\nsignificant benefits in terms of design quality. Motivated by this observation,\nthis paper presents a reliability-centric high-level synthesis approach that\naddresses the soft error problem. The proposed approach tries to maximize\nreliability of the design while observing the bounds on area and performance,\nand makes use of our reliability characterization of hardware components such\nas adders and multipliers. We implemented the proposed approach, performed\nexperiments with several designs, and compared the results with those obtained\nby a prior proposal."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4685v1", 
    "title": "Reliable System Specification for Self-Checking Data-Paths", 
    "arxiv-id": "0710.4685v1", 
    "author": "L. Pomante", 
    "publish": "2007-10-25T09:08:39Z", 
    "summary": "The design of reliable circuits has received a lot of attention in the past,\nleading to the definition of several design techniques introducing fault\ndetection and fault tolerance properties in systems for critical\napplications/environments. Such design methodologies tackled the problem at\ndifferent abstraction levels, from switch-level to logic, RT level, and more\nrecently to system level. Aim of this paper is to introduce a novel\nsystem-level technique based on the redefinition of the operators functionality\nin the system specification. This technique provides reliability properties to\nthe system data path, transparently with respect to the designer. Feasibility,\nfault coverage, performance degradation and overheads are investigated on a FIR\ncircuit."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4686v1", 
    "title": "Test Planning for Mixed-Signal SOCs with Wrapped Analog Cores", 
    "arxiv-id": "0710.4686v1", 
    "author": "Krishnendu Chakrabarty", 
    "publish": "2007-10-25T09:08:40Z", 
    "summary": "Many SOCs today contain both digital and analog embedded cores. Even though\nthe test cost for such mixed-signal SOCs is significantly higher than that for\ndigital SOCs, most prior research in this area has focused exclusively on\ndigital cores. We propose a low-cost test development methodology for\nmixed-signal SOCs that allows the analog and digital cores to be tested in a\nunified manner, thereby minimizing the overall test cost. The analog cores in\nthe SOC are wrapped such that they can be accessed using a digital test access\nmechanism (TAM). We evaluate the impact of the use of analog test wrappers on\narea overhead and test time. To reduce area overhead, we present an analog test\nwrapper optimization technique, which is then combined with TAM optimization in\na cost-oriented heuristic approach for test scheduling. We also demonstrate the\nfeasibility of using analog wrappers by presenting transistor-level simulations\nfor an analog wrapper and a representative core. We present experimental\nresults on test scheduling for an ITC'02 benchmark SOC that has been augmented\nwith five analog cores."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4687v1", 
    "title": "On-Chip Test Infrastructure Design for Optimal Multi-Site Testing of   System Chips", 
    "arxiv-id": "0710.4687v1", 
    "author": "Erik Jan Marinissen", 
    "publish": "2007-10-25T09:09:14Z", 
    "summary": "Multi-site testing is a popular and effective way to increase test throughput\nand reduce test costs. We present a test throughput model, in which we focus on\nwafer testing, and consider parameters like test time, index time,\nabort-on-fail, and contact yield. Conventional multi-site testing requires\nsufficient ATE resources, such as ATE channels, to allow to test multiple SOCs\nin parallel. In this paper, we design and optimize on-chip DfT, in order to\nmaximize the test throughput for a given SOC and ATE. The on-chip DfT consists\nof an E-RPCT wrapper, and, for modular SOCs, module wrappers and TAMs. We\npresent experimental results for a Philips SOC and several ITC'02 SOC Test\nBenchmarks."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4688v1", 
    "title": "On the Optimal Design of Triple Modular Redundancy Logic for SRAM-based   FPGAs", 
    "arxiv-id": "0710.4688v1", 
    "author": "M. Sonza Reorda", 
    "publish": "2007-10-25T09:09:34Z", 
    "summary": "Triple Modular Redundancy (TMR) is a suitable fault tolerant technique for\nSRAM-based FPGA. However, one of the main challenges in achieving 100%\nrobustness in designs protected by TMR running on programmable platforms is to\nprevent upsets in the routing from provoking undesirable connections between\nsignals from distinct redundant logic parts, which can generate an error in the\noutput. This paper investigates the optimal design of the TMR logic (e.g., by\ncleverly inserting voters) to ensure robustness. Four different versions of a\nTMR digital filter were analyzed by fault injection. Faults were randomly\ninserted straight into the bitstream of the FPGA. The experimental results\npresented in this paper demonstrate that the number and placement of voters in\nthe TMR design can directly affect the fault tolerance, ranging from 4.03% to\n0.98% the number of upsets in the routing able to cause an error in the TMR\ncircuit."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4691v1", 
    "title": "An O(bn^2) Time Algorithm for Optimal Buffer Insertion with b Buffer   Types", 
    "arxiv-id": "0710.4691v1", 
    "author": "Weiping Shi", 
    "publish": "2007-10-25T09:11:11Z", 
    "summary": "Buffer insertion is a popular technique to reduce the interconnect delay. The\nclassic buffer insertion algorithm of van Ginneken has time complexity O(n^2),\nwhere n is the number of buffer positions. Lillis, Cheng and Lin extended van\nGinneken's algorithm to allow b buffer types in time O (b^2 n^2). For modern\ndesign libraries that contain hundreds of buffers, it is a serious challenge to\nbalance the speed and performance of the buffer insertion algorithm. In this\npaper, we present a new algorithm that computes the optimal buffer insertion in\nO (bn^2) time. The reduction is achieved by the observation that the (Q, C)\npairs of the candidates that generate the new candidates must form a convex\nhull. On industrial test cases, the new algorithm is faster than the previous\nbest buffer insertion algorithms by orders of magnitude."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4692v1", 
    "title": "Cantilever-Based Biosensors in CMOS Technology", 
    "arxiv-id": "0710.4692v1", 
    "author": "A. Hierlemannn", 
    "publish": "2007-10-25T09:11:49Z", 
    "summary": "Single-chip CMOS-based biosensors that feature microcantilevers as transducer\nelements are presented. The cantilevers are functionalized for the capturing of\nspecific analytes, e.g., proteins or DNA. The binding of the analyte changes\nthe mechanical properties of the cantilevers such as surface stress and\nresonant frequency, which can be detected by an integrated Wheatstone bridge.\nThe monolithic integrated readout allows for a high signal-to-noise ratio,\nlowers the sensitivity to external interference and enables autonomous device\noperation."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4693v1", 
    "title": "Memory Testing Under Different Stress Conditions: An Industrial   Evaluation", 
    "arxiv-id": "0710.4693v1", 
    "author": "Fred Bowen", 
    "publish": "2007-10-25T09:14:05Z", 
    "summary": "This paper presents the effectiveness of various stress conditions (mainly\nvoltage and frequency) on detecting the resistive shorts and open defects in\ndeep sub-micron embedded memories in an industrial environment. Simulation\nstudies on very-low voltage, high voltage and at-speed testing show the need of\nthe stress conditions for high quality products; i.e., low defect-per-million\n(DPM) level, which is driving the semiconductor market today. The above test\nconditions have been validated to screen out bad devices on real silicon (a\ntest-chip) built on CMOS 0.18 um technology. IFA (inductive fault analysis)\nbased simulation technique leads to an efficient fault coverage and DPM\nestimator, which helps the customers upfront to make decisions on test\nalgorithm implementations under different stress conditions in order to reduce\nthe number of test escapes."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4697v1", 
    "title": "Statistical Timing Based Optimization using Gate Sizing", 
    "arxiv-id": "0710.4697v1", 
    "author": "David Blaauw", 
    "publish": "2007-10-25T09:16:49Z", 
    "summary": "The increased dominance of intra-die process variations has motivated the\nfield of Statistical Static Timing Analysis (SSTA) and has raised the need for\nSSTA-based circuit optimization. In this paper, we propose a new sensitivity\nbased, statistical gate sizing method. Since brute-force computation of the\nchange in circuit delay distribution to gate size change is computationally\nexpensive, we propose an efficient and exact pruning algorithm. The pruning\nalgorithm is based on a novel theory of perturbation bounds which are shown to\ndecrease as they propagate through the circuit. This allows pruning of gate\nsensitivities without complete propagation of their perturbations. We apply our\nproposed optimization algorithm to ISCAS benchmark circuits and demonstrate the\naccuracy and efficiency of the proposed method. Our results show an improvement\nof up to 10.5% in the 99-percentile circuit delay for the same circuit area,\nusing the proposed statistical optimizer and a run time improvement of up to\n56x compared to the brute-force approach."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4703v1", 
    "title": "A Way Memoization Technique for Reducing Power Consumption of Caches in   Application Specific Integrated Processors", 
    "arxiv-id": "0710.4703v1", 
    "author": "Farzan Fallah", 
    "publish": "2007-10-25T09:27:22Z", 
    "summary": "This paper presents a technique for eliminating redundant cache-tag and\ncache-way accesses to reduce power consumption. The basic idea is to keep a\nsmall number of Most Recently Used (MRU) addresses in a Memory Address Buffer\n(MAB) and to omit redundant tag and way accesses when there is a MAB-hit. Since\nthe approach keeps only tag and set-index values in the MAB, the energy and\narea overheads are relatively small even for a MAB with a large number of\nentries. Furthermore, the approach does not sacrifice the performance. In other\nwords, neither the cycle time nor the number of executed cycles increases. The\nproposed technique has been applied to Fujitsu VLIW processor (FR-V) and its\npower saving has been estimated using NanoSim. Experiments for 32kB 2-way set\nassociative caches show the power consumption of I-cache and D-cache can be\nreduced by 40% and 50%, respectively."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4704v1", 
    "title": "Resource Sharing and Pipelining in Coarse-Grained Reconfigurable   Architecture for Domain-Specific Optimization", 
    "arxiv-id": "0710.4704v1", 
    "author": "Kiyoung Choi", 
    "publish": "2007-10-25T09:28:05Z", 
    "summary": "Coarse-grained reconfigurable architectures aim to achieve both goals of high\nperformance and flexibility. However, existing reconfigurable array\narchitectures require many resources without considering the specific\napplication domain. Functional resources that take long latency and/or large\narea can be pipelined and/or shared among the processing elements. Therefore\nthe hardware cost and the delay can be effectively reduced without any\nperformance degradation for some application domains. We suggest such\nreconfigurable array architecture template and design space exploration flow\nfor domain-specific optimization. Experimental results show that our approach\nis much more efficient both in performance and area compared to existing\nreconfigurable architectures."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4705v1", 
    "title": "A Study of the Speedups and Competitiveness of FPGA Soft Processor Cores   using Dynamic Hardware/Software Partitioning", 
    "arxiv-id": "0710.4705v1", 
    "author": "Frank Vahid", 
    "publish": "2007-10-25T09:29:03Z", 
    "summary": "Field programmable gate arrays (FPGAs) provide designers with the ability to\nquickly create hardware circuits. Increases in FPGA configurable logic capacity\nand decreasing FPGA costs have enabled designers to more readily incorporate\nFPGAs in their designs. FPGA vendors have begun providing configurable soft\nprocessor cores that can be synthesized onto their FPGA products. While FPGAs\nwith soft processor cores provide designers with increased flexibility, such\nprocessors typically have degraded performance and energy consumption compared\nto hard-core processors. Previously, we proposed warp processing, a technique\ncapable of optimizing a software application by dynamically and transparently\nre-implementing critical software kernels as custom circuits in on-chip\nconfigurable logic. In this paper, we study the potential of a MicroBlaze\nsoft-core based warp processing system to eliminate the performance and energy\noverhead of a soft-core processor compared to a hard-core processor. We\ndemonstrate that the soft-core based warp processor achieves average speedups\nof 5.8 and energy reductions of 57% compared to the soft core alone. Our data\nshows that a soft-core based warp processor yields performance and energy\nconsumption competitive with existing hard-core processors, thus expanding the\nusefulness of soft processor cores on FPGAs to a broader range of applications."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4706v1", 
    "title": "An Infrastructure to Functionally Test Designs Generated by Compilers   Targeting FPGAs", 
    "arxiv-id": "0710.4706v1", 
    "author": "Joao M. P. Cardoso", 
    "publish": "2007-10-25T09:29:33Z", 
    "summary": "This paper presents an infrastructure to test the functionality of the\nspecific architectures output by a high-level compiler targeting dynamically\nreconfigurable hardware. It results in a suitable scheme to verify the\narchitectures generated by the compiler, each time new optimization techniques\nare included or changes in the compiler are performed. We believe this kind of\ninfrastructure is important to verify, by functional simulation, further\nresearch techniques, as far as compilation to Field-Programmable Gate Array\n(FPGA) platforms is concerned."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4707v1", 
    "title": "Energy- and Performance-Driven NoC Communication Architecture Synthesis   Using a Decomposition Approach", 
    "arxiv-id": "0710.4707v1", 
    "author": "Radu Marculescu", 
    "publish": "2007-10-25T09:29:58Z", 
    "summary": "In this paper, we present a methodology for customized communication\narchitecture synthesis that matches the communication requirements of the\ntarget application. This is an important problem, particularly for\nnetwork-based implementations of complex applications. Our approach is based on\nusing frequently encountered generic communication primitives as an alphabet\ncapable of characterizing any given communication pattern. The proposed\nalgorithm searches through the entire design space for a solution that\nminimizes the system total energy consumption, while satisfying the other\ndesign constraints. Compared to the standard mesh architecture, the customized\narchitecture generated by the newly proposed approach shows about 36%\nthroughput increase and 51% reduction in the energy required to encrypt 128\nbits of data with a standard encryption algorithm."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4709v1", 
    "title": "Analog and Digital Circuit Design in 65 nm CMOS: End of the Road?", 
    "arxiv-id": "0710.4709v1", 
    "author": "Ted Vucurevich", 
    "publish": "2007-10-25T09:30:46Z", 
    "summary": "This special session adresses the problems that designers face when\nimplementing analog and digital circuits in nanometer technologies. An\nintroductory embedded tutorial will give an overview of the design problems at\nhand : the leakage power and process variability and their implications for\ndigital circuits and memories, and the reducing supply voltages, the design\nproductivity and signal integrity problems for embedded analog blocks. Next, a\npanel of experts from both industrial semiconductor houses and design\ncompanies, EDA vendors and research institutes will present and discuss with\nthe audience their opinions on whether the design road ends at marker \"65nm\" or\nnot."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4711v1", 
    "title": "FPGA Architecture for Multi-Style Asynchronous Logic", 
    "arxiv-id": "0710.4711v1", 
    "author": "M. Renaudin", 
    "publish": "2007-10-25T09:32:43Z", 
    "summary": "This paper presents a novel FPGA architecture for implementing various styles\nof asynchronous logic. The main objective is to break the dependency between\nthe FPGA architecture dedicated to asynchronous logic and the logic style. The\ninnovative aspects of the architecture are described. Moreover the structure is\nwell suited to be rebuilt and adapted to fit with further asynchronous logic\nevolutions thanks to the architecture genericity. A full-adder was implemented\nin different styles of logic to show the architecture flexibility."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4712v1", 
    "title": "An Accurate SER Estimation Method Based on Propagation Probability", 
    "arxiv-id": "0710.4712v1", 
    "author": "Mehdi B. Tahoori", 
    "publish": "2007-10-25T09:33:14Z", 
    "summary": "In this paper, we present an accurate but very fast soft error rate (SER)\nestimation technique for digital circuits based on error propagation\nprobability (EPP) computation. Experiments results and comparison of the\nresults with the random simulation technique show that our proposed method is\non average within 6% of the random simulation method and four to five orders of\nmagnitude faster."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4713v1", 
    "title": "Improving the Process-Variation Tolerance of Digital Circuits Using Gate   Sizing and Statistical Techniques", 
    "arxiv-id": "0710.4713v1", 
    "author": "Xiaoyu Song", 
    "publish": "2007-10-25T09:33:36Z", 
    "summary": "A new approach for enhancing the process-variation tolerance of digital\ncircuits is described. We extend recent advances in statistical timing analysis\ninto an optimization framework. Our objective is to reduce the performance\nvariance of a technology-mapped circuit where delays across elements are\nrepresented by random variables which capture the manufacturing variations. We\nintroduce the notion of statistical critical paths, which account for both\nmeans and variances of performance variation. An optimization engine is used to\nsize gates with a goal of reducing the timing variance along the statistical\ncritical paths. We apply a pair of nested statistical analysis methods\ndeploying a slower more accurate approach for tracking statistical critical\npaths and a fast engine for evaluation of gate size assignments. We derive a\nnew approximation for the max operation on random variables which is deployed\nfor the faster inner engine. Circuit optimization is carried out using a\ngain-based algorithm that terminates when constraints are satisfied or no\nfurther improvements can be made. We show optimization results that demonstrate\nan average of 72% reduction in performance variation at the expense of average\n20% increase in design area."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4714v1", 
    "title": "Assertion-Based Design Exploration of DVS in Network Processor   Architectures", 
    "arxiv-id": "0710.4714v1", 
    "author": "Felice Balarin", 
    "publish": "2007-10-25T09:33:38Z", 
    "summary": "With the scaling of technology and higher requirements on performance and\nfunctionality, power dissipation is becoming one of the major design\nconsiderations in the development of network processors. In this paper, we use\nan assertion-based methodology for system-level power/performance analysis to\nstudy two dynamic voltage scaling (DVS) techniques, traffic-based DVS and\nexecution-based DVS, in a network processor model. Using the automatically\ngenerated distribution analyzers, we analyze the power and performance\ndistributions and study their trade-offs for the two DVS policies with\ndifferent parameter settings such as threshold values and window sizes. We\ndiscuss the optimal configurations of the two DVS policies under different\ndesign requirements. By a set of experiments, we show that the assertion-based\ntrace analysis methodology is an efficient tool that can help a designer easily\ncompare and study optimal architectural configurations in a large design space."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4715v1", 
    "title": "Circuit-Level Modeling for Concurrent Testing of Operational Defects due   to Gate Oxide Breakdown", 
    "arxiv-id": "0710.4715v1", 
    "author": "Daniel J. Sorin", 
    "publish": "2007-10-25T09:34:11Z", 
    "summary": "As device sizes shrink and current densities increase, the probability of\ndevice failures due to gate oxide breakdown (OBD) also increases. To provide\ndesigns that are tolerant to such failures, we must investigate and understand\nthe manifestations of this physical phenomenon at the circuit and system level.\nIn this paper, we develop a model for operational OBD defects, and we explore\nhow to test for faults due to OBD. For a NAND gate, we derive the necessary\ninput conditions that excite and detect errors due to OBD defects at the gate\nlevel. We show that traditional pattern generators fail to exercise all of\nthese defects. Finally, we show that these test patterns can be propagated and\njustified for a combinational circuit in a manner similar to traditional ATPG."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4716v1", 
    "title": "Optimized Generation of Data-Path from C Codes for FPGAs", 
    "arxiv-id": "0710.4716v1", 
    "author": "Kees Vissers", 
    "publish": "2007-10-25T09:34:19Z", 
    "summary": "FPGAs, as computing devices, offer significant speedup over microprocessors.\nFurthermore, their configurability offers an advantage over traditional ASICs.\nHowever, they do not yet enjoy high-level language programmability, as\nmicroprocessors do. This has become the main obstacle for their wider\nacceptance by application designers. ROCCC is a compiler designed to generate\ncircuits from C source code to execute on FPGAs, more specifically on CSoCs. It\ngenerates RTL level HDLs from frequently executing kernels in an application.\nIn this paper, we describe ROCCC's system overview and focus on its data path\ngeneration. We compare the performance of ROCCC-generated VHDL code with that\nof Xilinx IPs. The synthesis result shows that ROCCC-generated circuit takes\naround 2x ~ 3x area and runs at comparable clock rate."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4717v1", 
    "title": "Multi-Placement Structures for Fast and Optimized Placement in Analog   Circuit Synthesis", 
    "arxiv-id": "0710.4717v1", 
    "author": "Ranga Vemuri", 
    "publish": "2007-10-25T09:35:03Z", 
    "summary": "This paper presents the novel idea of multi-placement structures, for a fast\nand optimized placement instantiation in analog circuit synthesis. These\nstructures need to be generated only once for a specific circuit topology. When\nused in synthesis, these pre-generated structures instantiate various layout\nfloorplans for various sizes and parameters of a circuit. Unlike procedural\nlayout generators, they enable fast placement of circuits while keeping the\nquality of the placements at a high level during a synthesis process. The fast\nplacement is a result of high speed instantiation resulting from the efficiency\nof the multi-placement structure. The good quality of placements derive from\nthe extensive and intelligent search process that is used to build the\nmulti-placement structure. The target benchmarks of these structures are analog\ncircuits in the vicinity of 25 modules. An algorithm for the generation of such\nmulti-placement structures is presented. Experimental results show placement\nexecution times with an average of a few milliseconds making them usable during\nlayout-aware synthesis for optimized placements."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4719v1", 
    "title": "Specification Test Compaction for Analog Circuits and MEMS", 
    "arxiv-id": "0710.4719v1", 
    "author": "Larry T. Pileggi", 
    "publish": "2007-10-25T09:36:21Z", 
    "summary": "Testing a non-digital integrated system against all of its specifications can\nbe quite expensive due to the elaborate test application and measurement setup\nrequired. We propose to eliminate redundant tests by employing e-SVM based\nstatistical learning. Application of the proposed methodology to an operational\namplifier and a MEMS accelerometer reveal that redundant tests can be\nstatistically identified from a complete set of specification-based tests with\nnegligible error. Specifically, after eliminating five of eleven\nspecification-based tests for an operational amplifier, the defect escape and\nyield loss is small at 0.6% and 0.9%, respectively. For the accelerometer,\ndefect escape of 0.2% and yield loss of 0.1% occurs when the hot and colt tests\nare eliminated. For the accelerometer, this level of Compaction would reduce\ntest cost by more than half."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4720v1", 
    "title": "Soft-Error Tolerance Analysis and Optimization of Nanometer Circuits", 
    "arxiv-id": "0710.4720v1", 
    "author": "Abhijit Chatterjee", 
    "publish": "2007-10-25T09:36:27Z", 
    "summary": "Nanometer circuits are becoming increasingly susceptible to soft-errors due\nto alpha-particle and atmospheric neutron strikes as device scaling reduces\nnode capacitances and supply/threshold voltage scaling reduces noise margins.\nIt is becoming crucial to add soft-error tolerance estimation and optimization\nto the design flow to handle the increasing susceptibility. The first part of\nthis paper presents a tool for accurate soft-error tolerance analysis of\nnanometer circuits (ASERTA) that can be used to estimate the soft-error\ntolerance of nanometer circuits consisting of millions of gates. The tolerance\nestimates generated by the tool match SPICE generated estimates closely while\ntaking orders of magnitude less computation time. The second part of the paper\npresents a tool for soft-error tolerance optimization of nanometer circuits\n(SERTOPT) using the tolerance estimates generated by ASERTA. The tool finds\noptimal sizes, channel lengths, supply voltages and threshold voltages to be\nassigned to gates in a combinational circuit such that the soft-error tolerance\nis increased while meeting the timing constraint. Experiments on ISCAS'85\nbenchmark circuits showed that soft-error rate of the optimized circuit\ndecreased by as much as 47% with marginal increase in circuit delay."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4721v1", 
    "title": "IEEE 1149.4 Compatible ABMs for Basic RF Measurements", 
    "arxiv-id": "0710.4721v1", 
    "author": "Markku Moilanen", 
    "publish": "2007-10-25T09:36:53Z", 
    "summary": "An analogue testing standard IEEE 1149.4 is mainly targeted for low-frequency\ntesting. The problem studied in this paper is extending the standard also for\nradio frequency testing. IEEE 1149.4 compatible measurement structures (ABMs)\ndeveloped in this study extract the information one is measuring from the radio\nfrequency signal and represent the result as a DC voltage level. The ABMs\npresented in this paper are targeted for power and frequency measurements\noperating in frequencies from 1 GHz to 2 GHz. The power measurement error\ncaused by temperature, supply voltage and process variations is roughly 2 dB\nand the frequency measurement error is 0.1 GHz, respectively."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4722v1", 
    "title": "Designer-Driven Topology Optimization for Pipelined Analog to Digital   Converters", 
    "arxiv-id": "0710.4722v1", 
    "author": "Tamal Mukherjee", 
    "publish": "2007-10-25T09:36:56Z", 
    "summary": "This paper suggests a practical \"hybrid\" synthesis methodology which\nintegrates designer-derived analytical models for system-level description with\nsimulation-based models at the circuit level. We show how to optimize\nstage-resolution to minimize the power in a pipelined ADC. Exploration (via\ndetailed synthesis) of several ADC configurations is used to show that a\n4-3-2... resolution distribution uses the least power for a 13-bit 40 MSPS\nconverter in a 0.25 $\\mu$m CMOS process."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4724v1", 
    "title": "Systematic Figure of Merit Computation for the Design of Pipeline ADC", 
    "arxiv-id": "0710.4724v1", 
    "author": "D. Houzet", 
    "publish": "2007-10-25T09:37:45Z", 
    "summary": "The emerging concept of SoC-AMS leads to research new top-down methodologies\nto aid systems designers in sizing analog and mixed devices. This work applies\nthis idea to the high-level optimization of pipeline ADC. Considering a given\ntechnology, it consists in comparing different configurations according to\ntheir imperfections and their architectures without FFT computation or\ntime-consuming simulations. The final selection is based on a figure of merit."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4727v1", 
    "title": "Top-Down Design of a Low-Power Multi-Channel 2.5-Gbit/s/Channel Gated   Oscillator Clock-Recovery Circuit", 
    "arxiv-id": "0710.4727v1", 
    "author": "Yusuf Leblebici", 
    "publish": "2007-10-25T09:38:14Z", 
    "summary": "We present a complete top-down design of a low-power multi-channel clock\nrecovery circuit based on gated current-controlled oscillators. The flow\nincludes several tools and methods used to specify block constraints, to design\nand verify the topology down to the transistor level, as well as to achieve a\npower consumption as low as 5mW/Gbit/s. Statistical simulation is used to\nestimate the achievable bit error rate in presence of phase and frequency\nerrors and to prove the feasibility of the concept. VHDL modeling provides\nextensive verification of the topology. Thermal noise modeling based on\nwell-known concepts delivers design parameters for the device sizing and\nbiasing. We present two practical examples of possible design improvements\nanalyzed and implemented with this methodology."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4728v1", 
    "title": "Energy-Aware Routing for E-Textile Applications", 
    "arxiv-id": "0710.4728v1", 
    "author": "Radu Marculescu", 
    "publish": "2007-10-25T09:38:43Z", 
    "summary": "As the scale of electronic devices shrinks, \"electronic textiles\"\n(e-textiles) will make possible a wide variety of novel applications which are\ncurrently unfeasible. Due to the wearability concerns, low-power techniques are\ncritical for e-textile applications. In this paper, we address the issue of the\nenergy-aware routing for e-textile platforms and propose an efficient algorithm\nto solve it. The platform we consider consists of dedicated components for\ne-textiles, including computational modules, dedicated transmission lines and\nthin-film batteries on fiber substrates. Furthermore, we derive an analytical\nupper bound for the achievable number of jobs completed over all possible\nrouting strategies. From a practical standpoint, for the Advanced Encryption\nStandard (AES) cipher, the routing technique we propose achieves about fifty\npercent of this analytical upper bound. Moreover, compared to the\nnon-energy-aware counterpart, our routing technique increases the number of\nencryption jobs completed by one order of magnitude."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4729v1", 
    "title": "Modeling and Analysis of Loading Effect in Leakage of Nano-Scaled   Bulk-CMOS Logic Circuits", 
    "arxiv-id": "0710.4729v1", 
    "author": "Kaushik Roy", 
    "publish": "2007-10-25T09:39:25Z", 
    "summary": "In nanometer scaled CMOS devices significant increase in the subthreshold,\nthe gate and the reverse biased junction band-to-band-tunneling (BTBT) leakage,\nresults in the large increase of total leakage power in a logic circuit.\nLeakage components interact with each other in device level (through device\ngeometry, doping profile) and also in the circuit level (through node\nvoltages). Due to the circuit level interaction of the different leakage\ncomponents, the leakage of a logic gate strongly depends on the circuit\ntopology i.e. number and nature of the other logic gates connected to its input\nand output. In this paper, for the first time, we have analyzed loading effect\non leakage and proposed a method to accurately estimate the total leakage in a\nlogic circuit, from its logic level description considering the impact of\nloading and transistor stacking."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4731v1", 
    "title": "Leakage-Aware Interconnect for On-Chip Network", 
    "arxiv-id": "0710.4731v1", 
    "author": "Mary Jane Irwin", 
    "publish": "2007-10-25T09:40:02Z", 
    "summary": "On-chip networks have been proposed as the interconnect fabric for future\nsystems-on-chip and multi-processors on chip. Power is one of the main\nconstraints of these systems and interconnect consumes a significant portion of\nthe power budget. In this paper, we propose four leakage-aware interconnect\nschemes. Our schemes achieve 10.13%~63.57% active leakage savings and\n12.35%~95.96% standby leakage savings across schemes while the delay penalty\nranges from 0% to 4.69%."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4733v1", 
    "title": "Smart Temperature Sensor for Thermal Testing of Cell-Based ICs", 
    "arxiv-id": "0710.4733v1", 
    "author": "J. Segura", 
    "publish": "2007-10-25T09:41:13Z", 
    "summary": "In this paper we present a simple and efficient built-in temperature sensor\nfor thermal monitoring of standard-cell based VLSI circuits. The proposed smart\ntemperature sensor uses a ring-oscillator composed of complex gates instead of\ninverters to optimize their linearity. Simulation results from a 0.18$\\mu$m\nCMOS technology show that the non-linearity error of the sensor can be reduced\nwhen an adequate set of standard logic gates is selected."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4735v1", 
    "title": "Worst-Case and Average-Case Analysis of n-Detection Test Sets", 
    "arxiv-id": "0710.4735v1", 
    "author": "Sudhakar M. Reddy", 
    "publish": "2007-10-25T09:42:30Z", 
    "summary": "Test sets that detect each target fault n times (n-detection test sets) are\ntypically generated for restricted values of n due to the increase in test set\nsize with n. We perform both a worst-case analysis and an average-case analysis\nto check the effect of restricting n on the unmodeled fault coverage of an\n(arbitrary) n-detection test set. Our analysis is independent of any particular\ntest set or test generation approach. It is based on a specific set of target\nfaults and a specific set of untargeted faults. It shows that, depending on the\ncircuit, very large values of n may be needed to guarantee the detection of all\nthe untargeted faults. We discuss the implications of these results."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4736v1", 
    "title": "A New Embedded Measurement Structure for eDRAM Capacitor", 
    "arxiv-id": "0710.4736v1", 
    "author": "D. Nee", 
    "publish": "2007-10-25T09:42:35Z", 
    "summary": "The embedded DRAM (eDRAM) is more and more used in System On Chip (SOC). The\nintegration of the DRAM capacitor process into a logic process is challenging\nto get satisfactory yields. The specific process of DRAM capacitor and the low\ncapacitance value (~30F) of this device induce problems of process monitoring\nand failure analysis. We propose a new test structure to measure the\ncapacitance value of each DRAM cell capacitor in a DRAM array. This concept has\nbeen validated by simulation on a 0.18$\\mu$m eDRAM technology."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4738v1", 
    "title": "Exploring NoC Mapping Strategies: An Energy and Timing Aware Technique", 
    "arxiv-id": "0710.4738v1", 
    "author": "Fabiano Hessel", 
    "publish": "2007-10-25T09:43:59Z", 
    "summary": "Complex applications implemented as Systems on Chip (SoCs) demand extensive\nuse of system level modeling and validation. Their implementation gathers a\nlarge number of complex IP cores and advanced interconnection schemes, such as\nhierarchical bus architectures or networks on chip (NoCs). Modeling\napplications involves capturing its computation and communication\ncharacteristics. Previously proposed communication weighted models (CWM)\nconsider only the application communication aspects. This work proposes a\ncommunication dependence and computation model (CDCM) that can simultaneously\nconsider both aspects of an application. It presents a solution to the problem\nof mapping applications on regular NoCs while considering execution time and\nenergy consumption. The use of CDCM is shown to provide estimated average\nreductions of 40% in execution time, and 20% in energy consumption, for current\ntechnologies."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4742v1", 
    "title": "Hardware Accelerated Power Estimation", 
    "arxiv-id": "0710.4742v1", 
    "author": "Anand Raghunathan", 
    "publish": "2007-10-25T09:45:28Z", 
    "summary": "In this paper, we present power emulation, a novel design paradigm that\nutilizes hardware acceleration for the purpose of fast power estimation. Power\nemulation is based on the observation that the functions necessary for power\nestimation (power model evaluation, aggregation, etc.) can be implemented as\nhardware circuits. Therefore, we can enhance any given design with \"power\nestimation hardware\", map it to a prototyping platform, and exercise it with\nany given test stimuli to obtain power consumption estimates. Our empirical\nstudies with industrial designs reveal that power emulation can achieve\nsignificant speedups (10X to 500X) over state-of-the-art commercial\nregister-transfer level (RTL) power estimation tools."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4747v1", 
    "title": "An Efficient Transparent Test Scheme for Embedded Word-Oriented Memories", 
    "arxiv-id": "0710.4747v1", 
    "author": "Chin-Long Wey", 
    "publish": "2007-10-25T09:48:22Z", 
    "summary": "Memory cores are usually the densest portion with the smallest feature size\nin system-on-chip (SOC) designs. The reliability of memory cores thus has heavy\nimpact on the reliability of SOCs. Transparent test is one of useful technique\nfor improving the reliability of memories during life time. This paper presents\na systematic algorithm used for transforming a bit-oriented march test into a\ntransparent word-oriented march test. The transformed transparent march test\nhas shorter test complexity compared with that proposed in the previous works\n[Theory of transparent BIST for RAMs, A transparent online memory test for\nsimultaneous detection of functional faults and soft errors in memories]. For\nexample, if a memory with 32-bit words is tested with March C-, time complexity\nof the transparent word-oriented test transformed by the proposed scheme is\nonly about 56% or 19% time complexity of the transparent word-oriented test\nconverted by the scheme reported in [Theory of transparent BIST for RAMs] or [A\ntransparent online memory test for simultaneous detection of functional faults\nand soft errors in memories], respectively."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4748v1", 
    "title": "Systematic Transaction Level Modeling of Embedded Systems with SystemC", 
    "arxiv-id": "0710.4748v1", 
    "author": "Wolfgang Klingauf", 
    "publish": "2007-10-25T09:49:10Z", 
    "summary": "This paper gives an overview of a transaction level modeling (TLM) design\nflow for straightforward embedded system design with SystemC. The goal is to\nsystematically develop both application-specific HW and SW components of an\nembedded system using the TLM approach, thus allowing for fast communication\narchitecture exploration, rapid prototyping and early embedded SW development.\nTo this end, we specify the lightweight transaction-based communication\nprotocol SHIP and present a methodology for automatic mapping of the\ncommunication part of a system to a given architecture, including HW/SW\ninterfaces."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4751v1", 
    "title": "Influence of Memory Hierarchies on Predictability for Time Constrained   Embedded Software", 
    "arxiv-id": "0710.4751v1", 
    "author": "Peter Marwedel", 
    "publish": "2007-10-25T09:51:11Z", 
    "summary": "Safety-critical embedded systems having to meet real-time constraints are\nexpected to be highly predictable in order to guarantee at design time that\ncertain timing deadlines will always be met. This requirement usually prevents\ndesigners from utilizing caches due to their highly dynamic, thus hardly\npredictable behavior. The integration of scratchpad memories represents an\nalternative approach which allows the system to benefit from a performance gain\ncomparable to that of caches while at the same time maintaining predictability.\nIn this work, we compare the impact of scratchpad memories and caches on worst\ncase execution time (WCET) analysis results. We show that caches, despite\nrequiring complex techniques, can have a negative impact on the predicted WCET,\nwhile the estimated WCET for scratchpad memories scales with the achieved\nPerformance gain at no extra analysis cost."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4754v1", 
    "title": "Design of a Virtual Component Neutral Network-on-Chip Transaction Layer", 
    "arxiv-id": "0710.4754v1", 
    "author": "Philippe Martin", 
    "publish": "2007-10-25T09:52:56Z", 
    "summary": "Research studies have demonstrated the feasibility and advantages of\nNetwork-on-Chip (NoC) over traditional bus-based architectures but have not\nfocused on compatibility communication standards. This paper describes a number\nof issues faced when designing a VC-neutral NoC, i.e. compatible with standards\nsuch as AHB 2.0, AXI, VCI, OCP, and various other proprietary protocols, and\nhow a layered approach to communication helps solve these issues."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4757v1", 
    "title": "Techniques for Fast Transient Fault Grading Based on Autonomous   Emulation", 
    "arxiv-id": "0710.4757v1", 
    "author": "Luis Entrena-Arrontes", 
    "publish": "2007-10-25T09:53:37Z", 
    "summary": "Very deep submicron and nanometer technologies have increased notably\nintegrated circuit (IC) sensitiveness to radiation. Soft errors are currently\nappearing into ICs working at earth surface. Hardened circuits are currently\nrequired in many applications where Fault Tolerance (FT) was not a requirement\nin the very near past. The use of platform FPGAs for the emulation of\nsingle-event upset effects (SEU) is gaining attention in order to speed up the\nFT evaluation. In this work, a new emulation system for FT evaluation with\nrespect to SEU effects is proposed, providing shorter evaluation times by\nperforming all the evaluation process in the FPGA and avoiding emulator-host\ncommunication bottlenecks."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4759v1", 
    "title": "A Fast Concurrent Power-Thermal Model for Sub-100nm Digital ICs", 
    "arxiv-id": "0710.4759v1", 
    "author": "J. Segura", 
    "publish": "2007-10-25T09:54:18Z", 
    "summary": "As technology scales down, the static power is expected to become a\nsignificant fraction of the total power. The exponential dependence of static\npower with the operating temperature makes the thermal profile estimation of\nhigh-performance ICs a key issue to compute the total power dissipated in\nnext-generations. In this paper we present accurate and compact analytical\nmodels to estimate the static power dissipation and the temperature of\noperation of CMOS gates. The models are the fundamentals of a performance\nestimation tool in which numerical procedures are avoided for any computation\nto set a faster estimation and optimization. The models developed are compared\nto measurements and SPICE simulations for a 0.12mm technology showing excellent\nresults."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4760v1", 
    "title": "Low Power Oriented CMOS Circuit Optimization Protocol", 
    "arxiv-id": "0710.4760v1", 
    "author": "D. Auvergne", 
    "publish": "2007-10-25T09:54:46Z", 
    "summary": "Low power oriented circuit optimization consists in selecting the best\nalternative between gate sizing, buffer insertion and logic structure\ntransformation, for satisfying a delay constraint at minimum area cost. In this\npaper we used a closed form model of delay in CMOS structures to define metrics\nfor a deterministic selection of the optimization alternative. The target is\ndelay constraint satisfaction with minimum area cost. We validate the design\nspace exploration method, defining maximum and minimum delay bounds on logical\npaths. Then we adapt this method to a \"constant sensitivity method\" allowing to\nsize a circuit at minimum area under a delay constraint. An optimisation\nprotocol is finally defined to manage the trade-off performance constraint -\ncircuit structure. These methods are implemented in an optimization tool (POPS)\nand validated by comparing on a 0.25$\\mu$m process, the optimization efficiency\nobtained on various benchmarks (ISCAS?85) to that resulting from an industrial\ntool."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4761v1", 
    "title": "Low-Cost Multi-Gigahertz Test Systems Using CMOS FPGAs and PECL", 
    "arxiv-id": "0710.4761v1", 
    "author": "N. Taher", 
    "publish": "2007-10-25T09:55:04Z", 
    "summary": "This paper describes two research projects that develop new low-cost\ntechniques for testing devices with multiple high-speed (2 to 5 Gbps) signals.\nEach project uses commercially available components to keep costs low, yet\nachieves performance characteristics comparable to (and in some ways exceeding)\nmore expensive ATE. A common CMOS FPGA-based logic core provides flexibility,\nadaptability, and communication with controlling computers while customized\npositive emitter-coupled logic (PECL) achieves multi-gigahertz data rates with\nabout $\\pm$25ps timing accuracy."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4762v1", 
    "title": "Area-Efficient Selective Multi-Threshold CMOS Design Methodology for   Standby Leakage Power Reduction", 
    "arxiv-id": "0710.4762v1", 
    "author": "Toshiyuki Furusawa", 
    "publish": "2007-10-25T09:55:21Z", 
    "summary": "This paper presents a design flow for an improved selective\nmulti-threshold(Selective-MT) circuit. The Selective-MT circuit is improved so\nthat plural MT-cells can share one switch transistor. We propose the design\nmethodology from RTL(Register Transfer Level) to final layout with optimizing\nswitch transistor structure."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4763v1", 
    "title": "Logic Design for On-Chip Test Clock Generation - Implementation Details   and Impact on Delay Test Quality", 
    "arxiv-id": "0710.4763v1", 
    "author": "Ron Press", 
    "publish": "2007-10-25T09:55:27Z", 
    "summary": "This paper addresses delay test for SOC devices with high frequency clock\ndomains. A logic design for on-chip high-speed clock generation, implemented to\navoid expensive test equipment, is described in detail. Techniques for on-chip\nclock generation, meant to reduce test vector count and to increase test\nquality, are discussed. ATPG results for the proposed techniques are given."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4764v1", 
    "title": "Hotspot Prevention Through Runtime Reconfiguration in Network-On-Chip", 
    "arxiv-id": "0710.4764v1", 
    "author": "N. Vijaykrishnan", 
    "publish": "2007-10-25T09:55:48Z", 
    "summary": "Many existing thermal management techniques focus on reducing the overall\npower consumption of the chip, and do not address location-specific temperature\nproblems referred to as hotspots. We propose the use of dynamic runtime\nreconfiguration to shift the hotspot-inducing computation periodically and make\nthe thermal profile more uniform. Our analysis shows that dynamic\nreconfiguration is an effective technique in reducing hotspots for NoCs."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4794v1", 
    "title": "Power-Performance Trade-Offs in Nanometer-Scale Multi-Level Caches   Considering Total Leakage", 
    "arxiv-id": "0710.4794v1", 
    "author": "Trevor Mudge", 
    "publish": "2007-10-25T11:51:44Z", 
    "summary": "In this paper, we investigate the impact of T_{ox} and Vth on power\nperformance trade-offs for on-chip caches. We start by examining the\noptimization of the various components of a single level cache and then extend\nthis to two level cache systems. In addition to leakage, our studies also\naccount for the dynamic power expanded as a result of cache misses. Our results\nshow that one can often reduce overall power by increasing the size of the L2\ncache if we only allow one pair of Vth/T_{ox} in L2. However, if we allow the\nmemory cells and the peripherals to have their own Vth's and T_{ox}'s, we show\nthat a two-level cache system with smaller L2's will yield less total leakage.\nWe further show that two Vth's and two T_{ox}'s are sufficient to get close to\nan optimal solution, and that Vth is generally a better design knob than T_{ox}\nfor leakage optimization, thus it is better to restrict the number of T_{ox}'s\nrather than Vth's if cost is a concern."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4795v1", 
    "title": "Test Time Reduction Reusing Multiple Processors in a Network-on-Chip   Based Architecture", 
    "arxiv-id": "0710.4795v1", 
    "author": "Edson I. Moreno", 
    "publish": "2007-10-25T11:52:22Z", 
    "summary": "The increasing complexity and the short life cycles of embedded systems are\npushing the current system-on-chip designs towards a rapid increasing on the\nnumber of programmable processing units, while decreasing the gate count for\ncustom logic. Considering this trend, this work proposes a test planning method\ncapable of reusing available processors as test sources and sinks, and the\non-chip network as the test access mechanism. Experimental results are based on\nITC'02 benchmarks and on two open core processors compliant with MIPS and SPARC\ninstruction set. The results show that the cooperative use of both the on-chip\nnetwork and the embedded processors can increase the test parallelism and\nreduce the test time without additional cost in area and pins."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4796v1", 
    "title": "A Hybrid Prefetch Scheduling Heuristic to Minimize at Run-Time the   Reconfiguration Overhead of Dynamically Reconfigurable Hardware", 
    "arxiv-id": "0710.4796v1", 
    "author": "Francky Catthoor", 
    "publish": "2007-10-25T11:53:03Z", 
    "summary": "Due to the emergence of highly dynamic multimedia applications there is a\nneed for flexible platforms and run-time scheduling support for embedded\nsystems. Dynamic Reconfigurable Hardware (DRHW) is a promising candidate to\nprovide this flexibility but, currently, not sufficient run-time scheduling\nsupport to deal with the run-time reconfigurations exists. Moreover, executing\nat run-time a complex scheduling heuristic to provide this support may generate\nan excessive run-time penalty. Hence, we have developed a hybrid\ndesign/run-time prefetch heuristic that schedules the reconfigurations at\nrun-time, but carries out the scheduling computations at design-time by\ncarefully identifying a set of near-optimal schedules that can be selected at\nrun-time. This approach provides run-time flexibility with a negligible\npenalty."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4801v1", 
    "title": "Behavioural Transformation to Improve Circuit Performance in High-Level   Synthesis", 
    "arxiv-id": "0710.4801v1", 
    "author": "R. Hermida", 
    "publish": "2007-10-25T11:55:59Z", 
    "summary": "Early scheduling algorithms usually adjusted the clock cycle duration to the\nexecution time of the slowest operation. This resulted in large slack times\nwasted in those cycles executing faster operations. To reduce the wasted times\nmulti-cycle and chaining techniques have been employed. While these techniques\nhave produced successful designs, its effectiveness is often limited due to the\narea increment that may derive from chaining, and the extra latencies that may\nderive from multicycling. In this paper we present an optimization method that\nsolves the time-constrained scheduling problem by transforming behavioural\nspecifications into new ones whose subsequent synthesis substantially improves\ncircuit performance. Our proposal breaks up some of the specification\noperations, allowing their execution during several possibly unconsecutive\ncycles, and also the calculation of several data-dependent operation fragments\nin the same cycle. To do so, it takes into account the circuit latency and the\nexecution time of every specification operation. The experimental results\ncarried out show that circuits obtained from the optimized specification are on\naverage 60% faster than those synthesized from the original specification, with\nonly slight increments in the circuit area."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4805v1", 
    "title": "Modeling of a Reconfigurable OFDM IP Block Family For an RF System   Simulator", 
    "arxiv-id": "0710.4805v1", 
    "author": "Jussi Liedes", 
    "publish": "2007-10-25T11:57:50Z", 
    "summary": "The idea of design domain specific Mother Model of IP block family as a base\nof modeling of system integration is presented here. A common reconfigurable\nMother Model for ten different standardized digital OFDM transmitters has been\ndeveloped. By means of a set of parameters, the mother model can be\nreconfigured to any of the ten selected standards. So far the applicability of\nthe proposed reconfiguration and analog-digital co-modeling methods have been\nproved by modeling the function of the digital parts of three, 802.11a, ADSL\nand DRM, transmitters in an RF system simulator. The model is intended to be\nused as signal source template in RF system simulations. The concept is not\nrestricted to signal sources, it can be applied to any IP block development.\nThe idea of the Mother Model will be applied in other design domains to prove\nthat in certain application areas, OFDM transceivers in this case, the design\nprocess can progress simultaneously in different design domains - mixed signal,\nsystem and RTL-architectural - without the need of high-level synthesis. Only\nthe Mother Models of three design domains are needed to be formally proved to\nfunction as specified."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4806v1", 
    "title": "A VLSI Design Flow for Secure Side-Channel Attack Resistant ICs", 
    "arxiv-id": "0710.4806v1", 
    "author": "Ingrid Verbauwhede", 
    "publish": "2007-10-25T11:57:56Z", 
    "summary": "This paper presents a digital VLSI design flow to create secure, side-channel\nattack (SCA) resistant integrated circuits. The design flow starts from a\nnormal design in a hardware description language such as VHDL or Verilog and\nprovides a direct path to a SCA resistant layout. Instead of a full custom\nlayout or an iterative design process with extensive simulations, a few key\nmodifications are incorporated in a regular synchronous CMOS standard cell\ndesign flow. We discuss the basis for side-channel attack resistance and adjust\nthe library databases and constraints files of the synthesis and place & route\nprocedures accordingly. Experimental results show that a DPA attack on a\nregular single ended CMOS standard cell implementation of a module of the DES\nalgorithm discloses the secret key after 200 measurements. The same attack on a\nsecure version still does not disclose the secret key after more than 2000\nmeasurements."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4808v1", 
    "title": "Fast and Accurate Transaction Level Modeling of an Extended AMBA2.0 Bus   Architecture", 
    "arxiv-id": "0710.4808v1", 
    "author": "Soo-Kwan Eo", 
    "publish": "2007-10-25T11:59:15Z", 
    "summary": "Transaction Level Modeling (TLM) approach is used to meet the simulation\nspeed as well as cycle accuracy for large scale SoC performance analysis. We\nimplemented a transaction-level model of a proprietary bus called AHB+ which\nsupports an extended AMBA2.0 protocol. The AHB+ transaction-level model shows\n353 times faster than pin-accurate RTL model while maintaining 97% of accuracy\non average. We also present the development procedure of TLM of a bus\narchitecture."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4809v1", 
    "title": "C Based Hardware Design for Wireless Applications", 
    "arxiv-id": "0710.4809v1", 
    "author": "Thomas Bollaert", 
    "publish": "2007-10-25T11:59:48Z", 
    "summary": "The algorithms used in wireless applications are increasingly more\nsophisticated and consequently more challenging to implement in hardware.\nTraditional design flows require developing the micro architecture, coding the\nRTL, and verifying the generated RTL against the original functional C or\nMATLAB specification. This paper describes a C-based design flow that is well\nsuited for the hardware implementation of DSP algorithms commonly found in\nwireless applications. The C design flow relies on guided synthesis to generate\nthe RTL directly from the untimed C algorithm. The specifics of the C-based\ndesign flow are described using a simple DSP filtering algorithm consisting of\na forward adaptive equalizer, a 64-QAM slicer and an adaptive decision feedback\nequalizer. The example illustrates some of the capabilities and advantages\noffered by this flow."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4812v1", 
    "title": "Area and Throughput Trade-Offs in the Design of Pipelined Discrete   Wavelet Transform Architectures", 
    "arxiv-id": "0710.4812v1", 
    "author": "Sergio Bampi", 
    "publish": "2007-10-25T12:00:41Z", 
    "summary": "The JPEG2000 standard defines the discrete wavelet transform (DWT) as a\nlinear space-to-frequency transform of the image domain in an irreversible\ncompression. This irreversible discrete wavelet transform is implemented by FIR\nfilter using 9/7 Daubechies coefficients or a lifting scheme of factorizated\ncoefficients from 9/7 Daubechies coefficients. This work investigates the\ntradeoffs between area, power and data throughput (or operating frequency) of\nseveral implementations of the Discrete Wavelet Transform using the lifting\nscheme in various pipeline designs. This paper shows the results of five\ndifferent architectures synthesized and simulated in FPGAs. It concludes that\nthe descriptions with pipelined operators provide the best area-power-operating\nfrequency trade-off over non-pipelined operators descriptions. Those\ndescriptions require around 40% more hardware to increase the maximum operating\nfrequency up to 100% and reduce power consumption to less than 50%. Starting\nfrom behavioral HDL descriptions provide the best area-power-operating\nfrequency trade-off, improving hardware cost and maximum operating frequency\naround 30% in comparison to structural descriptions for the same power\nrequirement."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4813v1", 
    "title": "Queue Management in Network Processors", 
    "arxiv-id": "0710.4813v1", 
    "author": "A. Nikologiannis", 
    "publish": "2007-10-25T12:00:48Z", 
    "summary": "One of the main bottlenecks when designing a network processing system is\nvery often its memory subsystem. This is mainly due to the state-of-the-art\nnetwork links operating at very high speeds and to the fact that in order to\nsupport advanced Quality of Service (QoS), a large number of independent queues\nis desirable. In this paper we analyze the performance bottlenecks of various\ndata memory managers integrated in typical Network Processing Units (NPUs). We\nexpose the performance limitations of software implementations utilizing the\nRISC processing cores typically found in most NPU architectures and we identify\nthe requirements for hardware assisted memory management in order to achieve\nwire-speed operation at gigabit per second rates. Furthermore, we describe the\narchitecture and performance of a hardware memory manager that fulfills those\nrequirements. This memory manager, although it is implemented in a\nreconfigurable technology, it can provide up to 6.2Gbps of aggregate\nthroughput, while handling 32K independent queues."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4814v1", 
    "title": "picoArray Technology: The Tool's Story", 
    "arxiv-id": "0710.4814v1", 
    "author": "Will Robbins", 
    "publish": "2007-10-25T12:01:15Z", 
    "summary": "This paper briefly describes the picoArray? architecture, and in particular\nthe deterministic internal communication fabric. The methods that have been\ndeveloped for debugging and verifying systems using devices from the picoArray\nfamily are explained. In order to maximize the computational ability of these\ndevices, hardware debugging support has been kept to a minimum and the methods\nand tools developed to take this into account."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4820v1", 
    "title": "ISEGEN: Generation of High-Quality Instruction Set Extensions by   Iterative Improvement", 
    "arxiv-id": "0710.4820v1", 
    "author": "Paolo Ienne", 
    "publish": "2007-10-25T12:04:11Z", 
    "summary": "Customization of processor architectures through Instruction Set Extensions\n(ISEs) is an effective way to meet the growing performance demands of embedded\napplications. A high-quality ISE generation approach needs to obtain results\nclose to those achieved by experienced designers, particularly for complex\napplications that exhibit regularity: expert designers are able to exploit\nmanually such regularity in the data flow graphs to generate high-quality ISEs.\nIn this paper, we present ISEGEN, an approach that identifies high-quality ISEs\nby iterative improvement following the basic principles of the well-known\nKernighan-Lin (K-L) min-cut heuristic. Experimental results on a number of\nMediaBench, EEMBC and cryptographic applications show that our approach matches\nthe quality of the optimal solution obtained by exhaustive search. We also show\nthat our ISEGEN technique is on average 20x faster than a genetic formulation\nthat generates equivalent solutions. Furthermore, the ISEs identified by our\ntechnique exhibit 35% more speedup than the genetic solution on a large\ncryptographic application (AES) by effectively exploiting its regular\nstructure."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4824v1", 
    "title": "FPGA based Agile Algorithm-On-Demand Co-Processor", 
    "arxiv-id": "0710.4824v1", 
    "author": "V. Kamakoti", 
    "publish": "2007-10-25T12:04:43Z", 
    "summary": "With growing computational needs of many real-world applications, frequently\nchanging specifications of standards, and the high design and NRE costs of\nASICs, an algorithm-agile FPGA based co-processor has become a viable\nalternative. In this article, we report about the general design of an\nalgorith-agile co-processor and the proof-of-concept implementation."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4825v1", 
    "title": "Meeting the Embedded Design Needs of Automotive Applications", 
    "arxiv-id": "0710.4825v1", 
    "author": "Wayne Lyons", 
    "publish": "2007-10-25T12:05:33Z", 
    "summary": "The importance of embedded systems in driving innovation in automotive\napplications continues to grow. Understanding the specific needs of developers\ntargeting this market is also helping to drive innovation in RISC core design.\nThis paper describes how a RISC instruction set architecture has evolved to\nbetter meet those needs, and the key implementation features in two very\ndifferent RISC cores are used to demonstrate the challenges of designing for\nreal-time automotive systems."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4826v1", 
    "title": "The Integration of On-Line Monitoring and Reconfiguration Functions   using EDAA - European design and Automation Association1149.4 Into a Safety   Critical Automotive Electronic Control Unit", 
    "arxiv-id": "0710.4826v1", 
    "author": "S. Riches", 
    "publish": "2007-10-25T12:06:43Z", 
    "summary": "This paper presents an innovative application of EDAA - European design and\nAutomation Association 1149.4 and the Integrated Diagnostic Reconfiguration\n(IDR) as tools for the implementation of an embedded test solution for an\nAutomotive Electronic Control Unit implemented as a fully integrated mixed\nsignal system. The paper described how the test architecture can be used for\nfault avoidance with results from a hardware prototype presented. The paper\nconcludes that fault avoidance can be integrated into mixed signal electronic\nsystems to handle key failure modes."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4827v1", 
    "title": "Debug Support, Calibration and Emulation for Multiple Processor and   Powertrain Control SoCs", 
    "arxiv-id": "0710.4827v1", 
    "author": "K. D. Mcdonald-Maier", 
    "publish": "2007-10-25T12:07:17Z", 
    "summary": "The introduction of complex SoCs with multiple processor cores presents new\ndevelopment challenges, such that development support is now a decisive factor\nwhen choosing a System-on-Chip (SoC). The presented developments support\nstrategy addresses the challenges using both architecture and technology\napproaches. The Multi-Core Debug Support (MCDS) architecture provides flexible\ntriggering using cross triggers and a multiple core break and suspend switch.\nTemporal trace ordering is guaranteed down to cycle level by on-chip time\nstamping. The Package Sized-ICE (PSI) approach is a novel method of including\ntrace buffers, overlay memories, processing resources and communication\ninterfaces without changing device behavior. PSI requires no external emulation\nbox, as the debug host interfaces directly with the SoC using a standard\ninterface."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4832v1", 
    "title": "SystemC Analysis of a New Dynamic Power Management Architecture", 
    "arxiv-id": "0710.4832v1", 
    "author": "Massimo Conti", 
    "publish": "2007-10-25T12:10:19Z", 
    "summary": "This paper presents a new dynamic power management architecture of a System\non Chip. The Power State Machine describing the status of the core follows the\nrecommendations of the ACPI standard. The algorithm controls the power states\nof each block on the basis of battery status, chip temperature and a user\ndefined task priority."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4833v1", 
    "title": "Exploiting Real-Time FPGA Based Adaptive Systems Technology for   Real-Time Sensor Fusion in Next Generation Automotive Safety Systems", 
    "arxiv-id": "0710.4833v1", 
    "author": "Chris Sullivan", 
    "publish": "2007-10-25T12:11:11Z", 
    "summary": "We present a system for the boresighting of sensors using inertial\nmeasurement devices as the basis for developing a range of dynamic real-time\nsensor fusion applications. The proof of concept utilizes a COTS FPGA platform\nfor sensor fusion and real-time correction of a misaligned video sensor. We\nexploit a custom-designed 32-bit soft processor core and C-based design &\nsynthesis for rapid, platform-neutral development. Kalman filter and sensor\nfusion techniques established in advanced aviation systems are applied to\nautomotive vehicles with results exceeding typical industry requirements for\nsensor alignment. Results of the static and the dynamic tests demonstrate that\nusing inexpensive accelerometers mounted on (or during assembly of) a sensor\nand an Inertial Measurement Unit (IMU) fixed to a vehicle can be used to\ncompute the misalignment of the sensor to the IMU and thus vehicle. In some\ncases the model predications and test results exceeded the requirements by an\norder of magnitude with a 3-sigma or 99% confidence."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4834v1", 
    "title": "Platform Based Design for Automotive Sensor Conditioning", 
    "arxiv-id": "0710.4834v1", 
    "author": "A. Rocchi", 
    "publish": "2007-10-25T12:12:03Z", 
    "summary": "In this paper a general architecture suitable to interface several kinds of\nsensors for automotive applications is presented. A platform based design\napproach is pursued to improve system performance while minimizing\ntime-to-market.. The platform is composed by an analog front-end and a digital\nsection. The latter is based on a microcontroller core (8051 IP by Oregano)\nplus a set of dedicated hardware dedicated to the complex signal processing\nrequired for sensor conditioning. The microcontroller handles also the\ncommunication with external devices (as a PC) for data output and fast\nprototyping. A case study is presented concerning the conditioning of a Gyro\nyaw rate sensor for automotive applications. Measured performance results\noutperform current state-of-the-art commercial devices."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4838v1", 
    "title": "A 6bit, 1.2GSps Low-Power Flash-ADC in 0.13$\u03bc$m Digital CMOS", 
    "arxiv-id": "0710.4838v1", 
    "author": "Franz Kuttner", 
    "publish": "2007-10-25T12:15:35Z", 
    "summary": "A 6bit flash-ADC with 1.2GSps, wide analog bandwidth and low power, realized\nin a standard digital 0.13 $\\mu$m CMOS copper technology is presented.\nEmploying capacitive interpolation gives various advantages when designing for\nlow power: no need for a reference resistor ladder, implicit sample-and-hold\noperation, no edge effects in the interpolation network (as compared to\nresistive interpolation), and a very low input capacitance of only 400fF, which\nleads to an easily drivable analog converter interface. Operating at 1.2GSps\nthe ADC achieves an effective resolution bandwidth (ERBW) of 700MHz, while\nconsuming 160mW of power. At 600MSps we achieve an ERBW of 600MHz with only\n90mW power consumption, both from a 1.5V supply. This corresponds to\noutstanding Figure-of-Merit numbers (FoM) of 2.2 and 1.5pJ/convstep,\nrespectively. The module area is 0.12mm^2."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4839v1", 
    "title": "A 97mW 110MS/s 12b Pipeline ADC Implemented in 0.18$\u03bc$m Digital CMOS", 
    "arxiv-id": "0710.4839v1", 
    "author": "Oystein Moldsvor", 
    "publish": "2007-10-25T12:16:26Z", 
    "summary": "A 12 bit Pipeline ADC fabricated in a 0.18 $\\mu$m pure digital CMOS\ntechnology is presented. Its nominal conversion rate is 110MS/s and the nominal\nsupply voltage is 1.8V. The effective number of bits is 10.4 when a 10MHz input\nsignal with 2V_{P-P} signal swing is applied. The occupied silicon area is\n0.86mm^2 and the power consumption equals 97mW. A switched capacitor bias\ncurrent circuit scale the bias current automatically with the conversion rate,\nwhich gives scaleable power consumption and full performance of the ADC from 20\nto 140MS/s."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4840v1", 
    "title": "Testing Logic Cores using a BIST P1500 Compliant Approach: A Case of   Study", 
    "arxiv-id": "0710.4840v1", 
    "author": "M. Sonza Reorda", 
    "publish": "2007-10-25T12:17:29Z", 
    "summary": "In this paper we describe how we applied a BIST-based approach to the test of\na logic core to be included in System-on-a-chip (SoC) environments. The\napproach advantages are the ability to protect the core IP, the simple test\ninterface (thanks also to the adoption of the P1500 standard), the possibility\nto run the test at-speed, the reduced test time, and the good diagnostic\ncapabilities. The paper reports figures about the achieved fault coverage, the\nrequired area overhead, and the performance slowdown, and compares the figures\nwith those for alternative approaches, such as those based on full scan and\nsequential ATPG."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4842v1", 
    "title": "Using Mobilize Power Management IP for Dynamic & Static Power Reduction   in SoC at 130 nm", 
    "arxiv-id": "0710.4842v1", 
    "author": "Dan Hillman", 
    "publish": "2007-10-25T12:18:38Z", 
    "summary": "At 130 nm and 90 nm, power consumption (both dynamic and static) has become a\nbarrier in the roadmap for SoC designs targeting battery powered, mobile\napplications. This paper presents the results of dynamic and static power\nreduction achieved implementing Tensilica's 32-bit Xtensa microprocessor core,\nusing Virtual Silicon's Power Management IP. Independent voltage islands are\ncreated using Virtual Silicon's VIP PowerSaver standard cells by using voltage\nlevel shifting cells and voltage isolation cells to implement power islands.\nThe VIP PowerSaver standard cells are characterized at 1.2V, 1.0V and 0.8V, to\naccommodate voltage scaling. Power islands can also be turned off completely.\nDesigners can significantly lower both the dynamic power and the quiescent or\nleakage power of their SoC designs, with very little impact on speed or area\nusing Virtual Silicon's VIP Gate Bias standard cells."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4843v1", 
    "title": "MultiNoC: A Multiprocessing System Enabled by a Network on Chip", 
    "arxiv-id": "0710.4843v1", 
    "author": "Fernando Moraes", 
    "publish": "2007-10-25T12:19:07Z", 
    "summary": "The MultiNoC system implements a programmable on-chip multiprocessing\nplatform built on top of an efficient, low area overhead intra-chip\ninterconnection scheme. The employed interconnection structure is a Network on\nChip, or NoC. NoCs are emerging as a viable alternative to increasing demands\non interconnection architectures, due to the following characteristics: (i)\nenergy efficiency and reliability; (ii) scalability of bandwidth, when compared\nto traditional bus architectures; (iii) reusability; (iv) distributed routing\ndecisions. An external host computer feeds MultiNoC with application\ninstructions and data. After this initialization procedure, MultiNoC executes\nsome algorithm. After finishing execution of the algorithm, output data can be\nread back by the host. Sequential or parallel algorithms conveniently adapted\nto the MultiNoC structure can be executed. The main motivation to propose this\ndesign is to enable the investigation of current trends to increase the number\nof embedded processors in SoCs, leading to the concept of \"sea of processors\"\nsystems."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4844v1", 
    "title": "A Partitioning Methodology for Accelerating Applications in Hybrid   Reconfigurable Platforms", 
    "arxiv-id": "0710.4844v1", 
    "author": "C. E. Goutis", 
    "publish": "2007-10-25T12:20:27Z", 
    "summary": "In this paper, we propose a methodology for partitioning and mapping\ncomputational intensive applications in reconfigurable hardware blocks of\ndifferent granularity. A generic hybrid reconfigurable architecture is\nconsidered so as the methodology can be applicable to a large number of\nheterogeneous reconfigurable platforms. The methodology mainly consists of two\nstages, the analysis and the mapping of the application onto fine and\ncoarse-grain hardware resources. A prototype framework consisting of analysis,\npartitioning and mapping tools has been also developed. For the coarse-grain\nreconfigurable hardware, we use our previous-developed high-performance\ncoarse-grain data-path. In this work, the methodology is validated using two\nreal-world applications, an OFDM transmitter and a JPEG encoder. In the case of\nthe OFDM transmitter, a maximum clock cycles decrease of 82% relative to the\nones in an all fine-grain mapping solution is achieved. The corresponding\nperformance improvement for the JPEG is 43%."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4845v1", 
    "title": "Evaluation of SystemC Modelling of Reconfigurable Embedded Systems", 
    "arxiv-id": "0710.4845v1", 
    "author": "Wayne Luk", 
    "publish": "2007-10-25T12:21:19Z", 
    "summary": "This paper evaluates the use of pin and cycle accurate SystemC models for\nembedded system design exploration and early software development. The target\nsystem is MicroBlaze VanillaNet Platform running MicroBlaze uClinux operating\nsystem. The paper compares Register Transfer Level (RTL) Hardware Description\nLanguage (HDL) simulation speed to the simulation speed of several different\nSystemC models. It is shown that simulation speed of pin and cycle accurate\nmodels can go up to 150 kHz, compared to 100 Hz range of HDL simulation.\nFurthermore, utilising techniques that temporarily compromise cycle accuracy,\neffective simulation speed of up to 500 kHz can be obtained."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.31", 
    "link": "http://arxiv.org/pdf/0710.4850v1", 
    "title": "Hardware Support for QoS-based Function Allocation in Reconfigurable   Systems", 
    "arxiv-id": "0710.4850v1", 
    "author": "Jurgen Becker", 
    "publish": "2007-10-25T12:24:59Z", 
    "summary": "This contribution presents a new approach for allocating suitable\nfunction-implementation variants depending on given quality-of-service\nfunction-requirements for run-time reconfigurable multi-device systems. Our\napproach adapts methodologies from the domain of knowledge-based systems which\ncan be used for doing run-time hardware/software resource usage optimizations."
},{
    "category": "cs.AR", 
    "doi": "10.1017/S0960129509990314", 
    "link": "http://arxiv.org/pdf/0711.0838v2", 
    "title": "On the operating unit size of load/store architectures", 
    "arxiv-id": "0711.0838v2", 
    "author": "C. A. Middelburg", 
    "publish": "2007-11-06T11:16:34Z", 
    "summary": "We introduce a strict version of the concept of a load/store instruction set\narchitecture in the setting of Maurer machines. We take the view that\ntransformations on the states of a Maurer machine are achieved by applying\nthreads as considered in thread algebra to the Maurer machine. We study how the\ntransformations on the states of the main memory of a strict load/store\ninstruction set architecture that can be achieved by applying threads depend on\nthe operating unit size, the cardinality of the instruction set, and the\nmaximal number of states of the threads."
},{
    "category": "cs.AR", 
    "doi": "10.1017/S0960129509990314", 
    "link": "http://arxiv.org/pdf/0711.2383v1", 
    "title": "Decoding the Golden Code: a VLSI design", 
    "arxiv-id": "0711.2383v1", 
    "author": "Emanuele Viterbo", 
    "publish": "2007-11-15T11:55:30Z", 
    "summary": "The recently proposed Golden code is an optimal space-time block code for 2 X\n2 multiple-input multiple-output (MIMO) systems. The aim of this work is the\ndesign of a VLSI decoder for a MIMO system coded with the Golden code. The\narchitecture is based on a rearrangement of the sphere decoding algorithm that\nachieves maximum-likelihood (ML) decoding performance. Compared to other\napproaces, the proposed solution exhibits an inherent flexibility in terms of\nmodulation schemes QAM modulation size and this makes our architecture\nparticularly suitable for adaptive modulation schemes."
},{
    "category": "cs.AR", 
    "doi": "10.1017/S0960129509990314", 
    "link": "http://arxiv.org/pdf/0711.2671v1", 
    "title": "Combined Integer and Variable Precision (CIVP) Floating Point   Multiplication Architecture for FPGAs", 
    "arxiv-id": "0711.2671v1", 
    "author": "Kamal K. Sharma", 
    "publish": "2007-11-16T20:18:32Z", 
    "summary": "In this paper, we propose an architecture/methodology for making FPGAs\nsuitable for integer as well as variable precision floating point\nmultiplication. The proposed work will of great importance in applications\nwhich requires variable precision floating point multiplication such as\nmulti-media processing applications. In the proposed architecture/methodology,\nwe propose the replacement of existing 18x18 bit and 25x18 bit dedicated\nmultipliers in FPGAs with dedicated 24x24 bit and 24x9 bit multipliers,\nrespectively. We have proved that our approach of providing the dedicated 24x24\nbit and 24x9 bit multipliers in FPGAs will make them efficient for performing\ninteger as well as single precision, double precision, and Quadruple precision\nfloating point multiplications."
},{
    "category": "cs.AR", 
    "doi": "10.1017/S0960129509990314", 
    "link": "http://arxiv.org/pdf/0711.2674v1", 
    "title": "Partial Reversible Gates(PRG) for Reversible BCD Arithmetic", 
    "arxiv-id": "0711.2674v1", 
    "author": "Kamal K. Sharma", 
    "publish": "2007-11-16T20:25:20Z", 
    "summary": "IEEE 754r is the ongoing revision to the IEEE 754 floating point standard and\na major enhancement to the standard is the addition of decimal format.\nFurthermore, in the recent years reversible logic has emerged as a promising\ncomputing paradigm having its applications in low power CMOS, quantum\ncomputing, nanotechnology, and optical computing. The major goal in reversible\nlogic is to minimize the number of reversible gates and garbage outputs. Thus,\nthis paper proposes the novel concept of partial reversible gates that will\nsatisfy the reversibility criteria for specific cases in BCD arithmetic. The\npartial reversible gate is proposed to minimize the number of reversible gates\nand garbage outputs, while designing the reversible BCD arithmetic circuits."
},{
    "category": "cs.AR", 
    "doi": "10.1017/S0960129509990314", 
    "link": "http://arxiv.org/pdf/0802.3441v1", 
    "title": "Efficient implementation of GALS systems over commercial synchronous   FPGAs: a new approach", 
    "arxiv-id": "0802.3441v1", 
    "author": "Javier D. Garcia-Lasheras", 
    "publish": "2008-02-23T13:11:13Z", 
    "summary": "The new vision presented is aimed to overcome the logic overhead issues that\nprevious works exhibit when applying GALS techniques to programmable logic\ndevices. The proposed new view relies in a 2-phase, bundled data parity based\nprotocol for data transfer and clock generation tasks. The ability of the\nintroduced methodology for smart real-time delay selection allows the\nimplementation of a variety of new methodologies for electromagnetic\ninterference mitigation and device environment changes adaptation."
},{
    "category": "cs.AR", 
    "doi": "10.1007/978-3-642-03354-4_7", 
    "link": "http://arxiv.org/pdf/0807.1765v1", 
    "title": "Archer: A Community Distributed Computing Infrastructure for Computer   Architecture Research and Education", 
    "arxiv-id": "0807.1765v1", 
    "author": "Gary Tyson", 
    "publish": "2008-07-11T02:47:55Z", 
    "summary": "This paper introduces Archer, a community-based computing resource for\ncomputer architecture research and education. The Archer infrastructure\nintegrates virtualization and batch scheduling middleware to deliver\nhigh-throughput computing resources aggregated from resources distributed\nacross wide-area networks and owned by different participating entities in a\nseamless manner. The paper discusses the motivations leading to the design of\nArcher, describes its core middleware components, and presents an analysis of\nthe functionality and performance of a prototype wide-area deployment running a\nrepresentative computer architecture simulation workload."
},{
    "category": "cs.AR", 
    "doi": "10.1007/978-3-642-03354-4_7", 
    "link": "http://arxiv.org/pdf/0807.3732v1", 
    "title": "An adaptive embedded architecture for real-time Particle Image   Velocimetry algorithms", 
    "arxiv-id": "0807.3732v1", 
    "author": "Virginie Fresse", 
    "publish": "2008-07-23T19:22:06Z", 
    "summary": "Particle Image Velocimetry (PIV) is a method of im-aging and analysing fields\nof flows. The PIV tech-niques compute and display all the motion vectors of the\nfield in a resulting image. Speeds more than thou-sand vectors per second can\nbe required, each speed being environment-dependent. Essence of this work is to\npropose an adaptive FPGA-based system for real-time PIV algorithms. The\nproposed structure is ge-neric so that this unique structure can be re-used for\nany PIV applications that uses the cross-correlation technique. The major\nstructure remains unchanged, adaptations only concern the number of processing\noperations. The required speed (corresponding to the number of vector per\nsecond) is obtained thanks to a parallel processing strategy. The image\nprocessing designer duplicates the processing modules to distrib-ute the\noperations. The result is a FPGA-based archi-tecture, which is easily adapted\nto algorithm specifica-tions without any hardware requirement. The design flow\nis fast and reliable."
},{
    "category": "cs.AR", 
    "doi": "10.1007/978-3-642-03354-4_7", 
    "link": "http://arxiv.org/pdf/0808.2584v2", 
    "title": "On Transformations of Load-Store Maurer Instruction Set Architecture", 
    "arxiv-id": "0808.2584v2", 
    "author": "Tie Hou", 
    "publish": "2008-08-19T12:31:07Z", 
    "summary": "In this paper, we study how certain conditions can affect the transformations\non the states of the memory of a strict load-store Maurer ISA, when half of the\ndata memory serves as the part of the operating unit."
},{
    "category": "cs.AR", 
    "doi": "10.1007/978-3-642-03354-4_7", 
    "link": "http://arxiv.org/pdf/0808.2602v2", 
    "title": "Easily testable logical networks based on a 'widened long flip-flop'", 
    "arxiv-id": "0808.2602v2", 
    "author": "Nick Stukach", 
    "publish": "2008-08-19T14:44:05Z", 
    "summary": "The article describes an attempt to solve at once three basic problems\narising at testing a complex digital equipment for defects: 1) the problem of\nan exponential increasing of the complexity of testing the equipment with the\ncomplexity of the equipment; 2) the problem of testing of the tester; 3) the\nproblem of a mutual masking of defects. The proposed solution is nothing more\nthan using certain limitations for connections between usual logical gates.\nArbitrary multiple stuck-at-faults are supposed as defects."
},{
    "category": "cs.AR", 
    "doi": "10.1007/978-3-642-03354-4_7", 
    "link": "http://arxiv.org/pdf/0812.3871v1", 
    "title": "Decting Errors in Reversible Circuits With Invariant Relationships", 
    "arxiv-id": "0812.3871v1", 
    "author": "Nuno Alves", 
    "publish": "2008-12-19T18:14:54Z", 
    "summary": "Reversible logic is experience renewed interest as we are approach the limits\nof CMOS technologies. While physical implementations of reversible gates have\nyet to materialize, it is safe to assume that they will rely on faulty\nindividual components. In this work we present a present a method to provide\nfault tolerance to a reversible circuit based on invariant relationships."
},{
    "category": "cs.AR", 
    "doi": "10.1007/978-3-642-03354-4_7", 
    "link": "http://arxiv.org/pdf/0901.4081v1", 
    "title": "Adaptive FPGA NoC-based Architecture for Multispectral Image Correlation", 
    "arxiv-id": "0901.4081v1", 
    "author": "Viktor Fischer", 
    "publish": "2009-01-26T19:54:27Z", 
    "summary": "An adaptive FPGA architecture based on the NoC (Network-on-Chip) approach is\nused for the multispectral image correlation. This architecture must contain\nseveral distance algorithms depending on the characteristics of spectral images\nand the precision of the authentication. The analysis of distance algorithms is\nrequired which bases on the algorithmic complexity, result precision, execution\ntime and the adaptability of the implementation. This paper presents the\ncomparison of these distance computation algorithms on one spectral database.\nThe result of a RGB algorithm implementation was discussed."
},{
    "category": "cs.AR", 
    "doi": "10.1007/978-3-642-03354-4_7", 
    "link": "http://arxiv.org/pdf/0906.3832v1", 
    "title": "Hardware Trojan by Hot Carrier Injection", 
    "arxiv-id": "0906.3832v1", 
    "author": "W. Clay", 
    "publish": "2009-06-20T22:56:19Z", 
    "summary": "This paper discusses how hot carrier injection (HCI) can be exploited to\ncreate a trojan that will cause hardware failures. The trojan is produced not\nvia additional logic circuitry but by controlled scenarios that maximize and\naccelerate the HCI effect in transistors. These scenarios range from\nmanipulating the manufacturing process to varying the internal voltage\ndistribution. This new type of trojan is difficult to test due to its gradual\nhardware degradation mechanism. This paper describes the HCI effect, detection\ntechniques and discusses the possibility for maliciously induced HCI trojans."
},{
    "category": "cs.AR", 
    "doi": "10.1007/978-3-642-03354-4_7", 
    "link": "http://arxiv.org/pdf/0906.3834v1", 
    "title": "Exploiting Semiconductor Properties for Hardware Trojans", 
    "arxiv-id": "0906.3834v1", 
    "author": "W. Clay", 
    "publish": "2009-06-20T23:12:45Z", 
    "summary": "This paper discusses the possible introduction of hidden reliability defects\nduring CMOS foundry fabrication processes that may lead to accelerated wearout\nof the devices. These hidden defects or hardware Trojans can be created by\ndeviation from foundry design rules and processing parameters. The Trojans are\nproduced by exploiting time-based wearing mechanisms (HCI, NBTI, TDDB and EM)\nand/or condition-based triggers (ESD, Latchup and Softerror). This class of\nlatent damage is difficult to test due to its gradual degradation nature. The\npaper describes life-time expectancy results for various Trojan induced\nscenarios. Semiconductor properties, processing and design parameters critical\nfor device reliability and Trojan creation are discussed."
},{
    "category": "cs.AR", 
    "doi": "10.1007/978-3-642-03354-4_7", 
    "link": "http://arxiv.org/pdf/0909.0099v1", 
    "title": "Hardware Virtualization Support In INTEL, AMD And IBM Power Processors", 
    "arxiv-id": "0909.0099v1", 
    "author": "Md. Ashraful Islam", 
    "publish": "2009-09-01T06:15:22Z", 
    "summary": "At present, the mostly used and developed mechanism is hardware\nvirtualization which provides a common platform to run multiple operating\nsystems and applications in independent partitions. More precisely, it is all\nabout resource virtualization as the term hardware virtualization is\nemphasized. In this paper, the aim is to find out the advantages and\nlimitations of current virtualization techniques, analyze their cost and\nperformance and also depict which forthcoming hardware virtualization\ntechniques will able to provide efficient solutions for multiprocessor\noperating systems. This is done by making a methodical literature survey and\nstatistical analysis of the benchmark reports provided by SPEC (Standard\nPerformance Evaluation Corporation) and TPC (Transaction processing Performance\nCouncil). Finally, this paper presents the current aspects of hardware\nvirtualization which will help the IT managers of the large organizations to\ntake effective decision while choosing server with virtualization support.\nAgain, the future works described in section 4 of this paper focuses on some\nreal world challenges such as abstraction of multiple servers, language level\nvirtualization, pre-virtualization etc. which may be point of great interest\nfor the researchers."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TCSI.2010.2046257", 
    "link": "http://arxiv.org/pdf/0909.1876v1", 
    "title": "Turbo NOC: a framework for the design of Network On Chip based turbo   decoder architectures", 
    "arxiv-id": "0909.1876v1", 
    "author": "Guido Masera", 
    "publish": "2009-09-10T07:29:52Z", 
    "summary": "This work proposes a general framework for the design and simulation of\nnetwork on chip based turbo decoder architectures. Several parameters in the\ndesign space are investigated, namely the network topology, the parallelism\ndegree, the rate at which messages are sent by processing nodes over the\nnetwork and the routing strategy. The main results of this analysis are: i) the\nmost suited topologies to achieve high throughput with a limited complexity\noverhead are generalized de-Bruijn and generalized Kautz topologies; ii)\ndepending on the throughput requirements different parallelism degrees, message\ninjection rates and routing algorithms can be used to minimize the network area\noverhead."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TCSII.2010.2056014", 
    "link": "http://arxiv.org/pdf/0910.3427v4", 
    "title": "A Scalable VLSI Architecture for Soft-Input Soft-Output Depth-First   Sphere Decoding", 
    "arxiv-id": "0910.3427v4", 
    "author": "Heinrich Meyr", 
    "publish": "2009-10-18T21:51:55Z", 
    "summary": "Multiple-input multiple-output (MIMO) wireless transmission imposes huge\nchallenges on the design of efficient hardware architectures for iterative\nreceivers. A major challenge is soft-input soft-output (SISO) MIMO demapping,\noften approached by sphere decoding (SD). In this paper, we introduce the - to\nour best knowledge - first VLSI architecture for SISO SD applying a single\ntree-search approach. Compared with a soft-output-only base architecture\nsimilar to the one proposed by Studer et al. in IEEE J-SAC 2008, the\narchitectural modifications for soft input still allow a one-node-per-cycle\nexecution. For a 4x4 16-QAM system, the area increases by 57% and the operating\nfrequency degrades by 34% only."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TCSII.2010.2056014", 
    "link": "http://arxiv.org/pdf/0910.3736v1", 
    "title": "A Fault-tolerant Structure for Reliable Multi-core Systems Based on   Hardware-Software Co-design", 
    "arxiv-id": "0910.3736v1", 
    "author": "Hui Wang", 
    "publish": "2009-10-20T04:01:51Z", 
    "summary": "To cope with the soft errors and make full use of the multi-core system, this\npaper gives an efficient fault-tolerant hardware and software co-designed\narchitecture for multi-core systems. And with a not large number of test\npatterns, it will use less than 33% hardware resources compared with the\ntraditional hardware redundancy (TMR) and it will take less than 50% time\ncompared with the traditional software redundancy (time redundant).Therefore,\nit will be a good choice for the fault-tolerant architecture for the future\nhigh-reliable multi-core systems."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TCSII.2010.2056014", 
    "link": "http://arxiv.org/pdf/1001.3716v1", 
    "title": "A Multicore Processor based Real-Time System for Automobile management   application", 
    "arxiv-id": "1001.3716v1", 
    "author": "T. R. Gopalakrishnan Nair", 
    "publish": "2010-01-21T04:34:07Z", 
    "summary": "In this paper we propose an Intelligent Management System which is capable of\nmanaging the automobile functions using the rigorous real-time principles and a\nmulticore processor in order to realize higher efficiency and safety for the\nvehicle. It depicts how various automobile functionalities can be fine grained\nand treated to fit in real time concepts. It also shows how the modern\nmulticore processors can be of good use in organizing vast amounts of\ncorrelated functions to be executed in real-time with excellent time\ncommitments. The modeling of the automobile tasks with real time commitments,\norganizing appropriate scheduling for various real time tasks and the usage of\na multicore processor enables the system to realize higher efficiency and offer\nbetter safety levels to the vehicle. The industry available real time operating\nsystem is used for scheduling various tasks and jobs on the multicore\nprocessor."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TCSII.2010.2056014", 
    "link": "http://arxiv.org/pdf/1001.3781v1", 
    "title": "An Architectural Approach for Decoding and Distributing Functions in   FPUs in a Functional Processor System", 
    "arxiv-id": "1001.3781v1", 
    "author": "H. K. Krutthika", 
    "publish": "2010-01-21T11:31:11Z", 
    "summary": "The main goal of this research is to develop the concepts of a revolutionary\nprocessor system called Functional Processor System. The fairly novel work\ncarried out in this proposal concentrates on decoding of function pipelines and\ndistributing it in FPUs as a part of scheduling approach. As the functional\nprograms are super-level programs that entails requirements only at functional\nlevel, decoding of functions and distribution of functions in the heterogeneous\nfunctional processor units are a challenge. We explored the possibilities of\nsegregation of the functions from the application program and distributing the\nfunctions on the relevant FPUs by using address mapping techniques. Here we\npursue the perception of feeding the functions into the processor farm rather\nthan the processor fetching the instructions or functions and executing it.\nThis work is carried out at theoretical levels and it requires a long way to go\nin the realization of this work in hardware perhaps with a large industrial\nteam with a pragmatic time frame."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TCSII.2010.2056014", 
    "link": "http://arxiv.org/pdf/1001.4694v1", 
    "title": "VLSI Architectures for WIMAX Channel Decoders", 
    "arxiv-id": "1001.4694v1", 
    "author": "Guido Masera", 
    "publish": "2010-01-26T14:11:18Z", 
    "summary": "This chapter describes the main architectures proposed in the literature to\nimplement the channel decoders required by the WiMax standard, namely\nconvolutional codes, turbo codes (both block and convolutional) and LDPC. Then\nit shows a complete design of a convolutional turbo code encoder/decoder system\nfor WiMax."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TCSII.2010.2056014", 
    "link": "http://arxiv.org/pdf/1002.1881v1", 
    "title": "Evaluation and Design Space Exploration of a Time-Division Multiplexed   NoC on FPGA for Image Analysis Applications", 
    "arxiv-id": "1002.1881v1", 
    "author": "Anne-Claire Legrand", 
    "publish": "2010-02-09T15:21:20Z", 
    "summary": "The aim of this paper is to present an adaptable Fat Tree NoC architecture\nfor Field Programmable Gate Array (FPGA) designed for image analysis\napplications. Traditional NoCs (Network on Chip) are not optimal for dataflow\napplications with large amount of data. On the opposite, point to point\ncommunications are designed from the algorithm requirements but they are\nexpensives in terms of resource and wire. We propose a dedicated communication\narchitecture for image analysis algorithms. This communication mechanism is a\ngeneric NoC infrastructure dedicated to dataflow image processing applications,\nmixing circuit-switching and packet-switching communications. The complete\narchitecture integrates two dedicated communication architectures and reusable\nIP blocks. Communications are based on the NoC concept to support the high\nbandwidth required for a large number and type of data."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2010.2302", 
    "link": "http://arxiv.org/pdf/1006.1179v1", 
    "title": "Low Power Shift and Add Multiplier Design", 
    "arxiv-id": "1006.1179v1", 
    "author": "Aswathy Ramesan", 
    "publish": "2010-06-07T06:32:39Z", 
    "summary": "Today every circuit has to face the power consumption issue for both portable\ndevice aiming at large battery life and high end circuits avoiding cooling\npackages and reliability issues that are too complex. It is generally accepted\nthat during logic synthesis power tracks well with area. This means that a\nlarger design will generally consume more power. The multiplier is an important\nkernel of digital signal processors. Because of the circuit complexity, the\npower consumption and area are the two important design considerations of the\nmultiplier. In this paper a low power low area architecture for the shift and\nadd multiplier is proposed. For getting the low power low area architecture,\nthe modifications made to the conventional architecture consist of the\nreduction in switching activities of the major blocks of the multiplier, which\nincludes the reduction in switching activity of the adder and counter. This\narchitecture avoids the shifting of the multiplier register. The simulation\nresult for 8 bit multipliers shows that the proposed low power architecture\nlowers the total power consumption by 35.25% and area by 52.72 % when compared\nto the conventional architecture. Also the reduction in power consumption\nincreases with the increase in bit width."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2010.2302", 
    "link": "http://arxiv.org/pdf/1008.2729v1", 
    "title": "Asynchronous logic circuits and sheaf obstructions", 
    "arxiv-id": "1008.2729v1", 
    "author": "Michael Robinson", 
    "publish": "2010-08-16T18:14:06Z", 
    "summary": "This article exhibits a particular encoding of logic circuits into a sheaf\nformalism. The central result of this article is that there exists strictly\nmore information available to a circuit designer in this setting than exists in\nstatic truth tables, but less than exists in event-level simulation. This\ninformation is related to the timing behavior of the logic circuits, and\nthereby provides a ``bridge'' between static logic analysis and detailed\nsimulation."
},{
    "category": "cs.AR", 
    "doi": "10.3329/jbas.v32i2.2431", 
    "link": "http://arxiv.org/pdf/1008.3288v1", 
    "title": "Reversible Logic Synthesis of Fault Tolerant Carry Skip BCD Adder", 
    "arxiv-id": "1008.3288v1", 
    "author": "Zerina Begum", 
    "publish": "2010-08-19T12:25:44Z", 
    "summary": "Reversible logic is emerging as an important research area having its\napplication in diverse fields such as low power CMOS design, digital signal\nprocessing, cryptography, quantum computing and optical information processing.\nThis paper presents a new 4*4 parity preserving reversible logic gate, IG. The\nproposed parity preserving reversible gate can be used to synthesize any\narbitrary Boolean function. It allows any fault that affects no more than a\nsingle signal readily detectable at the circuit's primary outputs. It is shown\nthat a fault tolerant reversible full adder circuit can be realized using only\ntwo IGs. The proposed fault tolerant full adder (FTFA) is used to design other\narithmetic logic circuits for which it is used as the fundamental building\nblock. It has also been demonstrated that the proposed design offers less\nhardware complexity and is efficient in terms of gate count, garbage outputs\nand constant inputs than the existing counterparts."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ACTEA.2009.5227871", 
    "link": "http://arxiv.org/pdf/1008.3311v1", 
    "title": "Fault tolerant reversible logic synthesis: Carry look-ahead and   carry-skip adders", 
    "arxiv-id": "1008.3311v1", 
    "author": "Mohd. Zulfiquar Hafiz", 
    "publish": "2010-08-19T14:35:12Z", 
    "summary": "Irreversible logic circuits dissipate heat for every bit of information that\nis lost. Information is lost when the input vector cannot be recovered from its\ncorresponding output vector. Reversible logic circuit naturally takes care of\nheating because it implements only the functions that have one-to-one mapping\nbetween its input and output vectors. Therefore reversible logic design becomes\none of the promising research directions in low power dissipating circuit\ndesign in the past few years and has found its application in low power CMOS\ndesign, digital signal processing and nanotechnology. This paper presents the\nefficient approaches for designing reversible fast adders that implement carry\nlook-ahead and carry-skip logic. The proposed 16-bit high speed reversible\nadder will include IG gates for the realization of its basic building block.\nThe IG gate is universal in the sense that it can be used to synthesize any\narbitrary Boolean-functions. The IG gate is parity preserving, that is, the\nparity of the inputs matches the parity of the outputs. It allows any fault\nthat affects no more than a single signal readily detectable at the circuit's\nprimary outputs. Therefore, the proposed high speed adders will have the\ninherent opportunity of detecting errors in its output side. It has also been\ndemonstrated that the proposed design offers less hardware complexity and is\nefficient in terms of gate count, garbage outputs and constant inputs than the\nexisting counterparts."
},{
    "category": "cs.AR", 
    "doi": "10.1109/CAS-ICTD.2009.4960883", 
    "link": "http://arxiv.org/pdf/1008.3340v1", 
    "title": "Synthesis of Fault Tolerant Reversible Logic Circuits", 
    "arxiv-id": "1008.3340v1", 
    "author": "Abdullah Al Mahmud", 
    "publish": "2010-08-19T16:12:11Z", 
    "summary": "Reversible logic is emerging as an important research area having its\napplication in diverse fields such as low power CMOS design, digital signal\nprocessing, cryptography, quantum computing and optical information processing.\nThis paper presents a new 4*4 universal reversible logic gate, IG. It is a\nparity preserving reversible logic gate, that is, the parity of the inputs\nmatches the parity of the outputs. The proposed parity preserving reversible\ngate can be used to synthesize any arbitrary Boolean function. It allows any\nfault that affects no more than a single signal readily detectable at the\ncircuit's primary outputs. Finally, it is shown how a fault tolerant reversible\nfull adder circuit can be realized using only two IGs. It has also been\ndemonstrated that the proposed design offers less hardware complexity and is\nefficient in terms of gate count, garbage outputs and constant inputs than the\nexisting counterparts."
},{
    "category": "cs.AR", 
    "doi": "10.1109/CAS-ICTD.2009.4960883", 
    "link": "http://arxiv.org/pdf/1008.3344v1", 
    "title": "Efficient Approaches for Designing Fault Tolerant Reversible Carry   Look-Ahead and Carry-Skip Adders", 
    "arxiv-id": "1008.3344v1", 
    "author": "Mohd. Zulfiquar Hafiz", 
    "publish": "2010-08-19T16:27:28Z", 
    "summary": "Combinational or Classical logic circuits dissipate heat for every bit of\ninformation that is lost. Information is lost when the input vector cannot be\nrecovered from its corresponding output vector. Reversible logic circuit\nimplements only the functions having one-to-one mapping between its input and\noutput vectors and therefore naturally takes care of heating. Reversible logic\ndesign becomes one of the promising research directions in low power\ndissipating circuit design in the past few years and has found its application\nin low power CMOS design, digital signal processing and nanotechnology. This\npaper presents the efficient approaches for designing fault tolerant reversible\nfast adders that implement carry look-ahead and carry-skip logic. The proposed\nhigh speed reversible adders include MIG gates for the realization of its basic\nbuilding block. The MIG gate is universal and parity preserving. It allows any\nfault that affects no more than a single signal readily detectable at the\ncircuit's primary outputs. It has also been demonstrated that the proposed\ndesign offers less hardware complexity and is efficient in terms of gate count,\ngarbage outputs and constant inputs than the existing counterparts."
},{
    "category": "cs.AR", 
    "doi": "10.1109/CAS-ICTD.2009.4960883", 
    "link": "http://arxiv.org/pdf/1008.3352v1", 
    "title": "Variable Block Carry Skip Logic using Reversible Gates", 
    "arxiv-id": "1008.3352v1", 
    "author": "Hafiz Md. Hasan Babu", 
    "publish": "2010-08-19T17:07:51Z", 
    "summary": "Reversible circuits have applications in digital signal processing, computer\ngraphics, quantum computation and cryptography. In this paper, a generalized\nk*k reversible gate family is proposed and a 3*3 gate of the family is\ndiscussed. Inverter, AND, OR, NAND, NOR, and EXOR gates can be realized by this\ngate. Implementation of a full-adder circuit using two such 3*3 gates is given.\nThis full-adder circuit contains only two reversible gates and produces no\nextra garbage outputs. The proposed full-adder circuit is efficient in terms of\ngate count, garbage outputs and quantum cost. A 4-bit carry skip adder is\ndesigned using this full-adder circuit and a variable block carry skip adder is\ndiscussed. Necessary equations required to evaluate these adder are presented."
},{
    "category": "cs.AR", 
    "doi": "10.1109/CAS-ICTD.2009.4960883", 
    "link": "http://arxiv.org/pdf/1008.3357v1", 
    "title": "Building Toffoli Network for Reversible Logic Synthesis Based on   Swapping Bit Strings", 
    "arxiv-id": "1008.3357v1", 
    "author": "Abdullah Al Mahmud", 
    "publish": "2010-08-19T17:21:54Z", 
    "summary": "In this paper, we have implemented and designed a sorting network for\nreversible logic circuits synthesis in terms of n*n Toffoli gates. The\nalgorithm presented in this paper constructs a Toffoli Network based on\nswapping bit strings. Reduction rules are then applied by simple template\nmatching and removing useless gates from the network. Random selection of bit\nstrings and reduction of control inputs are used to minimize both the number of\ngates and gate width. The method produces near optimal results for up to\n3-input 3-output circuits."
},{
    "category": "cs.AR", 
    "doi": "10.1109/CAS-ICTD.2009.4960883", 
    "link": "http://arxiv.org/pdf/1008.3452v2", 
    "title": "Memristor-based Circuits for Performing Basic Arithmetic Operations", 
    "arxiv-id": "1008.3452v2", 
    "author": "Saeed Bagheri Shouraki", 
    "publish": "2010-08-20T07:53:24Z", 
    "summary": "In almost all of the currently working circuits, especially in analog\ncircuits implementing signal processing applications, basic arithmetic\noperations such as multiplication, addition, subtraction and division are\nperformed on values which are represented by voltages or currents. However, in\nthis paper, we propose a new and simple method for performing analog arithmetic\noperations which in this scheme, signals are represented and stored through a\nmemristance of the newly found circuit element, i.e. memristor, instead of\nvoltage or current. Some of these operators such as divider and multiplier are\nmuch simpler and faster than their equivalent voltage-based circuits and they\nrequire less chip area. In addition, a new circuit is designed for programming\nthe memristance of the memristor with predetermined analog value. Presented\nsimulation results demonstrate the effectiveness and the accuracy of the\nproposed circuits."
},{
    "category": "cs.AR", 
    "doi": "10.1109/CAS-ICTD.2009.4960883", 
    "link": "http://arxiv.org/pdf/1008.3533v1", 
    "title": "A Novel Quantum Cost Efficient Reversible Full Adder Gate in   Nanotechnology", 
    "arxiv-id": "1008.3533v1", 
    "author": "Md. Saiful Islam", 
    "publish": "2010-08-20T16:23:54Z", 
    "summary": "Reversible logic has become one of the promising research directions in low\npower dissipating circuit design in the past few years and has found its\napplications in low power CMOS design, cryptography, optical information\nprocessing and nanotechnology. This paper presents a novel and quantum cost\nefficient reversible full adder gate in nanotechnology. This gate can work\nsingly as a reversible full adder unit and requires only one clock cycle. The\nproposed gate is a universal gate in the sense that it can be used to\nsynthesize any arbitrary Boolean functions. It has been demonstrated that the\nhardware complexity offered by the proposed gate is less than the existing\ncounterparts. The proposed reversible full adder gate also adheres to the\ntheoretical minimum established by the researchers."
},{
    "category": "cs.AR", 
    "doi": "10.1109/CAS-ICTD.2009.4960883", 
    "link": "http://arxiv.org/pdf/1008.3694v1", 
    "title": "Sorting Network for Reversible Logic Synthesis", 
    "arxiv-id": "1008.3694v1", 
    "author": "Muhammad Rezaul karim", 
    "publish": "2010-08-22T11:13:34Z", 
    "summary": "In this paper, we have introduced an algorithm to implement a sorting network\nfor reversible logic synthesis based on swapping bit strings. The algorithm\nfirst constructs a network in terms of n*n Toffoli gates read from left to\nright. The number of gates in the circuit produced by our algorithm is then\nreduced by template matching and removing useless gates from the network. We\nhave also compared the efficiency of the proposed method with the existing\nones."
},{
    "category": "cs.AR", 
    "doi": "10.1109/CAS-ICTD.2009.4960883", 
    "link": "http://arxiv.org/pdf/1008.4668v1", 
    "title": "BSSSN: Bit String Swapping Sorting Network for Reversible Logic   Synthesis", 
    "arxiv-id": "1008.4668v1", 
    "author": "Md. Saiful Islam", 
    "publish": "2010-08-27T09:05:49Z", 
    "summary": "In this paper, we have introduced the notion of UselessGate and\nReverseOperation. We have also given an algorithm to implement a sorting\nnetwork for reversible logic synthesis based on swapping bit strings. The\nnetwork is constructed in terms of n*n Toffoli Gates read from left to right\nand it has shown that there will be no more gates than the number of swappings\nthe algorithm requires. The gate complexity of the network is O(n2). The number\nof gates in the network can be further reduced by template reduction technique\nand removing UselessGate from the network."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcnc.2010.2409", 
    "link": "http://arxiv.org/pdf/1009.1796v1", 
    "title": "Power optimized programmable embedded controller", 
    "arxiv-id": "1009.1796v1", 
    "author": "A. V. N. Tilak", 
    "publish": "2010-09-09T14:41:27Z", 
    "summary": "Now a days, power has become a primary consideration in hardware design, and\nis critical in computer systems especially for portable devices with high\nperformance and more functionality. Clock-gating is the most common technique\nused for reducing processor's power. In this work clock gating technique is\napplied to optimize the power of fully programmable Embedded Controller (PEC)\nemploying RISC architecture. The CPU designed supports i) smart instruction\nset, ii) I/O port, UART iii) on-chip clocking to provide a range of frequencies\n, iv) RISC as well as controller concepts. The whole design is captured using\nVHDL and is implemented on FPGA chip using Xilinx .The architecture and clock\ngating technique together is found to reduce the power consumption by 33.33% of\ntotal power consumed by this chip."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcnc.2010.2409", 
    "link": "http://arxiv.org/pdf/1009.2622v1", 
    "title": "On the Design and Analysis of Quaternary Serial and Parallel Adders", 
    "arxiv-id": "1009.2622v1", 
    "author": "Masud Hasan", 
    "publish": "2010-09-14T10:48:56Z", 
    "summary": "Optimization techniques for decreasing the time and area of adder circuits\nhave been extensively studied for years mostly in binary logic system. In this\npaper, we provide the necessary equations required to design a full adder in\nquaternary logic system. We develop the equations for single-stage parallel\nadder which works as a carry look-ahead adder. We also provide the design of a\nlogarithmic stage parallel adder which can compute the carries within log2(n)\ntime delay for n qudits. At last, we compare the designs and finally propose a\nhybrid adder which combines the advantages of serial and parallel adder."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcnc.2010.2409", 
    "link": "http://arxiv.org/pdf/1009.3819v1", 
    "title": "Fault Tolerant Variable Block Carry Skip Logic (VBCSL) using Parity   Preserving Reversible Gates", 
    "arxiv-id": "1009.3819v1", 
    "author": "Mohd. Zulfiquar Hafiz", 
    "publish": "2010-09-20T13:53:39Z", 
    "summary": "Reversible logic design has become one of the promising research directions\nin low power dissipating circuit design in the past few years and has found its\napplication in low power CMOS design, digital signal processing and\nnanotechnology. This paper presents the efficient design approaches of fault\ntolerant carry skip adders (FTCSAs) and compares those designs with the\nexisting ones. Variable block carry skip logic (VBCSL) using the fault tolerant\nfull adders (FTFAs) has also been developed. The designs are minimized in terms\nof hardware complexity, gate count, constant inputs and garbage outputs.\nBesides of it, technology independent evaluation of the proposed designs\nclearly demonstrates its superiority with the existing counterparts."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcnc.2010.2409", 
    "link": "http://arxiv.org/pdf/1009.4590v1", 
    "title": "A Unique 10 Segment Display for Bengali Numerals", 
    "arxiv-id": "1009.4590v1", 
    "author": "S. M. Kamruzzaman", 
    "publish": "2010-09-23T12:01:38Z", 
    "summary": "Segmented display is widely used for efficient display of alphanumeric\ncharacters. English numerals are displayed by 7 segment and 16 segment display.\nThe segment size is uniform in this two display architecture. Display\narchitecture using 8, 10, 11, 18 segments have been proposed for Bengali\nnumerals 0...9 yet no display architecture is designed using segments of\nuniform size and uniform power consumption. In this paper we have proposed a\nuniform 10 segment architecture for Bengali numerals. This segment architecture\nuses segments of uniform size and no bent segment is used."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcnc.2010.2409", 
    "link": "http://arxiv.org/pdf/1009.4977v1", 
    "title": "Universal Numeric Segmented Display", 
    "arxiv-id": "1009.4977v1", 
    "author": "S. M. Kamruzzaman", 
    "publish": "2010-09-25T06:17:02Z", 
    "summary": "Segmentation display plays a vital role to display numerals. But in today's\nworld matrix display is also used in displaying numerals. Because numerals has\nlots of curve edges which is better supported by matrix display. But as matrix\ndisplay is costly and complex to implement and also needs more memory, segment\ndisplay is generally used to display numerals. But as there is yet no proposed\ncompact display architecture to display multiple language numerals at a time,\nthis paper proposes uniform display architecture to display multiple language\ndigits and general mathematical expressions with higher accuracy and simplicity\nby using a 18-segment display, which is an improvement over the 16 segment\ndisplay."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcnc.2010.2406", 
    "link": "http://arxiv.org/pdf/1009.6132v1", 
    "title": "Multi-standard programmable baseband modulator for next generation   wireless communication", 
    "arxiv-id": "1009.6132v1", 
    "author": "Indrajit Chakrabarti", 
    "publish": "2010-09-09T04:43:52Z", 
    "summary": "Considerable research has taken place in recent times in the area of\nparameterization of software defined radio (SDR) architecture. Parameterization\ndecreases the size of the software to be downloaded and also limits the\nhardware reconfiguration time. The present paper is based on the design and\ndevelopment of a programmable baseband modulator that perform the QPSK\nmodulation schemes and as well as its other three commonly used variants to\nsatisfy the requirement of several established 2G and 3G wireless communication\nstandards. The proposed design has been shown to be capable of operating at a\nmaximum data rate of 77 Mbps on Xilinx Virtex 2-Pro University field\nprogrammable gate array (FPGA) board. The pulse shaping root raised cosine\n(RRC) filter has been implemented using distributed arithmetic (DA) technique\nin the present work in order to reduce the computational complexity, and to\nachieve appropriate power reduction and enhanced throughput. The designed\nmultiplier-less programmable 32-tap FIR-based RRC filter has been found to\nwithstand a peak inter-symbol interference (ISI) distortion of -41 dBs"
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcnc.2010.2406", 
    "link": "http://arxiv.org/pdf/1011.4157v2", 
    "title": "A full-custom ASIC design of a 8-bit, 25 MHz, Pipeline ADC using 0.35 um   CMOS technology", 
    "arxiv-id": "1011.4157v2", 
    "author": "Imran Khan", 
    "publish": "2010-11-18T09:12:50Z", 
    "summary": "The purpose of this project was to design and implement a pipeline\nAnalog-to-Digital Converter using 0.35um CMOS technology. Initial requirements\nof a 25-MHz conversion rate and 8-bits of resolution where the only given ones.\nAlthough additional secondary goals such as low power consumption and small\narea were stated. The architecture is based on a 1.5 bit per stage structure\nutilizing digital correction for each stage [12]. A differential switched\ncapacitor circuit consisting of a cascade gm-C op-amp with 200MHz ft is used\nfor sampling and amplification in each stage [12]. Differential dynamic\ncomparators are used to implement the decision levels required for the 1.5-b\nper stage structure. Correction of the pipeline is accomplished by using\ndigital correction circuit consist of D-latches and full-adders. Area and Power\nconsumption of whole design was 0.24mm2 and 35mW respectively. The maximum\nsample rate at which the converter gave an adequate output was 33MHz."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcnc.2010.2406", 
    "link": "http://arxiv.org/pdf/1101.3698v1", 
    "title": "Systolic Arrays for Lattice-Reduction-Aided MIMO Detection", 
    "arxiv-id": "1101.3698v1", 
    "author": "Kung Yao", 
    "publish": "2011-01-17T18:09:52Z", 
    "summary": "Multiple-input, multiple-output (MIMO) technology provides high data rate and\nenhanced QoS for wireless com- munications. Since the benefits from MIMO result\nin a heavy computational load in detectors, the design of low-complexity\nsub-optimum receivers is currently an active area of research.\nLattice-reduction-aided detection (LRAD) has been shown to be an effective\nlow-complexity method with near-ML performance. In this paper we advocate the\nuse of systolic array architectures for MIMO receivers, and in particular we\nexhibit one of them based on LRAD. The \"LLL lattice reduction algorithm\" and\nthe ensuing linear detections or successive spatial-interference cancellations\ncan be located in the same array, which is con- siderably hardware-efficient.\nSince the conventional form of the LLL algorithm is not immediately suitable\nfor parallel processing, two modified LLL algorithms are considered here for\nthe systolic array. LLL algorithm with full-size reduction (FSR-LLL) is one of\nthe versions more suitable for parallel processing. Another variant is the\nall-swap lattice-reduction (ASLR) algorithm for complex-valued lattices, which\nprocesses all lattice basis vectors simultaneously within one iteration. Our\nnovel systolic array can operate both algorithms with different external logic\ncontrols. In order to simplify the systolic array design, we replace the\nLov\\'asz condition in the definition of LLL-reduced lattice with the looser\nSiegel condition. Simulation results show that for LR- aided linear detections,\nthe bit-error-rate performance is still maintained with this relaxation.\nComparisons between the two algorithms in terms of bit-error-rate performance,\nand average FPGA processing time in the systolic array are made, which shows\nthat ASLR is a better choice for a systolic architecture, especially for\nsystems with a large number of antennas."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcnc.2010.2406", 
    "link": "http://arxiv.org/pdf/1101.5364v1", 
    "title": "RISC and CISC", 
    "arxiv-id": "1101.5364v1", 
    "author": "Farhat Masood", 
    "publish": "2011-01-27T19:20:42Z", 
    "summary": "Comparison of RISC & CISC in details, encompassing the addressing modes,\nevolution, definitions and characteristics. Pre - RISC design is also\nelaborated. Both the architectures are explained with the help of example.\nAnalysis is made based on performance."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcnc.2010.2406", 
    "link": "http://arxiv.org/pdf/1102.0884v1", 
    "title": "A Simulation Experiment on a Built-In Self Test Equipped with   Pseudorandom Test Pattern Generator and Multi-Input Shift Register (MISR)", 
    "arxiv-id": "1102.0884v1", 
    "author": "A. Ahmad", 
    "publish": "2011-02-04T11:40:14Z", 
    "summary": "This paper investigates the impact of the changes of the characteristic\npolynomials and initial loadings, on behaviour of aliasing errors of parallel\nsignature analyzer (Multi-Input Shift Register), used in an LFSR based digital\ncircuit testing technique. The investigation is carried-out through an\nextensive simulation study of the effectiveness of the LFSR based digital\ncircuit testing technique. The results of the study show that when the\nidentical characteristic polynomials of order n are used in both pseudo-random\ntest-pattern generator, as well as in Multi-Input Shift Register (MISR)\nsignature analyzer (parallel type) then the probability of aliasing errors\nremains unchanged due to the changes in the initial loadings of the\npseudo-random test-pattern generator."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcnc.2010.2406", 
    "link": "http://arxiv.org/pdf/1105.1014v1", 
    "title": "Improving Network-on-Chip-based turbo decoder architectures", 
    "arxiv-id": "1105.1014v1", 
    "author": "Guido Masera", 
    "publish": "2011-05-05T08:41:43Z", 
    "summary": "In this work novel results concerning Network-on-Chip-based turbo decoder\narchitectures are presented. Stemming from previous publications, this work\nconcentrates first on improving the throughput by exploiting adaptive-bandwidth\nreduction techniques. This technique shows in the best case an improvement of\nmore than 60 Mb/s. Moreover, it is known that double-binary turbo decoders\nrequire higher area than binary ones. This characteristic has the negative\neffect of increasing the data width of the network nodes. Thus, the second\ncontribution of this work is to reduce the network complexity to support\ndoublebinary codes, by exploiting bit-level and pseudo-floating-point\nrepresentation of the extrinsic information. These two techniques allow for an\narea reduction of up to more than the 40% with a performance degradation of\nabout 0.2 dB."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcnc.2010.2406", 
    "link": "http://arxiv.org/pdf/1105.1967v1", 
    "title": "Algebra-Logical Repair Method for FPGA Logic Blocks", 
    "arxiv-id": "1105.1967v1", 
    "author": "Olesya Guz", 
    "publish": "2011-05-10T15:03:05Z", 
    "summary": "An algebra-logical repair method for FPGA functional logic blocks on the\nbasis of solving the coverage problem is proposed. It is focused on\nimplementation into Infrastructure IP for system-on-a chip and\nsystem-in-package. A method is designed for providing the operability of FPGA\nblocks and digital system as a whole. It enables to obtain exact and optimal\nsolution associated with the minimum number of spares needed to repair the FPGA\nlogic components with multiple faults."
},{
    "category": "cs.AR", 
    "doi": "10.1109/AQTR.2010.5520841", 
    "link": "http://arxiv.org/pdf/1105.1973v1", 
    "title": "Brain-like infrastructure for embedded SoC diagnosis", 
    "arxiv-id": "1105.1973v1", 
    "author": "Olesya Guz", 
    "publish": "2011-05-10T15:24:49Z", 
    "summary": "This article describes high-speed multiprocessor architecture for the\nconcurrent analyzing information represented in analytic, graph- and table\nforms of associative relations to search, recognize and make a decision in\nn-dimensional vector discrete space. Vector-logical process models of actual\napplications,for which the quality of solution is estimated by the proposed\nintegral non-arithmetical metric of the interaction between Boolean vectors,\nare described."
},{
    "category": "cs.AR", 
    "doi": "10.1109/AQTR.2010.5520841", 
    "link": "http://arxiv.org/pdf/1105.2624v1", 
    "title": "A Flexible LDPC code decoder with a Network on Chip as underlying   interconnect architecture", 
    "arxiv-id": "1105.2624v1", 
    "author": "Guido Masera", 
    "publish": "2011-05-13T07:17:16Z", 
    "summary": "LDPC (Low Density Parity Check) codes are among the most powerful and widely\nadopted modern error correcting codes. The iterative decoding algorithms\nrequired for these codes involve high computational complexity and high\nprocessing throughput is achieved by allocating a sufficient number of\nprocessing elements (PEs). Supporting multiple heterogeneous LDPC codes on a\nparallel decoder poses serious problems in the design of the interconnect\nstructure for such PEs. The aim of this work is to explore the feasibility of\nNoC (Network on Chip) based decoders, where full flexibility in terms of\nsupported LDPC codes is obtained resorting to an NoC to connect PEs. NoC based\nLDPC decoders have been previously considered unfeasible because of the cost\noverhead associated to packet management and routing. On the contrary, the\ndesigned NoC adopts a low complexity routing, which introduces a very limited\ncost overhead with respect to architectures dedicated to specific classes of\ncodes. Moreover the paper proposes an efficient configuration technique, which\nallows for fast on--the--fly switching among different codes. The decoder\narchitecture is scalable and VLSI synthesis results are presented for several\ncases of study, including the whole set of WiMAX LDPC codes, WiFi codes and\nDVB-S2 standard."
},{
    "category": "cs.AR", 
    "doi": "10.1109/AQTR.2010.5520841", 
    "link": "http://arxiv.org/pdf/1105.2960v1", 
    "title": "Multi-Amdahl: Optimal Resource Sharing with Multiple Program Execution   Segments", 
    "arxiv-id": "1105.2960v1", 
    "author": "Uri Weiser", 
    "publish": "2011-05-15T19:03:25Z", 
    "summary": "This paper presents Multi-Amdahl, a resource allocation analytical tool for\nheterogeneous systems. Our model includes multiple program execution segments,\nwhere each one is accelerated by a specific hardware unit. The acceleration\nspeedup of the specific hardware unit is a function of a limited resource, such\nas the unit area, power, or energy. Using the Lagrange theorem we discover the\noptimal resource distribution between all specific units. We then illustrate\nthis general Multi-Amdahl technique using several examples of area and power\nallocation among several cores and accelerators."
},{
    "category": "cs.AR", 
    "doi": "10.1109/AQTR.2010.5520841", 
    "link": "http://arxiv.org/pdf/1106.3677v1", 
    "title": "Pseudo-Ring Testing Schemes and Algorithms of RAM Built-In and Embedded   Self-Testing", 
    "arxiv-id": "1106.3677v1", 
    "author": "Wajeb Gharibi", 
    "publish": "2011-06-18T18:44:38Z", 
    "summary": "Scan and ring schemes of the pseudo-ring memory selftesting are investigated.\nBoth schemes are based on emulation of the linear or nonlinear feedback shift\nregister by memory itself. Peculiarities of the pseudo-ring schemes\nimplementation for multi-port and embedded memories, and for register file are\ndescribed. It is shown that only small additional logic is required and allows\nmicrocontrollers at-speed testing. Also, in this article,are given the a\nposteriori values of some type of memories faults coverage when pseudo-ring\ntesting schemes are applied."
},{
    "category": "cs.AR", 
    "doi": "10.1109/EWDTS.2008.5580135", 
    "link": "http://arxiv.org/pdf/1106.3681v1", 
    "title": "SoC Software Components Diagnosis Technology", 
    "arxiv-id": "1106.3681v1", 
    "author": "Aleksey Sushanov", 
    "publish": "2011-06-18T19:07:44Z", 
    "summary": "A novel approach to evaluation of hardware and software testability,\nrepresented in the form of register transfer graph, is proposed. Instances of\nmaking of software graph models for their subsequent testing and diagnosis are\nshown."
},{
    "category": "cs.AR", 
    "doi": "10.1109/EWDTS.2008.5580135", 
    "link": "http://arxiv.org/pdf/1107.3924v1", 
    "title": "Reversible arithmetic logic unit", 
    "arxiv-id": "1107.3924v1", 
    "author": "Manqun Zhang", 
    "publish": "2011-07-20T09:20:30Z", 
    "summary": "Quantum computer requires quantum arithmetic. The sophisticated design of a\nreversible arithmetic logic unit (reversible ALU) for quantum arithmetic has\nbeen investigated in this letter. We provide explicit construction of\nreversible ALU effecting basic arithmetic operations. By provided the\ncorresponding control unit, the proposed reversible ALU can combine the\nclassical arithmetic and logic operation in a reversible integrated system.\nThis letter provides actual evidence to prove the possibility of the\nrealization of reversible Programmable Logic Device (RPLD) using reversible\nALU."
},{
    "category": "cs.AR", 
    "doi": "10.1109/EWDTS.2008.5580135", 
    "link": "http://arxiv.org/pdf/1108.3970v2", 
    "title": "A Design Methodology for Folded, Pipelined Architectures in VLSI   Applications using Projective Space Lattices", 
    "arxiv-id": "1108.3970v2", 
    "author": "Sachin Patkar", 
    "publish": "2011-08-19T14:32:32Z", 
    "summary": "Semi-parallel, or folded, VLSI architectures are used whenever hardware\nresources need to be saved at design time. Most recent applications that are\nbased on Projective Geometry (PG) based balanced bipartite graph also fall in\nthis category. In this paper, we provide a high-level, top-down design\nmethodology to design optimal semi-parallel architectures for applications,\nwhose Data Flow Graph (DFG) is based on PG bipartite graph. Such applications\nhave been found e.g. in error-control coding and matrix computations. Unlike\nmany other folding schemes, the topology of connections between physical\nelements does not change in this methodology. Another advantage is the ease of\nimplementation. To lessen the throughput loss due to folding, we also\nincorporate a multi-tier pipelining strategy in the design methodology. The\ndesign methodology has been verified by implementing a synthesis tool in C++,\nwhich has been verified as well. The tool is publicly available. Further, a\ncomplete decoder was manually protototyped before the synthesis tool design, to\nverify all the algorithms evolved in this paper, towards various steps of\nrefinement. Another specific high-performance design of an LDPC decoder based\non this methodology was worked out in past, and has been patented as well."
},{
    "category": "cs.AR", 
    "doi": "10.1109/EWDTS.2008.5580135", 
    "link": "http://arxiv.org/pdf/1108.5497v2", 
    "title": "Formulation and Development of a Novel Quaternary Algebra", 
    "arxiv-id": "1108.5497v2", 
    "author": "Masud Hasan", 
    "publish": "2011-08-28T08:07:09Z", 
    "summary": "In this work, a novel quaternary algebra has been proposed that can be used\nto implement any quaternary logic function. Unlike other variants of quaternary\nalgebra, this algebra is closely related to Boolean algebra and can be used to\nconvert any binary function into quaternary without any significant\nmodification. For this purpose, we have defined a set of quaternary operators\nand developed two ways to express any quaternary function mathematically.\nFinally, we have presented the design of several combinational logic circuits\nand compared these designs with several other variants of quaternary logic.\nSince a quaternary digit can contain as much information as a pair of binary\ndigits, this new logic may be quite useful in the fields of communication and\ncomputing."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2011.2306", 
    "link": "http://arxiv.org/pdf/1110.1549v1", 
    "title": "Power comparison of CMOS and adiabatic full adder circuit", 
    "arxiv-id": "1110.1549v1", 
    "author": "Rajendra prasad", 
    "publish": "2011-10-07T14:40:51Z", 
    "summary": "Full adders are important components in applications such as digital signal\nprocessors (DSP) architectures and microprocessors. Apart from the basic\naddition adders also used in performing useful operations such as subtraction,\nmultiplication, division, address calculation, etc. In most of these systems\nthe adder lies in the critical path that determines the overall performance of\nthe system. In this paper conventional complementary metal oxide semiconductor\n(CMOS) and adiabatic adder circuits are analyzed in terms of power and\ntransistor count using 0.18UM technology."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2011.2306", 
    "link": "http://arxiv.org/pdf/1110.3281v4", 
    "title": "Faster Energy Efficient Dadda Based Baugh-Wooley Multipliers", 
    "arxiv-id": "1110.3281v4", 
    "author": "Harish M Kittur", 
    "publish": "2011-10-14T17:52:39Z", 
    "summary": "In this work faster Baugh-Wooley multiplication has been achieved by using a\ncombination of two design techniques: partition of the partial products into\ntwo parts for independent parallel column compression and acceleration of the\nfinal addition using a hybrid adder proposed in this work. Based on the\nproposed techniques 8, 16, 32 and 64-bit Dadda based Baugh-Wooley multipliers\nhas been developed and compared with the regular Baugh-Wooley multiplier. The\nperformance of the proposed multiplier is analyzed by evaluating the delay,\narea and power, with 180 nm process technologies on interconnect and layout\nusing industry standard design and layout tools. The result analysis shows that\nthe 64-bit proposed multiplier is as much as 26.9% faster than the regular\nBaugh-Wooley multiplier and requires only 2.21% more power. Also the\npower-delay product of the proposed design is significantly lower than that of\nthe regular Baugh-Wooley multiplier."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2011.2306", 
    "link": "http://arxiv.org/pdf/1110.3376v2", 
    "title": "Faster and Low Power Twin Precision Multiplier", 
    "arxiv-id": "1110.3376v2", 
    "author": "Harish M Kittur", 
    "publish": "2011-10-15T03:54:27Z", 
    "summary": "In this work faster unsigned multiplication has been achieved by using a\ncombination of High Performance Multiplication [HPM] column reduction technique\nand implementing a N-bit multiplier using 4 N/2-bit multipliers (recursive\nmultiplication) and acceleration of the final addition using a hybrid adder.\nLow power has been achieved by using clock gating technique. Based on the\nproposed technique 16 and 32-bit multipliers are developed. The performance of\nthe proposed multiplier is analyzed by evaluating the delay, area and power,\nwith TCBNPHP 90 nm process technology on interconnect and layout using Cadence\nNC launch, RTL compiler and ENCOUNTER tools. The results show that the 32-bit\nproposed multiplier is as much as 22% faster, occupies only 3% more area and\nconsumes 30% lesser power with respect to the recently reported twin precision\nmultiplier."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2011.2306", 
    "link": "http://arxiv.org/pdf/1110.3535v1", 
    "title": "Multi-core processors - An overview", 
    "arxiv-id": "1110.3535v1", 
    "author": "Balaji Venu", 
    "publish": "2011-10-16T22:48:56Z", 
    "summary": "Microprocessors have revolutionized the world we live in and continuous\nefforts are being made to manufacture not only faster chips but also smarter\nones. A number of techniques such as data level parallelism, instruction level\nparallelism and hyper threading (Intel's HT) already exists which have\ndramatically improved the performance of microprocessor cores. This paper\nbriefs on evolution of multi-core processors followed by introducing the\ntechnology and its advantages in today's world. The paper concludes by\ndetailing on the challenges currently faced by multi-core processors and how\nthe industry is trying to address these issues."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2011.2306", 
    "link": "http://arxiv.org/pdf/1110.3584v1", 
    "title": "Optimal Final Carry Propagate Adder Design for Parallel Multipliers", 
    "arxiv-id": "1110.3584v1", 
    "author": "Harish M. Kittur", 
    "publish": "2011-10-17T06:16:05Z", 
    "summary": "Based on the ASIC layout level simulation of 7 types of adder structures each\nof four different sizes, i.e. a total of 28 adders, we propose expressions for\nthe width of each of the three regions of the final Carry Propagate Adder (CPA)\nto be used in parallel multipliers. We also propose the types of adders to be\nused in each region that would lead to the optimal performance of the hybrid\nfinal adders in parallel multipliers. This work evaluates the complete\nperformance of the analyzed designs in terms of delay, area, power through\ncustom design and layout in 0.18 um CMOS process technology."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2011.2306", 
    "link": "http://arxiv.org/pdf/1110.3655v1", 
    "title": "Accelerating Algorithms using a Dataflow Graph in a Reconfigurable   System", 
    "arxiv-id": "1110.3655v1", 
    "author": "Antonio Carlos Fernandes da Silva", 
    "publish": "2011-10-17T13:00:10Z", 
    "summary": "In this paper, the acceleration of algorithms using a design of a field\nprogrammable gate array (FPGA) as a prototype of a static dataflow architecture\nis discussed. The static dataflow architecture using operators interconnected\nby parallel buses was implemented. Accelerating algorithms using a dataflow\ngraph in a reconfigurable system shows the potential for high computation\nrates. The results of benchmarks implemented using the static dataflow\narchitecture are reported at the end of this paper."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2011.2306", 
    "link": "http://arxiv.org/pdf/1110.6865v1", 
    "title": "FPGA implementation of short critical path CORDIC-based approximation of   the eight-point DCT", 
    "arxiv-id": "1110.6865v1", 
    "author": "Alexander Petrovsky", 
    "publish": "2011-10-31T17:13:25Z", 
    "summary": "This paper presents an efficient approach for multiplierless implementation\nfor eight-point DCT approximation, which based on coordinate rotation digital\ncomputer (CORDIC) algorithm. The main design objective is to make critical path\nof corresponding circuits shorter and reduce the combinational delay of\nproposed scheme."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2011.2306", 
    "link": "http://arxiv.org/pdf/1111.0703v1", 
    "title": "Efficient Network for Non-Binary QC-LDPC Decoder", 
    "arxiv-id": "1111.0703v1", 
    "author": "Keshab K. Parhi", 
    "publish": "2011-11-03T01:10:43Z", 
    "summary": "This paper presents approaches to develop efficient network for non-binary\nquasi-cyclic LDPC (QC-LDPC) decoders. By exploiting the intrinsic shifting and\nsymmetry properties of the check matrices, significant reduction of memory size\nand routing complexity can be achieved. Two different efficient network\narchitectures for Class-I and Class-II non-binary QC-LDPC decoders have been\nproposed, respectively. Comparison results have shown that for the code of the\n64-ary (1260, 630) rate-0.5 Class-I code, the proposed scheme can save more\nthan 70.6% hardware required by shuffle network than the state-of-the-art\ndesigns. The proposed decoder example for the 32-ary (992, 496) rate-0.5\nClass-II code can achieve a 93.8% shuffle network reduction compared with the\nconventional ones. Meanwhile, based on the similarity of Class-I and Class-II\ncodes, similar shuffle network is further developed to incorporate both classes\nof codes at a very low cost."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2011.2306", 
    "link": "http://arxiv.org/pdf/1111.0704v1", 
    "title": "Reduced-Latency SC Polar Decoder Architectures", 
    "arxiv-id": "1111.0704v1", 
    "author": "Keshab K. Parhi", 
    "publish": "2011-11-03T01:12:49Z", 
    "summary": "Polar codes have become one of the most favorable capacity achieving error\ncorrection codes (ECC) along with their simple encoding method. However, among\nthe very few prior successive cancellation (SC) polar decoder designs, the\nrequired long code length makes the decoding latency high. In this paper,\nconventional decoding algorithm is transformed with look-ahead techniques. This\nreduces the decoding latency by 50%. With pipelining and parallel processing\nschemes, a parallel SC polar decoder is proposed. Sub-structure sharing\napproach is employed to design the merged processing element (PE). Moreover,\ninspired by the real FFT architecture, this paper presents a novel input\ngenerating circuit (ICG) block that can generate additional input signals for\nmerged PEs on-the-fly. Gate-level analysis has demonstrated that the proposed\ndesign shows advantages of 50% decoding latency and twice throughput over the\nconventional one with similar hardware cost."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2011.2306", 
    "link": "http://arxiv.org/pdf/1111.0705v1", 
    "title": "Low-Latency SC Decoder Architectures for Polar Codes", 
    "arxiv-id": "1111.0705v1", 
    "author": "Keshab K. Parhi", 
    "publish": "2011-11-03T01:15:58Z", 
    "summary": "Nowadays polar codes are becoming one of the most favorable capacity\nachieving error correction codes for their low encoding and decoding\ncomplexity. However, due to the large code length required by practical\napplications, the few existing successive cancellation (SC) decoder\nimplementations still suffer from not only the high hardware cost but also the\nlong decoding latency. This paper presents novel several approaches to design\nlow-latency decoders for polar codes based on look-ahead techniques. Look-ahead\ntechniques can be employed to reschedule the decoding process of polar decoder\nin numerous approaches. However, among those approaches, only well-arranged\nones can achieve good performance in terms of both latency and hardware\ncomplexity. By revealing the recurrence property of SC decoding chart, the\nauthors succeed in reducing the decoding latency by 50% with look-ahead\ntechniques. With the help of VLSI-DSP design techniques such as pipelining,\nfolding, unfolding, and parallel processing, methodologies for four different\npolar decoder architectures have been proposed to meet various application\ndemands. Sub-structure sharing scheme has been adopted to design the merged\nprocessing element (PE) for further hardware reduction. In addition, systematic\nmethods for construction refined pipelining decoder (2nd design) and the input\ngenerating circuits (ICG) block have been given. Detailed gate-level analysis\nhas demonstrated that the proposed designs show latency advantages over\nconventional ones with similar hardware cost."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsea.2011.1506", 
    "link": "http://arxiv.org/pdf/1111.3056v1", 
    "title": "Performance of Cache Memory Subsystems for Multicore Architectures", 
    "arxiv-id": "1111.3056v1", 
    "author": "N. Ammasai Gounden", 
    "publish": "2011-11-13T19:28:01Z", 
    "summary": "Advancements in multi-core have created interest among many research groups\nin finding out ways to harness the true power of processor cores. Recent\nresearch suggests that on-board component such as cache memory plays a crucial\nrole in deciding the performance of multi-core systems. In this paper,\nperformance of cache memory is evaluated through the parameters such as cache\naccess time, miss rate and miss penalty. The influence of cache parameters over\nexecution time is also discussed. Results obtained from simulated studies of\nmulti-core environments with different instruction set architectures (ISA) like\nALPHA and X86 are produced."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsea.2011.1506", 
    "link": "http://arxiv.org/pdf/1111.4279v1", 
    "title": "Elastic Fidelity: Trading-off Computational Accuracy for Energy   Reduction", 
    "arxiv-id": "1111.4279v1", 
    "author": "Srinivasan Parthasarathy", 
    "publish": "2011-11-18T04:12:12Z", 
    "summary": "Power dissipation and energy consumption have become one of the most\nimportant problems in the design of processors today. This is especially true\nin power-constrained environments, such as embedded and mobile computing. While\nlowering the operational voltage can reduce power consumption, there are limits\nimposed at design time, beyond which hardware components experience faulty\noperation. Moreover, the decrease in feature size has led to higher\nsusceptibility to process variations, leading to reliability issues and\nlowering yield. However, not all computations and all data in a workload need\nto maintain 100% fidelity. In this paper, we explore the idea of employing\nfunctional or storage units that let go the conservative guardbands imposed on\nthe design to guarantee reliable execution. Rather, these units exhibit Elastic\nFidelity, by judiciously lowering the voltage to trade-off reliable execution\nfor power consumption based on the error guarantees required by the executing\ncode. By estimating the accuracy required by each computational segment of a\nworkload, and steering each computation to different functional and storage\nunits, Elastic Fidelity Computing obtains power and energy savings while\nreaching the reliability targets required by each computational segment. Our\npreliminary results indicate that even with conservative estimates, Elastic\nFidelity can reduce the power and energy consumption of a processor by 11-13%\nwhen executing applications involving human perception that are typically\nincluded in modern mobile platforms, such as audio, image, and video decoding."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsea.2011.1506", 
    "link": "http://arxiv.org/pdf/1111.7258v1", 
    "title": "A New Design for Array Multiplier with Trade off in Power and Area", 
    "arxiv-id": "1111.7258v1", 
    "author": "T. Subba Rao", 
    "publish": "2011-11-30T18:07:44Z", 
    "summary": "In this paper a low power and low area array multiplier with carry save adder\nis proposed. The proposed adder eliminates the final addition stage of the\nmultiplier than the conventional parallel array multiplier. The conventional\nand proposed multiplier both are synthesized with 16-T full adder. Among\nTransmission Gate, Transmission Function Adder, 14-T, 16-T full adder shows\nenergy efficiency. In the proposed 4x4 multiplier to add carry bits with out\nusing Ripple Carry Adder (RCA) in the final stage, the carries given to the\ninput of the next left column input. Due to this the proposed multiplier shows\n56 less transistor count, then cause trade off in power and area. The proposed\nmultiplier has shown 13.91% less power, 34.09% more speed and 59.91% less\nenergy consumption for TSMC 0.18nm technology at a supply voltage 2.0V than the\nconventional multiplier."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsea.2011.1506", 
    "link": "http://arxiv.org/pdf/1112.0727v1", 
    "title": "Quantum Cost Efficient Reversible BCD Adder for Nanotechnology Based   Systems", 
    "arxiv-id": "1112.0727v1", 
    "author": "Zerina Begum", 
    "publish": "2011-12-04T06:48:53Z", 
    "summary": "Reversible logic allows low power dissipating circuit design and founds its\napplication in cryptography, digital signal processing, quantum and optical\ninformation processing. This paper presents a novel quantum cost efficient\nreversible BCD adder for nanotechnology based systems using PFAG gate. It has\nbeen demonstrated that the proposed design offers less hardware complexity and\nrequires minimum number of garbage outputs than the existing counterparts. The\nremarkable property of the proposed designs is that its quantum realization is\ngiven in NMR technology."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsea.2011.1506", 
    "link": "http://arxiv.org/pdf/1201.0954v1", 
    "title": "Information Analysis Infrastructure for Diagnosis", 
    "arxiv-id": "1201.0954v1", 
    "author": "Svetlana Chumachenko", 
    "publish": "2012-01-04T18:21:06Z", 
    "summary": "A high-speed multiprocessor architecture for brain-like analyzing information\nrepresented in analytic, graph- and table forms of associative relations to\nsearch, recognize and make a decision in n-dimensional vector discrete space is\noffered. Vector-logical process models of actual applications, where the\nquality of solution is estimated by the proposed integral non-arithmetical\nmetric of the interaction between binary vectors, are described. The\ntheoretical proof of the metric for a vector logical space and the quality\ncriteria for estimating solutions is created."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsea.2011.1506", 
    "link": "http://arxiv.org/pdf/1201.1674v1", 
    "title": "Theoretical Modeling and Simulation of Phase-Locked Loop (PLL) for Clock   Data Recovery (CDR)", 
    "arxiv-id": "1201.1674v1", 
    "author": "Anis Nurashikin Nordin", 
    "publish": "2012-01-09T01:00:44Z", 
    "summary": "Modern communication and computer systems require rapid (Gbps), efficient and\nlarge bandwidth data transfers. Agressive scaling of digital integrated systems\nallow buses and communication controller circuits to be integrated with the\nmicroprocessor on the same chip. The Peripheral Component Interconnect Express\n(PCIe) protocol handles all communcation between the central processing unit\n(CPU) and hardware devices. PCIe buses require efficient clock data recovery\ncircuits (CDR) to recover clock signals embedded in data during transmission.\nThis paper describes the theoretical modeling and simulation of a phase-locked\nloop (PLL) used in a CDR circuit. A simple PLL architecture for a 5 GHz CDR\ncircuit is proposed and elaborated in this work. Simulations were carried out\nusing a Hardware Description Language, Verilog- AMS. The effect of jitter on\nthe proposed design is also simulated and evaluated in this work. It was found\nthat the proposed design is robust against both input and VCO jitter."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2011.2410", 
    "link": "http://arxiv.org/pdf/1201.2107v1", 
    "title": "Design and ASIC implementation of DUC/DDC for communication systems", 
    "arxiv-id": "1201.2107v1", 
    "author": "Naagesh S. Bhat", 
    "publish": "2012-01-10T16:46:57Z", 
    "summary": "Communication systems use the concept of transmitting information using the\nelectrical distribution network as a communication channel. To enable the\ntransmission data signal modulated on a carrier signal is superimposed on the\nelectrical wires. Typical power lines are designed to handle 50/60 Hz of AC\npower signal; however they can carry the signals up to 500 KHz frequency. This\nwork aims to aid transmission/reception of an audio signal in the spectrum from\n300 Hz to 4000 Hz using PLCC on a tunable carrier frequency in the spectrum\nfrom 200 KHz to 500 KHz. For digital amplitude modulation the sampling rate of\nthe carrier and the audio signal has to be matched. Tunable carrier generation\ncan be achieved with Direct Digital Synthesizers at a desired sampling rate.\nDSP Sample rate conversion techniques are very useful to make the sampling\ncircuits to work on their own sampling rates which are fine for the\ndata/modulated-carrier signal's bandwidth. This also simplifies the complexity\nof the sampling circuits. Digital Up Conversion (DUC) and Digital Down\nConversion (DDC) are DSP sample rate conversion techniques which refer to\nincreasing and decreasing the sampling rate of a signal respectively."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2011.2410", 
    "link": "http://arxiv.org/pdf/1202.0613v1", 
    "title": "A Resolution for Shared Memory Conflict in Multiprocessor   System-on-a-Chip", 
    "arxiv-id": "1202.0613v1", 
    "author": "Nitin", 
    "publish": "2012-02-03T06:47:39Z", 
    "summary": "Now days, manufacturers are focusing on increasing the concurrency in\nmultiprocessor system-on-a-chip (MPSoC) architecture instead of increasing\nclock speed, for embedded systems. Traditionally lock-based synchronization is\nprovided to support concurrency; as managing locks can be very difficult and\nerror prone. Transactional memories and lock based systems have been\nextensively used to provide synchronization between multiple processors [1] in\ngeneral-purpose systems. It has been shown that locks have numerous\nshortcomings over transactional memory in terms of power consumption, ease of\nprogramming and performance. In this paper, we propose a new semaphore scheme\nfor synchronization in shared cache memory in an MPSoC. Moreover, we have\nevaluated and compared our scheme with locks and transactions in terms of\nenergy consumption and cache miss rate using SimpleScalar functional simulator."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2011.2410", 
    "link": "http://arxiv.org/pdf/1203.0787v1", 
    "title": "A handy systematic method for data hazards detection in an instruction   set of a pipelined microprocessor", 
    "arxiv-id": "1203.0787v1", 
    "author": "Ahmed M. Mahran", 
    "publish": "2012-03-04T23:43:07Z", 
    "summary": "It is intended in this document to introduce a handy systematic method for\nenumerating all possible data dependency cases that could occur between any two\ninstructions that might happen to be processed at the same time at different\nstages of the pipeline. Given instructions of the instruction set, specific\ninformation about operands of each instruction and when an instruction reads or\nwrites data, the method could be used to enumerate all possible data hazard\ncases and to determine whether forwarding or stalling is suitable for resolving\neach case."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2011.2410", 
    "link": "http://arxiv.org/pdf/1203.4150v1", 
    "title": "Designing a WISHBONE Protocol Network Adapter for an Asynchronous   Network-on-Chip", 
    "arxiv-id": "1203.4150v1", 
    "author": "Hesham M. A. M. Keshk", 
    "publish": "2012-03-19T16:18:54Z", 
    "summary": "The Scaling of microchip technologies, from micron to submicron and now to\ndeep sub-micron (DSM) range, has enabled large scale systems-on-chip (SoC). In\nfuture deep submicron (DSM) designs, the interconnect effect will definitely\ndominate performance. Network-on-Chip (NoC) has become a promising solution to\nbus-based communication infrastructure limitations. NoC designs usually targets\nApplication Specific Integrated Circuits (ASICs), however, the fabrication\nprocess costs a lot. Implementing a NoC on an FPGA does not only reduce the\ncost but also decreases programming and verification cycles. In this paper, an\nAsynchronous NoC has been implemented on a SPARTAN-3E\\textregistered device.\nThe NoC supports basic transactions of both widely used on-chip interconnection\nstandards, the Open Core Protocol (OCP) and the WISHBONE Protocol. Although,\nFPGA devices are synchronous in nature, it has been shown that they can be used\nto prototype a Global Asynchronous Local Synchronous (GALS) systems, comprising\nan Asynchronous NoC connecting IP cores operating in different clock domains."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2011.2410", 
    "link": "http://arxiv.org/pdf/1203.5349v1", 
    "title": "LOCKE Detailed Specification Tables", 
    "arxiv-id": "1203.5349v1", 
    "author": "Jose-Angel Gregorio", 
    "publish": "2012-03-22T10:48:33Z", 
    "summary": "This document shows the detailed specification of LOCKE coherence protocol\nfor each cache controller, using a table-based technique. This representation\nprovides clear, concise visual information yet includes sufficient detail\n(e.g., transient states) arguably lacking in the traditional, graphical form of\nstate diagrams."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2011.2410", 
    "link": "http://arxiv.org/pdf/1205.1737v2", 
    "title": "A simple 1-byte 1-clock RC4 design and its efficient implementation in   FPGA coprocessor for secured ethernet communication", 
    "arxiv-id": "1205.1737v2", 
    "author": "Ranjan Ghosh", 
    "publish": "2012-05-08T16:30:40Z", 
    "summary": "In the field of cryptography till date the 1-byte in 1-clock is the best\nknown RC4 hardware design [1], while the 1-byte in 3clocks is the best known\nimplementation [2,3]. The design algorithm in [1] considers two consecutive\nbytes together and processes them in 2 clocks. The design of 1-byte in 3-clocks\nis too much modular and clock hungry. In this paper considering the RC4\nalgorithm, as it is, a simpler RC4 hardware design providing higher throughput\nis proposed in which 1-byte is processed in 1-clock. In the design two\nsequential tasks are executed as two independent events during rising and\nfalling edges of the same clock and the swapping is directly executed using a\nMUX-DEMUX combination. The power consumed in behavioral and structural designs\nof RC4 are estimated and a power optimization technique is proposed. The NIST\nstatistical test suite is run on RC4 key streams in order to know its\nrandomness property. The encryption and decryption designs are respectively\nembedded on two FPGA boards with RC4 in a custom coprocessor followed by\nEthernet communication."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2012.3210", 
    "link": "http://arxiv.org/pdf/1205.1860v1", 
    "title": "Wishbone bus Architecture - A Survey and Comparison", 
    "arxiv-id": "1205.1860v1", 
    "author": "Dilip Kumar", 
    "publish": "2012-05-09T03:18:40Z", 
    "summary": "The performance of an on-chip interconnection architecture used for\ncommunication between IP cores depends on the efficiency of its bus\narchitecture. Any bus architecture having advantages of faster bus clock speed,\nextra data transfer cycle, improved bus width and throughput is highly\ndesirable for a low cost, reduced time-to-market and efficient System-on-Chip\n(SoC). This paper presents a survey of WISHBONE bus architecture and its\ncomparison with three other on-chip bus architectures viz. Advanced Micro\ncontroller Bus Architecture (AMBA) by ARM, CoreConnect by IBM and Avalon by\nAltera. The WISHBONE Bus Architecture by Silicore Corporation appears to be\ngaining an upper edge over the other three bus architecture types because of\nits special performance parameters like the use of flexible arbitration scheme\nand additional data transfer cycle (Read-Modify-Write cycle). Moreover, its IP\nCores are available free for use requiring neither any registration nor any\nagreement or license."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2012.3205", 
    "link": "http://arxiv.org/pdf/1205.1866v1", 
    "title": "Microcontroller Based Testing of Digital IP-Core", 
    "arxiv-id": "1205.1866v1", 
    "author": "Balwinder Singh", 
    "publish": "2012-05-09T04:15:39Z", 
    "summary": "Testing core based System on Chip is a challenge for the test engineers. To\ntest the complete SOC at one time with maximum fault coverage, test engineers\nprefer to test each IP-core separately. At speed testing using external testers\nis more expensive because of gigahertz processor. The purpose of this paper is\nto develop cost efficient and flexible test methodology for testing digital\nIP-cores . The prominent feature of the approach is to use microcontroller to\ntest IP-core. The novel feature is that there is no need of test pattern\ngenerator and output response analyzer as microcontroller performs the function\nof both. This approach has various advantages such as at speed testing, low\ncost, less area overhead and greater flexibility since most of the testing\nprocess is based on software."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2012.3205", 
    "link": "http://arxiv.org/pdf/1205.1871v1", 
    "title": "Design Space Exploration to Find the Optimum Cache and Register File   Size for Embedded Applications", 
    "arxiv-id": "1205.1871v1", 
    "author": "Hesamodin shojaei baghini", 
    "publish": "2012-05-09T05:23:13Z", 
    "summary": "In the future, embedded processors must process more computation-intensive\nnetwork applications and internet traffic and packet-processing tasks become\nheavier and sophisticated. Since the processor performance is severely related\nto the average memory access delay and also the number of processor registers\naffects the performance, cache and register file are two major parts in\ndesigning embedded processor architecture. Although increasing cache and\nregister file size leads to performance improvement in embedded applications\nand packet-processing tasks in high traffic networks with too much packets, the\nincreased area, power consumption and memory hierarchy delay are the overheads\nof these techniques. Therefore, implementing these components in the optimum\nsize is of significant interest in the design of embedded processors. This\npaper explores the effect of cache and register file size on the processor\nperformance to calculate the optimum size of these components for embedded\napplications. Experimental results show that although having bigger cache and\nregister file is one of the performance improvement approaches in embedded\nprocessors, however, by increasing the size of these parameters over a\nthreshold level, performance improvement is saturated and then, decreased."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2012.3205", 
    "link": "http://arxiv.org/pdf/1205.2153v1", 
    "title": "Design and implementation of real time AES-128 on real time operating   system for multiple FPGA communication", 
    "arxiv-id": "1205.2153v1", 
    "author": "Amlan Chakrabarti", 
    "publish": "2012-05-10T04:04:45Z", 
    "summary": "Security is the most important part in data communication system, where more\nrandomization in secret keys increases the security as well as complexity of\nthe cryptography algorithms. As a result in recent dates these algorithms are\ncompensating with enormous memory spaces and large execution time on hardware\nplatform. Field programmable gate arrays (FPGAs), provide one of the major\nalternative in hardware platform scenario due to its reconfiguration nature,\nlow price and marketing speed. In FPGA based embedded system we can use\nembedded processor to execute particular algorithm with the inclusion of a real\ntime operating System (RTOS), where threads may reduce resource utilization and\ntime consumption. A process in the runtime is separated in different smaller\ntasks which are executed by the scheduler to meet the real time dead line using\nRTOS. In this paper we demonstrate the design and implementation of a 128-bit\nAdvanced Encryption Standard (AES) both symmetric key encryption and decryption\nalgorithm by developing suitable hardware and software design on Xilinx\nSpartan- 3E (XC3S500E-FG320) device using an Xilkernel RTOS, the implementation\nhas been tested successfully The system is optimized in terms of execution\nspeed and hardware utilization."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2012.3205", 
    "link": "http://arxiv.org/pdf/1205.2428v1", 
    "title": "Relaxed Half-Stochastic Belief Propagation", 
    "arxiv-id": "1205.2428v1", 
    "author": "Warren J. Gross", 
    "publish": "2012-05-11T05:06:47Z", 
    "summary": "Low-density parity-check codes are attractive for high throughput\napplications because of their low decoding complexity per bit, but also because\nall the codeword bits can be decoded in parallel. However, achieving this in a\ncircuit implementation is complicated by the number of wires required to\nexchange messages between processing nodes. Decoding algorithms that exchange\nbinary messages are interesting for fully-parallel implementations because they\ncan reduce the number and the length of the wires, and increase logic density.\nThis paper introduces the Relaxed Half-Stochastic (RHS) decoding algorithm, a\nbinary message belief propagation (BP) algorithm that achieves a coding gain\ncomparable to the best known BP algorithms that use real-valued messages. We\nderive the RHS algorithm by starting from the well-known Sum-Product algorithm,\nand then derive a low-complexity version suitable for circuit implementation.\nWe present extensive simulation results on two standardized codes having\ndifferent rates and constructions, including low bit error rate results. These\nsimulations show that RHS can be an advantageous replacement for the existing\nstate-of-the-art decoding algorithms when targeting fully-parallel\nimplementations."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2012.3205", 
    "link": "http://arxiv.org/pdf/1205.4967v1", 
    "title": "Investigating Warp Size Impact in GPUs", 
    "arxiv-id": "1205.4967v1", 
    "author": "Ahmad Khonsari", 
    "publish": "2012-05-22T16:26:23Z", 
    "summary": "There are a number of design decisions that impact a GPU's performance. Among\nsuch decisions deciding the right warp size can deeply influence the rest of\nthe design. Small warps reduce the performance penalty associated with branch\ndivergence at the expense of a reduction in memory coalescing. Large warps\nenhance memory coalescing significantly but also increase branch divergence.\nThis leaves designers with two choices: use a small warps and invest in finding\nnew solutions to enhance coalescing or use large warps and address branch\ndivergence employing effective control-flow solutions. In this work our goal is\nto investigate the answer to this question. We analyze warp size impact on\nmemory coalescing and branch divergence. We use our findings to study two\nmachines: a GPU using small warps but equipped with excellent memory coalescing\n(SW+) and a GPU using large warps but employing an MIMD engine immune from\ncontrol-flow costs (LW+). Our evaluations show that building\ncoalescing-enhanced small warp GPUs is a better approach compared to pursuing a\ncontrol-flow enhanced large warp GPU."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2012.3205", 
    "link": "http://arxiv.org/pdf/1206.1567v1", 
    "title": "Architecture for real time continuous sorting on large width data volume   for fpga based applications", 
    "arxiv-id": "1206.1567v1", 
    "author": "Amlan Chakrabarti", 
    "publish": "2012-06-07T18:17:32Z", 
    "summary": "In engineering applications sorting is an important and widely studied\nproblem where execution speed and resources used for computation are of extreme\nimportance, especially if we think about real time data processing. Most of the\ntraditional sorting techniques compute the process after receiving all of the\ndata and hence the process needs large amount of resources for data storage.\nSo, suitable design strategy needs to be adopted if we wish to sort a large\namount of data in real time, which essential means higher speed of process\nexecution and utilization of fewer resources in most of the cases. This paper\nproposes a single chip scalable architecture based on Field Programmable Gate\nArray(FPGA), for a modified counting sort algorithm where data acquisition and\nsorting is being done in real time scenario. Our design promises to work\nefficiently, where data can be accepted in the run time scenario without any\nneed of prior storage of data and also the execution speed of our algorithm is\ninvariant to the length of the data stream. The proposed design is implemented\nand verified on Spartan 3E(XC3S500E-FG320) FPGA system. The results prove that\nour design is better in terms of some of the design parameters compared to the\nexisting research works."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2012.3205", 
    "link": "http://arxiv.org/pdf/1206.2132v1", 
    "title": "RepTFD: Replay Based Transient Fault Detection", 
    "arxiv-id": "1206.2132v1", 
    "author": "Ruiyang Wu", 
    "publish": "2012-06-11T08:50:37Z", 
    "summary": "The advances in IC process make future chip multiprocessors (CMPs) more and\nmore vulnerable to transient faults. To detect transient faults, previous\ncore-level schemes provide redundancy for each core separately. As a result,\nthey may leave transient faults in the uncore parts, which consume over 50%\narea of a modern CMP, escaped from detection. This paper proposes RepTFD, the\nfirst core-level transient fault detection scheme with 100% coverage. Instead\nof providing redundancy for each core separately, RepTFD provides redundancy\nfor a group of cores as a whole. To be specific, it replays the execution of\nthe checked group of cores on a redundant group of cores. Through comparing the\nexecution results between the two groups of cores, all malignant transient\nfaults can be caught. Moreover, RepTFD adopts a novel pending period based\nrecord-replay approach, which can greatly reduce the number of execution orders\nthat need to be enforced in the replay-run. Hence, RepTFD brings only 4.76%\nperformance overhead in comparison to the normal execution without\nfault-tolerance according to our experiments on the RTL design of an industrial\nCMP named Godson-3. In addition, RepTFD only consumes about 0.83% area of\nGodson-3, while needing only trivial modifications to existing components of\nGodson-3."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2012.3205", 
    "link": "http://arxiv.org/pdf/1206.4753v2", 
    "title": "DLS: Directoryless Shared Last-level Cache", 
    "arxiv-id": "1206.4753v2", 
    "author": "Weiwu Hu", 
    "publish": "2012-06-21T00:59:43Z", 
    "summary": "Directory-based protocols have been the de facto solution for maintaining\ncache coherence in shared-memory parallel systems comprising multi/many cores,\nwhere each store instruction is eagerly made globally visible by invalidating\nthe private cache (PC) backups of other cores. Consequently, the directory not\nonly consumes large chip area, but also incurs considerable energy consumption\nand performance degradation, due to the large number of Invalidation/Ack\nmessages transferred in the interconnection network and resulting network\ncongestion. In this paper, we reveal the interesting fact that the directory is\nactually an unnecessary luxury for practical parallel systems. Because of\nwidely deployed software/hardware techniques involving instruction reordering,\nmost (if not all) parallel systems work under the weak consistency model, where\na remote store instruction is allowed to be invisible to a core before the next\nsynchronization of the core, instead of being made visible eagerly by\ninvalidating PC backups of other cores. Based on this key observation, we\npropose a lightweight novel scheme called {\\em DLS (DirectoryLess Shared\nlast-level cache)}, which completely removes the directory and Invalidation/Ack\nmessages, and efficiently maintains cache coherence using a novel {\\em\nself-suspicion + speculative execution} mechanism. Experimental results over\nSPLASH-2 benchmarks show that on a 16-core processor, DLS not only completely\nremoves the chip area cost of the directory, but also improves processor\nperformance by 11.08%, reduces overall network traffic by 28.83%, and reduces\nenergy consumption of the network by 15.65% on average (compared with\ntraditional MESI protocol with full directory). Moreover, DLS does not involve\nany modification to programming languages and compilers, and hence is\nseamlessly compatible with legacy codes."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2012.3205", 
    "link": "http://arxiv.org/pdf/1208.0995v1", 
    "title": "Design and implementation of a digital clock showing digits in Bangla   font using microcontroller AT89C4051", 
    "arxiv-id": "1208.0995v1", 
    "author": "Sheikh Mominul Islam", 
    "publish": "2012-08-05T09:22:06Z", 
    "summary": "In this paper, a digital clock is designed where the microcontroller is used\nfor timing controller and the font of the Bangla digits are designed, and\nprogrammed within the microcontroller. The design is cost effective, simple and\neasy for maintenance."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2012.3205", 
    "link": "http://arxiv.org/pdf/1208.2374v2", 
    "title": "Dynamic Warp Resizing in High-Performance SIMT", 
    "arxiv-id": "1208.2374v2", 
    "author": "Ahmad Khonsari", 
    "publish": "2012-08-11T18:05:59Z", 
    "summary": "Modern GPUs synchronize threads grouped in a warp at every instruction. These\nresults in improving SIMD efficiency and makes sharing fetch and decode\nresources possible. The number of threads included in each warp (or warp size)\naffects divergence, synchronization overhead and the efficiency of memory\naccess coalescing. Small warps reduce the performance penalty associated with\nbranch and memory divergence at the expense of a reduction in memory\ncoalescing. Large warps enhance memory coalescing significantly but also\nincrease branch and memory divergence. Dynamic workload behavior, including\nbranch/memory divergence and coalescing, is an important factor in determining\nthe warp size returning best performance. Optimal warp size can vary from one\nworkload to another or from one program phase to the next. Based on this\nobservation, we propose Dynamic Warp Resizing (DWR). DWR takes innovative\nmicroarchitectural steps to adjust warp size during runtime and according to\nprogram characteristics. DWR outperforms static warp size decisions, up to 1.7X\nto 2.28X, while imposing less than 1% area overhead. We investigate various\nalternative configurations and show that DWR performs better for narrower SIMD\nand larger caches."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2012.3205", 
    "link": "http://arxiv.org/pdf/1209.3099v1", 
    "title": "A Cache Management Strategy to Replace Wear Leveling Techniques for   Embedded Flash Memory", 
    "arxiv-id": "1209.3099v1", 
    "author": "St\u00e9phane Rubini", 
    "publish": "2012-09-14T06:09:10Z", 
    "summary": "Prices of NAND flash memories are falling drastically due to market growth\nand fabrication process mastering while research efforts from a technological\npoint of view in terms of endurance and density are very active. NAND flash\nmemories are becoming the most important storage media in mobile computing and\ntend to be less confined to this area. The major constraint of such a\ntechnology is the limited number of possible erase operations per block which\ntend to quickly provoke memory wear out. To cope with this issue,\nstate-of-the-art solutions implement wear leveling policies to level the wear\nout of the memory and so increase its lifetime. These policies are integrated\ninto the Flash Translation Layer (FTL) and greatly contribute in decreasing the\nwrite performance. In this paper, we propose to reduce the flash memory wear\nout problem and improve its performance by absorbing the erase operations\nthroughout a dual cache system replacing FTL wear leveling and garbage\ncollection services. We justify this idea by proposing a first performance\nevaluation of an exclusively cache based system for embedded flash memories.\nUnlike wear leveling schemes, the proposed cache solution reduces the total\nnumber of erase operations reported on the media by absorbing them in the cache\nfor workloads expressing a minimal global sequential rate."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2012.3205", 
    "link": "http://arxiv.org/pdf/1209.3564v1", 
    "title": "Deadlock Recovery Technique in Bus Enhanced NoC Architecture", 
    "arxiv-id": "1209.3564v1", 
    "author": "Hamid Shahimohamadi", 
    "publish": "2012-09-17T07:14:15Z", 
    "summary": "Increase in the speed of processors has led to crucial role of communication\nin the performance of systems. As a result, routing is taken into consideration\nas one of the most important subjects of the Network on Chip architecture.\nRouting algorithms to deadlock avoidance prevent packets route completely based\non network traffic condition by means of restricting the route of packets. This\naction leads to less performance especially in non-uniform traffic patterns. On\nthe other hand True Fully Adoptive Routing algorithm provides routing of\npackets completely based on traffic condition. However, deadlock detection and\nrecovery mechanisms are needed to handle deadlocks. Use of global bus beside\nNoC as a parallel supportive environment, provide platform to offer advantages\nof both features of bus and NoC. This bus is useful for broadcast and multicast\noperations, sending delay sensitive signals, system management and other\nservices. In this research, we use this bus as an escaping path for deadlock\nrecovery technique. According to simulation results, this bus is suitable\nplatform for deadlock recovery technique."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2012.3205", 
    "link": "http://arxiv.org/pdf/1210.6338v1", 
    "title": "A Ternary Digital to Analog Converter with High Power Output and 170-dB   Dynamic Range", 
    "arxiv-id": "1210.6338v1", 
    "author": "Guido Stolfi", 
    "publish": "2012-10-22T15:11:08Z", 
    "summary": "A prototype of a very high dynamic range 32-bits Digital to Analog Converter\n(DAC) was designed and built for the purpose of direct auditory stimulus\ngeneration. It provides signals from less than 100 nV up to 50 Watts peak power\noutput, driving a 32-Ohms earphone or speaker. The use of ternary cells makes\npossible a 170 dB dynamic range that is basically limited by thermal noise\nonly."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2012.3205", 
    "link": "http://arxiv.org/pdf/1211.5248v1", 
    "title": "Design Of A Reconfigurable DSP Processor With Bit Efficient Residue   Number System", 
    "arxiv-id": "1211.5248v1", 
    "author": "Amitabha Sinha", 
    "publish": "2012-11-22T10:46:25Z", 
    "summary": "Residue Number System (RNS), which originates from the Chinese Remainder\nTheorem, offers a promising future in VLSI because of its carry-free operations\nin addition, subtraction and multiplication. This property of RNS is very\nhelpful to reduce the complexity of calculation in many applications. A residue\nnumber system represents a large integer using a set of smaller integers,\ncalled residues. But the area overhead, cost and speed not only depend on this\nword length, but also the selection of moduli, which is a very crucial step for\nresidue system. This parameter determines bit efficiency, area, frequency etc.\nIn this paper a new moduli set selection technique is proposed to improve bit\nefficiency which can be used to construct a residue system for digital signal\nprocessing environment. Subsequently, it is theoretically proved and\nillustrated using examples, that the proposed solution gives better results\nthan the schemes reported in the literature. The novelty of the architecture is\nshown by comparison the different schemes reported in the literature. Using the\nnovel moduli set, a guideline for a Reconfigurable Processor is presented here\nthat can process some predefined functions. As RNS minimizes the carry\npropagation, the scheme can be implemented in Real Time Signal Processing &\nother fields where high speed computations are required."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2012.3205", 
    "link": "http://arxiv.org/pdf/1302.4172v1", 
    "title": "Reduction in Packet Delay Through the use of Common Buffer over   Distributed Buffer in the Routing Node of NOC Architecture", 
    "arxiv-id": "1302.4172v1", 
    "author": "Sanjay L. Badjate", 
    "publish": "2013-02-18T07:35:15Z", 
    "summary": "Performance evaluation of the routing node in terms of latency is the\ncharacteristics of an efficient design of Buffer in input module. It is\nintended to study and quantify the behavior of the single packet array design\nin relation to the multiple packet array design. The utilization efficiency of\nthe packet buffer array improves when a common buffer is used instead of\nindividual buffers in each input port. First Poissons Queuing model was\nprepared to manifest the differences in packet delays. The queuing model can be\nclassified as (M/M/1), (32/FIFO). Arrival rate has been assumed to be Poisson\ndistributed with a mean arrival rate of 10 x 1000000. The service rate is\nassumed to be exponentially distributed with a mean service rate of 10.05 x\n1000000. It has been observed that latency in Common Buffer improved by 46\npercent over its distributed buffer. A Simulink model later simulated on MATLAB\nto calculate the improvement in packet delay. It has been observed that the\ndelay improved by approximately 40 percent through the use of a common buffer.\nA verilog RTL for both common and shared buffer has been prepared and later\nsynthesized using Design Compiler of SYNOPSYS. In distributed buffer, arrival\nof data packet could be delayed by 2 or 4 clock cycles which lead to latency\nimprovement either by 17 percent or 34 percent in a common buffer"
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASAP.2013.6567594", 
    "link": "http://arxiv.org/pdf/1302.4463v1", 
    "title": "A Low-Power Content-Addressable-Memory Based on   Clustered-Sparse-Networks", 
    "arxiv-id": "1302.4463v1", 
    "author": "Warren J. Gross", 
    "publish": "2013-02-18T21:23:54Z", 
    "summary": "A low-power Content-Addressable-Memory (CAM) is introduced employing a new\nmechanism for associativity between the input tags and the corresponding\naddress of the output data. The proposed architecture is based on a recently\ndeveloped clustered-sparse-network using binary-weighted connections that\non-average will eliminate most of the parallel comparisons performed during a\nsearch. Therefore, the dynamic energy consumption of the proposed design is\nsignificantly lower compared to that of a conventional low-power CAM design.\nGiven an input tag, the proposed architecture computes a few possibilities for\nthe location of the matched tag and performs the comparisons on them to locate\na single valid match. A 0.13 um CMOS technology was used for simulation\npurposes. The energy consumption and the search delay of the proposed design\nare 9.5%, and 30.4% of that of the conventional NAND architecture respectively\nwith a 3.4% higher number of transistors."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASAP.2013.6567594", 
    "link": "http://arxiv.org/pdf/1302.6515v2", 
    "title": "Hybrid Crossbar Architecture for a Memristor Based Memory", 
    "arxiv-id": "1302.6515v2", 
    "author": "Tarek M. Taha", 
    "publish": "2013-02-26T17:48:12Z", 
    "summary": "This paper describes a new memristor crossbar architecture that is proposed\nfor use in a high density cache design. This design has less than 10% of the\nwrite energy consumption than a simple memristor crossbar. Also, it has up to 4\ntimes the bit density of an STT-MRAM system and up to 11 times the bit density\nof an SRAM architecture. The proposed architecture is analyzed using a detailed\nSPICE analysis that accounts for the resistance of the wires in the memristor\nstructure. Additionally, the memristor model used in this work has been matched\nto specific device characterization data to provide accurate results in terms\nof energy, area, and timing."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASAP.2013.6567594", 
    "link": "http://arxiv.org/pdf/1303.2175v1", 
    "title": "An efficient cntfet-based 7-input minority gate", 
    "arxiv-id": "1303.2175v1", 
    "author": "Keivan Navi", 
    "publish": "2013-03-09T06:57:21Z", 
    "summary": "Complementary metal oxide semiconductor technology (CMOS) has been faced\ncritical challenges in nano-scale regime. CNTFET (Carbon Nanotube Field effect\ntransistor) technology is a promising alternative for CMOS technology. In this\npaper, we proposed a novel 7-input minority gate in CNTFET technology that has\nonly 9 CNTFETs. Minority function is utilized in the voting systems for\ndecision making and also it is used in data mining. This proposed 7-input\nminority gate is utilized less fewer transistors than the conventional CMOS\nmethod which utilizes many transistors for implementing sum of products. By\nmeans of this proposed 7-input minority gate, a 4-input NAND gate can be\nimplemented, which gets better the conventional design in terms of delay and\nenergy efficiency and has much more deriving power at its output."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASAP.2013.6567594", 
    "link": "http://arxiv.org/pdf/1303.4892v1", 
    "title": "On whether and how D-RISC and Microgrids can be kept relevant   (self-assessment report)", 
    "arxiv-id": "1303.4892v1", 
    "author": "Raphael Poss", 
    "publish": "2013-03-20T10:17:54Z", 
    "summary": "This report lays flat my personal views on D-RISC and Microgrids as of March\n2013. It reflects the opinions and insights that I have gained from working on\nthis project during the period 2008-2013. This report is structed in two parts:\ndeconstruction and reconstruction. In the deconstruction phase, I review what I\nbelieve are the fundamental motivation and goals of the D-RISC/Microgrids\nenterprise, and identify what I judge are shortcomings: that the project did\nnot deliver on its expectations, that fundamental questions are left\nunanswered, and that its original motivation may not even be relevant in\nscientific research any more in this day and age. In the reconstruction phase,\nI start by identifying the merits of the current D-RISC/Microgrids technology\nand know-how taken at face value, re-motivate its existence from a different\nangle, and suggest new, relevant research questions that could justify\ncontinued scientific investment."
},{
    "category": "cs.AR", 
    "doi": "10.1109/FTFC.2012.6231733", 
    "link": "http://arxiv.org/pdf/1303.5762v1", 
    "title": "Object-oriented approach to Rapid Custom Instruction design", 
    "arxiv-id": "1303.5762v1", 
    "author": "Mohamed Abid", 
    "publish": "2013-03-21T22:53:24Z", 
    "summary": "Due to continuous evolution of Systems-on-Chip (SoC), the complexity of their\ndesign and development has augmented exponentially. To deal with the\never-growing complexity of such embedded systems, we introduce, in this paper,\nan object-oriented approach to rapid SoC design using auto-generation of\nhardware custom instructions to simplify and accelerate the SoC design process.\nIn our approach, a Data Flow Graph (DFG) is adopted as a representation of the\narithmetic operation to convert it to a custom instruction. Then VHDL code will\nbe automatically generated. The input C code is automatically updated for\ncalling the new hardware components. To prove the effectiveness of the proposed\napproach, a Java source code framework named Automatic Custom Architecture\ngenerator (ACAgen) is developed. Experimental results on 3D sample application\nvalidate our approach and demonstrate how the proposed framework facilitates\nand accelerates the SoC design process at low costs."
},{
    "category": "cs.AR", 
    "doi": "10.1109/GlobalSIP.2013.6737140", 
    "link": "http://arxiv.org/pdf/1308.6021v1", 
    "title": "Selective Decoding in Associative Memories Based on Sparse-Clustered   Networks", 
    "arxiv-id": "1308.6021v1", 
    "author": "Warren J. Gross", 
    "publish": "2013-08-28T00:37:56Z", 
    "summary": "Associative memories are structures that can retrieve previously stored\ninformation given a partial input pattern instead of an explicit address as in\nindexed memories. A few hardware approaches have recently been introduced for a\nnew family of associative memories based on Sparse-Clustered Networks (SCN)\nthat show attractive features. These architectures are suitable for\nimplementations with low retrieval latency, but are limited to small networks\nthat store a few hundred data entries. In this paper, a new hardware\narchitecture of SCNs is proposed that features a new data-storage technique as\nwell as a method we refer to as Selective Decoding (SD-SCN). The SD-SCN has\nbeen implemented using a similar FPGA used in the previous efforts and achieves\ntwo orders of magnitude higher capacity, with no error-performance penalty but\nwith the cost of few extra clock cycles per data access."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2013.4406", 
    "link": "http://arxiv.org/pdf/1309.2458v1", 
    "title": "Low power-area designs of 1bit full adder in cadence virtuoso platform", 
    "arxiv-id": "1309.2458v1", 
    "author": "Karthik Reddy. G", 
    "publish": "2013-09-10T11:19:15Z", 
    "summary": "Power consumption has emerged as a primary design constraint for integrated\ncircuits (ICs). In the Nano meter technology regime, leakage power has become a\nmajor component of total power. Full adder is the basic functional unit of an\nALU. The power consumption of a processor is lowered by lowering the power\nconsumption of an ALU, and the power consumption of an ALU can be lowered by\nlowering the power consumption of Full adder. So the full adder designs with\nlow power characteristics are becoming more popular these days. This proposed\nwork illustrates the design of the low-power less transistor full adder designs\nusing cadence tool and virtuoso platform, the entire simulations have been done\non 180nm single n-well CMOS bulk technology, in virtuoso platform of cadence\ntool with the supply voltage 1.8V and frequency of 100MHz. These circuits\nconsume less power with maximum (6T design)of 93.1% power saving compare to\nconventional 28T design and 80.2% power saving compare to SERF design without\nmuch delay degradation. The proposed circuit exploits the advantage of GDI\ntechnique and pass transistor logic"
},{
    "category": "cs.AR", 
    "doi": "10.2298/FUEE0301083M", 
    "link": "http://arxiv.org/pdf/1309.3685v1", 
    "title": "On the Performance Potential of Speculative Execution based on Branch   and Value Prediction", 
    "arxiv-id": "1309.3685v1", 
    "author": "Marjan Gusev", 
    "publish": "2013-09-14T16:43:05Z", 
    "summary": "Fluid Stochastic Petri Nets are used to capture the dynamic behavior of an\nILP processor, and discrete-event simulation is applied to assess the\nperformance potential of predictions and speculative execution in boosting the\nperformance of ILP processors that fetch, issue, execute and commit a large\nnumber of instructions per cycle."
},{
    "category": "cs.AR", 
    "doi": "10.2298/FUEE0301083M", 
    "link": "http://arxiv.org/pdf/1309.3785v1", 
    "title": "Energy Saving Techniques for Phase Change Memory (PCM)", 
    "arxiv-id": "1309.3785v1", 
    "author": "Sparsh Mittal", 
    "publish": "2013-09-15T18:32:21Z", 
    "summary": "In recent years, the energy consumption of computing systems has increased\nand a large fraction of this energy is consumed in main memory. Towards this,\nresearchers have proposed use of non-volatile memory, such as phase change\nmemory (PCM), which has low read latency and power; and nearly zero leakage\npower. However, the write latency and power of PCM are very high and this,\nalong with limited write endurance of PCM present significant challenges in\nenabling wide-spread adoption of PCM. To address this, several\narchitecture-level techniques have been proposed. In this report, we review\nseveral techniques to manage power consumption of PCM. We also classify these\ntechniques based on their characteristics to provide insights into them. The\naim of this work is encourage researchers to propose even better techniques for\nimproving energy efficiency of PCM based main memory."
},{
    "category": "cs.AR", 
    "doi": "10.2298/FUEE0301083M", 
    "link": "http://arxiv.org/pdf/1309.5459v1", 
    "title": "Advances in computer architecture", 
    "arxiv-id": "1309.5459v1", 
    "author": "Irfan Uddin", 
    "publish": "2013-09-21T10:33:36Z", 
    "summary": "In the past, efforts were taken to improve the performance of a processor via\nfrequency scaling. However, industry has reached the limits of increasing the\nfrequency and therefore concurrent execution of instructions on multiple cores\nseems the only possible option. It is not enough to provide concurrent\nexecution by the hardware, software also have to introduce concurrency in order\nto exploit the parallelism."
},{
    "category": "cs.AR", 
    "doi": "10.2298/FUEE0301083M", 
    "link": "http://arxiv.org/pdf/1309.5507v1", 
    "title": "Microgrid - The microthreaded many-core architecture", 
    "arxiv-id": "1309.5507v1", 
    "author": "Irfan Uddin", 
    "publish": "2013-09-21T17:50:09Z", 
    "summary": "Traditional processors use the von Neumann execution model, some other\nprocessors in the past have used the dataflow execution model. A combination of\nvon Neuman model and dataflow model is also tried in the past and the resultant\nmodel is referred as hybrid dataflow execution model. We describe a hybrid\ndataflow model known as the microthreading. It provides constructs for\ncreation, synchronization and communication between threads in an intermediate\nlanguage. The microthreading model is an abstract programming and machine model\nfor many-core architecture. A particular instance of this model is named as the\nmicrothreaded architecture or the Microgrid. This architecture implements all\nthe concurrency constructs of the microthreading model in the hardware with the\nmanagement of these constructs in the hardware."
},{
    "category": "cs.AR", 
    "doi": "10.2298/FUEE0301083M", 
    "link": "http://arxiv.org/pdf/1309.5551v1", 
    "title": "Design space exploration in the microthreaded many-core architecture", 
    "arxiv-id": "1309.5551v1", 
    "author": "Irfan Uddin", 
    "publish": "2013-09-22T02:01:28Z", 
    "summary": "Design space exploration is commonly performed in embedded system, where the\narchitecture is a complicated piece of engineering. With the current trend of\nmany-core systems, design space exploration in general-purpose computers can no\nlonger be avoided. Microgrid is a complicated architecture, and therefor we\nneed to perform design space exploration. Generally, simulators are used for\nthe design space exploration of an architecture. Different simulators with\ndifferent levels of complexity, simulation time and accuracy are used.\nSimulators with little complexity, low simulation time and reasonable accuracy\nare desirable for the design space exploration of an architecture. These\nsimulators are referred as high-level simulators and are commonly used in the\ndesign of embedded systems. However, the use of high-level simulation for\ndesign space exploration in general-purpose computers is a relatively new area\nof research."
},{
    "category": "cs.AR", 
    "doi": "10.2298/FUEE0301083M", 
    "link": "http://arxiv.org/pdf/1309.5647v1", 
    "title": "A Cache-Coloring Based Technique for Saving Leakage Energy In   Multitasking Systems", 
    "arxiv-id": "1309.5647v1", 
    "author": "Sparsh Mittal", 
    "publish": "2013-09-22T20:44:49Z", 
    "summary": "There has been a significant increase in leakage energy dissipation of CMOS\ncircuits with each technology generation. Further, due to their large size,\nlast level caches (LLCs) spend a large fraction of their energy in the form of\nleakage energy and hence, addressing this has become extremely important to\nmeet the challenges of chip power budget. For addressing this, several\ntechniques have been proposed. However, most of these techniques require\noffline profiling and hence cannot be used for real-life systems which usually\nrun multitasking programs, with possible pre-emptions. In this paper, we\npropose a dynamic profiling based technique for saving cache leakage energy in\nmultitasking systems. Our technique uses a small coloring-based profiling\ncache, to estimate performance and energy consumption of multiple cache\nconfigurations and then selects the best (least-energy) configuration among\nthem. Our technique uses non-intrusive profiling and saves energy despite\nintra-task and inter-task variations; thus, it is suitable for multitasking\nsystems. Simulations performed using workloads from SPEC2006 suite show the\nsuperiority of our technique over an existing cache energy saving technique.\nWith a 2MB baseline cache, the average saving in memory sub-system energy is\n22.8%."
},{
    "category": "cs.AR", 
    "doi": "10.2298/FUEE0301083M", 
    "link": "http://arxiv.org/pdf/1309.7082v1", 
    "title": "A Cache Reconfiguration Approach for Saving Leakage and Refresh Energy   in Embedded DRAM Caches", 
    "arxiv-id": "1309.7082v1", 
    "author": "Sparsh Mittal", 
    "publish": "2013-09-26T22:18:43Z", 
    "summary": "In recent years, the size and leakage energy consumption of large last level\ncaches (LLCs) has increased. To address this, embedded DRAM (eDRAM) caches have\nbeen considered which have lower leakage energy consumption; however eDRAM\ncaches consume a significant amount of energy in the form of refresh energy. In\nthis paper, we present a technique for saving both leakage and refresh energy\nin eDRAM caches. We use dynamic cache reconfiguration approach to intelligently\nturn-off part of the cache to save leakage energy and refresh only valid data\nof the active (i.e. not turned-off) cache to save refresh energy. We evaluate\nour technique using an x86-64 simulator and SPEC2006 benchmarks and compare it\nwith a recently proposed technique for saving refresh energy, named Refrint.\nThe experiments have shown that our technique provides better performance and\nenergy efficiency than Refrint. Using our technique, for a 2MB LLC and 40\nmicro-seconds eDRAM refresh period, the average saving in energy over eDRAM\nbaseline (which periodically refreshes all cache lines) is 22.8%."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ISPCC.2013.6663444", 
    "link": "http://arxiv.org/pdf/1309.7163v1", 
    "title": "A Low-Voltage, Low-Power 4-bit BCD Adder, designed using the Clock Gated   Power Gating, and the DVT Scheme", 
    "arxiv-id": "1309.7163v1", 
    "author": "C. K. Sarkar", 
    "publish": "2013-09-27T09:09:37Z", 
    "summary": "This paper proposes a Low-Power, Energy Efficient 4-bit Binary Coded Decimal\n(BCD) adder design where the conventional 4-bit BCD adder has been modified\nwith the Clock Gated Power Gating Technique. Moreover, the concept of DVT\n(Dual-vth) scheme has been introduced while designing the full adder blocks to\nreduce the Leakage Power, as well as, to maintain the overall performance of\nthe entire circuit. The reported architecture of 4-bit BCD adder is designed\nusing 45 nm technology and it consumes 1.384 {\\mu}Watt of Average Power while\noperating with a frequency of 200 MHz, and a Supply Voltage (Vdd) of 1 Volt.\nThe results obtained from different simulation runs on SPICE, indicate the\nsuperiority of the proposed design compared to the conventional 4-bit BCD\nadder. Considering the product of Average Power and Delay, for the operating\nfrequency of 200 MHz, a fair 47.41 % reduction compared to the conventional\ndesign has been achieved with this proposed scheme."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ISPCC.2013.6663444", 
    "link": "http://arxiv.org/pdf/1309.7321v1", 
    "title": "Recycled Error Bits: Energy-Efficient Architectural Support for Higher   Precision Floating Point", 
    "arxiv-id": "1309.7321v1", 
    "author": "Xiaobai Sun", 
    "publish": "2013-09-27T18:24:32Z", 
    "summary": "In this work, we provide energy-efficient architectural support for floating\npoint accuracy. Our goal is to provide accuracy that is far greater than that\nprovided by the processor's hardware floating point unit (FPU). Specifically,\nfor each floating point addition performed, we \"recycle\" that operation's\nerror: the difference between the finite-precision result produced by the\nhardware and the result that would have been produced by an infinite-precision\nFPU. We make this error architecturally visible such that it can be used, if\ndesired, by software. Experimental results on physical hardware show that\nsoftware that exploits architecturally recycled error bits can achieve accuracy\ncomparable to a 2B-bit FPU with performance and energy that are comparable to a\nB-bit FPU."
},{
    "category": "cs.AR", 
    "doi": "10.1109/SiPS.2013.6674541", 
    "link": "http://arxiv.org/pdf/1309.7818v1", 
    "title": "Partial Sums Generation Architecture for Successive Cancellation   Decoding of Polar Codes", 
    "arxiv-id": "1309.7818v1", 
    "author": "Dominique Dallet", 
    "publish": "2013-09-30T12:20:47Z", 
    "summary": "Polar codes are a new family of error correction codes for which efficient\nhardware architectures have to be defined for the encoder and the decoder.\nPolar codes are decoded using the successive cancellation decoding algorithm\nthat includes partial sums computations. We take advantage of the recursive\nstructure of polar codes to introduce an efficient partial sums computation\nunit that can also implements the encoder. The proposed architecture is\nsynthesized for several codelengths in 65nm ASIC technology. The area of the\nresulting design is reduced up to 26% and the maximum working frequency is\nimproved by ~25%."
},{
    "category": "cs.AR", 
    "doi": "10.1109/SiPS.2013.6674541", 
    "link": "http://arxiv.org/pdf/1311.0041v2", 
    "title": "A Technique for Write-endurance aware Management of Resistive RAM Last   Level Caches", 
    "arxiv-id": "1311.0041v2", 
    "author": "Sparsh Mittal", 
    "publish": "2013-10-31T21:41:18Z", 
    "summary": "Due to increasing cache sizes and large leakage consumption of SRAM device,\nconventional SRAM caches contribute significantly to the processor power\nconsumption. Recently researchers have used non-volatile memory devices to\ndesign caches, since they provide high density, comparable read latency and low\nleakage power dissipation. However, their high write latency may increase the\nexecution time and hence, leakage energy consumption. Also, since their write\nendurance is small, a conventional energy saving technique may further\naggravate the problem of write-variations, thus reducing their lifetime. In\nthis paper, we present a cache energy saving technique for non-volatile caches,\nwhich also attempts to improve their lifetime by making writes equally\ndistributed to the cache. Our technique uses dynamic cache reconfiguration to\nadjust the cache size to meet program requirement and turns off the remaining\ncache to save energy. Microarchitectural simulations performed using an x86-64\nsimulator, SPEC2006 benchmarks and a resistive-RAM LLC (last level cache) show\nthat over an 8MB baseline cache, our technique saves 17.55% memory subsystem\n(last level cache + main memory) energy and improves the lifetime by 1.33X.\nOver the same resistive-RAM baseline, an SRAM of similar area with no cache\nreconfiguration leads to an energy loss of 186.13%."
},{
    "category": "cs.AR", 
    "doi": "10.1109/SiPS.2013.6674541", 
    "link": "http://arxiv.org/pdf/1311.0170v1", 
    "title": "A Technique for Efficiently Managing SRAM-NVM Hybrid Cache", 
    "arxiv-id": "1311.0170v1", 
    "author": "Sparsh Mittal", 
    "publish": "2013-11-01T12:52:59Z", 
    "summary": "In this paper, we present a SRAM-PCM hybrid cache design, along with a cache\nreplacement policy, named dead fast block (DFB) to manage the hybrid cache.\nThis design aims to leverage the best features of both SRAM and PCM devices.\nCompared to a PCM-only cache, the hybrid cache with DFB policy provides\nsuperior results on all relevant evaluation metrics, viz. cache lifetime,\nperformance and energy efficiency. Also, use of DFB policy for managing the\nhybrid cache provides better results compared to LRU replacement policy on all\nthe evaluation metrics."
},{
    "category": "cs.AR", 
    "doi": "10.1109/SiPS.2013.6674541", 
    "link": "http://arxiv.org/pdf/1311.0602v2", 
    "title": "Input-Output Logic based Fault-Tolerant Design Technique for SRAM-based   FPGAs", 
    "arxiv-id": "1311.0602v2", 
    "author": "Zafar Ali Khan", 
    "publish": "2013-11-04T08:23:38Z", 
    "summary": "Effects of radiation on electronic circuits used in extra-terrestrial\napplications and radiation prone environments need to be corrected. Since FPGAs\noffer flexibility, the effects of radiation on them need to be studied and\nrobust methods of fault tolerance need to be devised. In this paper a new\nfault-tolerant design strategy has been presented. This strategy exploits the\nrelation between changes in inputs and the expected change in output.\nEssentially, it predicts whether or not a change in the output is expected and\nthereby calculates the error. As a result this strategy reduces hardware and\ntime redundancy required by existing strategies like Duplication with\nComparison (DWC) and Triple Modular Redundancy (TMR). The design arising from\nthis strategy has been simulated and its robustness to fault-injection has been\nverified. Simulations for a 16 bit multiplier show that the new design strategy\nperforms better than the state-of-the-art on critical factors such as hardware\nredundancy, time redundancy and power consumption."
},{
    "category": "cs.AR", 
    "doi": "10.1109/SiPS.2013.6674541", 
    "link": "http://arxiv.org/pdf/1311.1667v1", 
    "title": "3D Cache Hierarchy Optimization", 
    "arxiv-id": "1311.1667v1", 
    "author": "Ran Ginosar", 
    "publish": "2013-11-07T13:15:11Z", 
    "summary": "3D integration has the potential to improve the scalability and performance\nof Chip Multiprocessors (CMP). A closed form analytical solution for optimizing\n3D CMP cache hierarchy is developed. It allows optimal partitioning of the\ncache hierarchy levels into 3D silicon layers and optimal allocation of area\namong cache hierarchy levels under constrained area and power budgets. The\noptimization framework is extended by incorporating the impact of multithreaded\ndata sharing on the private cache miss rate. An analytical model for cache\naccess time as a function of cache size and a number of 3D partitions is\nproposed and verified using CACTI simulation."
},{
    "category": "cs.AR", 
    "doi": "10.1109/SiPS.2013.6674541", 
    "link": "http://arxiv.org/pdf/1402.2415v2", 
    "title": "Reversible Squaring Circuit For Low Power Digital Signal Processing", 
    "arxiv-id": "1402.2415v2", 
    "author": "Devraj Gautam", 
    "publish": "2014-02-11T10:01:15Z", 
    "summary": "With the high demand of low power digital systems, energy dissipation in the\ndigital system is one of the limiting factors. Reversible logic is one of the\nalternate to reduce heat/energy dissipation in the digital circuits and have a\nvery significant importance in bioinformatics, optical information processing,\nCMOS design etc. In this paper the authors propose the design of new 2- bit\nbinary Squaring circuit used in most of the digital signal processing hardware\nusing Feynman & MUX gate. The proposed squaring circuit having less garbage\noutputs, constant inputs, Quantum cost and Total logical calculation i.e. less\ndelay as compared to the traditional method of squaring operation by reversible\nmultiplier. The simulating results and quantized results are also shown in the\npaper which shows the greatest improvement in the design against the previous\nmethodology."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASPDAC.2013.6509604", 
    "link": "http://arxiv.org/pdf/1402.2420v1", 
    "title": "L-Shape based Layout Fracturing for E-Beam Lithography", 
    "arxiv-id": "1402.2420v1", 
    "author": "David Z. Pan", 
    "publish": "2014-02-11T10:10:39Z", 
    "summary": "Layout fracturing is a fundamental step in mask data preparation and e-beam\nlithography (EBL) writing. To increase EBL throughput, recently a new L-shape\nwriting strategy is proposed, which calls for new L-shape fracturing, versus\nthe conventional rectangular fracturing. Meanwhile, during layout fracturing,\none must minimize very small/narrow features, also called slivers, due to\nmanufacturability concern. This paper addresses this new research problem of\nhow to perform L-shaped fracturing with sliver minimization. We propose two\nnovel algorithms. The first one, rectangular merging (RM), starts from a set of\nrectangular fractures and merges them optimally to form L-shape fracturing. The\nsecond algorithm, direct L-shape fracturing (DLF), directly and effectively\nfractures the input layouts into L-shapes with sliver minimization. The\nexperimental results show that our algorithms are very effective."
},{
    "category": "cs.AR", 
    "doi": "10.1117/12.2011355", 
    "link": "http://arxiv.org/pdf/1402.2425v1", 
    "title": "Triple Patterning Lithography (TPL) Layout Decomposition using   End-Cutting", 
    "arxiv-id": "1402.2425v1", 
    "author": "David Z. Pan", 
    "publish": "2014-02-11T10:26:20Z", 
    "summary": "Triple patterning lithography (TPL) is one of the most promising techniques\nin the 14nm logic node and beyond. However, traditional LELELE type TPL\ntechnology suffers from native conflict and overlapping problems. Recently\nLELEEC process was proposed to overcome the limitations, where the third mask\nis used to generate the end-cuts. In this paper we propose the first study for\nLELEEC layout decomposition. Conflict graphs and end-cut graphs are constructed\nto extract all the geometrical relationships of input layout and end-cut\ncandidates. Based on these graphs, integer linear programming (ILP) is\nformulated to minimize the conflict number and the stitch number."
},{
    "category": "cs.AR", 
    "doi": "10.1117/12.2011355", 
    "link": "http://arxiv.org/pdf/1402.2435v1", 
    "title": "E-BLOW: E-Beam Lithography Overlapping aware Stencil Planning for MCC   System", 
    "arxiv-id": "1402.2435v1", 
    "author": "David Z. Pan", 
    "publish": "2014-02-11T10:37:37Z", 
    "summary": "Electron beam lithography (EBL) is a promising maskless solution for the\ntechnology beyond 14nm logic node. To overcome its throughput limitation,\nrecently the traditional EBL system is extended into MCC system. %to further\nimprove the throughput. In this paper, we present E-BLOW, a tool to solve the\noverlapping aware stencil planning (OSP) problems in MCC system. E-BLOW is\nintegrated with several novel speedup techniques, i.e., successive relaxation,\ndynamic programming and KD-Tree based clustering, to achieve a good performance\nin terms of runtime and solution quality. Experimental results show that,\ncompared with previous works, E-BLOW demonstrates better performance for both\nconventional EBL system and MCC system."
},{
    "category": "cs.AR", 
    "doi": "10.1117/12.2011660", 
    "link": "http://arxiv.org/pdf/1402.2442v1", 
    "title": "Self-Aligned Double Patterning Friendly Configuration for Standard Cell   Library Considering Placement", 
    "arxiv-id": "1402.2442v1", 
    "author": "David Z. Pan", 
    "publish": "2014-02-11T11:02:42Z", 
    "summary": "Self-aligned double patterning (SADP) has become a promising technique to\npush pattern resolution limit to sub-22nm technology node. Although SADP\nprovides good overlay controllability, it encounters many challenges in\nphysical design stages to obtain conflict-free layout decomposition. In this\npaper, we study the impact on placement by different standard cell layout\ndecomposition strategies. We propose a SADP friendly standard cell\nconfiguration which provides pre-coloring results for standard cells. These\nconfigurations are brought into the placement stage to help ensure layout\ndecomposability and save the extra effort for solving conflicts in later\nstages."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICCAD.2011.6105297", 
    "link": "http://arxiv.org/pdf/1402.2459v1", 
    "title": "Layout decomposition for triple patterning lithography", 
    "arxiv-id": "1402.2459v1", 
    "author": "David Z. Pan", 
    "publish": "2014-02-11T11:36:51Z", 
    "summary": "As minimum feature size and pitch spacing further decrease, triple patterning\nlithography (TPL) is a possible 193nm extension along the paradigm of double\npatterning lithography (DPL). However, there is very little study on TPL layout\ndecomposition. In this paper, we show that TPL layout decomposition is a more\ndifficult problem than that for DPL. We then propose a general integer linear\nprogramming formulation for TPL layout decomposition which can simultaneously\nminimize conflict and stitch numbers. Since ILP has very poor scalability, we\npropose three acceleration techniques without sacrificing solution quality:\nindependent component computation, layout graph simplification, and bridge\ncomputation. For very dense layouts, even with these speedup techniques, ILP\nformulation may still be too slow. Therefore, we propose a novel vector\nprogramming formulation for TPL decomposition, and solve it through effective\nsemidefinite programming (SDP) approximation. Experimental results show that\nthe ILP with acceleration techniques can reduce 82% runtime compared to the\nbaseline ILP. Using SDP based algorithm, the runtime can be further reduced by\n42% with some tradeoff in the stitch number (reduced by 7%) and the conflict\n(9% more). However, for very dense layouts, SDP based algorithm can achieve\n140x speed-up even compared with accelerated ILP."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASPDAC.2011.5722236", 
    "link": "http://arxiv.org/pdf/1402.2460v1", 
    "title": "Network flow-based simultaneous retiming and slack budgeting for low   power design", 
    "arxiv-id": "1402.2460v1", 
    "author": "Satoshi Goto", 
    "publish": "2014-02-11T11:49:24Z", 
    "summary": "Low power design has become one of the most significant requirements when\nCMOS technology entered the nanometer era. Therefore, timing budget is often\nperformed to slow down as many components as possible so that timing slacks can\nbe applied to reduce the power consumption while maintaining the performance of\nthe whole design. Retiming is a procedure that involves the relocation of\nflip-flops (FFs) across logic gates to achieve faster clocking speed. In this\npaper we show that the retiming and slack budgeting problem can be formulated\nto a convex cost dual network flow problem. Both the theoretical analysis and\nexperimental results show the efficiency of our approach which can not only\nreduce power consumption by 8.9%, but also speedup previous work by 500 times."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASPDAC.2010.5419825", 
    "link": "http://arxiv.org/pdf/1402.2462v1", 
    "title": "Floorplanning and Topology Generation for Application-Specific   Network-on-Chip", 
    "arxiv-id": "1402.2462v1", 
    "author": "Satoshi Goto", 
    "publish": "2014-02-11T11:57:04Z", 
    "summary": "Network-on-chip (NoC) architectures have been proposed as a promising\nalternative to classical bus-based communication architectures. In this paper,\nwe propose a two phases framework to solve application-specific NoCs topology\ngeneration problem. At floorplanning phase, we carry out partition driven\nfloorplanning. At post-floorplanning phase, a heuristic method and a min-cost\nmax-flow algorithm is used to insert switches and network interfaces. Finally,\nwe allocate paths to minimize power consumption. The experimental results show\nour algorithm is effective for power saving."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASPDAC.2010.5419825", 
    "link": "http://arxiv.org/pdf/1402.2536v1", 
    "title": "Design and Implementation of Bit Transition Counter", 
    "arxiv-id": "1402.2536v1", 
    "author": "Balwinder Singh", 
    "publish": "2014-02-11T15:51:52Z", 
    "summary": "In today VLSI system design, power consumption is gaining more attention as\ncompared to performance and area. This is due to battery life in portable\ndevices and operating frequency of the design. Power consumption mainly\nconsists of static power, dynamic power, leakage power and short circuit power.\nDynamic power is dominant among all which depends on many factors viz. power\nsupply, load capacitance and frequency. Switching activity also affects dynamic\npower consumption of bus which is determined by calculating the number of bit\ntransitions on bus. The purpose of this paper is to design a bit transition\ncounter which can be used to calculate the switching activity of the circuit\nnodes. The novel feature is that it can be inserted at any node of the circuit,\nthus helpful for calculating power consumption of bus."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASPDAC.2010.5419825", 
    "link": "http://arxiv.org/pdf/1402.2635v1", 
    "title": "Methodology for standard cell compliance and detailed placement for   triple patterning lithography", 
    "arxiv-id": "1402.2635v1", 
    "author": "David Z. Pan", 
    "publish": "2014-02-11T20:29:09Z", 
    "summary": "As the feature size of semiconductor process further scales to sub-16nm\ntechnology node, triple patterning lithography (TPL) has been regarded one of\nthe most promising lithography candidates. M1 and contact layers, which are\nusually deployed within standard cells, are most critical and complex parts for\nmodern digital designs. Traditional design flow that ignores TPL in early\nstages may limit the potential to resolve all the TPL conflicts. In this paper,\nwe propose a coherent framework, including standard cell compliance and\ndetailed placement to enable TPL friendly design. Considering TPL constraints\nduring early design stages, such as standard cell compliance, improves the\nlayout decomposability. With the pre-coloring solutions of standard cells, we\npresent a TPL aware detailed placement, where the layout decomposition and\nplacement can be resolved simultaneously. Our experimental results show that,\nwith negligible impact on critical path delay, our framework can resolve the\nconflicts much more easily, compared with the traditional physical design flow\nand followed layout decomposition."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASPDAC.2010.5419825", 
    "link": "http://arxiv.org/pdf/1402.2890v1", 
    "title": "A High-Performance Triple Patterning Layout Decomposer with Balanced   Density", 
    "arxiv-id": "1402.2890v1", 
    "author": "David Z. Pan", 
    "publish": "2014-02-12T16:43:46Z", 
    "summary": "Triple patterning lithography (TPL) has received more and more attentions\nfrom industry as one of the leading candidate for 14nm/11nm nodes. In this\npaper, we propose a high performance layout decomposer for TPL. Density\nbalancing is seamlessly integrated into all key steps in our TPL layout\ndecomposition, including density-balanced semi-definite programming (SDP),\ndensity-based mapping, and density-balanced graph simplification. Our new TPL\ndecomposer can obtain high performance even compared to previous\nstate-of-the-art layout decomposers which are not balanced-density aware, e.g.,\nby Yu et al. (ICCAD'11), Fang et al. (DAC'12), and Kuang et al. (DAC'13).\nFurthermore, the balanced-density version of our decomposer can provide more\nbalanced density which leads to less edge placement error (EPE), while the\nconflict and stitch numbers are still very comparable to our\nnon-balanced-density baseline."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASICON.2009.5351219", 
    "link": "http://arxiv.org/pdf/1402.2894v1", 
    "title": "Multi-Voltage and Level-Shifter Assignment Driven Floorplanning", 
    "arxiv-id": "1402.2894v1", 
    "author": "Statoshi Goto", 
    "publish": "2014-02-12T16:55:10Z", 
    "summary": "As technology scales, low power design has become a significant requirement\nfor SOC designers. Among the existing techniques, Multiple-Supply Voltage (MSV)\nis a popular and effective method to reduce both dynamic and static power.\nBesides, level shifters consume area and delay, and should be considered during\nfloorplanning. In this paper, we present a new floorplanning system, called\nMVLSAF, to solve multi-voltage and level shifter assignment problem. We use a\nconvex cost network flow algorithm to assign arbitrary number of legal working\nvoltages and a minimum cost flow algorithm to handle level-shifter assignment.\nThe experimental results show MVLSAF is effective."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASPDAC.2012.6165031", 
    "link": "http://arxiv.org/pdf/1402.2899v1", 
    "title": "GLOW: A global router for low-power thermal-reliable interconnect   synthesis using photonic wavelength multiplexing", 
    "arxiv-id": "1402.2899v1", 
    "author": "David Z. Pan", 
    "publish": "2014-02-12T17:03:22Z", 
    "summary": "In this paper, we examine the integration potential and explore the design\nspace of low power thermal reliable on-chip interconnect synthesis featuring\nnanophotonics Wavelength Division Multiplexing (WDM). With the recent\nadvancements, it is foreseen that nanophotonics holds the promise to be\nemployed for future on-chip data signalling due to its unique power efficiency,\nsignal delay and huge multiplexing potential. However, there are major\nchallenges to address before feasible on-chip integration could be reached. In\nthis paper, we present GLOW, a hybrid global router to provide low power\nopto-electronic interconnect synthesis under the considerations of thermal\nreliability and various physical design constraints such as optical power,\ndelay and signal quality. GLOW is evaluated with testing cases derived from\nISPD07-08 global routing benchmarks. Compared with a greedy approach, GLOW\ndemonstrates around 23%-50% of total optical power reduction, revealing great\npotential of on-chip WDM interconnect synthesis."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASPDAC.2012.6164956", 
    "link": "http://arxiv.org/pdf/1402.2904v1", 
    "title": "EPIC: Efficient prediction of IC manufacturing hotspots with a unified   meta-classification formulation", 
    "arxiv-id": "1402.2904v1", 
    "author": "David Z. Pan", 
    "publish": "2014-02-12T17:25:05Z", 
    "summary": "In this paper we present EPIC, an efficient and effective predictor for IC\nmanufacturing hotspots in deep sub-wavelength lithography. EPIC proposes a\nunified framework to combine different hotspot detection methods together, such\nas machine learning and pattern matching, using mathematical\nprogramming/optimization. EPIC algorithm has been tested on a number of\nindustry benchmarks under advanced manufacturing conditions. It demonstrates so\nfar the best capability in selectively combining the desirable features of\nvarious hotspot detection methods (3.5-8.2% accuracy improvement) as well as\nsignificant suppression of the detection noise (e.g., 80% false-alarm\nreduction). These characteristics make EPIC very suitable for conducting high\nperformance physical verification and guiding efficient manufacturability\nfriendly physical design."
},{
    "category": "cs.AR", 
    "doi": "10.1145/2429384.2429408", 
    "link": "http://arxiv.org/pdf/1402.2906v1", 
    "title": "TRIAD: a triple patterning lithography aware detailed router", 
    "arxiv-id": "1402.2906v1", 
    "author": "Yih-Lang Li", 
    "publish": "2014-02-12T17:34:01Z", 
    "summary": "TPL-friendly detailed routers require a systematic approach to detect TPL\nconflicts. However, the complexity of conflict graph (CG) impedes directly\ndetecting TPL conflicts in CG. This work proposes a token graph-embedded\nconflict graph (TECG) to facilitate the TPL conflict detection while\nmaintaining high coloring-flexibility. We then develop a TPL aware detailed\nrouter (TRIAD) by applying TECG to a gridless router with the TPL stitch\ngeneration. Compared to a greedy coloring approach, experimental results\nindicate that TRIAD generates no conflicts and few stitches with shorter\nwirelength at the cost of 2.41x of runtime."
},{
    "category": "cs.AR", 
    "doi": "10.1587/transfun.E92.A.2990", 
    "link": "http://arxiv.org/pdf/1402.3149v1", 
    "title": "Voltage and Level-Shifter Assignment Driven Floorplanning", 
    "arxiv-id": "1402.3149v1", 
    "author": "Satoshi Goto", 
    "publish": "2014-02-13T14:32:26Z", 
    "summary": "Low Power Design has become a significant requirement when the CMOS\ntechnology entered the nanometer era. Multiple-Supply Voltage (MSV) is a\npopular and effective method for both dynamic and static power reduction while\nmaintaining performance. Level shifters may cause area and Interconnect Length\nOverhead (ILO), and should be considered at both floorplanning and\npost-floorplanning stages. In this paper, we propose a two phases algorithm\nframework, called VLSAF, to solve voltage and level shifter assignment problem.\nAt floorplanning phase, we use a convex cost network flow algorithm to assign\nvoltage and a minimum cost flow algorithm to handle level-shifter assignment.\nAt post-floorplanning phase, a heuristic method is adopted to redistribute\nwhite spaces and calculate the positions and shapes of level shifters. The\nexperimental results show VLSAF is effective."
},{
    "category": "cs.AR", 
    "doi": "10.1587/transfun.E92.A.2990", 
    "link": "http://arxiv.org/pdf/1402.3150v1", 
    "title": "Lithography Hotspot Detection and Mitigation in Nanometer VLSI", 
    "arxiv-id": "1402.3150v1", 
    "author": "David Z. Pan", 
    "publish": "2014-02-13T14:32:56Z", 
    "summary": "With continued feature size scaling, even state of the art semiconductor\nmanufacturing processes will often run into layouts with poor printability and\nyield. Identifying lithography hotspots is important at both physical\nverification and early physical design stages. While detailed lithography\nsimulations can be very accurate, they may be too computationally expensive for\nfull-chip scale and physical design inner loops. Meanwhile, pattern matching\nand machine learning based hotspot detection methods can provide acceptable\nquality and yet fast turn-around-time for full-chip scale physical verification\nand design. In this paper, we discuss some key issues and recent results on\nlithography hotspot detection and mitigation in nanometer VLSI."
},{
    "category": "cs.AR", 
    "doi": "10.1587/transfun.E92.A.2990", 
    "link": "http://arxiv.org/pdf/1402.6005v1", 
    "title": "Open Cores for Digital Signal Processing", 
    "arxiv-id": "1402.6005v1", 
    "author": "Alexander L\u00f3pez-Parrado", 
    "publish": "2014-02-24T22:42:02Z", 
    "summary": "This paper presents the design and implementation of three System on Chip\n(SoC) cores, which implement the Digital Signal Processing (DSP) functions:\nFinite Impulse Response (FIR) filter, Infinite Impulse Response (IIR) filter\nand Fast Fourier Transform (FFT). The FIR filter core is based on the\nsymmetrical realization form, the IIR filter core is based on the Second Order\nSections (SOS) architecture and the FFT core is based on the Radix $2^2$ Single\nDelay Feedback (R$2^2$SDF) architecture. The three cores are compatible with\nthe Wishbone SoC bus and they were described using generic and structural VHDL.\nIn system hardware verification was performed by using an OpenRisc-based SoC\nsynthesized on an Altera FPGA, the tests showed that the designed DSP cores are\nsuitable for building SoC based on the OpenRisc processor and the Wishbone bus."
},{
    "category": "cs.AR", 
    "doi": "10.1145/2656106.2656108", 
    "link": "http://arxiv.org/pdf/1404.1602v2", 
    "title": "A high-level model of embedded flash energy consumption", 
    "arxiv-id": "1404.1602v2", 
    "author": "Jeremy Bennett", 
    "publish": "2014-04-06T17:34:23Z", 
    "summary": "The alignment of code in the flash memory of deeply embedded SoCs can have a\nlarge impact on the total energy consumption of a computation. We investigate\nthe effect of code alignment in six SoCs and find that a large proportion of\nthis energy (up to 15% of total SoC energy consumption) can be saved by changes\nto the alignment.\n  A flexible model is created to predict the read-access energy consumption of\nflash memory on deeply embedded SoCs, where code is executed in place. This\nmodel uses the instruction level memory accesses performed by the processor to\ncalculate the flash energy consumption of a sequence of instructions. We derive\nthe model parameters for five SoCs and validate them. The error is as low as\n5%, with a 11% average normalized RMS deviation overall.\n  The scope for using this model to optimize code alignment is explored across\na range of benchmarks and SoCs. Analysis shows that over 30% of loops can be\nbetter aligned. This can significantly reduce energy while increasing code size\nby less than 4%. We conclude that this effect has potential as an effective\noptimization, saving significant energy in deeply embedded SoCs."
},{
    "category": "cs.AR", 
    "doi": "10.1145/2656106.2656108", 
    "link": "http://arxiv.org/pdf/1404.3162v1", 
    "title": "A Signal Processor for Gaussian Message Passing", 
    "arxiv-id": "1404.3162v1", 
    "author": "Qiuting Huang", 
    "publish": "2014-04-11T17:28:54Z", 
    "summary": "In this paper, we present a novel signal processing unit built upon the\ntheory of factor graphs, which is able to address a wide range of signal\nprocessing algorithms. More specifically, the demonstrated factor graph\nprocessor (FGP) is tailored to Gaussian message passing algorithms. We show how\nto use a highly configurable systolic array to solve the message update\nequations of nodes in a factor graph efficiently. A proper instruction set and\ncompilation procedure is presented. In a recursive least squares channel\nestimation example we show that the FGP can compute a message update faster\nthan a state-ofthe- art DSP. The results demonstrate the usabilty of the FGP\narchitecture as a flexible HW accelerator for signal-processing and\ncommunication systems."
},{
    "category": "cs.AR", 
    "doi": "10.1145/2656106.2656108", 
    "link": "http://arxiv.org/pdf/1404.3381v1", 
    "title": "Modeling the Temperature Bias of Power Consumption for Nanometer-Scale   CPUs in Application Processors", 
    "arxiv-id": "1404.3381v1", 
    "author": "Fabien Coelho", 
    "publish": "2014-04-13T13:07:36Z", 
    "summary": "We introduce and experimentally validate a new macro-level model of the CPU\ntemperature/power relationship within nanometer-scale application processors or\nsystem-on-chips. By adopting a holistic view, this model is able to take into\naccount many of the physical effects that occur within such systems. Together\nwith two algorithms described in the paper, our results can be used, for\ninstance by engineers designing power or thermal management units, to cancel\nthe temperature-induced bias on power measurements. This will help them gather\ntemperature-neutral power data while running multiple instance of their\nbenchmarks. Also power requirements and system failure rates can be decreased\nby controlling the CPU's thermal behavior.\n  Even though it is usually assumed that the temperature/power relationship is\nexponentially related, there is however a lack of publicly available physical\ntemperature/power measurements to back up this assumption, something our paper\ncorrects. Via measurements on two pertinent platforms sporting nanometer-scale\napplication processors, we show that the power/temperature relationship is\nindeed very likely exponential over a 20{\\deg}C to 85{\\deg}C temperature range.\nOur data suggest that, for application processors operating between 20{\\deg}C\nand 50{\\deg}C, a quadratic model is still accurate and a linear approximation\nis acceptable."
},{
    "category": "cs.AR", 
    "doi": "10.1145/2656106.2656108", 
    "link": "http://arxiv.org/pdf/1404.3877v1", 
    "title": "Design space exploration for image processing architectures on FPGA   targets", 
    "arxiv-id": "1404.3877v1", 
    "author": "Ranjan Ghosh", 
    "publish": "2014-04-15T11:46:50Z", 
    "summary": "Due to the emergence of embedded applications in image and video processing,\ncommunication and cryptography, improvement of pictorial information for better\nhuman perception like deblurring, denoising in several fields such as satellite\nimaging, medical imaging, mobile applications etc. are gaining importance for\nrenewed research. Behind such developments, the primary responsibility lies\nwith the advancement of semiconductor technology leading to FPGA based\nprogrammable logic devices, which combines the advantages of both custom\nhardware and dedicated DSP resources. In addition, FPGA provides powerful\nreconfiguration feature and hence is an ideal target for rapid prototyping. We\nhave endeavoured to exploit exceptional features of FPGA technology in respect\nto hardware parallelism leading to higher computational density and throughput,\nand have observed better performances than those one can get just merely\nporting the image processing software algorithms to hardware. In this paper, we\nintend to present an elaborate review, based on our expertise and experiences,\non undertaking necessary transformation to an image processing software\nalgorithm including the optimization techniques that makes its operation in\nhardware comparatively faster."
},{
    "category": "cs.AR", 
    "doi": "10.1145/2656106.2656108", 
    "link": "http://arxiv.org/pdf/1404.4629v2", 
    "title": "A Survey of Methods For Analyzing and Improving GPU Energy Efficiency", 
    "arxiv-id": "1404.4629v2", 
    "author": "Jeffrey S. Vetter", 
    "publish": "2014-04-17T19:57:51Z", 
    "summary": "Recent years have witnessed a phenomenal growth in the computational\ncapabilities and applications of GPUs. However, this trend has also led to\ndramatic increase in their power consumption. This paper surveys research works\non analyzing and improving energy efficiency of GPUs. It also provides a\nclassification of these techniques on the basis of their main research idea.\nFurther, it attempts to synthesize research works which compare energy\nefficiency of GPUs with other computing systems, e.g. FPGAs and CPUs. The aim\nof this survey is to provide researchers with knowledge of state-of-the-art in\nGPU power management and motivate them to architect highly energy-efficient\nGPUs of tomorrow."
},{
    "category": "cs.AR", 
    "doi": "10.14445/22315381/IJETT-V10P235", 
    "link": "http://arxiv.org/pdf/1404.5885v1", 
    "title": "Hardware Efficient WiMAX Deinterleaver Capable of Address Generation for   Random Interleaving Depths", 
    "arxiv-id": "1404.5885v1", 
    "author": "Gangadharaiah S. L", 
    "publish": "2014-04-22T12:38:22Z", 
    "summary": "The variation in the prescribed modulation schemes and code rates for WiMAX\ninterleaver design, as defined by IEEE 802.16 standard, demands a plethora of\nhardware if all the modulation schemes and code rates have to be unified into a\nsingle electronic device. Add to this the complexities involved with the\nalgorithms and permutations of the WiMAX standard, invariably dependent on\nfloor function which is extremely hardware inefficient. This paper is an\nattempt towards removing the complexities and excess hardware involvement in\nthe implementation of the permutations involved in Deinterleaver designs as\ndefined by IEEE 802.16"
},{
    "category": "cs.AR", 
    "doi": "10.14445/22315381/IJETT-V10P235", 
    "link": "http://arxiv.org/pdf/1404.5929v1", 
    "title": "FPGA design of a cdma2000 turbo decoder", 
    "arxiv-id": "1404.5929v1", 
    "author": "Fabio G. Guerrero", 
    "publish": "2014-04-23T19:09:19Z", 
    "summary": "This paper presents the FPGA hardware design of a turbo decoder for the\ncdma2000 standard. The work includes a study and mathematical analysis of the\nturbo decoding process, based on the MAX-Log-MAP algorithm. Results of decoding\nfor a packet size of two hundred fifty bits are presented, as well as an\nanalysis of area versus performance, and the key variables for hardware design\nin turbo decoding."
},{
    "category": "cs.AR", 
    "doi": "10.14445/22315381/IJETT-V10P235", 
    "link": "http://arxiv.org/pdf/1406.1886v1", 
    "title": "The Z1: Architecture and Algorithms of Konrad Zuse's First Computer", 
    "arxiv-id": "1406.1886v1", 
    "author": "Raul Rojas", 
    "publish": "2014-06-07T11:23:31Z", 
    "summary": "This paper provides the first comprehensive description of the Z1, the\nmechanical computer built by the German inventor Konrad Zuse in Berlin from\n1936 to 1938. The paper describes the main structural elements of the machine,\nthe high-level architecture, and the dataflow between components. The computer\ncould perform the four basic arithmetic operations using floating-point\nnumbers. Instructions were read from punched tape. A program consisted of a\nsequence of arithmetical operations, intermixed with memory store and load\ninstructions, interrupted possibly by input and output operations. Numbers were\nstored in a mechanical memory. The machine did not include conditional\nbranching in the instruction set. While the architecture of the Z1 is similar\nto the relay computer Zuse finished in 1941 (the Z3) there are some significant\ndifferences. The Z1 implements operations as sequences of microinstructions, as\nin the Z3, but does not use rotary switches as micro-steppers. The Z1 uses a\ndigital incrementer and a set of conditions which are translated into\nmicroinstructions for the exponent and mantissa units, as well as for the\nmemory blocks. Microinstructions select one out of 12 layers in a machine with\na 3D mechanical structure of binary mechanical elements. The exception circuits\nfor mantissa zero, necessary for normalized floating-point, were lacking; they\nwere first implemented in the Z3. The information for this article was\nextracted from careful study of the blueprints drawn by Zuse for the\nreconstruction of the Z1 for the German Technology Museum in Berlin, from some\nletters, and from sketches in notebooks. Although the machine has been in\nexhibition since 1989 (non-operational), no detailed high-level description of\nthe machine's architecture had been available. This paper fills that gap."
},{
    "category": "cs.AR", 
    "doi": "10.5120/11187-6411", 
    "link": "http://arxiv.org/pdf/1406.4628v1", 
    "title": "An Efficient Synchronous Static Memory design for Embedded System", 
    "arxiv-id": "1406.4628v1", 
    "author": "Manoj Kumar Jain", 
    "publish": "2014-06-18T07:50:50Z", 
    "summary": "Custom memory organization are challenging task in the area of VLSI design.\nThis study aims to design high speed and low power consumption memory for\nembedded system. Synchronous SRAM has been proposed and analyzed using various\nsimulators. Xilinx simulator simulates the Synchronous SRAM memories which can\nperform efficient read/write capability for embedded systems. Xinix tool also\nprovide the access time that required selecting a word and reading it.\nSynchronous Static RAM which has easily read /writes capability and performs\nscheduled read /writes operation in efficient manner."
},{
    "category": "cs.AR", 
    "doi": "10.5120/15782-4526", 
    "link": "http://arxiv.org/pdf/1406.5000v1", 
    "title": "Application Specific Cache Simulation Analysis for Application Specific   Instruction set Processor", 
    "arxiv-id": "1406.5000v1", 
    "author": "Manoj Kumar Jain", 
    "publish": "2014-06-19T10:40:23Z", 
    "summary": "An Efficient Simulation of application specific instruction-set processors\n(ASIP) is a challenging onus in the area of VLSI design. This paper\nreconnoiters the possibility of use of ASIP simulators for ASIP Simulation.\nThis proposed study allow as the simulation of the cache memory design with\nvarious ASIP simulators like Simple scalar and VEX. In this paper we have\nimplemented the memory configuration according to desire application. These\nsimulators performs the cache related results such as cache name, sets, cache\nassociativity, cache block size, cache replacement policy according to specific\napplication."
},{
    "category": "cs.AR", 
    "doi": "10.5120/15782-4526", 
    "link": "http://arxiv.org/pdf/1406.7662v1", 
    "title": "Selective Match-Line Energizer Content Addressable Memory(SMLE -CAM)", 
    "arxiv-id": "1406.7662v1", 
    "author": "Harish M Kittur", 
    "publish": "2014-06-30T10:46:50Z", 
    "summary": "A Content Addressable Memory (CAM) is a memory primarily designed for high\nspeed search operation. Parallel search scheme forms the basis of CAM, thus\npower reduction is the challenge associated with a large amount of parallel\nactive circuits. We are presenting a novel algorithm and architecture described\nas Selective Match-Line Energizer Content Addressable Memory (SMLE-CAM) which\nenergizes only those MLs (Match-Line) whose first three bits are conditionally\nmatched with corresponding first three search bit using special architecture\nwhich comprises of novel XNOR-CAM cell and novel XOR-CAM cell. The rest of the\nCAM chain is followed by NOR-CAM cell. The 256 X 144 bit SMLE-CAM is\nimplemented in TSMC 90 nm technology and its robustness across PVT variation is\nverified. The post-layout simulation result shows, it has energy metric of\n0.115 fJ/bit/search with search time 361.6 ps, the best reported so far. The\nmaximum operating frequency is 1GHz."
},{
    "category": "cs.AR", 
    "doi": "10.5120/15782-4526", 
    "link": "http://arxiv.org/pdf/1408.0982v1", 
    "title": "Modeling and simulation of multiprocessor systems MPSoC by SystemC/TLM2", 
    "arxiv-id": "1408.0982v1", 
    "author": "Mohamed Sadik", 
    "publish": "2014-08-05T14:19:21Z", 
    "summary": "The current manufacturing technology allows the integration of a complex\nmultiprocessor system on one piece of silicon (MPSoC for Multiprocessor\nSystem-on- Chip). One way to manage the growing complexity of these systems is\nto increase the level of abstraction and to address the system-level design. In\nthis paper, we focus on the implementation in SystemC language with TLM\n(Transaction Level Model) to model an MPSOC platform. Our main contribution is\nto define a comprehensive, fast and accurate method for designing and\nevaluating performance for MPSoC systems. The studied MPSoC is composed of\nMicroBlaze microprocessors, memory, a timer, a VGA and an interrupt handler\nwith two examples of software. This paper has two novel contributions: the\nfirst is to develop this MPSOC at CABA and TLM for ISS (Instruction Set\nSimulator), Native simulations and timed Programmer s View (PV+T); the second\nis to show that with PV+T simulations we can achieve timing fidelity with\nhigher speeds than CABA simulations and have almost the same precision."
},{
    "category": "cs.AR", 
    "doi": "10.5120/15782-4526", 
    "link": "http://arxiv.org/pdf/1408.5401v1", 
    "title": "A Many-Core Overlay for High-Performance Embedded Computing on FPGAs", 
    "arxiv-id": "1408.5401v1", 
    "author": "Hor\u00e1cio Neto", 
    "publish": "2014-08-21T11:57:16Z", 
    "summary": "In this work, we propose a configurable many-core overlay for\nhigh-performance embedded computing. The size of internal memory, supported\noperations and number of ports can be configured independently for each core of\nthe overlay. The overlay was evaluated with matrix multiplication, LU\ndecomposition and Fast-Fourier Transform (FFT) on a ZYNQ-7020 FPGA platform.\nThe results show that using a system-level many-core overlay avoids complex\nhardware design and still provides good performance results."
},{
    "category": "cs.AR", 
    "doi": "10.1109/JSSC.2014.2349994", 
    "link": "http://arxiv.org/pdf/1409.8018v1", 
    "title": "An ECG-on-Chip with 535-nW/Channel Integrated Lossless Data Compressor   for Wireless Sensors", 
    "arxiv-id": "1409.8018v1", 
    "author": "Y. Lian", 
    "publish": "2014-09-29T08:06:04Z", 
    "summary": "This paper presents a low-power ECG recording system-on-chip (SoC) with\non-chip low-complexity lossless ECG compression for data reduction in\nwireless/ambulatory ECG sensor devices. The chip uses a linear slope predictor\nfor data compression, and incorporates a novel low-complexity dynamic\ncoding-packaging scheme to frame the prediction error into fixed-length 16-bit\nformat. The proposed technique achieves an average compression ratio of 2.25x\non MIT/BIH ECG database. Implemented in a standard 0.35 um process, the\ncompressor uses 0.565K gates/channel occupying 0.4 mm2 for four channels, and\nconsumes 535 nW/channel at 2.4 V for ECG sampled at 512 Hz. Small size and\nultra-low power consumption makes the proposed technique suitable for wearable\nECG sensor applications."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DELTA.2010.43", 
    "link": "http://arxiv.org/pdf/1409.8020v1", 
    "title": "An ECG-on-Chip for Wearable Cardiac Monitoring Devices", 
    "arxiv-id": "1409.8020v1", 
    "author": "Y. Lian", 
    "publish": "2014-09-29T08:14:15Z", 
    "summary": "This paper describes a highly integrated, low power chip solution for ECG\nsignal processing in wearable devices. The chip contains an instrumentation\namplifier with programmable gain, a band-pass filter, a 12-bit SAR ADC, a novel\nQRS detector, 8K on-chip SRAM, and relevant control circuitry and CPU\ninterfaces. The analog front end circuits accurately senses and digitizes the\nraw ECG signal, which is then filtered to extract the QRS. The sampling\nfrequency used is 256 Hz. ECG samples are buffered locally on an asynchronous\nFIFO and is read out using a faster clock, as and when it is required by the\nhost CPU via an SPI interface. The chip was designed and implemented in 0.35um\nstandard CMOS process. The analog core operates at 1V while the digital\ncircuits and SRAM operate at 3.3V. The chip total core area is 5.74 mm^2 and\nconsumes 9.6uW. Small size and low power consumption make this design suitable\nfor usage in wearable heart monitoring devices."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DELTA.2010.43", 
    "link": "http://arxiv.org/pdf/1501.00579v1", 
    "title": "A Model Study of an All-Digital, Discrete-Time and Embedded Linear   Regulator", 
    "arxiv-id": "1501.00579v1", 
    "author": "Arijit Raychowdhury", 
    "publish": "2015-01-03T16:55:01Z", 
    "summary": "With an increasing number of power-states, finer- grained power management\nand larger dynamic ranges of digital circuits, the integration of compact,\nscalable linear-regulators embedded deep within logic blocks has become\nimportant. While analog linear-regulators have traditionally been used in\ndigital ICs, the need for digitally implementable designs that can be\nsynthesized and embedded in digital functional units for ultra fine- grained\npower management has emerged. This paper presents the circuit design and\ncontrol models of an all-digital, discrete-time linear regulator and explores\nthe parametric design space for transient response time and loop stability."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DELTA.2010.43", 
    "link": "http://arxiv.org/pdf/1501.04192v1", 
    "title": "Design of a Transport Triggered Architecture Processor for Flexible   Iterative Turbo Decoder", 
    "arxiv-id": "1501.04192v1", 
    "author": "Markku Juntti", 
    "publish": "2015-01-17T11:52:53Z", 
    "summary": "In order to meet the requirement of high data rates for the next generation\nwireless systems, the efficient implementation of receiver algorithms is\nessential. On the other hand, the rapid development of technology motivates the\ninvestigation of programmable implementations. This paper summarizes the design\nof a programmable turbo decoder as an applicationspecific instruction-set\nprocessor (ASIP) using Transport Triggered Architecture (TTA). The processor\narchitecture is designed in such manner that it can be programmed to support\nother receiver algorithms, for example, decoding based on the Viterbi\nalgorithm. Different suboptimal maximum a posteriori (MAP) algorithms are used\nand compared to one another for the softinput soft-output (SISO) component\ndecoders in a single TTA processor. The max-log-MAP algorithm outperforms the\nother suboptimal algorithms in terms of latency. The design enables the\ndesigner to change the suboptimal algorithms according to the bit error rate\n(BER) performance requirement. Unlike many other programmable turbo decoder\nimplementations, quadratic polynomial permutation (QPP) interleaver is used in\nthis work for contention-free memory access and to make the processor 3GPP LTE\ncompliant. Several optimization techniques to enable real time processing on\nprogrammable platforms are introduced. Using our method, with a single\niteration 31.32 Mbps throughput is achieved for the max-log-MAP algorithm for a\nclock frequency of 200 MHz."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DELTA.2010.43", 
    "link": "http://arxiv.org/pdf/1501.07420v1", 
    "title": "Tejas Simulator : Validation against Hardware", 
    "arxiv-id": "1501.07420v1", 
    "author": "Seep Goel", 
    "publish": "2015-01-29T11:44:47Z", 
    "summary": "In this report we show results that validate the Tejas architectural\nsimulator against native hardware. We report mean error rates of 11.45% and\n18.77% for the SPEC2006 and Splash2 benchmark suites respectively. These error\nrates are competitive and in most cases better than the numbers reported by\nother contemporary simulators."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICM.2009.5418636", 
    "link": "http://arxiv.org/pdf/1007.4465v1", 
    "title": "FPGA Implementation of a Reconfigurable Viterbi Decoder for WiMAX   Receiver", 
    "arxiv-id": "1007.4465v1", 
    "author": "Khaled Ali Shehata", 
    "publish": "2010-07-26T14:06:59Z", 
    "summary": "Field Programmable Gate Array technology (FPGA) is a highly configurable\noption for implementing many sophisticated signal processing tasks in Software\nDefined Radios (SDRs). Those types of radios are realized using highly\nconfigurable hardware platforms. Convolutional codes are used in every robust\ndigital communication system and Viterbi algorithm is employed in wireless\ncommunications to decode the convolutional codes. Such decoders are complex and\ndissipate large amount of power. In this paper, a low power-reconfigurable\nViterbi decoder for WiMAX receiver is described using a VHDL code for FPGA\nimplementation. The proposed design is implemented on Xilinx Virtex-II Pro,\nXC2vpx30 FPGA using the FPGA Advantage Pro package provided by Mentor Graphics\nand ISE 10.1 by Xilinx."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICM.2009.5418636", 
    "link": "http://arxiv.org/pdf/1104.0298v1", 
    "title": "High Speed Multiple Valued Logic Full Adder Using Carbon Nano Tube Field   Effect Transistor", 
    "arxiv-id": "1104.0298v1", 
    "author": "Iman Mahmoudi", 
    "publish": "2011-04-02T07:14:38Z", 
    "summary": "High speed Full-Adder (FA) module is a critical element in designing high\nperformance arithmetic circuits. In this paper, we propose a new high speed\nmultiple-valued logic FA module. The proposed FA is constructed by 14\ntransistors and 3 capacitors, using carbon nano-tube field effect transistor\n(CNFET) technology. Furthermore, our proposed technique has been examined in\ndifferent voltages (i.e., 0.65v and 0.9v). The observed results reveal power\nconsumption and power delay product (PDP) improvements compared to existing FA\ncounterparts"
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICM.2009.5418636", 
    "link": "http://arxiv.org/pdf/1104.3310v1", 
    "title": "Computer Arithmetic Preserving Hamming Distance of Operands in Operation   Result", 
    "arxiv-id": "1104.3310v1", 
    "author": "Dan Tamir", 
    "publish": "2011-04-17T12:15:42Z", 
    "summary": "The traditional approach to fault tolerant computing involves replicating\ncomputation units and applying a majority vote operation on individual result\nbits. This approach, however, has several limitations; the most severe is the\nresource requirement. This paper presents a new method for fault tolerant\ncomputing where for a given error rate, the hamming distance between correct\ninputs and faulty inputs as well as the hamming distance between a correct\nresult and a faulty result is preserved throughout processing thereby enabling\ncorrection of up to transient faults per computation cycle. The new method is\ncompared and contrasted with current protection methods and its cost /\nperformance is analyzed."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijait.2011.1403", 
    "link": "http://arxiv.org/pdf/1109.0708v1", 
    "title": "A Novel Methodology for Thermal Analysis & 3-Dimensional Memory   Integration", 
    "arxiv-id": "1109.0708v1", 
    "author": "Vinod Pangracious", 
    "publish": "2011-09-04T12:28:46Z", 
    "summary": "The semiconductor industry is reaching a fascinating confluence in several\nevolutionary trends that will likely lead to a number of revolutionary changes\nin the design, implementation, scaling, and the use of computer systems.\nHowever, recently Moore's law has come to a stand-still since device scaling\nbeyond 65 nm is not practical. 2D integration has problems like memory latency,\npower dissipation, and large foot-print. 3D technology comes as a solution to\nthe problems posed by 2D integration. The utilization of 3D is limited by the\nproblem of temperature crisis. It is important to develop an accurate power\nprofile extraction methodology to design 3D structure. In this paper, design of\n3D integration of memory is considered and hence the static power dissipation\nof the memory cell is analysed in transistor level and is used to accurately\nmodel the inter-layer thermal effects for 3D memory stack. Subsequently,\npackaging of the chip is considered and modelled using an architecture level\nsimulator. This modelling is intended to analyse the thermal effects of 3D\nmemory, its reliability and lifetime of the chip, with greater accuracy."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijait.2011.1403", 
    "link": "http://arxiv.org/pdf/1109.0752v1", 
    "title": "An improved distributed routing algorithm for Benes based optical NoC", 
    "arxiv-id": "1109.0752v1", 
    "author": "Yintang Yang", 
    "publish": "2011-09-04T20:02:53Z", 
    "summary": "Integrated optical interconnect is believed to be one of the main\ntechnologies to replace electrical wires. Optical Network-on-Chip (ONoC) has\nattracted more attentions nowadays. Benes topology is a good choice for ONoC\nfor its rearrangeable non-blocking character, multistage feature and easy\nscalability. Routing algorithm plays an important role in determining the\nperformance of ONoC. But traditional routing algorithms for Benes network are\nnot suitable for ONoC communication, we developed a new distributed routing\nalgorithm for Benes ONoC in this paper. Our algorithm selected the routing path\ndynamically according to network condition and enables more path choices for\nthe message traveling in the network. We used OPNET to evaluate the performance\nof our routing algorithm and also compared it with a well-known bit-controlled\nrouting algorithm. ETE delay and throughput were showed under different packet\nlength and network sizes. Simulation results show that our routing algorithm\ncan provide better performance for ONoC."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijait.2011.1403", 
    "link": "http://arxiv.org/pdf/1109.0755v1", 
    "title": "Intelligent Bees for QoS Routing in Networks-on-Chip", 
    "arxiv-id": "1109.0755v1", 
    "author": "Huaxi Gu", 
    "publish": "2011-09-04T20:46:08Z", 
    "summary": "Networks-on-Chip (NoCs) for future many-core processor platforms integrate\nmore and more heterogeneous components of different types and many real-time\nand latency-sensitive applications can run on a single chip concurrently. The\nreconfigurable FPGA and reconfigurable NoCs have emerged for the purpose of\nreusability. Those types' traffics within NoCs exhibit diverse, burst, and\nunpredictable communication patterns. QoS guaranteed mechanisms are necessary\nto provide guaranteed throughput (GT) or guaranteed bandwidth (GB) performance\nfor NoCs. In this paper, we propose a QoS routing algorithm inspired by bees'\nforaging behaviors to provide guaranteed bandwidth performance. Virtual\ncircuits and Spatial Division Multiplexing are employed to maintain available\npaths for different type's traffics."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijait.2011.1403", 
    "link": "http://arxiv.org/pdf/1204.1179v1", 
    "title": "C-slow Technique vs Multiprocessor in designing Low Area Customized   Instruction set Processor for Embedded Applications", 
    "arxiv-id": "1204.1179v1", 
    "author": "Muhammad Masood Sarfaraz", 
    "publish": "2012-04-05T10:59:03Z", 
    "summary": "The demand for high performance embedded processors, for consumer\nelectronics, is rapidly increasing for the past few years. Many of these\nembedded processors depend upon custom built Instruction Ser Architecture (ISA)\nsuch as game processor (GPU), multimedia processors, DSP processors etc.\nPrimary requirement for consumer electronic industry is low cost with high\nperformance and low power consumption. A lot of research has been evolved to\nenhance the performance of embedded processors through parallel computing. But\nsome of them focus superscalar processors i.e. single processors with more\nresources like Instruction Level Parallelism (ILP) which includes Very Long\nInstruction Word (VLIW) architecture, custom instruction set extensible\nprocessor architecture and others require more number of processing units on a\nsingle chip like Thread Level Parallelism (TLP) that includes Simultaneous\nMultithreading (SMT), Chip Multithreading (CMT) and Chip Multiprocessing (CMP).\nIn this paper, we present a new technique, named C-slow, to enhance performance\nfor embedded processors for consumer electronics by exploiting multithreading\ntechnique in single core processors. Without resulting into the complexity of\nmicro controlling with Real Time Operating system (RTOS), C-slowed processor\ncan execute multiple threads in parallel using single datapath of Instruction\nSet processing element. This technique takes low area & approach complexity of\ngeneral purpose processor running RTOS."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijait.2011.1403", 
    "link": "http://arxiv.org/pdf/1204.2809v1", 
    "title": "Performance-Optimum Superscalar Architecture for Embedded Applications", 
    "arxiv-id": "1204.2809v1", 
    "author": "Mostafa E. Salehi", 
    "publish": "2012-04-12T18:40:55Z", 
    "summary": "Embedded applications are widely used in portable devices such as wireless\nphones, personal digital assistants, laptops, etc. High throughput and real\ntime requirements are especially important in such data-intensive tasks.\nTherefore, architectures that provide the required performance are the most\ndesirable. On the other hand, processor performance is severely related to the\naverage memory access delay, number of processor registers and also size of the\ninstruction window and superscalar parameters. Therefore, cache, register file\nand superscalar parameters are the major architectural concerns in designing a\nsuperscalar architecture for embedded processors. Although increasing cache and\nregister file size leads to performance improvements in high performance\nembedded processors, the increased area, power consumption and memory delay are\nthe overheads of these techniques. This paper explores the effect of cache,\nregister file and superscalar parameters on the processor performance to\nspecify the optimum size of these parameters for embedded applications.\nExperimental results show that although having bigger size of these parameters\nis one of the performance improvement approaches in embedded processors,\nhowever, by increasing the size of some parameters over a threshold value,\nperformance improvement is saturated and especially in cache size, increments\nover this threshold value decrease the performance."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijait.2011.1403", 
    "link": "http://arxiv.org/pdf/1204.5407v1", 
    "title": "Reversible Programmable Logic Array (RPLA) using Feynman & MUX Gates for   Low Power Industrial Applications", 
    "arxiv-id": "1204.5407v1", 
    "author": "Naveen Kr. Malik", 
    "publish": "2012-04-24T15:28:25Z", 
    "summary": "This paper present the research work directed towards the design of\nreversible programmable logic array using very high speed integrated circuit\nhardware description language (VHDL). Reversible logic circuits have\nsignificant importance in bioinformatics, optical information processing, CMOS\ndesign etc. In this paper the authors propose the design of new RPLA using\nFeynman & MUX gate.VHDL based codes of reversible gates with simulating results\nare shown .This proposed RPLA may be further used to design any reversible\nlogic function or Boolean function (Adder, subtractor etc.) which dissipate\nvery low or ideally no heat."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijait.2011.1403", 
    "link": "http://arxiv.org/pdf/1207.1187v1", 
    "title": "Dynamic Priority Queue: An SDRAM Arbiter With Bounded Access Latencies   for Tight WCET Calculation", 
    "arxiv-id": "1207.1187v1", 
    "author": "Alois Knoll", 
    "publish": "2012-07-05T08:20:02Z", 
    "summary": "This report introduces a shared resource arbitration scheme \"DPQ - Dynamic\nPriority Queue\" which provides bandwidth guarantees and low worst case latency\nto each master in an MPSoC. Being a non-trivial candidate for timing analysis,\nSDRAM has been chosen as a showcase, but the approach is valid for any shared\nresource arbitration.\n  Due to its significant cost, data rate and physical size advantages, SDRAM is\na potential candidate for cost sensitive, safety critical and space conserving\nsystems. The variable access latency is a major drawback of SDRAM that induces\nlargely over estimated Worst Case Execution Time (WCET) bounds of applications.\nIn this report we present the DPQ together with an algorithm to predict the\nshared SDRAM's worst case latencies. We use the approach to calculate WCET\nbounds of six hardware tasks executing on an Altera Cyclone III FPGA with\nshared DDR2 memory. The results show that the DPQ is a fair arbitration scheme\nand produces low WCET bounds."
},{
    "category": "cs.AR", 
    "doi": "10.5120/7452-0633", 
    "link": "http://arxiv.org/pdf/1207.1683v1", 
    "title": "Design and Development of Low Cost Multi-Channel USB Data", 
    "arxiv-id": "1207.1683v1", 
    "author": "Nungleppam Gopil Singh", 
    "publish": "2012-07-06T16:52:24Z", 
    "summary": "This paper describes the design and development of low cost USB Data\nAcquisition System (DAS) for the measurement of physical parameters. Physical\nparameters such as temperature, humidity, light intensity etc., which are\ngenerally slowly varying signals are sensed by respective sensors or integrated\nsensors and converted into voltages. The DAS is designed using PIC18F4550\nmicrocontroller, communicating with Personal Computer (PC) through USB\n(Universal Serial Bus). The designed DAS has been tested with the application\nprogram developed in Visual Basic, which allows online monitoring in graphical\nas well as numerical display."
},{
    "category": "cs.AR", 
    "doi": "10.5120/7452-0633", 
    "link": "http://arxiv.org/pdf/1207.2060v1", 
    "title": "Design of PIC12F675 Microcontroller Based Data Acquisition System for   Slowly Varying Signals", 
    "arxiv-id": "1207.2060v1", 
    "author": "K. C. Sarma", 
    "publish": "2012-07-09T14:25:51Z", 
    "summary": "The present paper describes the design of a cost effective, better resolution\ndata acquisition system (DAS) which is compatible to most of the PC and\nlaptops. A low cost DAS has been designed using PIC12F675 having 4-channel\nanalog input with 10-bit resolution for the monitoring of slowly varying\nsignals. The DAS so designed is interfaced to the serial port of the PC.\nFirmware is written in Basic using Oshonsoft PIC IDE and burn to the\nmicrocontroller by using PICkit2 programmer. An application program is also\ndeveloped using Visual Basic 6 which allows to display the waveform of the\nsignal(s) and simultaneously the data also can be saved into the hard disk of\nthe computer for future use and analysis."
},{
    "category": "cs.AR", 
    "doi": "10.5120/7452-0633", 
    "link": "http://arxiv.org/pdf/1207.2739v1", 
    "title": "Low Cost PC Based Real Time Data Logging System Using PCs Parallel Port   For Slowly Varying Signals", 
    "arxiv-id": "1207.2739v1", 
    "author": "K. C. Sarma", 
    "publish": "2012-07-11T18:29:21Z", 
    "summary": "A low cost PC based real time data logging system can be used in the\nlaboratories for the measurement, monitoring and storage of the data for slowly\nvarying signals in science and engineering stream. This can be designed and\ninterfaced to the PCs Parallel Port, which is common to all desktop computers\nor Personal Computers (PCs). By the use of this data logging system one can\nmonitor, measure and store data for slowly varying signals, which is hard to\nvisualise the signal waveforms by ordinary CRO (Cathode Ray Oscilloscope) and\nDSO (Digital Storage Oscilloscope). The data so stored can be used for further\nstudy and analysis. It can be used for a wide range of applications to monitor\nand store data of temperature, humidity, light intensity, ECG signals etc. with\nproper signal conditioning circuitry."
},{
    "category": "cs.AR", 
    "doi": "10.5120/7452-0633", 
    "link": "http://arxiv.org/pdf/1207.2840v1", 
    "title": "Design and Performance Analysis of hybrid adders for high speed   arithmetic circuit", 
    "arxiv-id": "1207.2840v1", 
    "author": "Veerati Raju", 
    "publish": "2012-07-12T03:57:37Z", 
    "summary": "Adder cells using Gate Diffusion Technique (GDI) & PTL-GDI technique are\ndescribed in this paper. GDI technique allows reducing power consumption,\npropagation delay and low PDP (power delay product) whereas Pass Transistor\nLogic (PTL) reduces the count of transistors used to make different logic\ngates, by eliminating redundant transistors. Performance comparison with\nvarious Hybrid Adder is been presented. In this paper, we propose two new\ndesigns based on GDI & PTL techniques, which is found to be much more power\nefficient in comparison with existing design technique. Only 10 transistors are\nused to implement the SUM & CARRY function for both the designs. The SUM and\nCARRY cell are implemented in a cascaded way i.e. firstly the XOR cell is\nimplemented and then using XOR as input SUM as well as CARRY cell is\nimplemented. For Proposed GDI adder the SUM as well as CARRY cell is designed\nusing GDI technique. On the other hand in Proposed PTL-GDI adder the SUM cell\nis constructed using PTL technique and the CARRY cell is designed using GDI\ntechnique. The advantages of both the designs are discussed. The significance\nof these designs is substantiated by the simulation results obtained from\nCadence Virtuoso 180nm environment."
},{
    "category": "cs.AR", 
    "doi": "10.1007/s11390-014-1428-7", 
    "link": "http://arxiv.org/pdf/1301.0051v1", 
    "title": "MIMS: Towards a Message Interface based Memory System", 
    "arxiv-id": "1301.0051v1", 
    "author": "Yungang Bao", 
    "publish": "2013-01-01T03:19:24Z", 
    "summary": "Memory system is often the main bottleneck in chipmultiprocessor (CMP)\nsystems in terms of latency, bandwidth and efficiency, and recently\nadditionally facing capacity and power problems in an era of big data. A lot of\nresearch works have been done to address part of these problems, such as\nphotonics technology for bandwidth, 3D stacking for capacity, and NVM for power\nas well as many micro-architecture level innovations. Many of them need a\nmodification of current memory architecture, since the decades-old synchronous\nmemory architecture (SDRAM) has become an obstacle to adopt those advances.\nHowever, to the best of our knowledge, none of them is able to provide a\nuniversal memory interface that is scalable enough to cover all these problems.\n  In this paper, we argue that a message-based interface should be adopted to\nreplace the traditional bus-based interface in memory system. A novel message\ninterface based memory system (MIMS) is proposed. The key innovation of MIMS is\nthat processor and memory system communicate through a universal and flexible\nmessage interface. Each message packet could contain multiple memory requests\nor commands along with various semantic information. The memory system is more\nintelligent and active by equipping with a local buffer scheduler, which is\nresponsible to process packet, schedule memory requests, and execute specific\ncommands with the help of semantic information. The experimental results by\nsimulator show that, with accurate granularity message, the MIMS would improve\nperformance by 53.21%, while reducing energy delay product (EDP) by 55.90%, the\neffective bandwidth utilization is improving by 62.42%. Furthermore, combining\nmultiple requests in a packet would reduce link overhead and provide\nopportunity for address compression."
},{
    "category": "cs.AR", 
    "doi": "10.1007/s11390-014-1428-7", 
    "link": "http://arxiv.org/pdf/1301.1465v2", 
    "title": "A joint communication and application simulator for NoC-based SoCs", 
    "arxiv-id": "1301.1465v2", 
    "author": "Guido Masera", 
    "publish": "2013-01-08T09:59:28Z", 
    "summary": "NoCs have become a widespread paradigm in the system-on-chip design world,\nnot only for multi-purpose SoCs, but also for application-specific ICs. The\ncommon approach in the NoC design world is to separate the design of the\ninterconnection from the design of the processing elements: this is well suited\nfor a large number of developments, but the need for joint application and NoC\ndesign is not uncommon, especially in the application specific case. The\ncorrelation between processing and communication tasks can be strong, and\nseparate or trace-based simulations fall often short of the desired precision.\nIn this work, the OMNET++ based JANoCS simulator is presented: concurrent\nsimulation of processing and communication allow cycle-accurate evaluation of\nthe system. Two cases of study are presented, showing both the need for joint\nsimulations and the effectiveness of JANoCS."
},{
    "category": "cs.AR", 
    "doi": "10.5121/cseij.2012.2601", 
    "link": "http://arxiv.org/pdf/1301.3281v1", 
    "title": "Reconfiguration Strategies for Online Hardware Multitasking in Embedded   Systems", 
    "arxiv-id": "1301.3281v1", 
    "author": "Sara Roman", 
    "publish": "2013-01-15T09:51:33Z", 
    "summary": "An intensive use of reconfigurable hardware is expected in future embedded\nsystems. This means that the system has to decide which tasks are more suitable\nfor hardware execution. In order to make an efficient use of the FPGA it is\nconvenient to choose one that allows hardware multitasking, which is\nimplemented by using partial dynamic reconfiguration. One of the challenges for\nhardware multitasking in embedded systems is the online management of the only\nreconfiguration port of present FPGA devices. This paper presents different\nonline reconfiguration scheduling strategies which assign the reconfiguration\ninterface resource using different criteria: workload distribution or task\ndeadline. The online scheduling strategies presented take efficient and fast\ndecisions based on the information available at each moment. Experiments have\nbeen made in order to analyze the performance and convenience of these\nreconfiguration strategies."
},{
    "category": "cs.AR", 
    "doi": "10.5121/cseij.2012.2601", 
    "link": "http://arxiv.org/pdf/1304.0835v1", 
    "title": "Improved Analytical Delay Models for RC-Coupled Interconnects", 
    "arxiv-id": "1304.0835v1", 
    "author": "Zhiyuan Yan", 
    "publish": "2013-04-03T03:52:52Z", 
    "summary": "As the process technologies scale into deep submicron region, crosstalk delay\nis becoming increasingly severe, especially for global on-chip buses. To cope\nwith this problem, accurate delay models of coupled interconnects are needed.\nIn particular, delay models based on analytical approaches are desirable,\nbecause they not only are largely transparent to technology, but also\nexplicitly establish the connections between delays of coupled interconnects\nand transition patterns, thereby enabling crosstalk alleviating techniques such\nas crosstalk avoidance codes (CACs). Unfortunately, existing analytical delay\nmodels, such as the widely cited model in [1], have limited accuracy and do not\naccount for loading capacitance. In this paper, we propose analytical delay\nmodels for coupled interconnects that address these disadvantages. By\naccounting for more wires and eschewing the Elmore delay, our delay models\nachieve better accuracy than the model in [1]."
},{
    "category": "cs.AR", 
    "doi": "10.5121/cseij.2012.2601", 
    "link": "http://arxiv.org/pdf/1304.5081v1", 
    "title": "Open Tiled Manycore System-on-Chip", 
    "arxiv-id": "1304.5081v1", 
    "author": "Andreas Herkersdorf", 
    "publish": "2013-04-18T11:00:50Z", 
    "summary": "Manycore System-on-Chip include an increasing amount of processing elements\nand have become an important research topic for improvements of both hardware\nand software. While research can be conducted using system simulators,\nprototyping requires a variety of components and is very time consuming. With\nthe Open Tiled Manycore System-on-Chip (OpTiMSoC) we aim at building such an\nenvironment for use in our and other research projects as prototyping platform.\n  This paper describes the project goals and aspects of OpTiMSoC and summarizes\nthe current status and ideas."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcseit.2013.3201", 
    "link": "http://arxiv.org/pdf/1305.3038v1", 
    "title": "Phase-Priority based Directory Coherence for Multicore Processor", 
    "arxiv-id": "1305.3038v1", 
    "author": "Hong An", 
    "publish": "2013-05-14T06:56:10Z", 
    "summary": "As the number of cores in a single chip increases, a typical implementation\nof coherence protocol adds significant hardware and complexity overhead.\nBesides, the performance of CMP system depends on the data access latency,\nwhich is highly affected by coherence protocol and on-chip interconnect. In\nthis paper, we propose PPB (Phase-Priority Based) cache coherence protocol, an\noptimization of modern directory coherence protocol. We take advantage of the\nobservation that transient states occur in directory coherence protocol,\nresulting in some unnecessary transient states and stalling. PPB cache\ncoherence protocol decouples a coherence transaction and introduces the idea of\nphase message. This phase is considered as the priority of the message.\nAdditionally, we also add new priority-based arbitrators in on-chip network to\nsupport PPB cache coherence protocol. This mechanism in on-chip network can\nsupport effective cache access, which makes the on-chip network more efficient.\nOur analysis on an execution-driven full system simulator using SPLASH-2\nbenchmark shows that PPB cache coherence outperforms a MESI based directory,\nand the number of unnecessary transient states and stalling reduces up to 24%.\nAlso it reported the speedup of 7.4%. Other advantages of this strategy are\nreduced delay of flits and significantly less energy consumption in on-chip\nnetwork."
},{
    "category": "cs.AR", 
    "doi": "10.1145/2490302.2490304", 
    "link": "http://arxiv.org/pdf/1306.0089v1", 
    "title": "A Novel Reconfigurable Architecture of a DSP Processor for Efficient   Mapping of DSP Functions using Field Programmable DSP Arrays", 
    "arxiv-id": "1306.0089v1", 
    "author": "Suranjan Chakraborty", 
    "publish": "2013-06-01T09:04:40Z", 
    "summary": "Development of modern integrated circuit technologies makes it feasible to\ndevelop cheaper, faster and smaller special purpose signal processing function\ncircuits. Digital Signal processing functions are generally implemented either\non ASICs with inflexibility, or on FPGAs with bottlenecks of relatively smaller\nutilization factor or lower speed compared to ASIC. Field Programmable DSP\nArray (FPDA) is the proposed DSP dedicated device, redolent to FPGA, but with\nbasic fixed common modules (CMs) (like adders, subtractors, multipliers,\nscaling units, shifters) instead of CLBs. This paper introduces the development\nof reconfigurable system architecture with a focus on FPDA that integrates\ndifferent DSP functions like DFT, FFT, DCT, FIR, IIR, and DWT etc. The\nswitching between DSP functions is occurred by reconfiguring the\ninterconnection between CMs. Validation of the proposed architecture has been\nachieved on Virtex5 FPGA. The architecture provides sufficient amount of\nflexibility, parallelism and scalability."
},{
    "category": "cs.AR", 
    "doi": "10.1145/2490302.2490304", 
    "link": "http://arxiv.org/pdf/1306.1889v1", 
    "title": "An Improved Structure Of Reversible Adder And Subtractor", 
    "arxiv-id": "1306.1889v1", 
    "author": "Nitin Maheshwari", 
    "publish": "2013-06-08T07:21:22Z", 
    "summary": "In today's world everyday a new technology which is faster, smaller and more\ncomplex than its predecessor is being developed. The increased number of\ntransistors packed onto a chip of a conventional system results in increased\npower consumption that is why Reversible logic has drawn attention of\nResearchers due to its less heat dissipating characteristics. Reversible logic\ncan be imposed over applications such as quantum computing, optical computing,\nquantum dot cellular automata, low power VLSI circuits, DNA computing. This\npaper presents the reversible combinational circuit of adder, subtractor and\nparity preserving subtractor. The suggested circuit in this paper are designed\nusing Feynman, Double Feynman and MUX gates which are better than the existing\none in literature in terms of Quantum cost, Garbage output and Total logical\ncalculations."
},{
    "category": "cs.AR", 
    "doi": "10.1145/2490302.2490304", 
    "link": "http://arxiv.org/pdf/1306.3109v2", 
    "title": "Computer Architecture with Associative Processor Replacing Last Level   Cache and SIMD Accelerator", 
    "arxiv-id": "1306.3109v2", 
    "author": "Ran Ginosar", 
    "publish": "2013-06-13T14:02:13Z", 
    "summary": "This study presents a novel computer architecture where a last level cache\nand a SIMD accelerator are replaced by an Associative Processor. Associative\nProcessor combines data storage and data processing and provides parallel\ncomputational capabilities and data memory at the same time. An analytic\nperformance model of the new computer architecture is introduced. Comparative\nanalysis supported by simulation shows that this novel architecture may\noutperform a conventional architecture comprising a SIMD coprocessor and a\nshared last level cache while consuming less power."
},{
    "category": "cs.AR", 
    "doi": "10.1145/2490302.2490304", 
    "link": "http://arxiv.org/pdf/1306.5501v1", 
    "title": "A Wrapper of PCI Express with FIFO Interfaces based on FPGA", 
    "arxiv-id": "1306.5501v1", 
    "author": "Hefei Hu", 
    "publish": "2013-06-24T02:50:32Z", 
    "summary": "This paper proposes a PCI Express (PCIE) Wrapper core named PWrapper with\nFIFO interfaces. Compared with other PCIE solutions, PWrapper has several\nadvantages such as flexibility, isolation of clock domain, etc. PWrapper is\nimplemented and verified on Vertex -5-FX70T which is a development board\nprovided by Xilinx Inc. Architecture of PWrapper and design of two key modules\nare illustrated, which timing optimization methods have been adopted. Then we\nexplained the advantages and challenges of on-chip interfaces technology based\non FIFOs. The verification results show that PWrapper can achieve the speed of\n1.8Gbps (Giga bits per second)."
},{
    "category": "cs.AR", 
    "doi": "10.1145/2490302.2490304", 
    "link": "http://arxiv.org/pdf/1307.3324v1", 
    "title": "Power efficient carry propagate adder", 
    "arxiv-id": "1307.3324v1", 
    "author": "Ganga Agnihotri", 
    "publish": "2013-07-12T04:57:14Z", 
    "summary": "Here we describe the design details and performance of proposed Carry\nPropagate Adder based on GDI technique. GDI technique is power efficient\ntechnique for designing digital circuit that consumes less power as compare to\nmost commonly used CMOS technique. GDI also has an advantage of minimum\npropagation delay, minimum area required and less complexity for designing any\ndigital circuit. We designed Carry Propagate Adder using GDI technique and\ncompared its performance with CMOS technique in terms of area, delay and power\ndissipation. Circuit designed using CADENCE EDA tool and simulated using\nSPECTRE VIRTUOSO tool at 0.18m technology. Comparative performance result shows\nthat Carry Propagate Adder using GDI technique dissipated 55.6% less power as\ncompare to Carry Propagate Adder using CMOS technique."
},{
    "category": "cs.AR", 
    "doi": "10.1145/2490302.2490304", 
    "link": "http://arxiv.org/pdf/1307.3853v1", 
    "title": "Thermal analysis of 3D associative processor", 
    "arxiv-id": "1307.3853v1", 
    "author": "Ran Ginosar", 
    "publish": "2013-07-15T08:44:19Z", 
    "summary": "Thermal density and hot spots limit three-dimensional (3D) implementation of\nmassively-parallel SIMD processors and prohibit stacking DRAM dies above them.\nThis study proposes replacing SIMD by an Associative Processor (AP). AP\nexhibits close to uniform thermal distribution with reduced hot spots.\nAdditionally, AP may outperform SIMD processor when the data set size is\nsufficiently large, while dissipating less power. Comparative performance and\nthermal analysis supported by simulation confirm that AP might be preferable\nover SIMD for 3D implementation of large scale massively parallel processing\nengines combined with 3D DRAM integration."
},{
    "category": "cs.AR", 
    "doi": "10.1145/2490302.2490304", 
    "link": "http://arxiv.org/pdf/1307.6406v1", 
    "title": "Relative Performance of a Multi-level Cache with Last-Level Cache   Replacement: An Analytic Review", 
    "arxiv-id": "1307.6406v1", 
    "author": "Bijay Paikaray", 
    "publish": "2013-07-24T13:09:43Z", 
    "summary": "Current day processors employ multi-level cache hierarchy with one or two\nlevels of private caches and a shared last-level cache (LLC). An efficient\ncache replacement policy at LLC is essential for reducing the off-chip memory\ntransfer as well as conflict for memory bandwidth. Cache replacement techniques\nfor inclusive LLCs may not be efficient for multilevel cache as it can be\nshared by enormous applications with varying access behavior, running\nsimultaneously. One application may dominate another by flooding of cache\nrequests and evicting the useful data of the other application. From the\nperformance point of view, an exclusive LLC make the replacement policies more\ndemanding, as compared to an inclusive LLC. This paper analyzes some of the\nexisting replacement techniques on the LLC with their performance assessment."
},{
    "category": "cs.AR", 
    "doi": "10.1109/MWSCAS.2012.6292184", 
    "link": "http://arxiv.org/pdf/1307.8319v1", 
    "title": "Allocating the chains of consecutive additions for optimal fixed-point   data path synthesis", 
    "arxiv-id": "1307.8319v1", 
    "author": "Gregory W. Donohoe", 
    "publish": "2013-07-31T13:40:40Z", 
    "summary": "Minimization of computational errors in the fixed-point data path is often\ndifficult task. Many signal processing algorithms use chains of consecutive\nadditions. The analyzing technique that can be applied to fixed-point data path\nsynthesis has been proposed. This technique takes advantage of allocating the\nchains of consecutive additions in order to predict growing width of the data\npath and minimize the design complexity and computational errors."
},{
    "category": "cs.AR", 
    "doi": "10.1109/MWSCAS.2012.6292184", 
    "link": "http://arxiv.org/pdf/1307.8401v1", 
    "title": "FpSynt: a fixed-point datapath synthesis tool for embedded systems", 
    "arxiv-id": "1307.8401v1", 
    "author": "Gregory W. Donohoe", 
    "publish": "2013-07-31T17:45:54Z", 
    "summary": "Digital mobile systems must function with low power, small size and weight,\nand low cost. High-performance desktop microprocessors, with built-in floating\npoint hardware, are not suitable in these cases. For embedded systems, it can\nbe advantageous to implement these calculations with fixed point arithmetic\ninstead. We present an automated fixed-point data path synthesis tool FpSynt\nfor designing embedded applications in fixed-point domain with sufficient\naccuracy for most applications. FpSynt is available under the GNU General\nPublic License from the following GitHub repository:\nhttp://github.com/izhbannikov/FPSYNT"
},{
    "category": "cs.AR", 
    "doi": "10.1109/MWSCAS.2012.6292184", 
    "link": "http://arxiv.org/pdf/1310.0100v1", 
    "title": "Technical report: Functional Constraint Extraction From Register   Transfer Level for ATPG", 
    "arxiv-id": "1310.0100v1", 
    "author": "Jean-Fran\u00e7ois Boland", 
    "publish": "2013-10-01T00:06:15Z", 
    "summary": "We proposed in \"Functional Constraint Extraction From Register Transfer Level\nfor ATPG\" that is currently submitted to TVLSI, an automatic functional\nconstraint extractor that can be applied on the RT level. These functional\nconstraints are used to generate pseudo functional test patterns with ATPG\ntools. The patterns are then used to improve the verification process. This\ntechnical report complements the work proposed as it contains the\nimplementation details of the proposed methodology and shows the detailed\nintermediate and final results of the application of this methodology on a\nconcrete example."
},{
    "category": "cs.AR", 
    "doi": "10.1109/MWSCAS.2012.6292184", 
    "link": "http://arxiv.org/pdf/1310.3356v1", 
    "title": "A Novel Reconfigurable Computing Architecture for Image Signal   Processing Using Circuit-Switched NoC and Synchronous Dataflow Model", 
    "arxiv-id": "1310.3356v1", 
    "author": "Huazhong Yang", 
    "publish": "2013-10-12T10:05:07Z", 
    "summary": "In this paper, a novel reconfigurable architecture is proposed for\nmultifunctional image signal processing systems. A circuit-switched NoC is used\nto provide interconnection because the non-TMD links ensure fixed throughput,\nwhich is a desirable behavior for computational intensive image processing\nalgorithms compared with packet-switched NoC. Image processing algorithms are\nmodeled as synchronous dataflow graphs which provide a unified model for\ngeneral computing procedure. An image processing system is considered as\nseveral temporally mutually exclusive algorithms. Thus, their dataflow graph\nrepresentations could be considered as a group and a merging algorithm could be\napplied to generate a union graph while eliminating spatial redundancy for area\nconsumption optimization. After the union graph have been mapped and routed on\nthe NoC, the reconfigurable system could be configured to any of its target\nimage processing algorithms by properly setting the NoC topology. Experiments\nshow the demo reconfigurable system with two image processing applications cost\n26.4% less hardware resource, compared with the non-reconfigurable\nimplementations."
},{
    "category": "cs.AR", 
    "doi": "10.1109/MWSCAS.2012.6292184", 
    "link": "http://arxiv.org/pdf/1310.4231v1", 
    "title": "Dynamic cache reconfiguration based techniques for improving cache   energy efficiency", 
    "arxiv-id": "1310.4231v1", 
    "author": "Sparsh Mittal", 
    "publish": "2013-10-16T00:41:12Z", 
    "summary": "Modern multicore processors are employing large last-level caches, for\nexample Intel's E7-8800 processor uses 24MB L3 cache. Further, with each CMOS\ntechnology generation, leakage energy has been dramatically increasing and\nhence, leakage energy is expected to become a major source of energy\ndissipation, especially in last-level caches (LLCs). The conventional schemes\nof cache energy saving either aim at saving dynamic energy or are based on\nproperties specific to first-level caches, and thus these schemes have limited\nutility for last-level caches. Further, several other techniques require\noffline profiling or per-application tuning and hence are not suitable for\nproduct systems. In this research, we propose novel cache leakage energy saving\nschemes for single-core and multicore systems; desktop, QoS, real-time and\nserver systems. We propose software-controlled, hardware-assisted techniques\nwhich use dynamic cache reconfiguration to configure the cache to the most\nenergy efficient configuration while keeping the performance loss bounded. To\nprofile and test a large number of potential configurations, we utilize\nlow-overhead, micro-architecture components, which can be easily integrated\ninto modern processor chips. We adopt a system-wide approach to save energy to\nensure that cache reconfiguration does not increase energy consumption of other\ncomponents of the processor. We have compared our techniques with the\nstate-of-art techniques and have found that our techniques outperform them in\ntheir energy efficiency. This research has important applications in improving\nenergy-efficiency of higher-end embedded, desktop, server processors and\nmultitasking systems. We have also proposed performance estimation approach for\nefficient design space exploration and have implemented time-sampling based\nsimulation acceleration approach for full-system architectural simulators."
},{
    "category": "cs.AR", 
    "doi": "10.1109/MWSCAS.2012.6292184", 
    "link": "http://arxiv.org/pdf/1310.7792v1", 
    "title": "Evaluating Cache Coherent Shared Virtual Memory for Heterogeneous   Multicore Chips", 
    "arxiv-id": "1310.7792v1", 
    "author": "Daniel J. Sorin", 
    "publish": "2013-10-29T13:03:38Z", 
    "summary": "The trend in industry is towards heterogeneous multicore processors (HMCs),\nincluding chips with CPUs and massively-threaded throughput-oriented processors\n(MTTOPs) such as GPUs. Although current homogeneous chips tightly couple the\ncores with cache-coherent shared virtual memory (CCSVM), this is not the\ncommunication paradigm used by any current HMC. In this paper, we present a\nCCSVM design for a CPU/MTTOP chip, as well as an extension of the pthreads\nprogramming model, called xthreads, for programming this HMC. Our goal is to\nevaluate the potential performance benefits of tightly coupling heterogeneous\ncores with CCSVM."
},{
    "category": "cs.AR", 
    "doi": "10.1109/MWSCAS.2012.6292184", 
    "link": "http://arxiv.org/pdf/1310.8494v1", 
    "title": "Using Cache-coloring to Mitigate Inter-set Write Variation in   Non-volatile Caches", 
    "arxiv-id": "1310.8494v1", 
    "author": "Sparsh Mittal", 
    "publish": "2013-10-31T13:33:16Z", 
    "summary": "In recent years, researchers have explored use of non-volatile devices such\nas STT-RAM (spin torque transfer RAM) for designing on-chip caches, since they\nprovide high density and consume low leakage power. A common limitation of all\nnon-volatile devices is their limited write endurance. Further, since existing\ncache management policies are write-variation unaware, excessive writes to a\nfew blocks may lead to a quick failure of the whole cache. We propose an\narchitectural technique for wear-leveling of non-volatile last level caches\n(LLCs). Our technique uses cache-coloring approach which adds a\nsoftware-controlled mapping layer between groups of physical pages and cache\nsets. Periodically the mapping is altered to ensure that write-traffic can be\nspread uniformly to different sets of the cache to achieve wear-leveling.\nSimulations performed with an x86-64 simulator and SPEC2006 benchmarks show\nthat our technique reduces the worst-case writes to cache blocks and thus\nimproves the cache lifetime by 4.07X."
},{
    "category": "cs.AR", 
    "doi": "10.1155/2014/814975", 
    "link": "http://arxiv.org/pdf/1312.0885v4", 
    "title": "Row-Based Dual Vdd Assignment, for a Level Converter Free CSA Design and   Its Near-Threshold Operation", 
    "arxiv-id": "1312.0885v4", 
    "author": "C. K. Sarkar", 
    "publish": "2013-11-29T09:48:57Z", 
    "summary": "Subthreshold circuit designs are very much popular for some of the ultra low\npower applications, where the minimum energy consumption is the primary\nconcern. But, due to the weak driving current, these circuits generally suffer\nfrom huge performance degradation. Therefore, in this paper, we primarily\ntargeted to analyze the performance of a Near-Threshold Circuit (NTC), which\nretains the excellent energy efficiency of the subthreshold design, while\nimproving the performance to a certain extent. A modified row-based dual Vdd\n4-operand CSA (Carry Save Adder) design has been reported in the present work\nusing 45 nm technology. Moreover, to find out the effectiveness of the\nnear-threshold operation of the 4-operand CSA design; it has been compared with\nthe other design styles. From the simulation results, obtained for the\nfrequency of 20 MHz, we found that the proposed scheme of CSA design consumes\n3.009*10-7 Watt of Average Power (Pavg), which is almost 90.9 % lesser than\nthat of the conventional CSA design. Whereas, looking at the perspective of\nmaximum delay at output, the proposed scheme of CSA design provides a fair\n44.37 % improvement, compared to that of the subthreshold CSA design."
},{
    "category": "cs.AR", 
    "doi": "10.1155/2014/814975", 
    "link": "http://arxiv.org/pdf/1312.2207v2", 
    "title": "A Cache Energy Optimization Technique for STT-RAM Last Level Cache", 
    "arxiv-id": "1312.2207v2", 
    "author": "Sparsh Mittal", 
    "publish": "2013-12-08T13:03:15Z", 
    "summary": "Last level caches (LLCs) occupy a large chip-area and there size is expected\nto grow further to offset the limitations of memory bandwidth and speed. Due to\nhigh leakage consumption of SRAM device, caches designed with SRAM consume\nlarge amount of energy. To address this, use of emerging technologies such as\nspin torque transfer RAM (STT-RAM) has been investigated which have lower\nleakage power dissipation. However, the high write latency and power of it may\nlead to large energy consumption which present challenges in its use. In this\nreport, we propose a cache reconfiguration based technique for improving the\nenergy efficiency of STT-RAM based LLCs. Our technique dynamically adjusts the\nactive cache size to reduce the cache leakage energy consumption with minimum\nperformance loss. We choose a suitable value of STT-RAM retention time for\navoiding refresh overhead and gaining performance. Single-core simulations have\nbeen performed using SPEC2006 benchmarks and Sniper x86-64 simulator. The\nresults show that while, compared to an STT-RAM LLC of similar area, an SRAM\nLLC incurs nearly 100% loss in energy and 7.3% loss in performance; our\ntechnique using STT-RAM cache saves 21.8% energy and incurs only 1.7% loss in\nperformance."
},{
    "category": "cs.AR", 
    "doi": "10.14569/IJACSA.2013.040910", 
    "link": "http://arxiv.org/pdf/1312.2976v1", 
    "title": "A Survey of Network-On-Chip Tools", 
    "arxiv-id": "1312.2976v1", 
    "author": "Slim Ben Saoud", 
    "publish": "2013-12-10T21:39:01Z", 
    "summary": "Nowadays System-On-Chips (SoCs) have evolved considerably in term of\nperformances, reliability and integration capacity. The last advantage has\ninduced the growth of the number of cores or Intellectual Properties (IPs) in a\nsame chip. Unfortunately, this important number of IPs has caused a new issue\nwhich is the intra-communication between the elements of a same chip. To\nresolve this problem, a new paradigm has been introduced which is the\nNetwork-On-Chip (NoC). Since the introduction of the NoC paradigm in the last\ndecade, new methodologies and approaches have been presented by research\ncommunity and many of them have been adopted by industrials. The literature\ncontains many relevant studies and surveys discussing NoC proposals and\ncontributions. However, few of them have discussed or proposed a comparative\nstudy of NoC tools. The objective of this work is to establish a reliable\nsurvey about available design, simulation or implementation NoC tools. We\ncollected an important amount of information and characteristics about NoC\ndedicated tools that we will present throughout this survey. This study is\nbuilt around a respectable amount of references and we hope it will help\nscientists."
},{
    "category": "cs.AR", 
    "doi": "10.14569/IJACSA.2013.040910", 
    "link": "http://arxiv.org/pdf/1401.0765v1", 
    "title": "A Survey of Techniques For Improving Energy Efficiency in Embedded   Computing Systems", 
    "arxiv-id": "1401.0765v1", 
    "author": "Sparsh Mittal", 
    "publish": "2014-01-04T02:06:23Z", 
    "summary": "Recent technological advances have greatly improved the performance and\nfeatures of embedded systems. With the number of just mobile devices now\nreaching nearly equal to the population of earth, embedded systems have truly\nbecome ubiquitous. These trends, however, have also made the task of managing\ntheir power consumption extremely challenging. In recent years, several\ntechniques have been proposed to address this issue. In this paper, we survey\nthe techniques for managing power consumption of embedded systems. We discuss\nthe need of power management and provide a classification of the techniques on\nseveral important parameters to highlight their similarities and differences.\nThis paper is intended to help the researchers and application-developers in\ngaining insights into the working of power management techniques and designing\neven more efficient high-performance embedded systems of tomorrow."
},{
    "category": "cs.AR", 
    "doi": "10.14569/IJACSA.2013.040910", 
    "link": "http://arxiv.org/pdf/1401.1003v1", 
    "title": "On the likelihood of multiple bit upsets in logic circuits", 
    "arxiv-id": "1401.1003v1", 
    "author": "Madhav P. Desai", 
    "publish": "2014-01-06T07:36:13Z", 
    "summary": "Soft errors have a significant impact on the circuit reliability at nanoscale\ntechnologies. At the architectural level, soft errors are commonly modeled by a\nprobabilistic bit-flip model. In developing such abstract fault models, an\nimportant issue to consider is the likelihood of multiple bit errors caused by\nparticle strikes. This likelihood has been studied to a great extent in\nmemories, but has not been understood to the same extent in logic circuits. In\nthis paper, we attempt to quantify the likelihood that a single transient event\ncan cause multiple bit errors in logic circuits consisting of combinational\ngates and flip-flops. In particular, we calculate the conditional probability\nof multiple bit-flips given that a single bit flips as a result of the\ntransient. To calculate this conditional probability, we use a Monte Carlo\ntechnique in which samples are generated using detailed post-layout circuit\nsimulations. Our experiments on the ISCAS'85 benchmarks and a few other\ncircuits indicate that, this conditional probability is quite significant and\ncan be as high as 0.31. Thus we conclude that multiple bit-flips must\nnecessarily be considered in order to obtain a realistic architectural fault\nmodel for soft errors."
},{
    "category": "cs.AR", 
    "doi": "10.14569/IJACSA.2013.040910", 
    "link": "http://arxiv.org/pdf/1401.2727v1", 
    "title": "Hardware Implementation of four byte per clock RC4 algorithm", 
    "arxiv-id": "1401.2727v1", 
    "author": "Ranjan Ghosh", 
    "publish": "2014-01-13T06:57:21Z", 
    "summary": "In the field of cryptography till date the 2-byte in 1-clock is the best\nknown RC4 hardware design [1], while 1-byte in 1-clock [2], and the 1-byte in 3\nclocks [3][4] are the best known implementation. The design algorithm in[2]\nconsiders two consecutive bytes together and processes them in 2 clocks. The\ndesign [1] is a pipelining architecture of [2]. The design of 1-byte in\n3-clocks is too much modular and clock hungry. In this paper considering the\nRC4 algorithm, as it is, a simpler RC4 hardware design providing higher\nthroughput is proposed in which 6 different architecture has been proposed. In\ndesign 1, 1-byte is processed in 1-clock, design 2 is a dynamic KSA-PRGA\narchitecture of Design 1. Design 3 can process 2 byte in a single clock, where\nas Design 4 is Dynamic KSA-PRGA architecture of Design 3. Design 5 and Design 6\nare parallelization architecture design 2 and design 4 which can compute 4 byte\nin a single clock. The maturity in terms of throughput, power consumption and\nresource usage, has been achieved from design 1 to design 6. The RC4 encryption\nand decryption designs are respectively embedded on two FPGA boards as\nco-processor hardware, the communication between the two boards performed using\nEthernet."
},{
    "category": "cs.AR", 
    "doi": "10.14569/IJACSA.2013.040910", 
    "link": "http://arxiv.org/pdf/1401.2732v1", 
    "title": "Fault Detection for RC4 Algorithm and its Implementation on FPGA   Platform", 
    "arxiv-id": "1401.2732v1", 
    "author": "Ranjan Ghosh", 
    "publish": "2014-01-13T07:19:52Z", 
    "summary": "In hardware implementation of a cryptographic algorithm, one may achieve\nleakage of secret information by creating scopes to introduce controlled faulty\nbit(s) even though the algorithm is mathematically a secured one. The technique\nis very effective in respect of crypto processors embedded in smart cards. In\nthis paper few fault detecting architectures for RC4 algorithm are designed and\nimplemented on Virtex5(ML505, LX110t) FPGA board. The results indicate that the\nproposed architectures can handle most of the faults without loss of throughput\nconsuming marginally additional hardware and power."
},{
    "category": "cs.AR", 
    "doi": "10.14569/IJACSA.2013.040910", 
    "link": "http://arxiv.org/pdf/1401.2768v1", 
    "title": "Design of novel architectures and field programmable gate arrays   implementation of two dimensional gaussian surround function", 
    "arxiv-id": "1401.2768v1", 
    "author": "M. T. Gopalakrishna", 
    "publish": "2014-01-13T09:52:08Z", 
    "summary": "A new design and novel architecture suitable for FPGA/ASIC implementation of\na 2D Gaussian surround function for image processing application is presented\nin this paper. The proposed scheme results in enormous savings of memory\nnormally required for 2D Gaussian function implementation. In the present work,\nthe Gaussian symmetric characteristics which quickly falls off toward\nplus/minus infinity has been used in order to save the memory. The 2D Gaussian\nfunction implementation is presented for use in applications such as image\nenhancement, smoothing, edge detection and filtering etc. The FPGA\nimplementation of the proposed 2D Gaussian function is capable of processing\n(blurring, smoothing, and convolution) high resolution color pictures of size\nup to $1600\\times1200$ pixels at the real time video rate of 30 frames/sec. The\nGaussian design exploited here has been used in the core part of retinex based\ncolor image enhancement. Therefore, the design presented produces Gaussian\noutput with three different scales, namely, 16, 64 and 128. The design was\ncoded in Verilog, a popular hardware design language used in industries,\nconforming to RTL coding guidelines and fits onto a single chip with a gate\ncount utilization of 89,213 gates. Experimental results presented confirms that\nthe proposed method offers a new approach for development of large sized\nGaussian pyramid while reducing the on-chip memory utilization."
},{
    "category": "cs.AR", 
    "doi": "10.14569/IJACSA.2013.040910", 
    "link": "http://arxiv.org/pdf/1401.4629v1", 
    "title": "HERMES: A Hierarchical Broadcast-Based Silicon Photonic Interconnect for   Scalable Many-Core Systems", 
    "arxiv-id": "1401.4629v1", 
    "author": "Alan Mickelson", 
    "publish": "2014-01-19T03:20:40Z", 
    "summary": "Optical interconnection networks, as enabled by recent advances in silicon\nphotonic device and fabrication technology, have the potential to address\non-chip and off-chip communication bottlenecks in many-core systems. Although\nseveral designs have shown superior power efficiency and performance compared\nto electrical alternatives, these networks will not scale to the thousands of\ncores required in the future.\n  In this paper, we introduce Hermes, a hybrid network composed of an optimized\nbroadcast for power-efficient low-latency global-scale coordination and\ncircuit-switch sub-networks for high-throughput data delivery. This network\nwill scale for use in thousand core chip systems. At the physical level,\nSoI-based adiabatic coupler has been designed to provide low-loss and compact\noptical power splitting. Based on the adiabatic coupler, a topology based on\n2-ary folded butterfly is designed to provide linear power division in a\nthousand core layout with minimal cross-overs. To address the network agility\nand provide for efficient use of optical bandwidth, a flow control and routing\nmechanism is introduced to dynamically allocate bandwidth and provide fairness\nusage of network resources. At the system level, bloom filter-based filtering\nfor localization of communication are designed for reducing global traffic. In\naddition, a novel greedy-based data and workload migration are leveraged to\nincrease the locality of communication in a NUCA (non-uniform cache access)\narchitecture. First order analytic evaluation results have indicated that\nHermes is scalable to at least 1024 cores and offers significant performance\nimprovement and power savings over prior silicon photonic designs."
},{
    "category": "cs.AR", 
    "doi": "10.14569/IJACSA.2013.040910", 
    "link": "http://arxiv.org/pdf/1401.4891v1", 
    "title": "The Design of a Network-On-Chip Architecture Based On An Avionic   Protocol", 
    "arxiv-id": "1401.4891v1", 
    "author": "Slim Ben Saoud", 
    "publish": "2014-01-20T13:20:58Z", 
    "summary": "When the Network-On-Chip (NoC) paradigm was introduced, many researchers have\nproposed many novelistic NoC architectures, tools and design strategies. In\nthis paper we introduce a new approach in the field of designing\nNetwork-On-Chip (NoC). Our inspiration came from an avionic protocol which is\nthe AFDX protocol. The proposed NoC architecture is a switch centric\narchitecture, with exclusive shortcuts between hosts and utilizes the\nflexibility, the reliability and the performances offered by AFDX."
},{
    "category": "cs.AR", 
    "doi": "10.7321/jscse.v2.n9.4", 
    "link": "http://arxiv.org/pdf/1401.6370v1", 
    "title": "Design of a High Speed XAUI Based on Dynamic Reconfigurable Transceiver   IP Core", 
    "arxiv-id": "1401.6370v1", 
    "author": "Mengmeng Cao", 
    "publish": "2014-01-24T15:14:52Z", 
    "summary": "By using the dynamic reconfigurable transceiver in high speed interface\ndesign, designer can solve critical technology problems such as ensuring signal\nintegrity conveniently, with lower error binary rate. In this paper, we\ndesigned a high speed XAUI (10Gbps Ethernet Attachment Unit Interface) to\ntransparently extend the physical reach of the XGMII. The following points are\nfocused: (1) IP (Intellectual Property) core usage. Altera Co. offers two\ntransceiver IP cores in Quartus II MegaWizard Plug-In Manager for XAUI design\nwhich is featured of dynamic reconfiguration performance, that is,\nALTGX_RECO?FIG instance and ALTGX instance, we can get various groups by\nchanging settings of the devices without power off. These two blocks can\naccomplish function of PCS (Physical Coding Sub-layer) and PMA (Physical Medium\nAttachment), however, with higher efficiency and reliability. (2) 1+1\nprotection. In our design, two ALTGX IP cores are used to work in parallel,\nwhich named XAUI0 and XAUI1. The former works as the main channel while the\nlatter redundant channel. When XAUI0 is out of service for some reasons, XAUI1\nwill start to work to keep the business. (3) RTL (Register Transfer Level)\ncoding with Verilog HDL and simulation. Create the ALTGX_RECO?FIG instance and\nALTGX instance, enable dynamic reconfiguration in the ALTGXB Megafunction, then\nconnect the ALTGX_RECO?FIG with the ALTGX instances. After RTL coding, the\ndesign was simulated on VCS simulator. The validated result indicates that the\npackets are transferred efficiently. FPGA makes high-speed optical\ncommunication system design simplified."
},{
    "category": "cs.AR", 
    "doi": "10.7321/jscse.v2.n9.4", 
    "link": "http://arxiv.org/pdf/1403.1928v1", 
    "title": "Five Modular Redundancy with Mitigation Technique to Recover the Error   Module", 
    "arxiv-id": "1403.1928v1", 
    "author": "Agfianto Eko Putra", 
    "publish": "2014-03-08T04:21:39Z", 
    "summary": "Hazard radiation can lead the system fault therefore Fault Tolerance is\nrequired. Fault Tolerant is a system, which is designed to keep operations\nrunning, despite the degradation in the specific module is happening. Many\nfault tolerances have been developed to handle the problem, to find the most\nrobust and efficient in the possible technology. This paper will present the\nFive Modular Redundancy (FMR) with Mitigation Technique to Recover the Error\nModule. With Dynamic Partial Reconfiguration technology that have already\navailable today, such fault tolerance technique can be implemented\nsuccessfully. The project showed the robustness of the system is increased and\nmodule which is error can be recovered immediately."
},{
    "category": "cs.AR", 
    "doi": "10.7321/jscse.v2.n9.4", 
    "link": "http://arxiv.org/pdf/1403.2686v1", 
    "title": "Development of SyReC based expandable reversible logic circuits", 
    "arxiv-id": "1403.2686v1", 
    "author": "Vandana Maheshwari", 
    "publish": "2014-03-11T18:49:18Z", 
    "summary": "Reversible computing is gaining high interest from researchers due to its\nvarious promises. One of the prominent advantages perceived from reversible\nlogic is that of reduced power dissipation with many reversible gates at hand,\ndesigning a reversible circuit (combinational) has received due attention and\nachievement. A proposed language for description of reversible circuit, namely\nSyReC, is also in place. What remain are the software tools which would help in\nreversible circuit synthesis through simulation. Beginning with the smallest\nreversible circuit realizations the SyReC statements and expressions, we employ\na hierarchal approach to develop a complete reversible circuit, entirely from\nits SyReC code. We implement this as a software tool. The tool allows a user to\nexpand a reversible circuit of choice in terms of bit width of its inputs. The\nbackground approach of expansion of a reversible circuit has also been proposed\nas a part of this dissertation. Also, a user can use the tool to observe the\neffect of expansion on incurred costs, in terms of increase in number of lines,\nnumber of gates and quantum cost. The importance of observing the change in\ncosts with respect to scale of expansion is important not only from analysis\npoint of view, but also because the cost depends on the approach used for\nexpansion. This dissertation also proposes a reversible circuit design for\nelevator controller (combinational) and the related costs. The aim is to\nemphasize use of the proposed approach is designing customized circuits."
},{
    "category": "cs.AR", 
    "doi": "10.7321/jscse.v2.n9.4", 
    "link": "http://arxiv.org/pdf/1403.2785v1", 
    "title": "State Dependent Statistical Timing Model for Voltage Scaled Circuits", 
    "arxiv-id": "1403.2785v1", 
    "author": "Fadi J. Kurdahi", 
    "publish": "2014-03-12T01:26:16Z", 
    "summary": "This paper presents a novel statistical state-dependent timing model for\nvoltage over scaled (VoS) logic circuits that accurately and rapidly finds the\ntiming distribution of output bits. Using this model erroneous VoS circuits can\nbe represented as error-free circuits combined with an error-injector. A case\nstudy of a two point DFT unit employing the proposed model is presented and\ncompared to HSPICE circuit simulation. Results show an accurate match, with\nsignificant speedup gains."
},{
    "category": "cs.AR", 
    "doi": "10.7321/jscse.v2.n9.4", 
    "link": "http://arxiv.org/pdf/1403.4554v1", 
    "title": "A Flexible Design for Optimization of Hardware Architecture in   Distributed Arithmetic based FIR Filters", 
    "arxiv-id": "1403.4554v1", 
    "author": "Omid Hashemipour", 
    "publish": "2014-03-18T18:02:25Z", 
    "summary": "FIR filters are used in many performance/power critical applications such as\nmobile communication devices, analogue to digital converters and digital signal\nprocessing applications. Design of appropriate FIR filters usually causes the\norder of filter to be increased. Synthesis and tape-out of high-order FIR\nfilters with reasonable delay, area and power has become an important challenge\nfor hardware designers. In many cases the complexity of high-order filters\ncauses the constraints of the total design could not be satisfied. In this\npaper, efficient hardware architecture is proposed for distributed arithmetic\n(DA) based FIR filters. The architecture is based on optimized combination of\nLook-up Tables (LUTs) and compressors. The optimized system level solution is\nobtained from a set of dynamic programming optimization algorithms. The\nexperiments show the proposed design educed the delay cost between 16%-62.5% in\ncomparison of previous optimized structures for DA-based architectures."
},{
    "category": "cs.AR", 
    "doi": "10.7321/jscse.v2.n9.4", 
    "link": "http://arxiv.org/pdf/1403.6632v1", 
    "title": "Design space exploration tools for the ByoRISC configurable processor   family", 
    "arxiv-id": "1403.6632v1", 
    "author": "Spiridon Nikolaidis", 
    "publish": "2014-03-26T11:24:19Z", 
    "summary": "In this paper, the ByoRISC (Build your own RISC) configurable\napplication-specific instruction-set processor (ASIP) family is presented.\nByoRISCs, as vendor-independent cores, provide extensive architectural\nparameters over a baseline processor, which can be customized by\napplication-specific hardware extensions (ASHEs). Such extensions realize\nmulti-input multi-output (MIMO) custom instructions with local state and\nload/store accesses to the data memory. ByoRISCs incorporate a true multi-port\nregister file, zero-overhead custom instruction decoding, and scalable data\nforwarding mechanisms. Given these design decisions, ByoRISCs provide a unique\ncombination of features that allow their use as architectural testbeds and the\nseamless and rapid development of new high-performance ASIPs.\n  The performance characteristics of ByoRISCs, implemented as\nvendor-independent cores, have been evaluated for both ASIC and FPGA\nimplementations, and it is proved that they provide a viable solution in\nFPGA-based system-on-a-chip design. A case study of an image processing\npipeline is also presented to highlight the process of utilizing a ByoRISC\ncustom processor. A peak performance speedup of up to 8.5$\\times$ can be\nobserved, whereas an average performance speedup of 4.4$\\times$ on Xilinx\nVirtex-4 targets is achieved. In addition, ByoRISC outperforms an experimental\nVLIW architecture named VEX even in its 16-wide configuration for a number of\ndata-intensive application kernels."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICIAFS.2012.6419895", 
    "link": "http://arxiv.org/pdf/1403.7291v1", 
    "title": "Instruction-set Selection for Multi-application based ASIP Design: An   Instruction-level Study", 
    "arxiv-id": "1403.7291v1", 
    "author": "Angelo Ambrose", 
    "publish": "2014-03-28T07:35:09Z", 
    "summary": "Efficiency in embedded systems is paramount to achieve high performance while\nconsuming less area and power. Processors in embedded systems have to be\ndesigned carefully to achieve such design constraints. Application Specific\nInstruction set Processors (ASIPs) exploit the nature of applications to design\nan optimal instruction set. Despite being not general to execute any\napplication, ASIPs are highly preferred in the embedded systems industry where\nthe devices are produced to satisfy a certain type of application domain/s\n(either intra-domain or inter-domain). Typically, ASIPs are designed from a\nbase-processor and functionalities are added for applications. This paper\nstudies the multi-application ASIPs and their instruction sets, extensively\nanalysing the instructions for inter-domain and intra-domain designs. Metrics\nanalysed are the reusable instructions and the extra cost to add a certain\napplication. A wide range of applications from various application benchmarks\n(MiBench, MediaBench and SPEC2006) and domains are analysed for two different\narchitectures (ARM-Thumb and PISA). Our study shows that the intra-domain\napplications contain larger number of common instructions, whereas the\ninter-domain applications have very less common instructions, regardless of the\narchitecture (and therefore the ISA)."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICIINFS.2011.6038036", 
    "link": "http://arxiv.org/pdf/1403.7299v1", 
    "title": "Heterogeneous processor pipeline for a product cipher application", 
    "arxiv-id": "1403.7299v1", 
    "author": "S. Radhakrishnan", 
    "publish": "2014-03-28T08:13:20Z", 
    "summary": "Processing data received as a stream is a task commonly performed by modern\nembedded devices, in a wide range of applications such as multimedia\n(encoding/decoding/ playing media), networking (switching and routing), digital\nsecurity, scientific data processing, etc. Such processing normally tends to be\ncalculation intensive and therefore requiring significant processing power.\nTherefore, hardware acceleration methods to increase the performance of such\napplications constitute an important area of study. In this paper, we present\nan evaluation of one such method to process streaming data, namely\nmulti-processor pipeline architecture. The hardware is based on a\nMultiple-Processor System on Chip (MPSoC), using a data encryption algorithm as\na case study. The algorithm is partitioned on a coarse grained level and mapped\non to an MPSoC with five processor cores in a pipeline, using specifically\nconfigured Xtensa LX3 cores. The system is then selectively optimized by\nstrengthening and pruning the resources of each processor core. The optimized\nsystem is evaluated and compared against an optimal single-processor System on\nChip (SoC) for the same application. The multiple-processor pipeline system for\ndata encryption algorithms used was observed to provide significant speed ups,\nup to 4.45 times that of the single-processor system, which is close to the\nideal speed up from a five-stage pipeline."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICIINFS.2011.6038036", 
    "link": "http://arxiv.org/pdf/1403.7380v1", 
    "title": "Generating and evaluating application-specific hardware extensions", 
    "arxiv-id": "1403.7380v1", 
    "author": "Nikolaos Kavvadias", 
    "publish": "2014-03-28T14:06:17Z", 
    "summary": "Modern platform-based design involves the application-specific extension of\nembedded processors to fit customer requirements. To accomplish this task, the\npossibilities offered by recent custom/extensible processors for tuning their\ninstruction set and microarchitecture to the applications of interest have to\nbe exploited. A significant factor often determining the success of this\nprocess is the utomation available in application analysis and custom\ninstruction generation.\n  In this paper we present YARDstick, a design automation tool for custom\nprocessor development flows that focuses on generating and evaluating\napplication-specific hardware extensions. YARDstick is a building block for\nASIP development, integrating application analysis, custom instruction\ngeneration and selection with user-defined compiler intermediate\nrepresentations. In a YARDstick-enabled environment, practical issues in\ntraditional ASIP design are confronted efficiently; the exploration\ninfrastructure is liberated from compiler and simulator idiosyncrasies, since\nthe ASIP designer is empowered with the freedom of specifying the target\narchitectures of choice and adding new implementations of analyses and custom\ninstruction generation/selection methods. To illustrate the capabilities of the\nYARDstick approach, we present interesting exploration scenarios: quantifying\nthe effect of machine-dependent compiler optimizations and the selection of the\ntarget architecture in terms of operation set and memory model on custom\ninstruction generation/selection under different input/output constraints."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICIINFS.2011.6038036", 
    "link": "http://arxiv.org/pdf/1405.2909v1", 
    "title": "Emulated ASIC Power and Temperature Monitor System for FPGA Prototyping   of an Invasive MPSoC Computing Architecture", 
    "arxiv-id": "1405.2909v1", 
    "author": "Doris Schmitt-Landsiedel", 
    "publish": "2014-05-12T16:40:23Z", 
    "summary": "In this contribution the emulation of an ASIC temperature and power\nmonitoring system (TPMon) for FPGA prototyping is presented and tested to\ncontrol processor temperatures under different control targets and operating\nstrategies. The approach for emulating the power monitor is based on an\ninstruction-level energy model. For emulating the temperature monitor, a\nthermal RC model is used. The monitoring system supplies an invasive MPSoC\ncomputing architecture with hardware status information (power and temperature\ndata of the processors within the system). These data are required for\nresource-aware load distribution. As a proof of concept different operating\nstrategies and control targets were evaluated for a 2-tile invasive MPSoC\ncomputing system."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICIINFS.2011.6038036", 
    "link": "http://arxiv.org/pdf/1405.4232v2", 
    "title": "Architectural Design of a RAM Arbiter", 
    "arxiv-id": "1405.4232v2", 
    "author": "Sourangsu Banerji", 
    "publish": "2014-05-16T16:31:35Z", 
    "summary": "Standard memory modules to store (and access) data are designed for use with\na single system accessing it. More complicated memory modules would be accessed\nthrough a memory controller, which are also designed for one system. For\nmultiple systems to access a single memory module there must be some\nfacilitation that allows them to access the memory without overriding or\ncorrupting the access from the others. This was done with the use of a memory\narbiter, which controls the flow of traffic into the memory controller. The\narbiter has a set of rules to abide to in order to choose which system gets\nthrough to the memory controller. In this project, a regular RAM module is\ndesigned for use with one system. Furthermore, a memory arbiter is also\ndesigned in Verilog that allows for more than one system to use a single RAM\nmodule in a controlled and synchronized manner. The arbiter uses a fixed\npriority scheme to avoid starvation of the system. In addition one of the major\nproblems associated with such systems i.e. The Address Clash Problem has been\nnicely tackled and solved. The design is verified in simulation and validated\non a Xilinx ML605 evaluation board with a Virtex 6 FPGA."
},{
    "category": "cs.AR", 
    "doi": "10.5120/16834-6599", 
    "link": "http://arxiv.org/pdf/1407.0147v1", 
    "title": "Application Specific Hardware Design Simulation for High Performance   Embedded System", 
    "arxiv-id": "1407.0147v1", 
    "author": "Manoj Kumar Jain", 
    "publish": "2014-07-01T09:10:26Z", 
    "summary": "Application specific simulation is challenging task in various real time high\nperformance embedded devices. In this study specific application is implemented\nwith the help of Xilinx. Xilinx provides SDK and XPS tools, XPS tools used for\ndevelop complete hardware platform and SDK provides software platform for\napplication creation and verification. Xilinx XUP-5 board have been used and\nimplemented various specific Applications with hardware platform. In this study\nthe base instruction set with customized instructions, supported with specific\nhardware resources are analyzed."
},{
    "category": "cs.AR", 
    "doi": "10.5120/16834-6599", 
    "link": "http://arxiv.org/pdf/1407.2082v1", 
    "title": "FPGA Based Efficient Multiplier for Image Processing Applications Using   Recursive Error Free Mitchell Log Multiplier and KOM Architecture", 
    "arxiv-id": "1407.2082v1", 
    "author": "L M Patnaik", 
    "publish": "2014-07-08T13:46:42Z", 
    "summary": "The Digital Image processing applications like medical imaging, satellite\nimaging, Biometric trait images etc., rely on multipliers to improve the\nquality of image. However, existing multiplication techniques introduce errors\nin the output with consumption of more time, hence error free high speed\nmultipliers has to be designed. In this paper we propose FPGA based Recursive\nError Free Mitchell Log Multiplier (REFMLM) for image Filters. The 2x2 error\nfree Mitchell log multiplier is designed with zero error by introducing error\ncorrection term is used in higher order Karastuba-Ofman Multiplier (KOM)\nArchitectures. The higher order KOM multipliers is decomposed into number of\nlower order multipliers using radix 2 till basic multiplier block of order 2x2\nwhich is designed by error free Mitchell log multiplier. The 8x8 REFMLM is\ntested for Gaussian filter to remove noise in fingerprint image. The Multiplier\nis synthesized using Spartan 3 FPGA family device XC3S1500-5fg320. It is\nobserved that the performance parameters such as area utilization, speed, error\nand PSNR are better in the case of proposed architecture compared to existing\narchitectures"
},{
    "category": "cs.AR", 
    "doi": "10.5120/16834-6599", 
    "link": "http://arxiv.org/pdf/1407.5173v1", 
    "title": "An ECG-SoC with 535nW/channel lossless data compression for wearable   sensors", 
    "arxiv-id": "1407.5173v1", 
    "author": "C. J. Deepu", 
    "publish": "2014-07-19T11:42:48Z", 
    "summary": "This paper presents a low power ECG recording Sys-tem-on-Chip (SoC) with\non-chip low complexity lossless ECG compression for data reduction in\nwireless/ambulatory ECG sensor devices. The proposed algorithm uses a linear\nslope predictor to estimate the ECG samples, and uses a novel low complexity\ndynamic coding-packaging scheme to frame the resulting estimation error into\nfixed-length 16-bit format. The proposed technique achieves an average\ncompression ratio of 2.25x on MIT/BIH ECG database. Implemented in 0.35 {\\mu}m\nprocess, the compressor uses 0.565 K gates/channel occupying 0.4 mm2 for\n4-channel, and consumes 535 nW/channel at 2.4V for ECG sampled at 512 Hz. Small\nsize and ultra-low power consumption makes the proposed technique suitable for\nwearable ECG sensor application."
},{
    "category": "cs.AR", 
    "doi": "10.5120/16834-6599", 
    "link": "http://arxiv.org/pdf/1410.7560v1", 
    "title": "Multi Core SSL/TLS Security Processor Architecture Prototype Design with   automated Preferential Algorithm in FPGA", 
    "arxiv-id": "1410.7560v1", 
    "author": "Ranjan Ghosh", 
    "publish": "2014-10-28T09:11:21Z", 
    "summary": "In this paper a pipelined architecture of a high speed network security\nprocessor (NSP) for SSL,TLS protocol is implemented on a system on chip (SOC)\nwhere hardware information of all encryption, hashing and key exchange\nalgorithms are stored in flash memory in terms of bit files, in contrary to\nrelated works where all are actually implemented in hardware. The NSP finds\napplications in e-commerce, virtual private network (VPN) and in other fields\nthat require data confidentiality. The motivation of the present work is to\ndynamically execute applications with stipulated throughput within budgeted\nhardware resource and power. A preferential algorithm choosing an appropriate\ncipher suite is proposed, which is based on Efficient System Index (ESI) budget\ncomprising of power, throughput and resource given by the user. The bit files\nof the chosen security algorithms are downloaded from the flash memory to the\npartial region of field programmable gate array (FPGA). The proposed SOC\ncontrols data communication between an application running in a system through\na PCI and the Ethernet interface of a network. Partial configuration feature is\nused in ISE14.4 suite with ZYNQ 7z020-clg484 FPGA platform. The performances"
},{
    "category": "cs.AR", 
    "doi": "10.5120/16834-6599", 
    "link": "http://arxiv.org/pdf/1411.0863v1", 
    "title": "Inner Loop Optimizations in Mapping Single Threaded Programs to Hardware", 
    "arxiv-id": "1411.0863v1", 
    "author": "Madhav Desai", 
    "publish": "2014-11-04T11:26:58Z", 
    "summary": "In the context of mapping high-level algorithms to hardware, we consider the\nbasic problem of generating an efficient hardware implementation of a single\nthreaded program, in particular, that of an inner loop. We describe a\ncontrol-flow mechanism which provides dynamic loop-pipelining capability in\nhardware, so that multiple iterations of an arbitrary inner loop can be made\nsimultaneously active in the generated hardware, We study the impact of this\nloop-pipelining scheme in conjunction with source-level loop-unrolling. In\nparticular, we apply this technique to some common loop kernels: regular\nkernels such as the fast-fourier transform and matrix multiplication, as well\nas an example of an inner loop whose body has branching. The resulting\nresulting hardware descriptions are synthesized to an FPGA target, and then\ncharacterized for performance and resource utilization. We observe that the use\nof dynamic loop-pipelining mechanism alone typically results in a significant\nimprovements in the performance of the hardware. If the loop is statically\nunrolled and if loop-pipelining is applied to the unrolled program, then the\nperformance improvement is still substantial. When dynamic loop pipelining is\nused in conjunction with static loop unrolling, the improvement in performance\nranges from 6X to 20X (in terms of number of clock cycles needed for the\ncomputation) across the loop kernels that we have studied. These optimizations\ndo have a hardware overhead, but, in spite of this, we observe that the joint\nuse of these loop optimizations not only improves performance, but also the\nperformance/cost ratio of the resulting hardware."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2014.5501", 
    "link": "http://arxiv.org/pdf/1411.2088v1", 
    "title": "Energy Efficient Full Adder Cell Design With Using Carbon Nanotube Field   Effect Transistors In 32 Nanometer Technology", 
    "arxiv-id": "1411.2088v1", 
    "author": "Ghazaleh Ghorbani", 
    "publish": "2014-11-08T05:57:42Z", 
    "summary": "Full Adder is one of the critical parts of logical and arithmetic units. So,\npresenting a low power full adder cell reduces the power consumption of the\nentire circuit. Also, using Nano-scale transistors, because of their unique\ncharacteristics will save energy consumption and decrease the chip area. In\nthis paper we presented a low power full adder cell by using carbon nanotube\nfield effect transistors (CNTFETs). Simulation results were carried out using\nHSPICE based on the CNTFET model in 32 nanometer technology in Different values\nof temperature and VDD."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2014.5503", 
    "link": "http://arxiv.org/pdf/1411.2212v1", 
    "title": "Designing high-speed, low-power full adder cells based on carbon   nanotube technology", 
    "arxiv-id": "1411.2212v1", 
    "author": "Keivan Navi", 
    "publish": "2014-11-09T09:26:43Z", 
    "summary": "This article presents novel high speed and low power full adder cells based\non carbon nanotube field effect transistor (CNFET). Four full adder cells are\nproposed in this article. First one (named CN9P4G) and second one (CN9P8GBUFF)\nutilizes 13 and 17 CNFETs respectively. Third design that we named CN10PFS uses\nonly 10 transistors and is full swing. Finally, CN8P10G uses 18 transistors and\ndivided into two modules, causing Sum and Cout signals are produced in a\nparallel manner. All inputs have been used straight, without inverting. These\ndesigns also used the special feature of CNFET that is controlling the\nthreshold voltage by adjusting the diameters of CNFETs to achieve the best\nperformance and right voltage levels. All simulation performed using Synopsys\nHSPICE software and the proposed designs are compared to other classical and\nmodern CMOS and CNFET-based full adder cells in terms of delay, power\nconsumption and power delay product."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2014.5503", 
    "link": "http://arxiv.org/pdf/1411.2917v1", 
    "title": "Fast Prefix Adders for Non-Uniform Input Arrival Times", 
    "arxiv-id": "1411.2917v1", 
    "author": "Sophie Spirkl", 
    "publish": "2014-11-11T18:52:26Z", 
    "summary": "We consider the problem of constructing fast and small parallel prefix adders\nfor non-uniform input arrival times. This problem arises whenever the adder is\nembedded into a more complex circuit, e. g. a multiplier.\n  Most previous results are based on representing binary carry-propagate adders\nas so-called parallel prefix graphs, in which pairs of generate and propagate\nsignals are combined using complex gates known as prefix gates. Adders\nconstructed in this model usually minimize the delay in terms of these prefix\ngates. However, the delay in terms of logic gates can be worse by a factor of\ntwo.\n  In contrast, we aim to minimize the delay of the underlying logic circuit\ndirectly. We prove a lower bound on the delay of a carry bit computation\nachievable by any prefix carry bit circuit and develop an algorithm that\ncomputes a prefix carry bit circuit with optimum delay up to a small additive\nconstant. Furthermore, we use this algorithm to construct a small parallel\nprefix adder.\n  Compared to existing algorithms we simultaneously improve the delay and size\nguarantee, as well as the running time for constructing prefix carry bit and\nadder circuits."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2014.5503", 
    "link": "http://arxiv.org/pdf/1411.3492v1", 
    "title": "Evaluation of silicon consumption for a connectionless Network-on-Chip", 
    "arxiv-id": "1411.3492v1", 
    "author": "Ant\u00f4nio Augusto Fr\u00f6hlich", 
    "publish": "2014-11-13T10:37:18Z", 
    "summary": "We present the design and evaluation of a predictable Network-on-Chip (NoC)\nto interconnect processing units running multimedia applications with\nvariable-bit-rate. The design is based on a connectionless strategy in which\nflits from different communication flows are interleaved in the same\ncommunication channel between routers. Each flit carries routing information\nused by routers to perform arbitration and scheduling of the corresponding\noutput communication channel. Analytic comparisons show that our approach keeps\naverage latency lower than a network based on resource reservation, when both\nnetworks are working over 80% of offered load. We also evaluate the proposed\nNoC on FPGA and ASIC technologies to understand the trade-off due to our\napproach, in terms of silicon consumption."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2014.5503", 
    "link": "http://arxiv.org/pdf/1411.3929v1", 
    "title": "Analog Signal Processing Solution for Image Alignment", 
    "arxiv-id": "1411.3929v1", 
    "author": "Dev Gupta", 
    "publish": "2014-11-14T15:07:54Z", 
    "summary": "Imaging and Image sensors is a field that is continuously evolving. There are\nnew products coming into the market every day. Some of these have very severe\nSize, Weight and Power constraints whereas other devices have to handle very\nhigh computational loads. Some require both these conditions to be met\nsimultaneously. Current imaging architectures and digital image processing\nsolutions will not be able to meet these ever increasing demands. There is a\nneed to develop novel imaging architectures and image processing solutions to\naddress these requirements. In this work we propose analog signal processing as\na solution to this problem. The analog processor is not suggested as a\nreplacement to a digital processor but it will be used as an augmentation\ndevice which works in parallel with the digital processor, making the system\nfaster and more efficient. In order to show the merits of analog processing the\nhighly computational Normalized Cross Correlation algorithm is implemented. We\npropose two novel modifications to the algorithm and a new imaging architecture\nwhich, significantly reduces the computation time."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2014.5503", 
    "link": "http://arxiv.org/pdf/1411.6498v1", 
    "title": "Correction to the 2005 paper: \"Digit Selection for SRT Division and   Square Root\"", 
    "arxiv-id": "1411.6498v1", 
    "author": "Peter Kornerup", 
    "publish": "2014-11-24T16:00:47Z", 
    "summary": "It has been pointed out by counterexamples in a 2013 paper in the IEEE\nTransactions on Computers [1], that there is an error in the previously ibid.\\\nin 2005 published paper [2] on the construction of valid digit selection tables\nfor SRT type division and square root algorithms. The error has been corrected,\nand new results found on selection constants for maximally redundant digit\nsets."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2014.5503", 
    "link": "http://arxiv.org/pdf/1412.1140v1", 
    "title": "Sphynx: A Shared Instruction Cache Exporatory Study", 
    "arxiv-id": "1412.1140v1", 
    "author": "Josef Spjut", 
    "publish": "2014-12-03T00:16:43Z", 
    "summary": "The Sphynx project was an exploratory study to discover what might be done to\nimprove the heavy replication of in- structions in independent instruction\ncaches for a massively parallel machine where a single program is executing\nacross all of the cores. While a machine with only many cores (fewer than 50)\nmight not have any issues replicating the instructions for each core, as we\napproach the era where thousands of cores can be placed on one chip, the\noverhead of instruction replication may become unacceptably large. We believe\nthat a large amount of sharing should be possible when the ma- chine is\nconfigured for all of the threads to issue from the same set of instructions.\nWe propose a technique that allows sharing an instruction cache among a number\nof independent processor cores to allow for inter-thread sharing and reuse of\ninstruction memory. While we do not have test cases to demonstrate the\npotential magnitude of performance gains that could be achieved, the potential\nfor sharing reduces the die area required for instruction storage on chip."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2014.5503", 
    "link": "http://arxiv.org/pdf/1412.2950v1", 
    "title": "Performance Enhancement of Routers in Networks-on-Chip Using Dynamic   Virtual Channels Allocation", 
    "arxiv-id": "1412.2950v1", 
    "author": "Farshad Safaei", 
    "publish": "2014-12-09T13:14:29Z", 
    "summary": "This study proposes a new router architecture to improve the performance of\ndynamic allocation of virtual channels. The proposed router is designed to\nreduce the hardware complexity and to improve power and area consumption,\nsimultaneously. In the new structure of the proposed router, all of the\ncontrolling components have been implemented sequentially inside the allocator\nrouter modules. This optimizes communications between the controlling\ncomponents and eliminates the most of hardware overloads of modular\ncommunications. Eliminating additional communications also reduces the hardware\ncomplexity. In order to show the validity of the proposed design in real\nhardware resources, the proposed router has been implemented onto a\nField-Programmable Gate Array (FPGA). Since the implementation of a\nNetwork-on-Chip (NoC) requires certain amount of area on the chip, the\nsuggested approach is also able to reduce the demand of hardware resources. In\nthis method, the internal memory of the FPGA is used for implementing control\nunits. This memory is faster and can be used with specific patterns. The use of\nthe FPGA memory saves the hardware resources and allows the implementation of\nNoC based FPGA."
},{
    "category": "cs.AR", 
    "doi": "10.1109/EmbeddedCom-ScalCom.2009.128", 
    "link": "http://arxiv.org/pdf/1412.3224v1", 
    "title": "Prophet: A Speculative Multi-threading Execution Model with   Architectural Support Based on CMP", 
    "arxiv-id": "1412.3224v1", 
    "author": "Du Yanning", 
    "publish": "2014-12-10T08:43:27Z", 
    "summary": "Speculative multi-threading (SpMT) has been proposed as a perspective method\nto exploit Chip Multiprocessors (CMP) hardware potential. It is a thread level\nspeculation (TLS) model mainly depending on software and hardware co-design.\nThis paper researches speculative thread-level parallelism of general purpose\nprograms and a speculative multi-threading execution model called Prophet is\npresented. The architectural support for Prophet execution model is designed\nbased on CMP. In Prophet the inter-thread data dependency are predicted by\npre-computation slice (p-slice) to reduce RAW violation. Prophet\nmulti-versioning Cache system along with thread state control mechanism in\narchitectural support are utilized for buffering the speculative data, and a\nsnooping bus based cache coherence protocol is used to detect data dependence\nviolation. The simulation-based evaluation shows that the Prophet system could\nachieve significant speedup for general-purpose programs."
},{
    "category": "cs.AR", 
    "doi": "10.1109/EmbeddedCom-ScalCom.2009.128", 
    "link": "http://arxiv.org/pdf/1412.3829v5", 
    "title": "A High-Throughput Energy-Efficient Implementation of   Successive-Cancellation Decoder for Polar Codes Using Combinational Logic", 
    "arxiv-id": "1412.3829v5", 
    "author": "Erdal Ar\u0131kan", 
    "publish": "2014-12-11T21:29:49Z", 
    "summary": "This paper proposes a high-throughput energy-efficient Successive\nCancellation (SC) decoder architecture for polar codes based on combinational\nlogic. The proposed combinational architecture operates at relatively low clock\nfrequencies compared to sequential circuits, but takes advantage of the high\ndegree of parallelism inherent in such architectures to provide a favorable\ntradeoff between throughput and energy efficiency at short to medium block\nlengths. At longer block lengths, the paper proposes a hybrid-logic SC decoder\nthat combines the advantageous aspects of the combinational decoder with the\nlow-complexity nature of sequential-logic decoders. Performance characteristics\non ASIC and FPGA are presented with a detailed power consumption analysis for\ncombinational decoders. Finally, the paper presents an analysis of the\ncomplexity and delay of combinational decoders, and of the throughput gains\nobtained by hybrid-logic decoders with respect to purely synchronous\narchitectures."
},{
    "category": "cs.AR", 
    "doi": "10.1049/el.2014.4432", 
    "link": "http://arxiv.org/pdf/1412.6043v1", 
    "title": "A 237 Gbps Unrolled Hardware Polar Decoder", 
    "arxiv-id": "1412.6043v1", 
    "author": "Warren J. Gross", 
    "publish": "2014-12-18T20:07:22Z", 
    "summary": "In this letter we present a new architecture for a polar decoder using a\nreduced complexity successive cancellation decoding algorithm. This novel\nfully-unrolled, deeply-pipelined architecture is capable of achieving a coded\nthroughput of over 237 Gbps for a (1024,512) polar code implemented using an\nFPGA. This decoder is two orders of magnitude faster than state-of-the-art\npolar decoders."
},{
    "category": "cs.AR", 
    "doi": "10.1049/el.2014.4432", 
    "link": "http://arxiv.org/pdf/1412.7692v1", 
    "title": "A Feasibility Study on Programmer Specific Instruction Set Processors   (PSISPs)", 
    "arxiv-id": "1412.7692v1", 
    "author": "R. G. Ragel", 
    "publish": "2014-12-24T15:35:44Z", 
    "summary": "ASIPs are designed in order to execute instructions of a particular domain of\napplications. The designing of ASIPs addresses the major challenges faced by a\nsystem on chip such as size, cost, performance and energy consumption. The\nhigher the number of similar instructions within the domain to be mapped the\nlesser the energy consumption, the smaller the size and the higher the\nperformance of the ASIP. Thus, designing processors for domains with more\nsimilar programs would overcome these issues. This paper describes the\ninvestigation of whether the domains of programmer specific programs have any\nsignificance like application specific program domains and thus, whether the\napproach of designing processors known as Programmer Specific Instruction Set\nProcessors is worthwhile. We performed the evaluation at the instruction level\nby using four different measures to obtain the similarity of programs: (1) by\nthe existence of each instruction, (2) by the frequency of each instruction,\n(3) by two consecutive instruction patterns and (4) by three consecutive\ninstruction patterns of application specific and programmer specific programs.\nWe found that although programmer specific instructions show some impact on the\nsimilarity measures, they are much smaller and therefore insignificant compared\nto the impact from application specific programs."
},{
    "category": "cs.AR", 
    "doi": "10.1049/el.2014.4432", 
    "link": "http://arxiv.org/pdf/1502.01237v1", 
    "title": "Running Identical Threads in C-Slow Retiming based Designs for   Functional Failure Detection", 
    "arxiv-id": "1502.01237v1", 
    "author": "Tobias Strauch", 
    "publish": "2015-02-04T15:43:55Z", 
    "summary": "This paper shows the usage of C-Slow Retiming (CSR) in safety critical and\nlow power applications. CSR generates C copies of a design by reusing the given\nlogic resources in a time sliced fashion. When all C design copies are\nstimulated with the same input values, then all C design copies should behave\nthe same way and will therefore create a redundant system. The paper shows that\nthis special method of using CSR offers great benefits when used in safety\ncritical and low power applications. Additional optimization techniques towards\nreducing register count are shown and an on-the-fly recovery mechanism is\ndiscussed."
},{
    "category": "cs.AR", 
    "doi": "10.1049/el.2014.4432", 
    "link": "http://arxiv.org/pdf/1502.02239v1", 
    "title": "A High-Performance Solid-State Disk with Double-Data-Rate NAND Flash   Memory", 
    "arxiv-id": "1502.02239v1", 
    "author": "Sungroh Yoon", 
    "publish": "2015-02-08T11:07:50Z", 
    "summary": "We propose a novel solid-state disk (SSD) architecture that utilizes a\ndouble-data-rate synchronous NAND flash interface for improving read and write\nperformance. Unlike the conventional design, the data transfer rate in the\nproposed design is doubled in harmony with synchronous signaling. The new\narchitecture does not require any extra pins with respect to the conventional\narchitecture, thereby guaranteeing backward compatibility. For performance\nevaluation, we simulated various SSD designs that adopt the proposed\narchitecture and measured their performance in terms of read/write bandwidths\nand energy consumption. Both NAND flash cell types, namely single-level cells\n(SLCs) and multi-level cells (MLCs), were considered. In the experiments using\nSLC-type NAND flash chips, the read and write speeds of the proposed\narchitecture were 1.65-2.76 times and 1.09-2.45 times faster than those of the\nconventional architecture, respectively. Similar improvements were observed for\nthe MLC-based architectures tested. It was particularly effective to combine\nthe proposed architecture with the way-interleaving technique that multiplexes\nthe data channel between the controller and each flash chip. For a reasonably\nhigh degree of way interleaving, the read/write performance and the energy\nconsumption of our approach were notably better than those of the conventional\ndesign."
},{
    "category": "cs.AR", 
    "doi": "10.1049/el.2014.4432", 
    "link": "http://arxiv.org/pdf/1502.07055v1", 
    "title": "A Novel Architecture of Area Efficient FFT Algorithm for FPGA   Implementation", 
    "arxiv-id": "1502.07055v1", 
    "author": "Debesh Choudhury", 
    "publish": "2015-02-25T05:45:08Z", 
    "summary": "Fast Fourier transform (FFT) of large number of samples requires huge\nhardware resources of field programmable gate arrays (FPGA), which needs more\narea and power. In this paper, we present an area efficient architecture of FFT\nprocessor that reuses the butterfly elements several times. The FFT processor\nis simulated using VHDL and the results are validated on a Virtex-6 FPGA. The\nproposed architecture outperforms the conventional architecture of a $N$-point\nFFT processor in terms of area which is reduced by a factor of $log_N 2$ with\nnegligible increase in processing time."
},{
    "category": "cs.AR", 
    "doi": "10.1049/el.2014.4432", 
    "link": "http://arxiv.org/pdf/1502.07454v1", 
    "title": "Generation and Validation of Custom Multiplication IP Blocks from the   Web", 
    "arxiv-id": "1502.07454v1", 
    "author": "Minas Dasygenis", 
    "publish": "2015-02-26T06:21:58Z", 
    "summary": "Every CPU carries one or more arithmetical and logical units. One popular\noperation that is performed by these units is multiplication. Automatic\ngeneration of custom VHDL models for performing this operation, allows the\ndesigner to achieve a time efficient design space exploration. Although these\nunits are heavily utilized in modern digital circuits and DSP, there is no\ntool, accessible from the web, to generate the HDL description of such designs\nfor arbitrary and different input bitwidths. In this paper, we present our web\naccessible tool to construct completely custom optimized multiplication units\ntogether with random generated test vectors for their verification. Our novel\ntool is one of the firsts web based EDA tools to automate the design of such\nunits and simultaneously provide custom testbenches to verify their\ncorrectness. Our synthesized circuits on Xilinx Virtex 6 FPGA, operate up to\n589 Mhz."
},{
    "category": "cs.AR", 
    "doi": "10.1049/el.2014.4432", 
    "link": "http://arxiv.org/pdf/1503.02354v1", 
    "title": "A General Scheme for Noise-Tolerant Logic Design Based on Probabilistic   and DCVS Approaches", 
    "arxiv-id": "1503.02354v1", 
    "author": "Huazhong Yang", 
    "publish": "2015-03-09T01:36:50Z", 
    "summary": "In this paper, a general circuit scheme for noise-tolerant logic design based\non Markov Random Field theory and differential Cascade Voltage Switch technique\nhas been proposed, which is an extension of the work in [1-3], [4]. A block\nwith only four transistors has been successfully inserted to the original\ncircuit scheme from [3] and extensive simulation results show that our proposed\ndesign can operate correctly with the input signal of 1 dB signal-noise-ratio.\nWhen using the evaluation parameter from [5], the output value of our design\ndecreases by 76.5% on average than [3] which means that superior noise-immunity\ncould be obtained through our work."
},{
    "category": "cs.AR", 
    "doi": "10.1049/el.2014.4432", 
    "link": "http://arxiv.org/pdf/1503.03166v1", 
    "title": "Design of High Performance MIPS Cryptography Processor Based on T-DES   Algorithm", 
    "arxiv-id": "1503.03166v1", 
    "author": "Shivani Parmar", 
    "publish": "2015-03-08T18:23:32Z", 
    "summary": "The paper describes the design of high performance MIPS Cryptography\nprocessor based on triple data encryption standard. The organization of\npipeline stages in such a way that pipeline can be clocked at high frequency.\nEncryption and Decryption blocks of triple data encryption standard (T-DES)\ncrypto system and dependency among themselves are explained in detail with the\nhelp of block diagram. In order to increase the processor functionality and\nperformance, especially for security applications we include three new 32-bit\ninstructions LKLW, LKUW and CRYPT. The design has been synthesized at 40nm\nprocess technology targeting using Xilinx Virtex-6 device. The overall MIPS\nCrypto processor works at 209MHz."
},{
    "category": "cs.AR", 
    "doi": "10.1049/el.2014.4432", 
    "link": "http://arxiv.org/pdf/1503.03169v1", 
    "title": "Dynamic Partitioning of Physical Memory Among Virtual Machines,   ASMI:Architectural Support for Memory Isolation", 
    "arxiv-id": "1503.03169v1", 
    "author": "Priya Chandran", 
    "publish": "2015-03-10T09:38:51Z", 
    "summary": "Cloud computing relies on secure and efficient virtualization. Software level\nsecurity solutions compromise the performance of virtual machines (VMs), as a\nlarge amount of computational power would be utilized for running the security\nmodules. Moreover, software solutions are only as secure as the level that they\nwork on. For example a security module on a hypervisor cannot provide security\nin the presence of an infected hypervisor. It is a challenge for virtualization\ntechnology architects to enhance the security of VMs without degrading their\nperformance. Currently available server machines are not fully equipped to\nsupport a secure VM environment without compromising on performance. A few\nhardware modifications have been introduced by manufactures like Intel and AMD\nto provide a secure VM environment with low performance degradation. In this\npaper we propose a novel memory architecture model named \\textit{ Architectural\nSupport for Memory Isolation(ASMI)}, that can achieve a true isolated physical\nmemory region to each VM without degrading performance. Along with true memory\nisolation, ASMI is designed to provide lower memory access times, better\nutilization of available memory, support for DMA isolation and support for\nplatform independence for users of VMs."
},{
    "category": "cs.AR", 
    "doi": "10.1049/el.2014.4432", 
    "link": "http://arxiv.org/pdf/1503.04628v1", 
    "title": "Logic BIST: State-of-the-Art and Open Problems", 
    "arxiv-id": "1503.04628v1", 
    "author": "Kim Petersen", 
    "publish": "2015-03-16T12:45:04Z", 
    "summary": "Many believe that in-field hardware faults are too rare in practice to\njustify the need for Logic Built-In Self-Test (LBIST) in a design. Until now,\nLBIST was primarily used in safety-critical applications. However, this may\nchange soon. First, even if costly methods like burn-in are applied, it is no\nlonger possible to get rid of all latent defects in devices at leading-edge\ntechnology. Second, demands for high reliability spread to consumer electronics\nas smartphones replace our wallets and IDs. However, today many ASIC vendors\nare reluctant to use LBIST. In this paper, we describe the needs for successful\ndeployment of LBIST in the industrial practice and discuss how these needs can\nbe addressed. Our work is hoped to attract a wider attention to this important\nresearch topic."
},{
    "category": "cs.AR", 
    "doi": "10.1049/el.2014.4432", 
    "link": "http://arxiv.org/pdf/1503.05694v2", 
    "title": "Improving GPU Performance Through Resource Sharing", 
    "arxiv-id": "1503.05694v2", 
    "author": "Amey Karkare", 
    "publish": "2015-03-19T10:21:42Z", 
    "summary": "Graphics Processing Units (GPUs) consisting of Streaming Multiprocessors\n(SMs) achieve high throughput by running a large number of threads and context\nswitching among them to hide execution latencies. The number of thread blocks,\nand hence the number of threads that can be launched on an SM, depends on the\nresource usage--e.g. number of registers, amount of shared memory--of the\nthread blocks. Since the allocation of threads to an SM is at the thread block\ngranularity, some of the resources may not be used up completely and hence will\nbe wasted.\n  We propose an approach that shares the resources of SM to utilize the wasted\nresources by launching more thread blocks. We show the effectiveness of our\napproach for two resources: register sharing, and scratchpad (shared memory)\nsharing. We further propose optimizations to hide long execution latencies,\nthus reducing the number of stall cycles. We implemented our approach in\nGPGPU-Sim simulator and experimentally validated it on several applications\nfrom 4 different benchmark suites: GPGPU-Sim, Rodinia, CUDA-SDK, and Parboil.\nWe observed that with register sharing, applications show maximum improvement\nof 24%, and average improvement of 11%. With scratchpad sharing, we observed a\nmaximum improvement of 30% and an average improvement of 12.5%."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICASSP.2015.7178128", 
    "link": "http://arxiv.org/pdf/1504.03437v1", 
    "title": "Low-latency List Decoding Of Polar Codes With Double Thresholding", 
    "arxiv-id": "1504.03437v1", 
    "author": "Bin Li", 
    "publish": "2015-04-14T07:12:24Z", 
    "summary": "For polar codes with short-to-medium code length, list successive\ncancellation decoding is used to achieve a good error-correcting performance.\nHowever, list pruning in the current list decoding is based on the sorting\nstrategy and its timing complexity is high. This results in a long decoding\nlatency for large list size. In this work, aiming at a low-latency list\ndecoding implementation, a double thresholding algorithm is proposed for a fast\nlist pruning. As a result, with a negligible performance degradation, the list\npruning delay is greatly reduced. Based on the double thresholding, a\nlow-latency list decoding architecture is proposed and implemented using a UMC\n90nm CMOS technology. Synthesis results show that, even for a large list size\nof 16, the proposed low-latency architecture achieves a decoding throughput of\n220 Mbps at a frequency of 641 MHz."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICASSP.2015.7178128", 
    "link": "http://arxiv.org/pdf/1504.04297v1", 
    "title": "MigrantStore: Leveraging Virtual Memory in DRAM-PCM Memory Architecture", 
    "arxiv-id": "1504.04297v1", 
    "author": "T. N. Vijaykumar", 
    "publish": "2015-04-16T16:36:14Z", 
    "summary": "With the imminent slowing down of DRAM scaling, Phase Change Memory (PCM) is\nemerging as a lead alternative for main memory technology. While PCM achieves\nlow energy due to various technology-specific advantages, PCM is significantly\nslower than DRAM (especially for writes) and can endure far fewer writes before\nwearing out. Previous work has proposed to use a large, DRAM-based hardware\ncache to absorb writes and provide faster access. However, due to ineffectual\ncaching where blocks are evicted before sufficient number of accesses, hardware\ncaches incur significant overheads in energy and bandwidth, two key but scarce\nresources in modern multicores. Because using hardware for detecting and\nremoving such ineffectual caching would incur additional hardware cost and\ncomplexity, we leverage the OS virtual memory support for this purpose. We\npropose a DRAM-PCM hybrid memory architecture where the OS migrates pages on\ndemand from the PCM to DRAM. We call the DRAM part of our memory as\nMigrantStore which includes two ideas. First, to reduce the energy, bandwidth,\nand wear overhead of ineffectual migrations, we propose migration hysteresis.\nSecond, to reduce the software overhead of good replacement policies, we\npropose recently- accessed-page-id (RAPid) buffer, a hardware buffer to track\nthe addresses of recently-accessed MigrantStore pages."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICASSP.2015.7178128", 
    "link": "http://arxiv.org/pdf/1504.04586v1", 
    "title": "A Reconfigurable Vector Instruction Processor for Accelerating a   Convection Parametrization Model on FPGAs", 
    "arxiv-id": "1504.04586v1", 
    "author": "Wim Vanderbauwhede", 
    "publish": "2015-04-17T17:27:27Z", 
    "summary": "High Performance Computing (HPC) platforms allow scientists to model\ncomputationally intensive algorithms. HPC clusters increasingly use\nGeneral-Purpose Graphics Processing Units (GPGPUs) as accelerators; FPGAs\nprovide an attractive alternative to GPGPUs for use as co-processors, but they\nare still far from being mainstream due to a number of challenges faced when\nusing FPGA-based platforms. Our research aims to make FPGA-based high\nperformance computing more accessible to the scientific community. In this work\nwe present the results of investigating the acceleration of a particular\natmospheric model, Flexpart, on FPGAs. We focus on accelerating the most\ncomputationally intensive kernel from this model. The key contribution of our\nwork is the architectural exploration we undertook to arrive at a solution that\nbest exploits the parallelism available in the legacy code, and is also\nconvenient to program, so that eventually the compilation of high-level legacy\ncode to our architecture can be fully automated. We present the three different\ntypes of architecture, comparing their resource utilization and performance,\nand propose that an architecture where there are a number of computational\ncores, each built along the lines of a vector instruction processor, works best\nin this particular scenario, and is a promising candidate for a generic\nFPGA-based platform for scientific computation. We also present the results of\nexperiments done with various configuration parameters of the proposed\narchitecture, to show its utility in adapting to a range of scientific\napplications."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TCSI.2016.2586218", 
    "link": "http://arxiv.org/pdf/1505.01459v2", 
    "title": "Multi-mode Unrolled Architectures for Polar Decoders", 
    "arxiv-id": "1505.01459v2", 
    "author": "Warren J. Gross", 
    "publish": "2015-05-06T19:00:56Z", 
    "summary": "In this work, we present a family of architectures for polar decoders using a\nreduced-complexity successive-cancellation decoding algorithm that employs\nunrolling to achieve extremely high throughput values while retaining moderate\nimplementation complexity. The resulting fully-unrolled, deeply-pipelined\narchitecture is capable of achieving a coded throughput in excess of 1 Tbps on\na 65 nm ASIC at 500 MHz---three orders of magnitude greater than current\nstate-of-the-art polar decoders. However, unrolled decoders are built for a\nspecific, fixed code. Therefore we also present a new method to enable the use\nof multiple code lengths and rates in a fully-unrolled polar decoder\narchitecture. This method leads to a length- and rate-flexible decoder while\nretaining the very high speed typical to unrolled decoders. The resulting\ndecoders can decode a master polar code of a given rate and length, and several\nshorter codes of different rates and lengths. We present results for two\nversions of a multi-mode decoder supporting eight and ten different polar\ncodes, respectively. Both are capable of a peak throughput of 25.6 Gbps. For\neach decoder, the energy efficiency for the longest supported polar code is\nshown to be of 14.8 pJ/bit at 250 MHz and of 8.8 pJ/bit at 500 MHz."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TCSI.2016.2586218", 
    "link": "http://arxiv.org/pdf/1505.03476v1", 
    "title": "Twin-Load: Building a Scalable Memory System over the Non-Scalable   Interface", 
    "arxiv-id": "1505.03476v1", 
    "author": "Mingyu Chen", 
    "publish": "2015-05-13T17:54:15Z", 
    "summary": "Commodity memory interfaces have difficulty in scaling memory capacity to\nmeet the needs of modern multicore and big data systems. DRAM device density\nand maximum device count are constrained by technology, package, and signal in-\ntegrity issues that limit total memory capacity. Synchronous DRAM protocols\nrequire data to be returned within a fixed latency, and thus memory extension\nmethods over commodity DDRx interfaces fail to support scalable topologies.\nCurrent extension approaches either use slow PCIe interfaces, or require\nexpensive changes to the memory interface, which limits commercial\nadoptability. Here we propose twin-load, a lightweight asynchronous memory\naccess mechanism over the synchronous DDRx interface. Twin-load uses two\nspecial loads to accomplish one access request to extended memory, the first\nserves as a prefetch command to the DRAM system, and the second asynchronously\ngets the required data. Twin-load requires no hardware changes on the processor\nside and only slight soft- ware modifications. We emulate this system on a\nprototype to demonstrate the feasibility of our approach. Twin-load has\ncomparable performance to NUMA extended memory and outperforms a page-swapping\nPCIe-based system by several orders of magnitude. Twin-load thus enables\ninstant capacity increases on commodity platforms, but more importantly, our\narchitecture opens opportunities for the design of novel, efficient, scalable,\ncost-effective memory subsystems."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TCSI.2016.2586218", 
    "link": "http://arxiv.org/pdf/1505.03899v1", 
    "title": "An Approach to Data Prefetching Using 2-Dimensional Selection Criteria", 
    "arxiv-id": "1505.03899v1", 
    "author": "Josef Spjut", 
    "publish": "2015-05-14T21:57:26Z", 
    "summary": "We propose an approach to data memory prefetching which augments the standard\nprefetch buffer with selection criteria based on performance and usage pattern\nof a given instruction. This approach is built on top of a pattern matching\nbased prefetcher, specifically one which can choose between a stream, a stride,\nor a stream followed by a stride. We track the most recently called\ninstructions to make a decision on the quantity of data to prefetch next. The\ndecision is based on the frequency with which these instructions are called and\nthe hit/miss rate of the prefetcher. In our approach, we separate the amount of\ndata to prefetch into three categories: a high degree, a standard degree and a\nlow degree. We ran tests on different values for the high prefetch degree,\nstandard prefetch degree and low prefetch degree to determine that the most\noptimal combination was 1, 4, 8 lines respectively. The 2 dimensional selection\ncriteria improved the performance of the prefetcher by up to 9.5% over the\nfirst data prefetching championship winner. Unfortunately performance also fell\nby as much as 14%, but remained similar on average across all of the benchmarks\nwe tested."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TCSI.2016.2586218", 
    "link": "http://arxiv.org/pdf/1505.04339v1", 
    "title": "A 2.48Gb/s QC-LDPC Decoder Implementation on the NI USRP-2953R", 
    "arxiv-id": "1505.04339v1", 
    "author": "Predrag Spasojevic", 
    "publish": "2015-05-16T23:32:40Z", 
    "summary": "The increasing data rates expected to be of the order of Gb/s for future\nwireless systems directly impact the throughput requirements of the modulation\nand coding subsystems of the physical layer. In an effort to design a suitable\nchannel coding solution for 5G wireless systems, in this brief we present a\nmassively-parallel 2.48Gb/s Quasi-Cyclic Low-Density Parity-Check (QC-LDPC)\ndecoder implementation operating at 200MHz on the NI USRP-2953R, on a single\nFPGA. The high-level description of the entire massively-parallel decoder was\ntranslated to a Hardware Description Language (HDL), namely VHDL, using the\nalgorithmic compiler in the National Instruments LabVIEW Communication System\nDesign Suite (CSDS) in approximately 2 minutes. This implementation not only\ndemonstrates the scalability of our decoder architecture but also, the rapid\nprototyping capability of the LabVIEW CSDS tools. As per our knowledge, at the\ntime of writing this paper, this is the fastest implementation of a standard\ncompliant QC-LDPC decoder on a USRP using an algorithmic compiler."
},{
    "category": "cs.AR", 
    "doi": "10.1088/1742-6596/664/8/082049", 
    "link": "http://arxiv.org/pdf/1505.04569v1", 
    "title": "High speed fault tolerant secure communication for muon chamber using   fpga based gbt emulator", 
    "arxiv-id": "1505.04569v1", 
    "author": "Subhasis Chattopadhyay", 
    "publish": "2015-05-18T09:32:11Z", 
    "summary": "The Compressed Baryonic Matter (CBM) experiment is a part of the Facility for\nAntiproton and Ion Research (FAIR) in Darmstadt at the GSI. The CBM experiment\nwill investigate the highly compressed nuclear matter using nucleus-nucleus\ncollisions. This experiment will examine heavy-ion collisions in fixed target\ngeometry and will be able to measure hadrons, electrons and muons. CBM requires\nprecise time synchronization, compact hardware, radiation tolerance,\nself-triggered front-end electronics, efficient data aggregation schemes and\ncapability to handle high data rate (up to several TB/s). As a part of the\nimplementation of read out chain of MUCH in India, we have tried to implement\nFPGA based emulator of GBTx in India. GBTx is a radiation tolerant ASIC that\ncan be used to implement multipurpose high speed bidirectional optical links\nfor high-energy physics (HEP) experiments and is developed by CERN. GBTx will\nbe used in highly irradiated area and more prone to be affected by multi bit\nerror. To mitigate this effect instead of single bit error correcting RS code\nwe have used two bit error correcting (15, 7) BCH code. It will increase the\nredundancy which in turn increases the reliability of the coded data. So the\ncoded data will be less prone to be affected by noise due to radiation. Data\nwill go from detector to PC through multiple nodes through the communication\nchannel. In order to make the data communication secure, advanced encryption\nstandard (AES - a symmetric key cryptography) and RSA (asymmetric key\ncryptography) are used after the channel coding."
},{
    "category": "cs.AR", 
    "doi": "10.1088/1742-6596/664/8/082049", 
    "link": "http://arxiv.org/pdf/1505.07502v1", 
    "title": "SQUASH: Simple QoS-Aware High-Performance Memory Scheduler for   Heterogeneous Systems with Hardware Accelerators", 
    "arxiv-id": "1505.07502v1", 
    "author": "Onur Mutlu", 
    "publish": "2015-05-27T22:07:28Z", 
    "summary": "Modern SoCs integrate multiple CPU cores and Hardware Accelerators (HWAs)\nthat share the same main memory system, causing interference among memory\nrequests from different agents. The result of this interference, if not\ncontrolled well, is missed deadlines for HWAs and low CPU performance.\nState-of-the-art mechanisms designed for CPU-GPU systems strive to meet a\ntarget frame rate for GPUs by prioritizing the GPU close to the time when it\nhas to complete a frame. We observe two major problems when such an approach is\nadapted to a heterogeneous CPU-HWA system. First, HWAs miss deadlines because\nthey are prioritized only close to their deadlines. Second, such an approach\ndoes not consider the diverse memory access characteristics of different\napplications running on CPUs and HWAs, leading to low performance for\nlatency-sensitive CPU applications and deadline misses for some HWAs, including\nGPUs.\n  In this paper, we propose a Simple Quality of service Aware memory Scheduler\nfor Heterogeneous systems (SQUASH), that overcomes these problems using three\nkey ideas, with the goal of meeting deadlines of HWAs while providing high CPU\nperformance. First, SQUASH prioritizes a HWA when it is not on track to meet\nits deadline any time during a deadline period. Second, SQUASH prioritizes HWAs\nover memory-intensive CPU applications based on the observation that the\nperformance of memory-intensive applications is not sensitive to memory\nlatency. Third, SQUASH treats short-deadline HWAs differently as they are more\nlikely to miss their deadlines and schedules their requests based on worst-case\nmemory access time estimates.\n  Extensive evaluations across a wide variety of different workloads and\nsystems show that SQUASH achieves significantly better CPU performance than the\nbest previous scheduler while always meeting the deadlines for all HWAs,\nincluding GPUs, thereby largely improving frame rates."
},{
    "category": "cs.AR", 
    "doi": "10.1088/1742-6596/664/8/082049", 
    "link": "http://arxiv.org/pdf/1506.03160v1", 
    "title": "Simultaneous Multi Layer Access: A High Bandwidth and Low Cost   3D-Stacked Memory Interface", 
    "arxiv-id": "1506.03160v1", 
    "author": "Onur Mutlu", 
    "publish": "2015-06-10T04:14:29Z", 
    "summary": "Limited memory bandwidth is a critical bottleneck in modern systems.\n3D-stacked DRAM enables higher bandwidth by leveraging wider\nThrough-Silicon-Via (TSV) channels, but today's systems cannot fully exploit\nthem due to the limited internal bandwidth of DRAM. DRAM reads a whole row\nsimultaneously from the cell array to a row buffer, but can transfer only a\nfraction of the data from the row buffer to peripheral IO circuit, through a\nlimited and expensive set of wires referred to as global bitlines. In presence\nof wider memory channels, the major bottleneck becomes the limited data\ntransfer capacity through these global bitlines. Our goal in this work is to\nenable higher bandwidth in 3D-stacked DRAM without the increased cost of adding\nmore global bitlines. We instead exploit otherwise-idle resources, such as\nglobal bitlines, already existing within the multiple DRAM layers by accessing\nthe layers simultaneously. Our architecture, Simultaneous Multi Layer Access\n(SMLA), provides higher bandwidth by aggregating the internal bandwidth of\nmultiple layers and transferring the available data at a higher IO frequency.\n  To implement SMLA, simultaneous data transfer from multiple layers through\nthe same IO TSVs requires coordination between layers to avoid channel\nconflict. We first study coordination by static partitioning, which we call\nDedicated-IO, that assigns groups of TSVs to each layer. We then provide a\nsimple, yet sophisticated mechanism, called Cascaded-IO, which enables\nsimultaneous access to each layer by time-multiplexing the IOs. By operating at\na frequency proportional to the number of layers, SMLA provides a higher\nbandwidth (4X for a four-layer stacked DRAM). Our evaluations show that SMLA\nprovides significant performance improvement and energy reduction (55%/18% on\naverage for multi-programmed workloads, respectively) over a baseline\n3D-stacked DRAM with very low area overhead."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2010.5457153", 
    "link": "http://arxiv.org/pdf/1506.03181v2", 
    "title": "DEW: A Fast Level 1 Cache Simulation Approach for Embedded Processors   with FIFO Replacement Policy", 
    "arxiv-id": "1506.03181v2", 
    "author": "Sri Parameswaran", 
    "publish": "2015-06-10T06:14:33Z", 
    "summary": "Increasing the speed of cache simulation to obtain hit/miss rates en- ables\nperformance estimation, cache exploration for embedded sys- tems and energy\nestimation. Previously, such simulations, particu- larly exact approaches, have\nbeen exclusively for caches which uti- lize the least recently used (LRU)\nreplacement policy. In this paper, we propose a new, fast and exact cache\nsimulation method for the First In First Out(FIFO) replacement policy. This\nmethod, called DEW, is able to simulate multiple level 1 cache configurations\n(dif- ferent set sizes, associativities, and block sizes) with FIFO replace-\nment policy. DEW utilizes a binomial tree based representation of cache\nconfigurations and a novel searching method to speed up sim- ulation over\nsingle cache simulators like Dinero IV. Depending on different cache block\nsizes and benchmark applications, DEW oper- ates around 8 to 40 times faster\nthan Dinero IV. Dinero IV compares 2.17 to 19.42 times more cache ways than DEW\nto determine accu- rate miss rates."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASPDAC.2013.6509615", 
    "link": "http://arxiv.org/pdf/1506.03182v2", 
    "title": "TRISHUL: A Single-pass Optimal Two-level Inclusive Data Cache Hierarchy   Selection Process for Real-time MPSoCs", 
    "arxiv-id": "1506.03182v2", 
    "author": "Shaobo Luo", 
    "publish": "2015-06-10T06:26:02Z", 
    "summary": "Hitherto discovered approaches analyze the execution time of a real time\napplication on all the possible cache hierarchy setups to find the application\nspecific optimal two level inclusive data cache hierarchy to reduce cost, space\nand energy consumption while satisfying the time deadline in real time\nMultiprocessor Systems on Chip. These brute force like approaches can take\nyears to complete. Alternatively, memory access trace driven crude estimation\nmethods can find a cache hierarchy quickly by compromising the accuracy of\nresults. In this article, for the first time, we propose a fast and accurate\ntrace driven approach to find the optimal real time application specific two\nlevel inclusive data cache hierarchy. Our proposed approach TRISHUL predicts\nthe optimal cache hierarchy performance first and then utilizes that\ninformation to find the optimal cache hierarchy quickly. TRISHUL can suggest a\ncache hierarchy, which has up to 128 times smaller size, up to 7 times faster\ncompared to the suggestion of the state of the art crude trace driven two level\ninclusive cache hierarchy selection approach for the application traces\nanalyzed."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICCAD.2011.6105316", 
    "link": "http://arxiv.org/pdf/1506.03186v2", 
    "title": "CIPARSim: Cache Intersection Property Assisted Rapid Single-pass FIFO   Cache Simulation Technique", 
    "arxiv-id": "1506.03186v2", 
    "author": "Sri Parameswaran", 
    "publish": "2015-06-10T06:57:55Z", 
    "summary": "In this paper, for the first time, we introduce a cache property called the\nIntersection Property that helps to reduce singlepass simulation time in a\nmanner similar to inclusion property. An intersection property defines\nconditions that if met, prove a particular element exists in larger caches,\nthus avoiding further search time. We have discussed three such intersection\nproperties for caches using the FIFO replacement policy in this paper. A rapid\nsinglepass FIFO cache simulator CIPARSim has also been proposed. CIPARSim is\nthe first singlepass simulator dependent on the FIFO cache properties to reduce\nsimulation time significantly. CIPARSim simulation time was up to 5 times\nfaster compared to the state of the art singlepass FIFO cache simulator for the\ncache configurations tested. CIPARSim produces the cache hit and miss rates of\nan application accurately on various cache configurations. During simulation,\nCIPARSim intersection properties alone predict up to 90% of the total hits,\nreducing simulationtime immensely"
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASPDAC.2015.7059045", 
    "link": "http://arxiv.org/pdf/1506.03193v2", 
    "title": "Accelerating Non-volatile/Hybrid Processor Cache Design Space   Exploration for Application Specific Embedded Systems", 
    "arxiv-id": "1506.03193v2", 
    "author": "Qingsong Wei", 
    "publish": "2015-06-10T07:14:45Z", 
    "summary": "In this article, we propose a technique to accelerate nonvolatile or hybrid\nof volatile and nonvolatile processor cache design space exploration for\napplication specific embedded systems. Utilizing a novel cache behavior\nmodeling equation and a new accurate cache miss prediction mechanism, our\nproposed technique can accelerate NVM or hybrid FIFO processor cache design\nspace exploration for SPEC CPU 2000 applications up to 249 times compared to\nthe conventional approach."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASPDAC.2015.7059045", 
    "link": "http://arxiv.org/pdf/1507.01777v1", 
    "title": "FPGA based Novel High Speed DAQ System Design with Error Correction", 
    "arxiv-id": "1507.01777v1", 
    "author": "Subhasish Chattopadhyay", 
    "publish": "2015-07-07T12:24:25Z", 
    "summary": "Present state of the art applications in the area of high energy physics\nexperiments (HEP), radar communication, satellite communication and bio medical\ninstrumentation require fault resilient data acquisition (DAQ) system with the\ndata rate in the order of Gbps. In order to keep the high speed DAQ system\nfunctional in such radiation environment where direct intervention of human is\nnot possible, a robust and error free communication system is necessary. In\nthis work we present an efficient DAQ design and its implementation on field\nprogrammable gate array (FPGA). The proposed DAQ system supports high speed\ndata communication (~4.8 Gbps) and achieves multi-bit error correction\ncapabilities. BCH code (named after Raj Bose and D. K. RayChaudhuri) has been\nused for multi-bit error correction. The design has been implemented on Xilinx\nKintex-7 board and is tested for board to board communication as well as for\nboard to PC using PCIe (Peripheral Component Interconnect express) interface.\nTo the best of our knowledge, the proposed FPGA based high speed DAQ system\nutilizing optical link and multi-bit error resiliency can be considered first\nof its kind. Performance estimation of the implemented DAQ system is done based\non resource utilization, critical path delay, efficiency and bit error rate\n(BER)."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASPDAC.2015.7059045", 
    "link": "http://arxiv.org/pdf/1507.03303v1", 
    "title": "Managing Hybrid Main Memories with a Page-Utility Driven Performance   Model", 
    "arxiv-id": "1507.03303v1", 
    "author": "Onur Mutlu", 
    "publish": "2015-07-13T01:47:16Z", 
    "summary": "Hybrid memory systems comprised of dynamic random access memory (DRAM) and\nnon-volatile memory (NVM) have been proposed to exploit both the capacity\nadvantage of NVM and the latency and dynamic energy advantages of DRAM. An\nimportant problem for such systems is how to place data between DRAM and NVM to\nimprove system performance.\n  In this paper, we devise the first mechanism, called UBM (page Utility Based\nhybrid Memory management), that systematically estimates the system performance\nbenefit of placing a page in DRAM versus NVM and uses this estimate to guide\ndata placement. UBM's estimation method consists of two major components.\nFirst, it estimates how much an application's stall time can be reduced if the\naccessed page is placed in DRAM. To do this, UBM comprehensively considers\naccess frequency, row buffer locality, and memory level parallelism (MLP) to\nestimate the application's stall time reduction. Second, UBM estimates how much\neach application's stall time reduction contributes to overall system\nperformance. Based on this estimation method, UBM can determine and place the\nmost critical data in DRAM to directly optimize system performance.\nExperimental results show that UBM improves system performance by 14% on\naverage (and up to 39%) compared to the best of three state-of-the-art\nmechanisms for a large number of data-intensive workloads from the SPEC CPU2006\nand Yahoo Cloud Serving Benchmark (YCSB) suites."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASPDAC.2015.7059045", 
    "link": "http://arxiv.org/pdf/1508.06811v1", 
    "title": "Model-based Hardware Design for FPGAs using Folding Transformations   based on Subcircuits", 
    "arxiv-id": "1508.06811v1", 
    "author": "Peter Zipf", 
    "publish": "2015-08-27T11:37:36Z", 
    "summary": "We present a tool flow and results for a model-based hardware design for\nFPGAs from Simulink descriptions which nicely integrates into existing\nenvironments. While current commercial tools do not exploit some high-level\noptimizations, we investigate the promising approach of using reusable\nsubcircuits for folding transformations to control embedded multiplier usage\nand to optimize logic block usage. We show that resource improvements of up to\n70% compared to the original model are possible, but it is also shown that\nsubcircuit selection is a critical task. While our tool flow provides good\nresults already, the investigation and optimization of subcircuit selection is\nclearly identified as an additional keypoint to extend high-level control on\nlow-level FPGA mapping properties."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASPDAC.2015.7059045", 
    "link": "http://arxiv.org/pdf/1508.06832v1", 
    "title": "Designing Hardware/Software Systems for Embedded High-Performance   Computing", 
    "arxiv-id": "1508.06832v1", 
    "author": "Hor\u00e1cio C. Neto", 
    "publish": "2015-08-27T12:44:22Z", 
    "summary": "In this work, we propose an architecture and methodology to design\nhardware/software systems for high-performance embedded computing on FPGA. The\nhardware side is based on a many-core architecture whose design is generated\nautomatically given a set of architectural parameters. Both the architecture\nand the methodology were evaluated running dense matrix multiplication and\nsparse matrix-vector multiplication on a ZYNQ-7020 FPGA platform. The results\nshow that using a system-level design of the system avoids complex hardware\ndesign and still provides good performance results."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASPDAC.2015.7059045", 
    "link": "http://arxiv.org/pdf/1508.07139v1", 
    "title": "Using System Hyper Pipelining (SHP) to Improve the Performance of a   Coarse-Grained Reconfigurable Architecture (CGRA) Mapped on an FPGA", 
    "arxiv-id": "1508.07139v1", 
    "author": "Tobias Strauch", 
    "publish": "2015-08-28T09:19:57Z", 
    "summary": "The well known method C-Slow Retiming (CSR) can be used to automatically\nconvert a given CPU into a multithreaded CPU with independent threads. These\nCPUs are then called streaming or barrel processors. System Hyper Pipelining\n(SHP) adds a new flexibility on top of CSR by allowing a dynamic number of\nthreads to be executed and by enabling the threads to be stalled, bypassed and\nreordered. SHP is now applied on the programming elements (PE) of a\ncoarse-grained reconfigurable architecture (CGRA). By using SHP, more\nperformance can be achieved per PE. Fork-Join operations can be implemented on\na PE using the flexibility provided by SHP to dynamically adjust the number of\nthreads per PE. Multiple threads can share the same data locally, which greatly\nreduces the data traffic load on the CGRA's routing structure. The paper shows\nthe results of a CGRA using SHP-ed RISC-V cores as PEs implemented on a FPGA."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASPDAC.2015.7059045", 
    "link": "http://arxiv.org/pdf/1509.03575v1", 
    "title": "FPGA Implementation of High Speed Baugh-Wooley Multiplier using   Decomposition Logic", 
    "arxiv-id": "1509.03575v1", 
    "author": "Navdeep Prashar", 
    "publish": "2015-09-11T16:20:07Z", 
    "summary": "The Baugh-Wooley algorithm is a well-known iterative algorithm for performing\nmultiplication in digital signal processing applications. Decomposition logic\nis used with Baugh-Wooley algorithm to enhance the speed and to reduce the\ncritical path delay. In this paper a high speed multiplier is designed and\nimplemented using decomposition logic and Baugh-Wooley algorithm. The result is\ncompared with booth multiplier. FPGA based architecture is presented and design\nhas been implemented using Xilinx 12.3 device."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASPDAC.2015.7059045", 
    "link": "http://arxiv.org/pdf/1509.03721v1", 
    "title": "DReAM: Dynamic Re-arrangement of Address Mapping to Improve the   Performance of DRAMs", 
    "arxiv-id": "1509.03721v1", 
    "author": "Mikel Luj\u00e1n", 
    "publish": "2015-09-12T08:02:39Z", 
    "summary": "The initial location of data in DRAMs is determined and controlled by the\n'address-mapping' and even modern memory controllers use a fixed and\nrun-time-agnostic address mapping. On the other hand, the memory access pattern\nseen at the memory interface level will dynamically change at run-time. This\ndynamic nature of memory access pattern and the fixed behavior of address\nmapping process in DRAM controllers, implied by using a fixed address mapping\nscheme, means that DRAM performance cannot be exploited efficiently. DReAM is a\nnovel hardware technique that can detect a workload-specific address mapping at\nrun-time based on the application access pattern which improves the performance\nof DRAMs. The experimental results show that DReAM outperforms the best\nevaluated address mapping on average by 9%, for mapping-sensitive workloads, by\n2% for mapping-insensitive workloads, and up to 28% across all the workloads.\nDReAM can be seen as an insurance policy capable of detecting which scenarios\nare not well served by the predefined address mapping."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASPDAC.2015.7059045", 
    "link": "http://arxiv.org/pdf/1509.03740v1", 
    "title": "HAPPY: Hybrid Address-based Page Policy in DRAMs", 
    "arxiv-id": "1509.03740v1", 
    "author": "Mikel Luj\u00e1n", 
    "publish": "2015-09-12T13:03:04Z", 
    "summary": "Memory controllers have used static page closure policies to decide whether a\nrow should be left open, open-page policy, or closed immediately, close-page\npolicy, after the row has been accessed. The appropriate choice for a\nparticular access can reduce the average memory latency. However, since\napplication access patterns change at run time, static page policies cannot\nguarantee to deliver optimum execution time. Hybrid page policies have been\ninvestigated as a means of covering these dynamic scenarios and are now\nimplemented in state-of-the-art processors. Hybrid page policies switch between\nopen-page and close-page policies while the application is running, by\nmonitoring the access pattern of row hits/conflicts and predicting future\nbehavior. Unfortunately, as the size of DRAM memory increases, fine-grain\ntracking and analysis of memory access patterns does not remain practical. We\npropose a compact memory address-based encoding technique which can improve or\nmaintain the performance of DRAMs page closure predictors while reducing the\nhardware overhead in comparison with state-of-the-art techniques. As a case\nstudy, we integrate our technique, HAPPY, with a state-of-the-art monitor, the\nIntel-adaptive open-page policy predictor employed by the Intel Xeon X5650, and\na traditional Hybrid page policy. We evaluate them across 70 memory intensive\nworkload mixes consisting of single-thread and multi-thread applications. The\nexperimental results show that using the HAPPY encoding applied to the\nIntel-adaptive page closure policy can reduce the hardware overhead by 5X for\nthe evaluated 64 GB memory (up to 40X for a 512 GB memory) while maintaining\nthe prediction accuracy."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASPDAC.2015.7059045", 
    "link": "http://arxiv.org/pdf/1509.04268v1", 
    "title": "High Speed VLSI Architecture for 3-D Discrete Wavelet Transform", 
    "arxiv-id": "1509.04268v1", 
    "author": "Indrajit Chakrabarti", 
    "publish": "2015-09-14T03:46:00Z", 
    "summary": "This paper presents a memory efficient, high throughput parallel lifting\nbased running three dimensional discrete wavelet transform (3-D DWT)\narchitecture. 3-D DWT is constructed by combining the two spatial and four\ntemporal processors. Spatial processor (SP) apply the two dimensional DWT on a\nframe, using lifting based 9/7 filter bank through the row rocessor (RP) in row\ndirection and then apply in the colum direction through column processor (CP).\nTo reduce the temporal memory and the latency, the temporal processor (TP) has\nbeen designed with lifting based 1-D Haar wavelet filter. The proposed\narchitecture replaced the multiplications by pipeline shift-add operations to\nreduce the CPD. Two spatial processors works simultaneously on two adjacent\nframes and provide 2-D DWT coefficients as inputs to the temporal processors.\nTPs apply the one dimensional DWT in temporal direction and provide eight 3-D\nDWT coefficients per clock (throughput). Higher throughput reduces the\ncomputing cycles per frame and enable the lower power consumption.\nImplementation results shows that the proposed architecture has the advantage\nin reduced memory, low power consumption, low latency, and high throughput over\nthe existing designs. The RTL of the proposed architecture is described using\nverilog and synthesized using 90-nm technology CMOS standard cell library and\nresults show that it consumes 43.42 mW power and occupies an area equivalent to\n231.45 K equivalent gate at frequency of 200 MHz. The proposed architecture has\nalso been synthesised for the Xilinx zynq 7020 series field programmable gate\narray (FPGA)."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASPDAC.2015.7059045", 
    "link": "http://arxiv.org/pdf/1509.04618v1", 
    "title": "Cost Efficient Design of Reversible Adder Circuits for Low Power   Applications", 
    "arxiv-id": "1509.04618v1", 
    "author": "Amit Kumar", 
    "publish": "2015-09-11T16:38:57Z", 
    "summary": "A large amount of research is currently going on in the field of reversible\nlogic, which have low heat dissipation, low power consumption, which is the\nmain factor to apply reversible in digital VLSI circuit design. This paper\nintroduces reversible gate named as Inventive0 gate. The novel gate is\nsynthesis the efficient adder modules with minimum garbage output and gate\ncount. The Inventive0 gate capable of implementing a 4-bit ripple carry adder\nand carry skip adders.It is presented that Inventive0 gate is much more\nefficient and optimized approach as compared to their existing design, in terms\nof gate count, garbage outputs and constant inputs. In addition, some popular\navailable reversible gates are implemented in the MOS transistor design the\nimplementation kept in mind for minimum MOS transistor count and are completely\nreversible in behavior more precise forward and backward computation. Lesser\narchitectural complexity show that the novel designs are compact, fast as well\nas low power."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASPDAC.2015.7059045", 
    "link": "http://arxiv.org/pdf/1509.06891v1", 
    "title": "A Novel Method for Soft Error Mitigation in FPGA using Adaptive Cross   Parity Code", 
    "arxiv-id": "1509.06891v1", 
    "author": "Subhasis Chattopadhyay", 
    "publish": "2015-09-23T09:02:49Z", 
    "summary": "Field Programmable Gate Arrays (FPGAs) are more prone to be affected by\ntransient faults in presence of radiation and other environmental hazards\ncompared to Application Specific Integrated Circuits (ASICs). Hence, error\nmitigation and recovery techniques are absolutely necessary to protect the FPGA\nhardware from soft errors arising due to such transient faults. In this paper,\na new efficient multi-bit error correcting method for FPGAs is proposed using\nadaptive cross parity check (ACPC) code. ACPC is easy to implement and the\nneeded decoding circuit is also simple. In the proposed scheme total\nconfiguration memory is partitioned into two parts. One part will contain ACPC\nhardware, which is static and assumed to be unaffected by any kind of errors.\nOther portion will store the binary file for logic, which is to be protected\nfrom transient error and is assumed to be dynamically reconfigurable (Partial\nreconfigurable area). Binary file from the secondary memory passes through ACPC\nhardware and the bits for forward error correction (FEC) field are calculated\nbefore entering into the reconfigurable portion. In the runtime scenario, the\ndata from the dynamically reconfigurable portion of the configuration memory\nwill be read back and passed through the ACPC hardware. The ACPC hardware will\ncorrect the errors before the data enters into the dynamic configuration\nmemory. We propose a first of its kind methodology for novel transient fault\ncorrection using ACPC code for FPGAs. To validate the design we have tested the\nproposed methodology with Kintex FPGA. We have also measured different\nparameters like critical path, power consumption, overhead resource and error\ncorrection efficiency to estimate the performance of our proposed method."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ASPDAC.2015.7059045", 
    "link": "http://arxiv.org/pdf/1509.08111v3", 
    "title": "Automatic latency balancing in VHDL-implemented complex pipelined   systems", 
    "arxiv-id": "1509.08111v3", 
    "author": "Wojciech M. Zabolotny", 
    "publish": "2015-09-27T17:32:42Z", 
    "summary": "Balancing (equalization) of latency in parallel paths in the pipelined data\nprocessing system is an important problem. Without that the data from different\npaths arrive at the processing blocks in different clock cycles, and incorrect\nresults are produced. Manual correction of latencies is a tedious and\nerror-prone work. This paper presents an automatic method of latency\nequalization in systems described in VHDL. The method is based on simulation\nand is portable between different simulation and synthesis tools. The method\ndoes not increase the complexity of the synthesized design comparing to the\nsolution based on manual latency adjustment. The example implementation of the\nproposed methodology together with a simple design demonstrating its use is\navailable as an open source project under BSD license."
},{
    "category": "cs.AR", 
    "doi": "10.13140/RG.2.1.2435.6566", 
    "link": "http://arxiv.org/pdf/1509.09249v1", 
    "title": "In-Field Logic Repair of Deep Sub-Micron CMOS Processors", 
    "arxiv-id": "1509.09249v1", 
    "author": "Mark Zwolinski", 
    "publish": "2015-09-30T16:36:32Z", 
    "summary": "Ultra Deep-Sub-Micron CMOS chips have to function correctly and reliably, not\nonly during their early post-fabrication life, but also for their entire life\nspan. In this paper, we present an architectural-level in-field repair\ntechnique. The key idea is to trade area for reliability by adding repair\nfeatures to the system while keeping the power and the performance overheads as\nlow as possible. In the case of permanent faults, spare blocks will replace the\nfaulty blocks on the fly. Meanwhile by shutting down the main logic blocks,\npartial threshold voltage recovery can be achieved which will alleviate the\nageing-related delays and timing issues. The technique can avoid fatal\nshut-downs in the system and will decrease the down-time, hence the\navailability of such a system will be preserved. We have implemented the\nproposed idea on a pipelined processor core using a conventional ASIC design\nflow. The simulation results show that by tolerating about 70% area overhead\nand less than 18% power overhead we can dramatically increase the reliability\nand decrease the downtime of the processor."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TVLSI.2015.2499777", 
    "link": "http://arxiv.org/pdf/1510.02574v1", 
    "title": "A High Throughput List Decoder Architecture for Polar Codes", 
    "arxiv-id": "1510.02574v1", 
    "author": "Zhiyuan Yan", 
    "publish": "2015-10-09T06:11:34Z", 
    "summary": "While long polar codes can achieve the capacity of arbitrary binary-input\ndiscrete memoryless channels when decoded by a low complexity successive\ncancelation (SC) algorithm, the error performance of the SC algorithm is\ninferior for polar codes with finite block lengths. The cyclic redundancy check\n(CRC) aided successive cancelation list (SCL) decoding algorithm has better\nerror performance than the SC algorithm. However, current CRC aided SCL\n(CA-SCL) decoders still suffer from long decoding latency and limited\nthroughput. In this paper, a reduced latency list decoding (RLLD) algorithm for\npolar codes is proposed. Our RLLD algorithm performs the list decoding on a\nbinary tree, whose leaves correspond to the bits of a polar code. In existing\nSCL decoding algorithms, all the nodes in the tree are traversed and all\npossibilities of the information bits are considered. Instead, our RLLD\nalgorithm visits much fewer nodes in the tree and considers fewer possibilities\nof the information bits. When configured properly, our RLLD algorithm\nsignificantly reduces the decoding latency and hence improves throughput, while\nintroducing little performance degradation. Based on our RLLD algorithm, we\nalso propose a high throughput list decoder architecture, which is suitable for\nlarger block lengths due to its scalable partial sum computation unit. Our\ndecoder architecture has been implemented for different block lengths and list\nsizes using the TSMC 90nm CMOS technology. The implementation results\ndemonstrate that our decoders achieve significant latency reduction and area\nefficiency improvement compared with other list polar decoders in the\nliterature."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TVLSI.2015.2499777", 
    "link": "http://arxiv.org/pdf/1510.04241v1", 
    "title": "A Clock Synchronizer for Repeaterless Low Swing On-Chip Links", 
    "arxiv-id": "1510.04241v1", 
    "author": "Dinesh K. Sharma", 
    "publish": "2015-10-14T19:09:21Z", 
    "summary": "A clock synchronizing circuit for repeaterless low swing interconnects is\npresented in this paper. The circuit uses a delay locked loop (DLL) to generate\nmultiple phases of the clock, of which the one closest to the center of the eye\nis picked by a phase detector loop. The picked phase is then further fine tuned\nby an analog voltage controlled delay to position the sampling clock at the\ncenter of the eye. A clock domain transfer circuit then transfers the sampled\ndata to the receiver clock domain with a maximum latency of three clock cycles.\nThe proposed synchronizer has been designed and fabricated in 130 nm UMC MM\nCMOS technology. The circuit consumes 1.4 mW from a 1.2 V supply at a data rate\nof 1.3 Gbps. Further, the proposed synchronizer has been designed and simulated\nin TSMC 65 nm CMOS technology. Post layout simulations show that the\nsynchronizer consumes 1.5 mW from a 1 V supply, at a data rate of 4 Gbps in\nthis technology."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TVLSI.2015.2499777", 
    "link": "http://arxiv.org/pdf/1510.06791v1", 
    "title": "Network-on-Chip with load balancing based on interleave of flits   technique", 
    "arxiv-id": "1510.06791v1", 
    "author": "Marcelo Daniel Berejuck", 
    "publish": "2015-10-23T00:14:10Z", 
    "summary": "This paper presents the evaluation of a Network-on-Chip (NoC) that offers\nload balancing for Systems-on-Chip (SoCs) dedicated for multimedia applications\nthat require high traffic of variable bitrate communication. The NoC is based\non a technique that allows the interleaving of flits from diferente flows in\nthe same communication channel, and keep the load balancing without a\ncentralized control in the network. For this purpose, all flits in the network\nreceived extra bits, such that every flit carries routing information. The\nrouters use this extra information to perform arbitration and schedule the\nflits to the corresponding output ports. Analytic comparisons and experimental\ndata show that the approach adopted in the network keeps average latency lower\nfor variable bitrate flows than a network based on resource reservation when\nboth networks are working over 80% of offered load."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TVLSI.2015.2499777", 
    "link": "http://arxiv.org/pdf/1511.01946v1", 
    "title": "SecureD: A Secure Dual Core Embedded Processor", 
    "arxiv-id": "1511.01946v1", 
    "author": "Sri Parameswaran", 
    "publish": "2015-11-05T23:00:13Z", 
    "summary": "Security of embedded computing systems is becoming of paramount concern as\nthese devices become more ubiquitous, contain personal information and are\nincreasingly used for financial transactions. Security attacks targeting\nembedded systems illegally gain access to the information in these devices or\ndestroy information. The two most common types of attacks embedded systems\nencounter are code-injection and power analysis attacks. In the past, a number\nof countermeasures, both hardware- and software-based, were proposed\nindividually against these two types of attacks. However, no single system\nexists to counter both of these two prominent attacks in a processor based\nembedded system. Therefore, this paper, for the first time, proposes a\nhardware/software based countermeasure against both code-injection attacks and\npower analysis based side-channel attacks in a dual core embedded system. The\nproposed processor, named SecureD, has an area overhead of just 3.80% and an\naverage runtime increase of 20.0% when compared to a standard dual processing\nsystem. The overhead were measured using a set of industry standard application\nbenchmarks, with two encryption and five other programs."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TVLSI.2015.2499777", 
    "link": "http://arxiv.org/pdf/1511.06726v1", 
    "title": "Testable Design of Repeaterless Low Swing On-Chip Interconnect", 
    "arxiv-id": "1511.06726v1", 
    "author": "Dinesh K. Sharma", 
    "publish": "2015-11-20T19:10:00Z", 
    "summary": "Repeaterless low swing interconnects use mixed signal circuits to achieve\nhigh performance at low power. When these interconnects are used in large scale\nand high volume digital systems their testability becomes very important. This\npaper discusses the testability of low swing repeaterless on-chip interconnects\nwith equalization and clock synchronization. A capacitively coupled transmitter\nwith a weak driver is used as the transmitter. The receiver samples the low\nswing input data at the center of the data eye and converts it to rail to rail\nlevels and also synchronizes the data to the receiver's clock domain. The\nsystem is a mixed signal circuit and the digital components are all scan\ntestable. For the analog section, just a DC test has a fault coverage of 50% of\nthe structural faults. Simple techniques allow integration of the analog\ncomponents into the digital scan chain increasing the coverage to 74%. Finally,\na BIST with low overhead enhances the coverage to 95% of the structural faults.\nThe design and simulations have been done in UMC 130 nm CMOS technology."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TVLSI.2015.2499777", 
    "link": "http://arxiv.org/pdf/1511.08774v3", 
    "title": "Tardis 2.0: Optimized Time Traveling Coherence for Relaxed Consistency   Models", 
    "arxiv-id": "1511.08774v3", 
    "author": "Srinivas Devadas", 
    "publish": "2015-11-27T19:44:36Z", 
    "summary": "Cache coherence scalability is a big challenge in shared memory systems.\nTraditional protocols do not scale due to the storage and traffic overhead of\ncache invalidation. Tardis, a recently proposed coherence protocol, removes\ncache invalidation using logical timestamps and achieves excellent scalability.\nThe original Tardis protocol, however, only supports the Sequential Consistency\n(SC) memory model, limiting its applicability. Tardis also incurs extra network\ntraffic on some benchmarks due to renew messages, and has suboptimal\nperformance when the program uses spinning to communicate between threads.\n  In this paper, we address these downsides of Tardis protocol and make it\nsignificantly more practical. Specifically, we discuss the architectural,\nmemory system and protocol changes required in order to implement the TSO\nconsistency model on Tardis, and prove that the modified protocol satisfies\nTSO. We also describe modifications for Partial Store Order (PSO) and Release\nConsistency (RC). Finally, we propose optimizations for better leasing policies\nand to handle program spinning. On a set of benchmarks, optimized Tardis\nimproves on a full-map directory protocol in the metrics of performance,\nstorage and network traffic, while being simpler to implement."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TVLSI.2015.2499777", 
    "link": "http://arxiv.org/pdf/1511.09074v1", 
    "title": "Digital LDO with Time-Interleaved Comparators for Fast Response and Low   Ripple", 
    "arxiv-id": "1511.09074v1", 
    "author": "Mrigank Sharad", 
    "publish": "2015-11-29T19:42:09Z", 
    "summary": "On-chip voltage regulation using distributed Digital Low Drop Out (LDO)\nvoltage regulators has been identified as a promising technique for efficient\npower-management for emerging multi-core processors. Digital LDOs (DLDO) can\noffer low voltage operation, faster transient response, and higher current\nefficiency. Response time as well as output voltage ripple can be reduced by\nincreasing the speed of the dynamic comparators. However, the comparator offset\nsteeply increases for high clock frequencies, thereby leading to enhanced\nvariations in output voltage. In this work we explore the design of digital\nLDOs with multiple dynamic comparators that can overcome this bottleneck. In\nthe proposed topology, we apply time-interleaved comparators with the same\nvoltage threshold and uniform current step in order to accomplish the\naforementioned features. Simulation based analysis shows that the DLDO with\ntime-interleaved comparators can achieve better overall performance in terms of\ncurrent efficiency, ripple and settling time. For a load step of 50mA, a DLDO\nwith 8 time-interleaved comparators could achieve an output ripple of less than\n5mV, while achieving a settling time of less than 0.5us. Load current dependant\ndynamic adjustment of clock frequency is proposed to maintain high current\nefficiency of ~97%."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2015.6603", 
    "link": "http://arxiv.org/pdf/1601.01463v1", 
    "title": "Design of a Low-Power 1.65 Gbps Data Channel for HDMI Transmitter", 
    "arxiv-id": "1601.01463v1", 
    "author": "R. S. Gamad", 
    "publish": "2016-01-07T10:12:25Z", 
    "summary": "This paper presents a design of low power data channel for application in\nHigh Definition Multimedia Interface (HDMI) Transmitter circuit. The input is\n10 bit parallel data and output is serial data at 1.65 Gbps. This circuit uses\nonly a single frequency of serial clock input. All other timing signals are\nderived within the circuit from the serial clock. This design has dedicated\nlines to disable and enable all its channels within two pixel-clock periods\nonly. A pair of disable and enable functions performed immediately after\npower-on of the circuit serves as the reset function. The presented design is\nimmune to data-dependent switching spikes in supply current and pushes them in\nthe range of serial frequency and its multiples. Thus filtering requirements\nare relaxed. The output stage uses a bias voltage of 2.8 volts for a receiver\npull-up voltage of 3.3 volts. The reported data channel is designed using UMC\n180 nm CMOS Technology. The design is modifiable for other inter-board serial\ninterfaces like USB and LAN with different number of bits at the parallel\ninput."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2015.6603", 
    "link": "http://arxiv.org/pdf/1601.06352v1", 
    "title": "Reducing Performance Impact of DRAM Refresh by Parallelizing Refreshes   with Accesses", 
    "arxiv-id": "1601.06352v1", 
    "author": "Onur Mutlu", 
    "publish": "2016-01-24T07:25:02Z", 
    "summary": "Modern DRAM cells are periodically refreshed to prevent data loss due to\nleakage. Commodity DDR DRAM refreshes cells at the rank level. This degrades\nperformance significantly because it prevents an entire rank from serving\nmemory requests while being refreshed. DRAM designed for mobile platforms,\nLPDDR DRAM, supports an enhanced mode, called per-bank refresh, that refreshes\ncells at the bank level. This enables a bank to be accessed while another in\nthe same rank is being refreshed, alleviating part of the negative performance\nimpact of refreshes. However, there are two shortcomings of per-bank refresh.\nFirst, the per-bank refresh scheduling scheme does not exploit the full\npotential of overlapping refreshes with accesses across banks because it\nrestricts the banks to be refreshed in a sequential round-robin order. Second,\naccesses to a bank that is being refreshed have to wait.\n  To mitigate the negative performance impact of DRAM refresh, we propose two\ncomplementary mechanisms, DARP (Dynamic Access Refresh Parallelization) and\nSARP (Subarray Access Refresh Parallelization). The goal is to address the\ndrawbacks of per-bank refresh by building more efficient techniques to\nparallelize refreshes and accesses within DRAM. First, instead of issuing\nper-bank refreshes in a round-robin order, DARP issues per-bank refreshes to\nidle banks in an out-of-order manner. Furthermore, DARP schedules refreshes\nduring intervals when a batch of writes are draining to DRAM. Second, SARP\nexploits the existence of mostly-independent subarrays within a bank. With\nminor modifications to DRAM organization, it allows a bank to serve memory\naccesses to an idle subarray while another subarray is being refreshed.\nExtensive evaluations show that our mechanisms improve system performance and\nenergy efficiency compared to state-of-the-art refresh policies and the benefit\nincreases as DRAM density increases."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2015.6603", 
    "link": "http://arxiv.org/pdf/1601.06903v1", 
    "title": "Tiered-Latency DRAM (TL-DRAM)", 
    "arxiv-id": "1601.06903v1", 
    "author": "Onur Mutlu", 
    "publish": "2016-01-26T06:36:03Z", 
    "summary": "This paper summarizes the idea of Tiered-Latency DRAM, which was published in\nHPCA 2013. The key goal of TL-DRAM is to provide low DRAM latency at low cost,\na critical problem in modern memory systems. To this end, TL-DRAM introduces\nheterogeneity into the design of a DRAM subarray by segmenting the bitlines,\nthereby creating a low-latency, low-energy, low-capacity portion in the\nsubarray (called the near segment), which is close to the sense amplifiers, and\na high-latency, high-energy, high-capacity portion, which is farther away from\nthe sense amplifiers. Thus, DRAM becomes heterogeneous with a small portion\nhaving lower latency and a large portion having higher latency. Various\ntechniques can be employed to take advantage of the low-latency near segment\nand this new heterogeneous DRAM substrate, including hardware-based caching and\nsoftware based caching and memory allocation of frequently used data in the\nnear segment. Evaluations with simple such techniques show significant\nperformance and energy-efficiency benefits."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2015.6603", 
    "link": "http://arxiv.org/pdf/1602.00722v1", 
    "title": "Enabling Efficient Dynamic Resizing of Large DRAM Caches via A Hardware   Consistent Hashing Mechanism", 
    "arxiv-id": "1602.00722v1", 
    "author": "Onur Mutlu", 
    "publish": "2016-02-01T21:43:40Z", 
    "summary": "Die-stacked DRAM has been proposed for use as a large, high-bandwidth,\nlast-level cache with hundreds or thousands of megabytes of capacity. Not all\nworkloads (or phases) can productively utilize this much cache space, however.\nUnfortunately, the unused (or under-used) cache continues to consume power due\nto leakage in the peripheral circuitry and periodic DRAM refresh. Dynamically\nadjusting the available DRAM cache capacity could largely eliminate this energy\noverhead. However, the current proposed DRAM cache organization introduces new\nchallenges for dynamic cache resizing. The organization differs from a\nconventional SRAM cache organization because it places entire cache sets and\ntheir tags within a single bank to reduce on-chip area and power overhead.\nHence, resizing a DRAM cache requires remapping sets from the powered-down\nbanks to active banks.\n  In this paper, we propose CRUNCH (Cache Resizing Using Native Consistent\nHashing), a hardware data remapping scheme inspired by consistent hashing, an\nalgorithm originally proposed to uniformly and dynamically distribute Internet\ntraffic across a changing population of web servers. CRUNCH provides a\nload-balanced remapping of data from the powered-down banks alone to the active\nbanks, without requiring sets from all banks to be remapped, unlike naive\nschemes to achieve load balancing. CRUNCH remaps only sets from the\npowered-down banks, so it achieves this load balancing with low bank\npower-up/down transition latencies. CRUNCH's combination of good load balancing\nand low transition latencies provides a substrate to enable efficient DRAM\ncache resizing."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2015.6603", 
    "link": "http://arxiv.org/pdf/1602.01329v1", 
    "title": "Effect of Data Sharing on Private Cache Design in Chip Multiprocessors", 
    "arxiv-id": "1602.01329v1", 
    "author": "Ran Ginosar", 
    "publish": "2016-02-03T15:02:05Z", 
    "summary": "In multithreaded applications with high degree of data sharing, the miss rate\nof private cache is shown to exhibit a compulsory miss component. It manifests\nbecause at least some of the shared data originates from other cores and can\nonly be accessed in a shared cache. The compulsory component does not change\nwith the private cache size, causing its miss rate to diminish slower as the\ncache size grows. As a result, the peak performance of a Chip Multiprocessor\n(CMP) for workloads with high degree of data sharing is achieved with a smaller\nprivate cache, compared to workloads with no data sharing. The CMP performance\ncan be improved by reassigning some of the constrained area or power resource\nfrom private cache to core. Alternatively, the area or power budget of a CMP\ncan be reduced without a performance hit."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2015.6603", 
    "link": "http://arxiv.org/pdf/1602.01348v1", 
    "title": "A Framework for Accelerating Bottlenecks in GPU Execution with Assist   Warps", 
    "arxiv-id": "1602.01348v1", 
    "author": "Onur Mutlu", 
    "publish": "2016-02-03T15:57:59Z", 
    "summary": "Modern Graphics Processing Units (GPUs) are well provisioned to support the\nconcurrent execution of thousands of threads. Unfortunately, different\nbottlenecks during execution and heterogeneous application requirements create\nimbalances in utilization of resources in the cores. For example, when a GPU is\nbottlenecked by the available off-chip memory bandwidth, its computational\nresources are often overwhelmingly idle, waiting for data from memory to\narrive.\n  This work describes the Core-Assisted Bottleneck Acceleration (CABA)\nframework that employs idle on-chip resources to alleviate different\nbottlenecks in GPU execution. CABA provides flexible mechanisms to\nautomatically generate \"assist warps\" that execute on GPU cores to perform\nspecific tasks that can improve GPU performance and efficiency.\n  CABA enables the use of idle computational units and pipelines to alleviate\nthe memory bandwidth bottleneck, e.g., by using assist warps to perform data\ncompression to transfer less data from memory. Conversely, the same framework\ncan be employed to handle cases where the GPU is bottlenecked by the available\ncomputational units, in which case the memory pipelines are idle and can be\nused by CABA to speed up computation, e.g., by performing memoization using\nassist warps.\n  We provide a comprehensive design and evaluation of CABA to perform effective\nand flexible data compression in the GPU memory hierarchy to alleviate the\nmemory bandwidth bottleneck. Our extensive evaluations show that CABA, when\nused to implement data compression, provides an average performance improvement\nof 41.7% (as high as 2.6X) across a variety of memory-bandwidth-sensitive GPGPU\napplications."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2015.6603", 
    "link": "http://arxiv.org/pdf/1602.03095v1", 
    "title": "OpenRISC System-on-Chip Design Emulation", 
    "arxiv-id": "1602.03095v1", 
    "author": "Fei Xie", 
    "publish": "2016-02-09T17:59:24Z", 
    "summary": "Recently the hardware emulation technique has emerged as a promising approach\nto accelerating hardware verification/debugging process. To fully evaluate the\npowerfulness of the emulation approach and demonstrate its potential impact, we\npropose to emulate a system-on-chip (SoC) design using Mentor Graphics Veloce\nemulation platform. This article presents our project setup and the results we\nhave achieved. The results are encouraging. ORPSoC emulation with Veloce has\nmore than ten times faster than hardware simulation. Our experimental results\ndemonstrate that Mentor Graphics Veloce has major advantages in emulation,\nverification, and debugging of complicated real hardware designs, especially in\nthe context of SoC complexity. Through our three major tasks, we will\ndemonstrate that (1) Veloce can successfully emulate large-scale SoC designs;\n(2) it has much better performance comparing to the state-of-the-art simulation\ntools; (3) it can significantly accelerate the process of hardware verification\nand debugging while maintaining full signal visibility."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2015.6603", 
    "link": "http://arxiv.org/pdf/1602.04414v1", 
    "title": "Temperature-aware Dynamic Optimization of Embedded Systems", 
    "arxiv-id": "1602.04414v1", 
    "author": "Ann Gordon-Ross", 
    "publish": "2016-02-14T04:42:19Z", 
    "summary": "Due to embedded systems` stringent design constraints, much prior work\nfocused on optimizing energy consumption and/or performance. Since embedded\nsystems typically have fewer cooling options, rising temperature, and thus\ntemperature optimization, is an emergent concern. Most embedded systems only\ndissipate heat by passive convection, due to the absence of dedicated thermal\nmanagement hardware mechanisms. The embedded system`s temperature not only\naffects the system`s reliability, but could also affect the performance, power,\nand cost. Thus, embedded systems require efficient thermal management\ntechniques. However, thermal management can conflict with other optimization\nobjectives, such as execution time and energy consumption. In this paper, we\nfocus on managing the temperature using a synergy of cache optimization and\ndynamic frequency scaling, while also optimizing the execution time and energy\nconsumption. This paper provides new insights on the impact of cache parameters\non efficient temperature-aware cache tuning heuristics. In addition, we present\ntemperature-aware phase-based tuning, TaPT, which determines Pareto optimal\nclock frequency and cache configurations for fine-grained execution time,\nenergy, and temperature tradeoffs. TaPT enables autonomous system optimization\nand also allows designers to specify temperature constraints and optimization\npriorities. Experiments show that TaPT can effectively reduce execution time,\nenergy, and temperature, while imposing minimal hardware overhead."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2015.6603", 
    "link": "http://arxiv.org/pdf/1602.04415v1", 
    "title": "Phase distance mapping: a phase-based cache tuning methodology for   embedded systems", 
    "arxiv-id": "1602.04415v1", 
    "author": "Arslan Munir", 
    "publish": "2016-02-14T04:42:38Z", 
    "summary": "Networked embedded systems typically leverage a collection of low-power\nembedded systems (nodes) to collaboratively execute applications spanning\ndiverse application domains (e.g., video, image processing, communication,\netc.) with diverse application requirements. The individual networked nodes\nmust operate under stringent constraints (e.g., energy, memory, etc.) and\nshould be specialized to meet varying application requirements in order to\nadhere to these constraints. Phase-based tuning specializes system tunable\nparameters to the varying runtime requirements of different execution phases to\nmeet optimization goals. Since the design space for tunable systems can be very\nlarge, one of the major challenges in phase-based tuning is determining the\nbest configuration for each phase without incurring significant tuning overhead\n(e.g., energy and/or performance) during design space exploration. In this\npaper, we propose phase distance mapping, which directly determines the best\nconfiguration for a phase, thereby eliminating design space exploration. Phase\ndistance mapping applies the correlation between the characteristics and best\nconfiguration of a known phase to determine the best configuration of a new\nphase. Experimental results verify that our phase distance mapping approach,\nwhen applied to cache tuning, determines cache configurations within 1 % of the\noptimal configurations on average and yields an energy delay product savings of\n27 % on average."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2015.6603", 
    "link": "http://arxiv.org/pdf/1603.01187v1", 
    "title": "A Dynamic Overlay Supporting Just-In-Time Assembly to Construct   Customized Hardware Accelerators", 
    "arxiv-id": "1603.01187v1", 
    "author": "David Andrews", 
    "publish": "2016-03-03T17:17:56Z", 
    "summary": "Barriers that prevent programmers from using FPGAs include the need to work\nwithin vendor specific CAD tools, knowledge of hardware programming models, and\nthe requirement to pass each design through synthesis, place and route. In this\nwork, a dynamic overlay is designed to support Just- In-Time assembly by\ncomposing hardware operators to construct full accelerators. The hardware\noperators are pre-synthesized bit- streams and can be downloaded to Partially\nReconfigurable(PR) regions at runtime."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2015.6603", 
    "link": "http://arxiv.org/pdf/1603.04094v1", 
    "title": "Design and Implementation of an Improved Carry Increment Adder", 
    "arxiv-id": "1603.04094v1", 
    "author": "Romesh Laishram", 
    "publish": "2016-03-10T06:32:36Z", 
    "summary": "A complex digital circuit comprises of adder as a basic unit. The performance\nof the circuit depends on the design of this basic adder unit. The speed of\noperation of a circuit is one of the important performance criteria of many\ndigital circuits which ultimately depends on the delay of the basic adder unit.\nMany research works have been devoted in improving the delay of the adder\ncircuit. In this paper we have proposed an improved carry increment adder (CIA)\nthat improves the delay performance of the circuit. The improvement is achieved\nby incorporating carry look adder (CLA) in the design of CIA contrary to the\nprevious design of CIA that employs ripple carry adder (RCA). A simulation\nstudy is carried out for comparative analysis. The coding is done in Verilog\nhardware description language (HDL) and the simulation is carried out in Xilinx\nISE 13.1 environment."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2015.6603", 
    "link": "http://arxiv.org/pdf/1603.04627v1", 
    "title": "Modified Micropipline Architecture for Synthesizable Asynchronous FIR   Filter Design", 
    "arxiv-id": "1603.04627v1", 
    "author": "Hsien-Chih Chiu", 
    "publish": "2016-03-15T10:44:29Z", 
    "summary": "The use of asynchronous design approaches to construct digital signal\nprocessing (DSP) systems is a rapidly growing research area driven by a wide\nrange of emerging energy constrained applications such as wireless sensor\nnetwork, portable medical devices and brain implants. The asynchronous design\ntechniques allow the construction of systems which are samples driven, which\nmeans they only dissipate dynamic energy when there processing data and idle\notherwise. This inherent advantage of asynchronous design over conventional\nsynchronous circuits allows them to be energy efficient. However the\nimplementation flow of asynchronous systems is still difficult due to its lack\nof compatibility with industry-standard synchronous design tools and modelling\nlanguages. This paper devises a novel asynchronous design for a finite impulse\nresponse (FIR) filter, an essential building block of DSP systems, which is\nsynthesizable and suitable for implementation using conventional synchronous\nsystems design flow and tools. The proposed design is based on a modified\nversion of the micropipline architecture and it is constructed using four phase\nbundled data protocol. A hardware prototype of the proposed filter has been\ndeveloped on an FPGA, and systematically verified. The results prove correct\nfunctionality of the novel design and a superior performance compared to a\nsynchronous FIR implementation. The findings of this work will allow a wider\nadoption of asynchronous circuits by DSP designers to harness their energy and\nperformance benefits."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2015.6603", 
    "link": "http://arxiv.org/pdf/1603.07961v1", 
    "title": "ASIC-based Implementation of Synchronous Section-Carry Based Carry   Lookahead Adders", 
    "arxiv-id": "1603.07961v1", 
    "author": "N E Mastorakis", 
    "publish": "2016-03-25T17:02:58Z", 
    "summary": "The section-carry based carry lookahead adder (SCBCLA) topology was proposed\nas an improved high-speed alternative to the conventional carry lookahead adder\n(CCLA) topology in previous works. Self-timed and FPGA-based implementations of\nSCBCLAs and CCLAs were considered earlier, and it was found that SCBCLAs could\nhelp in delay reduction i.e. pave the way for improved speed compared to CCLAs\nat the expense of some increase in area and/or power parameters. In this work,\nwe consider semi-custom ASIC-based implementations of different variants of\nSCBCLAs and CCLAs to perform 32-bit dual-operand addition. Based on the\nsimulation results for 32-bit dual-operand addition obtained by targeting a\nhigh-end 32/28nm CMOS process, it is found that an optimized SCBCLA\narchitecture reports a 9.8% improvement in figure-of-merit (FOM) compared to an\noptimized CCLA architecture, where the FOM is defined as the inverse of the\nproduct of power, delay, and area. It is generally inferred from the\nsimulations that the SCBCLA architecture could be more beneficial compared to\nthe CCLA architecture in terms of the design metrics whilst benefitting a\nvariety of computer arithmetic operations involving dual-operand and/or\nmulti-operand additions. Also, it is observed that heterogeneous CLA\narchitectures tend to fare well compared to homogeneous CLA architectures, as\nsubstantiated by the simulation results."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2015.6603", 
    "link": "http://arxiv.org/pdf/1603.07962v1", 
    "title": "Global versus Local Weak-Indication Self-Timed Function Blocks - A   Comparative Analysis", 
    "arxiv-id": "1603.07962v1", 
    "author": "N E Mastorakis", 
    "publish": "2016-03-25T17:11:33Z", 
    "summary": "This paper analyzes the merits and demerits of global weak-indication\nself-timed function blocks versus local weak-indication self-timed function\nblocks, implemented using a delay-insensitive data code and adhering to 4-phase\nreturn-to-zero handshaking. A self-timed ripple carry adder is considered as an\nexample function block for the analysis. The analysis shows that while global\nweak-indication could help in optimizing the power, latency and area\nparameters, local weak-indication facilitates the optimum performance in terms\nof realizing the data-dependent cycle time that is characteristic of a\nweak-indication self-timed design."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2015.6603", 
    "link": "http://arxiv.org/pdf/1603.07964v1", 
    "title": "Power, Delay and Area Comparisons of Majority Voters relevant to TMR   Architectures", 
    "arxiv-id": "1603.07964v1", 
    "author": "N E Mastorakis", 
    "publish": "2016-03-25T17:14:55Z", 
    "summary": "N-modular redundancy (NMR) is commonly used to enhance the fault tolerance of\na circuit/system, when subject to a fault-inducing environment such as in space\nor military systems, where upsets due to radiation phenomena, temperature\nand/or other environmental conditions are anticipated. Triple Modular\nRedundancy (TMR), which is a 3-tuple version of NMR, is widely preferred for\nmission-control space, military, and aerospace, and safety-critical nuclear,\npower, medical, and industrial control and automation systems. The TMR scheme\ninvolves the two-times duplication of a simplex system hardware, with a\nmajority voter ensuring correctness provided at least two out of three copies\nof the hardware remain operational. Thus the majority voter plays a pivotal\nrole in ensuring the correct operation of the TMR scheme. In this paper, a\nnumber of standard-cell based majority voter designs relevant to TMR\narchitectures are presented, and their power, delay and area parameters are\nestimated based on physical realization using a 32/28nm CMOS process."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2015.6603", 
    "link": "http://arxiv.org/pdf/1603.08454v1", 
    "title": "Adaptive-Latency DRAM (AL-DRAM)", 
    "arxiv-id": "1603.08454v1", 
    "author": "Onur Mutlu", 
    "publish": "2016-03-28T17:39:23Z", 
    "summary": "This paper summarizes the idea of Adaptive-Latency DRAM (AL-DRAM), which was\npublished in HPCA 2015. The key goal of AL-DRAM is to exploit the extra margin\nthat is built into the DRAM timing parameters to reduce DRAM latency. The key\nobservation is that the timing parameters are dictated by the worst-case\ntemperatures and worst-case DRAM cells, both of which lead to small amount of\ncharge storage and hence high access latency. One can therefore reduce latency\nby adapting the timing parameters to the current operating temperature and the\ncurrent DIMM that is being accessed. Using an FPGA-based testing platform, our\nwork first characterizes the extra margin for 115 DRAM modules from three major\nmanufacturers. The experimental results demonstrate that it is possible to\nreduce four of the most critical timing parameters by a minimum/maximum of\n17.3%/54.8% at 55C while maintaining reliable operation. AL-DRAM adaptively\nselects between multiple different timing parameters for each DRAM module based\non its current operating condition. AL-DRAM does not require any changes to the\nDRAM chip or its interface; it only requires multiple different timing\nparameters to be specified and supported by the memory controller. Real system\nevaluations show that AL-DRAM improves the performance of memory-intensive\nworkloads by an average of 14% without introducing any errors."
},{
    "category": "cs.AR", 
    "doi": "10.1145/2897937.2897996", 
    "link": "http://arxiv.org/pdf/1604.03062v2", 
    "title": "CLEAR: Cross-Layer Exploration for Architecting Resilience - Combining   Hardware and Software Techniques to Tolerate Soft Errors in Processor Cores", 
    "arxiv-id": "1604.03062v2", 
    "author": "Subhasish Mitra", 
    "publish": "2016-04-11T18:44:27Z", 
    "summary": "We present a first of its kind framework which overcomes a major challenge in\nthe design of digital systems that are resilient to reliability failures:\nachieve desired resilience targets at minimal costs (energy, power, execution\ntime, area) by combining resilience techniques across various layers of the\nsystem stack (circuit, logic, architecture, software, algorithm). This is also\nreferred to as cross-layer resilience. In this paper, we focus on\nradiation-induced soft errors in processor cores. We address both single-event\nupsets (SEUs) and single-event multiple upsets (SEMUs) in terrestrial\nenvironments. Our framework automatically and systematically explores the large\nspace of comprehensive resilience techniques and their combinations across\nvarious layers of the system stack (586 cross-layer combinations in this\npaper), derives cost-effective solutions that achieve resilience targets at\nminimal costs, and provides guidelines for the design of new resilience\ntechniques. We demonstrate the practicality and effectiveness of our framework\nusing two diverse designs: a simple, in-order processor core and a complex,\nout-of-order processor core. Our results demonstrate that a carefully optimized\ncombination of circuit-level hardening, logic-level parity checking, and\nmicro-architectural recovery provides a highly cost-effective soft error\nresilience solution for general-purpose processor cores. For example, a 50x\nimprovement in silent data corruption rate is achieved at only 2.1% energy cost\nfor an out-of-order core (6.1% for an in-order core) with no speed impact.\nHowever, selective circuit-level hardening alone, guided by a thorough analysis\nof the effects of soft errors on application benchmarks, provides a\ncost-effective soft error resilience solution as well (with ~1% additional\nenergy cost for a 50x improvement in silent data corruption rate)."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1604.04006v1", 
    "title": "Area/latency optimized early output asynchronous full adders and   relative-timed ripple carry adders", 
    "arxiv-id": "1604.04006v1", 
    "author": "S Yamashita", 
    "publish": "2016-04-14T01:01:41Z", 
    "summary": "This article presents two area/latency optimized gate level asynchronous full\nadder designs which correspond to early output logic. The proposed full adders\nare constructed using the delay-insensitive dual-rail code and adhere to the\nfour-phase return-to-zero handshaking. For an asynchronous ripple carry adder\n(RCA) constructed using the proposed early output full adders, the\nrelative-timing assumption becomes necessary and the inherent advantages of the\nrelative-timed RCA are: (1) computation with valid inputs, i.e., forward\nlatency is data-dependent, and (2) computation with spacer inputs involves a\nbare minimum constant reverse latency of just one full adder delay, thus\nresulting in the optimal cycle time. With respect to different 32-bit RCA\nimplementations, and in comparison with the optimized strong-indication,\nweak-indication, and early output full adder designs, one of the proposed early\noutput full adders achieves respective reductions in latency by 67.8, 12.3 and\n6.1 %, while the other proposed early output full adder achieves corresponding\nreductions in area by 32.6, 24.6 and 6.9 %, with practically no power penalty.\nFurther, the proposed early output full adders based asynchronous RCAs enable\nminimum reductions in cycle time by 83.4, 15, and 8.8 % when considering\ncarry-propagation over the entire RCA width of 32-bits, and maximum reductions\nin cycle time by 97.5, 27.4, and 22.4 % for the consideration of a typical\ncarry chain length of 4 full adder stages, when compared to the least of the\ncycle time estimates of various strong-indication, weak-indication, and early\noutput asynchronous RCAs of similar size. All the asynchronous full adders and\nRCAs were realized using standard cells in a semi-custom design fashion based\non a 32/28 nm CMOS process technology."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1604.08041v1", 
    "title": "Reducing DRAM Latency at Low Cost by Exploiting Heterogeneity", 
    "arxiv-id": "1604.08041v1", 
    "author": "Donghyuk Lee", 
    "publish": "2016-04-27T12:35:05Z", 
    "summary": "In modern systems, DRAM-based main memory is significantly slower than the\nprocessor. Consequently, processors spend a long time waiting to access data\nfrom main memory, making the long main memory access latency one of the most\ncritical bottlenecks to achieving high system performance. Unfortunately, the\nlatency of DRAM has remained almost constant in the past decade. This is mainly\nbecause DRAM has been optimized for cost-per-bit, rather than access latency.\nAs a result, DRAM latency is not reducing with technology scaling, and\ncontinues to be an important performance bottleneck in modern and future\nsystems.\n  This dissertation seeks to achieve low latency DRAM-based memory systems at\nlow cost in three major directions. First, based on the observation that long\nbitlines in DRAM are one of the dominant sources of DRAM latency, we propose a\nnew DRAM architecture, Tiered-Latency DRAM (TL-DRAM), which divides the long\nbitline into two shorter segments using an isolation transistor, allowing one\nsegment to be accessed with reduced latency. Second, we propose a fine-grained\nDRAM latency reduction mechanism, Adaptive-Latency DRAM, which optimizes DRAM\nlatency for the common operating conditions for individual DRAM module. Third,\nwe propose a new technique, Architectural-Variation-Aware DRAM (AVA-DRAM),\nwhich reduces DRAM latency at low cost, by profiling and identifying only the\ninherently slower regions in DRAM to dynamically determine the lowest latency\nDRAM can operate at without causing failures.\n  This dissertation provides a detailed analysis of DRAM latency by using both\ncircuit-level simulation with a detailed DRAM model and FPGA-based profiling of\nreal DRAM modules. Our latency analysis shows that our low latency DRAM\nmechanisms enable significant latency reductions, leading to large improvement\nin both system performance and energy efficiency."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1605.03229v1", 
    "title": "CORDIC-based Architecture for Powering Computation in Fixed-Point   Arithmetic", 
    "arxiv-id": "1605.03229v1", 
    "author": "Daniel Llamocca", 
    "publish": "2016-05-10T22:18:06Z", 
    "summary": "We present a fixed point architecture (source VHDL code is provided) for\npowering computation. The fully customized architecture, based on the expanded\nhyperbolic CORDIC algorithm, allows for design space exploration to establish\ntrade-offs among design parameters (numerical format, number of iterations),\nexecution time, resource usage and accuracy. We also generate Pareto-optimal\nrealizations in the resource-accuracy space: this approach can produce optimal\nhardware realizations that simultaneously satisfy resource and accuracy\nrequirements."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1605.03770v1", 
    "title": "An Asynchronous Early Output Full Adder and a Relative-Timed Ripple   Carry Adder", 
    "arxiv-id": "1605.03770v1", 
    "author": "N E Mastorakis", 
    "publish": "2016-05-12T11:50:33Z", 
    "summary": "This article presents the design of a new asynchronous early output full\nadder which when cascaded leads to a relative-timed ripple carry adder (RCA).\nThe relative-timed RCA requires imposing a very small relative-timing\nassumption to overcome the problem of gate orphans associated with internal\ncarry propagation. The relative-timing assumption is however independent of the\nRCA size. The primary benefits of the relative-timed RCA are processing of\nvalid data incurs data-dependent forward latency, while the processing of\nspacer involves a very fast constant time reverse latency of just 1 full adder\ndelay which represents the ultimate in the design of an asynchronous RCA with\nthe fastest reset. The secondary benefits of the relative-timed RCA are it\nachieves good optimization of power and area metrics simultaneously. A 32-bit\nrelative-timed RCA constructed using the proposed early output full adder\nachieves respective reductions in forward latency by 67%, 10% and 3.5% compared\nto the optimized strong-indication, weak-indication, and early output 32-bit\nasynchronous RCAs existing in the literature. Based on a similar comparison,\nthe proposed 32-bit relative-timed RCA achieves corresponding reductions in\ncycle time by 83%, 12.7% and 6.4%. In terms of area, the proposed 32-bit\nrelative-timed RCA occupies 27% less Silicon than its optimized\nstrong-indication counterpart and 17% less Silicon than its optimized\nweak-indication counterpart, and features increased area occupancy by a meager\n1% compared to the optimized early output 32-bit asynchronous RCA. The average\npower dissipation of all the asynchronous 32-bit RCAs are found to be\ncomparable since they all satisfy the monotonic cover constraint. The\nsimulation results obtained correspond to a 32/28nm CMOS process."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1605.03771v1", 
    "title": "A Fault Tolerance Improved Majority Voter for TMR System Architectures", 
    "arxiv-id": "1605.03771v1", 
    "author": "N E Mastorakis", 
    "publish": "2016-05-12T11:54:44Z", 
    "summary": "For digital system designs, triple modular redundancy (TMR), which is a\n3-tuple version of N-modular redundancy is widely preferred for many\nmission-control and safety-critical applications. The TMR scheme involves\ntwo-times duplication of the simplex system hardware, with a majority voter\nensuring correctness provided at least two out of three copies of the system\nremain operational. Thus the majority voter plays a pivotal role in ensuring\nthe correct operation of the system. The fundamental assumption implicit in the\nTMR scheme is that the majority voter does not become faulty, which may not\nhold well for implementations based on latest technology nodes with dimensions\nof the order of just tens of nanometers. To overcome the drawbacks of the\nclassical majority voter some new voter designs were put forward in the\nliterature with the aim of enhancing the fault tolerance. However, these voter\ndesigns generally ensure the correct system operation in the presence of either\na faulty function module or the faulty voter, considered only in isolation.\nSince multiple faults may no longer be excluded in the nanoelectronics regime,\nsimultaneous fault occurrences on both the function module and the voter should\nbe considered, and the fault tolerance of the voters have to be analyzed under\nsuch a scenario. In this context, this article proposes a new fault-tolerant\nmajority voter which is found to be more robust to faults than the existing\nvoters in the presence of faults occurring internally and/or externally to the\nvoter. Moreover, the proposed voter features less power dissipation, delay, and\narea metrics based on the simulation results obtained by using a 32/28nm CMOS\nprocess."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1605.04582v2", 
    "title": "A Foray into Efficient Mapping of Algorithms to Hardware Platforms on   Heterogeneous Systems", 
    "arxiv-id": "1605.04582v2", 
    "author": "Martin Margala", 
    "publish": "2016-05-15T17:52:28Z", 
    "summary": "Heterogeneous computing can potentially offer significant performance and\nperformance per watt improvements over homogeneous computing, but the question\n\"what is the ideal mapping of algorithms to architectures?\" remains an open\none. In the past couple of years new types of computing devices such as FPGAs\nhave come into general computing use. In this work we attempt to add to the\nbody of scientific knowledge by comparing Kernel performance and performance\nper watt of seven key algorithms according to Berkley's dwarf taxonomy. We do\nso using the Rodinia benchmark suite on three different high-end hardware\narchitecture representatives from the CPU, GPU and FPGA families. We find\nresults that support some distinct mappings between the architecture and\nperformance per watt. Perhaps the most interesting finding is that, for our\nspecific hardware representatives, FPGAs should be considered as alternatives\nto GPUs and CPUs in several key algorithms: N-body simulations, dense linear\nalgebra and structured grid."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1605.06483v1", 
    "title": "Simple DRAM and Virtual Memory Abstractions to Enable Highly Efficient   Memory Systems", 
    "arxiv-id": "1605.06483v1", 
    "author": "Vivek Seshadri", 
    "publish": "2016-05-20T19:38:14Z", 
    "summary": "In most modern systems, the memory subsystem is managed and accessed at\nmultiple different granularities at various resources. We observe that such\nmulti-granularity management results in significant inefficiency in the memory\nsubsystem. Specifically, we observe that 1) page-granularity virtual memory\nunnecessarily triggers large memory operations, and 2) existing cache-line\ngranularity memory interface is inefficient for performing bulk data operations\nand operations that exhibit poor spatial locality. To address these problems,\nwe present a series of techniques in this thesis.\n  First, we propose page overlays, a framework augments the existing virtual\nmemory framework with the ability to track a new version of a subset of cache\nlines within each virtual page. We show that this extension is powerful by\ndemonstrating its benefits on a number of applications.\n  Second, we show that DRAM can be used to perform more complex operations than\njust store data. We propose RowClone, a mechanism to perform bulk data copy and\ninitialization completely inside DRAM, and Buddy RAM, a mechanism to perform\nbulk bitwise operations using DRAM. Both these techniques achieve an\norder-of-magnitude improvement in the efficiency of the respective operations.\n  Third, we propose Gather-Scatter DRAM, a technique that exploits DRAM\norganization to effectively gather/scatter values with a power-of-2 strided\naccess patterns. For these access patterns, GS-DRAM achieves near-ideal\nbandwidth and cache utilization, without increasing the latency of fetching\ndata from memory.\n  Finally, we propose the Dirty-Block Index, a new way of tracking dirty\nblocks. In addition to improving the efficiency of bulk data coherence, DBI has\nseveral applications including high-performance memory scheduling, efficient\ncache lookup bypassing, and enabling heterogeneous ECC."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1605.08149v1", 
    "title": "Proceedings of the 2nd International Workshop on Overlay Architectures   for FPGAs (OLAF 2016)", 
    "arxiv-id": "1605.08149v1", 
    "author": "John Wawrzynek", 
    "publish": "2016-05-26T05:46:03Z", 
    "summary": "The 2nd International Workshop on Overlay Architectures for FPGAs (OLAF 2016)\nwas held on 21 Mar, 2016 as a co-located workshop at the 24th ACM/SIGDA\nInternational Symposium on Field-Programmable Gate Arrays (FPGA 2016). This\nyear, the program committee selected 6 papers and 3 extended abstracts to be\npresented at the workshop, which are subsequently collected in this online\nvolume."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1606.01037v1", 
    "title": "GRVI Phalanx: A Massively Parallel RISC-V FPGA Accelerator Accelerator", 
    "arxiv-id": "1606.01037v1", 
    "author": "Jan Gray", 
    "publish": "2016-06-03T10:37:41Z", 
    "summary": "GRVI is an FPGA-efficient RISC-V RV32I soft processor. Phalanx is a parallel\nprocessor and accelerator array framework. Groups of processors and\naccelerators form shared memory clusters. Clusters are interconnected with each\nother and with extreme bandwidth I/O and memory devices by a 300- bit-wide\nHoplite NOC. An example Kintex UltraScale KU040 system has 400 RISC-V cores,\npeak throughput of 100,000 MIPS, peak shared memory bandwidth of 600 GB/s, NOC\nbisection bandwidth of 700 Gbps, and uses 13 W."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1606.03717v1", 
    "title": "Automated Space/Time Scaling of Streaming Task Graph", 
    "arxiv-id": "1606.03717v1", 
    "author": "Guy G. F. Lemieux", 
    "publish": "2016-06-12T14:26:01Z", 
    "summary": "In this paper, we describe a high-level synthesis (HLS) tool that\nautomatically allows area/throughput trade-offs for implementing streaming task\ngraphs (STG). Our tool targets a massively parallel processor array (MPPA)\narchitecture, very similar to the Ambric MPPA chip architecture, which is to be\nimplemented as an FPGA overlay. Similar to Ambric tools, our HLS tool accepts a\nSTG as input written in a subset of Java and a structural language in the style\nof a Kahn Processing Network (KPN). Unlike the Ambric tools, our HLS tool\nanalyzes the parallelism internal to each Java \"node\" and evaluates the\nthroughput and area of several possible implementations. It then analyzes the\nfull graph for bottlenecks or excess compute capacity, selects an\nimplementation for each node, and even considers replicating or splitting nodes\nwhile either minimizing area (for a fixed throughput target), or maximizing\nthroughput (for a fixed area target). In addition to traditional node selection\nand replication methods used in prior work, we have uniquely implemented node\ncombining and splitting to find a better area/throughput trade-off. We present\ntwo optimization approaches, a formal ILP formulation and a heuristic solution.\nResults show that the heuristic is more flexible and can find design points not\navailable to the ILP, thereby achieving superior results."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1606.04609v1", 
    "title": "High Throughput Neural Network based Embedded Streaming Multicore   Processors", 
    "arxiv-id": "1606.04609v1", 
    "author": "David J. Mountain", 
    "publish": "2016-06-15T01:26:24Z", 
    "summary": "With power consumption becoming a critical processor design issue,\nspecialized architectures for low power processing are becoming popular.\nSeveral studies have shown that neural networks can be used for signal\nprocessing and pattern recognition applications. This study examines the design\nof memristor based multicore neural processors that would be used primarily to\nprocess data directly from sensors. Additionally, we have examined the design\nof SRAM based neural processors for the same task. Full system evaluation of\nthe multicore processors based on these specialized cores were performed taking\nI/O and routing circuits into consideration. The area and power benefits were\ncompared with traditional multicore RISC processors. Our results show that the\nmemristor based architectures can provide an energy efficiency between three\nand five orders of magnitude greater than that of RISC processors for the\nbenchmarks examined."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1606.05094v1", 
    "title": "A 0.3-2.6 TOPS/W Precision-Scalable Processor for Real-Time Large-Scale   ConvNets", 
    "arxiv-id": "1606.05094v1", 
    "author": "Marian Verhelst", 
    "publish": "2016-06-16T08:40:57Z", 
    "summary": "A low-power precision-scalable processor for ConvNets or convolutional neural\nnetworks (CNN) is implemented in a 40nm technology. Its 256 parallel processing\nunits achieve a peak 102GOPS running at 204MHz. To minimize energy consumption\nwhile maintaining throughput, this works is the first to both exploit the\nsparsity of convolutions and to implement dynamic precision-scalability\nenabling supply- and energy scaling. The processor is fully C-programmable,\nconsumes 25-288mW at 204 MHz and scales efficiency from 0.3-2.6 real TOPS/W.\nThis system hereby outperforms the state-of-the-art up to 3.9x in energy\nefficiency."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1606.05621v1", 
    "title": "Design of Synchronous Section-Carry Based Carry Lookahead Adders with   Improved Figure of Merit", 
    "arxiv-id": "1606.05621v1", 
    "author": "N E Mastorakis", 
    "publish": "2016-06-17T18:54:48Z", 
    "summary": "The section-carry based carry lookahead adder (SCBCLA) architecture was\nproposed as an efficient alternative to the conventional carry lookahead adder\n(CCLA) architecture for the physical implementation of computer arithmetic. In\nprevious related works, self-timed SCBCLA architectures and synchronous SCBCLA\narchitectures were realized using standard cells and FPGAs. In this work, we\ndeal with improved realizations of synchronous SCBCLA architectures designed in\na semi-custom fashion using standard cells. The improvement is quantified in\nterms of a figure of merit (FOM), where the FOM is defined as the inverse\nproduct of power, delay and area. Since power, delay and area of digital\ndesigns are desirable to be minimized, the FOM is desirable to be maximized.\nStarting from an efficient conventional carry lookahead generator, we show how\nan optimized section-carry based carry lookahead generator is realized. In\ncomparison with our recent work dealing with standard cells based\nimplementation of SCBCLAs to perform 32-bit addition of two binary operands, we\nshow in this work that with improved section-carry based carry lookahead\ngenerators, the resulting SCBCLAs exhibit significant improvements in FOM.\nCompared to the earlier optimized hybrid SCBCLA, the proposed optimized hybrid\nSCBCLA improves the FOM by 88.3%. Even the optimized hybrid CCLA features\nimprovement in FOM by 77.3% over the earlier optimized hybrid CCLA. However,\nthe proposed optimized hybrid SCBCLA is still the winner and has a better FOM\nthan the currently optimized hybrid CCLA by 15.3%. All the CCLAs and SCBCLAs\nare implemented to realize 32-bit dual-operand binary addition using a 32/28nm\nCMOS process."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1606.05933v1", 
    "title": "Criticality Aware Multiprocessors", 
    "arxiv-id": "1606.05933v1", 
    "author": "Anil Krishna", 
    "publish": "2016-06-20T00:57:30Z", 
    "summary": "Typically, a memory request from a processor may need to go through many\nintermediate interconnect routers, directory node, owner node, etc before it is\nfinally serviced. Current multiprocessors do not give preference to any\nparticular memory request. But certain memory requests are more critical to\nmultiprocessor's performance than other requests. Example: memory requests from\ncritical sections, load request feeding into multiple dependent instructions,\netc. This knowledge can be used to improve the performance of current\nmultiprocessors by letting the ordering point and the interconnect routers\nprioritize critical requests over non-critical ones. In this paper, we evaluate\nusing SIMICS/GEMS infrastructure. For lock-intensive microbenchmarks,\ncriticality-aware multiprocessors showed 5-15% performance improvement over\nbaseline multiprocessor. Criticality aware multiprocessor provides a new\ndirection for tapping performance in a shared memory multiprocessor and can\nprovide substantial speedup in lock intensive benchmarks."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1606.06451v1", 
    "title": "High Level Synthesis with a Dataflow Architectural Template", 
    "arxiv-id": "1606.06451v1", 
    "author": "John Wawrzynek", 
    "publish": "2016-06-21T07:22:12Z", 
    "summary": "In this work, we present a new approach to high level synthesis (HLS), where\nhigh level functions are first mapped to an architectural template, before\nhardware synthesis is performed. As FPGA platforms are especially suitable for\nimplementing streaming processing pipelines, we perform transformations on\nconventional high level programs where they are turned into multi-stage\ndataflow engines [1]. This target template naturally overlaps slow memory data\naccesses with computations and therefore has much better tolerance towards\nmemory subsystem latency. Using a state-of-the-art HLS tool for the actual\ncircuit generation, we observe up to 9x improvement in overall performance when\nthe dataflow architectural template is used as an intermediate compilation\ntarget."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1606.06452v1", 
    "title": "Reliability-Aware Overlay Architectures for FPGAs: Features and Design   Challenges", 
    "arxiv-id": "1606.06452v1", 
    "author": "Mihalis Psarakis", 
    "publish": "2016-06-21T07:25:05Z", 
    "summary": "The FPGA overlay architectures have been mainly proposed to improve design\nproductivity, circuit portability and system debugging. In this paper, we\naddress the use of overlay architectures for building fault tolerant SRAM-based\nFPGA systems and discuss the main features and design challenges of a\nreliability-aware overlay architecture."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1606.06454v1", 
    "title": "Soft GPGPUs for Embedded FPGAs: An Architectural Evaluation", 
    "arxiv-id": "1606.06454v1", 
    "author": "Russell Tessier", 
    "publish": "2016-06-21T07:33:43Z", 
    "summary": "We present a customizable soft architecture which allows for the execution of\nGPGPU code on an FPGA without the need to recompile the design. Issues related\nto scaling the overlay architecture to multiple GPGPU multiprocessors are\nconsidered along with application-class architectural optimizations. The\noverlay architecture is optimized for FPGA implementation to support efficient\nuse of embedded block memories and DSP blocks. This architecture supports\ndirect CUDA compilation of integer computations to a binary which is executable\non the FPGA-based GPGPU. The benefits of our architecture are evaluated for a\ncollection of five standard CUDA benchmarks which are compiled using standard\nGPGPU compilation tools. Speedups of 44x, on average, versus a MicroBlaze\nmicroprocessor are achieved. We show dynamic energy savings versus a soft-core\nprocessor of 80% on average. Application-customized versions of the soft GPGPU\ncan be used to further reduce dynamic energy consumption by an average of 14%."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1606.06457v1", 
    "title": "Enabling Effective FPGA Debug using Overlays: Opportunities and   Challenges", 
    "arxiv-id": "1606.06457v1", 
    "author": "Steven J. E. Wilton", 
    "publish": "2016-06-21T07:43:55Z", 
    "summary": "FPGAs are going mainstream. Major companies that were not traditionally\nFPGA-focused are now seeking ways to exploit the benefits of reconfigurable\ntechnology and provide it to their customers. In order to do so, a debug\necosystem that provides for effective visibility into a working design and\nquick debug turn-around times is essential. Overlays have the opportunity to\nplay a key role in this ecosystem. In this overview paper, we discuss how an\noverlay fabric that allows the user to rapidly add debug instrumentation to a\ndesign can be created and exploited. We discuss the requirements of such an\noverlay and some of the research challenges and opportunities that need to be\naddressed. To make our exposition concrete, we use two previously-published\nexamples of overlays that have been developed to implement debug\ninstrumentation."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1606.06460v1", 
    "title": "An Area-Efficient FPGA Overlay using DSP Block based Time-multiplexed   Functional Units", 
    "arxiv-id": "1606.06460v1", 
    "author": "Suhaib A. Fahmy", 
    "publish": "2016-06-21T07:52:00Z", 
    "summary": "Coarse grained overlay architectures improve FPGA design productivity by\nproviding fast compilation and software-like programmability. Throughput\noriented spatially configurable overlays typically suffer from area overheads\ndue to the requirement of one functional unit for each compute kernel\noperation. Hence, these overlays have often been of limited size, supporting\nonly relatively small compute kernels while consuming considerable FPGA\nresources. This paper examines the possibility of sharing the functional units\namong kernel operations for reducing area overheads. We propose a linear\ninterconnected array of time-multiplexed FUs as an overlay architecture with\nreduced instruction storage and interconnect resource requirements, which uses\na fully-pipelined, architecture-aware FU design supporting a fast context\nswitching time. The results presented show a reduction of up to 85% in FPGA\nresource requirements compared to existing throughput oriented overlay\narchitectures, with an operating frequency which approaches the theoretical\nlimit for the FPGA device."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1606.06483v1", 
    "title": "A Soft Processor Overlay with Tightly-coupled FPGA Accelerator", 
    "arxiv-id": "1606.06483v1", 
    "author": "Hayden Kwok-Hay So", 
    "publish": "2016-06-21T09:00:33Z", 
    "summary": "FPGA overlays are commonly implemented as coarse-grained reconfigurable\narchitectures with a goal to improve designers' productivity through balancing\nflexibility and ease of configuration of the underlying fabric. To truly\nfacilitate full application acceleration, it is often necessary to also include\na highly efficient processor that integrates and collaborates with the\naccelerators while maintaining the benefits of being implemented within the\nsame overlay framework. This paper presents an open-source soft processor that\nis designed to tightly-couple with FPGA accelerators as part of an overlay\nframework. RISC-V is chosen as the instruction set for its openness and\nportability, and the soft processor is designed as a 4-stage pipeline to\nbalance resource consumption and performance when implemented on FPGAs. The\nprocessor is generically implemented so as to promote design portability and\ncompatibility across different FPGA platforms. Experimental results show that\nintegrated software-hardware applications using the proposed tightly-coupled\narchitecture achieve comparable performance as hardware-only accelerators while\nthe proposed architecture provides additional run-time flexibility. The\nprocessor has been synthesized to both low-end and high-performance FPGA\nfamilies from different vendors, achieving the highest frequency of 268.67MHz\nand resource consumption comparable to existing RISC-V designs."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1606.07852v1", 
    "title": "FPMax: a 106GFLOPS/W at 217GFLOPS/mm2 Single-Precision FPU, and a   43.7GFLOPS/W at 74.6GFLOPS/mm2 Double-Precision FPU, in 28nm UTBB FDSOI", 
    "arxiv-id": "1606.07852v1", 
    "author": "Mark Horowitz", 
    "publish": "2016-06-24T23:20:50Z", 
    "summary": "FPMax implements four FPUs optimized for latency or throughput workloads in\ntwo precisions, fabricated in 28nm UTBB FDSOI. Each unit's parameters, e.g\npipeline stages, booth encoding etc., were optimized to yield 1.42ns latency at\n110GLOPS/W (SP) and 1.39ns latency at 36GFLOPS/W (DP). At 100% activity,\nbody-bias control improves the energy efficiency by about 20%; at 10% activity\nthis saving is almost 2x.\n  Keywords: FPU, energy efficiency, hardware generator, SOI"
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1606.08686v1", 
    "title": "A Benes Based NoC Switching Architecture for Mixed Criticality Embedded   Systems", 
    "arxiv-id": "1606.08686v1", 
    "author": "Kerstin Eder", 
    "publish": "2016-06-28T13:19:10Z", 
    "summary": "Multi-core, Mixed Criticality Embedded (MCE) real-time systems require high\ntiming precision and predictability to guarantee there will be no interference\nbetween tasks. These guarantees are necessary in application areas such as\navionics and automotive, where task interference or missed deadlines could be\ncatastrophic, and safety requirements are strict. In modern multi-core systems,\nthe interconnect becomes a potential point of uncertainty, introducing major\nchallenges in proving behaviour is always within specified constraints,\nlimiting the means of growing system performance to add more tasks, or provide\nmore computational resources to existing tasks.\n  We present MCENoC, a Network-on-Chip (NoC) switching architecture that\nprovides innovations to overcome this with predictable, formally verifiable\ntiming behaviour that is consistent across the whole NoC. We show how the\nfundamental properties of Benes networks benefit MCE applications and meet our\narchitecture requirements. Using SystemVerilog Assertions (SVA), formal\nproperties are defined that aid the refinement of the specification of the\ndesign as well as enabling the implementation to be exhaustively formally\nverified. We demonstrate the performance of the design in terms of size,\nthroughput and predictability, and discuss the application level considerations\nneeded to exploit this architecture."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1607.00064v1", 
    "title": "Maximizing CNN Accelerator Efficiency Through Resource Partitioning", 
    "arxiv-id": "1607.00064v1", 
    "author": "Peter Milder", 
    "publish": "2016-06-30T22:10:13Z", 
    "summary": "Convolutional neural networks (CNNs) are revolutionizing a variety of machine\nlearning tasks, but they present significant computational challenges.\nRecently, FPGA-based accelerators have been proposed to improve the speed and\nefficiency of CNNs. Current approaches construct a single processor that\ncomputes the CNN layers one at a time; this single processor is optimized to\nmaximize the overall throughput at which the collection of layers are computed.\nHowever, this approach leads to inefficient designs because the same processor\nstructure is used to compute CNN layers of radically varying dimensions.\n  We present a new CNN accelerator paradigm and an accompanying automated\ndesign methodology that partitions the available FPGA resources into multiple\nprocessors, each of which is tailored for a different subset of the CNN\nconvolutional layers. Using the same FPGA resources as a single large\nprocessor, multiple smaller specialized processors result in increased\ncomputational efficiency and lead to a higher overall throughput. Our design\nmethodology achieves 1.51x higher throughput than the state of the art approach\non evaluating the popular AlexNet CNN on a Xilinx Virtex-7 FPGA. Our\nprojections indicate that the benefit of our approach increases with the amount\nof available FPGA resources, already growing to over 3x over the state of the\nart within the next generation of FPGAs."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1607.02318v1", 
    "title": "The Renewed Case for the Reduced Instruction Set Computer: Avoiding ISA   Bloat with Macro-Op Fusion for RISC-V", 
    "arxiv-id": "1607.02318v1", 
    "author": "Krste Asanovi\u0107", 
    "publish": "2016-07-08T11:15:31Z", 
    "summary": "This report makes the case that a well-designed Reduced Instruction Set\nComputer (RISC) can match, and even exceed, the performance and code density of\nexisting commercial Complex Instruction Set Computers (CISC) while maintaining\nthe simplicity and cost-effectiveness that underpins the original RISC goals.\n  We begin by comparing the dynamic instruction counts and dynamic instruction\nbytes fetched for the popular proprietary ARMv7, ARMv8, IA-32, and x86-64\nInstruction Set Architectures (ISAs) against the free and open RISC-V RV64G and\nRV64GC ISAs when running the SPEC CINT2006 benchmark suite. RISC-V was designed\nas a very small ISA to support a wide range of implementations, and has a less\nmature compiler toolchain. However, we observe that on SPEC CINT2006 RV64G\nexecutes on average 16% more instructions than x86-64, 3% more instructions\nthan IA-32, 9% more instructions than ARMv8, but 4% fewer instructions than\nARMv7.\n  CISC x86 implementations break up complex instructions into smaller internal\nRISC-like micro-ops, and the RV64G instruction count is within 2% of the x86-64\nretired micro-op count. RV64GC, the compressed variant of RV64G, is the densest\nISA studied, fetching 8% fewer dynamic instruction bytes than x86-64. We\nobserved that much of the increased RISC-V instruction count is due to a small\nset of common multi-instruction idioms.\n  Exploiting this fact, the RV64G and RV64GC effective instruction count can be\nreduced by 5.4% on average by leveraging macro-op fusion. Combining the\ncompressed RISC-V ISA extension with macro-op fusion provides both the densest\nISA and the fewest dynamic operations retired per program, reducing the\nmotivation to add more instructions to the ISA. This approach retains a single\nsimple ISA suitable for both low-end and high-end implementations, where\nhigh-end implementations can boost performance through microarchitectural\ntechniques."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1607.03238v5", 
    "title": "Scratchpad Sharing in GPUs", 
    "arxiv-id": "1607.03238v5", 
    "author": "Amey Karkare", 
    "publish": "2016-07-12T06:45:08Z", 
    "summary": "GPGPU applications exploit on-chip scratchpad memory available in the\nGraphics Processing Units (GPUs) to improve performance. The amount of thread\nlevel parallelism present in the GPU is limited by the number of resident\nthreads, which in turn depends on the availability of scratchpad memory in its\nstreaming multiprocessor (SM). Since the scratchpad memory is allocated at\nthread block granularity, part of the memory may remain unutilized. In this\npaper, we propose architectural and compiler optimizations to improve the\nscratchpad utilization. Our approach, Scratchpad Sharing, addresses scratchpad\nunder-utilization by launching additional thread blocks in each SM. These\nthread blocks use unutilized scratchpad and also share scratchpad with other\nresident blocks. To improve the performance of scratchpad sharing, we propose\nOwner Warp First (OWF) scheduling that schedules warps from the additional\nthread blocks effectively. The performance of this approach, however, is\nlimited by the availability of the shared part of scratchpad.\n  We propose compiler optimizations to improve the availability of shared\nscratchpad. We describe a scratchpad allocation scheme that helps in allocating\nscratchpad variables such that shared scratchpad is accessed for short\nduration. We introduce a new instruction, relssp, that when executed, releases\nthe shared scratchpad. Finally, we describe an analysis for optimal placement\nof relssp instructions such that shared scratchpad is released as early as\npossible.\n  We implemented the hardware changes using the GPGPU-Sim simulator and\nimplemented the compiler optimizations in Ocelot framework. We evaluated the\neffectiveness of our approach on 19 kernels from 3 benchmarks suites: CUDA-SDK,\nGPGPU-Sim, and Rodinia. The kernels that underutilize scratchpad memory show an\naverage improvement of 19% and maximum improvement of 92.17% compared to the\nbaseline approach."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1607.07766v2", 
    "title": "Uber: Utilizing Buffers to Simplify NoCs for Hundreds-Cores", 
    "arxiv-id": "1607.07766v2", 
    "author": "Giorgos Passas", 
    "publish": "2016-07-26T15:53:54Z", 
    "summary": "Approaching ideal wire latency using a network-on-chip (NoC) is an important\npractical problem for many-core systems, particularly hundreds-cores. Although\nother researchers have focused on optimizing large meshes, bypassing or\nspeculating router pipelines, or creating more intricate logarithmic\ntopologies, this paper proposes a balanced combination that trades queue\nbuffers for simplicity. Preliminary analysis of nine benchmarks from PARSEC and\nSPLASH using execution-driven simulation shows that utilization rises from 2%\nwhen connecting a single core per mesh port to at least 50%, as slack for delay\nin concentrator and router queues is around 6x higher compared to the ideal\nlatency of just 20 cycles. That is, a 16-port mesh suffices because queueing is\nthe uncommon case for system performance. In this way, the mesh hop count is\nbounded to three, as load becomes uniform via extended concentration, and ideal\nlatency is approached using conventional four-stage pipelines for the mesh\nrouters together with minor logarithmic edges. A realistic Uber is also\ndetailed, featuring the same performance as a 64-port mesh that employs\noptimized router pipelines, improving the baseline by 12%. Ongoing work\ndevelops techniques to better balance load by tuning the placement of cache\nblocks, and compares Uber with bufferless routing."
},{
    "category": "cs.AR", 
    "doi": "10.1186/s40064-016-2074-z", 
    "link": "http://arxiv.org/pdf/1608.01225v1", 
    "title": "Early Output Hybrid Input Encoded Asynchronous Full Adder and   Relative-Timed Ripple Carry Adder", 
    "arxiv-id": "1608.01225v1", 
    "author": "K Prasad", 
    "publish": "2016-08-03T15:40:01Z", 
    "summary": "This paper presents a new early output hybrid input encoded asynchronous full\nadder designed using dual-rail and 1-of-4 delay-insensitive data codes. The\nproposed full adder when cascaded to form a ripple carry adder (RCA)\nnecessitates the use of a small relative-timing assumption with respect to the\ninternal carries, which is independent of the RCA size. The forward latency of\nthe proposed hybrid input encoded full adder based RCA is data-dependent while\nits reverse latency is the least equaling the propagation delay of just one\nfull adder. Compared to the best of the existing hybrid input encoded full\nadders based 32-bit RCAs, the proposed early output hybrid input encoded full\nadder based 32-bit RCA enables respective reductions in forward latency and\narea by 7.9% and 5.6% whilst dissipating the same average power; in terms of\nthe theoretically computed cycle time, the latter reports a 10.9% reduction\ncompared to the former."
},{
    "category": "cs.AR", 
    "doi": "10.1145/3037697.3037719", 
    "link": "http://arxiv.org/pdf/1608.07547v2", 
    "title": "TriCheck: Memory Model Verification at the Trisection of Software,   Hardware, and ISA", 
    "arxiv-id": "1608.07547v2", 
    "author": "Margaret Martonosi", 
    "publish": "2016-08-26T18:13:57Z", 
    "summary": "Memory consistency models (MCMs) which govern inter-module interactions in a\nshared memory system, are a significant, yet often under-appreciated, aspect of\nsystem design. MCMs are defined at the various layers of the hardware-software\nstack, requiring thoroughly verified specifications, compilers, and\nimplementations at the interfaces between layers. Current verification\ntechniques evaluate segments of the system stack in isolation, such as proving\ncompiler mappings from a high-level language (HLL) to an ISA or proving\nvalidity of a microarchitectural implementation of an ISA.\n  This paper makes a case for full-stack MCM verification and provides a\ntoolflow, TriCheck, capable of verifying that the HLL, compiler, ISA, and\nimplementation collectively uphold MCM requirements. The work showcases\nTriCheck's ability to evaluate a proposed ISA MCM in order to ensure that each\nlayer and each mapping is correct and complete. Specifically, we apply TriCheck\nto the open source RISC-V ISA, seeking to verify accurate, efficient, and legal\ncompilations from C11. We uncover under-specifications and potential\ninefficiencies in the current RISC-V ISA documentation and identify possible\nsolutions for each. As an example, we find that a RISC-V-compliant\nmicroarchitecture allows 144 outcomes forbidden by C11 to be observed out of\n1,701 litmus tests examined. Overall, this paper demonstrates the necessity of\nfull-stack verification for detecting MCM-related bugs in the hardware-software\nstack."
},{
    "category": "cs.AR", 
    "doi": "10.1145/3037697.3037719", 
    "link": "http://arxiv.org/pdf/1608.08376v1", 
    "title": "A near-threshold RISC-V core with DSP extensions for scalable IoT   Endpoint Devices", 
    "arxiv-id": "1608.08376v1", 
    "author": "Luca Benini", 
    "publish": "2016-08-30T09:14:14Z", 
    "summary": "Endpoint devices for Internet-of-Things not only need to work under extremely\ntight power envelope of a few milliwatts, but also need to be flexible in their\ncomputing capabilities, from a few kOPS to GOPS. Near-threshold(NT) operation\ncan achieve higher energy efficiency, and the performance scalability can be\ngained through parallelism. In this paper we describe the design of an\nopen-source RISC-V processor core specifically designed for NT operation in\ntightly coupled multi-core clusters. We introduce instruction-extensions and\nmicroarchitectural optimizations to increase the computational density and to\nminimize the pressure towards the shared memory hierarchy. For typical\ndata-intensive sensor processing workloads the proposed core is on average 3.5x\nfaster and 3.2x more energy-efficient, thanks to a smart L0 buffer to reduce\ncache access contentions and support for compressed instructions. SIMD\nextensions, such as dot-products, and a built-in L0 storage further reduce the\nshared memory accesses by 8x reducing contentions by 3.2x. With four\nNT-optimized cores, the cluster is operational from 0.6V to 1.2V achieving a\npeak efficiency of 67MOPS/mW in a low-cost 65nm bulk CMOS technology. In a low\npower 28nm FDSOI process a peak efficiency of 193MOPS/mW(40MHz, 1mW) can be\nachieved."
},{
    "category": "cs.AR", 
    "doi": "10.1145/3037697.3037719", 
    "link": "http://arxiv.org/pdf/1609.00306v1", 
    "title": "On-Chip Mechanisms to Reduce Effective Memory Access Latency", 
    "arxiv-id": "1609.00306v1", 
    "author": "Milad Hashemi", 
    "publish": "2016-09-01T16:32:54Z", 
    "summary": "This dissertation develops hardware that automatically reduces the effective\nlatency of accessing memory in both single-core and multi-core systems. To\naccomplish this, the dissertation shows that all last level cache misses can be\nseparated into two categories: dependent cache misses and independent cache\nmisses. Independent cache misses have all of the source data that is required\nto generate the address of the memory access available on-chip, while dependent\ncache misses depend on data that is located off-chip. This dissertation\nproposes that dependent cache misses are accelerated by migrating the\ndependence chain that generates the address of the memory access to the memory\ncontroller for execution. Independent cache misses are accelerated using a new\nmode for runahead execution that only executes filtered dependence chains. With\nthese mechanisms, this dissertation demonstrates a 62% increase in performance\nand a 19% decrease in effective memory access latency for a quad-core processor\non a set of high memory intensity workloads."
},{
    "category": "cs.AR", 
    "doi": "10.1145/3037697.3037719", 
    "link": "http://arxiv.org/pdf/1609.01585v1", 
    "title": "A Hardware-Efficient Approach to Computing the Rotation Matrix from a   Quaternion", 
    "arxiv-id": "1609.01585v1", 
    "author": "Galina Cariowa", 
    "publish": "2016-09-06T14:54:26Z", 
    "summary": "In this paper, we have proposed a novel VLSI-oriented approach to computing\nthe rotation matrix entries from the quaternion coefficients. The advantage of\nthis approach is the complete elimination of multiplications and replacing them\nby less costly squarings. Our approach uses Logan's identity, which proposes to\nreplace the calculation of the product of two numbers on summing the squares\nvia the Binomial Theorem. Replacing multiplications by squarings implies\nreducing power consumption as well as decreases hardware circuit complexity."
},{
    "category": "cs.AR", 
    "doi": "10.1145/3037697.3037719", 
    "link": "http://arxiv.org/pdf/1609.03897v3", 
    "title": "Design of a Ternary Edge-Triggered D Flip-Flap-Flop for Multiple-Valued   Sequential Logic", 
    "arxiv-id": "1609.03897v3", 
    "author": "Niloofar Farahani", 
    "publish": "2016-09-13T15:33:06Z", 
    "summary": "Development of large computerized systems requires both combinational and\nsequential circuits. Registers and counters are two important examples of\nsequential circuits, which are widely used in practical applications like CPUs.\nThe basic element of sequential logic is Flip-Flop, which stores an input value\nand returns two outputs (Q and Q_bar). This paper presents an innovative\nternary D Flip-Flap-Flop, which offers circuit designers to customize their\ndesign by eliminating one of the outputs if it is not required. This unique\nfeature of the new design leads to considerable power reduction in comparison\nwith the previously presented structures. The proposed design is simulated and\ntested by HSPICE and 45 nm CMOS technology."
},{
    "category": "cs.AR", 
    "doi": "10.1145/3037697.3037719", 
    "link": "http://arxiv.org/pdf/1609.04913v1", 
    "title": "Design of an Optoelectronic State Machine with integrated BDD based   Optical logic", 
    "arxiv-id": "1609.04913v1", 
    "author": "Macauley Coggins", 
    "publish": "2016-09-16T06:13:37Z", 
    "summary": "In this paper I demonstrate a novel design for an optoelectronic State\nMachine which replaces input/output forming logic found in conventional state\nmachines with BDD based optical logic while still using solid state memory in\nthe form of flip-flops in order to store states. This type of logic makes use\nof waveguides and ring resonators to create binary switches. These switches in\nturn can be used to create combinational logic which can be used as\ninput/output forming logic for a state machine. Replacing conventional\ncombinational logic with BDD based optical logic allows for a faster range of\nstate machines that can certainly outperform conventional state machines as\npropagation delays within the logic described are in the order of picoseconds\nas opposed to nanoseconds in digital logic."
},{
    "category": "cs.AR", 
    "doi": "10.1145/3037697.3037719", 
    "link": "http://arxiv.org/pdf/1609.07234v1", 
    "title": "Reducing DRAM Access Latency by Exploiting DRAM Leakage Characteristics   and Common Access Patterns", 
    "arxiv-id": "1609.07234v1", 
    "author": "Hasan Hassan", 
    "publish": "2016-09-23T05:31:18Z", 
    "summary": "DRAM-based memory is a critical factor that creates a bottleneck on the\nsystem performance since the processor speed largely outperforms the DRAM\nlatency. In this thesis, we develop a low-cost mechanism, called ChargeCache,\nwhich enables faster access to recently-accessed rows in DRAM, with no\nmodifications to DRAM chips. Our mechanism is based on the key observation that\na recently-accessed row has more charge and thus the following access to the\nsame row can be performed faster. To exploit this observation, we propose to\ntrack the addresses of recently-accessed rows in a table in the memory\ncontroller. If a later DRAM request hits in that table, the memory controller\nuses lower timing parameters, leading to reduced DRAM latency. Row addresses\nare removed from the table after a specified duration to ensure rows that have\nleaked too much charge are not accessed with lower latency. We evaluate\nChargeCache on a wide variety of workloads and show that it provides\nsignificant performance and energy benefits for both single-core and multi-core\nsystems."
},{
    "category": "cs.AR", 
    "doi": "10.1145/3037697.3037719", 
    "link": "http://arxiv.org/pdf/1610.00751v1", 
    "title": "An overview about Networks-on-Chip with multicast suppor", 
    "arxiv-id": "1610.00751v1", 
    "author": "Marcelo Daniel Berejuck", 
    "publish": "2016-10-03T20:59:17Z", 
    "summary": "Modern System-on-Chip (SoC) platforms typically consist of multiple\nprocessors and a communication interconnect between them. Network-on-Chip (NoC)\narises as a solution to interconnect these systems, which provides a scalable,\nreusable, and an efficient interconnect. For these SoC platforms, multicast\ncommunication is significantly used for parallel applications. Cache coherency\nin distributed sharedmemory,clock synchronization, replication, or barrier\nsynchronization are examples of these requests. This paper presents an overview\nof research on NoC with support for multicast communication and delineates the\nmajor issues addressed so far by the scientific community in this investigation\narea."
},{
    "category": "cs.AR", 
    "doi": "10.1145/3037697.3037719", 
    "link": "http://arxiv.org/pdf/1610.01832v1", 
    "title": "Epiphany-V: A 1024 processor 64-bit RISC System-On-Chip", 
    "arxiv-id": "1610.01832v1", 
    "author": "Andreas Olofsson", 
    "publish": "2016-10-06T12:05:14Z", 
    "summary": "This paper describes the design of a 1024-core processor chip in 16nm FinFet\ntechnology. The chip (\"Epiphany-V\") contains an array of 1024 64-bit RISC\nprocessors, 64MB of on-chip SRAM, three 136-bit wide mesh Networks-On-Chip, and\n1024 programmable IO pins. The chip has taped out and is being manufactured by\nTSMC.\n  This research was developed with funding from the Defense Advanced Research\nProjects Agency (DARPA). The views, opinions and/or findings expressed are\nthose of the author and should not be interpreted as representing the official\nviews or policies of the Department of Defense or the U.S. Government."
},{
    "category": "cs.AR", 
    "doi": "10.1145/3037697.3037719", 
    "link": "http://arxiv.org/pdf/1610.02094v1", 
    "title": "Validating Simplified Processor Models in Architectural Studies", 
    "arxiv-id": "1610.02094v1", 
    "author": "Arvind", 
    "publish": "2016-10-06T23:21:05Z", 
    "summary": "Cycle-accurate software simulation of multicores with complex\nmicroarchitectures is often excruciatingly slow. People use simplified core\nmodels to gain simulation speed. However, a persistent question is to what\nextent the results derived from a simplified core model can be used to\ncharacterize the behavior of a real machine.\n  We propose a new methodology of validating simplified simulation models,\nwhich focuses on the trends of metric values across benchmarks and\narchitectures, instead of errors of absolute metric values. To illustrate this\nmethodology, we conduct a case study using an FPGA-accelerated cycle-accurate\nfull system simulator. We evaluated three cache replacement polices on a\n10-stage in-order core model, and then re-conducted all the experiments by\nsubstituting a 1-IPC core model for the 10-stage core model. We found that the\n1-IPC core model generally produces qualitatively the same results as the\naccurate core model except for a few mismatches. We argue that most observed\nmismatches were either indistinguishable from experimental noise or\ncorresponded to the cases where the policy differences even in the accurate\nmodel showed inconclusive results. We think it is fair to use simplified core\nmodels to study a feature once the influence of the simplification is\nunderstood. Additional studies on branch predictors and scaling properties of\nmultithread benchmarks reinforce our argument. However, the validation of a\nsimplified model requires a detailed cycle-accurate model!"
},{
    "category": "cs.AR", 
    "doi": "10.1145/3037697.3037719", 
    "link": "http://arxiv.org/pdf/1610.07501v1", 
    "title": "A 481pJ/decision 3.4M decision/s Multifunctional Deep In-memory   Inference Processor using Standard 6T SRAM Array", 
    "arxiv-id": "1610.07501v1", 
    "author": "Naresh Shanbhag", 
    "publish": "2016-10-24T17:24:56Z", 
    "summary": "This paper describes a multi-functional deep in-memory processor for\ninference applications. Deep in-memory processing is achieved by embedding\npitch-matched low-SNR analog processing into a standard 6T 16KB SRAM array in\n65 nm CMOS. Four applications are demonstrated. The prototype achieves up to\n5.6X (9.7X estimated for multi-bank scenario) energy savings with negligible\n(<1%) accuracy degradation in all four applications as compared to the\nconventional architecture."
},{
    "category": "cs.AR", 
    "doi": "10.1145/3037697.3037719", 
    "link": "http://arxiv.org/pdf/1610.08705v2", 
    "title": "Accelerating BLAS and LAPACK via Efficient Floating Point Architecture   Design", 
    "arxiv-id": "1610.08705v2", 
    "author": "Ranjani Narayan", 
    "publish": "2016-10-27T11:02:38Z", 
    "summary": "Basic Linear Algebra Subprograms (BLAS) and Linear Algebra Package (LAPACK)\nform basic building blocks for several High Performance Computing (HPC)\napplications and hence dictate performance of the HPC applications. Performance\nin such tuned packages is attained through tuning of several algorithmic and\narchitectural parameters such as number of parallel operations in the Directed\nAcyclic Graph of the BLAS/LAPACK routines, sizes of the memories in the memory\nhierarchy of the underlying platform, bandwidth of the memory, and structure of\nthe compute resources in the underlying platform. In this paper, we closely\ninvestigate the impact of the Floating Point Unit (FPU) micro-architecture for\nperformance tuning of BLAS and LAPACK. We present theoretical analysis for\npipeline depth of different floating point operations like multiplier, adder,\nsquare root, and divider followed by characterization of BLAS and LAPACK to\ndetermine several parameters required in the theoretical framework for deciding\noptimum pipeline depth of the floating operations. A simple design of a\nProcessing Element (PE) is presented and shown that the PE outperforms the most\nrecent custom realizations of BLAS and LAPACK by 1.1X to 1.5X in Gflops/W, and\n1.9X to 2.1X in Gflops/mm^2."
},{
    "category": "cs.AR", 
    "doi": "10.1145/3037697.3037719", 
    "link": "http://arxiv.org/pdf/1610.09603v1", 
    "title": "The Processing Using Memory Paradigm:In-DRAM Bulk Copy, Initialization,   Bitwise AND and OR", 
    "arxiv-id": "1610.09603v1", 
    "author": "Onur Mutlu", 
    "publish": "2016-10-30T05:01:54Z", 
    "summary": "In existing systems, the off-chip memory interface allows the memory\ncontroller to perform only read or write operations. Therefore, to perform any\noperation, the processor must first read the source data and then write the\nresult back to memory after performing the operation. This approach consumes\nhigh latency, bandwidth, and energy for operations that work on a large amount\nof data. Several works have proposed techniques to process data near memory by\nadding a small amount of compute logic closer to the main memory chips. In this\narticle, we describe two techniques proposed by recent works that take this\napproach of processing in memory further by exploiting the underlying operation\nof the main memory technology to perform more complex tasks. First, we describe\nRowClone, a mechanism that exploits DRAM technology to perform bulk copy and\ninitialization operations completely inside main memory. We then describe a\ncomplementary work that uses DRAM to perform bulk bitwise AND and OR operations\ninside main memory. These two techniques significantly improve the performance\nand energy efficiency of the respective operations."
},{
    "category": "cs.AR", 
    "doi": "10.1145/3037697.3037719", 
    "link": "http://arxiv.org/pdf/1610.09604v1", 
    "title": "Reducing DRAM Latency by Exploiting Design-Induced Latency Variation in   Modern DRAM Chips", 
    "arxiv-id": "1610.09604v1", 
    "author": "Onur Mutlu", 
    "publish": "2016-10-30T05:21:07Z", 
    "summary": "Variation has been shown to exist across the cells within a modern DRAM chip.\nPrior work has studied and exploited several prior forms of this variation,\nsuch as manufacturing-process- or temperature-induced variation. We empirically\nobserve a new form of variation that exists within a DRAM chip, induced by the\ndesign and placement of different components in the DRAM chip, where different\nregions in DRAM, based on their relative distance from the peripheral\nstructures, require different minimum access latencies for reliable operation.\nIn particular, cells closer to the peripheral structures can be accessed much\nfaster than cells that are farther. We call this phenomenon design-induced\nvariation in DRAM. Our goal, in this work, is to understand and exploit\ndesign-induced variation to develop low-cost mechanisms to dynamically find and\nuse the lowest latency a DRAM chip can reliably operate at and thus improve\noverall system performance while ensuring reliable system operation.\n  To this end, we first experimentally demonstrate and analyze designed-induced\nvariation in modern DRAM devices by testing and characterizing 96 DIMMs (768\nDRAM chips). Our characterization identifies DRAM regions that are vulnerable\nto errors, if operated at lower latency, and finds consistency in their\nlocations across a given DRAM chip generation, due to design-induced variation.\nBased on our experimental analysis, we develop two mechanisms that reliably\nreduce DRAM latency."
},{
    "category": "cs.AR", 
    "doi": "10.1145/3037697.3037719", 
    "link": "http://arxiv.org/pdf/1610.09761v1", 
    "title": "ARAPrototyper: Enabling Rapid Prototyping and Evaluation for   Accelerator-Rich Architectures", 
    "arxiv-id": "1610.09761v1", 
    "author": "Peipei Zhou", 
    "publish": "2016-10-31T02:29:23Z", 
    "summary": "Compared to conventional general-purpose processors, accelerator-rich\narchitectures (ARAs) can provide orders-of-magnitude performance and energy\ngains and are emerging as one of the most promising solutions in the age of\ndark silicon. However, many design issues related to the complex interaction\nbetween general-purpose cores, accelerators, customized on-chip interconnects,\nand memory systems remain unclear and difficult to evaluate.\n  In this paper we design and implement the ARAPrototyper to enable rapid\ndesign space explorations for ARAs in real silicons and reduce the tedious\nprototyping efforts far down to manageable efforts. First, ARAPrototyper\nprovides a reusable baseline prototype with a highly customizable memory\nsystem, including interconnect between accelerators and buffers, interconnect\nbetween buffers and last-level cache (LLC) or DRAM, coherency choice at LLC or\nDRAM, and address translation support. Second, ARAPrototyper provides a clean\ninterface to quickly integrate users' own accelerators written in high-level\nsynthesis (HLS) code. The whole design flow is highly automated to generate a\nprototype of ARA on an FPGA system-on-chip (SoC). Third, to quickly develop\napplications that run seamlessly on the ARA prototype, ARAPrototyper provides a\nsystem software stack, abstracts the accelerators as software libraries, and\nprovides APIs for software developers. Our experimental results demonstrate\nthat ARAPrototyper enables a wide range of design space explorations for ARAs\nat manageable prototyping efforts, which has 4,000X to 10,000X faster\nevaluation time than full-system simulations. We believe that ARAPrototyper can\nbe an attractive alternative for ARA design and evaluation."
},{
    "category": "cs.AR", 
    "doi": "10.1145/3037697.3037719", 
    "link": "http://arxiv.org/pdf/1611.02450v1", 
    "title": "PipeCNN: An OpenCL-Based FPGA Accelerator for Large-Scale Convolution   Neuron Networks", 
    "arxiv-id": "1611.02450v1", 
    "author": "Ke Xu", 
    "publish": "2016-11-08T09:43:03Z", 
    "summary": "Convolutional neural networks (CNNs) have been widely employed in many\napplications such as image classification, video analysis and speech\nrecognition. Being compute-intensive, CNN computations are mainly accelerated\nby GPUs with high power dissipations. Recently, studies were carried out\nexploiting FPGA as CNN accelerator because of its reconfigurability and energy\nefficiency advantage over GPU, especially when OpenCL-based high-level\nsynthesis tools are now available providing fast verification and\nimplementation flows. Previous OpenCL-based design only focused on creating a\ngeneric framework to identify performance-related hardware parameters, without\nutilizing FPGA's special capability of pipelining kernel functions to minimize\nmemory bandwidth requirement. In this work, we propose an FPGA accelerator with\na new architecture of deeply pipelined OpenCL kernels. Data reuse and task\nmapping techniques are also presented to improve design efficiency. The\nproposed schemes are verified by implementing two representative large-scale\nCNNs, AlexNet and VGG on Altera Stratix-V A7 FPGA. We have achieved a similar\npeak performance of 33.9 GOPS with a 34% resource reduction on DSP blocks\ncompared to previous work. Our design is openly accessible and thus can be\nreused to explore new architectures for neural network accelerators."
},{
    "category": "cs.AR", 
    "doi": "10.1145/3037697.3037719", 
    "link": "http://arxiv.org/pdf/1611.02792v1", 
    "title": "Non-volatile Hierarchical Temporal Memory: Hardware for Spatial Pooling", 
    "arxiv-id": "1611.02792v1", 
    "author": "Kevin Gomez", 
    "publish": "2016-11-09T01:25:59Z", 
    "summary": "Hierarchical Temporal Memory (HTM) is a biomimetic machine learning algorithm\nimbibing the structural and algorithmic properties of the neocortex. Two main\nfunctional components of HTM that enable spatio-temporal processing are the\nspatial pooler and temporal memory. In this research, we explore a scalable\nhardware realization of the spatial pooler closely coupled with the\nmathematical formulation of spatial pooler. This class of neuromorphic\nalgorithms are advantageous in solving a subset of the future engineering\nproblems by extracting nonintuitive patterns in complex data. The proposed\narchitecture, Non-volatile HTM (NVHTM), leverages large-scale solid state flash\nmemory to realize a optimal memory organization, area and power envelope. A\nbehavioral model of NVHTM is evaluated against the MNIST dataset, yielding\n91.98% classification accuracy. A full custom layout is developed to validate\nthe design in a TSMC 180nm process. The area and power profile of the spatial\npooler are 30.538mm2 and 64.394mW, respectively. This design is a\nproof-of-concept that storage processing is a viable platform for large scale\nHTM network models."
},{
    "category": "cs.AR", 
    "doi": "10.14810/ecij.2015.4301", 
    "link": "http://arxiv.org/pdf/1611.02915v1", 
    "title": "Power Gating Structure for Reversible Programmable Logic Array", 
    "arxiv-id": "1611.02915v1", 
    "author": "Pradeep Singla", 
    "publish": "2015-10-17T04:27:53Z", 
    "summary": "Throughout the world, the numbers of researchers or hardware designer\nstruggle for the reducing of power dissipation in low power VLSI systems. This\npaper presented an idea of using the power gating structure for reducing the\nsub threshold leakage in the reversible system. This concept presented in the\npaper is entirely new and presented in the literature of reversible logics. By\nusing the reversible logics for the digital systems, the energy can be saved up\nto the gate level implementation. But at the physical level designing of the\nreversible logics by the modern CMOS technology the heat or energy is\ndissipated due the sub-threshold leakage at the time of inactivity or standby\nmode. The Reversible Programming logic array (RPLA) is one of the important\nparts of the low power industrial applications and in this paper the physical\ndesign of the RPLA is presented by using the sleep transistor and the results\nis shown with the help of TINA- PRO software. The results for the proposed\ndesign is also compare with the CMOS design and shown that of 40.8% of energy\nsaving. The Transient response is also produces in the paper for the switching\nactivity and showing that the proposed design is much better that the modern\nCMOS design of the RPLA."
},{
    "category": "cs.AR", 
    "doi": "10.14810/ecij.2015.4301", 
    "link": "http://arxiv.org/pdf/1611.05415v1", 
    "title": "Multipliers: comparison of Fourier transformation based method and   Synopsys design technique for up to 32 bits inputs in regular and saturation   arithmetics", 
    "arxiv-id": "1611.05415v1", 
    "author": "Danila Gorodecky", 
    "publish": "2016-11-16T19:39:08Z", 
    "summary": "The technique for hardware multiplication based upon Fourier transformation\nhas been introduced. The technique has the highest efficiency on multiplication\nunits with up to 8 bit range. Each multiplication unit is realized on base of\nthe minimized Boolean functions. Experimental data showed that this technique\nthe multiplication process speed up to 20% higher for 2-8 bit range of input\noperands and up to 3% higher for 8-32 bit range of input operands than\nanalogues designed by Synopsys technique."
},{
    "category": "cs.AR", 
    "doi": "10.14810/ecij.2015.4301", 
    "link": "http://arxiv.org/pdf/1611.09446v1", 
    "title": "FPGA Based Implementation of Distributed Minority and Majority Voting   Based Redundancy for Mission and Safety-Critical Applications", 
    "arxiv-id": "1611.09446v1", 
    "author": "N E Mastorakis", 
    "publish": "2016-11-29T00:48:14Z", 
    "summary": "Electronic circuits and systems used in mission and safety-critical\napplications usually employ redundancy in the design to overcome arbitrary\nfault(s) or failure(s) and guarantee the correct operation. In this context,\nthe distributed minority and majority voting based redundancy (DMMR) scheme\nforms an efficient alternative to the conventional N-modular redundancy (NMR)\nscheme for implementing mission and safety-critical circuits and systems by\nsignificantly minimizing their weight and design cost and also their design\nmetrics whilst providing a similar degree of fault tolerance. This article\npresents the first FPGAs based implementation of example DMMR circuits and\ncompares it with counterpart NMR circuits on the basis of area occupancy and\ncritical path delay viz. area-delay product (ADP). The example DMMR circuits\nand counterpart NMR circuits are able to accommodate the faulty or failure\nstates of 2, 3 and 4 function modules. For physical synthesis, two commercial\nXilinx FPGAs viz. Spartan 3E and Virtex 5 corresponding to 90nm and 65nm CMOS\nprocesses, and two radiation-tolerant and military grade Xilinx FPGAs viz. QPro\nVirtex 2 and QPro Virtex E corresponding to 150nm and 180nm CMOS processes were\nconsidered for the NMR and DMMR circuit realizations which employ the 4-by-4\narray multiplier as a representative function module. To achieve a fault\ntolerance of 2 function modules, both the DMMR and the NMR schemes provide near\nsimilar mean ADPs across all the four FPGAs. But while achieving a fault\ntolerance of 3 function modules the DMMR features reduced ADP by 44.5% on\naverage compared to the NMR, and in achieving a fault tolerance of 4 function\nmodules the DMMR reports reduced ADP by 56.5% on average compared to the NMR\nwith respect to all the four FPGAs considered."
},{
    "category": "cs.AR", 
    "doi": "10.14810/ecij.2015.4301", 
    "link": "http://arxiv.org/pdf/1611.09452v2", 
    "title": "An Efficient Partial Sums Generator for Constituent Code based   Successive Cancellation Decoding of Polar Codes", 
    "arxiv-id": "1611.09452v2", 
    "author": "Gwan Choi", 
    "publish": "2016-11-29T01:28:58Z", 
    "summary": "This paper proposes the architecture of partial sum generator for constituent\ncodes based polar code decoder. Constituent codes based polar code decoder has\nthe advantage of low latency. However, no purposefully designed partial sum\ngenerator design exists that can yield desired timing for the decoder. We first\nderive the mathematical presentation with the partial sums set $\\bm{\\beta^c}$\nwhich is corresponding to each constituent codes. From this, we concoct a\nshift-register based partial sum generator. Next, the overall architecture and\ndesign details are described, and the overhead compared with conventional\npartial sum generator is evaluated. Finally, the implementation results with\nboth ASIC and FPGA technology and relevant discussions are presented."
},{
    "category": "cs.AR", 
    "doi": "10.14810/ecij.2015.4301", 
    "link": "http://arxiv.org/pdf/1611.09988v1", 
    "title": "Buddy-RAM: Improving the Performance and Efficiency of Bulk Bitwise   Operations Using DRAM", 
    "arxiv-id": "1611.09988v1", 
    "author": "Todd C. Mowry", 
    "publish": "2016-11-30T03:34:57Z", 
    "summary": "Bitwise operations are an important component of modern day programming. Many\nwidely-used data structures (e.g., bitmap indices in databases) rely on fast\nbitwise operations on large bit vectors to achieve high performance.\nUnfortunately, in existing systems, regardless of the underlying architecture\n(e.g., CPU, GPU, FPGA), the throughput of such bulk bitwise operations is\nlimited by the available memory bandwidth.\n  We propose Buddy, a new mechanism that exploits the analog operation of DRAM\nto perform bulk bitwise operations completely inside the DRAM chip. Buddy\nconsists of two components. First, simultaneous activation of three DRAM rows\nthat are connected to the same set of sense amplifiers enables us to perform\nbitwise AND and OR operations. Second, the inverters present in each sense\namplifier enables us to perform bitwise NOT operations, with modest changes to\nthe DRAM array. These two components make Buddy functionally complete. Our\nimplementation of Buddy largely exploits the existing DRAM structure and\ninterface, and incurs low overhead (1% of DRAM chip area).\n  Our evaluations based on SPICE simulations show that, across seven\ncommonly-used bitwise operations, Buddy provides between 10.9X---25.6X\nimprovement in raw throughput and 25.1X---59.5X reduction in energy\nconsumption. We evaluate three real-world data-intensive applications that\nexploit bitwise operations: 1) bitmap indices, 2) BitWeaving, and 3)\nbitvector-based implementation of sets. Our evaluations show that Buddy\nsignificantly outperforms the state-of-the-art."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IISWC.2016.7581279", 
    "link": "http://arxiv.org/pdf/1611.10316v1", 
    "title": "Memory Controller Design Under Cloud Workloads", 
    "arxiv-id": "1611.10316v1", 
    "author": "Andreas Moshovos", 
    "publish": "2016-11-30T19:09:07Z", 
    "summary": "This work studies the behavior of state-of-the-art memory controller designs\nwhen executing scale-out workloads. It considers memory scheduling techniques,\nmemory page management policies, the number of memory channels, and the address\nmapping scheme used. Experimental measurements demonstrate: 1)~Several recently\nproposed memory scheduling policies are not a good match for these scale-out\nworkloads. 2)~The relatively simple First-Ready-First-Come-First-Served\n(FR-FCFS) policy performs consistently better, and 3)~for most of the studied\nworkloads, the even simpler First-Come-First-Served scheduling policy is within\n1\\% of FR-FCFS. 4)~Increasing the number of memory channels offers negligible\nperformance benefits, e.g., performance improves by 1.7\\% on average for\n4-channels vs. 1-channel. 5)~77\\%-90\\% of DRAM rows activations are accessed\nonly once before closure. These observation can guide future development and\noptimization of memory controllers for scale-out workloads."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IISWC.2016.7581279", 
    "link": "http://arxiv.org/pdf/1612.04277v1", 
    "title": "Copycat: A High Precision Real Time NAND Simulator", 
    "arxiv-id": "1612.04277v1", 
    "author": "Sang Lyul Min", 
    "publish": "2016-12-12T01:43:11Z", 
    "summary": "In this paper, we describe the design and implementation of a high precision\nreal time NAND simulator called Copycat that runs on a commodity multi-core\ndesktop environment. This NAND simulator facilitates the development of\nembedded flash memory management software such as the flash translation layer\n(FTL). The simulator also allows a comprehensive fault injection for testing\nthe reliability of the FTL. Compared against a real FPGA implementation, the\nsimulator's response time deviation is under 0.28% on average, with a maximum\nof 10.12%."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IISWC.2016.7581279", 
    "link": "http://arxiv.org/pdf/1612.04855v1", 
    "title": "A 700uW 1GS/s 4-bit Folding-Flash ADC in 65nm CMOS for Wideband Wireless   Communications", 
    "arxiv-id": "1612.04855v1", 
    "author": "Davood Shahrjerdi", 
    "publish": "2016-12-14T21:52:33Z", 
    "summary": "We present the design of a low-power 4-bit 1GS/s folding-flash ADC with a\nfolding factor of two. The design of a new unbalanced double-tail dynamic\ncomparator affords an ultra-low power operation and a high dynamic range.\nUnlike the conventional approaches, this design uses a fully matched input\nstage, an unbalanced latch stage, and a two-clock operation scheme. A\ncombination of these features yields significant reduction of the kick-back\nnoise, while allowing the design flexibility for adjusting the trip points of\nthe comparators. As a result, the ADC achieves SNDR of 22.3 dB at 100MHz and\n21.8 dB at 500MHz (i.e. the Nyquist frequency). The maximum INL and DNL are\nabout 0.2 LSB. The converter consumes about 700uW from a 1-V supply yielding a\nfigure of merit of 65fJ/conversion step. These attributes make the proposed\nfolding-flash ADC attractive for the next-generation wireless applications."
},{
    "category": "cs.AR", 
    "doi": "10.4204/EPTCS.233.9", 
    "link": "http://arxiv.org/pdf/1612.04986v1", 
    "title": "HADES: Microprocessor Hazard Analysis via Formal Verification of   Parameterized Systems", 
    "arxiv-id": "1612.04986v1", 
    "author": "Tom\u00e1\u0161 Vojnar", 
    "publish": "2016-12-15T08:51:02Z", 
    "summary": "HADES is a fully automated verification tool for pipeline-based\nmicroprocessors that aims at flaws caused by improperly handled data hazards.\nIt focuses on single-pipeline microprocessors designed at the register transfer\nlevel (RTL) and deals with read-after-write, write-after-write, and\nwrite-after-read hazards. HADES combines several techniques, including\ndata-flow analysis, error pattern matching, SMT solving, and abstract regular\nmodel checking. It has been successfully tested on several microprocessors for\nembedded applications."
},{
    "category": "cs.AR", 
    "doi": "10.4204/EPTCS.233.9", 
    "link": "http://arxiv.org/pdf/1612.05166v1", 
    "title": "A Novel RTL ATPG Model Based on Gate Inherent Faults (GIF-PO) of Complex   Gates", 
    "arxiv-id": "1612.05166v1", 
    "author": "Tobias Strauch", 
    "publish": "2016-12-15T17:55:06Z", 
    "summary": "This paper starts with a comprehensive survey on RTL ATPG. It then proposes a\nnovel RTL ATPG model based on \"Gate Inherent Faults\" (GIF). These GIF are\nextracted from each complex gate (adder, case-statement, etc.) of the RTL\nsource code individually. They are related to the internal logic paths of a\ncomplex gate. They are not related to any net/signal in the RTL design. It is\nobserved, that when all GIF on RTL are covered (100%) and the same stimulus is\napplied, then all gate level stuck-at faults of the netlist are covered (100%)\nas well. The proposed RTL ATPG model is therefore synthesis independent. This\nis shown on ITC'99 testcases. The applied semi-automatic test pattern\ngeneration process is based on functional simulation."
},{
    "category": "cs.AR", 
    "doi": "10.4204/EPTCS.233.9", 
    "link": "http://arxiv.org/pdf/1612.05547v1", 
    "title": "Prototyping RISC Based, Reconfigurable Networking Applications in Open   Source", 
    "arxiv-id": "1612.05547v1", 
    "author": "Andrew W. Moore", 
    "publish": "2016-12-16T16:42:28Z", 
    "summary": "In the last decade we have witnessed a rapid growth in data center systems,\nrequiring new and highly complex networking devices. The need to refresh\nnetworking infrastructure whenever new protocols or functions are introduced,\nand the increasing costs that this entails, are of a concern to all data center\nproviders. New generations of Systems on Chip (SoC), integrating\nmicroprocessors and higher bandwidth interfaces, are an emerging solution to\nthis problem. These devices permit entirely new systems and architectures that\ncan obviate the replacement of existing networking devices while enabling\nseamless functionality change. In this work, we explore open source, RISC\nbased, SoC architectures with high performance networking capabilities. The\nprototype architectures are implemented on the NetFPGA-SUME platform. Beyond\ndetails of the architecture, we also describe the hardware implementation and\nthe porting of operating systems to the platform. The platform can be exploited\nfor the development of practical networking appliances, and we provide use case\nexamples."
},{
    "category": "cs.AR", 
    "doi": "10.4204/EPTCS.233.9", 
    "link": "http://arxiv.org/pdf/1612.05974v1", 
    "title": "An IoT Endpoint System-on-Chip for Secure and Energy-Efficient   Near-Sensor Analytics", 
    "arxiv-id": "1612.05974v1", 
    "author": "Luca Benini", 
    "publish": "2016-12-18T19:20:42Z", 
    "summary": "Near-sensor data analytics is a promising direction for IoT endpoints, as it\nminimizes energy spent on communication and reduces network load. However,\nperforming feature extraction or classification directly on the end-nodes poses\nsecurity concerns, as valuable data, \"distilled\" with application knowledge, is\nstored or sent over the network at various stages of the analytics pipeline.\nUsing encryption to protect sensitive data at the boundary of the on-chip\nanalytics engine is a way to address data security issues. To cope with the\ncombined workload of analytics and encryption in a tight power envelope, we\npropose Fulmine, a System-on-Chip based on a tightly-coupled multi-core cluster\naugmented with specialized blocks for compute-intensive data processing and\nencryption functions, supporting software programmability for regular computing\ntasks. The Fulmine SoC, fabricated in 65nm technology, consumes less than 20mW\non average at 0.8V achieving an efficiency of up to 70pJ/B in encryption,\n50pJ/px in convolution, or up to 25MIPS/mW in software. As a strong argument\nfor real-life flexible application of our platform, we show experimental\nresults for three secure analytics use cases: secure autonomous aerial\nsurveillance with a state-of-the-art deep CNN consuming 3.16pJ per equivalent\nRISC op; local CNN-based face detection with secured remote recognition in\n5.74pJ/op; and seizure detection with encrypted data collection from EEG within\n12.7pJ/op."
},{
    "category": "cs.AR", 
    "doi": "10.4204/EPTCS.233.9", 
    "link": "http://arxiv.org/pdf/1612.08239v1", 
    "title": "Higher likelihood of multiple bit-flips due to neutron-induced strikes   on logic gates", 
    "arxiv-id": "1612.08239v1", 
    "author": "Madhav P. Desai", 
    "publish": "2016-12-25T06:20:51Z", 
    "summary": "High energy particles from cosmic rays or packaging materials can generate a\nglitch or a current transient (single event transient or SET) in a logic\ncircuit. This SET can eventually get captured in a register resulting in a flip\nof the register content, which is known as soft error or single-event upset\n(SEU). A soft error is typically modeled as a probabilistic single bit-flip\nmodel. In developing such abstract fault models, an important issue to consider\nis the likelihood of multiple bit errors caused by particle strikes. In an\nearlier related work, we performed a characterization study of the impact of an\nSET on a logic circuit to quantify the extent to which this model is accurate.\nWe found that, a substantial fraction of SEU outcomes had multiple register\nflips. In this paper, we perform a deeper analysis to understand the individual\ncontributions of, 'strike on a register' and 'strike on a logic gate', on\nmultiple flips. We use post-layout circuit simulations and Monte Carlo sampling\nscheme to study the impact of an SET. We perform our simulations on ISCAS'85,\nISCAS'89 and ITC'99 benchmarks in 180nm and 65nm technologies. We find that,\namongst the erroneous outcomes, the probability of multiple bit-flips for\n'gate-strike' cases was substantial and went up to 50%, where as those for\n'register-strike' cases was just about 2%. This implies that, if we were to do\nhardened flip-flop designs to eliminate the flips due to register strikes, in\nsuch designs, out of the remaining flips which are going to be due to 'gate\nstrikes', a large fraction will be multiple flips. Hardening the flip-flops is\nnot going to help in this scenario. Thus, gate strikes are problematic and\ncomplex error correction schemes at the circuit level are needed to eliminate\nthe multiple errors due to 'gate strikes'."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/1701.01630v1", 
    "title": "Reducing Competitive Cache Misses in Modern Processor Architectures", 
    "arxiv-id": "1701.01630v1", 
    "author": "Pece Mitrevski", 
    "publish": "2017-01-06T13:32:36Z", 
    "summary": "The increasing number of threads inside the cores of a multicore processor,\nand competitive access to the shared cache memory, become the main reasons for\nan increased number of competitive cache misses and performance decline.\nInevitably, the development of modern processor architectures leads to an\nincreased number of cache misses. In this paper, we make an attempt to\nimplement a technique for decreasing the number of competitive cache misses in\nthe first level of cache memory. This technique enables competitive access to\nthe entire cache memory when there is a hit - but, if there are cache misses,\nmemory data (by using replacement techniques) is put in a virtual part given to\nthreads, so that competitive cache misses are avoided. By using a simulator\ntool, the results show a decrease in the number of cache misses and performance\nincrease for up to 15%. The conclusion that comes out of this research is that\ncache misses are a real challenge for future processor designers, in order to\nhide memory latency."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/1701.03499v2", 
    "title": "VESPA: VIPT Enhancements for Superpage Accesses", 
    "arxiv-id": "1701.03499v2", 
    "author": "Tushar Krishna", 
    "publish": "2017-01-12T20:31:53Z", 
    "summary": "L1 caches are critical to the performance of modern computer systems. Their\ndesign involves a delicate balance between fast lookups, high hit rates, low\naccess energy, and simplicity of implementation. Unfortunately, constraints\nimposed by virtual memory make it difficult to satisfy all these attributes\ntoday. Specifically, the modern staple of supporting virtual-indexing and\nphysical-tagging (VIPT) for parallel TLB-L1 lookups means that L1 caches are\nusually grown with greater associativity rather than sets. This compromises\nperformance -- by degrading access times without significantly boosting hit\nrates -- and increases access energy. We propose VIPT Enhancements for\nSuperPage Accesses or VESPA in response. VESPA side-steps the traditional\nproblems of VIPT by leveraging the increasing ubiquity of superpages; since\nsuperpages have more page offset bits, they can accommodate L1 cache\norganizations with more sets than baseline pages can. VESPA dynamically adapts\nto any OS distribution of page sizes to operate L1 caches with good access\ntimes, hit rates, and energy, for both single- and multi-threaded workloads.\nSince the hardware changes are modest, and there are no OS or application\nchanges, VESPA is readily-implementable.\n  By superpages (also called huge or large pages) we refer to any page sizes\nsupported by the architecture bigger than baseline page size."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/1701.03878v1", 
    "title": "HoLiSwap: Reducing Wire Energy in L1 Caches", 
    "arxiv-id": "1701.03878v1", 
    "author": "William J. Dally", 
    "publish": "2017-01-14T04:03:50Z", 
    "summary": "This paper describes HoLiSwap a method to reduce L1 cache wire energy, a\nsignificant fraction of total cache energy, by swapping hot lines to the cache\nway nearest to the processor. We observe that (i) a small fraction (<3%) of\ncache lines (hot lines) serve over 60% of the L1 cache accesses and (ii) the\ndifference in wire energy between the nearest and farthest cache subarray can\nbe over 6$\\times$. Our method exploits this difference in wire energy to\ndynamically identify hot lines and swap them to the nearest physical way in a\nset-associative L1 cache. This provides up to 44% improvement in the wire\nenergy (1.82% saving in overall system energy) with no impact on the cache miss\nrate and 0.13% performance drop. We also show that HoLiSwap can simplify\nway-prediction."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/1701.06382v1", 
    "title": "Design of an Audio Interface for Patmos", 
    "arxiv-id": "1701.06382v1", 
    "author": "Fabian Goerge", 
    "publish": "2017-01-23T13:40:16Z", 
    "summary": "This paper describes the design and implementation of an audio interface for\nthe Patmos processor, which runs on an Altera DE2-115 FPGA board. This board\nhas an audio codec included, the WM8731. The interface described in this work\nallows to receive and send audio from and to the WM8731, and to synthesize,\nstore or manipulate audio signals writing C programs for Patmos. The audio\ninterface described in this paper is intended to be used with the Patmos\nprocessor. Patmos is an open source RISC ISAs with a load-store architecture,\nthat is optimized for Real-Time Systems. Patmos is part of a project founded by\nthe European Union called T-CREST (Time-predictable Multi-Core Architecture for\nEmbedded Systems).[5] The structure of this project is integrated with the\nPatmos project: new hardware modules have been added as IOs, which allow the\ncommunication between the processor and the audio codec. These modules include\na clock generator for the audio chip, ADC and DAC modules for the audio\nconversion from analog to digital and vice versa, and an I2C module which\nallows setting configuration parameters on the audio codec. Moreover, a top\nmodule has been created, which connects all the modules previously mentioned\nbetween them, to Patmos and to the WM8731, using the external pins of the FPGA."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/1701.06741v3", 
    "title": "Variability-Aware Design for Energy Efficient Computational Artificial   Intelligence Platform", 
    "arxiv-id": "1701.06741v3", 
    "author": "Rhonda P. Zhang", 
    "publish": "2017-01-24T06:06:25Z", 
    "summary": "Portable computing devices, which include tablets, smart phones and various\ntypes of wearable sensors, experienced a rapid development in recent years. One\nof the most critical limitations for these devices is the power consumption as\nthey use batteries as the power supply. However, the bottleneck of the power\nsaving schemes in both hardware design and software algorithm is the huge\nvariability in power consumption. The variability is caused by a myriad of\nfactors, including the manufacturing process, the ambient environment\n(temperature, humidity), the aging effects and etc. As the technology node\nscaled down to 28nm and even lower, the variability becomes more severe. As a\nresult, a platform for variability characterization seems to be very necessary\nand helpful."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/1701.07517v2", 
    "title": "Hardware Translation Coherence for Virtualized Systems", 
    "arxiv-id": "1701.07517v2", 
    "author": "Abhishek Bhattacharjee", 
    "publish": "2017-01-25T23:27:30Z", 
    "summary": "To improve system performance, modern operating systems (OSes) often\nundertake activities that require modification of virtual-to-physical page\ntranslation mappings. For example, the OS may migrate data between physical\nframes to defragment memory and enable superpages. The OS may migrate pages of\ndata between heterogeneous memory devices. We refer to all such activities as\npage remappings. Unfortunately, page remappings are expensive. We show that\ntranslation coherence is a major culprit and that systems employing\nvirtualization are especially badly affected by their overheads. In response,\nwe propose hardware translation invalidation and coherence or HATRIC, a readily\nimplementable hardware mechanism to piggyback translation coherence atop\nexisting cache coherence protocols. We perform detailed studies using KVM-based\nvirtualization, showing that HATRIC achieves up to 30% performance and 10%\nenergy benefits, for per-CPU area overheads of 2%. We also quantify HATRIC's\nbenefits on systems running Xen and find up to 33% performance improvements."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/1701.08849v1", 
    "title": "Accurate Measurement of Power Consumption Overhead During FPGA Dynamic   Partial Reconfiguration", 
    "arxiv-id": "1701.08849v1", 
    "author": "Yves Louet", 
    "publish": "2017-01-30T22:09:23Z", 
    "summary": "In the context of embedded systems design, two important challenges are still\nunder investigation. First, improve real-time data processing,\nreconfigurability, scalability, and self-adjusting capabilities of hardware\ncomponents. Second, reduce power consumption through low-power design\ntechniques as clock gating, logic gating, and dynamic partial reconfiguration\n(DPR) capabilities. Today, several application, e.g., cryptography,\nSoftware-defined radio or aerospace missions exploit the benefits of DPR of\nprogrammable logic devices. The DPR allows well defined reconfigurable FPGA\nregion to be modified during runtime. However, it introduces an overhead in\nterm of power consumption and time during the reconfiguration phase. In this\npaper, we present an investigation of power consumption overhead of the DPR\nprocess using a high-speed digital oscilloscope and the shunt resistor method.\nResults in terms of reconfiguration time and power consumption overhead for\nVirtex 5 FPGAs are shown."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/1701.08877v2", 
    "title": "1.5 bit-per-stage 8-bit Pipelined CMOS A/D Converter for Neuromophic   Vision Processor", 
    "arxiv-id": "1701.08877v2", 
    "author": "Li Du", 
    "publish": "2017-01-31T00:14:32Z", 
    "summary": "Neuromorphic vision processor is an electronic implementation of vision\nalgorithm processor on semiconductor. To image the world, a low-power CMOS\nimage sensor array is required in the vision processor. The image sensor array\nis typically formed through photo diodes and analog to digital converter (ADC).\nTo achieve low power acquisition, a low-power mid-resolution ADC is necessary.\nIn this paper, a 1.8V, 8-bit, 166MS/s pipelined ADC was proposed in a 0.18 um\nCMOS technology. The ADC used operational amplifier sharing architecture to\nreduce power consumption and achieved maximum DNL of 0.24 LSB, maximum INL of\n0.35 LSB, at a power consumption of 38.9mW. When input frequency is 10.4MHz, it\nachieved an SNDR 45.9dB, SFDR 50dB, and an ENOB of 7.33 bit."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/1702.00483v2", 
    "title": "FPGA-based real-time 105-channel data acquisition platform for imaging   system", 
    "arxiv-id": "1702.00483v2", 
    "author": "Jason Y. Du", 
    "publish": "2017-01-18T01:08:14Z", 
    "summary": "In this paper, a real-time 105-channel data acquisition platform based on\nFPGA for imaging will be implemented for mm-wave imaging systems. PC platform\nis also realized for imaging results monitoring purpose. Mm-wave imaging\nexpands our vision by letting us see things under poor visibility conditions.\nWith this extended vision ability, a wide range of military imaging missions\nwould benefit, such as surveillance, precision targeting, navigation, and\nrescue. Based on the previously designed imager modules, this project would go\non finishing the PCB design (both schematic and layout) of the following signal\nprocessing systems consisting of Programmable Gain Amplifier(PGA) (4 PGA for\neach ADC) and 16-channel Analog to Digital Converter (ADC) (7 ADC in total).\nThen the system verification would be performed on the Artix-7 35T Arty FPGA\nwith the developing of proper controlling code to configure the ADC and realize\nthe communication between the FPGA and the PC (through both UART and Ethernet).\nFor the verification part, a simple test on a breadboard with a simple analog\ninput (generated from a resistor divider) would first be performed. After the\nPCB design is finished, the whole system would be tested again with a precise\nreference and analog input."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/1702.00938v1", 
    "title": "A Multi-Gbps Unrolled Hardware List Decoder for a Systematic Polar Code", 
    "arxiv-id": "1702.00938v1", 
    "author": "Warren J. Gross", 
    "publish": "2017-02-03T08:48:52Z", 
    "summary": "Polar codes are a new class of block codes with an explicit construction that\nprovably achieve the capacity of various communications channels, even with the\nlow-complexity successive-cancellation (SC) decoding algorithm. Yet, the more\ncomplex successive-cancellation list (SCL) decoding algorithm is gathering more\nattention lately as it significantly improves the error-correction performance\nof short- to moderate-length polar codes, especially when they are concatenated\nwith a cyclic redundancy check code. However, as SCL decoding explores several\ndecoding paths, existing hardware implementations tend to be significantly\nslower than SC-based decoders. In this paper, we show how the unrolling\ntechnique, which has already been used in the context of SC decoding, can be\nadapted to SCL decoding yielding a multi-Gbps SCL-based polar decoder with an\nerror-correction performance that is competitive when compared to an LDPC code\nof similar length and rate. Post-place-and-route ASIC results for 28 nm CMOS\nare provided showing that this decoder can sustain a throughput greater than 10\nGbps at 468 MHz with an energy efficiency of 7.25 pJ/bit."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/1702.01067v1", 
    "title": "Sense Amplifier Comparator with Offset Correction for Decision Feedback   Equalization based Receivers", 
    "arxiv-id": "1702.01067v1", 
    "author": "Dinesh Sharma", 
    "publish": "2017-02-03T16:06:21Z", 
    "summary": "A decision feedback circuit with integrated offset compensation is presented\nin this paper. The circuit is built around the sense amplifier comparator. The\nfeedback loop is closed around the first stage of the comparator resulting in\nminimum loop latency. The feedback loop is implemented using a switched\ncapacitor network that picks from one of pre-computed voltages to be fed back.\nThe comparator's offset that is to be compensated for, is added in the same\npath. Hence, an extra offset correction input is not required. The circuit is\nused as a receiver for a 10 mm low swing interconnect implemented in UMC 130 nm\nCMOS technology. The circuit is tested at a frequency of 1 GHz and it consumes\n145 $\\mu$A from a 1.2V supply at this frequency."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/1702.01295v1", 
    "title": "Embedded Systems Architecture for SLAM Applications", 
    "arxiv-id": "1702.01295v1", 
    "author": "Jean-Luc Gaudiot", 
    "publish": "2017-02-04T14:37:38Z", 
    "summary": "In recent years, we have observed a clear trend in the rapid rise of\nautonomous vehicles, robotics, virtual reality, and augmented reality. The core\ntechnology enabling these applications, Simultaneous Localization And Mapping\n(SLAM), imposes two main challenges: first, these workloads are computationally\nintensive and they often have real-time requirements; second, these workloads\nrun on battery-powered mobile devices with limited energy budget. In short, the\nessence of these challenges is that performance should be improved while\nsimultaneously reducing energy consumption, two rather contradicting goals by\nconventional wisdom. In this paper, we take a close look at state-of-the-art\nSimultaneous Localization And Mapping (SLAM) workloads, especially how these\nworkloads behave on mobile devices. Based on the results, we propose a mobile\narchitecture to improve SLAM performance on mobile devices."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/1702.02313v1", 
    "title": "FASHION: Fault-Aware Self-Healing Intelligent On-chip Network", 
    "arxiv-id": "1702.02313v1", 
    "author": "Nanning Zheng", 
    "publish": "2017-02-08T07:45:46Z", 
    "summary": "To avoid packet loss and deadlock scenarios that arise due to faults or power\ngating in multicore and many-core systems, the network-on-chip needs to possess\nresilient communication and load-balancing properties. In this work, we\nintroduce the Fashion router, a self-monitoring and self-reconfiguring design\nthat allows for the on-chip network to dynamically adapt to component failures.\nFirst, we introduce a distributed intelligence unit, called Self-Awareness\nModule (SAM), which allows the router to detect permanent component failures\nand build a network connectivity map. Using local information, SAM adapts to\nfaults, guarantees connectivity and deadlock-free routing inside the maximal\nconnected subgraph and keeps routing tables up-to-date. Next, to reconfigure\nnetwork links or virtual channels around faulty/power-gated components, we add\nbidirectional link and unified virtual channel structure features to the\nFashion router. This version of the router, named Ex-Fashion, further mitigates\nthe negative system performance impacts, leads to larger maximal connected\nsubgraph and sustains a relatively high degree of fault-tolerance. To support\nthe router, we develop a fault diagnosis and recovery algorithm executed by the\nBuilt-In Self-Test, self-monitoring, and self-reconfiguration units at runtime\nto provide fault-tolerant system functionalities. The Fashion router places no\nrestriction on topology, position or number of faults. It drops 54.3-55.4%\nfewer nodes for same number of faults (between 30 and 60 faults) in an 8x8\n2D-mesh over other state-of-the-art solutions. It is scalable and efficient.\nThe area overheads are 2.311% and 2.659% when implemented in 8x8 and 16x16\n2D-meshes using the TSMC 65nm library at 1.38GHz clock frequency."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/1703.05769v1", 
    "title": "A 594 Gbps LDPC Decoder Based on Finite-Alphabet Message Passing", 
    "arxiv-id": "1703.05769v1", 
    "author": "Andreas Burg", 
    "publish": "2017-03-16T18:01:55Z", 
    "summary": "An ultra-high throughput low-density parity check (LDPC) decoder with an\nunrolled full-parallel architecture is proposed, which achieves the highest\ndecoding throughput compared to previously reported LDPC decoders in\nliterature. The decoder benefits from a serial message-transfer approach\nbetween the decoding stages to alleviate the well-known routing congestion\nproblem in parallel LDPC decoders. Furthermore, a finite-alphabet message\npassing algorithm is employed to replace the variable node update rule of\nstandard min-sum decoders with optimized look-up tables, designed in a way that\nmaximize the mutual information between decoding messages. The proposed\nalgorithm results in an architecture with reduced bit-width messages, leading\nto a significantly higher decoding throughput and to a lower area as compared\nto a min-sum decoder when serial message-transfer is used. The architecture is\nplaced and routed for the standard min-sum reference decoder and for the\nproposed finite-alphabet decoder using a custom pseudo-hierarchical backend\ndesign strategy to further alleviate routing congestions and to handle the\nlarge design. Post-layout results show that the finite-alphabet decoder with\nthe serial message-transfer architecture achieves a throughput as large as 594\nGbps with an area of 16.2 mm$^2$ and dissipates an average power of 22.7 pJ per\ndecoded bit in a 28 nm FD-SOI library. Compared to the reference min-sum\ndecoder, this corresponds to 3.3 times smaller area and 2 times better energy\nefficiency."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/9809007v1", 
    "title": "Locally Served Network Computers", 
    "arxiv-id": "cs/9809007v1", 
    "author": "Jim Gray", 
    "publish": "1998-09-02T17:30:05Z", 
    "summary": "NCs are the natural evolution of PCs, ubiquitous computers everywhere. The\ncurrent vision of NCs requires two improbable developments: (1) inexpensive\nhigh-bandwidth WAN links to the Internet, and (2) inexpensive centralized\nservers. The large NC bandwidth requirements will force each home or office to\nhave a local server LAN attached to the NCs. These servers will be much less\nexpensive to purchase and manage than a centralized solution. Centralized staff\nare expensive and unresponsive."
},{
    "category": "cs.CL", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/9809021v1", 
    "title": "Producing NLP-based On-line Contentware", 
    "arxiv-id": "cs/9809021v1", 
    "author": "Olivier Gremont", 
    "publish": "1998-09-16T14:22:35Z", 
    "summary": "For its internal needs as well as for commercial purposes, CDC Group has\nproduced several NLP-based on-line contentware applications for years. The\ndevelopment process of such applications is subject to numerous constraints\nsuch as quality of service, integration of new advances in NLP, direct\nreactions from users, continuous versioning, short delivery deadlines and cost\ncontrol. Following this industrial and commercial experience, malleability of\nthe applications, their openness towards foreign components, efficiency of\napplications and their ease of exploitation have appeared to be key points. In\nthis paper, we describe TalLab, a powerful architecture for on-line contentware\nwhich fulfils these requirements."
},{
    "category": "cs.PL", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/9811021v1", 
    "title": "Automatic Hardware Synthesis for a Hybrid Reconfigurable CPU Featuring   Philips CPLDs", 
    "arxiv-id": "cs/9811021v1", 
    "author": "Bernardo Kastrup", 
    "publish": "1998-11-12T09:49:57Z", 
    "summary": "A high-level architecture of a Hybrid Reconfigurable CPU, based on a\nPhilips-supported core processor, is introduced. It features the Philips XPLA2\nCPLD as a reconfigurable functional unit. A compilation chain is presented, in\nwhich automatic implementation of time-critical program segments in custom\nhardware is performed. The entire process is transparent from the programmer's\npoint of view. The hardware synthesis module of the chain, which translates\nsegments of assembly code into a hardware netlist, is discussed in details.\nApplication examples are also presented."
},{
    "category": "cs.LO", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/9910014v2", 
    "title": "Processor Verification Using Efficient Reductions of the Logic of   Uninterpreted Functions to Propositional Logic", 
    "arxiv-id": "cs/9910014v2", 
    "author": "Miroslav N. Velev", 
    "publish": "1999-10-14T22:41:39Z", 
    "summary": "The logic of equality with uninterpreted functions (EUF) provides a means of\nabstracting the manipulation of data by a processor when verifying the\ncorrectness of its control logic. By reducing formulas in this logic to\npropositional formulas, we can apply Boolean methods such as Ordered Binary\nDecision Diagrams (BDDs) and Boolean satisfiability checkers to perform the\nverification.\n  We can exploit characteristics of the formulas describing the verification\nconditions to greatly simplify the propositional formulas generated. In\nparticular, we exploit the property that many equations appear only in positive\nform. We can therefore reduce the set of interpretations of the function\nsymbols that must be considered to prove that a formula is universally valid to\nthose that are ``maximally diverse.''\n  We present experimental results demonstrating the efficiency of this approach\nwhen verifying pipelined processors using the method proposed by Burch and\nDill."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/9912010v1", 
    "title": "Scalability Terminology: Farms, Clones, Partitions, Packs, RACS and RAPS", 
    "arxiv-id": "cs/9912010v1", 
    "author": "George Spix", 
    "publish": "1999-12-18T02:19:42Z", 
    "summary": "Defines a vocabulary for scaleable systems: Geoplexes, Farms, Clones, RACS,\nRAPS, clones, partitions, and packs and dicusses the design tradeoffs of using\nclones, partitons, and packs."
},{
    "category": "cs.DC", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0009020v1", 
    "title": "Cluster Computing: A High-Performance Contender", 
    "arxiv-id": "cs/0009020v1", 
    "author": "Dan Hyde", 
    "publish": "2000-09-22T10:39:30Z", 
    "summary": "When you first heard people speak of Piles of PCs, the first thing that came\nto mind may have been a cluttered computer room with processors, monitors, and\nsnarls of cables all around. Collections of computers have undoubtedly become\nmore sophisticated than in the early days of shared drives and modem\nconnections. No matter what you call them, Clusters of Workstations (COW),\nNetworks of Workstations (NOW), Workstation Clusters (WCs), Clusters of PCs\n(CoPs), clusters of computers are now filling the processing niche once\noccupied by more powerful stand-alone machines. This article discusses the need\nfor cluster computing technology, Technologies, Components, and Applications,\nSupercluster Systems and Issues, The Need for a New Task Force, and Cluster\nComputing Educational Resources."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0010007v1", 
    "title": "Towards a Theory of Cache-Efficient Algorithms", 
    "arxiv-id": "cs/0010007v1", 
    "author": "Neeraj Dumir", 
    "publish": "2000-10-02T17:09:06Z", 
    "summary": "We describe a model that enables us to analyze the running time of an\nalgorithm in a computer with a memory hierarchy with limited associativity, in\nterms of various cache parameters. Our model, an extension of Aggarwal and\nVitter's I/O model, enables us to establish useful relationships between the\ncache complexity and the I/O complexity of computations. As a corollary, we\nobtain cache-optimal algorithms for some fundamental problems like sorting,\nFFT, and an important subclass of permutations in the single-level cache model.\nWe also show that ignoring associativity concerns could lead to inferior\nperformance, by analyzing the average-case cache behavior of mergesort. We\nfurther extend our model to multiple levels of cache with limited associativity\nand present optimal algorithms for matrix transpose and sorting. Our techniques\nmay be used for systematic exploitation of the memory hierarchy starting from\nthe algorithm design stage, and dealing with the hitherto unresolved problem of\nlimited associativity."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0103025v1", 
    "title": "The Anatomy of the Grid - Enabling Scalable Virtual Organizations", 
    "arxiv-id": "cs/0103025v1", 
    "author": "Steven Tuecke", 
    "publish": "2001-03-29T14:30:18Z", 
    "summary": "\"Grid\" computing has emerged as an important new field, distinguished from\nconventional distributed computing by its focus on large-scale resource\nsharing, innovative applications, and, in some cases, high-performance\norientation. In this article, we define this new field. First, we review the\n\"Grid problem,\" which we define as flexible, secure, coordinated resource\nsharing among dynamic collections of individuals, institutions, and\nresources-what we refer to as virtual organizations. In such settings, we\nencounter unique authentication, authorization, resource access, resource\ndiscovery, and other challenges. It is this class of problem that is addressed\nby Grid technologies. Next, we present an extensible and open Grid\narchitecture, in which protocols, services, application programming interfaces,\nand software development kits are categorized according to their roles in\nenabling resource sharing. We describe requirements that we believe any such\nmechanisms must satisfy, and we discuss the central role played by the\nintergrid protocols that enable interoperability among different Grid systems.\nFinally, we discuss how Grid technologies relate to other contemporary\ntechnologies, including enterprise integration, application service provider,\nstorage service provider, and peer-to-peer computing. We maintain that Grid\nconcepts and technologies complement and have much to contribute to these other\napproaches."
},{
    "category": "cs.DC", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0108016v1", 
    "title": "Verifying Sequential Consistency on Shared-Memory Multiprocessors by   Model Checking", 
    "arxiv-id": "cs/0108016v1", 
    "author": "Shaz Qadeer", 
    "publish": "2001-08-25T00:58:27Z", 
    "summary": "The memory model of a shared-memory multiprocessor is a contract between the\ndesigner and programmer of the multiprocessor. The sequential consistency\nmemory model specifies a total order among the memory (read and write) events\nperformed at each processor. A trace of a memory system satisfies sequential\nconsistency if there exists a total order of all memory events in the trace\nthat is both consistent with the total order at each processor and has the\nproperty that every read event to a location returns the value of the last\nwrite to that location.\n  Descriptions of shared-memory systems are typically parameterized by the\nnumber of processors, the number of memory locations, and the number of data\nvalues. It has been shown that even for finite parameter values, verifying\nsequential consistency on general shared-memory systems is undecidable. We\nobserve that, in practice, shared-memory systems satisfy the properties of\ncausality and data independence. Causality is the property that values of read\nevents flow from values of write events. Data independence is the property that\nall traces can be generated by renaming data values from traces where the\nwritten values are distinct from each other. If a causal and data independent\nsystem also has the property that the logical order of write events to each\nlocation is identical to their temporal order, then sequential consistency can\nbe verified algorithmically. Specifically, we present a model checking\nalgorithm to verify sequential consistency on such systems for a finite number\nof processors and memory locations and an arbitrary number of data values."
},{
    "category": "cs.NI", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0110065v1", 
    "title": "Interfacing the ControlLogix PLC over Ethernet/IP", 
    "arxiv-id": "cs/0110065v1", 
    "author": "L. R. Dalesio", 
    "publish": "2001-10-31T18:07:17Z", 
    "summary": "The Allen-Bradley ControlLogix line of pro-grammable logic controllers (PLCs)\noffers several in-terfaces: Ethernet, ControlNet, DeviceNet, RS-232 and others.\nThe ControlLogix Ethernet interface module 1756-ENET uses EtherNet/IP, the\nControlNet protocol, encapsulated in Ethernet packages, with specific service\ncodes. A driver for the Experimental Physics and Industrial Control System\n(EPICS) has been developed that utilizes this EtherNet/IP protocol for\ncontrollers running the vxWorks RTOS as well as a Win32 and Unix/Linux test\nprogram. Features, per-formance and limitations of this interface are\npresented."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0307035v1", 
    "title": "Adaptive Domain Model: Dealing With Multiple Attributes of Self-Managing   Distributed Object Systems", 
    "arxiv-id": "cs/0307035v1", 
    "author": "Pavel Motuzenko", 
    "publish": "2003-07-13T13:01:19Z", 
    "summary": "Self-managing software has emerged as modern systems have become more\ncomplex. Some of the distributed object systems may contain thousands of\nobjects deployed on tens or even hundreds hosts. Development and support of\nsuch systems often costs a lot. To solve this issue the systems, which are\ncapable supporting multiple self-managing attributes, should be created. In the\npaper, the Adaptive domain concept is introduced as an extension to the basic\ndomain concept to support a generic adaptation environment for building\ndistributed object systems with multiple self-managing attributes."
},{
    "category": "cs.CC", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0307041v1", 
    "title": "High-density and Secure Data Transmission via Linear Combinations", 
    "arxiv-id": "cs/0307041v1", 
    "author": "Vince Grolmusz", 
    "publish": "2003-07-17T12:10:21Z", 
    "summary": "Suppose that there are $n$ Senders and $n$ Receivers. Our goal is to send\nlong messages from Sender $i$ to Receiver $i$ such that no other receiver can\nretrieve the message intended for Receiver $i$. The task can easily be\ncompleted using $n$ private channels between the pairs. Solutions, using one\nchannel needs either encryption or switching elements for routing the messages\nto their addressee.\n  The main result of the present work is a description of a network in which\nThe Senders and the Receivers are connected with only $n^{o(1)}$ channels; the\nencoding and de-coding is nothing else just very fast linear combinations of\nthe message-bits; and there are no switching or routing-elements in the\nnetwork, just linear combinations are computed, with fixed connections\n(channels or wires).\n  In the proofs we do not use {\\em any} unproven cryptographical or complexity\ntheoretical assumptions."
},{
    "category": "cs.GR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0310002v2", 
    "title": "The Graphics Card as a Streaming Computer", 
    "arxiv-id": "cs/0310002v2", 
    "author": "Suresh Venkatasubramanian", 
    "publish": "2003-10-05T06:30:56Z", 
    "summary": "Massive data sets have radically changed our understanding of how to design\nefficient algorithms; the streaming paradigm, whether it in terms of number of\npasses of an external memory algorithm, or the single pass and limited memory\nof a stream algorithm, appears to be the dominant method for coping with large\ndata.\n  A very different kind of massive computation has had the same effect at the\nlevel of the CPU. The most prominent example is that of the computations\nperformed by a graphics card. The operations themselves are very simple, and\nrequire very little memory, but require the ability to perform many\ncomputations extremely fast and in parallel to whatever degree possible. What\nhas resulted is a stream processor that is highly optimized for stream\ncomputations. An intriguing side effect of this is the growing use of a\ngraphics card as a general purpose stream processing engine. In an\never-increasing array of applications, researchers are discovering that\nperforming a computation on a graphics card is far faster than performing it on\na CPU, and so are using a GPU as a stream co-processor."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0310059v1", 
    "title": "Design and Implementation of MPICH2 over InfiniBand with RDMA Support", 
    "arxiv-id": "cs/0310059v1", 
    "author": "Brian Toonen", 
    "publish": "2003-10-30T18:11:28Z", 
    "summary": "For several years, MPI has been the de facto standard for writing parallel\napplications. One of the most popular MPI implementations is MPICH. Its\nsuccessor, MPICH2, features a completely new design that provides more\nperformance and flexibility. To ensure portability, it has a hierarchical\nstructure based on which porting can be done at different levels. In this\npaper, we present our experiences designing and implementing MPICH2 over\nInfiniBand. Because of its high performance and open standard, InfiniBand is\ngaining popularity in the area of high-performance computing. Our study focuses\non optimizing the performance of MPI-1 functions in MPICH2. One of our\nobjectives is to exploit Remote Direct Memory Access (RDMA) in Infiniband to\nachieve high performance. We have based our design on the RDMA Channel\ninterface provided by MPICH2, which encapsulates architecture-dependent\ncommunication functionalities into a very small set of functions. Starting with\na basic design, we apply different optimizations and also propose a\nzero-copy-based design. We characterize the impact of our optimizations and\ndesigns using microbenchmarks. We have also performed an application-level\nevaluation using the NAS Parallel Benchmarks. Our optimized MPICH2\nimplementation achieves 7.6 $\\mu$s latency and 857 MB/s bandwidth, which are\nclose to the raw performance of the underlying InfiniBand layer. Our study\nshows that the RDMA Channel interface in MPICH2 provides a simple, yet\npowerful, abstraction that enables implementations with high performance by\nexploiting RDMA operations in InfiniBand. To the best of our knowledge, this is\nthe first high-performance design and implementation of MPICH2 on InfiniBand\nusing RDMA support."
},{
    "category": "cs.NI", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0311017v1", 
    "title": "2 P2P or Not 2 P2P?", 
    "arxiv-id": "cs/0311017v1", 
    "author": "Jeff Mogul", 
    "publish": "2003-11-14T22:36:39Z", 
    "summary": "In the hope of stimulating discussion, we present a heuristic decision tree\nthat designers can use to judge the likely suitability of a P2P architecture\nfor their applications. It is based on the characteristics of a wide range of\nP2P systems from the literature, both proposed and deployed."
},{
    "category": "cs.DC", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0402027v1", 
    "title": "Efficient and Scalable Barrier over Quadrics and Myrinet with a New   NIC-Based Collective Message Passing Protocol", 
    "arxiv-id": "cs/0402027v1", 
    "author": "Dhabaleswar K. Panda", 
    "publish": "2004-02-12T20:37:26Z", 
    "summary": "Modern interconnects often have programmable processors in the network\ninterface that can be utilized to offload communication processing from host\nCPU. In this paper, we explore different schemes to support collective\noperations at the network interface and propose a new collective protocol. With\nbarrier as an initial case study, we have demontrated that much of the\ncommunication processing can be greatly simplified with this collective\nprotocol. Accordingly, %with our proposed collective processing scheme, we have\ndesigned and implemented efficient and scalable NIC-based barrier operations\nover two high performance interconnects, Quadrics and Myrinet.\n  Our evaluation shows that, over a Quadrics cluster of 8 nodes with ELan3\nNetwork, the NIC-based barrier operation achieves a barrier latency of only\n5.60$\\mu$s. This result is a 2.48 factor of improvement over the Elanlib\ntree-based barrier operation. Over a Myrinet cluster of 8 nodes with LANai-XP\nNIC cards, a barrier latency of 14.20$\\mu$s over 8 nodes is achieved. This is a\n2.64 factor of improvement over the host-based barrier algorithm. Furthermore,\nan analytical model developed for the proposed scheme indicates that a\nNIC-based barrier operation on a 1024-node cluster can be performed with only\n22.13$\\mu$s latency over Quadrics and with 38.94$\\mu$s latency over Myrinet.\nThese results indicate the potential for developing high performance\ncommunication subsystems for next generation clusters."
},{
    "category": "cs.AI", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0405004v1", 
    "title": "Quantum Computers", 
    "arxiv-id": "cs/0405004v1", 
    "author": "Archil Avaliani", 
    "publish": "2004-05-03T20:25:00Z", 
    "summary": "This research paper gives an overview of quantum computers - description of\ntheir operation, differences between quantum and silicon computers, major\nconstruction problems of a quantum computer and many other basic aspects. No\nspecial scientific knowledge is necessary for the reader."
},{
    "category": "cs.NI", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0408020v1", 
    "title": "Collaborative Storage Management In Sensor Networks", 
    "arxiv-id": "cs/0408020v1", 
    "author": "Wendi Heinzelman", 
    "publish": "2004-08-06T12:56:29Z", 
    "summary": "In this paper, we consider a class of sensor networks where the data is not\nrequired in real-time by an observer; for example, a sensor network monitoring\na scientific phenomenon for later play back and analysis. In such networks, the\ndata must be stored in the network. Thus, in addition to battery power, storage\nis a primary resource: the useful lifetime of the network is constrained by its\nability to store the generated data samples. We explore the use of\ncollaborative storage technique to efficiently manage data in storage\nconstrained sensor networks. The proposed collaborative storage technique takes\nadvantage of spatial correlation among the data collected by nearby sensors to\nsignificantly reduce the size of the data near the data sources. We show that\nthe proposed approach provides significant savings in the size of the stored\ndata vs. local buffering, allowing the network to run for a longer time without\nrunning out of storage space and reducing the amount of data that will\neventually be relayed to the observer. In addition, collaborative storage\nperforms load balancing of the available storage space if data generation rates\nare not uniform across sensors (as would be the case in an event driven sensor\nnetwork), or if the available storage varies across the network."
},{
    "category": "cs.DC", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0411050v1", 
    "title": "Utilizing Reconfigurable Hardware Processors via Grid Services", 
    "arxiv-id": "cs/0411050v1", 
    "author": "Ralf Clemens", 
    "publish": "2004-11-16T01:49:22Z", 
    "summary": "Computational grids typically consist of nodes utilizing ordinary processors\nsuch as the Intel Pentium. Field Programmable Gate Arrays (FPGAs) are able to\nperform certain compute-intensive tasks very well due to their inherent\nparallel architecture, often resulting in orders of magnitude speedups. This\npaper explores how FPGAs can be transparently exposed for remote use via grid\nservices, by integrating the Proteus Software Platform with the Globus Toolkit\n3.0."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0411075v1", 
    "title": "A Self-Reconfigurable Computing Platform Hardware Architecture", 
    "arxiv-id": "cs/0411075v1", 
    "author": "Darran Nathan", 
    "publish": "2004-11-20T06:31:32Z", 
    "summary": "Field Programmable Gate Arrays (FPGAs) have recently been increasingly used\nfor highly-parallel processing of compute intensive tasks. This paper\nintroduces an FPGA hardware platform architecture that is PC-based, allows for\nfast reconfiguration over the PCI bus, and retains a simple physical hardware\ndesign. The design considerations are first discussed, then the resulting\nsystem architecture designed is illustrated. Finally, experimental results on\nthe FPGA resources utilized for this design are presented."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0412093v1", 
    "title": "ScotGrid: A Prototype Tier 2 Centre", 
    "arxiv-id": "cs/0412093v1", 
    "author": "S. Thorn", 
    "publish": "2004-12-20T11:55:30Z", 
    "summary": "ScotGrid is a prototype regional computing centre formed as a collaboration\nbetween the universities of Durham, Edinburgh and Glasgow as part of the UK's\nnational particle physics grid, GridPP. We outline the resources available at\nthe three core sites and our optimisation efforts for our user communities. We\ndiscuss the work which has been conducted in extending the centre to embrace\nnew projects both from particle physics and new user communities and explain\nour methodology for doing this."
},{
    "category": "cs.NI", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0412119v1", 
    "title": "CDTP Chain Distributed Transfer Protocol", 
    "arxiv-id": "cs/0412119v1", 
    "author": "Shmuel Vagner", 
    "publish": "2004-12-30T19:43:14Z", 
    "summary": "The rapid growth of the internet in general and of bandwidth capacity at\ninternet clients in particular poses increasing computation and bandwidth\ndemands on internet servers. Internet access technologies like ADSL [DSL],\nCable Modem and Wireless modem allow internet clients to access the internet\nwith orders of magnitude more bandwidth than using traditional modems. We\npresent CDTP a distributed transfer protocol that allows clients to cooperate\nand therefore remove the strain from the internet server thus achieving much\nbetter performance than traditional transfer protocols (e.g. FTP [FTP]). The\nCDTP server and client tools are presented also as well as results of\nexperiments. Finally a bandwidth measurement technique is presented. CDTP tools\nuse this technique to differentiate between slow and fast clients."
},{
    "category": "cs.NI", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0502061v1", 
    "title": "A Geographic Directed Preferential Internet Topology Model", 
    "arxiv-id": "cs/0502061v1", 
    "author": "Avishai Wool", 
    "publish": "2005-02-14T11:39:04Z", 
    "summary": "The goal of this work is to model the peering arrangements between Autonomous\nSystems (ASes). Most existing models of the AS-graph assume an undirected\ngraph. However, peering arrangements are mostly asymmetric Customer-Provider\narrangements, which are better modeled as directed edges. Furthermore, it is\nwell known that the AS-graph, and in particular its clustering structure, is\ninfluenced by geography.\n  We introduce a new model that describes the AS-graph as a directed graph,\nwith an edge going from the customer to the provider, but also models symmetric\npeer-to-peer arrangements, and takes geography into account. We are able to\nmathematically analyze its power-law exponent and number of leaves. Beyond the\nanalysis we have implemented our model as a synthetic network generator we call\nGdTang. Experimentation with GdTang shows that the networks it produces are\nmore realistic than those generated by other network generators, in terms of\nits power-law exponent, fractions of customer-provider and symmetric peering\narrangements, and the size of its dense core. We believe that our model is the\nfirst to manifest realistic regional dense cores that have a clear geographic\nflavor. Our synthetic networks also exhibit path inflation effects that are\nsimilar to those observed in the real AS graph."
},{
    "category": "cs.CR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0502062v1", 
    "title": "Tree Parity Machine Rekeying Architectures", 
    "arxiv-id": "cs/0502062v1", 
    "author": "Sebastian Wallner", 
    "publish": "2005-02-14T13:06:26Z", 
    "summary": "The necessity to secure the communication between hardware components in\nembedded systems becomes increasingly important with regard to the secrecy of\ndata and particularly its commercial use. We suggest a low-cost (i.e. small\nlogic-area) solution for flexible security levels and short key lifetimes. The\nbasis is an approach for symmetric key exchange using the synchronisation of\nTree Parity Machines. Fast successive key generation enables a key exchange\nwithin a few milliseconds, given realistic communication channels with a\nlimited bandwidth. For demonstration we evaluate characteristics of a\nstandard-cell ASIC design realisation as IP-core in 0.18-micrometer\nCMOS-technology."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0505005v1", 
    "title": "Defragmenting the Module Layout of a Partially Reconfigurable Device", 
    "arxiv-id": "cs/0505005v1", 
    "author": "Juergen Teich", 
    "publish": "2005-05-02T01:10:04Z", 
    "summary": "Modern generations of field-programmable gate arrays (FPGAs) allow for\npartial reconfiguration. In an online context, where the sequence of modules to\nbe loaded on the FPGA is unknown beforehand, repeated insertion and deletion of\nmodules leads to progressive fragmentation of the available space, making\ndefragmentation an important issue. We address this problem by propose an\nonline and an offline component for the defragmentation of the available space.\nWe consider defragmenting the module layout on a reconfigurable device. This\ncorresponds to solving a two-dimensional strip packing problem. Problems of\nthis type are NP-hard in the strong sense, and previous algorithmic results are\nrather limited. Based on a graph-theoretic characterization of feasible\npackings, we develop a method that can solve two-dimensional defragmentation\ninstances of practical size to optimality. Our approach is validated for a set\nof benchmark instances."
},{
    "category": "cs.DL", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0508065v1", 
    "title": "Representing Digital Assets using MPEG-21 Digital Item Declaration", 
    "arxiv-id": "cs/0508065v1", 
    "author": "Herbert Van de Sompel", 
    "publish": "2005-08-13T03:09:25Z", 
    "summary": "Various XML-based approaches aimed at representing compound digital assets\nhave emerged over the last several years. Approaches that are of specific\nrelevance to the digital library community include the Metadata Encoding and\nTransmission Standard (METS), the IMS Content Packaging XML Binding, and the\nXML Formatted Data Units (XFDU) developed by CCSDS Panel 2. The MPEG-21 Digital\nItem Declaration (MPEG-21 DID) is another standard specifying the\nrepresentation of digital assets in XML that, so far, has received little\nattention in the digital library community. This article gives a brief insight\ninto the MPEG-21 standardization effort, highlights the major characteristics\nof the MPEG-21 DID Abstract Model, and describes the MPEG-21 Digital Item\nDeclaration Language (MPEG-21 DIDL), an XML syntax for the representation of\ndigital assets based on the MPEG-21 DID Abstract Model. Also, it briefly\ndemonstrates the potential relevance of MPEG-21 DID to the digital library\ncommunity by describing its use in the aDORe repository environment at the\nResearch Library of the Los Alamos National Laboratory (LANL) for the\nrepresentation of digital assets."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0508116v1", 
    "title": "Quantum Algorithm Processors to Reveal Hamiltonian Cycles", 
    "arxiv-id": "cs/0508116v1", 
    "author": "John Robert Burger", 
    "publish": "2005-08-25T19:04:22Z", 
    "summary": "Quantum computer versus quantum algorithm processor in CMOS are compared to\nfind (in parallel) all Hamiltonian cycles in a graph with m edges and n\nvertices, each represented by k bits. A quantum computer uses quantum states\nanalogous to CMOS registers. With efficient initialization, number of CMOS\nregisters is proportional to (n-1)! Number of qubits in a quantum computer is\napproximately proportional to kn+2mn in the approach below. Using CMOS, the\nbits per register is about proportional to kn, which is less since bits can be\nirreversibly reset. In either concept, number of gates, or operations to\nidentify Hamiltonian cycles is proportional to kmn. However, a quantum computer\nneeds an additional exponentially large number of operations to accomplish a\nprobabilistic readout. In contrast, CMOS is deterministic and readout is\ncomparable to ordinary memory."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0512104v1", 
    "title": "Reversible CAM Processor Modeled After Quantum Computer Behavior", 
    "arxiv-id": "cs/0512104v1", 
    "author": "John Robert Burger", 
    "publish": "2005-12-28T19:59:10Z", 
    "summary": "Proposed below is a reversible digital computer modeled after the natural\nbehavior of a quantum system. Using approaches usually reserved for idealized\nquantum computers, the Reversible CAM, or State Vector Parallel (RSVP)\nprocessor can easily find keywords in an unstructured database (that is, it can\nsolve a needle in a haystack problem). The RSVP processor efficiently solves a\nSAT (Satisfiability of Boolean Formulae) problem; also it can aid in the\nsolution of a GP (Global Properties of Truth Table) problem. The power delay\nproduct of the RSVP processor is exponentially lower than that of a standard\nCAM programmed to perform similar operations."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0602078v2", 
    "title": "Associative Memory For Reversible Programming and Charge Recovery", 
    "arxiv-id": "cs/0602078v2", 
    "author": "John Robert Burger", 
    "publish": "2006-02-21T21:58:06Z", 
    "summary": "Presented below is an interesting type of associative memory called toggle\nmemory based on the concept of T flip flops, as opposed to D flip flops. Toggle\nmemory supports both reversible programming and charge recovery. Circuits\ndesigned using the principles delineated below permit matchlines to charge and\ndischarge with near zero energy dissipation. The resulting lethargy is\ncompensated by the massive parallelism of associative memory. Simulation\nindicates over 33x reduction in energy dissipation using a sinusoidal power\nsupply at 2 MHz, assuming realistic 50 nm MOSFET models."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0603115v1", 
    "title": "Implementation of float-float operators on graphics hardware", 
    "arxiv-id": "cs/0603115v1", 
    "author": "David Defour", 
    "publish": "2006-03-29T11:48:29Z", 
    "summary": "The Graphic Processing Unit (GPU) has evolved into a powerful and flexible\nprocessor. The latest graphic processors provide fully programmable vertex and\npixel processing units that support vector operations up to single\nfloating-point precision. This computational power is now being used for\ngeneral-purpose computations. However, some applications require higher\nprecision than single precision. This paper describes the emulation of a 44-bit\nfloating-point number format and its corresponding operations. An\nimplementation is presented along with performance and accuracy results."
},{
    "category": "cs.OH", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0611134v1", 
    "title": "Hard Disk Drive as a Magnetomechanical Logic Device", 
    "arxiv-id": "cs/0611134v1", 
    "author": "Vladimir L. Safonov", 
    "publish": "2006-11-27T19:45:40Z", 
    "summary": "We consider the conditions how two binary numbers can be superimposed on the\nsame track with the use of different recording magnetic fields. As a result the\naverage magnetization of longitudinal medium along the track can have three\nstates: -M, 0 and +M. Possibility to perform logic operations with these states\nis considered. We demonstrate OR, AND, XOR and NOT operations and discuss a\nmodification of a recording device."
},{
    "category": "cs.DB", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0701165v1", 
    "title": "Petascale Computational Systems", 
    "arxiv-id": "cs/0701165v1", 
    "author": "Alex Szalay", 
    "publish": "2007-01-26T00:23:07Z", 
    "summary": "Computational science is changing to be data intensive. Super-Computers must\nbe balanced systems; not just CPU farms but also petascale IO and networking\narrays. Anyone building CyberInfrastructure should allocate resources to\nsupport a balanced Tier-1 through Tier-3 design."
},{
    "category": "cs.DB", 
    "doi": "10.5121/ijcsit.2016.8605", 
    "link": "http://arxiv.org/pdf/cs/0701166v1", 
    "title": "Empirical Measurements of Disk Failure Rates and Error Rates", 
    "arxiv-id": "cs/0701166v1", 
    "author": "Catharine van Ingen", 
    "publish": "2007-01-26T00:29:02Z", 
    "summary": "The SATA advertised bit error rate of one error in 10 terabytes is\nfrightening. We moved 2 PB through low-cost hardware and saw five disk read\nerror events, several controller failures, and many system reboots caused by\nsecurity patches. We conclude that SATA uncorrectable read errors are not yet a\ndominant system-fault source - they happen, but are rare compared to other\nproblems. We also conclude that UER (uncorrectable error rate) is not the\nrelevant metric for our needs. When an uncorrectable read error happens, there\nare typically several damaged storage blocks (and many uncorrectable read\nerrors.) Also, some uncorrectable read errors may be masked by the operating\nsystem. The more meaningful metric for data architects is Mean Time To Data\nLoss (MTTDL.)"
},{
    "category": "cs.AR", 
    "doi": "10.1063/1.2817968", 
    "link": "http://arxiv.org/pdf/cs/0702062v1", 
    "title": "Noise Limited Computational Speed", 
    "arxiv-id": "cs/0702062v1", 
    "author": "Luca Gammaitoni", 
    "publish": "2007-02-11T09:52:12Z", 
    "summary": "In modern transistor based logic gates, the impact of noise on computation\nhas become increasingly relevant since the voltage scaling strategy, aimed at\ndecreasing the dissipated power, has increased the probability of error due to\nthe reduced switching threshold voltages. In this paper we discuss the role of\nnoise in a two state model that mimic the dynamics of standard logic gates and\nshow that the presence of the noise sets a fundamental limit to the computing\nspeed. An optimal idle time interval that minimizes the error probability, is\nderived."
},{
    "category": "cs.AR", 
    "doi": "10.1142/S0129626407003150", 
    "link": "http://arxiv.org/pdf/cs/0703128v2", 
    "title": "Physarum machine: Implementation of Kolmogorov-Uspensky machine in   biological substrat", 
    "arxiv-id": "cs/0703128v2", 
    "author": "Andrew Adamatzky", 
    "publish": "2007-03-26T01:51:25Z", 
    "summary": "We implement Kolmogorov-Uspensky machine on a plasmodium of true slime mold\n{\\em Physarum polycephalum}. We provide experimental findings on realization of\nthe machine instructions, illustrate basic operations, and elements of\nprogramming."
},{
    "category": "cond-mat.dis-nn", 
    "doi": "10.1016/j.cpc.2007.09.006", 
    "link": "http://arxiv.org/pdf/0704.3573v1", 
    "title": "Simulating spin systems on IANUS, an FPGA-based computer", 
    "arxiv-id": "0704.3573v1", 
    "author": "J. L. Velasco", 
    "publish": "2007-04-26T15:49:47Z", 
    "summary": "We describe the hardwired implementation of algorithms for Monte Carlo\nsimulations of a large class of spin models. We have implemented these\nalgorithms as VHDL codes and we have mapped them onto a dedicated processor\nbased on a large FPGA device. The measured performance on one such processor is\ncomparable to O(100) carefully programmed high-end PCs: it turns out to be even\nbetter for some selected spin models. We describe here codes that we are\ncurrently executing on the IANUS massively parallel FPGA-based system."
},{
    "category": "cs.AR", 
    "doi": "10.1007/11839132", 
    "link": "http://arxiv.org/pdf/0708.1496v1", 
    "title": "A Light-Based Device for Solving the Hamiltonian Path Problem", 
    "arxiv-id": "0708.1496v1", 
    "author": "Mihai Oltean", 
    "publish": "2007-08-10T18:12:52Z", 
    "summary": "In this paper we suggest the use of light for performing useful computations.\nNamely, we propose a special device which uses light rays for solving the\nHamiltonian path problem on a directed graph. The device has a graph-like\nrepresentation and the light is traversing it following the routes given by the\nconnections between nodes. In each node the rays are uniquely marked so that\nthey can be easily identified. At the destination node we will search only for\nparticular rays that have passed only once through each node. We show that the\nproposed device can solve small and medium instances of the problem in\nreasonable time."
},{
    "category": "cs.AR", 
    "doi": "10.1007/s11047-007-9042-z", 
    "link": "http://arxiv.org/pdf/0708.1512v1", 
    "title": "Solving the Hamiltonian path problem with a light-based computer", 
    "arxiv-id": "0708.1512v1", 
    "author": "Mihai Oltean", 
    "publish": "2007-08-10T20:01:24Z", 
    "summary": "In this paper we propose a special computational device which uses light rays\nfor solving the Hamiltonian path problem on a directed graph. The device has a\ngraph-like representation and the light is traversing it by following the\nroutes given by the connections between nodes. In each node the rays are\nuniquely marked so that they can be easily identified. At the destination node\nwe will search only for particular rays that have passed only once through each\nnode. We show that the proposed device can solve small and medium instances of\nthe problem in reasonable time."
},{
    "category": "cs.AR", 
    "doi": "10.1007/s00354-008-0049-5", 
    "link": "http://arxiv.org/pdf/0708.1962v1", 
    "title": "Exact Cover with light", 
    "arxiv-id": "0708.1962v1", 
    "author": "Oana Muntean", 
    "publish": "2007-08-14T21:41:55Z", 
    "summary": "We suggest a new optical solution for solving the YES/NO version of the Exact\nCover problem by using the massive parallelism of light. The idea is to build\nan optical device which can generate all possible solutions of the problem and\nthen to pick the correct one. In our case the device has a graph-like\nrepresentation and the light is traversing it by following the routes given by\nthe connections between nodes. The nodes are connected by arcs in a special way\nwhich lets us to generate all possible covers (exact or not) of the given set.\nFor selecting the correct solution we assign to each item, from the set to be\ncovered, a special integer number. These numbers will actually represent delays\ninduced to light when it passes through arcs. The solution is represented as a\nsubray arriving at a certain moment in the destination node. This will tell us\nif an exact cover does exist or not."
},{
    "category": "cs.CE", 
    "doi": "10.1007/s00354-008-0049-5", 
    "link": "http://arxiv.org/pdf/0710.0244v1", 
    "title": "Theoretical Engineering and Satellite Comlink of a PTVD-SHAM System", 
    "arxiv-id": "0710.0244v1", 
    "author": "Philip B. Alipour", 
    "publish": "2007-10-01T09:35:30Z", 
    "summary": "This paper focuses on super helical memory system's design, 'Engineering,\nArchitectural and Satellite Communications' as a theoretical approach of an\ninvention-model to 'store time-data'. The current release entails three\nconcepts: 1- an in-depth theoretical physics engineering of the chip including\nits, 2- architectural concept based on VLSI methods, and 3- the time-data\nversus data-time algorithm. The 'Parallel Time Varying & Data Super-helical\nAccess Memory' (PTVD-SHAM), possesses a waterfall effect in its architecture\ndealing with the process of voltage output-switch into diverse logic and\nquantum states described as 'Boolean logic & image-logic', respectively.\nQuantum dot computational methods are explained by utilizing coiled carbon\nnanotubes (CCNTs) and CNT field effect transistors (CNFETs) in the chip's\narchitecture. Quantum confinement, categorized quantum well substrate, and\nB-field flux involvements are discussed in theory. Multi-access of coherent\nsequences of 'qubit addressing' in any magnitude, gained as pre-defined, here\ne.g., the 'big O notation' asymptotically confined into singularity while\npossessing a magnitude of 'infinity' for the orientation of array displacement.\nGaussian curvature of k<0 versus k'>(k<0) is debated in aim of specifying the\n2D electron gas characteristics, data storage system for defining short and\nlong time cycles for different CCNT diameters where space-time continuum is\nfolded by chance for the particle. Precise pre/post data timing for, e.g.,\nseismic waves before earthquake mantle-reach event occurrence, including time\nvarying self-clocking devices in diverse geographic locations for radar systems\nis illustrated in the Subsections of the paper. The theoretical fabrication\nprocess, electromigration between chip's components is discussed as well."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.166", 
    "link": "http://arxiv.org/pdf/0710.4643v1", 
    "title": "Generic Pipelined Processor Modeling and High Performance Cycle-Accurate   Simulator Generation", 
    "arxiv-id": "0710.4643v1", 
    "author": "Nikil Dutt", 
    "publish": "2007-10-25T08:14:40Z", 
    "summary": "Detailed modeling of processors and high performance cycle-accurate\nsimulators are essential for today's hardware and software design. These\nproblems are challenging enough by themselves and have seen many previous\nresearch efforts. Addressing both simultaneously is even more challenging, with\nmany existing approaches focusing on one over another. In this paper, we\npropose the Reduced Colored Petri Net (RCPN) model that has two advantages:\nfirst, it offers a very simple and intuitive way of modeling pipelined\nprocessors; second, it can generate high performance cycle-accurate simulators.\nRCPN benefits from all the useful features of Colored Petri Nets without\nsuffering from their exponential growth in complexity. RCPN processor models\nare very intuitive since they are a mirror image of the processor pipeline\nblock diagram. Furthermore, in our experiments on the generated cycle-accurate\nsimulators for XScale and StrongArm processor models, we achieved an order of\nmagnitude (~15 times) speedup over the popular SimpleScalar ARM simulator."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.166", 
    "link": "http://arxiv.org/pdf/0710.4658v1", 
    "title": "Compositional Memory Systems for Multimedia Communicating Tasks", 
    "arxiv-id": "0710.4658v1", 
    "author": "J. T. J. Van Eijndhoven", 
    "publish": "2007-10-25T08:35:10Z", 
    "summary": "Conventional cache models are not suited for real-time parallel processing\nbecause tasks may flush each other's data out of the cache in an unpredictable\nmanner. In this way the system is not compositional so the overall performance\nis difficult to predict and the integration of new tasks expensive. This paper\nproposes a new method that imposes compositionality to the system?s performance\nand makes different memory hierarchy optimizations possible for multimedia\ncommunicating tasks when running on embedded multiprocessor architectures. The\nmethod is based on a cache allocation strategy that assigns sets of the unified\ncache exclusively to tasks and to the communication buffers. We also\nanalytically formulate the problem and describe a method to compute the cache\npartitioning ratio for optimizing the throughput and the consumed power. When\napplied to a multiprocessor with memory hierarchy our technique delivers also\nperformance gain. Compared to the shared cache case, for an application\nconsisting of two jpeg decoders and one edge detection algorithm 5 times less\nmisses are experienced and for an mpeg2 decoder 6.5 times less misses are\nexperienced."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.166", 
    "link": "http://arxiv.org/pdf/0710.4667v1", 
    "title": "Integration, Verification and Layout of a Complex Multimedia SOC", 
    "arxiv-id": "0710.4667v1", 
    "author": "Youn-Long Lin", 
    "publish": "2007-10-25T08:44:47Z", 
    "summary": "We present our experience of designing a single-chip controller for advanced\ndigital still camera from specification all the way to mass production. The\nprocess involves collaboration with camera system designer, IP vendors, EDA\nvendors, silicon wafer foundry, package and testing houses, and camera maker.\nWe also co-work with academic research groups to develop a JPEG codec IP and\nmemory BIST and SOC testing methodology. In this presentation, we cover the\nproblems encountered, our solutions, and lessons learned."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.166", 
    "link": "http://arxiv.org/pdf/0712.1167v1", 
    "title": "Transactional WaveCache: Towards Speculative and Out-of-Order DataFlow   Execution of Memory Operations", 
    "arxiv-id": "0712.1167v1", 
    "author": "V\u00edtor Santos Costa", 
    "publish": "2007-12-07T15:59:37Z", 
    "summary": "The WaveScalar is the first DataFlow Architecture that can efficiently\nprovide the sequential memory semantics required by imperative languages. This\nwork presents an alternative memory ordering mechanism for this architecture,\nthe Transaction WaveCache. Our mechanism maintains the execution order of\nmemory operations within blocks of code, called Waves, but adds the ability to\nspeculatively execute, out-of-order, operations from different waves. This\nordering mechanism is inspired by progress in supporting Transactional\nMemories. Waves are considered as atomic regions and executed as nested\ntransactions. If a wave has finished the execution of all its memory\noperations, as soon as the previous waves are committed, it can be committed.\nIf a hazard is detected in a speculative Wave, all the following Waves\n(children) are aborted and re-executed. We evaluate the WaveCache on a set\nartificial benchmarks. If the benchmark does not access memory often, we could\nachieve speedups of around 90%. Speedups of 33.1% and 24% were observed on more\nmemory intensive applications, and slowdowns up to 16% arise if memory\nbandwidth is a bottleneck. For an application full of WAW, WAR and RAW hazards,\na speedup of 139.7% was verified."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.166", 
    "link": "http://arxiv.org/pdf/0801.2201v1", 
    "title": "Policies of System Level Pipeline Modeling", 
    "arxiv-id": "0801.2201v1", 
    "author": "Ed Harcourt", 
    "publish": "2008-01-15T15:44:28Z", 
    "summary": "Pipelining is a well understood and often used implementation technique for\nincreasing the performance of a hardware system. We develop several SystemC/C++\nmodeling techniques that allow us to quickly model, simulate, and evaluate\npipelines. We employ a small domain specific language (DSL) based on resource\nusage patterns that automates the drudgery of boilerplate code needed to\nconfigure connectivity in simulation models. The DSL is embedded directly in\nthe host modeling language SystemC/C++. Additionally we develop several\ntechniques for parameterizing a pipeline's behavior based on policies of\nfunction, communication, and timing (performance modeling)."
},{
    "category": "quant-ph", 
    "doi": "10.1145/2000502.2000504", 
    "link": "http://arxiv.org/pdf/0809.4317v5", 
    "title": "On the Effect of Quantum Interaction Distance on Quantum Addition   Circuits", 
    "arxiv-id": "0809.4317v5", 
    "author": "Rodney Van Meter", 
    "publish": "2008-09-25T03:59:24Z", 
    "summary": "We investigate the theoretical limits of the effect of the quantum\ninteraction distance on the speed of exact quantum addition circuits. For this\nstudy, we exploit graph embedding for quantum circuit analysis. We study a\nlogical mapping of qubits and gates of any $\\Omega(\\log n)$-depth quantum adder\ncircuit for two $n$-qubit registers onto a practical architecture, which limits\ninteraction distance to the nearest neighbors only and supports only one- and\ntwo-qubit logical gates. Unfortunately, on the chosen $k$-dimensional practical\narchitecture, we prove that the depth lower bound of any exact quantum addition\ncircuits is no longer $\\Omega(\\log {n})$, but $\\Omega(\\sqrt[k]{n})$. This\nresult, the first application of graph embedding to quantum circuits and\ndevices, provides a new tool for compiler development, emphasizes the impact of\nquantum computer architecture on performance, and acts as a cautionary note\nwhen evaluating the time performance of quantum algorithms."
},{
    "category": "cs.NA", 
    "doi": "10.1145/2000502.2000504", 
    "link": "http://arxiv.org/pdf/0810.4196v1", 
    "title": "Interval Semantics for Standard Floating-Point Arithmetic", 
    "arxiv-id": "0810.4196v1", 
    "author": "M. H. van Emden", 
    "publish": "2008-10-23T03:32:47Z", 
    "summary": "If the non-zero finite floating-point numbers are interpreted as point\nintervals, then the effect of rounding can be interpreted as computing one of\nthe bounds of the result according to interval arithmetic. We give an interval\ninterpretation for the signed zeros and infinities, so that the undefined\noperations 0*inf, inf - inf, inf/inf, and 0/0 become defined.\n  In this way no operation remains that gives rise to an error condition.\nMathematically questionable features of the floating-point standard become\nwell-defined sets of reals. Interval semantics provides a basis for the\nverification of numerical algorithms. We derive the results of the newly\ndefined operations and consider the implications for hardware implementation."
},{
    "category": "cs.AR", 
    "doi": "10.1145/2000502.2000504", 
    "link": "http://arxiv.org/pdf/0901.1123v1", 
    "title": "A High Dynamic Range 3-Moduli-Set with Efficient Reverse Converter", 
    "arxiv-id": "0901.1123v1", 
    "author": "Reza Rastegar", 
    "publish": "2009-01-08T20:14:00Z", 
    "summary": "-Residue Number System (RNS) is a valuable tool for fast and parallel\narithmetic. It has a wide application in digital signal processing, fault\ntolerant systems, etc. In this work, we introduce the 3-moduli set {2^n,\n2^{2n}-1, 2^{2n}+1} and propose its residue to binary converter using the\nChinese Remainder Theorem. We present its simple hardware implementation that\nmainly includes one Carry Save Adder (CSA) and a Modular Adder (MA). We compare\nthe performance and area utilization of our reverse converter to the reverse\nconverters of the moduli sets {2^n-1, 2^n, 2^n+1, 2^{2n}+1} and {2^n-1, 2^n,\n2^n+1, 2^n-2^{(n+1)/2}+1, 2^n+2^{(n+1)/2}+1} that have the same dynamic range\nand we demonstrate that our architecture is better in terms of performance and\narea utilization. Also, we show that our reverse converter is faster than the\nreverse converter of {2^n-1, 2^n, 2^n+1} for dynamic ranges like 8-bit, 16-bit,\n32-bit and 64-bit however it requires more area."
},{
    "category": "cs.DS", 
    "doi": "10.1145/2000502.2000504", 
    "link": "http://arxiv.org/pdf/0902.1737v1", 
    "title": "Optimal cache-aware suffix selection", 
    "arxiv-id": "0902.1737v1", 
    "author": "S. Muthukrishnan", 
    "publish": "2009-02-10T20:33:06Z", 
    "summary": "Given string $S[1..N]$ and integer $k$, the {\\em suffix selection} problem is\nto determine the $k$th lexicographically smallest amongst the suffixes $S[i...\nN]$, $1 \\leq i \\leq N$. We study the suffix selection problem in the\ncache-aware model that captures two-level memory inherent in computing systems,\nfor a \\emph{cache} of limited size $M$ and block size $B$. The complexity of\ninterest is the number of block transfers. We present an optimal suffix\nselection algorithm in the cache-aware model, requiring $\\Thetah{N/B}$ block\ntransfers, for any string $S$ over an unbounded alphabet (where characters can\nonly be compared), under the common tall-cache assumption (i.e.\n$M=\\Omegah{B^{1+\\epsilon}}$, where $\\epsilon<1$). Our algorithm beats the\nbottleneck bound for permuting an input array to the desired output array,\nwhich holds for nearly any nontrivial problem in hierarchical memory models."
},{
    "category": "quant-ph", 
    "doi": "10.1142/S0219749910006496", 
    "link": "http://arxiv.org/pdf/0903.0748v2", 
    "title": "Circuit Design for A Measurement-Based Quantum Carry-Lookahead Adder", 
    "arxiv-id": "0903.0748v2", 
    "author": "Rodney Van Meter", 
    "publish": "2009-03-04T12:32:01Z", 
    "summary": "We present the design and evaluation of a quantum carry-lookahead adder\n(QCLA) using measurement-based quantum computation (MBQC), called MBQCLA. QCLA\nwas originally designed for an abstract, concurrent architecture supporting\nlong-distance communication, but most realistic architectures heavily constrain\ncommunication distances. The quantum carry-lookahead adder is faster than a\nquantum ripple-carry adder; QCLA has logarithmic depth while ripple adders have\nlinear depth. MBQCLA utilizes MBQC's ability to transfer quantum states in unit\ntime to accelerate addition. MBQCLA breaks the latency limit of addition\ncircuits in nearest neighbor-only architectures : compared to the $\\Theta(n)$\nlimit on circuit depth for linear nearest-neighbor architectures, it can reach\n$\\Theta(log n)$ depth. MBQCLA is an order of magnitude faster than a\nripple-carry adder when adding registers longer than 100 qubits, but requires a\ncluster state that is an order of magnitude larger. The cluster state resources\ncan be classified as computation and communication; for the unoptimized form,\n$\\approx$ 88 % of the resources are used for communication. Hand optimization\nof horizontal communication costs results in a $\\approx$ 12% reduction in\nspatial resources for the in-place MBQCLA circuit. For comparison, a graph\nstate quantum carry-lookahead adder (GSQCLA) uses only $\\approx$ 9 % of the\nspatial resources of the MBQCLA."
},{
    "category": "cs.PF", 
    "doi": "10.1142/S0219749910006496", 
    "link": "http://arxiv.org/pdf/0905.0792v1", 
    "title": "Introducing a Performance Model for Bandwidth-Limited Loop Kernels", 
    "arxiv-id": "0905.0792v1", 
    "author": "Georg Hager", 
    "publish": "2009-05-06T10:55:04Z", 
    "summary": "We present a performance model for bandwidth limited loop kernels which is\nfounded on the analysis of modern cache based microarchitectures. This model\nallows an accurate performance prediction and evaluation for existing\ninstruction codes. It provides an in-depth understanding of how performance for\ndifferent memory hierarchy levels is made up. The performance of raw memory\nload, store and copy operations and a stream vector triad are analyzed and\nbenchmarked on three modern x86-type quad-core architectures in order to\ndemonstrate the capabilities of the model."
},{
    "category": "cs.PL", 
    "doi": "10.1142/S0219749910006496", 
    "link": "http://arxiv.org/pdf/0907.0749v1", 
    "title": "Function Interface Models for Hardware Compilation: Types, Signatures,   Protocols", 
    "arxiv-id": "0907.0749v1", 
    "author": "Dan R. Ghica", 
    "publish": "2009-07-04T09:24:26Z", 
    "summary": "The problem of synthesis of gate-level descriptions of digital circuits from\nbehavioural specifications written in higher-level programming languages\n(hardware compilation) has been studied for a long time yet a definitive\nsolution has not been forthcoming. The argument of this essay is mainly\nmethodological, bringing a perspective that is informed by recent developments\nin programming-language theory. We argue that one of the major obstacles in the\nway of hardware compilation becoming a useful and mature technology is the lack\nof a well defined function interface model, i.e. a canonical way in which\nfunctions communicate with arguments. We discuss the consequences of this\nproblem and propose a solution based on new developments in programming\nlanguage theory. We conclude by presenting a prototype implementation and some\nexamples illustrating our principles."
},{
    "category": "cs.RO", 
    "doi": "10.1142/S0219749910006496", 
    "link": "http://arxiv.org/pdf/0908.0221v1", 
    "title": "FPGA-based Controller for a Mobile Robot", 
    "arxiv-id": "0908.0221v1", 
    "author": "S. S. Shriramwar", 
    "publish": "2009-08-03T10:30:55Z", 
    "summary": "With application in the robotics and automation, more and more it becomes\nnecessary the development of applications based on methodologies that\nfacilitate future modifications, updates and enhancements in the original\nprojected system. This project presents a conception of mobile robots using\nrapid prototyping, distributing the several control actions in growing levels\nof complexity and computing proposal oriented to embed systems implementation.\nThis kind of controller can be tested on different platform representing the\nmobile robots using reprogrammable logic components (FPGA). This mobile robot\nwill detect obstacle and also be able to control the speed. Different modules\nwill be Actuators, Sensors, wireless transmission. All this modules will be\ninterfaced using FPGA controller. I would like to construct a mechanically\nsimple robot model, which can measure the distance from obstacle with the aid\nof sensor and accordingly should able to control the speed of motor. I would\nlike to construct a mechanically simple robot model, which can measure the\ndistance from obstacle with the aid of sensor and accordingly should able to\ncontrol the speed of motor."
},{
    "category": "cs.AR", 
    "doi": "10.1142/S0219749910006496", 
    "link": "http://arxiv.org/pdf/0909.1781v1", 
    "title": "Boosting XML Filtering with a Scalable FPGA-based Architecture", 
    "arxiv-id": "0909.1781v1", 
    "author": "Vassilis Tsotras", 
    "publish": "2009-09-09T18:10:30Z", 
    "summary": "The growing amount of XML encoded data exchanged over the Internet increases\nthe importance of XML based publish-subscribe (pub-sub) and content based\nrouting systems. The input in such systems typically consists of a stream of\nXML documents and a set of user subscriptions expressed as XML queries. The\npub-sub system then filters the published documents and passes them to the\nsubscribers. Pub-sub systems are characterized by very high input ratios,\ntherefore the processing time is critical. In this paper we propose a \"pure\nhardware\" based solution, which utilizes XPath query blocks on FPGA to solve\nthe filtering problem. By utilizing the high throughput that an FPGA provides\nfor parallel processing, our approach achieves drastically better throughput\nthan the existing software or mixed (hardware/software) architectures. The\nXPath queries (subscriptions) are translated to regular expressions which are\nthen mapped to FPGA devices. By introducing stacks within the FPGA we are able\nto express and process a wide range of path queries very efficiently, on a\nscalable environment. Moreover, the fact that the parser and the filter\nprocessing are performed on the same FPGA chip, eliminates expensive\ncommunication costs (that a multi-core system would need) thus enabling very\nfast and efficient pipelining. Our experimental evaluation reveals more than\none order of magnitude improvement compared to traditional pub/sub systems."
},{
    "category": "cs.AR", 
    "doi": "10.1142/S0219749910006496", 
    "link": "http://arxiv.org/pdf/0910.0505v2", 
    "title": "Hard Data on Soft Errors: A Large-Scale Assessment of Real-World Error   Rates in GPGPU", 
    "arxiv-id": "0910.0505v2", 
    "author": "Vijay S. Pande", 
    "publish": "2009-10-03T02:04:22Z", 
    "summary": "Graphics processing units (GPUs) are gaining widespread use in computational\nchemistry and other scientific simulation contexts because of their huge\nperformance advantages relative to conventional CPUs. However, the reliability\nof GPUs in error-intolerant applications is largely unproven. In particular, a\nlack of error checking and correcting (ECC) capability in the memory subsystems\nof graphics cards has been cited as a hindrance to the acceptance of GPUs as\nhigh-performance coprocessors, but the impact of this design has not been\npreviously quantified.\n  In this article we present MemtestG80, our software for assessing memory\nerror rates on NVIDIA G80 and GT200-architecture-based graphics cards.\nFurthermore, we present the results of a large-scale assessment of GPU error\nrate, conducted by running MemtestG80 on over 20,000 hosts on the Folding@home\ndistributed computing network. Our control experiments on consumer-grade and\ndedicated-GPGPU hardware in a controlled environment found no errors. However,\nour survey over cards on Folding@home finds that, in their installed\nenvironments, two-thirds of tested GPUs exhibit a detectable, pattern-sensitive\nrate of memory soft errors. We demonstrate that these errors persist after\ncontrolling for overclocking and environmental proxies for temperature, but\ndepend strongly on board architecture."
},{
    "category": "cs.AR", 
    "doi": "10.1142/S0219749910006496", 
    "link": "http://arxiv.org/pdf/0910.4052v1", 
    "title": "Virtual-Threading: Advanced General Purpose Processors Architecture", 
    "arxiv-id": "0910.4052v1", 
    "author": "Andrei I. Yafimau", 
    "publish": "2009-10-21T11:31:14Z", 
    "summary": "The paper describes the new computers architecture, the main features of\nwhich has been claimed in the Russian Federation patent 2312388 and in the US\npatent application 11/991331. This architecture is intended to effective\nsupport of the General Purpose Parallel Computing (GPPC), the essence of which\nis extremely frequent switching of threads between states of activity and\nstates of viewed in the paper the algorithmic latency. To emphasize the same\nimpact of the architectural latency and the algorithmic latency upon GPPC, is\nintroduced the new notion of the generalized latency and is defined its\nquantitative measure - the Generalized Latency Tolerance (GLT). It is shown\nthat a well suited for GPPC implementation architecture should have high level\nof GLT and is described such architecture, which is called the Virtual-Threaded\nMachine. This architecture originates a processor virtualization in the\ndirection of activities virtualization, which is orthogonal to the well-known\ndirection of memory virtualization. The key elements of the architecture are 1)\nthe distributed fine grain representation of the architectural register file,\nwhich elements are hardware swapped through levels of a microarchitectural\nmemory, 2) the prioritized fine grain direct hardware multiprogramming, 3) the\naccess controlled virtual addressing and 4) the hardware driven semaphores. The\ncomposition of these features lets to introduce new styles of operating system\n(OS) programming, which is free of interruptions, and of applied programming\nwith a very rare using the OS services."
},{
    "category": "cs.PF", 
    "doi": "10.1142/S0219749910006496", 
    "link": "http://arxiv.org/pdf/0910.4865v1", 
    "title": "Multi-core architectures: Complexities of performance prediction and the   impact of cache topology", 
    "arxiv-id": "0910.4865v1", 
    "author": "Gerhard Wellein", 
    "publish": "2009-10-26T12:48:02Z", 
    "summary": "The balance metric is a simple approach to estimate the performance of\nbandwidth-limited loop kernels. However, applying the method to in-cache\nsituations and modern multi-core architectures yields unsatisfactory results.\nThis paper analyzes the in uence of cache hierarchy design on performance\npredictions for bandwidth-limited loop kernels on current mainstream\nprocessors. We present a diagnostic model with improved predictive power,\ncorrecting the limitations of the simple balance metric. The importance of code\nexecution overhead even in bandwidth-bound situations is emphasized. Finally we\nanalyze the impact of synchronization overhead on multi-threaded performance\nwith a special emphasis on the in uence of cache topology."
},{
    "category": "hep-lat", 
    "doi": "10.1142/S0219749910006496", 
    "link": "http://arxiv.org/pdf/0911.2174v3", 
    "title": "QPACE -- a QCD parallel computer based on Cell processors", 
    "arxiv-id": "0911.2174v3", 
    "author": "F. Winter", 
    "publish": "2009-11-11T16:47:22Z", 
    "summary": "QPACE is a novel parallel computer which has been developed to be primarily\nused for lattice QCD simulations. The compute power is provided by the IBM\nPowerXCell 8i processor, an enhanced version of the Cell processor that is used\nin the Playstation 3. The QPACE nodes are interconnected by a custom,\napplication optimized 3-dimensional torus network implemented on an FPGA. To\nachieve the very high packaging density of 26 TFlops per rack a new water\ncooling concept has been developed and successfully realized. In this paper we\ngive an overview of the architecture and highlight some important technical\ndetails of the system. Furthermore, we provide initial performance results and\nreport on the installation of 8 QPACE racks providing an aggregate peak\nperformance of 200 TFlops."
},{
    "category": "cs.AR", 
    "doi": "10.1142/S0219749910006496", 
    "link": "http://arxiv.org/pdf/1001.4493v1", 
    "title": "Maintaining Virtual Areas on FPGAs using Strip Packing with Delays", 
    "arxiv-id": "1001.4493v1", 
    "author": "Juergen Teich", 
    "publish": "2010-01-25T17:36:32Z", 
    "summary": "Every year, the computing resources available on dynamically partially\nreconfigurable devices increase enormously. In the near future, we expect many\napplications to run on a single reconfigurable device. In this paper, we\npresent a concept for multitasking on dynamically partially reconfigurable\nsystems called virtual area management. We explain its advantages, show its\nchallenges, and discuss possible solutions. Furthermore, we investigate one\nproblem in more detail: Packing modules with time-varying resource requests.\nThis problem from the reconfigurable computing field results in a completely\nnew optimization problem not tackled before. ILP-based and heuristic approaches\nare compared in an experimental study and the drawbacks and benefits discussed."
},{
    "category": "cs.AR", 
    "doi": "10.1142/S0219749910006496", 
    "link": "http://arxiv.org/pdf/1002.1953v1", 
    "title": "Ahb Compatible DDR Sdram Controller Ip Core for Arm Based Soc", 
    "arxiv-id": "1002.1953v1", 
    "author": "C. S. Hemanthkumar", 
    "publish": "2010-02-09T19:47:34Z", 
    "summary": "DDR SDRAM is similar in function to the regular SDRAM but doubles the\nbandwidth of the memory by transferring data on both edges of the clock cycles.\nDDR SDRAM most commonly used in various embedded application like networking,\nimage or video processing, Laptops ete. Now a days many applications needs more\nand more cheap and fast memory. Especially in the field of signal processing,\nrequires significant amount of memory. The most used type of dynamic memory for\nthat purpose is DDR SDRAM. For FPGA design the IC manufacturers are providing\ncommercial memory controller IP cores working only on their products. Main\ndisadvantage is the lack of memory access optimization for random memory access\npatterns. The data path part of those controllers can be used free of charge.\nThis work propose an architecture of a DDR SDRAM controller, which takes\nadvantage of those available and well tested data paths and can be used for any\nFPGA device or ASIC design.(5). In most of the SOC design, DDR SDRAM is\ncommonly used. ARM processor is widely used in SOCs; so that we focused to\nimplement AHB compatible DDR SDRAM controller suitable for ARM based SOC\ndesign."
},{
    "category": "cs.AR", 
    "doi": "10.1142/S0219749910006496", 
    "link": "http://arxiv.org/pdf/1008.0838v1", 
    "title": "Associative control processor with a rigid structure", 
    "arxiv-id": "1008.0838v1", 
    "author": "Omar Khazamov", 
    "publish": "2010-08-04T18:35:25Z", 
    "summary": "The approach of applying associative processor for decision making problem\nwas proposed. It focuses on hardware implementations of fuzzy processing\nsystems, associativity as effective management basis of fuzzy processor. The\nstructural approach is being developed resulting in a quite simple and compact\nparallel associative memory unit (PAMU). The memory cost and speed comparison\nof processors with rigid and soft-variable structure is given. Also the example\nPAMU flashing is considered."
},{
    "category": "quant-ph", 
    "doi": "10.1145/2287696.2287707", 
    "link": "http://arxiv.org/pdf/1008.5093v1", 
    "title": "An $\u0398(\\sqrt{n})$-depth Quantum Adder on a 2D NTC Quantum Computer   Architecture", 
    "arxiv-id": "1008.5093v1", 
    "author": "Rodney Van Meter", 
    "publish": "2010-08-30T15:05:05Z", 
    "summary": "In this work, we propose an adder for the 2D NTC architecture, designed to\nmatch the architectural constraints of many quantum computing technologies. The\nchosen architecture allows the layout of logical qubits in two dimensions and\nthe concurrent execution of one- and two-qubit gates with nearest-neighbor\ninteraction only. The proposed adder works in three phases. In the first phase,\nthe first column generates the summation output and the other columns do the\ncarry-lookahead operations. In the second phase, these intermediate values are\npropagated from column to column, preparing for computation of the final carry\nfor each register position. In the last phase, each column, except the first\none, generates the summation output using this column-level carry. The depth\nand the number of qubits of the proposed adder are $\\Theta(\\sqrt{n})$ and O(n),\nrespectively. The proposed adder executes faster than the adders designed for\nthe 1D NTC architecture when the length of the input registers $n$ is larger\nthan 58."
},{
    "category": "cs.AR", 
    "doi": "10.1145/2287696.2287707", 
    "link": "http://arxiv.org/pdf/1010.4059v2", 
    "title": "Multiplierless Modules for Forward and Backward Integer Wavelet   Transform", 
    "arxiv-id": "1010.4059v2", 
    "author": "Vasil Kolev", 
    "publish": "2010-10-19T21:58:14Z", 
    "summary": "This article is about the architecture of a lossless wavelet filter bank with\nreprogrammable logic. It is based on second generation of wavelets with a\nreduced of number of operations. A new basic structure for parallel\narchitecture and modules to forward and backward integer discrete wavelet\ntransform is proposed."
},{
    "category": "cs.AR", 
    "doi": "10.1145/2287696.2287707", 
    "link": "http://arxiv.org/pdf/1011.3382v1", 
    "title": "Multi-core: Adding a New Dimension to Computing", 
    "arxiv-id": "1011.3382v1", 
    "author": "Md. Tanvir Al Amin", 
    "publish": "2010-11-15T13:48:33Z", 
    "summary": "Invention of Transistors in 1948 started a new era in technology, called\nSolid State Electronics. Since then, sustaining development and advancement in\nelectronics and fabrication techniques has caused the devices to shrink in size\nand become smaller, paving the quest for increasing density and clock speed.\nThat quest has suddenly come to a halt due to fundamental bounds applied by\nphysical laws. But, demand for more and more computational power is still\nprevalent in the computing world. As a result, the microprocessor industry has\nstarted exploring the technology along a different dimension. Speed of a single\nwork unit (CPU) is no longer the concern, rather increasing the number of\nindependent processor cores packed in a single package has become the new\nconcern. Such processors are commonly known as multi-core processors. Scaling\nthe performance by using multiple cores has gained so much attention from the\nacademia and the industry, that not only desktops, but also laptops, PDAs, cell\nphones and even embedded devices today contain these processors. In this paper,\nwe explore state of the art technologies for multi-core processors and existing\nsoftware tools to support parallelism. We also discuss present and future trend\nof research in this field. From our survey, we conclude that next few decades\nare going to be marked by the success of this \"Ubiquitous parallel processing\"."
},{
    "category": "cs.AR", 
    "doi": "10.1145/2287696.2287707", 
    "link": "http://arxiv.org/pdf/1101.4222v1", 
    "title": "Reversible Logic Based Concurrent Error Detection Methodology For   Emerging Nanocircuits", 
    "arxiv-id": "1101.4222v1", 
    "author": "Nagarajan Ranganathan", 
    "publish": "2011-01-21T20:06:28Z", 
    "summary": "Reversible logic has promising applications in emerging nanotechnologies,\nsuch as quantum computing, quantum dot cellular automata and optical computing,\netc. Faults in reversible logic circuits that result in multi-bit error at the\noutputs are very tough to detect, and thus in literature, researchers have only\naddressed the problem of online testing of faults that result single-bit error\nat the outputs based on parity preserving logic. In this work, we propose a\nmethodology for the concurrent error detection in reversible logic circuits to\ndetect faults that can result in multi-bit error at the outputs. The\nmethodology is based on the inverse property of reversible logic and is termed\nas 'inverse and compare' method. By using the inverse property of reversible\nlogic, all the inputs can be regenerated at the outputs. Thus, by comparing the\noriginal inputs with the regenerated inputs, the faults in reversible circuits\ncan be detected. Minimizing the garbage outputs is one of the main goals in\nreversible logic design and synthesis. We show that the proposed methodology\nresults in 'garbageless' reversible circuits. A design of reversible full adder\nthat can be concurrently tested for multi-bit error at the outputs is\nillustrated as the application of the proposed scheme. Finally, we showed the\napplication of the proposed scheme of concurrent error detection towards fault\ndetection in quantum dot cellular automata (QCA) emerging nanotechnology."
},{
    "category": "physics.comp-ph", 
    "doi": "10.1088/1742-6596/331/5/052029", 
    "link": "http://arxiv.org/pdf/1102.3796v1", 
    "title": "APEnet+: high bandwidth 3D torus direct network for petaflops scale   commodity clusters", 
    "arxiv-id": "1102.3796v1", 
    "author": "Piero Vicini", 
    "publish": "2011-02-18T09:59:53Z", 
    "summary": "We describe herein the APElink+ board, a PCIe interconnect adapter featuring\nthe latest advances in wire speed and interface technology plus hardware\nsupport for a RDMA programming model and experimental acceleration of GPU\nnetworking; this design allows us to build a low latency, high bandwidth PC\ncluster, the APEnet+ network, the new generation of our cost-effective,\ntens-of-thousands-scalable cluster network architecture. Some test results and\ncharacterization of data transmission of a complete testbench, based on a\ncommercial development card mounting an Altera FPGA, are provided."
},{
    "category": "cs.AR", 
    "doi": "10.1088/1742-6596/331/5/052029", 
    "link": "http://arxiv.org/pdf/1103.1360v2", 
    "title": "A Secure Asynchronous FPGA Architecture, Experimental Results and Some   Debug Feedback", 
    "arxiv-id": "1103.1360v2", 
    "author": "Marc Renaudin", 
    "publish": "2011-03-07T20:04:05Z", 
    "summary": "This article presents an asynchronous FPGA architecture for implementing\ncryptographic algorithms secured against physical cryptanalysis. We discuss the\nsuitability of asynchronous reconfigurable architectures for such applications\nbefore proceeding to model the side channel and defining our objectives. The\nlogic block architecture is presented in detail. We discuss several solutions\nfor the interconnect architecture, and how these solutions can be ported to\nother flavours of interconnect (i.e. single driver). Next We discuss in detail\na high speed asynchronous configuration chain architecture used to configure\nour asynchronous FPGA with simulation results, and we present a 3 X 3 prototype\nFPGA fabricated in 65 nm CMOS. Lastly we present experiments to test the high\nspeed asynchronous configuration chain and evaluate how far our objectives have\nbeen achieved with proposed solutions, and we conclude with emphasis on\ncomplementary FPGA CAD algorithms, and the effect of CMOS variation on\nSide-Channel Vulnerability."
},{
    "category": "cs.DC", 
    "doi": "10.1088/1742-6596/331/5/052029", 
    "link": "http://arxiv.org/pdf/1105.4780v3", 
    "title": "Fault-tolerant Algorithms for Tick-Generation in Asynchronous Logic:   Robust Pulse Generation", 
    "arxiv-id": "1105.4780v3", 
    "author": "Ulrich Schmid", 
    "publish": "2011-05-24T14:32:18Z", 
    "summary": "Today's hardware technology presents a new challenge in designing robust\nsystems. Deep submicron VLSI technology introduced transient and permanent\nfaults that were never considered in low-level system designs in the past.\nStill, robustness of that part of the system is crucial and needs to be\nguaranteed for any successful product. Distributed systems, on the other hand,\nhave been dealing with similar issues for decades. However, neither the basic\nabstractions nor the complexity of contemporary fault-tolerant distributed\nalgorithms match the peculiarities of hardware implementations. This paper is\nintended to be part of an attempt striving to overcome this gap between theory\nand practice for the clock synchronization problem. Solving this task\nsufficiently well will allow to build a very robust high-precision clocking\nsystem for hardware designs like systems-on-chips in critical applications. As\nour first building block, we describe and prove correct a novel Byzantine\nfault-tolerant self-stabilizing pulse synchronization protocol, which can be\nimplemented using standard asynchronous digital logic. Despite the strict\nlimitations introduced by hardware designs, it offers optimal resilience and\nsmaller complexity than all existing protocols."
},{
    "category": "cs.AR", 
    "doi": "10.1088/1742-6596/331/5/052029", 
    "link": "http://arxiv.org/pdf/1106.2568v1", 
    "title": "HMTT: A Hybrid Hardware/Software Tracing System for Bridging Memory   Trace's Semantic Gap", 
    "arxiv-id": "1106.2568v1", 
    "author": "Jianping Fan", 
    "publish": "2011-06-13T22:29:08Z", 
    "summary": "Memory trace analysis is an important technology for architecture research,\nsystem software (i.e., OS, compiler) optimization, and application performance\nimprovements. Hardware-snooping is an effective and efficient approach to\nmonitor and collect memory traces. Compared with software-based approaches,\nmemory traces collected by hardware-based approaches are usually lack of\nsemantic information, such as process/function/loop identifiers, virtual\naddress and I/O access. In this paper we propose a hybrid hardware/software\nmechanism which is able to collect memory reference trace as well as semantic\ninformation. Based on this mechanism, we designed and implemented a prototype\nsystem called HMTT (Hybrid Memory Trace Tool) which adopts a DIMMsnooping\nmechanism to snoop on memory bus and a software-controlled tracing mechanism to\ninject semantic information into normal memory trace. To the best of our\nknowledge, the HMTT system is the first hardware tracing system capable of\ncorrelating memory trace with high-level events. Comprehensive validations and\nevaluations show that the HMTT system has both hardware's (e.g., no distortion\nor pollution) and software's advantages (e.g., flexibility and more\ninformation)."
},{
    "category": "cs.PF", 
    "doi": "10.1088/1742-6596/331/5/052029", 
    "link": "http://arxiv.org/pdf/1107.4851v1", 
    "title": "AWRP: Adaptive Weight Ranking Policy for Improving Cache Performance", 
    "arxiv-id": "1107.4851v1", 
    "author": "Debabrata Swain", 
    "publish": "2011-07-25T06:43:39Z", 
    "summary": "Due to the huge difference in performance between the computer memory and\nprocessor, the virtual memory management plays a vital role in system\nperformance. A Cache memory is the fast memory which is used to compensate the\nspeed difference between the memory and processor. This paper gives an adaptive\nreplacement policy over the traditional policy which has low overhead, better\nperformance and is easy to implement. Simulations show that our algorithm\nperforms better than Least-Recently-Used (LRU), First-In-First-Out (FIFO) and\nClock with Adaptive Replacement (CAR)."
},{
    "category": "cond-mat.mtrl-sci", 
    "doi": "10.1088/0957-4484/23/7/075201", 
    "link": "http://arxiv.org/pdf/1110.1393v1", 
    "title": "High-Precision Tuning of State for Memristive Devices by Adaptable   Variation-Tolerant Algorithm", 
    "arxiv-id": "1110.1393v1", 
    "author": "Dmitri Strukov", 
    "publish": "2011-10-06T20:55:19Z", 
    "summary": "Using memristive properties common for the titanium dioxide thin film\ndevices, we designed a simple write algorithm to tune device conductance at a\nspecific bias point to 1% relative accuracy (which is roughly equivalent to\n7-bit precision) within its dynamic range even in the presence of large\nvariations in switching behavior. The high precision state is nonvolatile and\nthe results are likely to be sustained for nanoscale memristive devices because\nof the inherent filamentary nature of the resistive switching. The proposed\nfunctionality of memristive devices is especially attractive for analog\ncomputing with low precision data. As one representative example we demonstrate\nhybrid circuitry consisting of CMOS summing amplifier and two memristive\ndevices to perform analog multiply and accumulate computation, which is a\ntypical bottleneck operation in information processing."
},{
    "category": "cs.AR", 
    "doi": "10.1088/0957-4484/23/7/075201", 
    "link": "http://arxiv.org/pdf/1111.1086v1", 
    "title": "Design and Simulation of an 8-bit Dedicated Processor for calculating   the Sine and Cosine of an Angle using the CORDIC Algorithm", 
    "arxiv-id": "1111.1086v1", 
    "author": "M. G. Bhatia", 
    "publish": "2011-11-04T10:27:24Z", 
    "summary": "This paper describes the design and simulation of an 8-bit dedicated\nprocessor for calculating the Sine and Cosine of an Angle using CORDIC\nAlgorithm (COordinate Rotation DIgital Computer), a simple and efficient\nalgorithm to calculate hyperbolic and trigonometric functions. We have proposed\na dedicated processor system, modeled by writing appropriate programs in VHDL,\nfor calculating the Sine and Cosine of an angle. System simulation was carried\nout using ModelSim 6.3f and Xilinx ISE Design Suite 12.3. A maximum frequency\nof 81.353 MHz was reached with a minimum period of 12.292 ns. 126 (3%) slices\nwere used. This paper attempts to survey the existing CORDIC algorithm with an\neye towards implementation in Field Programmable Gate Arrays (FPGAs). A brief\ndescription of the theory behind the algorithm and the derivation of the Sine\nand Cosine of an angle using the CORDIC algorithm has been presented. The\nsystem can be implemented using Spartan3 XC3S400 with Xilinx ISE 12.3 and VHDL."
},{
    "category": "cs.PF", 
    "doi": "10.1088/0957-4484/23/7/075201", 
    "link": "http://arxiv.org/pdf/1111.4287v1", 
    "title": "Parametric Estimation of the Ultimate Size of Hypercomputers", 
    "arxiv-id": "1111.4287v1", 
    "author": "Dmitry Zinoviev", 
    "publish": "2011-11-18T05:29:44Z", 
    "summary": "The performance of the emerging petaflops-scale supercomputers of the nearest\nfuture (hypercomputers) will be governed not only by the clock frequency of the\nprocessing nodes or by the width of the system bus, but also by such factors as\nthe overall power consumption and the geometric size. In this paper, we study\nthe influence of such parameters on one of the most important characteristics\nof a general purpose computer - on the degree of multithreading that must be\npresent in an application to make the use of the hypercomputer justifiable. Our\nmajor finding is that for the class of applications with purely random memory\naccess patterns \"super-fast computing\" and \"high-performance computing\" are\nessentially synonyms for \"massively-parallel computing.\""
},{
    "category": "cs.RO", 
    "doi": "10.1088/0957-4484/23/7/075201", 
    "link": "http://arxiv.org/pdf/1201.0782v1", 
    "title": "Umgebungserfassungssystem fuer mobile Roboter (environment logging   system for mobile autonomous robots)", 
    "arxiv-id": "1201.0782v1", 
    "author": "Dirk Hesselbach", 
    "publish": "2012-01-03T22:15:22Z", 
    "summary": "This diploma thesis describes the theoretical bases, the conception of the\nmodule and the final result of the development process in application. for the\nenvironment logging with a small mobile robot for interiors should be sketched\nan economical alternative to the expensive laser scanners. the structure, color\nor the material of the objects in the radius of action, as well as the\nenvironment brightness and illuminating are to have thereby no influence on the\nresults of measurement."
},{
    "category": "cs.AR", 
    "doi": "10.1088/0957-4484/23/7/075201", 
    "link": "http://arxiv.org/pdf/1201.2542v1", 
    "title": "An efficient FPGA implementation of MRI image filtering and tumor   characterization using Xilinx system generator", 
    "arxiv-id": "1201.2542v1", 
    "author": "A. Kandaswamy", 
    "publish": "2012-01-12T12:23:33Z", 
    "summary": "This paper presents an efficient architecture for various image filtering\nalgorithms and tumor characterization using Xilinx System Generator (XSG). This\narchitecture offers an alternative through a graphical user interface that\ncombines MATLAB, Simulink and XSG and explores important aspects concerned to\nhardware implementation. Performance of this architecture implemented in\nSPARTAN-3E Starter kit (XC3S500E-FG320) exceeds those of similar or greater\nresources architectures. The proposed architecture reduces the resources\navailable on target device by 50%."
},{
    "category": "cs.ET", 
    "doi": "10.1088/0957-4484/23/7/075201", 
    "link": "http://arxiv.org/pdf/1201.3332v1", 
    "title": "A Novel Methodology for Thermal Aware Silicon Area Estimation for 2D &   3D MPSoCs", 
    "arxiv-id": "1201.3332v1", 
    "author": "Vinod Pangracious", 
    "publish": "2012-01-16T18:34:36Z", 
    "summary": "In a multiprocessor system on chip (MPSoC) IC the processor is one of the\nhighest heat dissipating devices. The temperature generated in an IC may vary\nwith floor plan of the chip. This paper proposes an integration and thermal\nanalysis methodology to extract the peak temperature and temperature\ndistribution of 2-dimensional and 3-dimensional multiprocessor system-on-chip.\nAs we know the peak temperature of chip increases in 3-dimensional structures\ncompared to 2-dimensional ones due to the reduced space in intra-layer and\ninter-layer components. In sub-nanometre scale technologies, it is inevitable\nto analysis the heat developed in individual chip to extract the temperature\ndistribution of the entire chip. With the technology scaling in new generation\nICs more and more components are integrated to a smaller area. Along with the\nother parameters threshold voltage is also scaled down which results in\nexponential increase in leakage current. This has resulted in rise in hotspot\ntemperature value due to increase in leakage power. In this paper, we have\nanalysed the temperature developed in an IC with four identical processors at\n2.4 GHz in different floorplans. The analysis has been done for both 2D and 3D\narrangements. In the 3D arrangement, a three layered structure has been\nconsidered with two Silicon layers and a thermal interface material (TIM) in\nbetween them. Based on experimental results the paper proposes a methodology to\nreduce the peak temperature developed in 2D and 3D integrated circuits ."
},{
    "category": "cs.DC", 
    "doi": "10.1088/0957-4484/23/7/075201", 
    "link": "http://arxiv.org/pdf/1202.1925v1", 
    "title": "FATAL+: A Self-Stabilizing Byzantine Fault-tolerant Clocking Scheme for   SoCs", 
    "arxiv-id": "1202.1925v1", 
    "author": "Andreas Steininger", 
    "publish": "2012-02-09T09:30:32Z", 
    "summary": "We present concept and implementation of a self-stabilizing Byzantine\nfault-tolerant distributed clock generation scheme for multi-synchronous GALS\narchitectures in critical applications. It combines a variant of a recently\nintroduced self-stabilizing algorithm for generating low-frequency,\nlow-accuracy synchronized pulses with a simple non-stabilizing high-frequency,\nhigh-accuracy clock synchronization algorithm. We provide thorough correctness\nproofs and a performance analysis, which use methods from fault-tolerant\ndistributed computing research but also addresses hardware-related issues like\nmetastability. The algorithm, which consists of several concurrent\ncommunicating asynchronous state machines, has been implemented in VHDL using\nPetrify in conjunction with some extensions, and synthetisized for an Altera\nCyclone FPGA. An experimental validation of this prototype has been carried out\nto confirm the skew and clock frequency bounds predicted by the theoretical\nanalysis, as well as the very short stabilization times (required for\nrecovering after excessively many transient failures) achievable in practice."
},{
    "category": "cs.AR", 
    "doi": "10.1088/0957-4484/23/7/075201", 
    "link": "http://arxiv.org/pdf/1203.1536v1", 
    "title": "The Distributed Network Processor: a novel off-chip and on-chip   interconnection network architecture", 
    "arxiv-id": "1203.1536v1", 
    "author": "Piero Vicini", 
    "publish": "2012-03-07T16:46:05Z", 
    "summary": "One of the most demanding challenges for the designers of parallel computing\narchitectures is to deliver an efficient network infrastructure providing low\nlatency, high bandwidth communications while preserving scalability. Besides\noff-chip communications between processors, recent multi-tile (i.e. multi-core)\narchitectures face the challenge for an efficient on-chip interconnection\nnetwork between processor's tiles. In this paper, we present a configurable and\nscalable architecture, based on our Distributed Network Processor (DNP) IP\nLibrary, targeting systems ranging from single MPSoCs to massive HPC platforms.\nThe DNP provides inter-tile services for both on-chip and off-chip\ncommunications with a uniform RDMA style API, over a multi-dimensional direct\nnetwork with a (possibly) hybrid topology."
},{
    "category": "cs.AR", 
    "doi": "10.1088/0957-4484/23/7/075201", 
    "link": "http://arxiv.org/pdf/1206.6213v1", 
    "title": "The Necessity for Hardware QoS Support for Server Consolidation and   Cloud Computing", 
    "arxiv-id": "1206.6213v1", 
    "author": "Jos\u00e9 \u00c1ngel Gregorio", 
    "publish": "2012-06-27T09:33:06Z", 
    "summary": "Chip multiprocessors (CMPs) are ubiquitous in most of today's computing\nfields. Although they provide noticeable benefits in terms of performance, cost\nand power efficiency, they also introduce some new issues. In this paper we\nanalyze how the interference from Virtual Private Servers running in other\ncores is a significant component of performance unpredictability and can\nthreaten the attainment of cloud computing. Even if virtualization is used, the\nsharing of the on-chip section of the memory hierarchy by different cores makes\nperformance isolation strongly dependent on what is running elsewhere in the\nsystem. We will show in three actual computing systems, based on Sun UltraSparc\nT1, Sun UltraSparc T2 and Intel Xeon processors, how state-of-the-art\nvirtualization techniques are unable to guarantee performance isolation in a\nrepresentative workload such as SPECweb2005. In an especially conceived near\nworst-case scenario, it is possible to reduce the performance achieved by a\nSolaris Zones consolidated server for this suite of benchmarks in a Sun Fire\nT1000 and a Sun Enterprise T5120 by up to 80%. The performance drop observed by\na Xen consolidated server running in a HP Proliant DL160 G5 is almost 45%. For\nall systems under study, off-chip bandwidth is shown to be the most critical\nresource."
},{
    "category": "cs.AR", 
    "doi": "10.1088/0957-4484/23/7/075201", 
    "link": "http://arxiv.org/pdf/1210.1158v3", 
    "title": "Emulating a large memory with a collection of small ones", 
    "arxiv-id": "1210.1158v3", 
    "author": "James Hanlon", 
    "publish": "2012-10-03T15:57:49Z", 
    "summary": "Sequential computation is well understood but does not scale well with\ncurrent technology. Within the next decade, systems will contain large numbers\nof processors with potentially thousands of processors per chip. Despite this,\nmany computational problems exhibit little or no parallelism and many existing\nformulations are sequential. It is therefore essential that highly-parallel\narchitectures can support sequential computation by emulating large memories\nwith collections of smaller ones, thus supporting efficient execution of\nsequential programs or sequential components of parallel programs.\n  This paper demonstrates that a realistic parallel architecture with scalable\nlow-latency communications can execute large-memory sequential programs with a\nfactor of only 2 to 3 slowdown, when compared to a conventional sequential\narchitecture. This overhead seems an acceptable price to pay to be able to\nswitch between executing highly-parallel programs and sequential programs with\nlarge memory requirements. Efficient emulation of large memories could\ntherefore facilitate a transition from sequential machines by allowing existing\nprograms to be compiled directly to a highly-parallel architecture and then for\ntheir performance to be improved by exploiting parallelism in memory accesses\nand computation."
},{
    "category": "physics.ins-det", 
    "doi": "10.1088/0957-4484/23/7/075201", 
    "link": "http://arxiv.org/pdf/1210.2907v1", 
    "title": "A Low-Power 9-bit Pipelined CMOS ADC with Amplifier and Comparator   Sharing Technique", 
    "arxiv-id": "1210.2907v1", 
    "author": "Dmitry Osipov", 
    "publish": "2012-10-10T13:27:20Z", 
    "summary": "This paper describes a pipelined analog-to-digital converter (ADC) employing\na power and area efficient architecture. The adjacent stages of a pipeline\nshare operational amplifiers. In order to keep accuracy of the amplifiers in\nthe first stages, they use a partially sharing technique. The feature of the\nproposed scheme is that it also shares the comparators. The capacitors of the\nfirst stages of a pipeline are scaled down along a pipeline for a further\nreducing the chip area and its power consumption. A 9-bit 20-MSamples/s ADC,\nintended for use in multi-channel mixed-signal chips, has been fabricated via\nEuropractice in a 180-nm CMOS process from UMC. The prototype ADC shows a\nspurious-free dynamic range of 58.5 dB at a sample rate of 20 MSamples/s, when\na 400 kHz input signal with a swing of 1 dB below full scale is applied. The\neffective number of bits is 8.0 at the same conditions. ADC occupies an active\narea of 0.4 mm2 and dissipates 8.6 mW at a 1.8 V supply."
},{
    "category": "cs.ET", 
    "doi": "10.1088/0957-4484/23/7/075201", 
    "link": "http://arxiv.org/pdf/1210.5342v1", 
    "title": "Design & Simulation of 128x Interpolator Filter", 
    "arxiv-id": "1210.5342v1", 
    "author": "Sonika Arora", 
    "publish": "2012-10-19T08:27:38Z", 
    "summary": "This paper presents the design consideration and simulation of interpolator\nof OSR 128. The proposed structure uses the half band filers & Comb/Sinc\nfilter. Experimental result shows that proposed interpolator achieves the\ndesign specification, and also has good noise rejection capabilities. The\ninterpolator accepts the input at 44.1 kHz for applications like CD & DVD\naudio. The interpolation filter can be applied to the delta sigma DAC. The\nrelated work is done with the MATLAB & XILINX ISE simulators. The maximum\noperating frequency is achieved as 34.584 MHz."
},{
    "category": "cs.PL", 
    "doi": "10.4204/EPTCS.102.10", 
    "link": "http://arxiv.org/pdf/1211.6192v1", 
    "title": "Static Analysis of Lockless Microcontroller C Programs", 
    "arxiv-id": "1211.6192v1", 
    "author": "Stefan Kowalewski", 
    "publish": "2012-11-27T02:37:00Z", 
    "summary": "Concurrently accessing shared data without locking is usually a subject to\nrace conditions resulting in inconsistent or corrupted data. However, there are\nprograms operating correctly without locking by exploiting the atomicity of\ncertain operations on a specific hardware. In this paper, we describe how to\nprecisely analyze lockless microcontroller C programs with interrupts by taking\nthe hardware architecture into account. We evaluate this technique in an\noctagon-based value range analysis using access-based localization to increase\nefficiency."
},{
    "category": "cs.AR", 
    "doi": "10.4204/EPTCS.102.10", 
    "link": "http://arxiv.org/pdf/1212.0310v1", 
    "title": "Design and Implementation of Multistage Interconnection Networks for SoC   Networks", 
    "arxiv-id": "1212.0310v1", 
    "author": "Majid Rezazadeh", 
    "publish": "2012-12-03T08:28:13Z", 
    "summary": "In this paper the focus is on a family of Interconnection Networks (INs)\nknown as Multistage Interconnection Networks (MINs). When it is exploited in\nNetwork-on-Chip (NoC) architecture designs, smaller circuit area, lower power\nconsumption, less junctions and broader bandwidth can be achieved. Each MIN can\nbe considered as an alternative for an NoC architecture design for its simple\ntopology and easy scalability with low degree. This paper includes two major\ncontributions. First, it compares the performance of seven prominent MINs (i.e.\nOmega, Butterfly, Flattened Butterfly, Flattened Baseline, Generalized Cube,\nBene\\v{s} and Clos networks) based on 45nm-CMOS technology and under different\ntypes of Synthetic and Trace-driven workloads. Second, a network called\nMeta-Flattened Network (MFN), was introduced that can decrease the blocking\nprobability by means of reduction the number of hops and increase the\nintermediate paths between stages. This is also led into significant decrease\nin power consumption."
},{
    "category": "cs.ET", 
    "doi": "10.4204/EPTCS.102.10", 
    "link": "http://arxiv.org/pdf/1212.2874v1", 
    "title": "Diametrical Mesh Of Tree (D2D-MoT) Architecture: A Novel Routing   Solution For NoC", 
    "arxiv-id": "1212.2874v1", 
    "author": "Sankar Karmakar", 
    "publish": "2012-12-12T16:37:23Z", 
    "summary": "Network-on-chip (NoC) is a new aspect for designing of future System-On-Chips\n(SoC) where a vast number of IP cores are connected through interconnection\nnetwork. The communication between the nodes occurred by routing packets rather\nthan wires. It supports high degree of scalability, reusability and parallelism\nin communication. In this paper, we present a Mesh routing architecture, which\nis called Diametrical 2D Mesh of Tree, based on Mesh-of-Tree (MoT) routing and\nDiametrical 2D Mesh. It has the advantage of having small diameter as well as\nlarge bisection width and small node degree clubbed with being the fastest\nnetwork in terms of speed. The routing algorithm ensures that the packets will\nalways reach from source to sink through shortest path and is deadlock free."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.102.10", 
    "link": "http://arxiv.org/pdf/1302.1078v1", 
    "title": "Performance Evaluation of Sparse Matrix Multiplication Kernels on Intel   Xeon Phi", 
    "arxiv-id": "1302.1078v1", 
    "author": "Umit V. Catalyurek", 
    "publish": "2013-02-05T16:06:15Z", 
    "summary": "Intel Xeon Phi is a recently released high-performance coprocessor which\nfeatures 61 cores each supporting 4 hardware threads with 512-bit wide SIMD\nregisters achieving a peak theoretical performance of 1Tflop/s in double\nprecision. Many scientific applications involve operations on large sparse\nmatrices such as linear solvers, eigensolver, and graph mining algorithms. The\ncore of most of these applications involves the multiplication of a large,\nsparse matrix with a dense vector (SpMV). In this paper, we investigate the\nperformance of the Xeon Phi coprocessor for SpMV. We first provide a\ncomprehensive introduction to this new architecture and analyze its peak\nperformance with a number of micro benchmarks. Although the design of a Xeon\nPhi core is not much different than those of the cores in modern processors,\nits large number of cores and hyperthreading capability allow many application\nto saturate the available memory bandwidth, which is not the case for many\ncutting-edge processors. Yet, our performance studies show that it is the\nmemory latency not the bandwidth which creates a bottleneck for SpMV on this\narchitecture. Finally, our experiments show that Xeon Phi's sparse kernel\nperformance is very promising and even better than that of cutting-edge general\npurpose processors and GPUs."
},{
    "category": "cs.AR", 
    "doi": "10.4204/EPTCS.102.10", 
    "link": "http://arxiv.org/pdf/1302.1390v1", 
    "title": "MGSim - Simulation tools for multi-core processor architectures", 
    "arxiv-id": "1302.1390v1", 
    "author": "Chris R. Jesshope", 
    "publish": "2013-02-06T15:00:35Z", 
    "summary": "MGSim is an open source discrete event simulator for on-chip hardware\ncomponents, developed at the University of Amsterdam. It is intended to be a\nresearch and teaching vehicle to study the fine-grained hardware/software\ninteractions on many-core and hardware multithreaded processors. It includes\nsupport for core models with different instruction sets, a configurable\nmulti-core interconnect, multiple configurable cache and memory models, a\ndedicated I/O subsystem, and comprehensive monitoring and interaction\nfacilities. The default model configuration shipped with MGSim implements\nMicrogrids, a many-core architecture with hardware concurrency management.\nMGSim is furthermore written mostly in C++ and uses object classes to represent\nchip components. It is optimized for architecture models that can be described\nas process networks."
},{
    "category": "cs.AR", 
    "doi": "10.4204/EPTCS.102.10", 
    "link": "http://arxiv.org/pdf/1302.4464v1", 
    "title": "Dynamic Power Reduction in a Novel CMOS 5T-SRAM for Low-Power SoC", 
    "arxiv-id": "1302.4464v1", 
    "author": "Richard F. Hobson", 
    "publish": "2013-02-18T21:24:22Z", 
    "summary": "This paper addresses a novel five-transistor (5T) CMOS SRAM design with high\nperformance and reliability in 65nm CMOS, and illustrates how it reduces the\ndynamic power consumption in comparison with the conventional and low-power 6T\nSRAM counterparts. This design can be used as cache memory in processors and\nlow-power portable devices. The proposed SRAM cell features ~13% area reduction\ncompared to a conventional 6T cell, and features a unique bit-line and negative\nsupply voltage biasing methodology and ground control architecture to enhance\nperformance, and suppress standby leakage power."
},{
    "category": "cs.DC", 
    "doi": "10.4204/EPTCS.102.10", 
    "link": "http://arxiv.org/pdf/1302.6911v1", 
    "title": "Using Virtual Addresses with Communication Channels", 
    "arxiv-id": "1302.6911v1", 
    "author": "Oskar Schirmer", 
    "publish": "2013-02-11T20:34:05Z", 
    "summary": "While for single processor and SMP machines, memory is the allocatable\nquantity, for machines made up of large amounts of parallel computing units,\neach with its own local memory, the allocatable quantity is a single computing\nunit. Where virtual address management is used to keep memory coherent and\nallow allocation of more than physical memory is actually available, virtual\ncommunication channel references can be used to make computing units stay\nconnected across allocation and swapping."
},{
    "category": "physics.ins-det", 
    "doi": "10.1088/1674-1137/37/10/106102", 
    "link": "http://arxiv.org/pdf/1303.6849v1", 
    "title": "A Fast Improved Fat Tree Encoder for Wave Union TDC in an FPGA", 
    "arxiv-id": "1303.6849v1", 
    "author": "Qi An", 
    "publish": "2013-03-27T14:56:33Z", 
    "summary": "Up to the present, the wave union method can achieve the best timing\nperformance in FPGA based TDC designs. However, it should be guaranteed in such\na structure that the non-thermometer code to binary code (NTH2B) encoding\nprocess should be finished within just one system clock cycle. So the\nimplementation of the NTH2B encoder is quite challenging considering the high\nspeed requirement. Besides, the high resolution wave union TDC also demands the\nencoder to convert an ultra-wide input code to a binary code. We present a fast\nimproved fat tree encoder (IFTE) to fulfill such requirements, in which bubble\nerror suppression is also integrated. With this encoder scheme, a wave union\nTDC with 7.7 ps RMS and 3.8 ps effective bin size was implemented in an FPGA\nfrom Xilinx Virtex 5 family. An encoding time of 8.33 ns was achieved for a\n276-bit non-thermometer code to a 9-bit binary code conversion. We conducted a\nseries of tests on the oscillating period of the wave union launcher, as well\nas the overall performance of the TDC; test results indicate that the IFTE\nworks well. In fact, in the implementation of this encoder, no manual routing\nor special constrains were required; therefore, this IFTE structure could also\nbe further applied in other delay chain based FPGA TDCs."
},{
    "category": "cs.ET", 
    "doi": "10.1109/TVLSI.2012.2232946", 
    "link": "http://arxiv.org/pdf/1308.0090v1", 
    "title": "Resistive Threshold Logic", 
    "arxiv-id": "1308.0090v1", 
    "author": "D. Kumar", 
    "publish": "2013-08-01T04:17:30Z", 
    "summary": "We report a resistance based threshold logic family useful for mimicking\nbrain like large variable logic functions in VLSI. A universal Boolean logic\ncell based on an analog resistive divider and threshold logic circuit is\npresented. The resistive divider is implemented using memristors and provides\noutput voltage as a summation of weighted product of input voltages. The output\nof resistive divider is converted into a binary value by a threshold operation\nimplemented by CMOS inverter and/or Opamp. An universal cell structure is\npresented to decrease the overall implementation complexity and number of\ncomponents. When the number of input variables become very high, the proposed\ncell offers advantages of smaller area and design simplicity in comparison with\nCMOS based logic circuits."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TVLSI.2012.2232946", 
    "link": "http://arxiv.org/pdf/1308.0840v1", 
    "title": "Designing Parity Preserving Reversible Circuits", 
    "arxiv-id": "1308.0840v1", 
    "author": "Chander Chandak", 
    "publish": "2013-08-04T19:06:44Z", 
    "summary": "Making a reversible circuit fault-tolerant is much more difficult than\nclassical circuit and there have been only a few works in the area of\nparity-preserving reversible logic design. Moreover, all of these designs are\nad hoc, based on some pre-defined parity preserving reversible gates as\nbuilding blocks. In this paper, we for the first time propose a novel and\nsystematic approach towards parity preserving reversible circuits design. We\nprovide some related theoretical results and give two algorithms, one from\nreversible specification to parity preserving reversible specification and\nanother from irreversible specification to parity preserving reversible\nspecification. We also evaluate the effectiveness of our approach by extensive\nexperimental results."
},{
    "category": "cs.DC", 
    "doi": "10.1109/TVLSI.2012.2232946", 
    "link": "http://arxiv.org/pdf/1308.1419v1", 
    "title": "Improving the GPU space of computation under triangular domain problems", 
    "arxiv-id": "1308.1419v1", 
    "author": "Nancy Hitschfeld", 
    "publish": "2013-08-06T20:44:35Z", 
    "summary": "There is a stage in the GPU computing pipeline where a grid of thread-blocks\nis mapped to the problem domain. Normally, this grid is a k-dimensional\nbounding box that covers a k-dimensional problem no matter its shape. Threads\nthat fall inside the problem domain perform computations, otherwise they are\ndiscarded at runtime. For problems with non-square geometry, this is not always\nthe best idea because part of the space of computation is executed without any\npractical use. Two- dimensional triangular domain problems, alias td-problems,\nare a particular case of interest. Problems such as the Euclidean distance map,\nLU decomposition, collision detection and simula- tions over triangular tiled\ndomains are all td-problems and they appear frequently in many areas of\nscience. In this work, we propose an improved GPU mapping function g(lambda),\nthat maps any lambda block to a unique location (i, j) in the triangular\ndomain. The mapping is based on the properties of the lower triangular matrix\nand it works at a block level, thus not compromising thread organization within\na block. The theoretical improvement from using g(lambda) is upper bounded as I\n< 2 and the number of wasted blocks is reduced from O(n^2) to O(n). We compare\nour strategy with other proposed methods; the upper-triangular mapping (UTM),\nthe rectangular box (RB) and the recursive partition (REC). Our experimental\nresults on Nvidias Kepler GPU architecture show that g(lambda) is between 12%\nand 15% faster than the bounding box (BB) strategy. When compared to the other\nstrategies, our mapping runs significantly faster than UTM and it is as fast as\nRB in practical use, with the advantage that thread organization is not\ncompromised, as in RB. This work also contributes at presenting, for the first\ntime, a fair comparison of all existing strategies running the same experiments\nunder the same hardware."
},{
    "category": "cs.PF", 
    "doi": "10.1109/TVLSI.2012.2232946", 
    "link": "http://arxiv.org/pdf/1308.3123v1", 
    "title": "First experiences with the Intel MIC architecture at LRZ", 
    "arxiv-id": "1308.3123v1", 
    "author": "Momme Allalen", 
    "publish": "2013-08-14T13:46:37Z", 
    "summary": "With the rapidly growing demand for computing power new accelerator based\narchitectures have entered the world of high performance computing since around\n5 years. In particular GPGPUs have recently become very popular, however\nprogramming GPGPUs using programming languages like CUDA or OpenCL is\ncumbersome and error-prone. Trying to overcome these difficulties, Intel\ndeveloped their own Many Integrated Core (MIC) architecture which can be\nprogrammed using standard parallel programming techniques like OpenMP and MPI.\nIn the beginning of 2013, the first production-level cards named Intel Xeon Phi\ncame on the market. LRZ has been considered by Intel as a leading research\ncentre for evaluating coprocessors based on the MIC architecture since 2010\nunder strict NDA. Since the Intel Xeon Phi is now generally available, we can\nshare our experience on programming Intel's new MIC architecture."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TVLSI.2012.2232946", 
    "link": "http://arxiv.org/pdf/1309.2533v1", 
    "title": "Evaluation of the Performance/Energy Overhead in DSP Video Decoding and   its Implications", 
    "arxiv-id": "1309.2533v1", 
    "author": "Djamel Benazzouz", 
    "publish": "2013-09-10T14:50:29Z", 
    "summary": "Video decoding is considered as one of the most compute and energy intensive\napplication in energy constrained mobile devices. Some specific processing\nunits, such as DSPs, are added to those devices in order to optimize the\nperformance and the energy consumption. However, in DSP video decoding, the\ninter-processor communication overhead may have a considerable impact on the\nperformance and the energy consumption. In this paper, we propose to evaluate\nthis overhead and analyse its impact on the performance and the energy\nconsumption as compared to the GPP decoding. Our work revealed that the GPP can\nbe the best choice in many cases due to the a significant overhead in DSP\ndecoding which may represents 30% of the total decoding energy."
},{
    "category": "cs.ET", 
    "doi": "10.1109/TVLSI.2012.2232946", 
    "link": "http://arxiv.org/pdf/1402.4046v1", 
    "title": "Boolean Logic Gates From A Single Memristor Via Low-Level Sequential   Logic", 
    "arxiv-id": "1402.4046v1", 
    "author": "Andrew Adamatzky", 
    "publish": "2014-02-17T16:21:31Z", 
    "summary": "By using the memristor's memory to both store a bit and perform an operation\nwith a second input bit, simple Boolean logic gates have been built with a\nsingle memristor. The operation makes use of the interaction of current spikes\n(occasionally called current transients) found in both memristors and other\ndevices. The sequential time-based logic methodology allows two logical input\nbits to be used on a one-port by sending the bits separated in time. The\nresulting logic gate is faster than one relying on memristor's state switching,\nlow power and requires only one memristor. We experimentally demonstrate\nworking OR and XOR gates made with a single flexible Titanium dioxide sol-gel\nmemristor."
},{
    "category": "cs.ET", 
    "doi": "10.1109/TVLSI.2012.2232946", 
    "link": "http://arxiv.org/pdf/1404.0296v1", 
    "title": "Metal-Gated Junctionless Nanowire Transistors", 
    "arxiv-id": "1404.0296v1", 
    "author": "Csaba Andras Moritz", 
    "publish": "2014-04-01T16:12:12Z", 
    "summary": "Junctionless Nanowire Field-Effect Transistors (JNFETs), where the channel\nregion is uniformly doped without the need for source-channel and drain-channel\njunctions or lateral doping abruptness, are considered an attractive\nalternative to conventional CMOS FETs. Previous theoretical and experimental\nworks [1][2] on JNFETs have considered polysilicon gates and silicon-dioxide\ndielectric. However, with further scaling, JNFETs will suffer from deleterious\neffects of doped polysilicon such as high resistance, additional capacitance\ndue to gate-oxide interface depletion, and incompatibility with high-k\ndielectrics[3][4]. In this paper, novel metal- gated high-k JNFETs are\ninvestigated through detailed process and device simulations. These MJNFETs are\nalso ideally suited for new types of nano-architectures such as N3ASICs [5]\nwhich utilize regular nanowire arrays with limited customization. In such nano-\nsystems, the simplified device geometry in conjunction with a single-type FET\ncircuit style [6] would imply that logic arrays could be patterned out of\npre-doped SOI wafers without the need for any additional ion implantation."
},{
    "category": "cs.ET", 
    "doi": "10.1109/TVLSI.2012.2232946", 
    "link": "http://arxiv.org/pdf/1404.0607v1", 
    "title": "Skybridge: 3-D Integrated Circuit Technology Alternative to CMOS", 
    "arxiv-id": "1404.0607v1", 
    "author": "Csaba Andras Moritz", 
    "publish": "2014-04-02T16:41:11Z", 
    "summary": "Continuous scaling of CMOS has been the major catalyst in miniaturization of\nintegrated circuits (ICs) and crucial for global socio-economic progress.\nHowever, scaling to sub-20nm technologies is proving to be challenging as\nMOSFETs are reaching their fundamental limits and interconnection bottleneck is\ndominating IC operational power and performance. Migrating to 3-D, as a way to\nadvance scaling, has eluded us due to inherent customization and manufacturing\nrequirements in CMOS that are incompatible with 3-D organization. Partial\nattempts with die-die and layer-layer stacking have their own limitations. We\npropose a 3-D IC fabric technology, Skybridge[TM], which offers paradigm shift\nin technology scaling as well as design. We co-architect Skybridge's core\naspects, from device to circuit style, connectivity, thermal management, and\nmanufacturing pathway in a 3-D fabric-centric manner, building on a uniform 3-D\ntemplate. Our extensive bottom-up simulations, accounting for detailed material\nsystem structures, manufacturing process, device, and circuit parasitics,\ncarried through for several designs including a designed microprocessor, reveal\na 30-60x density, 3.5x performance per watt benefits, and 10X reduction in\ninterconnect lengths vs. scaled 16-nm CMOS. Fabric-level heat extraction\nfeatures are shown to successfully manage IC thermal profiles in 3-D. Skybridge\ncan provide continuous scaling of integrated circuits beyond CMOS in the 21st\ncentury."
},{
    "category": "cs.AR", 
    "doi": "10.1109/LCOMM.2014.2317738", 
    "link": "http://arxiv.org/pdf/1404.1311v3", 
    "title": "Comments on \"IEEE 1588 Clock Synchronization using Dual Slave Clocks in   a Slave\"", 
    "arxiv-id": "1404.1311v3", 
    "author": "Kyeong Soo Kim", 
    "publish": "2014-03-25T21:54:56Z", 
    "summary": "In the above letter, Chin and Chen proposed an IEEE 1588 clock\nsynchronization method based on dual slave clocks, where they claim that\nmultiple unknown parameters --- i.e., clock offset, clock skew, and\nmaster-to-slave delay --- can be estimated with only one-way time transfers\nusing more equations than usual. This comment investigates Chin and Chen's dual\nclock scheme with detailed models for a master and dual slave clocks and shows\nthat the formulation of multi-parameter estimation is invalid, which affirms\nthat it is impossible to distinguish the effect of delay from that of clock\noffset at a slave even with dual slave clocks."
},{
    "category": "cs.NI", 
    "doi": "10.1109/LCOMM.2014.2317738", 
    "link": "http://arxiv.org/pdf/1406.0309v1", 
    "title": "Network Function Virtualization based on FPGAs:A Framework for   all-Programmable network devices", 
    "arxiv-id": "1406.0309v1", 
    "author": "Dimitrios Soudris", 
    "publish": "2014-06-02T09:45:59Z", 
    "summary": "Network Function Virtualization (NFV) refers to the use of commodity hardware\nresources as the basic platform to perform specialized network functions as\nopposed to specialized hardware devices. Currently, NFV is mainly implemented\nbased on general purpose processors, or general purpose network processors. In\nthis paper we propose the use of FPGAs as an ideal platform for NFV that can be\nused to provide both the flexibility of virtualizations and the high\nperformance of the specialized hardware. We present the early attempts of using\nFPGAs dynamic reconfiguration in network processing applications to provide\nflexible network functions and we present the opportunities for an FPGA-based\nNFV platform."
},{
    "category": "cs.AR", 
    "doi": "10.4204/EPTCS.152.12", 
    "link": "http://arxiv.org/pdf/1406.1565v1", 
    "title": "Modeling Algorithms in SystemC and ACL2", 
    "arxiv-id": "1406.1565v1", 
    "author": "David M. Russinoff", 
    "publish": "2014-06-06T01:48:45Z", 
    "summary": "We describe the formal language MASC, based on a subset of SystemC and\nintended for modeling algorithms to be implemented in hardware. By means of a\nspecial-purpose parser, an algorithm coded in SystemC is converted to a MASC\nmodel for the purpose of documentation, which in turn is translated to ACL2 for\nformal verification. The parser also generates a SystemC variant that is\nsuitable as input to a high-level synthesis tool. As an illustration of this\nmethodology, we describe a proof of correctness of a simple 32-bit radix-4\nmultiplier."
},{
    "category": "physics.ins-det", 
    "doi": "10.4204/EPTCS.152.12", 
    "link": "http://arxiv.org/pdf/1406.3568v1", 
    "title": "NaNet: a Low-Latency, Real-Time, Multi-Standard Network Interface Card   with GPUDirect Features", 
    "arxiv-id": "1406.3568v1", 
    "author": "P. Vicini", 
    "publish": "2014-06-13T15:27:05Z", 
    "summary": "While the GPGPU paradigm is widely recognized as an effective approach to\nhigh performance computing, its adoption in low-latency, real-time systems is\nstill in its early stages.\n  Although GPUs typically show deterministic behaviour in terms of latency in\nexecuting computational kernels as soon as data is available in their internal\nmemories, assessment of real-time features of a standard GPGPU system needs\ncareful characterization of all subsystems along data stream path.\n  The networking subsystem results in being the most critical one in terms of\nabsolute value and fluctuations of its response latency.\n  Our envisioned solution to this issue is NaNet, a FPGA-based PCIe Network\nInterface Card (NIC) design featuring a configurable and extensible set of\nnetwork channels with direct access through GPUDirect to NVIDIA Fermi/Kepler\nGPU memories.\n  NaNet design currently supports both standard - GbE (1000BASE-T) and 10GbE\n(10Base-R) - and custom - 34~Gbps APElink and 2.5~Gbps deterministic latency\nKM3link - channels, but its modularity allows for a straightforward inclusion\nof other link technologies.\n  To avoid host OS intervention on data stream and remove a possible source of\njitter, the design includes a network/transport layer offload module with\ncycle-accurate, upper-bound latency, supporting UDP, KM3link Time Division\nMultiplexing and APElink protocols.\n  After NaNet architecture description and its latency/bandwidth\ncharacterization for all supported links, two real world use cases will be\npresented: the GPU-based low level trigger for the RICH detector in the NA62\nexperiment at CERN and the on-/off-shore data link for KM3 underwater neutrino\ntelescope."
},{
    "category": "cs.AR", 
    "doi": "10.4204/EPTCS.152.12", 
    "link": "http://arxiv.org/pdf/1406.6037v1", 
    "title": "Preemptive Thread Block Scheduling with Online Structural Runtime   Prediction for Concurrent GPGPU Kernels", 
    "arxiv-id": "1406.6037v1", 
    "author": "Matthew J. Thazhuthaveetil", 
    "publish": "2014-06-23T19:44:03Z", 
    "summary": "Recent NVIDIA Graphics Processing Units (GPUs) can execute multiple kernels\nconcurrently. On these GPUs, the thread block scheduler (TBS) uses the FIFO\npolicy to schedule their thread blocks. We show that FIFO leaves performance to\nchance, resulting in significant loss of performance and fairness. To improve\nperformance and fairness, we propose use of the preemptive Shortest Remaining\nTime First (SRTF) policy instead. Although SRTF requires an estimate of runtime\nof GPU kernels, we show that such an estimate of the runtime can be easily\nobtained using online profiling and exploiting a simple observation on GPU\nkernels' grid structure. Specifically, we propose a novel Structural Runtime\nPredictor. Using a simple Staircase model of GPU kernel execution, we show that\nthe runtime of a kernel can be predicted by profiling only the first few thread\nblocks. We evaluate an online predictor based on this model on benchmarks from\nERCBench, and find that it can estimate the actual runtime reasonably well\nafter the execution of only a single thread block. Next, we design a thread\nblock scheduler that is both concurrent kernel-aware and uses this predictor.\nWe implement the SRTF policy and evaluate it on two-program workloads from\nERCBench. SRTF improves STP by 1.18x and ANTT by 2.25x over FIFO. When compared\nto MPMax, a state-of-the-art resource allocation policy for concurrent kernels,\nSRTF improves STP by 1.16x and ANTT by 1.3x. To improve fairness, we also\npropose SRTF/Adaptive which controls resource usage of concurrently executing\nkernels to maximize fairness. SRTF/Adaptive improves STP by 1.12x, ANTT by\n2.23x and Fairness by 2.95x compared to FIFO. Overall, our implementation of\nSRTF achieves system throughput to within 12.64% of Shortest Job First (SJF, an\noracle optimal scheduling policy), bridging 49% of the gap between FIFO and\nSJF."
},{
    "category": "cs.AR", 
    "doi": "10.1007/978-3-642-36321-4_56", 
    "link": "http://arxiv.org/pdf/1409.4043v1", 
    "title": "Design of Novel Algorithm and Architecture for Gaussian Based Color   Image Enhancement System for Real Time Applications", 
    "arxiv-id": "1409.4043v1", 
    "author": "D. R. Rameshbabu", 
    "publish": "2014-09-14T10:24:04Z", 
    "summary": "This paper presents the development of a new algorithm for Gaussian based\ncolor image enhancement system. The algorithm has been designed into\narchitecture suitable for FPGA/ASIC implementation. The color image enhancement\nis achieved by first convolving an original image with a Gaussian kernel since\nGaussian distribution is a point spread function which smoothen the image.\nFurther, logarithm-domain processing and gain/offset corrections are employed\nin order to enhance and translate pixels into the display range of 0 to 255.\nThe proposed algorithm not only provides better dynamic range compression and\ncolor rendition effect but also achieves color constancy in an image. The\ndesign exploits high degrees of pipelining and parallel processing to achieve\nreal time performance. The design has been realized by RTL compliant Verilog\ncoding and fits into a single FPGA with a gate count utilization of 321,804.\nThe proposed method is implemented using Xilinx Virtex-II Pro XC2VP40-7FF1148\nFPGA device and is capable of processing high resolution color motion pictures\nof sizes of up to 1600x1200 pixels at the real time video rate of 116 frames\nper second. This shows that the proposed design would work for not only still\nimages but also for high resolution video sequences."
},{
    "category": "cs.ET", 
    "doi": "10.1007/978-3-642-36321-4_56", 
    "link": "http://arxiv.org/pdf/1104.0924v2", 
    "title": "ReveR: Software Simulator of Reversible Processor with Stack", 
    "arxiv-id": "1104.0924v2", 
    "author": "Alexander Yu. Vlasov", 
    "publish": "2011-04-05T21:38:17Z", 
    "summary": "A software model of a reversible processor ReveR with the stack is discussed\nin this paper. An architecture, the minimal set of elementary reversible\noperations together with an implementation of the basic control flow structures\nand procedures calls using simple assembler language are described."
},{
    "category": "cond-mat.mes-hall", 
    "doi": "10.1063/1.3537923", 
    "link": "http://arxiv.org/pdf/1104.1493v1", 
    "title": "Scalability of spin FPGA: A Reconfigurable Architecture based on spin   MOSFET", 
    "arxiv-id": "1104.1493v1", 
    "author": "Yoshiaki Saito", 
    "publish": "2011-04-08T06:24:47Z", 
    "summary": "Scalability of Field Programmable Gate Array (FPGA) using spin MOSFET (spin\nFPGA) with magnetocurrent (MC) ratio in the range of 100% to 1000% is discussed\nfor the first time. Area and speed of million-gate spin FPGA are numerically\nbenchmarked with CMOS FPGA for 22nm, 32nm and 45nm technologies including 20%\ntransistor size variation. We show that area is reduced and speed is increased\nin spin FPGA owing to the nonvolatile memory function of spin MOSFET."
},{
    "category": "cs.SE", 
    "doi": "10.1063/1.3537923", 
    "link": "http://arxiv.org/pdf/1109.4351v1", 
    "title": "Designing a CPU model: from a pseudo-formal document to fast code", 
    "arxiv-id": "1109.4351v1", 
    "author": "Xiaomu Shi", 
    "publish": "2011-09-20T16:55:50Z", 
    "summary": "For validating low level embedded software, engineers use simulators that\ntake the real binary as input. Like the real hardware, these full-system\nsimulators are organized as a set of components. The main component is the CPU\nsimulator (ISS), because it is the usual bottleneck for the simulation speed,\nand its development is a long and repetitive task. Previous work showed that an\nISS can be generated from an Architecture Description Language (ADL). In the\nwork reported in this paper, we generate a CPU simulator directly from the\npseudo-formal descriptions of the reference manual. For each instruction, we\nextract the information describing its behavior, its binary encoding, and its\nassembly syntax. Next, after automatically applying many optimizations on the\nextracted information, we generate a SystemC/TLM ISS. We also generate tests\nfor the decoder and a formal specification in Coq. Experiments show that the\ngenerated ISS is as fast and stable as our previous hand-written ISS."
},{
    "category": "cs.AR", 
    "doi": "10.1063/1.3537923", 
    "link": "http://arxiv.org/pdf/1204.2772v1", 
    "title": "Effect of Thread Level Parallelism on the Performance of Optimum   Architecture for Embedded Applications", 
    "arxiv-id": "1204.2772v1", 
    "author": "Hojjat Taghdisi", 
    "publish": "2012-04-12T17:07:58Z", 
    "summary": "According to the increasing complexity of network application and internet\ntraffic, network processor as a subset of embedded processors have to process\nmore computation intensive tasks. By scaling down the feature size and emersion\nof chip multiprocessors (CMP) that are usually multi-thread processors, the\nperformance requirements are somehow guaranteed. As multithread processors are\nthe heir of uni-thread processors and there isn't any general design flow to\ndesign a multithread embedded processor, in this paper we perform a\ncomprehensive design space exploration for an optimum uni-thread embedded\nprocessor based on the limited area and power budgets. Finally we run multiple\nthreads on this architecture to find out the maximum thread level parallelism\n(TLP) based on performance per power and area optimum uni-thread architecture."
},{
    "category": "cond-mat.dis-nn", 
    "doi": "10.1140/epjst/e2012-01636-9", 
    "link": "http://arxiv.org/pdf/1204.4134v1", 
    "title": "Reconfigurable computing for Monte Carlo simulations: results and   prospects of the Janus project", 
    "arxiv-id": "1204.4134v1", 
    "author": "D. Yllanes", 
    "publish": "2012-04-18T17:03:44Z", 
    "summary": "We describe Janus, a massively parallel FPGA-based computer optimized for the\nsimulation of spin glasses, theoretical models for the behavior of glassy\nmaterials. FPGAs (as compared to GPUs or many-core processors) provide a\ncomplementary approach to massively parallel computing. In particular, our\nmodel problem is formulated in terms of binary variables, and floating-point\noperations can be (almost) completely avoided. The FPGA architecture allows us\nto run many independent threads with almost no latencies in memory access, thus\nupdating up to 1024 spins per cycle. We describe Janus in detail and we\nsummarize the physics results obtained in four years of operation of this\nmachine; we discuss two types of physics applications: long simulations on very\nlarge systems (which try to mimic and provide understanding about the\nexperimental non-equilibrium dynamics), and low-temperature equilibrium\nsimulations using an artificial parallel tempering dynamics. The time scale of\nour non-equilibrium simulations spans eleven orders of magnitude (from\npicoseconds to a tenth of a second). On the other hand, our equilibrium\nsimulations are unprecedented both because of the low temperatures reached and\nfor the large systems that we have brought to equilibrium. A finite-time\nscaling ansatz emerges from the detailed comparison of the two sets of\nsimulations. Janus has made it possible to perform spin-glass simulations that\nwould take several decades on more conventional architectures. The paper ends\nwith an assessment of the potential of possible future versions of the Janus\narchitecture, based on state-of-the-art technology."
},{
    "category": "cs.DC", 
    "doi": "10.5121/ijcsit.2012.4201", 
    "link": "http://arxiv.org/pdf/1204.6662v1", 
    "title": "Mppsocgen: A framework for automatic generation of mppsoc architecture", 
    "arxiv-id": "1204.6662v1", 
    "author": "Mohamed Abid", 
    "publish": "2012-04-30T15:04:49Z", 
    "summary": "Automatic code generation is a standard method in software engineering since\nit improves the code consistency and reduces the overall development time. In\nthis context, this paper presents a design flow for automatic VHDL code\ngeneration of mppSoC (massively parallel processing System-on-Chip)\nconfiguration. Indeed, depending on the application requirements, a framework\nof Netbeans Platform Software Tool named MppSoCGEN was developed in order to\naccelerate the design process of complex mppSoC. Starting from an architecture\nparameters design, VHDL code will be automatically generated using parsing\nmethod. Configuration rules are proposed to have a correct and valid VHDL\nsyntax configuration. Finally, an automatic generation of Processor Elements\nand network topologies models of mppSoC architecture will be done for Stratix\nII device family. Our framework improves its flexibility on Netbeans 5.5\nversion and centrino duo Core 2GHz with 22 Kbytes and 3 seconds average\nruntime. Experimental results for reduction algorithm validate our MppSoCGEN\ndesign flow and demonstrate the efficiency of generated architectures."
},{
    "category": "cs.AR", 
    "doi": "10.5121/ijcsit.2012.4201", 
    "link": "http://arxiv.org/pdf/1207.5138v1", 
    "title": "Ethernet Packet Processor for SoC Application", 
    "arxiv-id": "1207.5138v1", 
    "author": "R. C. Biradar", 
    "publish": "2012-07-21T13:47:55Z", 
    "summary": "As the demand for Internet expands significantly in numbers of users,\nservers, IP addresses, switches and routers, the IP based network architecture\nmust evolve and change. The design of domain specific processors that require\nhigh performance, low power and high degree of programmability is the\nbottleneck in many processor based applications. This paper describes the\ndesign of ethernet packet processor for system-on-chip (SoC) which performs all\ncore packet processing functions, including segmentation and reassembly,\npacketization classification, route and queue management which will speedup\nswitching/routing performance. Our design has been configured for use with\nmultiple projects ttargeted to a commercial configurable logic device the\nsystem is designed to support 10/100/1000 links with a speed advantage. VHDL\nhas been used to implement and simulated the required functions in FPGA."
},{
    "category": "cs.DS", 
    "doi": "10.5121/ijcsit.2012.4201", 
    "link": "http://arxiv.org/pdf/1304.2110v1", 
    "title": "An Improved GEF Fast Addition Algorithm", 
    "arxiv-id": "1304.2110v1", 
    "author": "M. M. A. Hashem", 
    "publish": "2013-04-08T06:22:59Z", 
    "summary": "In this paper, an improved GEF fast addition algorithm is proposed. The\nproposed algorithm reduces time and memory space. In this algorithm, carry is\ncalculated on the basis of arrival timing of the operand's bits without\noverhead of sorting. Intermediate terms are generated from the most significant\nbit and the carry is generated from the least significant bit using the\nfunctions of efficient operators. This algorithm shows better performance for\nuse in the fastest computational devices of the near future."
},{
    "category": "cs.CR", 
    "doi": "10.5121/ijcis.2013.3102", 
    "link": "http://arxiv.org/pdf/1304.6672v1", 
    "title": "Hardware Implementation of Algorithm for Cryptanalysis", 
    "arxiv-id": "1304.6672v1", 
    "author": "Rakesh Mehta", 
    "publish": "2013-04-11T11:57:33Z", 
    "summary": "Cryptanalysis of block ciphers involves massive computations which are\nindependent of each other and can be instantiated simultaneously so that the\nsolution space is explored at a faster rate. With the advent of low cost Field\nProgrammable Gate Arrays, building special purpose hardware for computationally\nintensive applications has now become possible. For this the Data Encryption\nStandard is used as a proof of concept. This paper presents the design for\nHardware implementation of DES cryptanalysis on FPGA using exhaustive key\nsearch. Two architectures viz. Rolled and Unrolled DES architecture are\ncompared and based on experimental result the Rolled architecture is\nimplemented on FPGA. The aim of this work is to make cryptanalysis faster and\nbetter."
},{
    "category": "cs.AR", 
    "doi": "10.4204/EPTCS.114.9", 
    "link": "http://arxiv.org/pdf/1304.7862v1", 
    "title": "A formalisation of XMAS", 
    "arxiv-id": "1304.7862v1", 
    "author": "Julien Schmaltz", 
    "publish": "2013-04-30T04:14:53Z", 
    "summary": "Communication fabrics play a key role in the correctness and performance of\nmodern multi-core processors and systems-on-chip. To enable formal\nverification, a recent trend is to use high-level micro-architectural models to\ncapture designers' intent about the communication and processing of messages.\nIntel proposed the xMAS language to support the formal definition of executable\nspecifications of micro-architectures. We formalise the semantics of xMAS in\nACL2. Our formalisation represents the computation of the values of all wires\nof a design. Our main function computes a set of possible routing targets for\neach message and whether a message can make progress according to the current\nnetwork state. We prove several properties on the semantics, including\ntermination, non-emptiness of routing, and correctness of progress conditions.\nOur current effort focuses on a basic subset of the entire xMAS language, which\nincludes queues, functions, and switches."
},{
    "category": "cs.CR", 
    "doi": "10.4204/EPTCS.114.9", 
    "link": "http://arxiv.org/pdf/1306.1916v1", 
    "title": "Performance Evaluation of Low Power MIPS Crypto Processor based on   Cryptography Algorithms", 
    "arxiv-id": "1306.1916v1", 
    "author": "Dilip Kumar", 
    "publish": "2013-06-08T13:18:48Z", 
    "summary": "This paper presents the design and implementation of low power 32-bit\nencrypted and decrypted MIPS processor for Data Encryption Standard (DES),\nTriple DES, Advanced Encryption Standard (AES) based on MIPS pipeline\narchitecture. The organization of pipeline stages has been done in such a way\nthat pipeline can be clocked at high frequency. Encryption and Decryption\nblocks of three standard cryptography algorithms on MIPS processor and\ndependency among themselves are explained in detail with the help of a block\ndiagram. Clock gating technique is used to reduce the power consumption in MIPS\ncrypto processor. This approach results in processor that meets power\nconsumption and performance specification for security applications. Proposed\nImplementation approach concludes higher system performance while reducing\noperating power consumption. Testing results shows that the MIPS crypto\nprocessor operates successfully at a working frequency of 218MHz and a\nbandwidth of 664Mbits/s."
},{
    "category": "cs.AR", 
    "doi": "10.4204/EPTCS.114.9", 
    "link": "http://arxiv.org/pdf/1306.3302v1", 
    "title": "The Effect of Communication and Synchronization on Amdahl Law in   Multicore Systems", 
    "arxiv-id": "1306.3302v1", 
    "author": "Ran Ginosar", 
    "publish": "2013-06-14T06:20:44Z", 
    "summary": "This work analyses the effects of sequential-to-parallel synchronization and\ninter-core communication on multicore performance, speedup and scaling. A\nmodification of Amdahl law is formulated, to reflect the finding that parallel\nspeedup is lower than originally predicted, due to these effects. In\napplications with high inter-core communication requirements, the workload\nshould be executed on a small number of cores, and applications of high\nsequential-to-parallel synchronization requirements may better be executed by\nthe sequential core, even when f, the Amdahl fraction of parallelization, is\nvery close to 1. To improve the scalability and performance speedup of a\nmulticore, it is as important to address the synchronization and connectivity\nintensities of parallel algorithms as their parallelization factor."
},{
    "category": "cs.DC", 
    "doi": "10.4204/EPTCS.114.9", 
    "link": "http://arxiv.org/pdf/1307.0100v1", 
    "title": "Marrying Many-core Accelerators and InfiniBand for a New Commodity   Processor", 
    "arxiv-id": "1307.0100v1", 
    "author": "Yuichi Tsujita", 
    "publish": "2013-06-29T13:07:10Z", 
    "summary": "During the last 15 years, the supercomputing industry has been using\nmass-produced, off-the-shelf components to build cluster computers. Such\ncomponents are not perfect for HPC purposes, but are cheap due to effect of\nscale in their production. The coming exa-scale era changes the landscape:\nexa-scale computers will contain components in quantities large enough to\njustify their custom development and production.\n  We propose a new heterogeneous processor, equipped with a network controller\nand designed specifically for HPC. We then show how it can be used for\nenterprise computing market, guaranteeing its widespread adoption and therefore\nlow production costs."
},{
    "category": "cs.AR", 
    "doi": "10.4204/EPTCS.114.9", 
    "link": "http://arxiv.org/pdf/1307.3690v1", 
    "title": "Design of Parity Preserving Logic Based Fault Tolerant Reversible   Arithmetic Logic Unit", 
    "arxiv-id": "1307.3690v1", 
    "author": "M. K. Venkatesha", 
    "publish": "2013-07-14T03:31:10Z", 
    "summary": "Reversible Logic is gaining significant consideration as the potential logic\ndesign style for implementation in modern nanotechnology and quantum computing\nwith minimal impact on physical entropy .Fault Tolerant reversible logic is one\nclass of reversible logic that maintain the parity of the input and the\noutputs. Significant contributions have been made in the literature towards the\ndesign of fault tolerant reversible logic gate structures and arithmetic units,\nhowever, there are not many efforts directed towards the design of fault\ntolerant reversible ALUs. Arithmetic Logic Unit (ALU) is the prime performing\nunit in any computing device and it has to be made fault tolerant. In this\npaper we aim to design one such fault tolerant reversible ALU that is\nconstructed using parity preserving reversible logic gates. The designed ALU\ncan generate up to seven Arithmetic operations and four logical operations."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2013.3303", 
    "link": "http://arxiv.org/pdf/1312.2306v1", 
    "title": "Dominant block guided optimal cache size estimation to maximize IPC of   embedded software", 
    "arxiv-id": "1312.2306v1", 
    "author": "Arvind Rajawat", 
    "publish": "2013-12-09T05:17:45Z", 
    "summary": "Embedded system software is highly constrained from performance, memory\nfootprint, energy consumption and implementing cost view point. It is always\ndesirable to obtain better Instructions per Cycle. Instruction cache has major\ncontribution in improving IPC. Cache memories are realized on the same chip\nwhere the processor is running. This considerably increases the system cost as\nwell. Hence, it is required to maintain a trade off between cache sizes and\nperformance improvement offered. Determining the number of cache lines and size\nof cache line are important parameters for cache designing. The design space\nfor cache is quite large. It is time taking to execute the given application\nwith different cache sizes on an instruction set simulator to figure out the\noptimal cache size. In this paper, a technique is proposed to identify a number\nof cache lines and cache line size for the L1 instruction cache that will offer\nbest or nearly best IPC. Cache size is derived, at a higher abstraction level,\nfrom basic block analysis in the Low Level Virtual Machine environment. The\ncache size estimated is cross validated by simulating the set of benchmark\napplications with different cache sizes in simple scalar simulator. The\nproposed method seems to be superior in terms of estimation accuracy and\nestimation time as compared to the existing methods for estimation of optimal\ncache size parameters like cache line size, number of cache lines."
},{
    "category": "cs.ET", 
    "doi": "10.5120/8967-3182", 
    "link": "http://arxiv.org/pdf/1312.7354v1", 
    "title": "Design of Reversible Random Access Memory", 
    "arxiv-id": "1312.7354v1", 
    "author": "Syed Monowar Hossain", 
    "publish": "2013-12-22T15:13:12Z", 
    "summary": "Reversible logic has become immensely popular research area and its\napplications have spread in various technologies for their low power\nconsumption. In this paper we proposed an efficient design of random access\nmemory using reversible logic. In the way of designing the reversible random\naccess memory we proposed a reversible decoder and a write enable reversible\nmaster slave D flip-flop. All the reversible designs are superior in terms of\nquantum cost, delay and garbage outputs compared to the designs existing in\nliterature."
},{
    "category": "cs.ET", 
    "doi": "10.5120/8967-3182", 
    "link": "http://arxiv.org/pdf/1312.7355v1", 
    "title": "A Novel Approach for Designing Online Testable Reversible Circuits", 
    "arxiv-id": "1312.7355v1", 
    "author": "Uzzal Kumar Prodhan", 
    "publish": "2013-12-22T15:59:43Z", 
    "summary": "Reversible logic is gaining interest of many researchers due to its low power\ndissipating characteristic. In this paper we proposed a new approach for\ndesigning online testable reversible circuits. The resultant testable\nreversible circuit can detect any single bit error whiles it is operating.\nAppropriate theorems and lemmas are presented to clarify the proposed design.\nThe experimental results show that our design approach is superior in terms of\nnumber of number of gates, garbage outputs and quantum cost."
},{
    "category": "cs.AR", 
    "doi": "10.5120/8967-3182", 
    "link": "http://arxiv.org/pdf/1401.3421v1", 
    "title": "Performance Evaluation of ECC in Single and Multi Processor   Architectures on FPGA Based Embedded System", 
    "arxiv-id": "1401.3421v1", 
    "author": "Amlan Chakrabarti", 
    "publish": "2014-01-15T03:25:41Z", 
    "summary": "Cryptographic algorithms are computationally costly and the challenge is more\nif we need to execute them in resource constrained embedded systems. Field\nProgrammable Gate Arrays (FPGAs) having programmable logic de- vices and\nprocessing cores, have proven to be highly feasible implementation platforms\nfor embedded systems providing lesser design time and reconfig- urability.\nDesign parameters like throughput, resource utilization and power requirements\nare the key issues. The popular Elliptic Curve Cryptography (ECC), which is\nsuperior over other public-key crypto-systems like RSA in many ways, such as\nproviding greater security for a smaller key size, is cho- sen in this work and\nthe possibilities of its implementation in FPGA based embedded systems for both\nsingle and dual processor core architectures in- volving task parallelization\nhave been explored. This exploration, which is first of its kind considering\nthe other existing works, is a needed activity for evaluating the best possible\narchitectural environment for ECC implementa- tion on FPGA (Virtex4 XC4VFX12,\nFF668, -10) based embedded platform."
},{
    "category": "cs.AR", 
    "doi": "10.7321/jscse.v2.n7.3", 
    "link": "http://arxiv.org/pdf/1401.6375v1", 
    "title": "Design of an Encryption-Decryption Module Oriented for Internet   Information Security SOC Design", 
    "arxiv-id": "1401.6375v1", 
    "author": "Tao Feng", 
    "publish": "2014-01-24T15:29:06Z", 
    "summary": "In order to protect the security of network data, a high speed chip module\nfor encrypting and decrypting of network data packet is designed. The chip\nmodule is oriented for internet information security SOC (System on Chip)\ndesign. During the design process, AES (Advanced Encryption Standard) and 3DES\n(Data Encryption Standard) encryption algorithm are adopted to protect the\nsecurity of network data. The following points are focused: (1) The SOC (System\non Chip) design methodology based on IP (Intellectual Property) core is used.\nAES (Advanced Encryption Standard) and 3DES (Data Encryption Standard) IP\n(Intellectual Property) cores are embedded in the chip module, peripheral\ncontrol sub-modules are designed to control the encryption-decryption module,\nwhich is capable of shortening the design period of the chip module. (2) The\nimplementation of encryption-decryption with hardware was presented, which\nimproves the safety of data through the encryption-decryption chip and reduce\nthe load of CPU. (3) In our hardware solution, two AES (Advanced Encryption\nStandard) cores are used to work in parallel, which improves the speed of the\nencryption module. Moreover, the key length of AES (Advanced Encryption\nStandard) encryption algorithm is designed with three optional configurations\nat 128 bits, 256 bits and 192 bits respectively and six optional encryption\nalgorithm modes: CBC (Cipher Block Chaining) mode, ECB (Electronic Code Book)\nmode, GCM (Galois/Counter Mode) mode, XTS(cipherteXT Stealing) mode, CTR\n(CounTeR) mode and 3DES respectively, which adds the flexibility to its\napplications."
},{
    "category": "cs.AR", 
    "doi": "10.7321/jscse.v2.n7.3", 
    "link": "http://arxiv.org/pdf/1405.2907v1", 
    "title": "Massively Parallel Processor Architectures for Resource-aware Computing", 
    "arxiv-id": "1405.2907v1", 
    "author": "J\u00fcrgen Teich", 
    "publish": "2014-05-12T16:39:44Z", 
    "summary": "We present a class of massively parallel processor architectures called\ninvasive tightly coupled processor arrays (TCPAs). The presented processor\nclass is a highly parameterizable template, which can be tailored before\nruntime to fulfill costumers' requirements such as performance, area cost, and\nenergy efficiency. These programmable accelerators are well suited for\ndomain-specific computing from the areas of signal, image, and video processing\nas well as other streaming processing applications. To overcome future scaling\nissues (e.g., power consumption, reliability, resource management, as well as\napplication parallelization and mapping), TCPAs are inherently designed in a\nway to support self-adaptivity and resource awareness at hardware level. Here,\nwe follow a recently introduced resource-aware parallel computing paradigm\ncalled invasive computing where an application can dynamically claim, execute,\nand release resources. Furthermore, we show how invasive computing can be used\nas an enabler for power management. Finally, we will introduce ideas on how to\nrealize fault-tolerant loop execution on such massively parallel architectures\nthrough employing on-demand spatial redundancies at the processor array level."
},{
    "category": "cs.SE", 
    "doi": "10.4204/EPTCS.156.7", 
    "link": "http://arxiv.org/pdf/1407.6342v1", 
    "title": "RTL2RTL Formal Equivalence: Boosting the Design Confidence", 
    "arxiv-id": "1407.6342v1", 
    "author": "S S Bindumadhava", 
    "publish": "2014-07-15T06:40:49Z", 
    "summary": "Increasing design complexity driven by feature and performance requirements\nand the Time to Market (TTM) constraints force a faster design and validation\nclosure. This in turn enforces novel ways of identifying and debugging\nbehavioral inconsistencies early in the design cycle. Addition of incremental\nfeatures and timing fixes may alter the legacy design behavior and would\ninadvertently result in undesirable bugs. The most common method of verifying\nthe correctness of the changed design is to run a dynamic regression test suite\nbefore and after the intended changes and compare the results, a method which\nis not exhaustive. Modern Formal Verification (FV) techniques involving new\nmethods of proving Sequential Hardware Equivalence enabled a new set of\nsolutions for the given problem, with complete coverage guarantee. Formal\nEquivalence can be applied for proving functional integrity after design\nchanges resulting from a wide variety of reasons, ranging from simple pipeline\noptimizations to complex logic redistributions. We present here our experience\nof successfully applying the RTL to RTL (RTL2RTL) Formal Verification across a\nwide spectrum of problems on a Graphics design. The RTL2RTL FV enabled checking\nthe design sanity in a very short time, thus enabling faster and safer design\nchurn. The techniques presented in this paper are applicable to any complex\nhardware design."
},{
    "category": "cs.DC", 
    "doi": "10.1016/j.simpat.2014.06.007", 
    "link": "http://arxiv.org/pdf/1407.6470v1", 
    "title": "New Trends in Parallel and Distributed Simulation: from Many-Cores to   Cloud Computing", 
    "arxiv-id": "1407.6470v1", 
    "author": "Moreno Marzolla", 
    "publish": "2014-07-24T07:05:38Z", 
    "summary": "Recent advances in computing architectures and networking are bringing\nparallel computing systems to the masses so increasing the number of potential\nusers of these kinds of systems. In particular, two important technological\nevolutions are happening at the ends of the computing spectrum: at the \"small\"\nscale, processors now include an increasing number of independent execution\nunits (cores), at the point that a mere CPU can be considered a parallel\nshared-memory computer; at the \"large\" scale, the Cloud Computing paradigm\nallows applications to scale by offering resources from a large pool on a\npay-as-you-go model. Multi-core processors and Clouds both require applications\nto be suitably modified to take advantage of the features they provide. In this\npaper, we analyze the state of the art of parallel and distributed simulation\ntechniques, and assess their applicability to multi-core architectures or\nClouds. It turns out that most of the current approaches exhibit limitations in\nterms of usability and adaptivity which may hinder their application to these\nnew computing architectures. We propose an adaptive simulation mechanism, based\non the multi-agent system paradigm, to partially address some of those\nlimitations. While it is unlikely that a single approach will work well on both\nsettings above, we argue that the proposed adaptive mechanism has useful\nfeatures which make it attractive both in a multi-core processor and in a Cloud\nsystem. These features include the ability to reduce communication costs by\nmigrating simulation components, and the support for adding (or removing) nodes\nto the execution architecture at runtime. We will also show that, with the help\nof an additional support layer, parallel and distributed simulations can be\nexecuted on top of unreliable resources."
},{
    "category": "cs.ET", 
    "doi": "10.1109/TVLSI.2014.2371857", 
    "link": "http://arxiv.org/pdf/1411.5255v1", 
    "title": "Threshold Logic Computing: Memristive-CMOS Circuits for Fast Fourier   Transform and Vedic Multiplication", 
    "arxiv-id": "1411.5255v1", 
    "author": "Arun Ajayan", 
    "publish": "2014-11-19T15:36:23Z", 
    "summary": "Brain inspired circuits can provide an alternative solution to implement\ncomputing architectures taking advantage of fault tolerance and generalisation\nability of logic gates. In this brief, we advance over the memristive threshold\ncircuit configuration consisting of memristive averaging circuit in combination\nwith operational amplifier and/or CMOS inverters in application to realizing\ncomplex computing circuits. The developed memristive threshold logic gates are\nused for designing FFT and multiplication circuits useful for modern\nmicroprocessors. Overall, the proposed threshold logic outperforms previous\nmemristive-CMOS logic cells on every aspect, however, indicate a lower chip\narea, lower THD, and controllable leakage power, but a higher power dissipation\nwith respect to CMOS logic."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TVLSI.2014.2371857", 
    "link": "http://arxiv.org/pdf/1412.5538v1", 
    "title": "Kickstarting High-performance Energy-efficient Manycore Architectures   with Epiphany", 
    "arxiv-id": "1412.5538v1", 
    "author": "Zain Ul-Abdin", 
    "publish": "2014-12-17T19:39:56Z", 
    "summary": "In this paper we introduce Epiphany as a high-performance energy-efficient\nmanycore architecture suitable for real-time embedded systems. This scalable\narchitecture supports floating point operations in hardware and achieves 50\nGFLOPS/W in 28 nm technology, making it suitable for high performance streaming\napplications like radio base stations and radar signal processing. Through an\nefficient 2D mesh Network-on-Chip and a distributed shared memory model, the\narchitecture is scalable to thousands of cores on a single chip. An\nEpiphany-based open source computer named Parallella was launched in 2012\nthrough Kickstarter crowd funding and has now shipped to thousands of customers\naround the world."
},{
    "category": "cs.CR", 
    "doi": "10.1109/TVLSI.2014.2371857", 
    "link": "http://arxiv.org/pdf/1412.6067v1", 
    "title": "Very Low Cost Entropy Source Based on Chaotic Dynamics Retrofittable on   Networked Devices to Prevent RNG Attacks", 
    "arxiv-id": "1412.6067v1", 
    "author": "Sergio Callegari", 
    "publish": "2014-12-17T16:40:03Z", 
    "summary": "Good quality entropy sources are indispensable in most modern cryptographic\nprotocols. Unfortunately, many currently deployed networked devices do not\ninclude them and may be vulnerable to Random Number Generator (RNG) attacks.\nSince most of these systems allow firmware upgrades and have serial\ncommunication facilities, the potential for retrofitting them with secure\nhardware-based entropy sources exists. To this aim, very low-cost, robust, easy\nto deploy solutions are required. Here, a retrofittable, sub 10$ entropy source\nbased on chaotic dynamics is illustrated, capable of a 32 kbit/s rate or more\nand offering multiple serial communication options including USB, I2C, SPI or\nUSART. Operation is based on a loop built around the Analog to Digital\nConverter (ADC) hosted on a standard microcontroller."
},{
    "category": "physics.space-ph", 
    "doi": "10.1109/TNS.2014.2369424", 
    "link": "http://arxiv.org/pdf/1502.03057v1", 
    "title": "Circuit Level Modeling of Extra Combinational Delays in SRAM FPGAs Due   to Transient Ionizing Radiation", 
    "arxiv-id": "1502.03057v1", 
    "author": "Claude Thibeault", 
    "publish": "2015-02-05T01:53:17Z", 
    "summary": "This paper presents a novel circuit level model that explains and confirms\nthe extra combinational delays in a SRAM-FPGA (Virtex-5) due to radiation,\nwhich matches the experimental results by proton irradiation at TRIUMF."
},{
    "category": "cs.NE", 
    "doi": "10.1109/ISCAS.2014.6865519", 
    "link": "http://arxiv.org/pdf/1503.00504v1", 
    "title": "FPGA Implementation of the CAR Model of the Cochlea", 
    "arxiv-id": "1503.00504v1", 
    "author": "Andr\u00e9 van Schaik", 
    "publish": "2015-03-02T12:55:12Z", 
    "summary": "The front end of the human auditory system, the cochlea, converts sound\nsignals from the outside world into neural impulses transmitted along the\nauditory pathway for further processing. The cochlea senses and separates sound\nin a nonlinear active fashion, exhibiting remarkable sensitivity and frequency\ndiscrimination. Although several electronic models of the cochlea have been\nproposed and implemented, none of these are able to reproduce all the\ncharacteristics of the cochlea, including large dynamic range, large gain and\nsharp tuning at low sound levels, and low gain and broad tuning at intense\nsound levels. Here, we implement the Cascade of Asymmetric Resonators (CAR)\nmodel of the cochlea on an FPGA. CAR represents the basilar membrane filter in\nthe Cascade of Asymmetric Resonators with Fast-Acting Compression (CAR-FAC)\ncochlear model. CAR-FAC is a neuromorphic model of hearing based on a pole-zero\nfilter cascade model of auditory filtering. It uses simple nonlinear extensions\nof conventional digital filter stages that are well suited to FPGA\nimplementations, so that we are able to implement up to 1224 cochlear sections\non Virtex-6 FPGA to process sound data in real time. The FPGA implementation of\nthe electronic cochlea described here may be used as a front-end sound analyser\nfor various machine-hearing applications."
},{
    "category": "cs.CR", 
    "doi": "10.1109/ISCAS.2014.6865519", 
    "link": "http://arxiv.org/pdf/1503.02304v1", 
    "title": "Efficient Hardware Design and Implementation of Encrypted MIPS Processor", 
    "arxiv-id": "1503.02304v1", 
    "author": "Dilip Kumar", 
    "publish": "2015-03-08T18:06:37Z", 
    "summary": "The paper describes the design and hardware implementation of 32-bit\nencrypted MIPS processor based on MIPS pipeline architecture. The organization\nof pipeline stages in such a way that pipeline can be clocked at high\nfrequency. Encryption and Decryption blocks of data encryption standard (DES)\ncryptosystem and dependency among themselves are explained in detail with the\nhelp of block diagram. In order to increase the processor functionality and\nperformance, especially for security applications we include three new\ninstructions 32-bit LKLW, LKUW and CRYPT. The design has been synthesized at\n40nm process technology targeting using Xilinx Virtex-6 device. The encrypted\nMIPS pipeline processor can work at 218MHz at synthesis level and 744MHz at\nsimulation level."
},{
    "category": "cs.DC", 
    "doi": "10.1109/ISCAS.2014.6865519", 
    "link": "http://arxiv.org/pdf/1503.08104v1", 
    "title": "Evaluating Asymmetric Multicore Systems-on-Chip using Iso-Metrics", 
    "arxiv-id": "1503.08104v1", 
    "author": "Enrique S. Quintana-Orti", 
    "publish": "2015-03-27T15:10:43Z", 
    "summary": "The end of Dennard scaling has pushed power consumption into a first order\nconcern for current systems, on par with performance. As a result,\nnear-threshold voltage computing (NTVC) has been proposed as a potential means\nto tackle the limited cooling capacity of CMOS technology. Hardware operating\nin NTV consumes significantly less power, at the cost of lower frequency, and\nthus reduced performance, as well as increased error rates. In this paper, we\ninvestigate if a low-power systems-on-chip, consisting of ARM's asymmetric\nbig.LITTLE technology, can be an alternative to conventional high performance\nmulticore processors in terms of power/energy in an unreliable scenario. For\nour study, we use the Conjugate Gradient solver, an algorithm representative of\nthe computations performed by a large range of scientific and engineering\ncodes."
},{
    "category": "cs.ET", 
    "doi": "10.1109/ISCAS.2014.6865519", 
    "link": "http://arxiv.org/pdf/1504.00450v1", 
    "title": "Recent Development in Analog Computation - A Brief Overview", 
    "arxiv-id": "1504.00450v1", 
    "author": "Yang Xue", 
    "publish": "2015-04-02T06:29:09Z", 
    "summary": "The recent development in analog computation is reviewed in this paper.\nAnalog computation was used in many applications where power and energy\nefficiency is of paramount importance. It is shown that by using innovative\narchitecture and circuit design, analog computation systems can achieve much\nhigher energy efficiency than their digital counterparts, as they are able to\nexploit the computational power inherent to the devices and physics. However,\nthese systems do suffer from some disadvantages, such as lower accuracy and\nspeed, and designers have come up with novel approaches to overcome them. The\npaper provides an overview of analog computation systems, from basic components\nsuch as memory and arithmetic elements, to architecture and system design."
},{
    "category": "q-bio.QM", 
    "doi": "10.1007/978-3-319-16214-0_29", 
    "link": "http://arxiv.org/pdf/1504.01718v1", 
    "title": "Modular Acquisition and Stimulation System for Timestamp-Driven   Neuroscience Experiments", 
    "arxiv-id": "1504.01718v1", 
    "author": "Jan Frans Willem Slaets", 
    "publish": "2015-04-07T19:46:04Z", 
    "summary": "Dedicated systems are fundamental for neuroscience experimental protocols\nthat require timing determinism and synchronous stimuli generation. We\ndeveloped a data acquisition and stimuli generator system for neuroscience\nresearch, optimized for recording timestamps from up to 6 spiking neurons and\nentirely specified in a high-level Hardware Description Language (HDL). Despite\nthe logic complexity penalty of synthesizing from such a language, it was\npossible to implement our design in a low-cost small reconfigurable device.\nUnder a modular framework, we explored two different memory arbitration schemes\nfor our system, evaluating both their logic element usage and resilience to\ninput activity bursts. One of them was designed with a decoupled and latency\ninsensitive approach, allowing for easier code reuse, while the other adopted a\ncentralized scheme, constructed specifically for our application. The usage of\na high-level HDL allowed straightforward and stepwise code modifications to\ntransform one architecture into the other. The achieved modularity is very\nuseful for rapidly prototyping novel electronic instrumentation systems\ntailored to scientific research."
},{
    "category": "cs.DC", 
    "doi": "10.1038/ncomms9941", 
    "link": "http://arxiv.org/pdf/1505.01139v1", 
    "title": "An event-based architecture for solving constraint satisfaction problems", 
    "arxiv-id": "1505.01139v1", 
    "author": "Giacomo Indiveri", 
    "publish": "2015-05-04T13:23:48Z", 
    "summary": "Constraint satisfaction problems (CSPs) are typically solved using\nconventional von Neumann computing architectures. However, these architectures\ndo not reflect the distributed nature of many of these problems and are thus\nill-suited to solving them. In this paper we present a hybrid analog/digital\nhardware architecture specifically designed to solve such problems. We cast\nCSPs as networks of stereotyped multi-stable oscillatory elements that\ncommunicate using digital pulses, or events. The oscillatory elements are\nimplemented using analog non-stochastic circuits. The non-repeating phase\nrelations among the oscillatory elements drive the exploration of the solution\nspace. We show that this hardware architecture can yield state-of-the-art\nperformance on a number of CSPs under reasonable assumptions on the\nimplementation. We present measurements from a prototype electronic chip to\ndemonstrate that a physical implementation of the proposed architecture is\nrobust to practical non-idealities and to validate the theory proposed."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TCAD.2015.2474373", 
    "link": "http://arxiv.org/pdf/1505.02211v2", 
    "title": "TPAD: Hardware Trojan Prevention and Detection for Trusted Integrated   Circuits", 
    "arxiv-id": "1505.02211v2", 
    "author": "Subhasish Mitra", 
    "publish": "2015-05-09T00:11:31Z", 
    "summary": "There are increasing concerns about possible malicious modifications of\nintegrated circuits (ICs) used in critical applications. Such attacks are often\nreferred to as hardware Trojans. While many techniques focus on hardware Trojan\ndetection during IC testing, it is still possible for attacks to go undetected.\nUsing a combination of new design techniques and new memory technologies, we\npresent a new approach that detects a wide variety of hardware Trojans during\nIC testing and also during system operation in the field. Our approach can also\nprevent a wide variety of attacks during synthesis, place-and-route, and\nfabrication of ICs. It can be applied to any digital system, and can be tuned\nfor both traditional and split-manufacturing methods. We demonstrate its\napplicability for both ASICs and FPGAs. Using fabricated test chips with Trojan\nemulation capabilities and also using simulations, we demonstrate: 1. The area\nand power costs of our approach can range between 7.4-165% and 0.07-60%,\nrespectively, depending on the design and the attacks targeted; 2. The speed\nimpact can be minimal (close to 0%); 3. Our approach can detect 99.998% of\nTrojans (emulated using test chips) that do not require detailed knowledge of\nthe design being attacked; 4. Our approach can prevent 99.98% of specific\nattacks (simulated) that utilize detailed knowledge of the design being\nattacked (e.g., through reverse-engineering). 5. Our approach never produces\nany false positives, i.e., it does not report attacks when the IC operates\ncorrectly."
},{
    "category": "cs.SD", 
    "doi": "10.1109/TCAD.2015.2474373", 
    "link": "http://arxiv.org/pdf/1508.06056v1", 
    "title": "A Novel Reconfigurable Hardware Design for Speech Enhancement Based on   Multi-Band Spectral Subtraction Involving Magnitude and Phase Components", 
    "arxiv-id": "1508.06056v1", 
    "author": "Amlan Chakrabarti", 
    "publish": "2015-08-25T08:02:38Z", 
    "summary": "This paper proposes an efficient reconfigurable hardware design for speech\nenhancement based on multi band spectral subtraction algorithm and involving\nboth magnitude and phase components. Our proposed design is novel as it\nestimates environmental noise from speech adaptively utilizing both magnitude\nand phase components of the speech spectrum. We performed multi-band spectrum\nsubtraction by dividing the noisy speech spectrum into different non-uniform\nfrequency bands having varying signal to noise ratio (SNR) and subtracting the\nestimated noise from each of these frequency bands. This results to the\nelimination of noise from both high SNR and low SNR signal components for all\nthe frequency bands. We have coined our proposed speech enhancement technique\nas Multi Band Magnitude Phase Spectral Subtraction (MBMPSS). The magnitude and\nphase operations are executed concurrently exploiting the parallel logic blocks\nof Field Programmable Gate Array (FPGA), thus increasing the throughput of the\nsystem to a great extent. We have implemented our design on Spartan6 Lx45 FPGA\nand presented the implementation result in terms of resource utilization and\ndelay information for the different blocks of our design. To the best of our\nbest knowledge, this is a new type of hardware design for speech enhancement\napplication and also a first of its kind implementation on reconfigurable\nhardware. We have used benchmark audio data for the evaluation of the proposed\nhardware and the experimental results show that our hardware shows a better SNR\nvalue compared to the existing state of the art research works."
},{
    "category": "cs.SE", 
    "doi": "10.1109/TCAD.2015.2474373", 
    "link": "http://arxiv.org/pdf/1508.06805v1", 
    "title": "Allowing Software Developers to Debug HLS Hardware", 
    "arxiv-id": "1508.06805v1", 
    "author": "Steven J. E. Wilton", 
    "publish": "2015-08-27T11:22:04Z", 
    "summary": "High-Level Synthesis (HLS) is emerging as a mainstream design methodology,\nallowing software designers to enjoy the benefits of a hardware implementation.\nSignificant work has led to effective compilers that produce high-quality\nhardware designs from software specifications. However, in order to fully\nbenefit from the promise of HLS, a complete ecosystem that provides the ability\nto analyze, debug, and optimize designs is essential. This ecosystem has to be\naccessible to software designers. This is challenging, since software\ndevelopers view their designs very differently than how they are physically\nimplemented on-chip. Rather than individual sequential lines of code, the\nimplementation consists of gates operating in parallel across multiple clock\ncycles. In this paper, we report on our efforts to create an ecosystem that\nallows software designers to debug HLS-generated circuits in a familiar manner.\nWe have implemented our ideas in a debug framework that will be included in the\nnext release of the popular LegUp high-level synthesis tool."
},{
    "category": "cs.DC", 
    "doi": "10.1109/TCAD.2015.2474373", 
    "link": "http://arxiv.org/pdf/1508.06821v1", 
    "title": "ThreadPoolComposer - An Open-Source FPGA Toolchain for Software   Developers", 
    "arxiv-id": "1508.06821v1", 
    "author": "Andreas Koch", 
    "publish": "2015-08-27T12:03:57Z", 
    "summary": "This extended abstract presents ThreadPoolComposer, a high-level\nsynthesis-based development framework and meta-toolchain that provides a\nuniform programming interface for FPGAs portable across multiple platforms."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TCAD.2015.2474373", 
    "link": "http://arxiv.org/pdf/1508.07126v1", 
    "title": "Performance monitoring for multicore embedded computing systems on FPGAs", 
    "arxiv-id": "1508.07126v1", 
    "author": "Alexandra Fedorova", 
    "publish": "2015-08-28T08:41:38Z", 
    "summary": "When designing modern embedded computing systems, most software programmers\nchoose to use multicore processors, possibly in combination with\ngeneral-purpose graphics processing units (GPGPUs) and/or hardware\naccelerators. They also often use an embedded Linux O/S and run\nmulti-application workloads that may even be multi-threaded. Modern FPGAs are\nlarge enough to combine multicore hard/soft processors with multiple hardware\naccelerators as custom compute units, enabling entire embedded compute systems\nto be implemented on a single FPGA. Furthermore, the large FPGA vendors also\nsupport embedded Linux kernels for both their soft and embedded processors.\nWhen combined with high-level synthesis to generate hardware accelerators using\na C-to-gates flows, the necessary primitives for a framework that can enable\nsoftware designers to use FPGAs as their custom compute platform now exist.\nHowever, in order to ensure that computing resources are integrated and shared\neffectively, software developers need to be able to monitor and debug the\nruntime performance of the applications in their workload. This paper describes\nABACUS, a performance-monitoring framework that can be used to debug the\nexecution behaviours and interactions of multi-application workloads on\nmulticore systems. We also discuss how this framework is extensible for use\nwith hardware accelerators in heterogeneous systems."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TCAD.2015.2474373", 
    "link": "http://arxiv.org/pdf/1508.07127v1", 
    "title": "Virtualization Architecture for NoC-based Reconfigurable Systems", 
    "arxiv-id": "1508.07127v1", 
    "author": "Pao-Ann Hsiung", 
    "publish": "2015-08-28T08:45:35Z", 
    "summary": "We propose a virtualization architecture for NoC-based reconfigurable\nsystems. The motivation of this work is to develop a service-oriented\narchitecture that includes Partial Reconfigurable Region as a Service (PRRaaS)\nand Processing Element as a Service (PEaaS) for software applications.\nAccording to the requirements of software applications, new PEs can be created\non-demand by (re)configuring the logic resource of the PRRs in the FPGA, while\nthe configured PEs can also be virtualized to support multiple application\ntasks at the same time. As a result, such a two-level virtualization mechanism,\nincluding the gate-level virtualization and the PE-level virtualization,\nenables an SoC to be dynamically adapted to changing application requirements.\nTherefore, more software applications can be performed, and system performance\ncan be further enhanced."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TCAD.2015.2474373", 
    "link": "http://arxiv.org/pdf/1509.00042v1", 
    "title": "Automatic Nested Loop Acceleration on FPGAs Using Soft CGRA Overlay", 
    "arxiv-id": "1509.00042v1", 
    "author": "Hayden Kwok-Hay So", 
    "publish": "2015-08-27T11:50:30Z", 
    "summary": "Offloading compute intensive nested loops to execute on FPGA accelerators\nhave been demonstrated by numerous researchers as an effective performance\nenhancement technique across numerous application domains. To construct such\naccelerators with high design productivity, researchers have increasingly\nturned to the use of overlay architectures as an intermediate generation target\nbuilt on top of off-the-shelf FPGAs. However, achieving the desired\nperformance-overhead trade-off remains a major productivity challenge as\ncomplex application-specific customizations over a large design space covering\nmultiple architectural parameters are needed.\n  In this work, an automatic nested loop acceleration framework utilizing a\nregular soft coarse-grained reconfigurable array (SCGRA) overlay is presented.\nGiven high-level resource constraints, the framework automatically customizes\nthe overlay architectural design parameters, high-level compilation options as\nwell as communication between the accelerator and the host processor for\noptimized performance specifically to the given application. In our\nexperiments, at a cost of 10 to 20 minutes additional tools run time, the\nproposed customization process resulted in up to 5 times additional speedup\nover a baseline accelerator generated by the same framework without\ncustomization. Overall, when compared to the equivalent software running on the\nhost ARM processor alone on the Zedboard, the resulting accelerators achieved\nup to 10 times speedup."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TCAD.2015.2474373", 
    "link": "http://arxiv.org/pdf/1509.02308v2", 
    "title": "Dissecting GPU Memory Hierarchy through Microbenchmarking", 
    "arxiv-id": "1509.02308v2", 
    "author": "Xiaowen Chu", 
    "publish": "2015-09-08T10:13:02Z", 
    "summary": "Memory access efficiency is a key factor in fully utilizing the computational\npower of graphics processing units (GPUs). However, many details of the GPU\nmemory hierarchy are not released by GPU vendors. In this paper, we propose a\nnovel fine-grained microbenchmarking approach and apply it to three generations\nof NVIDIA GPUs, namely Fermi, Kepler and Maxwell, to expose the previously\nunknown characteristics of their memory hierarchies. Specifically, we\ninvestigate the structures of different GPU cache systems, such as the data\ncache, the texture cache and the translation look-aside buffer (TLB). We also\ninvestigate the throughput and access latency of GPU global memory and shared\nmemory. Our microbenchmark results offer a better understanding of the\nmysterious GPU memory hierarchy, which will facilitate the software\noptimization and modelling of GPU architectures. To the best of our knowledge,\nthis is the first study to reveal the cache properties of Kepler and Maxwell\nGPUs, and the superiority of Maxwell in shared memory performance under bank\nconflict."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2015.6401", 
    "link": "http://arxiv.org/pdf/1509.04240v1", 
    "title": "Feasible methodology for optimization of a novel reversible binary   compressor", 
    "arxiv-id": "1509.04240v1", 
    "author": "Amit Kumar", 
    "publish": "2015-09-11T15:53:39Z", 
    "summary": "Now a day reversible logic is an attractive research area due to its low\npower consumption in the area of VLSI circuit design. The reversible logic gate\nis utilized to optimize power consumption by a feature of retrieving input\nlogic from an output logic because of bijective mapping between input and\noutput. In this manuscript, we design 4 2 and 5 2 reversible compressor\ncircuits using a new type of reversible gate. In addition, we propose new gate,\nnamed as inventive0 gate for optimizing a compressor circuit. The utility of\nthe inventive0 gate is that it can be used as full adder and full subtraction\nwith low value of garbage outputs and quantum cost. An algorithm is shown for\ndesigning a compressor structure. The comparative study shows that the proposed\ncompressor structure outperforms the existing ones in terms of garbage outputs,\nnumber of gates and quantum cost. The compressor can reduce the effect of carry\n(Produce from full adder) of the arithmetic frame design. In addition, we\nimplement a basic reversible gate of MOS transistor with less number of MOS\ntransistor count."
},{
    "category": "cs.NE", 
    "doi": "10.5121/vlsic.2015.6401", 
    "link": "http://arxiv.org/pdf/1509.08972v2", 
    "title": "VLSI Implementation of Deep Neural Network Using Integral Stochastic   Computing", 
    "arxiv-id": "1509.08972v2", 
    "author": "Warren J. Gross", 
    "publish": "2015-09-29T23:16:18Z", 
    "summary": "The hardware implementation of deep neural networks (DNNs) has recently\nreceived tremendous attention: many applications in fact require high-speed\noperations that suit a hardware implementation. However, numerous elements and\ncomplex interconnections are usually required, leading to a large area\noccupation and copious power consumption. Stochastic computing has shown\npromising results for low-power area-efficient hardware implementations, even\nthough existing stochastic algorithms require long streams that cause long\nlatencies. In this paper, we propose an integer form of stochastic computation\nand introduce some elementary circuits. We then propose an efficient\nimplementation of a DNN based on integral stochastic computing. The proposed\narchitecture has been implemented on a Virtex7 FPGA, resulting in 45% and 62%\naverage reductions in area and latency compared to the best reported\narchitecture in literature. We also synthesize the circuits in a 65 nm CMOS\ntechnology and we show that the proposed integral stochastic architecture\nresults in up to 21% reduction in energy consumption compared to the binary\nradix implementation at the same misclassification rate. Due to fault-tolerant\nnature of stochastic architectures, we also consider a quasi-synchronous\nimplementation which yields 33% reduction in energy consumption w.r.t. the\nbinary radix implementation without any compromise on performance."
},{
    "category": "cs.DC", 
    "doi": "10.5121/vlsic.2015.6401", 
    "link": "http://arxiv.org/pdf/1511.03639v2", 
    "title": "Analysis of Intel's Haswell Microarchitecture Using The ECM Model and   Microbenchmarks", 
    "arxiv-id": "1511.03639v2", 
    "author": "Gerhard Wellein", 
    "publish": "2015-11-11T20:20:03Z", 
    "summary": "This paper presents an in-depth analysis of Intel's Haswell microarchitecture\nfor streaming loop kernels. Among the new features examined is the dual-ring\nUncore design, Cluster-on-Die mode, Uncore Frequency Scaling, core improvements\nas new and improved execution units, as well as improvements throughout the\nmemory hierarchy. The Execution-Cache-Memory diagnostic performance model is\nused together with a generic set of microbenchmarks to quantify the efficiency\nof the microarchitecture. The set of microbenchmarks is chosen such that it can\nserve as a blueprint for other streaming loop kernels."
},{
    "category": "cs.ET", 
    "doi": "10.5121/vlsic.2015.6401", 
    "link": "http://arxiv.org/pdf/1511.09085v2", 
    "title": "Energy Efficient and High Performance Current-Mode Neural Network   Circuit using Memristors and Digitally Assisted Analog CMOS Neurons", 
    "arxiv-id": "1511.09085v2", 
    "author": "Mrigank Sharad", 
    "publish": "2015-11-29T20:27:15Z", 
    "summary": "Emerging nano-scale programmable Resistive-RAM (RRAM) has been identified as\na promising technology for implementing brain-inspired computing hardware.\nSeveral neural network architectures, that essentially involve computation of\nscalar products between input data vectors and stored network weights can be\nefficiently implemented using high density cross-bar arrays of RRAM integrated\nwith CMOS. In such a design, the CMOS interface may be responsible for\nproviding input excitations and for processing the RRAM output. In order to\nachieve high energy efficiency along with high integration density in RRAM\nbased neuromorphic hardware, the design of RRAM-CMOS interface can therefore\nplay a major role. In this work we propose design of high performance, current\nmode CMOS interface for RRAM based neural network design. The use of current\nmode excitation for input interface and design of digitally assisted\ncurrent-mode CMOS neuron circuit for the output interface is presented. The\nproposed technique achieve 10x energy as well as performance improvement over\nconventional approaches employed in literature. Network level simulations show\nthat the proposed scheme can achieve 2 orders of magnitude lower energy\ndissipation as compared to a digital ASIC implementation of a feed-forward\nneural network."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2015.6401", 
    "link": "http://arxiv.org/pdf/1512.00504v1", 
    "title": "Efficient Edge Detection on Low-Cost FPGAs", 
    "arxiv-id": "1512.00504v1", 
    "author": "Andrew Bainbridge-Smith", 
    "publish": "2015-12-01T22:32:21Z", 
    "summary": "Improving the efficiency of edge detection in embedded applications, such as\nUAV control, is critical for reducing system cost and power dissipation. Field\nprogrammable gate arrays (FPGA) are a good platform for making improvements\nbecause of their specialised internal structure. However, current FPGA edge\ndetectors do not exploit this structure well. A new edge detection architecture\nis proposed that is better optimised for FPGAs. The basis of the architecture\nis the Sobel edge kernels that are shown to be the most suitable because of\ntheir separability and absence of multiplications. Edge intensities are\ncalculated with a new 4:2 compressor that consists of two custom-designed 3:2\ncompressors. Addition speed is increased by breaking carry propagation chains\nwith look-ahead logic. Testing of the design showed it gives a 28% increase in\nspeed and 4.4% reduction in area over previous equivalent designs, which\ndemonstrated that it will lower the cost of edge detection systems, dissipate\nless power and still maintain high-speed control."
},{
    "category": "cs.CR", 
    "doi": "10.5121/vlsic.2015.6401", 
    "link": "http://arxiv.org/pdf/1512.01581v1", 
    "title": "Threshold Voltage-Defined Switches for Programmable Gates", 
    "arxiv-id": "1512.01581v1", 
    "author": "Swaroop Ghosh", 
    "publish": "2015-12-04T22:10:23Z", 
    "summary": "Semiconductor supply chain is increasingly getting exposed to variety of\nsecurity attacks such as Trojan insertion, cloning, counterfeiting, reverse\nengineering (RE), piracy of Intellectual Property (IP) or Integrated Circuit\n(IC) and side-channel analysis due to involvement of untrusted parties. In this\npaper, we propose transistor threshold voltage-defined switches to camouflage\nthe logic gate both logically and physically to resist against RE and IP\npiracy. The proposed gate can function as NAND, AND, NOR, OR, XOR, XNOR, INV\nand BUF robustly using threshold-defined switches. The camouflaged design\noperates at nominal voltage and obeys conventional reliability limits. The\nproposed gate can also be used to personalize the design during manufacturing."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2015.6401", 
    "link": "http://arxiv.org/pdf/1601.00894v2", 
    "title": "Configurable memory systems for embedded many-core processors", 
    "arxiv-id": "1601.00894v2", 
    "author": "Robert Mullins", 
    "publish": "2016-01-05T16:29:17Z", 
    "summary": "The memory system of a modern embedded processor consumes a large fraction of\ntotal system energy. We explore a range of different configuration options and\nshow that a reconfigurable design can make better use of the resources\navailable to it than any fixed implementation, and provide large improvements\nin both performance and energy consumption. Reconfigurability becomes\nincreasingly useful as resources become more constrained, so is particularly\nrelevant in the embedded space.\n  For an optimised architectural configuration, we show that a configurable\ncache system performs an average of 20% (maximum 70%) better than the best\nfixed implementation when two programs are competing for the same resources,\nand reduces cache miss rate by an average of 70% (maximum 90%). We then present\na case study of AES encryption and decryption, and find that a custom memory\nconfiguration can almost double performance, with further benefits being\nachieved by specialising the task of each core when parallelising the program."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2015.6401", 
    "link": "http://arxiv.org/pdf/1601.01722v1", 
    "title": "Profiling-Assisted Decoupled Access-Execute", 
    "arxiv-id": "1601.01722v1", 
    "author": "Alexandra Jimborean", 
    "publish": "2016-01-07T22:43:43Z", 
    "summary": "As energy efficiency became a critical factor in the embedded systems domain,\ndynamic voltage and frequency scaling (DVFS) techniques have emerged as means\nto control the system's power and energy efficiency. Additionally, due to the\ncompact design, thermal issues become prominent. State of the art work promotes\nsoftware decoupled access-execution (DAE) that statically generates code\namenable to DVFS techniques. The compiler builds memory-bound access phases,\ndesigned to prefetch data in the cache at low frequency, and compute-bound\nphases, that consume the data and perform computations at high frequency. This\nwork investigates techniques to find the optimal balance between lightweight\nand efficient access phases. A profiling step guides the selection of loads to\nbe prefetched in the access phase. For applications whose behavior vary\nsignificantly with respect to the input data, the profiling can be performed\nonline, accompanied by just-in-time compilation. We evaluated the benefits in\nenergy efficiency and performance for both static and dynamic code generation\nand showed that precise prefetching of critical loads can result in 20% energy\nimprovements, on average. DAE is particularly beneficial for embedded systems\nas by alternating access phases (executed at low frequency) and execute phases\n(at high frequency) DAE proactively reduces the temperature and therefore\nprevents thermal emergencies."
},{
    "category": "cs.CV", 
    "doi": "10.5121/vlsic.2015.6401", 
    "link": "http://arxiv.org/pdf/1602.01528v2", 
    "title": "EIE: Efficient Inference Engine on Compressed Deep Neural Network", 
    "arxiv-id": "1602.01528v2", 
    "author": "William J. Dally", 
    "publish": "2016-02-04T01:28:28Z", 
    "summary": "State-of-the-art deep neural networks (DNNs) have hundreds of millions of\nconnections and are both computationally and memory intensive, making them\ndifficult to deploy on embedded systems with limited hardware resources and\npower budgets. While custom hardware helps the computation, fetching weights\nfrom DRAM is two orders of magnitude more expensive than ALU operations, and\ndominates the required power.\n  Previously proposed 'Deep Compression' makes it possible to fit large DNNs\n(AlexNet and VGGNet) fully in on-chip SRAM. This compression is achieved by\npruning the redundant connections and having multiple connections share the\nsame weight. We propose an energy efficient inference engine (EIE) that\nperforms inference on this compressed network model and accelerates the\nresulting sparse matrix-vector multiplication with weight sharing. Going from\nDRAM to SRAM gives EIE 120x energy saving; Exploiting sparsity saves 10x;\nWeight sharing gives 8x; Skipping zero activations from ReLU saves another 3x.\nEvaluated on nine DNN benchmarks, EIE is 189x and 13x faster when compared to\nCPU and GPU implementations of the same DNN without compression. EIE has a\nprocessing power of 102GOPS/s working directly on a compressed network,\ncorresponding to 3TOPS/s on an uncompressed network, and processes FC layers of\nAlexNet at 1.88x10^4 frames/sec with a power dissipation of only 600mW. It is\n24,000x and 3,400x more energy efficient than a CPU and GPU respectively.\nCompared with DaDianNao, EIE has 2.9x, 19x and 3x better throughput, energy\nefficiency and area efficiency."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2015.6401", 
    "link": "http://arxiv.org/pdf/1602.01616v2", 
    "title": "FPGA Based Implementation of Deep Neural Networks Using On-chip Memory   Only", 
    "arxiv-id": "1602.01616v2", 
    "author": "Wonyong Sung", 
    "publish": "2016-02-04T10:16:13Z", 
    "summary": "Deep neural networks (DNNs) demand a very large amount of computation and\nweight storage, and thus efficient implementation using special purpose\nhardware is highly desired. In this work, we have developed an FPGA based\nfixed-point DNN system using only on-chip memory not to access external DRAM.\nThe execution time and energy consumption of the developed system is compared\nwith a GPU based implementation. Since the capacity of memory in FPGA is\nlimited, only 3-bit weights are used for this implementation, and training\nbased fixed-point weight optimization is employed. The implementation using\nXilinx XC7Z045 is tested for the MNIST handwritten digit recognition benchmark\nand a phoneme recognition task on TIMIT corpus. The obtained speed is about one\nquarter of a GPU based implementation and much better than that of a PC based\none. The power consumption is less than 5 Watt at the full speed operation\nresulting in much higher efficiency compared to GPU based systems."
},{
    "category": "cs.AR", 
    "doi": "10.5121/vlsic.2015.6401", 
    "link": "http://arxiv.org/pdf/1602.02517v1", 
    "title": "Energy Efficient Video Fusion with Heterogeneous CPU-FPGA Devices", 
    "arxiv-id": "1602.02517v1", 
    "author": "Tom Sun", 
    "publish": "2016-02-08T10:28:44Z", 
    "summary": "This paper presents a complete video fusion system with hardware acceleration\nand investigates the energy trade-offs between computing in the CPU or the FPGA\ndevice. The video fusion application is based on the Dual-Tree Complex Wavelet\nTransforms (DT-CWT). In this work the transforms are mapped to a hardware\naccelerator using high-level synthesis tools for the FPGA and also vectorized\ncode for the single instruction multiple data (SIMD) engine available in the\nCPU. The accelerated system reduces computation time and energy by a factor of\n2. Moreover, the results show a key finding that the FPGA is not always the\nbest choice for acceleration, and the SIMD engine should be selected when the\nwavelet decomposition reduces the frame size below a certain threshold. This\ndependency on workload size means that an adaptive system that intelligently\nselects between the SIMD engine and the FPGA achieves the most energy and\nperformance efficiency point."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TPDS.2015.2505725", 
    "link": "http://arxiv.org/pdf/1602.03016v1", 
    "title": "FPGA Hardware Acceleration of Monte Carlo Simulations for the Ising   Model", 
    "arxiv-id": "1602.03016v1", 
    "author": "Leonardo Franco", 
    "publish": "2016-02-09T15:04:11Z", 
    "summary": "A two-dimensional Ising model with nearest-neighbors ferromagnetic\ninteractions is implemented in a Field Programmable Gate Array (FPGA)\nboard.Extensive Monte Carlo simulations were carried out using an efficient\nhardware representation of individual spins and a combined global-local LFSR\nrandom number generator. Consistent results regarding the descriptive\nproperties of magnetic systems, like energy, magnetization and susceptibility\nare obtained while a speed-up factor of approximately 6 times is achieved in\ncomparison to previous FPGA-based published works and almost $10^4$ times in\ncomparison to a standard CPU simulation. A detailed description of the logic\ndesign used is given together with a careful analysis of the quality of the\nrandom number generator used. The obtained results confirm the potential of\nFPGAs for analyzing the statistical mechanics of magnetic systems."
},{
    "category": "cs.AR", 
    "doi": "10.1109/MDAT.2016.2573586", 
    "link": "http://arxiv.org/pdf/1602.04183v3", 
    "title": "Dark Memory and Accelerator-Rich System Optimization in the Dark Silicon   Era", 
    "arxiv-id": "1602.04183v3", 
    "author": "Mark A. Horowitz", 
    "publish": "2016-02-12T19:48:31Z", 
    "summary": "The key challenge to improving performance in the age of Dark Silicon is how\nto leverage transistors when they cannot all be used at the same time. In\nmodern SOCs, these transistors are often used to create specialized\naccelerators which improve energy efficiency for some applications by 10-1000X.\nWhile this might seem like the magic bullet we need, for most CPU applications\nmore energy is dissipated in the memory system than in the processor: these\nlarge gains in efficiency are only possible if the DRAM and memory hierarchy\nare mostly idle. We refer to this desirable state as Dark Memory, and it only\noccurs for applications with an extreme form of locality.\n  To show our findings, we introduce Pareto curves in the energy/op and\nmm$^2$/(ops/s) metric space for compute units, accelerators, and on-chip\nmemory/interconnect. These Pareto curves allow us to solve the power,\nperformance, area constrained optimization problem to determine which\naccelerators should be used, and how to set their design parameters to optimize\nthe system. This analysis shows that memory accesses create a floor to the\nachievable energy-per-op. Thus high performance requires Dark Memory, which in\nturn requires co-design of the algorithm for parallelism and locality, with the\nhardware."
},{
    "category": "cs.SE", 
    "doi": "10.1109/MDAT.2016.2573586", 
    "link": "http://arxiv.org/pdf/1602.06038v1", 
    "title": "Automatic Generation of High-Coverage Tests for RTL Designs using   Software Techniques and Tools", 
    "arxiv-id": "1602.06038v1", 
    "author": "Mengxing Huang", 
    "publish": "2016-02-19T03:49:44Z", 
    "summary": "Register Transfer Level (RTL) design validation is a crucial stage in the\nhardware design process. We present a new approach to enhancing RTL design\nvalidation using available software techniques and tools. Our approach converts\nthe source code of a RTL design into a C++ software program. Then a powerful\nsymbolic execution engine is employed to execute the converted C++ program\nsymbolically to generate test cases. To better generate efficient test cases,\nwe limit the number of cycles to guide symbolic execution. Moreover, we add\nbit-level symbolic variable support into the symbolic execution engine.\nGenerated test cases are further evaluated by simulating the RTL design to get\naccurate coverage. We have evaluated the approach on a floating point unit\n(FPU) design. The preliminary results show that our approach can deliver\nhigh-quality tests to achieve high coverage."
},{
    "category": "cs.CV", 
    "doi": "10.1109/FPT.2015.7393157", 
    "link": "http://arxiv.org/pdf/1603.05154v1", 
    "title": "2D Discrete Fourier Transform with Simultaneous Edge Artifact Removal   for Real-Time Applications", 
    "arxiv-id": "1603.05154v1", 
    "author": "Ulf Skoglund", 
    "publish": "2016-03-16T15:52:13Z", 
    "summary": "Two-Dimensional (2D) Discrete Fourier Transform (DFT) is a basic and\ncomputationally intensive algorithm, with a vast variety of applications. 2D\nimages are, in general, non-periodic, but are assumed to be periodic while\ncalculating their DFTs. This leads to cross-shaped artifacts in the frequency\ndomain due to spectral leakage. These artifacts can have critical consequences\nif the DFTs are being used for further processing. In this paper we present a\nnovel FPGA-based design to calculate high-throughput 2D DFTs with simultaneous\nedge artifact removal. Standard approaches for removing these artifacts using\napodization functions or mirroring, either involve removing critical\nfrequencies or a surge in computation by increasing image size. We use a\nperiodic-plus-smooth decomposition based artifact removal algorithm optimized\nfor FPGA implementation, while still achieving real-time ($\\ge$23 frames per\nsecond) performance for a 512$\\times$512 size image stream. Our optimization\napproach leads to a significant decrease in external memory utilization thereby\navoiding memory conflicts and simplifies the design. We have tested our design\non a PXIe based Xilinx Kintex 7 FPGA system communicating with a host PC which\ngives us the advantage to further expand the design for industrial\napplications."
},{
    "category": "q-bio.GN", 
    "doi": "10.1109/FPT.2015.7393157", 
    "link": "http://arxiv.org/pdf/1604.01789v2", 
    "title": "GateKeeper: A New Hardware Architecture for Accelerating Pre-Alignment   in DNA Short Read Mapping", 
    "arxiv-id": "1604.01789v2", 
    "author": "Can Alkan", 
    "publish": "2016-04-06T20:04:56Z", 
    "summary": "Motivation: High throughput DNA sequencing (HTS) technologies generate an\nexcessive number of small DNA segments -called short reads- that cause\nsignificant computational burden. To analyze the entire genome, each of the\nbillions of short reads must be mapped to a reference genome based on the\nsimilarity between a read and \"candidate\" locations in that reference genome.\nThe similarity measurement, called alignment, formulated as an approximate\nstring matching problem, is the computational bottleneck because: (1) it is\nimplemented using quadratic-time dynamic programming algorithms, and (2) the\nmajority of candidate locations in the reference genome do not align with a\ngiven read due to high dissimilarity. Calculating the alignment of such\nincorrect candidate locations consumes an overwhelming majority of a modern\nread mapper's execution time. Therefore, it is crucial to develop a fast and\neffective filter that can detect incorrect candidate locations and eliminate\nthem before using computationally costly alignment operations. Results: We\npropose GateKeeper, a new hardware accelerator that functions as a\npre-alignment step that quickly filters out most incorrect candidate locations.\nGateKeeper is the first design to accelerate pre-alignment using\nField-Programmable Gate Arrays (FPGAs), which can perform pre-alignment much\nfaster than software. GateKeeper can be integrated with any mapper that\nperforms sequence alignment for verification. When implemented on a single FPGA\nchip, GateKeeper maintains high accuracy (on average >96%) while providing up\nto 105-fold and 215-fold speedup over the state-of-the-art software\npre-alignment techniques, Adjacency Filter and Shifted Hamming Distance (SHD),\nrespectively. Availability: GateKeeper is available at:\nhttps://github.com/BilkentCompGen/GateKeeper."
},{
    "category": "cs.NA", 
    "doi": "10.1109/FPT.2015.7393157", 
    "link": "http://arxiv.org/pdf/1606.00251v1", 
    "title": "Profile-Driven Automated Mixed Precision", 
    "arxiv-id": "1606.00251v1", 
    "author": "Xiaobai Sun", 
    "publish": "2016-06-01T12:27:54Z", 
    "summary": "We present a scheme to automatically set the precision of floating point\nvariables in an application. We design a framework that profiles applications\nto measure undesirable numerical behavior at the floating point operation\nlevel. We use this framework to perform mixed precision analysis to\nheuristically set the precision of all variables in an application based on\ntheir numerical profiles. We experimentally evaluate the mixed precision\nanalysis to show that it can generate a range of results with different\naccuracy and performance characteristics."
},{
    "category": "cs.AR", 
    "doi": "10.1109/FPT.2015.7393157", 
    "link": "http://arxiv.org/pdf/1606.01607v1", 
    "title": "CG-OoO: Energy-Efficient Coarse-Grain Out-of-Order Execution", 
    "arxiv-id": "1606.01607v1", 
    "author": "William J. Dally", 
    "publish": "2016-06-06T03:44:52Z", 
    "summary": "We introduce the Coarse-Grain Out-of-Order (CG- OoO) general purpose\nprocessor designed to achieve close to In-Order processor energy while\nmaintaining Out-of-Order (OoO) performance. CG-OoO is an energy-performance\nproportional general purpose architecture that scales according to the program\nload. Block-level code processing is at the heart of the this architecture;\nCG-OoO speculates, fetches, schedules, and commits code at block-level\ngranularity. It eliminates unnecessary accesses to energy consuming tables, and\nturns large tables into smaller and distributed tables that are cheaper to\naccess. CG-OoO leverages compiler-level code optimizations to deliver efficient\nstatic code, and exploits dynamic instruction-level parallelism and block-level\nparallelism. CG-OoO introduces Skipahead issue, a complexity effective, limited\nout-of-order instruction scheduling model. Through the energy efficiency\ntechniques applied to the compiler and processor pipeline stages, CG-OoO closes\n64% of the average energy gap between the In-Order and Out-of-Order baseline\nprocessors at the performance of the OoO baseline. This makes CG-OoO 1.9x more\nefficient than the OoO on the energy-delay product inverse metric."
},{
    "category": "cs.AR", 
    "doi": "10.1109/FPT.2015.7393157", 
    "link": "http://arxiv.org/pdf/1606.01980v2", 
    "title": "Open-source Hardware: Opportunities and Challenges", 
    "arxiv-id": "1606.01980v2", 
    "author": "Karthikeyan Sankaralingam", 
    "publish": "2016-06-07T00:15:16Z", 
    "summary": "Innovation in hardware is slowing due to rising costs of chip design and\ndiminishing benefits from Moore's law and Dennard scaling. Software innovation,\non the other hand, is flourishing, helped in good measure by a thriving\nopen-source ecosystem. We believe that open source can similarly help hardware\ninnovation, but has not yet due to several reasons. We identify these reasons\nand how the industry, academia, and the hardware community at large can come\ntogether to address them."
},{
    "category": "cs.AR", 
    "doi": "10.1109/FPT.2015.7393157", 
    "link": "http://arxiv.org/pdf/1606.03248v1", 
    "title": "MAC: a novel systematically multilevel cache replacement policy for PCM   memory", 
    "arxiv-id": "1606.03248v1", 
    "author": "Dongsheng Wang", 
    "publish": "2016-06-10T09:47:14Z", 
    "summary": "The rapid development of multi-core system and increase of data-intensive\napplication in recent years call for larger main memory. Traditional DRAM\nmemory can increase its capacity by reducing the feature size of storage cell.\nNow further scaling of DRAM faces great challenge, and the frequent refresh\noperations of DRAM can bring a lot of energy consumption. As an emerging\ntechnology, Phase Change Memory (PCM) is promising to be used as main memory.\nIt draws wide attention due to the advantages of low power consumption, high\ndensity and nonvolatility, while it incurs finite endurance and relatively long\nwrite latency. To handle the problem of write, optimizing the cache replacement\npolicy to protect dirty cache block is an efficient way. In this paper, we\nconstruct a systematically multilevel structure, and based on it propose a\nnovel cache replacement policy called MAC. MAC can effectively reduce write\ntraffic to PCM memory with low hardware overhead. We conduct simulation\nexperiments on GEM5 to evaluate the performances of MAC and other related\nworks. The results show that MAC performs best in reducing the amount of writes\n(averagely 25.12%) without increasing the program execution time."
},{
    "category": "cs.DC", 
    "doi": "10.1109/FPT.2015.7393157", 
    "link": "http://arxiv.org/pdf/1606.03742v1", 
    "title": "NCAM: Near-Data Processing for Nearest Neighbor Search", 
    "arxiv-id": "1606.03742v1", 
    "author": "Ali Farhadi", 
    "publish": "2016-06-12T17:08:43Z", 
    "summary": "Deep down in many applications like natural language processing (NLP),\nvision, and robotics is a form of the k-nearest neighbor search algorithm\n(kNN). The kNN algorithm is primarily bottlenecked by data movement, limiting\nthroughput and incurring latency in these applications. While there do exist\nwell bounded kNN approximations that improve the performance of kNN, these\nalgorithms trade-off accuracy and quickly degrade into linear search for high\ndimensionality.\n  To address data movement, we designed the nearest neighbor content\naddressable memory (NCAM) which employs processing in-memory (PIM) to eliminate\ncostly data transfers, and provides exact nearest neighbor search. NCAMs\nbenefit from the modularity offered by 3D die-stacking technology which allows\nus to side-step the issues of direct integration with DRAM dies. The NCAM\nbenefits from the higher density and speeds of emerging memory technologies and\ninterfaces.\n  We characterize a state-of-the-art software kNN implementation and expose the\nshortcomings of approximate kNN search. We present a full NCAM design and\nestimate its performance using post-placement and route estimates, and we show\nthat its power characteristics are compatible with emerging memory substrates.\nWe then evaluate energy efficiency and latency compared to modern multi-core\nCPUs and GPGPU platforms using parameters typical of mobile and server\nworkloads. Our simulation results show that the NCAM can achieve up to 160x\nthroughput per watt and three orders of magnitude latency improvement over a\nNVIDIA Titan X GPU for server workloads, and ~2413x throughput per watt and\n~94.5x latency improvements over a multi-core Intel E5-2620 CPU. Finally, we\nshow that the NCAM is not limited to just kNN and can be generalized to act as\na content addressable memory (CAM) or ternary-CAM (TCAM)."
},{
    "category": "cs.PL", 
    "doi": "10.1109/FPT.2015.7393157", 
    "link": "http://arxiv.org/pdf/1606.05416v1", 
    "title": "Taming Weak Memory Models", 
    "arxiv-id": "1606.05416v1", 
    "author": "Muralidaran Vijayaraghavan", 
    "publish": "2016-06-17T04:34:34Z", 
    "summary": "Speculative techniques in microarchitectures relax various dependencies in\nprograms, which contributes to the complexity of (weak) memory models. We show\nusing WMM, a new weak memory model, that the model becomes simpler if it\nincludes load-value speculation and thus, does not enforce any dependency!\nHowever, in the absence of good value-prediction techniques, a programmer may\nend up paying a price for the extra fences. Thus, we also present WMM-D, which\nenforces the dependencies captured by the current microarchitectures. WMM-D is\nstill much simpler than other existing models. We also show that non-atomic\nmulti-copy stores arise as a result of sharing write-through caches. We think\nrestricting microarchitectures to write-back caches (and thus simpler weak\nmemory models) will not incur any performance penalty. Nevertheless, we present\nWMM-S, another extension to WMM, which could model the effects of non-atomic\nmulti-copy stores. WMM, WMM-D, and WMM-S are all defined using Instantaneous\nInstruction Execution (I^2E), a new way of describing memory models without\nexplicit reordering or speculative execution."
},{
    "category": "cs.AR", 
    "doi": "10.1109/FPT.2015.7393157", 
    "link": "http://arxiv.org/pdf/1607.00667v1", 
    "title": "Reducing the Energy Cost of Inference via In-sensor Information   Processing", 
    "arxiv-id": "1607.00667v1", 
    "author": "Naresh Shanbhag", 
    "publish": "2016-07-03T18:43:55Z", 
    "summary": "There is much interest in incorporating inference capabilities into\nsensor-rich embedded platforms such as autonomous vehicles, wearables, and\nothers. A central problem in the design of such systems is the need to extract\ninformation locally from sensed data on a severely limited energy budget. This\nnecessitates the design of energy-efficient sensory embedded system. A typical\nsensory embedded system enforces a physical separation between sensing and\ncomputational subsystems - a separation mandated by the differing requirements\nof the sensing and computational functions. As a consequence, the energy\nconsumption in such systems tends to be dominated by the energy consumed in\ntransferring data over the sensor-processor interface (communication energy)\nand the energy consumed in processing the data in digital processor\n(computational energy). In this article, we propose an in-sensor computing\narchitecture which (mostly) eliminates the sensor-processor interface by\nembedding inference computations in the noisy sensor fabric in analog and\nretraining the hyperparameters in order to compensate for non-ideal\ncomputations. The resulting architecture referred to as the Compute Sensor - a\nsensor that computes in addition to sensing - represents a radical departure\nfrom the conventional. We show that a Compute Sensor for image data can be\ndesigned by embedding both feature extraction and classification functions in\nthe analog domain in close proximity to the CMOS active pixel sensor (APS)\narray. Significant gains in energy-efficiency are demonstrated using behavioral\nand energy models in a commercial semiconductor process technology. In the\nprocess, the Compute Sensor creates a unique opportunity to develop machine\nlearning algorithms for information extraction from data on a noisy underlying\ncomputational fabric."
},{
    "category": "cs.DC", 
    "doi": "10.1109/FPT.2015.7393157", 
    "link": "http://arxiv.org/pdf/1607.01643v1", 
    "title": "A configurable accelerator for manycores: the Explicitly Many-Processor   Approach", 
    "arxiv-id": "1607.01643v1", 
    "author": "J\u00e1nos V\u00e9gh", 
    "publish": "2016-07-06T14:40:03Z", 
    "summary": "A new approach to designing processor accelerators is presented. A new\ncomputing model and a special kind of accelerator with dynamic (end-user\nprogrammable) architecture is suggested. The new model considers a processor,\nin which a newly introduced supervisor layer coordinates the job of the cores.\nThe cores have the ability (based on the parallelization information provided\nby the compiler, and using the help of the supervisor) to outsource part of the\njob they received to some neighbouring core. The introduced changes essentially\nand advantageously modify the architecture and operation of the computing\nsystems. The computing throughput drastically increases, the efficiency of the\ntechnological implementation (computing performance per logic gates) increases,\nthe non-payload activity for using operating system services decreases, the\nreal-time behavior changes advantageously, and connecting accelerators to the\nprocessor greatly simplifies. Here only some details of the architecture and\noperation of the processor are discussed, the rest is described elsewhere."
},{
    "category": "cs.DC", 
    "doi": "10.1109/HPEC.2016.7761635", 
    "link": "http://arxiv.org/pdf/1607.06541v1", 
    "title": "Novel Graph Processor Architecture, Prototype System, and Results", 
    "arxiv-id": "1607.06541v1", 
    "author": "Jeremy Kepner", 
    "publish": "2016-07-22T02:22:44Z", 
    "summary": "Graph algorithms are increasingly used in applications that exploit large\ndatabases. However, conventional processor architectures are inadequate for\nhandling the throughput and memory requirements of graph computation. Lincoln\nLaboratory's graph-processor architecture represents a rethinking of parallel\narchitectures for graph problems. Our processor utilizes innovations that\ninclude a sparse matrix-based graph instruction set, a cacheless memory system,\naccelerator-based architecture, a systolic sorter, high-bandwidth\nmulti-dimensional toroidal communication network, and randomized\ncommunications. A field-programmable gate array (FPGA) prototype of the new\ngraph processor has been developed with significant performance enhancement\nover conventional processors in graph computational throughput."
},{
    "category": "cs.AR", 
    "doi": "10.1109/HPEC.2016.7761635", 
    "link": "http://arxiv.org/pdf/1607.08086v2", 
    "title": "Read-Tuned STT-RAM and eDRAM Cache Hierarchies for Throughput and Energy   Enhancement", 
    "arxiv-id": "1607.08086v2", 
    "author": "Ronald F. DeMara", 
    "publish": "2016-07-27T13:37:30Z", 
    "summary": "As capacity and complexity of on-chip cache memory hierarchy increases, the\nservice cost to the critical loads from Last Level Cache (LLC), which are\nfrequently repeated, has become a major concern. The processor may stall for a\nconsiderable interval while waiting to access the data stored in the cache\nblocks in LLC, if there are no independent instructions to execute. To provide\naccelerated service to the critical loads requests from LLC, this work\nconcentrates on leveraging the additional capacity offered by replacing\nSRAM-based L2 with Spin-Transfer Torque Random Access Memory (STT-RAM) to\naccommodate frequently accessed cache blocks in exclusive read mode in favor of\nreducing the overall read service time. Our proposed technique partitions L2\ncache into two STT-RAM arrangements with different write performance and data\nretention time. The retention-relaxed STT-RAM arrays are utilized to\neffectively deal with the regular L2 cache requests while the high retention\nSTT-RAM arrays in L2 are selected for maintaining repeatedly read accessed\ncache blocks from LLC by incurring negligible energy consumption for data\nretention. Our experimental results show that the proposed technique can reduce\nthe mean L2 read miss ratio by 51.4% and increase the IPC by 11.7% on average\nacross PARSEC benchmark suite while significantly decreasing the total L2\nenergy consumption compared to conventional SRAM-based L2 design."
},{
    "category": "cs.AR", 
    "doi": "10.1109/HPEC.2016.7761635", 
    "link": "http://arxiv.org/pdf/1607.08523v1", 
    "title": "The Study of Transient Faults Propagation in Multithread Applications", 
    "arxiv-id": "1607.08523v1", 
    "author": "Armin Samiei", 
    "publish": "2016-07-28T16:33:31Z", 
    "summary": "Whereas contemporary Error Correcting Codes (ECC) designs occupy a\nsignificant fraction of total die area in chip-multiprocessors (CMPs),\napproaches to deal with the vulnerability increase of CMP architecture against\nSingle Event Upsets (SEUs) and Multi-Bit Upsets (MBUs) are sought. In this\npaper, we focus on reliability assessment of multithreaded applications running\non CMPs to propose an adaptive application-relevant architecture design to\naccommodate the impact of both SEUs and MBUs in the entire CMP architecture.\nThis work concentrates on leveraging the intrinsic soft-error-immunity feature\nof Spin-Transfer Torque RAM (STT-RAM) as an alternative for SRAM-based storage\nand operation components. We target a specific portion of working set for\nreallocation to improve the reliability level of the CMP architecture design. A\nselected portion of instructions in multithreaded program which experience high\nrate of referencing with the lowest memory modification are ideal candidate to\nbe stored and executed in STT-RAM based components. We argue about why we\ncannot use STT-RAM for the global storage and operation counterparts and\ndescribe the obtained resiliency compared to the baseline setup. In addition, a\ndetail study of the impact of SEUs and MBUs on multithreaded programs will be\npresented in the Appendix."
},{
    "category": "cs.CV", 
    "doi": "10.1109/HPEC.2016.7761635", 
    "link": "http://arxiv.org/pdf/1607.08635v1", 
    "title": "A 58.6mW Real-Time Programmable Object Detector with Multi-Scale   Multi-Object Support Using Deformable Parts Model on 1920x1080 Video at 30fps", 
    "arxiv-id": "1607.08635v1", 
    "author": "Vivienne Sze", 
    "publish": "2016-07-27T19:20:33Z", 
    "summary": "This paper presents a programmable, energy-efficient and real-time object\ndetection accelerator using deformable parts models (DPM), with 2x higher\naccuracy than traditional rigid body models. With 8 deformable parts detection,\nthree methods are used to address the high computational complexity:\nclassification pruning for 33x fewer parts classification, vector quantization\nfor 15x memory size reduction, and feature basis projection for 2x reduction of\nthe cost of each classification. The chip is implemented in 65nm CMOS\ntechnology, and can process HD (1920x1080) images at 30fps without any off-chip\nstorage while consuming only 58.6mW (0.94nJ/pixel, 1168 GOPS/W). The chip has\ntwo classification engines to simultaneously detect two different classes of\nobjects. With a tested high throughput of 60fps, the classification engines can\nbe time multiplexed to detect even more than two object classes. It is energy\nscalable by changing the pruning factor or disabling the parts classification."
},{
    "category": "cs.AR", 
    "doi": "10.1109/HPEC.2016.7761635", 
    "link": "http://arxiv.org/pdf/1608.07036v1", 
    "title": "System Reliability, Fault Tolerance and Design Metrics Tradeoffs in the   Distributed Minority and Majority Voting Based Redundancy Scheme", 
    "arxiv-id": "1608.07036v1", 
    "author": "N E Mastorakis", 
    "publish": "2016-08-25T07:26:33Z", 
    "summary": "The distributed minority and majority voting based redundancy (DMMR) scheme\nwas recently proposed as an efficient alternative to the conventional N-modular\nredundancy (NMR) scheme for the physical design of mission/safety-critical\ncircuits and systems. The DMMR scheme enables significant improvements in fault\ntolerance and design metrics compared to the NMR scheme albeit at the expense\nof a slight decrease in the system reliability. In this context, this paper\nstudies the system reliability, fault tolerance and design metrics tradeoffs in\nthe DMMR scheme compared to the NMR scheme when the majority logic group of the\nDMMR scheme is increased in size relative to the minority logic group. Some\nexample DMMR and NMR systems were realized using a 32/28nm CMOS process and\ncompared. The results show that 5-of-M DMMR systems have a similar or better\nfault tolerance whilst requiring similar or fewer function modules than their\ncounterpart NMR systems and simultaneously achieve optimizations in design\nmetrics. Nevertheless, 3-of-M DMMR systems have the upper hand with respect to\nfault tolerance and design metrics optimizations than the comparable NMR and\n5-of-M DMMR systems. With regard to system reliability, NMR systems are closely\nfollowed by 5-of-M DMMR systems which are closely followed by 3-of-M DMMR\nsystems. The verdict is 3-of-M DMMR systems are preferable to implement higher\nlevels of redundancy from a combined system reliability, fault tolerance and\ndesign metrics perspective to realize mission/safety-critical circuits and\nsystems."
},{
    "category": "cs.AR", 
    "doi": "10.1109/HPEC.2016.7761635", 
    "link": "http://arxiv.org/pdf/1608.07485v1", 
    "title": "When to use 3D Die-Stacked Memory for Bandwidth-Constrained Big Data   Workloads", 
    "arxiv-id": "1608.07485v1", 
    "author": "David A. Wood", 
    "publish": "2016-08-26T15:04:20Z", 
    "summary": "Response time requirements for big data processing systems are shrinking. To\nmeet this strict response time requirement, many big data systems store all or\nmost of their data in main memory to reduce the access latency. Main memory\ncapacities have grown, and systems with 2 TB of main memory capacity available\ntoday. However, the rate at which processors can access this data--the memory\nbandwidth--has not grown at the same rate. In fact, some of these big-memory\nsystems can access less than 10% of their main memory capacity in one second\n(billions of processor cycles).\n  3D die-stacking is one promising solution to this bandwidth problem, and\nindustry is investing significantly in 3D die-stacking. We use a simple\nback-of-the-envelope-style model to characterize if and when the 3D die-stacked\narchitecture is more cost-effective than current architectures for in-memory\nbig data workloads. We find that die-stacking has much higher performance than\ncurrent systems (up to 256x lower response times), and it does not require\nexpensive memory over provisioning to meet real-time (10 ms) response time\nservice-level agreements. However, the power requirements of the die-stacked\nsystems are significantly higher (up to 50x) than current systems, and its\nmemory capacity is lower in many cases. Even in this limited case study, we\nfind 3D die-stacking is not a panacea. Today, die-stacking is the most\ncost-effective solution for strict SLAs and by reducing the power of the\ncompute chip and increasing memory densities die-stacking can be cost-effective\nunder other constraints in the future."
},{
    "category": "cs.AR", 
    "doi": "10.1109/HPEC.2016.7761635", 
    "link": "http://arxiv.org/pdf/1609.02067v1", 
    "title": "Practical Data Compression for Modern Memory Hierarchies", 
    "arxiv-id": "1609.02067v1", 
    "author": "Gennady Pekhimenko", 
    "publish": "2016-09-07T16:53:40Z", 
    "summary": "In this thesis, we describe a new, practical approach to integrating\nhardware-based data compression within the memory hierarchy, including on-chip\ncaches, main memory, and both on-chip and off-chip interconnects. This new\napproach is fast, simple, and effective in saving storage space. A key insight\nin our approach is that access time (including decompression latency) is\ncritical in modern memory hierarchies. By combining inexpensive hardware\nsupport with modest OS support, our holistic approach to compression achieves\nsubstantial improvements in performance and energy efficiency across the memory\nhierarchy. Using this new approach, we make several major contributions in this\nthesis. First, we propose a new compression algorithm, Base-Delta-Immediate\nCompression (BDI), that achieves high compression ratio with very low\ncompression/decompression latency. BDI exploits the existing low dynamic range\nof values present in many cache lines to compress them to smaller sizes using\nBase+Delta encoding. Second, we observe that the compressed size of a cache\nblock can be indicative of its reuse. We use this observation to develop a new\ncache insertion policy for compressed caches, the Size-based Insertion Policy\n(SIP), which uses the size of a compressed block as one of the metrics to\npredict its potential future reuse. Third, we propose a new main memory\ncompression framework, Linearly Compressed Pages (LCP), that significantly\nreduces the complexity and power cost of supporting main memory compression. We\ndemonstrate that any compression algorithm can be adapted to fit the\nrequirements of LCP, and that LCP can be efficiently integrated with the\nexisting cache compression designs, avoiding extra compression/decompression."
},{
    "category": "cs.AR", 
    "doi": "10.1109/HPEC.2016.7761635", 
    "link": "http://arxiv.org/pdf/1609.04569v3", 
    "title": "FPGA Implementation of a Novel Image Steganography for Hiding Images", 
    "arxiv-id": "1609.04569v3", 
    "author": "Ali Sadeghi", 
    "publish": "2016-09-15T10:50:45Z", 
    "summary": "As the complexity of current data flow systems and according infrastructure\nnetworks increases, the security of data transition through such platforms\nbecomes more important. Thus, different areas of steganography turn to one of\nthe most challengeable topics of current researches. In this paper a novel\nmethod is presented to hide an image into the host image and Hardware/Software\ndesign is proposed to implement our stagenography system on FPGA- DE2 70 Altera\nboard. The size of the secret image is quadrant of the host image. Host image\nworks as a cipher key to completely distort and encrypt the secret image using\nXOR operand. Each pixel of the secret image is composed of 8 bits (4 bit-pair)\nin which each bit-pair is distorted by XORing it with two LSB bits of the host\nimage and putting the results in the location of two LSB bits of host image.\nThe experimental results show the effectiveness of the proposed method compared\nto the most recently proposed algorithms by considering that the obtained\ninformation entropy for encrypt image is approximately equal to 8."
},{
    "category": "cs.AR", 
    "doi": "10.1109/HPEC.2016.7761635", 
    "link": "http://arxiv.org/pdf/1609.08681v1", 
    "title": "Multi-Valued Routing Tracks for FPGAs in 28nm FDSOI Technology", 
    "arxiv-id": "1609.08681v1", 
    "author": "Yves Mathieu", 
    "publish": "2016-09-27T21:56:17Z", 
    "summary": "In this paper we present quaternary and ternary routing tracks for FPGAs, and\ntheir implementation in 28nm FDSOI technology. We discuss the transistor level\ndesign of multi-valued repeaters, multiplexers and translators, and specific\nfeatures of FDSOI technology which make it possible. Next we compare the\nmulti-valued routing architectures with equivalent single driver two-valued\nrouting architectures. We show that for long tracks, it is possible to achieve\nupto 3x reduction in dynamic switching energy, upto 2x reduction in routing\nwire area and 10% reduction in area dedicated to routing resources. The\nmulti-valued tracks are slightly more susceptible to process variation. We\npresent a layout method for multivalued standard cells and determine the layout\noverhead.We conclude with various usage scenarios of these tracks."
},{
    "category": "cs.DC", 
    "doi": "10.1109/HPEC.2016.7761635", 
    "link": "http://arxiv.org/pdf/1610.03360v2", 
    "title": "Implementing High-Order FIR Filters in FPGAs", 
    "arxiv-id": "1610.03360v2", 
    "author": "Peter Kaever", 
    "publish": "2016-10-11T14:24:52Z", 
    "summary": "Contemporary field-programmable gate arrays (FPGAs) are predestined for the\napplication of finite impulse response (FIR) filters. Their embedded digital\nsignal processing (DSP) blocks for multiply-accumulate operations enable\nefficient fixed-point computations, in cases where the filter structure is\naccurately mapped to the dedicated hardware architecture. This brief presents a\ngeneric systolic structure for high-order FIR filters, efficiently exploiting\nthe hardware resources of an FPGA in terms of routability and timing. Although\nthis seems to be an easily implementable task, the synthesizing tools require\nan adaptation of the straightforward digital filter implementation for an\noptimal mapping. Using the example of a symmetric FIR filter with 90 taps, we\ndemonstrate the performance of the proposed structure with FPGAs from Xilinx\nand Altera. The implementation utilizes less than 1% of slice logic and runs at\nclock frequencies up to 526 MHz. Moreover, an enhancement of the structure\nultimately provides an extended dynamic range for the quantized coefficients\nwithout the costs of additional slice logic."
},{
    "category": "cs.DC", 
    "doi": "10.1109/HPEC.2016.7761635", 
    "link": "http://arxiv.org/pdf/1610.05601v3", 
    "title": "High-performance K-means Implementation based on a Simplified Map-Reduce   Architecture", 
    "arxiv-id": "1610.05601v3", 
    "author": "Lingli Wang", 
    "publish": "2016-10-17T13:46:43Z", 
    "summary": "The k-means algorithm is one of the most common clustering algorithms and\nwidely used in data mining and pattern recognition. The increasing\ncomputational requirement of big data applications makes hardware acceleration\nfor the k-means algorithm necessary. In this paper, a simplified Map-Reduce\narchitecture is proposed to implement the k-means algorithm on an FPGA.\nAlgorithmic segmentation, data path elaboration and automatic control are\napplied to optimize the architecture for high performance. In addition, high\nlevel synthesis technique is utilized to reduce development cycles and\ncomplexity. For a single iteration in the k-means algorithm, a throughput of\n28.74 Gbps is achieved. The performance shows at least 3.93x speedup compared\nwith four representative existing FPGA-based implementations and can satisfy\nthe demand of big data applications."
},{
    "category": "cs.ET", 
    "doi": "10.1109/HPEC.2016.7761635", 
    "link": "http://arxiv.org/pdf/1610.06088v1", 
    "title": "Design of a Compact Reversible Read-Only-Memory with MOS Transistors", 
    "arxiv-id": "1610.06088v1", 
    "author": "Lafifa Jamal", 
    "publish": "2015-11-07T16:44:56Z", 
    "summary": "Energy conservative devices are the need of the modern technology which leads\nto the development of reversible logic. The synthesis of reversible logic has\nbecome an intensely studied area as it overcomes the problem of power\ndissipation associated with irreversibility. Storage device such as\nRead-Only-Memory (ROM) can be realized in a reversible way with low power\ndissipation. The reversibility of ROM has not been yet realized in literature\nand hence, this paper presents a novel reversible ROM with its Complementary\nMetal Oxide Semiconductor (CMOS) realization. On the way to present the\narchitecture of reversible ROM, we propose a new reversible gate named as\nNowrin Papiya (NP) gate. All the proposed circuits and gates are realized with\nCMOS based pass transistor logic. Finally, an algorithm as well as several\ntheorems on the numbers of gates, transistors and garbage outputs have been\npresented to show the optimality of the reversible ROM. Simulations using\nMicrowind DSCH software has been shown to verify the correctness of the\nproposed design. The comparative results prove that the proposed designs are\nefficient and optimized in terms of numbers of gates, transistors, garbage\noutputs, quantum cost and delay."
},{
    "category": "cs.AR", 
    "doi": "10.1109/HPEC.2016.7761635", 
    "link": "http://arxiv.org/pdf/1610.06385v5", 
    "title": "Accelerating BLAS on Custom Architecture through Algorithm-Architecture   Co-design", 
    "arxiv-id": "1610.06385v5", 
    "author": "Ranjani Narayan", 
    "publish": "2016-10-20T12:46:07Z", 
    "summary": "Basic Linear Algebra Subprograms (BLAS) play key role in high performance and\nscientific computing applications. Experimentally, yesteryear multicore and\nGeneral Purpose Graphics Processing Units (GPGPUs) are capable of achieving up\nto 15 to 57% of the theoretical peak performance at 65W to 240W respectively\nfor compute bound operations like Double/Single Precision General Matrix\nMultiplication (XGEMM). For bandwidth bound operations like Single/Double\nprecision Matrix-vector Multiplication (XGEMV) the performance is merely 5 to\n7% of the theoretical peak performance in multicores and GPGPUs respectively.\nAchieving performance in BLAS requires moving away from conventional wisdom and\nevolving towards customized accelerator tailored for BLAS through\nalgorithm-architecture co-design. In this paper, we present acceleration of\nLevel-1 (vector operations), Level-2 (matrix-vector operations), and Level-3\n(matrix-matrix operations) BLAS through algorithm architecture co-design on a\nCoarse-grained Reconfigurable Architecture (CGRA). We choose REDEFINE CGRA as a\nplatform for our experiments since REDEFINE can be adapted to support domain of\ninterest through tailor-made Custom Function Units (CFUs). For efficient\nsequential realization of BLAS, we present design of a Processing Element (PE)\nand perform micro-architectural enhancements in the PE to achieve up-to 74% of\nthe theoretical peak performance of PE in DGEMM, 40% in DGEMV and 20% in double\nprecision inner product (DDOT). We attach this PE to REDEFINE CGRA as a CFU and\nshow the scalability of our solution. Finally, we show performance improvement\nof 3-140x in PE over commercially available Intel micro-architectures,\nClearSpeed CSX700, FPGA, and Nvidia GPGPUs."
},{
    "category": "cs.AR", 
    "doi": "10.1109/HPEC.2016.7761635", 
    "link": "http://arxiv.org/pdf/1611.01571v2", 
    "title": "Flat ORAM: A Simplified Write-Only Oblivious RAM Construction for Secure   Processors", 
    "arxiv-id": "1611.01571v2", 
    "author": "Marten van Dijk", 
    "publish": "2016-11-04T23:53:32Z", 
    "summary": "Oblivious RAM (ORAM) is a cryptographic primitive which obfuscates the access\npatterns to a storage thereby preventing privacy leakage. So far in the current\nliterature, only `fully functional' ORAMs are widely studied which can protect,\nat a cost of considerable performance penalty, against the strong adversaries\nwho can monitor all read and write operations. However, recent research has\nshown that information can still be leaked even if only the write access\npattern (not reads) is visible to the adversary. For such weaker adversaries, a\nfully functional ORAM turns out to be an overkill causing unnecessary\noverheads. Instead, a simple `write-only' ORAM is sufficient, and, more\ninterestingly, is preferred as it can offer far more performance and energy\nefficiency than a fully functional ORAM.\n  In this work, we present Flat ORAM: an efficient write-only ORAM scheme which\noutperforms the closest existing write-only ORAM called HIVE. HIVE suffers from\nperformance bottlenecks while managing the memory occupancy information vital\nfor correctness of the protocol. Flat ORAM resolves these bottlenecks by\nintroducing a simple idea of Occupancy Map (OccMap) which efficiently manages\nthe memory occupancy information resulting in far better performance. Our\nsimulation results show that, on average, Flat ORAM only incurs a moderate\nslowdown of $3\\times$ over the insecure DRAM for memory intensive benchmarks\namong Splash2 and $1.6\\times$ for SPEC06. Compared to HIVE, Flat ORAM offers\n$50\\%$ performance gain on average and up to $80\\%$ energy savings."
},{
    "category": "cs.OH", 
    "doi": "10.1109/HPEC.2016.7761635", 
    "link": "http://arxiv.org/pdf/1611.03099v1", 
    "title": "A Brief Survey of Non-Residue Based Computational Error Correction", 
    "arxiv-id": "1611.03099v1", 
    "author": "Thomas M. Conte", 
    "publish": "2016-11-09T21:23:16Z", 
    "summary": "The idea of computational error correction has been around for over half a\ncentury. The motivation has largely been to mitigate unreliable devices,\nmanufacturing defects or harsh environments, primarily as a mandatory measure\nto preserve reliability, or more recently, as a means to lower energy by\nallowing soft errors to occasionally creep. While residue codes have shown\ngreat promise for this purpose, there have been several orthogonal non-residue\nbased techniques. In this article, we provide a high level outline of some of\nthese non-residual approaches."
},{
    "category": "cs.LG", 
    "doi": "10.1109/HPEC.2016.7761635", 
    "link": "http://arxiv.org/pdf/1611.03109v1", 
    "title": "Energy-efficient Machine Learning in Silicon: A Communications-inspired   Approach", 
    "arxiv-id": "1611.03109v1", 
    "author": "Naresh R. Shanbhag", 
    "publish": "2016-10-25T18:45:32Z", 
    "summary": "This position paper advocates a communications-inspired approach to the\ndesign of machine learning systems on energy-constrained embedded `always-on'\nplatforms. The communications-inspired approach has two versions - 1) a\ndeterministic version where existing low-power communication IC design methods\nare repurposed, and 2) a stochastic version referred to as Shannon-inspired\nstatistical information processing employing information-based metrics,\nstatistical error compensation (SEC), and retraining-based methods to implement\nML systems on stochastic circuit/device fabrics operating at the limits of\nenergy-efficiency. The communications-inspired approach has the potential to\nfully leverage the opportunities afforded by ML algorithms and applications in\norder to address the challenges inherent in their deployment on\nenergy-constrained platforms."
},{
    "category": "cs.AR", 
    "doi": "10.1109/HPEC.2016.7761588", 
    "link": "http://arxiv.org/pdf/1611.03380v1", 
    "title": "In-Storage Embedded Accelerator for Sparse Pattern Processing", 
    "arxiv-id": "1611.03380v1", 
    "author": "Arvind", 
    "publish": "2016-11-10T16:21:51Z", 
    "summary": "We present a novel architecture for sparse pattern processing, using flash\nstorage with embedded accelerators. Sparse pattern processing on large data\nsets is the essence of applications such as document search, natural language\nprocessing, bioinformatics, subgraph matching, machine learning, and graph\nprocessing. One slice of our prototype accelerator is capable of handling up to\n1TB of data, and experiments show that it can outperform C/C++ software\nsolutions on a 16-core system at a fraction of the power and cost; an optimized\nversion of the accelerator can match the performance of a 48-core server."
},{
    "category": "cs.OH", 
    "doi": "10.1109/HPEC.2016.7761588", 
    "link": "http://arxiv.org/pdf/1611.05438v1", 
    "title": "An Efficient Framework for Floor-plan Prediction of Dynamic Runtime   Reconfigurable Systems", 
    "arxiv-id": "1611.05438v1", 
    "author": "G. Grewal", 
    "publish": "2016-09-29T21:48:29Z", 
    "summary": "Several embedded application domains for reconfigurable systems tend to\ncombine frequent changes with high performance demands of their workloads such\nas image processing, wearable computing and network processors. Time\nmultiplexing of reconfigurable hardware resources raises a number of new\nissues, ranging from run-time systems to complex programming models that\nusually form a Reconfigurable hardware Operating System (ROS). The Operating\nSystem performs online task scheduling and handles resource management. There\nare many challenges in adaptive computing and dynamic reconfigurable systems.\nOne of the major understudied challenges is estimating the required resources\nin terms of soft cores, Programmable Reconfigurable Regions (PRRs), the\nappropriate communication infrastructure, and to predict a near optimal layout\nand floorplan of the reconfigurable logic fabric. Some of these issues are\nspecific to the application being designed, while others are more general and\nrelate to the underlying run-time environment. Static resource allocation for\nRun- Time Reconfiguration (RTR) often leads to inferior and unacceptable\nresults. In this paper, we present a novel adaptive and dynamic methodology,\nbased on a Machine Learning approach, for predicting and estimating the\nnecessary resources for an application based on past historical information. An\nimportant feature of the proposed methodology is that the system is able to\nlearn and generalize and, therefore, is expected to improve its accuracy over\ntime. The goal of the entire process is to extract useful hidden knowledge from\nthe data. This knowledge is the prediction and estimation of the necessary\nresources for an unknown or not previously seen application."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICEEI.2011.6021782", 
    "link": "http://arxiv.org/pdf/1611.06078v1", 
    "title": "Fast and reconfigurable packet classification engine in FPGA-based   firewall", 
    "arxiv-id": "1611.06078v1", 
    "author": "Arif Sasongko", 
    "publish": "2016-11-18T13:59:39Z", 
    "summary": "In data communication via internet, security is becoming one of the most\ninfluential aspects. One way to support it is by classifying and filtering\nethernet packets within network devices. Packet classification is a fundamental\ntask for network devices such as routers, firewalls, and intrusion detection\nsystems. In this paper we present architecture of fast and reconfigurable\nPacket Classification Engine (PCE). This engine is used in FPGA-based firewall.\nOur PCE inspects multi-dimensional field of packet header sequentially based on\ntree-based algorithm. This algorithm simplifies overall system to a lower scale\nand leads to a more secure system. The PCE works with an adaptation of single\ncycle processor architecture in the system. Ethernet packet is examined with\nPCE based on Source IP Address, Destination IP Address, Source Port,\nDestination Port, and Protocol fields of the packet header. These are basic\nfields to know whether it is a dangerous or normal packet before inspecting the\ncontent. Using implementation of tree-based algorithm in the architecture,\nfirewall rules are rebuilt into 24-bit sub-rules which are read as processor\ninstruction in the inspection process. The inspection process is comparing one\nsub-rule with input field of header every clock cycle. The proposed PCE shows\n91 MHz clock frequency in Cyclone II EP2C70F896C6 with 13 clocks throughput\naverage from input to output generation. The use of tree-based algorithm\nsimplifies the multidimensional packet inspection and gives us reconfigurable\nas well as scalable system. The architecture is fast, reliable, and adaptable\nand also can maximize the advantages of the algorithm very well. Although the\nPCE has high frequency and little amount of clock, filtering speed of a\nfirewall also depends on the other components, such as packet FIFO buffer. Fast\nand reliable FIFO buffer is needed to support the PCE. This PCE also is not\ncompleted with rule update mechanism yet. This proposed PCE is tested as a\ncomponent of FPGA-based firewall to filter Ethernet packet with FPGA DE2 Board\nusing NIOS II platform."
},{
    "category": "cs.DC", 
    "doi": "10.1109/ICEEI.2011.6021782", 
    "link": "http://arxiv.org/pdf/1611.07511v1", 
    "title": "Can Broken Multicore Hardware be Mended?", 
    "arxiv-id": "1611.07511v1", 
    "author": "J\u00e1nos V\u00e9gh", 
    "publish": "2016-11-12T19:14:05Z", 
    "summary": "A suggestion is made for mending multicore hardware, which has been diagnosed\nas broken."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICEEI.2011.6021782", 
    "link": "http://arxiv.org/pdf/1612.00445v1", 
    "title": "Near-Memory Address Translation", 
    "arxiv-id": "1612.00445v1", 
    "author": "Babak Falsafi", 
    "publish": "2016-12-01T17:45:18Z", 
    "summary": "Memory and logic integration on the same chip is becoming increasingly cost\neffective, creating the opportunity to offload data-intensive functionality to\nprocessing units placed inside memory chips. The introduction of memory-side\nprocessing units (MPUs) into conventional systems faces virtual memory as the\nfirst big showstopper: without efficient hardware support for address\ntranslation MPUs have highly limited applicability. Unfortunately, conventional\ntranslation hardware (i.e., TLBs, MMU caches, and page table walkers) incurs\ndramatic overheads due to the limited reach, increasingly high miss penalty,\nand high translation coherence cost incurred with rapidly growing aggregate\nmemory size.\n  In this paper, we are the first to show that the historically important\nflexibility to map any virtual page to any page frame is unnecessary in today's\nservers. We find that while limiting the associativity of the\nvirtual-to-physical mapping incurs no penalty, it can break the\ntranslate-then-fetch serialization if combined with careful data placement in\nthe MPU's memory, allowing for translation and data fetch to proceed\nindependently and in parallel. We propose the Distributed Inverted Page Table\n(DIPTA), a near-memory structure in which the smallest memory partition keeps\nthe translation information for its data share, ensuring that the translation\ncompletes together with the data fetch. DIPTA completely eliminates the\nconventional translation hardware, as well as the performance overhead of\ntranslation, achieving speedups of up to 4.95x and 2.44x over conventional\ntranslation using 4KB and 1GB pages respectively, and obviating the need for\ntranslation-related broadcasts."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICEEI.2011.6021782", 
    "link": "http://arxiv.org/pdf/1612.03182v1", 
    "title": "Arch2030: A Vision of Computer Architecture Research over the Next 15   Years", 
    "arxiv-id": "1612.03182v1", 
    "author": "Thomas F. Wenisch", 
    "publish": "2016-12-09T21:02:13Z", 
    "summary": "Application trends, device technologies and the architecture of systems drive\nprogress in information technologies. However, the former engines of such\nprogress - Moore's Law and Dennard Scaling - are rapidly reaching the point of\ndiminishing returns. The time has come for the computing community to boldly\nconfront a new challenge: how to secure a foundational future for information\ntechnology's continued progress. The computer architecture community engaged in\nseveral visioning exercises over the years. Five years ago, we released a white\npaper, 21st Century Computer Architecture, which influenced funding programs in\nboth academia and industry. More recently, the IEEE Rebooting Computing\nInitiative explored the future of computing systems in the architecture,\ndevice, and circuit domains. This report stems from an effort to continue this\ndialogue, reach out to the applications and devices/circuits communities, and\nunderstand their trends and vision. We aim to identify opportunities where\narchitecture research can bridge the gap between the application and device\ndomains."
},{
    "category": "cs.DC", 
    "doi": "10.1109/ICEEI.2011.6021782", 
    "link": "http://arxiv.org/pdf/1612.06748v1", 
    "title": "NOP - A Simple Experimental Processor for Parallel Deployment", 
    "arxiv-id": "1612.06748v1", 
    "author": "Oskar Schirmer", 
    "publish": "2016-12-20T16:49:43Z", 
    "summary": "The design of a parallel computing system using several thousands or even up\nto a million processors asks for processing units that are simple and thus\nsmall in space, to make as many processing units as possible fit on a single\ndie.\n  The design presented herewith is far from being optimised, it is not meant to\ncompete with industry performance devices. Its main purpose is to allow for a\nprototypical implementation of a dynamic software system as a proof of concept."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICEEI.2011.6021782", 
    "link": "http://arxiv.org/pdf/1612.09524v1", 
    "title": "Memory Efficient Multi-Scale Line Detector Architecture for Retinal   Blood Vessel Segmentation", 
    "arxiv-id": "1612.09524v1", 
    "author": "J. M. Pierre Langlois", 
    "publish": "2016-12-06T19:06:28Z", 
    "summary": "This paper presents a memory efficient architecture that implements the\nMulti-Scale Line Detector (MSLD) algorithm for real-time retinal blood vessel\ndetection in fundus images on a Zynq FPGA. This implementation benefits from\nthe FPGA parallelism to drastically reduce the memory requirements of the MSLD\nfrom two images to a few values. The architecture is optimized in terms of\nresource utilization by reusing the computations and optimizing the bit-width.\nThe throughput is increased by designing fully pipelined functional units. The\narchitecture is capable of achieving a comparable accuracy to its software\nimplementation but 70x faster for low resolution images. For high resolution\nimages, it achieves an acceleration by a factor of 323x."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICEEI.2011.6021782", 
    "link": "http://arxiv.org/pdf/1701.06420v1", 
    "title": "Neurostream: Scalable and Energy Efficient Deep Learning with Smart   Memory Cubes", 
    "arxiv-id": "1701.06420v1", 
    "author": "Luca Benini", 
    "publish": "2017-01-23T14:44:47Z", 
    "summary": "High-performance computing systems are moving toward 2.5D as in High\nBandwidth Memory (HBM) and 3D integration of memory and logic as in Hybrid\nMemory Cube (HMC) to mitigate the main memory bottlenecks. This trend is also\ncreating new opportunities to revisit near-memory computation. In this paper,\nwe propose a flexible processor-in-memory (PIM) solution for scalable and\nenergy-efficient execution of deep convolutional networks (ConvNets), one of\nthe fastest-growing workloads for servers and high-end embedded systems. Our\ncodesign approach consists of a network of Smart Memory Cubes (modular\nextensions to the standard HMC) each augmented with a many-core PIM platform\ncalled NeuroCluster. NeuroClusters have a modular design based on NeuroStream\nfloating-point (FP) co-processors (for Convolution-intensive computations) and\ngeneral-purpose RISC-V cores. In addition, a DRAM-friendly tiling mechanism and\na scalable programming paradigm are presented to efficiently harness this\ncomputational capability with a very low programming effort. NeuroCluster\noccupies only 8% of the total logic-base (LoB) die area in a standard HMC and\nachieves an average performance of 240 GFLOPS for complete execution of\nfull-featured state-of-the-art (SoA) ConvNets within a power budget of 2.5W. An\nenergy efficiency of 22.5 GFLOPS/W is achieved in a single 3D stack which is 5X\nbetter than the best off-the-shelf GPU implementation. The minor increase in\nsystem-level power and the negligible area increase make our PIM system a cost\neffective and energy efficient solution, easily scalable to 955 GFLOPS with a\nnetwork of four SMCs."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICEEI.2011.6021782", 
    "link": "http://arxiv.org/pdf/1702.01894v1", 
    "title": "CAAD: Computer Architecture for Autonomous Driving", 
    "arxiv-id": "1702.01894v1", 
    "author": "Jean-Luc Gaudiot", 
    "publish": "2017-02-07T06:55:03Z", 
    "summary": "We describe the computing tasks involved in autonomous driving, examine\nexisting autonomous driving computing platform implementations. To enable\nautonomous driving, the computing stack needs to simultaneously provide high\nperformance, low power consumption, and low thermal dissipation, at low cost.\nWe discuss possible approaches to design computing platforms that will meet\nthese needs."
},{
    "category": "cs.CR", 
    "doi": "10.1109/ICEEI.2011.6021782", 
    "link": "http://arxiv.org/pdf/1703.00073v1", 
    "title": "Physically unclonable function using initial waveform of ring   oscillators on 65 nm CMOS technology", 
    "arxiv-id": "1703.00073v1", 
    "author": "Yuichiro Mitani", 
    "publish": "2017-02-10T16:38:17Z", 
    "summary": "A silicon physically unclonable function (PUF) using ring oscillators (ROs)\nhas the advantage of easy application in both an application specific\nintegrated circuit (ASIC) and a field-programmable gate array (FPGA). Here, we\nprovide a RO-PUF using the initial waveform of the ROs based on 65 nm CMOS\ntechnology. Compared with the conventional RO-PUF, the number of ROs is greatly\nreduced and the time needed to generate an ID is within a couple of system\nclocks."
},{
    "category": "cs.OS", 
    "doi": "10.1109/ICEEI.2011.6021782", 
    "link": "http://arxiv.org/pdf/1703.00897v1", 
    "title": "Adapting the DMTCP Plugin Model for Checkpointing of Hardware Emulation", 
    "arxiv-id": "1703.00897v1", 
    "author": "K. Suresh", 
    "publish": "2017-03-02T18:52:45Z", 
    "summary": "Checkpoint-restart is now a mature technology. It allows a user to save and\nlater restore the state of a running process. The new plugin model for the\nupcoming version 3.0 of DMTCP (Distributed MultiThreaded Checkpointing) is\ndescribed here. This plugin model allows a target application to disconnect\nfrom the hardware emulator at checkpoint time and then re-connect to a possibly\ndifferent hardware emulator at the time of restart. The DMTCP plugin model is\nimportant in allowing three distinct parties to seamlessly inter-operate. The\nthree parties are: the EDA designer, who is concerned with formal verification\nof a circuit design; the DMTCP developers, who are concerned with providing\ntransparent checkpointing during the circuit emulation; and the hardware\nemulator vendor, who provides a plugin library that responds to checkpoint,\nrestart, and other events.\n  The new plugin model is an example of process-level virtualization:\nvirtualization of external abstractions from within a process. This capability\nis motivated by scenarios for testing circuit models with the help of a\nhardware emulator. The plugin model enables a three-way collaboration: allowing\na circuit designer and emulator vendor to each contribute separate proprietary\nplugins while sharing an open source software framework from the DMTCP\ndevelopers. This provides a more flexible platform, where different fault\ninjection models based on plugins can be designed within the DMTCP\ncheckpointing framework. After initialization, one restarts from a checkpointed\nstate under the control of the desired plugin. This restart saves the time\nspent in simulating the initialization phase, while enabling fault injection\nexactly at the region of interest. Upon restart, one can inject faults or\notherwise modify the remainder of the simulation. The work concludes with a\nbrief survey of checkpointing and process-level virtualization."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICEEI.2011.6021782", 
    "link": "http://arxiv.org/pdf/1703.01457v1", 
    "title": "Chain-NN: An Energy-Efficient 1D Chain Architecture for Accelerating   Deep Convolutional Neural Networks", 
    "arxiv-id": "1703.01457v1", 
    "author": "Takeshi Yoshimura", 
    "publish": "2017-03-04T14:14:14Z", 
    "summary": "Deep convolutional neural networks (CNN) have shown their good performances\nin many computer vision tasks. However, the high computational complexity of\nCNN involves a huge amount of data movements between the computational\nprocessor core and memory hierarchy which occupies the major of the power\nconsumption. This paper presents Chain-NN, a novel energy-efficient 1D chain\narchitecture for accelerating deep CNNs. Chain-NN consists of the dedicated\ndual-channel process engines (PE). In Chain-NN, convolutions are done by the 1D\nsystolic primitives composed of a group of adjacent PEs. These systolic\nprimitives, together with the proposed column-wise scan input pattern, can\nfully reuse input operand to reduce the memory bandwidth requirement for energy\nsaving. Moreover, the 1D chain architecture allows the systolic primitives to\nbe easily reconfigured according to specific CNN parameters with fewer design\ncomplexity. The synthesis and layout of Chain-NN is under TSMC 28nm process. It\ncosts 3751k logic gates and 352KB on-chip memory. The results show a 576-PE\nChain-NN can be scaled up to 700MHz. This achieves a peak throughput of\n806.4GOPS with 567.5mW and is able to accelerate the five convolutional layers\nin AlexNet at a frame rate of 326.2fps. 1421.0GOPS/W power efficiency is at\nleast 2.5 to 4.1x times better than the state-of-the-art works."
},{
    "category": "cs.DC", 
    "doi": "10.1109/ICEEI.2011.6021782", 
    "link": "http://arxiv.org/pdf/cs/0004014v2", 
    "title": "Cluster Computing White Paper", 
    "arxiv-id": "cs/0004014v2", 
    "author": "Mark Baker", 
    "publish": "2000-04-25T18:55:40Z", 
    "summary": "Cluster computing is not a new area of computing. It is, however, evident\nthat there is a growing interest in its usage in all areas where applications\nhave traditionally used parallel or distributed computing platforms. The\ngrowing interest has been fuelled in part by the availability of powerful\nmicroprocessors and high-speed networks as off-the-shelf commodity components\nas well as in part by the rapidly maturing software components available to\nsupport high performance and high availability applications.\n  This White Paper has been broken down into eleven sections, each of which has\nbeen put together by academics and industrial researchers who are both experts\nin their fields and where willing to volunteer their time and effort to put\ntogether this White Paper. The status of this paper is draft and we are at the\nstage of publicizing its presence and making a Request For Comments (RFC)."
},{
    "category": "cs.AI", 
    "doi": "10.1109/ICEEI.2011.6021782", 
    "link": "http://arxiv.org/pdf/cs/0206027v1", 
    "title": "Behaviour-based Knowledge Systems: An Epigenetic Path from Behaviour to   Knowledge", 
    "arxiv-id": "cs/0206027v1", 
    "author": "Carlos Gershenson", 
    "publish": "2002-06-18T13:05:50Z", 
    "summary": "In this paper we expose the theoretical background underlying our current\nresearch. This consists in the development of behaviour-based knowledge\nsystems, for closing the gaps between behaviour-based and knowledge-based\nsystems, and also between the understandings of the phenomena they model. We\nexpose the requirements and stages for developing behaviour-based knowledge\nsystems and discuss their limits. We believe that these are necessary\nconditions for the development of higher order cognitive capacities, in\nartificial and natural cognitive systems."
},{
    "category": "cs.DC", 
    "doi": "10.1109/ICEEI.2011.6021782", 
    "link": "http://arxiv.org/pdf/cs/0302020v1", 
    "title": "Analytical formulations of Peer-to-Peer Connection Efficiency", 
    "arxiv-id": "cs/0302020v1", 
    "author": "Aaron Harwood", 
    "publish": "2003-02-13T10:13:01Z", 
    "summary": "Use of Peer-to-Peer (P2P) service networks introduces a new communication\nparadigm because peers are both clients and servers and so each peer may\nprovide/request services to/from other peers. Empirical studies of P2P networks\nhave been undertaken and reveal useful characteristics. However there is to\ndate little analytical work to describe P2P networks with respect to their\ncommunication paradigm and their interconnections. This paper provides an\nanalytical formulation and optimisation of peer connection efficiency, in terms\nof minimising the fraction of wasted connection time. Peer connection\nefficiency is analysed for both a uni- and multi-connected peer. Given this\nfundamental optimisation, the paper optimises the number of connections that\npeers should make use of as a function of network load, in terms of minimising\nthe total queue size that requests in the P2P network experience. The results\nof this paper provide a basis for engineering high performance P2P\ninterconnection networks. The optimisations are useful for reducing bandwidth\nand power consumption, e.g. in the case of peers being mobile devices with a\nlimited power supply. Also these results could be used to determine when a\n(virtual) circuit should be switched to support a connection."
},{
    "category": "cs.DC", 
    "doi": "10.1109/ICEEI.2011.6021782", 
    "link": "http://arxiv.org/pdf/cs/0303016v1", 
    "title": "Fast Parallel I/O on Cluster Computers", 
    "arxiv-id": "cs/0303016v1", 
    "author": "Walter Tichy", 
    "publish": "2003-03-19T11:08:44Z", 
    "summary": "Today's cluster computers suffer from slow I/O, which slows down\nI/O-intensive applications. We show that fast disk I/O can be achieved by\noperating a parallel file system over fast networks such as Myrinet or Gigabit\nEthernet.\n  In this paper, we demonstrate how the ParaStation3 communication system helps\nspeed-up the performance of parallel I/O on clusters using the open source\nparallel virtual file system (PVFS) as testbed and production system. We will\ndescribe the set-up of PVFS on the Alpha-Linux-Cluster-Engine (ALiCE) located\nat Wuppertal University, Germany. Benchmarks on ALiCE achieve\nwrite-performances of up to 1 GB/s from a 32-processor compute-partition to a\n32-processor PVFS I/O-partition, outperforming known benchmark results for PVFS\non the same network by more than a factor of 2. Read-performance from\nbuffer-cache reaches up to 2.2 GB/s. Our benchmarks are giant, I/O-intensive\neigenmode problems from lattice quantum chromodynamics, demonstrating stability\nand performance of PVFS over Parastation in large-scale production runs."
},{
    "category": "cs.DM", 
    "doi": "10.1109/ICEEI.2011.6021782", 
    "link": "http://arxiv.org/pdf/cs/0304045v1", 
    "title": "On a composition of digraphs", 
    "arxiv-id": "cs/0304045v1", 
    "author": "Simone Severini", 
    "publish": "2003-04-30T16:11:30Z", 
    "summary": "Many \"good\" topologies for interconnection networks are based on line\ndigraphs of regular digraphs. These digraphs support unitary matrices. We\npropose the property \"being the digraph of a unitary matrix\" as additional\ncriterion for the design of new interconnection networks. We define a\ncomposition of digraphs, which we call diagonal union. Diagonal union can be\nused to construct digraphs of unitary matrices. We remark that digraphs\nobtained via diagonal union are state split graphs, as defined in symbolic\ndynamics. Finally, we list some potential directions for future research."
},{
    "category": "cs.OS", 
    "doi": "10.1109/ICEEI.2011.6021782", 
    "link": "http://arxiv.org/pdf/cs/0403007v1", 
    "title": "End-User Effects of Microreboots in Three-Tiered Internet Systems", 
    "arxiv-id": "cs/0403007v1", 
    "author": "Armando Fox", 
    "publish": "2004-03-06T02:52:17Z", 
    "summary": "Microreboots restart fine-grained components of software systems \"with a\nclean slate,\" and only take a fraction of the time needed for full system\nreboot. Microreboots provide an application-generic recovery technique for\nInternet services, which can be supported entirely in middleware and requires\nno changes to the applications or any a priori knowledge of application\nsemantics.\n  This paper investigates the effect of microreboots on end-users of an\neBay-like online auction application; we find that microreboots are nearly as\neffective as full reboots, but are significantly less disruptive in terms of\ndowntime and lost work. In our experiments, microreboots reduced the number of\nfailed user requests by 65% and the perceived downtime by 78% compared to a\nserver process restart. We also show how to replace user-visible transient\nfailures with transparent call-retry, at the cost of a slight increase in\nend-user-visible latency during recovery. Due to their low cost, microreboots\ncan be used aggressively, even when their necessity is less than certain, hence\nadding to the reduced recovery time a reduction in the fault detection time,\nwhich further improves availability."
},{
    "category": "cs.NI", 
    "doi": "10.1109/ICEEI.2011.6021782", 
    "link": "http://arxiv.org/pdf/cs/0411019v1", 
    "title": "Programmable Ethernet Switches and Their Applications", 
    "arxiv-id": "cs/0411019v1", 
    "author": "Tzi-cker Chiueh", 
    "publish": "2004-11-08T20:06:09Z", 
    "summary": "Modern Ethernet switches support many advanced features beyond route learning\nand packet forwarding such as VLAN tagging, IGMP snooping, rate limiting, and\nstatus monitoring, which can be controlled through a programmatic interface.\nTraditionally, these features are mostly used to statically configure a\nnetwork. This paper proposes to apply them as dynamic control mechanisms to\nmaximize physical network link resources, to minimize failure recovery time, to\nenforce QoS requirements, and to support link-layer multicast without\nbroadcasting. With these advanced programmable control mechanisms, standard\nEthernet switches can be used as effective building blocks for\nmetropolitan-area Ethernet networks (MEN), storage-area networks (SAN), and\ncomputation cluster interconnects. We demonstrate the usefulness of this new\nlevel of control over Ethernet switches with a MEN architecture that features\nmulti-fold throughput gains and sub-second failure recovery time."
},{
    "category": "cs.NI", 
    "doi": "10.1088/1742-5468/2005/08/P08007", 
    "link": "http://arxiv.org/pdf/cs/0508029v1", 
    "title": "Selfish vs. Unselfish Optimization of Network Creation", 
    "arxiv-id": "cs/0508029v1", 
    "author": "Scott Kirkpatrick", 
    "publish": "2005-08-03T18:16:13Z", 
    "summary": "We investigate several variants of a network creation model: a group of\nagents builds up a network between them while trying to keep the costs of this\nnetwork small. The cost function consists of two addends, namely (i) a constant\namount for each edge an agent buys and (ii) the minimum number of hops it takes\nsending messages to other agents. Despite the simplicity of this model, various\ncomplex network structures emerge depending on the weight between the two\naddends of the cost function and on the selfish or unselfish behaviour of the\nagents."
},{
    "category": "cs.NI", 
    "doi": "10.1088/1742-5468/2005/08/P08007", 
    "link": "http://arxiv.org/pdf/cs/0511012v1", 
    "title": "Parameters Affecting the Resilience of Scale-Free Networks to Random   Failures", 
    "arxiv-id": "cs/0511012v1", 
    "author": "Terran Lane", 
    "publish": "2005-11-02T22:22:14Z", 
    "summary": "It is commonly believed that scale-free networks are robust to massive\nnumbers of random node deletions. For example, Cohen et al. study scale-free\nnetworks including some which approximate the measured degree distribution of\nthe Internet. Their results suggest that if each node in this network failed\nindependently with probability 0.99, the remaining network would continue to\nhave a giant component. In this paper, we show that a large and important\nsubclass of scale-free networks are not robust to massive numbers of random\nnode deletions for practical purposes. In particular, we study finite\nscale-free networks which have minimum node degree of 1 and a power-law degree\ndistribution beginning with nodes of degree 1 (power-law networks). We show\nthat, in a power-law network approximating the Internet's reported\ndistribution, when the probability of deletion of each node is 0.5 only about\n25% of the surviving nodes in the network remain connected in a giant\ncomponent, and the giant component does not persist beyond a critical failure\nrate of 0.9. The new result is partially due to improved analytical\naccommodation of the large number of degree-0 nodes that result after node\ndeletions. Our results apply to finite power-law networks with a wide range of\npower-law exponents, including Internet-like networks. We give both analytical\nand empirical evidence that such networks are not generally robust to massive\nrandom node deletions."
},{
    "category": "cs.CR", 
    "doi": "10.1088/1742-5468/2005/08/P08007", 
    "link": "http://arxiv.org/pdf/cs/0605034v1", 
    "title": "Peer to Peer Networks for Defense Against Internet Worms", 
    "arxiv-id": "cs/0605034v1", 
    "author": "R. Srikant", 
    "publish": "2006-05-08T17:02:28Z", 
    "summary": "Internet worms, which spread in computer networks without human mediation,\npose a severe threat to computer systems today. The rate of propagation of\nworms has been measured to be extremely high and they can infect a large\nfraction of their potential hosts in a short time. We study two different\nmethods of patch dissemination to combat the spread of worms. We first show\nthat using a fixed number of patch servers performs woefully inadequately\nagainst Internet worms. We then show that by exploiting the exponential data\ndissemination capability of P2P systems, the spread of worms can be halted very\neffectively. We compare the two methods by using fluid models to compute two\nquantities of interest: the time taken to effectively combat the progress of\nthe worm and the maximum number of infected hosts. We validate our models using\nInternet measurements and simulations."
},{
    "category": "cs.AR", 
    "doi": "10.1088/1742-5468/2005/08/P08007", 
    "link": "http://arxiv.org/pdf/cs/0605039v4", 
    "title": "Fast and Generalized Polynomial Time Memory Consistency Verification", 
    "arxiv-id": "cs/0605039v4", 
    "author": "John C. Huang", 
    "publish": "2006-05-09T05:45:52Z", 
    "summary": "The problem of verifying multi-threaded execution against the memory\nconsistency model of a processor is known to be an NP hard problem. However\npolynomial time algorithms exist that detect almost all failures in such\nexecution. These are often used in practice for microprocessor verification. We\npresent a low complexity and fully parallelized algorithm to check program\nexecution against the processor consistency model. In addition our algorithm is\ngeneral enough to support a number of consistency models without any\ndegradation in performance. An implementation of this algorithm is currently\nused in practice to verify processors in the post silicon stage for multiple\narchitectures."
},{
    "category": "cs.DC", 
    "doi": "10.1088/1742-5468/2005/08/P08007", 
    "link": "http://arxiv.org/pdf/cs/0608061v5", 
    "title": "Concurrent Processing Memory", 
    "arxiv-id": "cs/0608061v5", 
    "author": "Chengpu Wang", 
    "publish": "2006-08-15T01:42:49Z", 
    "summary": "A theoretical memory with limited processing power and internal connectivity\nat each element is proposed. This memory carries out parallel processing within\nitself to solve generic array problems. The applicability of this in-memory\nfinest-grain massive SIMD approach is studied in some details. For an array of\nN items, it reduces the total instruction cycle count of universal operations\nsuch as insertion/deletion and match finding to ~ 1, local operations such as\nfiltering and template matching to ~ local operation size, and global\noperations such as sum, finding global limit and sorting to ~\\sqroot{N}\ninstruction cycles. It eliminates most streaming activities for data processing\npurpose on the system bus. Yet it remains general-purposed, easy to use, pin\ncompatible with conventional memory, and practical for implementation."
},{
    "category": "cs.NI", 
    "doi": "10.1088/1742-5468/2005/08/P08007", 
    "link": "http://arxiv.org/pdf/cs/0608077v1", 
    "title": "The Effect of Scheduling on Link Capacity in Multi-hopWireless Networks", 
    "arxiv-id": "cs/0608077v1", 
    "author": "Nael Abu-Ghazaleh", 
    "publish": "2006-08-18T16:45:33Z", 
    "summary": "Existing models of Multi-Hop Wireless Networks (MHWNs) assume that\ninterference estimators of link quality such as observed busy time predict the\ncapacity of the links. We show that these estimators do not capture the\nintricate interactions that occur at the scheduling level, which have a large\nimpact on effective link capacity under contention based MAC protocols. We\nobserve that scheduling problems arise only among those interfering sources\nwhose concurrent transmissions cannot be prevented by the MAC protocol's\ncollision management mechanisms; other interfering sources can arbitrate the\nmedium and coexist successfully. Based on this observation, we propose a\nmethodology for rating links and show that it achieves high correlation with\nobserved behavior in simulation. We then use this rating as part of a\nbranch-and-bound framework based on a linear programming formulation for\ntraffic engineering in static MHWNs and show that it achieves considerable\nimprovement in performance relative to interference based models."
},{
    "category": "cs.DC", 
    "doi": "10.1088/1742-5468/2005/08/P08007", 
    "link": "http://arxiv.org/pdf/cs/0609074v1", 
    "title": "A Non-anchored Unified Naming System for Ad Hoc Computing Environments", 
    "arxiv-id": "cs/0609074v1", 
    "author": "Dongman Lee", 
    "publish": "2006-09-13T12:52:45Z", 
    "summary": "A ubiquitous computing environment consists of many resources that need to be\nidentified by users and applications. Users and developers require some way to\nidentify resources by human readable names. In addition, ubiquitous computing\nenvironments impose additional requirements such as the ability to work well\nwith ad hoc situations and the provision of names that depend on context.\n  The Non-anchored Unified Naming (NUN) system was designed to satisfy these\nrequirements. It is based on relative naming among resources and provides the\nability to name arbitrary types of resources. By having resources themselves\ntake part in naming, resources are able to able contribute their specialized\nknowledge into the name resolution process, making context-dependent mapping of\nnames to resources possible. The ease of which new resource types can be added\nmakes it simple to incorporate new types of contextual information within\nnames.\n  In this paper, we describe the naming system and evaluate its use."
},{
    "category": "cs.CG", 
    "doi": "10.1088/1742-5468/2005/08/P08007", 
    "link": "http://arxiv.org/pdf/cs/0612121v1", 
    "title": "Power Assignment Problems in Wireless Communication", 
    "arxiv-id": "cs/0612121v1", 
    "author": "Rouven Naujoks", 
    "publish": "2006-12-22T12:53:15Z", 
    "summary": "A fundamental class of problems in wireless communication is concerned with\nthe assignment of suitable transmission powers to wireless devices/stations\nsuch that the resulting communication graph satisfies certain desired\nproperties and the overall energy consumed is minimized. Many concrete\ncommunication tasks in a wireless network like broadcast, multicast,\npoint-to-point routing, creation of a communication backbone, etc. can be\nregarded as such a power assignment problem.\n  This paper considers several problems of that kind; for example one problem\nstudied before in \\cite{Carrots, Bilo} aims to select and assign powers to $k$\nof the stations such that all other stations are within reach of at least one\nof the selected stations. We improve the running time for obtaining a\n$(1+\\epsilon)$-approximate solution for this problem from\n$n^{((\\alpha/\\epsilon)^{O(d)})}$ as reported by Bilo et al. (\\cite{Bilo}) to\n$O(n+ {(\\frac{k^{2d+1}}{\\epsilon^d})}^{\\min{\\{2k, (\\alpha/\\epsilon)^{O(d)}\n\\}}})$ that is, we obtain a running time that is \\emph{linear} in the network\nsize. Further results include a constant approximation algorithm for the TSP\nproblem under squared (non-metric!) edge costs, which can be employed to\nimplement a novel data aggregation protocol, as well as efficient schemes to\nperform $k$-hop multicasts."
},{
    "category": "cs.NI", 
    "doi": "10.1088/1742-5468/2005/08/P08007", 
    "link": "http://arxiv.org/pdf/cs/0701130v1", 
    "title": "On the Correlation of Geographic and Network Proximity at Internet Edges   and its Implications for Mobile Unicast and Multicast Routing", 
    "arxiv-id": "cs/0701130v1", 
    "author": "Ying Zhang", 
    "publish": "2007-01-20T23:06:57Z", 
    "summary": "Significant effort has been invested recently to accelerate handover\noperations in a next generation mobile Internet. Corresponding works for\ndeveloping efficient mobile multicast management are emergent. Both problems\nsimultaneously expose routing complexity between subsequent points of\nattachment as a characteristic parameter for handover performance in access\nnetworks.\n  As continuous mobility handovers necessarily occur between access routers\nlocated in geographic vicinity, this paper investigates on the hypothesis that\ngeographically adjacent edge networks attain a reduced network distances as\ncompared to arbitrary Internet nodes. We therefore evaluate and analyze edge\ndistance distributions in various regions for clustered IP ranges on their\ngeographic location such as a city. We use traceroute to collect packet\nforwarding path and round-trip-time of each intermediate node to scan-wise\nderive an upper bound of the node distances. Results of different scanning\norigins are compared to obtain the best estimation of network distance of each\npair. Our results are compared with corresponding analysis of CAIDA Skitter\ndata, overall leading to fairly stable, reproducible edge distance\ndistributions. As a first conclusion on expected impact on handover performance\nmeasures, our results indicate a general optimum for handover anticipation time\nin 802.11 networks of 25 ms."
},{
    "category": "q-bio.NC", 
    "doi": "10.1088/1742-5468/2005/08/P08007", 
    "link": "http://arxiv.org/pdf/q-bio/0505021v1", 
    "title": "Characterizing Self-Developing Biological Neural Networks: A First Step   Towards their Application To Computing Systems", 
    "arxiv-id": "q-bio/0505021v1", 
    "author": "Olivier Temam", 
    "publish": "2005-05-10T19:51:16Z", 
    "summary": "Carbon nanotubes are often seen as the only alternative technology to silicon\ntransistors. While they are the most likely short-term one, other longer-term\nalternatives should be studied as well. While contemplating biological neurons\nas an alternative component may seem preposterous at first sight, significant\nrecent progress in CMOS-neuron interface suggests this direction may not be\nunrealistic; moreover, biological neurons are known to self-assemble into very\nlarge networks capable of complex information processing tasks, something that\nhas yet to be achieved with other emerging technologies. The first step to\ndesigning computing systems on top of biological neurons is to build an\nabstract model of self-assembled biological neural networks, much like computer\narchitects manipulate abstract models of transistors and circuits. In this\narticle, we propose a first model of the structure of biological neural\nnetworks. We provide empirical evidence that this model matches the biological\nneural networks found in living organisms, and exhibits the small-world graph\nstructure properties commonly found in many large and self-organized systems,\nincluding biological neural networks. More importantly, we extract the simple\nlocal rules and characteristics governing the growth of such networks, enabling\nthe development of potentially large but realistic biological neural networks,\nas would be needed for complex information processing/computing tasks. Based on\nthis model, future work will be targeted to understanding the evolution and\nlearning properties of such networks, and how they can be used to build\ncomputing systems."
},{
    "category": "cs.IT", 
    "doi": "10.1088/1742-5468/2005/08/P08007", 
    "link": "http://arxiv.org/pdf/0704.0967v1", 
    "title": "Cross-Layer Optimization of MIMO-Based Mesh Networks with Gaussian   Vector Broadcast Channels", 
    "arxiv-id": "0704.0967v1", 
    "author": "Y. Thomas Hou", 
    "publish": "2007-04-07T03:18:46Z", 
    "summary": "MIMO technology is one of the most significant advances in the past decade to\nincrease channel capacity and has a great potential to improve network capacity\nfor mesh networks. In a MIMO-based mesh network, the links outgoing from each\nnode sharing the common communication spectrum can be modeled as a Gaussian\nvector broadcast channel. Recently, researchers showed that ``dirty paper\ncoding'' (DPC) is the optimal transmission strategy for Gaussian vector\nbroadcast channels. So far, there has been little study on how this fundamental\nresult will impact the cross-layer design for MIMO-based mesh networks. To fill\nthis gap, we consider the problem of jointly optimizing DPC power allocation in\nthe link layer at each node and multihop/multipath routing in a MIMO-based mesh\nnetworks. It turns out that this optimization problem is a very challenging\nnon-convex problem. To address this difficulty, we transform the original\nproblem to an equivalent problem by exploiting the channel duality. For the\ntransformed problem, we develop an efficient solution procedure that integrates\nLagrangian dual decomposition method, conjugate gradient projection method\nbased on matrix differential calculus, cutting-plane method, and subgradient\nmethod. In our numerical example, it is shown that we can achieve a network\nperformance gain of 34.4% by using DPC."
},{
    "category": "cs.AR", 
    "doi": "10.1063/1.2740566", 
    "link": "http://arxiv.org/pdf/0704.2852v1", 
    "title": "Nature-Inspired Interconnects for Self-Assembled Large-Scale   Network-on-Chip Designs", 
    "arxiv-id": "0704.2852v1", 
    "author": "Christof Teuscher", 
    "publish": "2007-04-21T21:26:03Z", 
    "summary": "Future nano-scale electronics built up from an Avogadro number of components\nneeds efficient, highly scalable, and robust means of communication in order to\nbe competitive with traditional silicon approaches. In recent years, the\nNetworks-on-Chip (NoC) paradigm emerged as a promising solution to interconnect\nchallenges in silicon-based electronics. Current NoC architectures are either\nhighly regular or fully customized, both of which represent implausible\nassumptions for emerging bottom-up self-assembled molecular electronics that\nare generally assumed to have a high degree of irregularity and imperfection.\nHere, we pragmatically and experimentally investigate important design\ntrade-offs and properties of an irregular, abstract, yet physically plausible\n3D small-world interconnect fabric that is inspired by modern network-on-chip\nparadigms. We vary the framework's key parameters, such as the connectivity,\nthe number of switch nodes, the distribution of long- versus short-range\nconnections, and measure the network's relevant communication characteristics.\nWe further explore the robustness against link failures and the ability and\nefficiency to solve a simple toy problem, the synchronization task. The results\nconfirm that (1) computation in irregular assemblies is a promising and\ndisruptive computing paradigm for self-assembled nano-scale electronics and (2)\nthat 3D small-world interconnect fabrics with a power-law decaying distribution\nof shortcut lengths are physically plausible and have major advantages over\nlocal 2D and 3D regular topologies."
},{
    "category": "cs.NI", 
    "doi": "10.1063/1.2740566", 
    "link": "http://arxiv.org/pdf/0706.1130v1", 
    "title": "A Communication Model for Adaptive Service Provisioning in Hybrid   Wireless Networks", 
    "arxiv-id": "0706.1130v1", 
    "author": "Steffen Rothkugel", 
    "publish": "2007-06-08T08:23:14Z", 
    "summary": "Mobile entities with wireless links are able to form a mobile ad-hoc network.\nSuch an infrastructureless network does not have to be administrated. However,\nself-organizing principles have to be applied to deal with upcoming problems,\ne.g. information dissemination. These kinds of problems are not easy to tackle,\nrequiring complex algorithms. Moreover, the usefulness of pure ad-hoc networks\nis arguably limited. Hence, enthusiasm for mobile ad-hoc networks, which could\neliminate the need for any fixed infrastructure, has been damped. The goal is\nto overcome the limitations of pure ad-hoc networks by augmenting them with\ninstant Internet access, e.g. via integration of UMTS respectively GSM links.\nHowever, this raises multiple questions at the technical as well as the\norganizational level. Motivated by characteristics of small-world networks that\ndescribe an efficient network even without central or organized design, this\npaper proposes to combine mobile ad-hoc networks and infrastructured networks\nto form hybrid wireless networks. One main objective is to investigate how this\napproach can reduce the costs of a permanent backbone link and providing in the\nsame way the benefits of useful information from Internet connectivity or\nservice providers. For the purpose of bridging between the different types of\nnetworks, an adequate middleware service is the focus of our investigation.\nThis paper shows our first steps forward to this middleware by introducing the\nInjection Communication paradigm as principal concept."
},{
    "category": "cs.AR", 
    "doi": "10.1063/1.2740566", 
    "link": "http://arxiv.org/pdf/0706.3009v1", 
    "title": "Application of a design space exploration tool to enhance interleaver   generation", 
    "arxiv-id": "0706.3009v1", 
    "author": "Eric Martin", 
    "publish": "2007-06-20T15:19:01Z", 
    "summary": "This paper presents a methodology to efficiently explore the design space of\ncommunication adapters. In most digital signal processing (DSP) applications,\nthe overall performance of the system is significantly affected by\ncommunication architectures, as a consequence the designers need specifically\noptimized adapters. By explicitly modeling these communications within an\neffective graph-theoretic model and analysis framework, we automatically\ngenerate an optimized architecture, named Space-Time AdapteR (STAR). Our design\nflow inputs a C description of Input/Output data scheduling, and user\nrequirements (throughput, latency, parallelism...), and formalizes\ncommunication constraints through a Resource Constraints Graph (RCG). Design\nspace exploration is then performed through associated tools, to synthesize a\nSTAR component under time-to-market constraints. The proposed approach has been\ntested to design an industrial data mixing block example: an Ultra-Wideband\ninterleaver."
},{
    "category": "cs.AR", 
    "doi": "10.1007/s11047-007-9059-3", 
    "link": "http://arxiv.org/pdf/0708.1964v1", 
    "title": "Solving the subset-sum problem with a light-based device", 
    "arxiv-id": "0708.1964v1", 
    "author": "Oana Muntean", 
    "publish": "2007-08-14T21:46:32Z", 
    "summary": "We propose a special computational device which uses light rays for solving\nthe subset-sum problem. The device has a graph-like representation and the\nlight is traversing it by following the routes given by the connections between\nnodes. The nodes are connected by arcs in a special way which lets us to\ngenerate all possible subsets of the given set. To each arc we assign either a\nnumber from the given set or a predefined constant. When the light is passing\nthrough an arc it is delayed by the amount of time indicated by the number\nplaced in that arc. At the destination node we will check if there is a ray\nwhose total delay is equal to the target value of the subset sum problem (plus\nsome constants)."
},{
    "category": "cs.AR", 
    "doi": "10.1145/1233501.1233575", 
    "link": "http://arxiv.org/pdf/0712.2640v1", 
    "title": "Optimal Memoryless Encoding for Low Power Off-Chip Data Buses", 
    "arxiv-id": "0712.2640v1", 
    "author": "Alan C. H. Ling", 
    "publish": "2007-12-17T06:37:11Z", 
    "summary": "Off-chip buses account for a significant portion of the total system power\nconsumed in embedded systems. Bus encoding schemes have been proposed to\nminimize power dissipation, but none has been demonstrated to be optimal with\nrespect to any measure. In this paper, we give the first provably optimal and\nexplicit (polynomial-time constructible) families of memoryless codes for\nminimizing bit transitions in off-chip buses. Our results imply that having\naccess to a clock does not make a memoryless encoding scheme that minimizes bit\ntransitions more powerful."
},{
    "category": "cs.AR", 
    "doi": "10.1109/NANOARCH.2008.4585787", 
    "link": "http://arxiv.org/pdf/0805.2684v1", 
    "title": "Assessing Random Dynamical Network Architectures for Nanoelectronics", 
    "arxiv-id": "0805.2684v1", 
    "author": "Thimo Rohlf", 
    "publish": "2008-05-17T16:22:27Z", 
    "summary": "Independent of the technology, it is generally expected that future nanoscale\ndevices will be built from vast numbers of densely arranged devices that\nexhibit high failure rates. Other than that, there is little consensus on what\ntype of technology and computing architecture holds most promises to go far\nbeyond today's top-down engineered silicon devices. Cellular automata (CA) have\nbeen proposed in the past as a possible class of architectures to the von\nNeumann computing architecture, which is not generally well suited for future\nparallel and fine-grained nanoscale electronics. While the top-down engineered\nsemi-conducting technology favors regular and locally interconnected\nstructures, future bottom-up self-assembled devices tend to have irregular\nstructures because of the current lack precise control over these processes. In\nthis paper, we will assess random dynamical networks, namely Random Boolean\nNetworks (RBNs) and Random Threshold Networks (RTNs), as alternative computing\narchitectures and models for future information processing devices. We will\nillustrate that--from a theoretical perspective--they offer superior properties\nover classical CA-based architectures, such as inherent robustness as the\nsystem scales up, more efficient information processing capabilities, and\nmanufacturing benefits for bottom-up designed devices, which motivates this\ninvestigation. We will present recent results on the dynamic behavior and\nrobustness of such random dynamical networks while also including manufacturing\nissues in the assessment."
},{
    "category": "cs.DC", 
    "doi": "10.1109/NANOARCH.2008.4585787", 
    "link": "http://arxiv.org/pdf/0811.1304v1", 
    "title": "NB-FEB: An Easy-to-Use and Scalable Universal Synchronization Primitive   for Parallel Programming", 
    "arxiv-id": "0811.1304v1", 
    "author": "Otto J. Anshus", 
    "publish": "2008-11-09T00:41:07Z", 
    "summary": "This paper addresses the problem of universal synchronization primitives that\ncan support scalable thread synchronization for large-scale many-core\narchitectures. The universal synchronization primitives that have been deployed\nwidely in conventional architectures like CAS and LL/SC are expected to reach\ntheir scalability limits in the evolution to many-core architectures with\nthousands of cores. We introduce a non-blocking full/empty bit primitive, or\nNB-FEB for short, as a promising synchronization primitive for parallel\nprogramming on may-core architectures. We show that the NB-FEB primitive is\nuniversal, scalable, feasible and convenient to use. NB-FEB, together with\nregisters, can solve the consensus problem for an arbitrary number of processes\n(universality). NB-FEB is combinable, namely its memory requests to the same\nmemory location can be combined into only one memory request, which\nconsequently mitigates performance degradation due to synchronization \"hot\nspots\" (scalability). Since NB-FEB is a variant of the original full/empty bit\nthat always returns a value instead of waiting for a conditional flag, it is as\nfeasible as the original full/empty bit, which has been implemented in many\ncomputer systems (feasibility). The original full/empty bit is well-known as a\nspecial-purpose primitive for fast producer-consumer synchronization and has\nbeen used extensively in the specific domain of applications. In this paper, we\nshow that NB-FEB can be deployed easily as a general-purpose primitive. Using\nNB-FEB, we construct a non-blocking software transactional memory system called\nNBFEB-STM, which can be used to handle concurrent threads conveniently.\nNBFEB-STM is space efficient: the space complexity of each object updated by\n$N$ concurrent threads/transactions is $\\Theta(N)$, the optimal."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TC.2008.130", 
    "link": "http://arxiv.org/pdf/0901.4694v1", 
    "title": "Limit on the Addressability of Fault-Tolerant Nanowire Decoders", 
    "arxiv-id": "0901.4694v1", 
    "author": "Alan C. H. Ling", 
    "publish": "2009-01-29T14:46:48Z", 
    "summary": "Although prone to fabrication error, the nanowire crossbar is a promising\ncandidate component for next generation nanometer-scale circuits. In the\nnanowire crossbar architecture, nanowires are addressed by controlling voltages\non the mesowires. For area efficiency, we are interested in the maximum number\nof nanowires $N(m,e)$ that can be addressed by $m$ mesowires, in the face of up\nto $e$ fabrication errors. Asymptotically tight bounds on $N(m,e)$ are\nestablished in this paper. In particular, it is shown that $N(m,e) = \\Theta(2^m\n/ m^{e+1/2})$. Interesting observations are made on the equivalence between\nthis problem and the problem of constructing optimal EC/AUED codes,\nsuperimposed distance codes, pooling designs, and diffbounded set systems.\nResults in this paper also improve upon those in the EC/AUEC codes literature."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TC.2008.130", 
    "link": "http://arxiv.org/pdf/0904.3148v1", 
    "title": "CRT-Based High Speed Parallel Architecture for Long BCH Encoding", 
    "arxiv-id": "0904.3148v1", 
    "author": "Hao Chen", 
    "publish": "2009-04-21T00:34:43Z", 
    "summary": "BCH (Bose-Chaudhuri-Hocquenghen) error correcting codes ([1]-[2]) are now\nwidely used in communication systems and digital technology. Direct LFSR(linear\nfeedback shifted register)-based encoding of a long BCH code suffers from\nserial-in and serial-out limitation and large fanout effect of some XOR gates.\nThis makes the LFSR-based encoders of long BCH codes cannot keep up with the\ndata transmission speed in some applications. Several parallel long parallel\nencoders for long cyclic codes have been proposed in [3]-[8]. The technique for\neliminating the large fanout effect by J-unfolding method and some algebraic\nmanipulation was presented in [7] and [8] . In this paper we propose a\nCRT(Chinese Remainder Theorem)-based parallel architecture for long BCH\nencoding. Our novel technique can be used to eliminate the fanout bottleneck.\nThe only restriction on the speed of long BCH encoding of our CRT-based\narchitecture is $log_2N$, where $N$ is the length of the BCH code."
},{
    "category": "cs.IT", 
    "doi": "10.1109/TSP.2010.2050480", 
    "link": "http://arxiv.org/pdf/0904.4526v1", 
    "title": "Feasibility Conditions for Interference Alignment", 
    "arxiv-id": "0904.4526v1", 
    "author": "Ahmet H. Kayran", 
    "publish": "2009-04-29T03:11:52Z", 
    "summary": "The degrees of freedom of MIMO interference networks with constant channel\ncoefficients are not known in general. Determining the feasibility of a linear\ninterference alignment solution is a key step toward solving this open problem.\nOur approach in this paper is to view the alignment problem as a system of\nbilinear equations and determine its solvability by comparing the number of\nequations and the number of variables. To this end, we divide interference\nalignment problems into two classes - proper and improper. An interference\nalignment problem is called proper if the number of equations does not exceed\nthe number of variables. Otherwise, it is called improper. Examples are\npresented to support the intuition that for generic channel matrices, proper\nsystems are almost surely feasible and improper systems are almost surely\ninfeasible."
},{
    "category": "cs.DC", 
    "doi": "10.1109/TSP.2010.2050480", 
    "link": "http://arxiv.org/pdf/1001.2262v1", 
    "title": "Classifying Application Phases in Asymmetric Chip Multiprocessors", 
    "arxiv-id": "1001.2262v1", 
    "author": "M. Analoui", 
    "publish": "2010-01-13T18:47:44Z", 
    "summary": "In present study, in order to improve the performance and reduce the amount\nof power which is dissipated in heterogeneous multicore processors, the ability\nof detecting the program execution phases is investigated. The programs\nexecution intervals have been classified in different phases based on their\nthroughput and the utilization of the cores. The results of implementing the\nphase detection technique are investigated on a single core processor and also\non a multicore processor. To minimize the profiling overhead, an algorithm for\nthe dynamic adjustment of the profiling intervals is presented. It is based on\nthe behavior of the program and reduces the profiling overhead more than three\nfold. The results are obtained from executing multiprocessor benchmarks on a\ngiven processor. In order to show the program phases clearly, throughput and\nutilization of execution intervals are presented on a scatter plot. The results\nare presented for both fixed and variable intervals."
},{
    "category": "cs.DC", 
    "doi": "10.4204/EPTCS.17.6", 
    "link": "http://arxiv.org/pdf/1002.0939v1", 
    "title": "Virtual Machine Support for Many-Core Architectures: Decoupling Abstract   from Concrete Concurrency Models", 
    "arxiv-id": "1002.0939v1", 
    "author": "Wolfgang De Meuter", 
    "publish": "2010-02-04T09:48:53Z", 
    "summary": "The upcoming many-core architectures require software developers to exploit\nconcurrency to utilize available computational power. Today's high-level\nlanguage virtual machines (VMs), which are a cornerstone of software\ndevelopment, do not provide sufficient abstraction for concurrency concepts. We\nanalyze concrete and abstract concurrency models and identify the challenges\nthey impose for VMs. To provide sufficient concurrency support in VMs, we\npropose to integrate concurrency operations into VM instruction sets.\n  Since there will always be VMs optimized for special purposes, our goal is to\ndevelop a methodology to design instruction sets with concurrency support.\nTherefore, we also propose a list of trade-offs that have to be investigated to\nadvise the design of such instruction sets.\n  As a first experiment, we implemented one instruction set extension for\nshared memory and one for non-shared memory concurrency. From our experimental\nresults, we derived a list of requirements for a full-grown experimental\nenvironment for further research."
},{
    "category": "cs.AR", 
    "doi": "10.4204/EPTCS.17.6", 
    "link": "http://arxiv.org/pdf/1002.3990v1", 
    "title": "Static Address Generation Easing: a Design Methodology for Parallel   Interleaver Architectures", 
    "arxiv-id": "1002.3990v1", 
    "author": "Pascal Urard", 
    "publish": "2010-02-21T18:51:31Z", 
    "summary": "For high throughput applications, turbo-like iterative decoders are\nimplemented with parallel architectures. However, to be efficient parallel\narchitectures require to avoid collision accesses i.e. concurrent read/write\naccesses should not target the same memory block. This consideration applies to\nthe two main classes of turbo-like codes which are Low Density Parity Check\n(LDPC) and Turbo-Codes. In this paper we propose a methodology which finds a\ncollision-free mapping of the variables in the memory banks and which optimizes\nthe resulting interleaving architecture. Finally, we show through a pedagogical\nexample the interest of our approach compared to state-of-the-art techniques."
},{
    "category": "cs.IT", 
    "doi": "10.4204/EPTCS.17.6", 
    "link": "http://arxiv.org/pdf/1003.3792v1", 
    "title": "On Complexity, Energy- and Implementation-Efficiency of Channel Decoders", 
    "arxiv-id": "1003.3792v1", 
    "author": "Heinrich Meyr", 
    "publish": "2010-03-19T13:41:21Z", 
    "summary": "Future wireless communication systems require efficient and flexible baseband\nreceivers. Meaningful efficiency metrics are key for design space exploration\nto quantify the algorithmic and the implementation complexity of a receiver.\nMost of the current established efficiency metrics are based on counting\noperations, thus neglecting important issues like data and storage complexity.\nIn this paper we introduce suitable energy and area efficiency metrics which\nresolve the afore-mentioned disadvantages. These are decoded information bit\nper energy and throughput per area unit. Efficiency metrics are assessed by\nvarious implementations of turbo decoders, LDPC decoders and convolutional\ndecoders. New exploration methodologies are presented, which permit an\nappropriate benchmarking of implementation efficiency, communications\nperformance, and flexibility trade-offs. These exploration methodologies are\nbased on efficiency trajectories rather than a single snapshot metric as done\nin state-of-the-art approaches."
},{
    "category": "cs.IT", 
    "doi": "10.1587/transfun.E93.A.1949", 
    "link": "http://arxiv.org/pdf/1008.4370v1", 
    "title": "Fourier Domain Decoding Algorithm of Non-Binary LDPC codes for Parallel   Implementation", 
    "arxiv-id": "1008.4370v1", 
    "author": "Kohichi Sakaniwa", 
    "publish": "2010-08-25T20:23:56Z", 
    "summary": "For decoding non-binary low-density parity check (LDPC) codes,\nlogarithm-domain sum-product (Log-SP) algorithms were proposed for reducing\nquantization effects of SP algorithm in conjunction with FFT. Since FFT is not\napplicable in the logarithm domain, the computations required at check nodes in\nthe Log-SP algorithms are computationally intensive. What is worth, check nodes\nusually have higher degree than variable nodes. As a result, most of the time\nfor decoding is used for check node computations, which leads to a bottleneck\neffect. In this paper, we propose a Log-SP algorithm in the Fourier domain.\nWith this algorithm, the role of variable nodes and check nodes are switched.\nThe intensive computations are spread over lower-degree variable nodes, which\ncan be efficiently calculated in parallel. Furthermore, we develop a fast\ncalculation method for the estimated bits and syndromes in the Fourier domain."
},{
    "category": "cs.LG", 
    "doi": "10.1109/TFUZZ.2011.2160024", 
    "link": "http://arxiv.org/pdf/1008.5133v2", 
    "title": "Memristor Crossbar-based Hardware Implementation of IDS Method", 
    "arxiv-id": "1008.5133v2", 
    "author": "Ali Rohani", 
    "publish": "2010-08-22T16:44:23Z", 
    "summary": "Ink Drop Spread (IDS) is the engine of Active Learning Method (ALM), which is\nthe methodology of soft computing. IDS, as a pattern-based processing unit,\nextracts useful information from a system subjected to modeling. In spite of\nits excellent potential in solving problems such as classification and modeling\ncompared to other soft computing tools, finding its simple and fast hardware\nimplementation is still a challenge. This paper describes a new hardware\nimplementation of IDS method based on the memristor crossbar structure. In\naddition of simplicity, being completely real-time, having low latency and the\nability to continue working after the occurrence of power breakdown are some of\nthe advantages of our proposed circuit."
},{
    "category": "cs.NE", 
    "doi": "10.1109/TFUZZ.2011.2160024", 
    "link": "http://arxiv.org/pdf/1009.0896v1", 
    "title": "Memristor Crossbar-based Hardware Implementation of Fuzzy Membership   Functions", 
    "arxiv-id": "1009.0896v1", 
    "author": "Saeed Bagheri Shouraki", 
    "publish": "2010-09-05T07:46:47Z", 
    "summary": "In May 1, 2008, researchers at Hewlett Packard (HP) announced the first\nphysical realization of a fundamental circuit element called memristor that\nattracted so much interest worldwide. This newly found element can easily be\ncombined with crossbar interconnect technology which this new structure has\nopened a new field in designing configurable or programmable electronic\nsystems. These systems in return can have applications in signal processing and\nartificial intelligence. In this paper, based on the simple memristor crossbar\nstructure, we propose new and simple circuits for hardware implementation of\nfuzzy membership functions. In our proposed circuits, these fuzzy membership\nfunctions can have any shapes and resolutions. In addition, these circuits can\nbe used as a basis in the construction of evolutionary systems."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TFUZZ.2011.2160024", 
    "link": "http://arxiv.org/pdf/1009.1305v1", 
    "title": "Wideband Spectrum Sensing at Sub-Nyquist Rates", 
    "arxiv-id": "1009.1305v1", 
    "author": "Yonina C. Eldar", 
    "publish": "2010-09-07T14:26:09Z", 
    "summary": "We present a mixed analog-digital spectrum sensing method that is especially\nsuited to the typical wideband setting of cognitive radio (CR). The advantages\nof our system with respect to current architectures are threefold. First, our\nanalog front-end is fixed and does not involve scanning hardware. Second, both\nthe analog-to-digital conversion (ADC) and the digital signal processing (DSP)\nrates are substantially below Nyquist. Finally, the sensing resources are\nshared with the reception path of the CR, so that the lowrate streaming samples\ncan be used for communication purposes of the device, besides the sensing\nfunctionality they provide. Combining these advantages leads to a real time map\nof the spectrum with minimal use of mobile resources. Our approach is based on\nthe modulated wideband converter (MWC) system, which samples sparse wideband\ninputs at sub-Nyquist rates. We report on results of hardware experiments,\nconducted on an MWC prototype circuit, which affirm fast and accurate spectrum\nsensing in parallel to CR communication."
},{
    "category": "cs.SY", 
    "doi": "10.1109/TFUZZ.2011.2160024", 
    "link": "http://arxiv.org/pdf/1010.4065v1", 
    "title": "Model-Based Development of Distributed Embedded Systems by the Example   of the Scicos/SynDEx Framework", 
    "arxiv-id": "1010.4065v1", 
    "author": "Bernhard Fischer", 
    "publish": "2010-10-19T22:25:36Z", 
    "summary": "The embedded systems engineering industry faces increasing demands for more\nfunctionality, rapidly evolving components, and shrinking schedules. Abilities\nto quickly adapt to changes, develop products with safe design, minimize\nproject costs, and deliver timely are needed. Model-based development (MBD)\nfollows a separation of concerns by abstracting systems with an appropriate\nintensity. MBD promises higher comprehension by modeling on several\nabstraction-levels, formal verification, and automated code generation. This\nthesis demonstrates MBD with the Scicos/SynDEx framework on a distributed\nembedded system. Scicos is a modeling and simulation environment for hybrid\nsystems. SynDEx is a rapid prototyping integrated development environment for\ndistributed systems. Performed examples implement well-known control algorithms\non a target system containing several networked microcontrollers, sensors, and\nactuators. The addressed research question tackles the feasibility of MBD for\nmedium-sized embedded systems. In the case of single-processor applications\nexperiments show that the comforts of tool-provided simulation, verification,\nand code-generation have to be weighed against an additional memory consumption\nin dynamic and static memory compared to a hand-written approach. Establishing\na near-seamless modeling-framework with Scicos/SynDEx is expensive. An\nincreased development effort indicates a high price for developing single\napplications, but might pay off for product families. A further drawback was\nthat the distributed code generated with SynDEx could not be adapted to\nmicrocontrollers without a significant alteration of the scheduling tables. The\nScicos/SynDEx framework forms a valuable tool set that, however, still needs\nmany improvements. Therefore, its usage is only recommended for experimental\npurposes."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TFUZZ.2011.2160024", 
    "link": "http://arxiv.org/pdf/1011.2919v1", 
    "title": "Hardware architectures for Successive Cancellation Decoding of Polar   Codes", 
    "arxiv-id": "1011.2919v1", 
    "author": "Warren J. Gross", 
    "publish": "2010-11-12T14:38:52Z", 
    "summary": "The recently-discovered polar codes are widely seen as a major breakthrough\nin coding theory. These codes achieve the capacity of many important channels\nunder successive cancellation decoding. Motivated by the rapid progress in the\ntheory of polar codes, we propose a family of architectures for efficient\nhardware implementation of successive cancellation decoders. We show that such\ndecoders can be implemented with O(n) processing elements and O(n) memory\nelements, while providing constant throughput. We also propose a technique for\noverlapping the decoding of several consecutive codewords, thereby achieving a\nsignificant speed-up factor. We furthermore show that successive cancellation\ndecoding can be implemented in the logarithmic domain, thereby eliminating the\nmultiplication and division operations and greatly reducing the complexity of\neach processing element."
},{
    "category": "cs.IT", 
    "doi": "10.1109/TFUZZ.2011.2160024", 
    "link": "http://arxiv.org/pdf/1011.4109v2", 
    "title": "Design and simulation of a sigma delta ADC", 
    "arxiv-id": "1011.4109v2", 
    "author": "Moslem Rashidi", 
    "publish": "2010-11-17T23:56:51Z", 
    "summary": "In this report we describe the design and simulation of a Sigma Delta ADC in\nMatlan/Simulink"
},{
    "category": "cs.DC", 
    "doi": "10.1109/TFUZZ.2011.2160024", 
    "link": "http://arxiv.org/pdf/1106.2593v1", 
    "title": "A Simple Multi-Processor Computer Based on Subleq", 
    "arxiv-id": "1106.2593v1", 
    "author": "Alex Kolodin", 
    "publish": "2011-06-14T01:26:41Z", 
    "summary": "Subleq (Subtract and Branch on result Less than or Equal to zero) is both an\ninstruction set and a programming language for One Instruction Set Computer\n(OISC). We describe a hardware implementation of an array of 28 one-instruction\nSubleq processors on a low-cost FPGA board. Our test results demonstrate that\ncomputational power of our Subleq OISC multi-processor is comparable to that of\nCPU of a modern personal computer. Additionally, we provide implementation\ndetails of our complier from a C-style language to Subleq."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.70.6", 
    "link": "http://arxiv.org/pdf/1110.4675v1", 
    "title": "Formal Verification of an Iterative Low-Power x86 Floating-Point   Multiplier with Redundant Feedback", 
    "arxiv-id": "1110.4675v1", 
    "author": "Peter-Michael Seidel", 
    "publish": "2011-10-21T00:45:53Z", 
    "summary": "We present the formal verification of a low-power x86 floating-point\nmultiplier. The multiplier operates iteratively and feeds back intermediate\nresults in redundant representation. It supports x87 and SSE instructions in\nvarious precisions and can block the issuing of new instructions. The design\nhas been optimized for low-power operation and has not been constrained by the\nformal verification effort. Additional improvements for the implementation were\nidentified through formal verification. The formal verification of the design\nalso incorporates the implementation of clock-gating and control logic. The\ncore of the verification effort was based on ACL2 theorem proving.\nAdditionally, model checking has been used to verify some properties of the\nfloating-point scheduler that are relevant for the correct operation of the\nunit."
},{
    "category": "cs.AR", 
    "doi": "10.4204/EPTCS.70.6", 
    "link": "http://arxiv.org/pdf/1111.4362v1", 
    "title": "Hardware Implementation of Successive Cancellation Decoders for Polar   Codes", 
    "arxiv-id": "1111.4362v1", 
    "author": "Warren J. Gross", 
    "publish": "2011-11-18T13:40:16Z", 
    "summary": "The recently-discovered polar codes are seen as a major breakthrough in\ncoding theory; they provably achieve the theoretical capacity of discrete\nmemoryless channels using the low complexity successive cancellation (SC)\ndecoding algorithm. Motivated by recent developments in polar coding theory, we\npropose a family of efficient hardware implementations for SC polar decoders.\nWe show that such decoders can be implemented with O(n) processing elements,\nO(n) memory elements, and can provide a constant throughput for a given target\nclock frequency. Furthermore, we show that SC decoding can be implemented in\nthe logarithm domain, thereby eliminating costly multiplication and division\noperations and reducing the complexity of each processing element greatly. We\nalso present a detailed architecture for an SC decoder and provide logic\nsynthesis results confirming the linear growth in complexity of the decoder as\nthe code length increases."
},{
    "category": "physics.optics", 
    "doi": "10.4204/EPTCS.70.6", 
    "link": "http://arxiv.org/pdf/1112.1616v1", 
    "title": "Multiplexed multiple-\u03c4 auto- and cross- correlators on a single   FPGA", 
    "arxiv-id": "1112.1616v1", 
    "author": "Gy\u00f6rgy V\u00e1mosi", 
    "publish": "2011-12-07T16:34:34Z", 
    "summary": "Fluorescence correlation and cross-correlation spectroscopy (FCS, FCCS) are\nwidely used techniques to study the diffusion properties and interactions of\nfluorescent molecules. Autocorrelation (ACFs) and cross-correlation functions\n(CCFs) are typically acquired with fast hardware correlators. Here we introduce\na new multiple-{\\tau} hardware correlator design for computing ACFs and CCFs in\nreal time. A scheduling algorithm minimizes the use of hardware resources by\ncalculating the different segments of the correlation function on a single\ncorrelator block. The program was written in LabVIEW, enabling computation of\ntwo multiple-{\\tau} ACFs and two CCFs on a National Instruments FPGA card (NI\n7833R) in real time with a minimal sampling time of 400 ns. Raw data are also\nstored with a time resolution of 50 ns for later analysis. The design can be\nadapted to other FPGA cards with only minor changes and extended to evaluate\nmore inputs and correlation functions."
},{
    "category": "cs.ET", 
    "doi": "10.1109/TNANO.2012.2206051", 
    "link": "http://arxiv.org/pdf/1202.1782v1", 
    "title": "Cross-point architecture for spin transfer torque magnetic random access   memory", 
    "arxiv-id": "1202.1782v1", 
    "author": "Pascale Mazoyer", 
    "publish": "2012-02-08T17:50:33Z", 
    "summary": "Spin transfer torque magnetic random access memory (STT-MRAM) is considered\nas one of the most promising candidates to build up a true universal memory\nthanks to its fast write/read speed, infinite endurance and non-volatility.\nHowever the conventional access architecture based on 1 transistor + 1 memory\ncell limits its storage density as the selection transistor should be large\nenough to ensure the write current higher than the critical current for the STT\noperation. This paper describes a design of cross-point architecture for\nSTT-MRAM. The mean area per word corresponds to only two transistors, which are\nshared by a number of bits (e.g. 64). This leads to significant improvement of\ndata density (e.g. 1.75 F2/bit). Special techniques are also presented to\naddress the sneak currents and low speed issues of conventional cross-point\narchitecture, which are difficult to surmount and few efficient design\nsolutions have been reported in the literature. By using a STT-MRAM SPICE model\nincluding precise experimental parameters and STMicroelectronics 65 nm\ntechnology, some chip characteristic results such as cell area, data access\nspeed and power have been calculated or simulated to demonstrate the expected\nperformances of this new memory architecture."
},{
    "category": "cs.OS", 
    "doi": "10.1109/TNANO.2012.2206051", 
    "link": "http://arxiv.org/pdf/1208.6428v1", 
    "title": "A Hardware Time Manager Implementation for the Xenomai Real-Time Kernel   of Embedded Linux", 
    "arxiv-id": "1208.6428v1", 
    "author": "Jalil Boukhobza", 
    "publish": "2012-08-31T09:04:05Z", 
    "summary": "Nowadays, the use of embedded operating systems in different embedded\nprojects is subject to a tremendous growth. Embedded Linux is becoming one of\nthose most popular EOSs due to its modularity, efficiency, reliability, and\ncost. One way to make it hard real-time is to include a real-time kernel like\nXenomai. One of the key characteristics of a Real-Time Operating System (RTOS)\nis its ability to meet execution time deadlines deterministically. So, the more\nprecise and flexible the time management can be, the better it can handle\nefficiently the determinism for different embedded applications. RTOS time\nprecision is characterized by a specific periodic interrupt service controlled\nby a software time manager. The smaller the period of the interrupt, the better\nthe precision of the RTOS, the more it overloads the CPU, and though reduces\nthe overall efficiency of the RTOS. In this paper, we propose to drastically\nreduce these overheads by migrating the time management service of Xenomai into\na configurable hardware component to relieve the CPU. The hardware component is\nimplemented in a Field Programmable Gate Array coupled to the CPU. This work\nwas achieved in a Master degree project where students could apprehend many\nfields of embedded systems: RTOS programming, hardware design, performance\nevaluation, etc."
},{
    "category": "cs.IT", 
    "doi": "10.1109/TNANO.2012.2206051", 
    "link": "http://arxiv.org/pdf/1209.4818v3", 
    "title": "Recursive Descriptions of Polar Codes", 
    "arxiv-id": "1209.4818v3", 
    "author": "Simon Litsyn", 
    "publish": "2012-09-21T13:46:26Z", 
    "summary": "Polar codes are recursive general concatenated codes. This property motivates\na recursive formalization of the known decoding algorithms: Successive\nCancellation, Successive Cancellation with Lists and Belief Propagation. Using\nsuch description allows an easy development of these algorithms for arbitrary\npolarizing kernels. Hardware architectures for these decoding algorithms are\nalso described in a recursive way, both for Arikan's standard polar codes and\nfor arbitrary polarizing kernels."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TNANO.2012.2206051", 
    "link": "http://arxiv.org/pdf/1212.6303v1", 
    "title": "A brief experience on journey through hardware developments for image   processing and its applications on Cryptography", 
    "arxiv-id": "1212.6303v1", 
    "author": "Suman Sau", 
    "publish": "2012-12-27T05:16:25Z", 
    "summary": "The importance of embedded applications on image and video\nprocessing,communication and cryptography domain has been taking a larger space\nin current research era. Improvement of pictorial information for betterment of\nhuman perception like deblurring, de-noising in several fields such as\nsatellite imaging, medical imaging etc are renewed research thrust.\nSpecifically we would like to elaborate our experience on the significance of\ncomputer vision as one of the domains where hardware implemented algorithms\nperform far better than those implemented through software. So far embedded\ndesign engineers have successfully implemented their designs by means of\nApplication Specific Integrated Circuits (ASICs) and/or Digital Signal\nProcessors (DSP), however with the advancement of VLSI technology a very\npowerful hardware device namely the Field Programmable Gate Array (FPGA)\ncombining the key advantages of ASICs and DSPs was developed which have the\npossibility of reprogramming making them a very attractive device for rapid\nprototyping.Communication of image and video data in multiple FPGA is no longer\nfar away from the thrust of secured transmission among them, and then the\nrelevance of cryptography is indeed unavoidable. This paper shows how the\nXilinx hardware development platform as well Mathworks Matlab can be used to\ndevelop hardware based computer vision algorithms and its corresponding crypto\ntransmission channel between multiple FPGA platform from a system level\napproach, making it favourable for developing a hardware-software co-design\nenvironment."
},{
    "category": "cs.ET", 
    "doi": "10.1109/TNANO.2012.2206051", 
    "link": "http://arxiv.org/pdf/1303.4949v1", 
    "title": "FreeIMU: An Open Hardware Framework for Orientation and Motion Sensing", 
    "arxiv-id": "1303.4949v1", 
    "author": "Fabio Varesano", 
    "publish": "2013-03-20T14:25:14Z", 
    "summary": "Orientation and Motion Sensing are widely implemented on various consumer\nproducts, such as mobile phones, tablets and cameras as they enable immediate\ninteraction with virtual information. The prototyping phase of any orientation\nand motion sensing capable device is however a quite difficult process as it\nmay involve complex hardware designing, math algorithms and programming.\n  In this paper, we present FreeIMU, an Open Hardware Framework for prototyping\norientation and motion sensing capable devices. The framework consists in a\nsmall circuit board containing various sensors and a software library, built on\ntop of the Arduino platform. Both the hardware and library are released under\nopen licences and supported by an active community allowing to be implemented\ninto research and commercial projects."
},{
    "category": "cs.IT", 
    "doi": "10.1109/TNANO.2012.2206051", 
    "link": "http://arxiv.org/pdf/1303.7127v3", 
    "title": "Hardware Architecture for List SC Decoding of Polar Codes", 
    "arxiv-id": "1303.7127v3", 
    "author": "A. Burg", 
    "publish": "2013-03-28T14:04:54Z", 
    "summary": "We present a hardware architecture and algorithmic improvements for list SC\ndecoding of polar codes. More specifically, we show how to completely avoid\ncopying of the likelihoods, which is algorithmically the most cumbersome part\nof list SC decoding. The hardware architecture was synthesized for a\nblocklength of N = 1024 bits and list sizes L = 2, 4 using a UMC 90nm VLSI\ntechnology. The resulting decoder can achieve a coded throughput of 181 Mbps at\na frequency of 459 MHz."
},{
    "category": "cs.ET", 
    "doi": "10.1109/TNANO.2012.2206051", 
    "link": "http://arxiv.org/pdf/1308.4169v1", 
    "title": "Ultra-low Energy, High Performance and Programmable Magnetic Threshold   Logic", 
    "arxiv-id": "1308.4169v1", 
    "author": "Kaushik Roy", 
    "publish": "2013-08-08T14:29:58Z", 
    "summary": "We propose magnetic threshold-logic (MTL) design based on non-volatile\nspin-torque switches. A threshold logic gate (TLG) performs summation of\nmultiple inputs multiplied by a fixed set of weights and compares the sum with\na threshold. MTL employs resistive states of magnetic tunnel junctions as\nprogrammable input weights, while, a low-voltage domain-wall shift based\nspin-torque switch is used for thresholding operation. The resulting MTL gate\nacts as a low-power, configurable logic unit and can be used to build fully\npipelined, high-performance programmable computing blocks. Multiple stages in\nsuch a MTL design can be connected using energy-efficient ultralow swing\nprogrammable interconnect networks based on resistive switches. Owing to\nmemory-based compact logic and interconnect design and low-voltage, high-speed\nspintorque based threshold operation, MTL can achieve more than two orders of\nmagnitude improvement in energy-delay product as compared to look-up table\nbased CMOS FPGA."
},{
    "category": "cs.ET", 
    "doi": "10.1109/TNANO.2012.2206051", 
    "link": "http://arxiv.org/pdf/1308.4672v1", 
    "title": "Ultra-low Energy, High-Performance Dynamic Resistive Threshold Logic", 
    "arxiv-id": "1308.4672v1", 
    "author": "Kaushik Roy", 
    "publish": "2013-08-08T15:29:45Z", 
    "summary": "We propose dynamic resistive threshold-logic (DRTL) design based on\nnon-volatile resistive memory. A threshold logic gate (TLG) performs summation\nof multiple inputs multiplied by a fixed set of weights and compares the sum\nwith a threshold. DRTL employs resistive memory elements to implement the\nweights and the thresholds, while a compact dynamic CMOS latch is used for the\ncomparison operation. The resulting DRTL gate acts as a low-power, configurable\ndynamic logic unit and can be used to build fully pipelined, high-performance\nprogrammable computing blocks. Multiple stages in such a DRTL design can be\nconnected using energy-efficient low swing programmable interconnect networks\nbased on resistive switches. Owing to memory-based compact logic and\ninterconnect design and highspeed dynamic-pipelined operation, DRTL can achieve\nmore than two orders of magnitude improvement in energy-delay product as\ncompared to look-up table based CMOS FPGA."
},{
    "category": "cs.AR", 
    "doi": "10.1088/1742-6596/513/5/052002", 
    "link": "http://arxiv.org/pdf/1311.1741v2", 
    "title": "Architectural improvements and 28 nm FPGA implementation of the APEnet+   3D Torus network for hybrid HPC systems", 
    "arxiv-id": "1311.1741v2", 
    "author": "Piero Vicini", 
    "publish": "2013-11-07T17:00:02Z", 
    "summary": "Modern Graphics Processing Units (GPUs) are now considered accelerators for\ngeneral purpose computation. A tight interaction between the GPU and the\ninterconnection network is the strategy to express the full potential on\ncapability computing of a multi-GPU system on large HPC clusters; that is the\nreason why an efficient and scalable interconnect is a key technology to\nfinally deliver GPUs for scientific HPC. In this paper we show the latest\narchitectural and performance improvement of the APEnet+ network fabric, a\nFPGA-based PCIe board with 6 fully bidirectional off-board links with 34 Gbps\nof raw bandwidth per direction, and X8 Gen2 bandwidth towards the host PC. The\nboard implements a Remote Direct Memory Access (RDMA) protocol that leverages\nupon peer-to-peer (P2P) capabilities of Fermi- and Kepler-class NVIDIA GPUs to\nobtain real zero-copy, low-latency GPU-to-GPU transfers. Finally, we report on\nthe development activities for 2013 focusing on the adoption of the latest\ngeneration 28 nm FPGAs and the preliminary tests performed on this new\nplatform."
},{
    "category": "cs.ET", 
    "doi": "10.1088/1742-6596/513/5/052002", 
    "link": "http://arxiv.org/pdf/1402.4013v1", 
    "title": "The Short-term Memory (D.C. Response) of the Memristor Demonstrates the   Causes of the Memristor Frequency Effect", 
    "arxiv-id": "1402.4013v1", 
    "author": "Andrew Adamatzky", 
    "publish": "2014-02-17T14:23:34Z", 
    "summary": "A memristor is often identified by showing its distinctive pinched hysteresis\ncurve and testing for the effect of frequency. The hysteresis size should\nrelate to frequency and shrink to zero as the frequency approaches infinity.\nAlthough mathematically understood, the material causes for this are not well\nknown. The d.c. response of the memristor is a decaying curve with its own\ntimescale. We show via mathematical reasoning that this decaying curve when\ntransformed to a.c. leads to the frequency effect by considering a descretized\ncurve. We then demonstrate the validity of this approach with experimental data\nfrom two different types of memristors."
},{
    "category": "cs.ET", 
    "doi": "10.1088/1742-6596/513/5/052002", 
    "link": "http://arxiv.org/pdf/1402.4036v1", 
    "title": "Is Spiking Logic the Route to Memristor-Based Computers?", 
    "arxiv-id": "1402.4036v1", 
    "author": "Andrew Adamatzky", 
    "publish": "2014-02-17T15:40:49Z", 
    "summary": "Memristors have been suggested as a novel route to neuromorphic computing\nbased on the similarity between neurons (synapses and ion pumps) and\nmemristors. The D.C. action of the memristor is a current spike, which we think\nwill be fruitful for building memristor computers. In this paper, we introduce\n4 different logical assignations to implement sequential logic in the memristor\nand introduce the physical rules, summation, `bounce-back', directionality and\n`diminishing returns', elucidated from our investigations. We then demonstrate\nhow memristor sequential logic works by instantiating a NOT gate, an AND gate\nand a Full Adder with a single memristor. The Full Adder makes use of the\nmemristor's memory to add three binary values together and outputs the value,\nthe carry digit and even the order they were input in."
},{
    "category": "cs.AI", 
    "doi": "10.1088/1742-6596/513/5/052002", 
    "link": "http://arxiv.org/pdf/1402.4914v1", 
    "title": "Building fast Bayesian computing machines out of intentionally   stochastic, digital parts", 
    "arxiv-id": "1402.4914v1", 
    "author": "Eric Jonas", 
    "publish": "2014-02-20T07:17:03Z", 
    "summary": "The brain interprets ambiguous sensory information faster and more reliably\nthan modern computers, using neurons that are slower and less reliable than\nlogic gates. But Bayesian inference, which underpins many computational models\nof perception and cognition, appears computationally challenging even given\nmodern transistor speeds and energy budgets. The computational principles and\nstructures needed to narrow this gap are unknown. Here we show how to build\nfast Bayesian computing machines using intentionally stochastic, digital parts,\nnarrowing this efficiency gap by multiple orders of magnitude. We find that by\nconnecting stochastic digital components according to simple mathematical\nrules, one can build massively parallel, low precision circuits that solve\nBayesian inference problems and are compatible with the Poisson firing\nstatistics of cortical neurons. We evaluate circuits for depth and motion\nperception, perceptual learning and causal reasoning, each performing inference\nover 10,000+ latent variables in real time - a 1,000x speed advantage over\ncommodity microprocessors. These results suggest a new role for randomness in\nthe engineering and reverse-engineering of intelligent computation."
},{
    "category": "cs.AR", 
    "doi": "10.1088/1742-6596/513/5/052002", 
    "link": "http://arxiv.org/pdf/1408.4423v2", 
    "title": "Proceedings of the First International Workshop on FPGAs for Software   Programmers (FSP 2014)", 
    "arxiv-id": "1408.4423v2", 
    "author": "Daniel Ziener", 
    "publish": "2014-08-18T18:43:54Z", 
    "summary": "This volume contains the papers accepted at the First International Workshop\non FPGAs for Software Programmers (FSP 2014), held in Munich, Germany,\nSeptember 1st, 2014. FSP 2014 was co-located with the International Conference\non Field Programmable Logic and Applications (FPL)."
},{
    "category": "physics.space-ph", 
    "doi": "10.1088/1742-6596/513/5/052002", 
    "link": "http://arxiv.org/pdf/1409.0736v1", 
    "title": "On Delay Faults Affecting I/O Blocks of an SRAM-Based FPGA Due to   Ionizing Radiations", 
    "arxiv-id": "1409.0736v1", 
    "author": "Yves Audet", 
    "publish": "2014-09-02T14:53:09Z", 
    "summary": "Experimental means to characterize delay faults induced by bit flips and SEUs\nin I/O blocks of SRAM-based FPGAs are proposed. A delay fault up to 6.2ns\nsensitized by an events chain is reported."
},{
    "category": "cs.AR", 
    "doi": "10.1088/1742-6596/513/5/052002", 
    "link": "http://arxiv.org/pdf/1409.4744v2", 
    "title": "An Efficient List Decoder Architecture for Polar Codes", 
    "arxiv-id": "1409.4744v2", 
    "author": "Zhiyuan Yan", 
    "publish": "2014-09-16T19:39:49Z", 
    "summary": "Long polar codes can achieve the symmetric capacity of arbitrary binary-input\ndiscrete memoryless channels under a low complexity successive cancelation (SC)\ndecoding algorithm. However, for polar codes with short and moderate code\nlength, the decoding performance of the SC algorithm is inferior. The cyclic\nredundancy check (CRC) aided successive cancelation list (SCL) decoding\nalgorithm has better error performance than the SC algorithm for short or\nmoderate polar codes. In this paper, we propose an efficient list decoder\narchitecture for the CRC aided SCL algorithm, based on both algorithmic\nreformulations and architectural techniques. In particular, an area efficient\nmessage memory architecture is proposed to reduce the area of the proposed\ndecoder architecture. An efficient path pruning unit suitable for large list\nsize is also proposed. For a polar code of length 1024 and rate $\\frac{1}{2}$,\nwhen list size $L=2$ and 4, the proposed list decoder architecture is\nimplemented under a TSMC 90nm CMOS technology. Compared with the list decoders\nin the literature, our decoder achieves 1.33 to 1.96 times hardware efficiency."
},{
    "category": "cs.PF", 
    "doi": "10.1088/1742-6596/513/5/052002", 
    "link": "http://arxiv.org/pdf/1409.5567v1", 
    "title": "Rank-Aware Dynamic Migrations and Adaptive Demotions for DRAM Power   Management", 
    "arxiv-id": "1409.5567v1", 
    "author": "Minyi Guo", 
    "publish": "2014-09-19T09:30:49Z", 
    "summary": "Modern DRAM architectures allow a number of low-power states on individual\nmemory ranks for advanced power management. Many previous studies have taken\nadvantage of demotions on low-power states for energy saving. However, most of\nthe demotion schemes are statically performed on a limited number of\npre-selected low-power states, and are suboptimal for different workloads and\nmemory architectures. Even worse, the idle periods are often too short for\neffective power state transitions, especially for memory intensive\napplications. Wrong decisions on power state transition incur significant\nenergy and delay penalties. In this paper, we propose a novel memory system\ndesign named RAMZzz with rank-aware energy saving optimizations including\ndynamic page migrations and adaptive demotions. Specifically, we group the\npages with similar access locality into the same rank with dynamic page\nmigrations. Ranks have their hotness: hot ranks are kept busy for high\nutilization and cold ranks can have more lengthy idle periods for power state\ntransitions. We further develop adaptive state demotions by considering all\nlow-power states for each rank and a prediction model to estimate the\npower-down timeout among states. We experimentally compare our algorithm with\nother energy saving policies with cycle-accurate simulation. Experiments with\nbenchmark workloads show that RAMZzz achieves significant improvement on\nenergy-delay2 and energy consumption over other energy saving techniques."
},{
    "category": "cs.NE", 
    "doi": "10.1088/1742-6596/513/5/052002", 
    "link": "http://arxiv.org/pdf/1109.4609v1", 
    "title": "Memristive fuzzy edge detector", 
    "arxiv-id": "1109.4609v1", 
    "author": "Saeed Bagheri Shouraki", 
    "publish": "2011-09-21T18:45:03Z", 
    "summary": "Fuzzy inference systems always suffer from the lack of efficient structures\nor platforms for their hardware implementation. In this paper, we tried to\novercome this problem by proposing new method for the implementation of those\nfuzzy inference systems which use fuzzy rule base to make inference. To achieve\nthis goal, we have designed a multi-layer neuro-fuzzy computing system based on\nthe memristor crossbar structure by introducing some new concepts like fuzzy\nminterms. Although many applications can be realized through the use of our\nproposed system, in this study we show how the fuzzy XOR function can be\nconstructed and how it can be used to extract edges from grayscale images. Our\nmemristive fuzzy edge detector (implemented in analog form) compared with other\ncommon edge detectors has this advantage that it can extract edges of any given\nimage all at once in real-time."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.114.5", 
    "link": "http://arxiv.org/pdf/1304.7858v1", 
    "title": "Abstract Stobjs and Their Application to ISA Modeling", 
    "arxiv-id": "1304.7858v1", 
    "author": "Matt Kaufmann", 
    "publish": "2013-04-30T04:14:22Z", 
    "summary": "We introduce a new ACL2 feature, the abstract stobj, and show how to apply it\nto modeling the instruction set architecture of a microprocessor. Benefits of\nabstract stobjs over traditional (\"concrete\") stobjs can include faster\nexecution, support for symbolic simulation, more efficient reasoning, and\nresilience of proof developments under modeling optimization."
},{
    "category": "cs.IT", 
    "doi": "10.1109/TCSI.2012.2230506", 
    "link": "http://arxiv.org/pdf/1305.0185v1", 
    "title": "A 2.0 Gb/s Throughput Decoder for QC-LDPC Convolutional Codes", 
    "arxiv-id": "1305.0185v1", 
    "author": "Wai M. Tam", 
    "publish": "2013-05-01T14:40:30Z", 
    "summary": "This paper propose a decoder architecture for low-density parity-check\nconvolutional code (LDPCCC). Specifically, the LDPCCC is derived from a\nquasi-cyclic (QC) LDPC block code. By making use of the quasi-cyclic structure,\nthe proposed LDPCCC decoder adopts a dynamic message storage in the memory and\nuses a simple address controller. The decoder efficiently combines the memories\nin the pipelining processors into a large memory block so as to take advantage\nof the data-width of the embedded memory in a modern field-programmable gate\narray (FPGA). A rate-5/6 QC-LDPCCC has been implemented on an Altera Stratix\nFPGA. It achieves up to 2.0 Gb/s throughput with a clock frequency of 100 MHz.\nMoreover, the decoder displays an excellent error performance of lower than\n$10^{-13}$ at a bit-energy-to-noise-power-spectral-density ratio ($E_b/N_0$) of\n3.55 dB."
},{
    "category": "cs.ET", 
    "doi": "10.1088/0957-4484/25/28/285201", 
    "link": "http://arxiv.org/pdf/1306.6133v2", 
    "title": "Dynamic Computing Random Access Memory", 
    "arxiv-id": "1306.6133v2", 
    "author": "Massimiliano Di Ventra", 
    "publish": "2013-06-26T05:12:46Z", 
    "summary": "The present von Neumann computing paradigm involves a significant amount of\ninformation transfer between a central processing unit (CPU) and memory, with\nconcomitant limitations in the actual execution speed. However, it has been\nrecently argued that a different form of computation, dubbed memcomputing\n[Nature Physics, 9, 200-202 (2013)] and inspired by the operation of our brain,\ncan resolve the intrinsic limitations of present day architectures by allowing\nfor computing and storing of information on the same physical platform. Here we\nshow a simple and practical realization of memcomputing that utilizes\neasy-to-build memcapacitive systems. We name this architecture Dynamic\nComputing Random Access Memory (DCRAM). We show that DCRAM provides\nmassively-parallel and polymorphic digital logic, namely it allows for\ndifferent logic operations with the same architecture, by varying only the\ncontrol signals. In addition, by taking into account realistic parameters, its\nenergy expenditures can be as low as a few fJ per operation. DCRAM is fully\ncompatible with CMOS technology, can be realized with current fabrication\nfacilities, and therefore can really serve as an alternative to the present\ncomputing technology."
},{
    "category": "cs.AR", 
    "doi": "10.1109/JSAC.2014.140514", 
    "link": "http://arxiv.org/pdf/1307.7154v2", 
    "title": "Fast Polar Decoders: Algorithm and Implementation", 
    "arxiv-id": "1307.7154v2", 
    "author": "Warren J. Gross", 
    "publish": "2013-07-26T20:07:04Z", 
    "summary": "Polar codes provably achieve the symmetric capacity of a memoryless channel\nwhile having an explicit construction. This work aims to increase the\nthroughput of polar decoder hardware by an order of magnitude relative to the\nstate of the art successive-cancellation decoder. We present an algorithm,\narchitecture, and FPGA implementation of a gigabit-per-second polar decoder."
},{
    "category": "cs.AR", 
    "doi": "10.1016/j.cpc.2013.10.019", 
    "link": "http://arxiv.org/pdf/1310.1032v1", 
    "title": "Janus II: a new generation application-driven computer for spin-system   simulations", 
    "arxiv-id": "1310.1032v1", 
    "author": "D. Yllanes", 
    "publish": "2013-10-03T16:49:55Z", 
    "summary": "This paper describes the architecture, the development and the implementation\nof Janus II, a new generation application-driven number cruncher optimized for\nMonte Carlo simulations of spin systems (mainly spin glasses). This domain of\ncomputational physics is a recognized grand challenge of high-performance\ncomputing: the resources necessary to study in detail theoretical models that\ncan make contact with experimental data are by far beyond those available using\ncommodity computer systems. On the other hand, several specific features of the\nassociated algorithms suggest that unconventional computer architectures, which\ncan be implemented with available electronics technologies, may lead to order\nof magnitude increases in performance, reducing to acceptable values on human\nscales the time needed to carry out simulation campaigns that would take\ncenturies on commercially available machines. Janus II is one such machine,\nrecently developed and commissioned, that builds upon and improves on the\nsuccessful JANUS machine, which has been used for physics since 2008 and is\nstill in operation today. This paper describes in detail the motivations behind\nthe project, the computational requirements, the architecture and the\nimplementation of this new machine and compares its expected performances with\nthose of currently available commercial systems."
},{
    "category": "cs.AR", 
    "doi": "10.1016/j.cpc.2013.10.019", 
    "link": "http://arxiv.org/pdf/1310.1712v2", 
    "title": "Partial Sums Computation In Polar Codes Decoding", 
    "arxiv-id": "1310.1712v2", 
    "author": "Dominique Dallet", 
    "publish": "2013-10-07T09:29:02Z", 
    "summary": "Polar codes are the first error-correcting codes to provably achieve the\nchannel capacity but with infinite codelengths. For finite codelengths the\nexisting decoder architectures are limited in working frequency by the partial\nsums computation unit. We explain in this paper how the partial sums\ncomputation can be seen as a matrix multiplication. Then, an efficient hardware\nimplementation of this product is investigated. It has reduced logic resources\nand interconnections. Formalized architectures, to compute partial sums and to\ngenerate the bits of the generator matrix k^n, are presented. The proposed\narchitecture allows removing the multiplexing resources used to assigned to\neach processing elements the required partial sums."
},{
    "category": "cs.CE", 
    "doi": "10.1016/j.cpc.2013.10.019", 
    "link": "http://arxiv.org/pdf/1312.4587v1", 
    "title": "FFTPL: An Analytic Placement Algorithm Using Fast Fourier Transform for   Density Equalization", 
    "arxiv-id": "1312.4587v1", 
    "author": "Chung-Kuan Cheng", 
    "publish": "2013-12-16T23:01:46Z", 
    "summary": "We propose a flat nonlinear placement algorithm FFTPL using fast Fourier\ntransform for density equalization. The placement instance is modeled as an\nelectrostatic system with the analogy of density cost to the potential energy.\nA well-defined Poisson's equation is proposed for gradient and cost\ncomputation. Our placer outperforms state-of-the-art placers with better\nsolution quality and efficiency."
},{
    "category": "cs.IT", 
    "doi": "10.1109/TCSI.2014.2309810", 
    "link": "http://arxiv.org/pdf/1403.3759v3", 
    "title": "Parallel Interleaver Design for a High Throughput HSPA+/LTE   Multi-Standard Turbo Decoder", 
    "arxiv-id": "1403.3759v3", 
    "author": "Yuanbin Guo", 
    "publish": "2014-03-15T06:23:28Z", 
    "summary": "To meet the evolving data rate requirements of emerging wireless\ncommunication technologies, many parallel architectures have been proposed to\nimplement high throughput turbo decoders. However, concurrent memory\nreading/writing in parallel turbo decoding architectures leads to severe memory\nconflict problem, which has become a major bottleneck for high throughput turbo\ndecoders. In this paper, we propose a flexible and efficient VLSI architecture\nto solve the memory conflict problem for highly parallel turbo decoders\ntargeting multi-standard 3G/4G wireless communication systems. To demonstrate\nthe effectiveness of the proposed parallel interleaver architecture, we\nimplemented an HSPA+/LTE/LTE-Advanced multi-standard turbo decoder with a 45nm\nCMOS technology. The implemented turbo decoder consists of 16 Radix-4 MAP\ndecoder cores, and the chip core area is 2.43 mm^2. When clocked at 600 MHz,\nthis turbo decoder can achieve a maximum decoding throughput of 826 Mbps in the\nHSPA+ mode and 1.67 Gbps in the LTE/LTE-Advanced mode, exceeding the peak data\nrate requirements for both standards."
},{
    "category": "cs.AR", 
    "doi": "10.1049/el.2013.1352", 
    "link": "http://arxiv.org/pdf/1405.0413v1", 
    "title": "Multiplierless Approximate 4-point DCT VLSI Architectures for Transform   Block Coding", 
    "arxiv-id": "1405.0413v1", 
    "author": "U. S. Potluri", 
    "publish": "2014-05-02T14:29:02Z", 
    "summary": "Two multiplierless algorithms are proposed for 4x4 approximate-DCT for\ntransform coding in digital video. Computational architectures for 1-D/2-D\nrealisations are implemented using Xilinx FPGA devices. CMOS synthesis at the\n45 nm node indicate real-time operation at 1 GHz yielding 4x4 block rates of\n125 MHz at less than 120 mW of dynamic power consumption."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TVLSI.2014.2359801", 
    "link": "http://arxiv.org/pdf/1410.1267v1", 
    "title": "Memristive Threshold Logic Circuit Design of Fast Moving Object   Detection", 
    "arxiv-id": "1410.1267v1", 
    "author": "Alex Pappachen James", 
    "publish": "2014-10-06T06:52:57Z", 
    "summary": "Real-time detection of moving objects involves memorisation of features in\nthe template image and their comparison with those in the test image. At high\nsampling rates, such techniques face the problems of high algorithmic\ncomplexity and component delays. We present a new resistive switching based\nthreshold logic cell which encodes the pixels of a template image. The cell\ncomprises a voltage divider circuit that programs the resistances of the\nmemristors arranged in a single node threshold logic network and the output is\nencoded as a binary value using a CMOS inverter gate. When a test image is\napplied to the template-programmed cell, a mismatch in the respective pixels is\nseen as a change in the output voltage of the cell. The proposed cell when\ncompared with CMOS equivalent implementation shows improved performance in\narea, leakage power, power dissipation and delay."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ISCAS.2015.7169066", 
    "link": "http://arxiv.org/pdf/1410.4460v2", 
    "title": "On Metric Sorting for Successive Cancellation List Decoding of Polar   Codes", 
    "arxiv-id": "1410.4460v2", 
    "author": "Andreas Burg", 
    "publish": "2014-10-16T15:07:54Z", 
    "summary": "We focus on the metric sorter unit of successive cancellation list decoders\nfor polar codes, which lies on the critical path in all current hardware\nimplementations of the decoder. We review existing metric sorter architectures\nand we propose two new architectures that exploit the structure of the path\nmetrics in a log-likelihood ratio based formulation of successive cancellation\nlist decoding. Our synthesis results show that, for the list size of $L=32$,\nour first proposed sorter is $14\\%$ faster and $45\\%$ smaller than existing\nsorters, while for smaller list sizes, our second sorter has a higher delay in\nreturn for up to $36\\%$ reduction in the area."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ISCAS.2015.7169066", 
    "link": "http://arxiv.org/pdf/1410.8772v1", 
    "title": "Programming the Adapteva Epiphany 64-core Network-on-chip Coprocessor", 
    "arxiv-id": "1410.8772v1", 
    "author": "Alistair P. Rendell", 
    "publish": "2014-10-30T08:29:11Z", 
    "summary": "In the construction of exascale computing systems energy efficiency and power\nconsumption are two of the major challenges. Low-power high performance\nembedded systems are of increasing interest as building blocks for large scale\nhigh- performance systems. However, extracting maximum performance out of such\nsystems presents many challenges. Various aspects from the hardware\narchitecture to the programming models used need to be explored. The Epiphany\narchitecture integrates low-power RISC cores on a 2D mesh network and promises\nup to 70 GFLOPS/Watt of processing efficiency. However, with just 32 KB of\nmemory per eCore for storing both data and code, and only low level inter-core\ncommunication support, programming the Epiphany system presents several\nchallenges. In this paper we evaluate the performance of the Epiphany system\nfor a variety of basic compute and communication operations. Guided by this\ndata we explore strategies for implementing scientific applications on memory\nconstrained low-powered devices such as the Epiphany. With future systems\nexpected to house thousands of cores in a single chip, the merits of such\narchitectures as a path to exascale is compared to other competing systems."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ISCAS.2015.7169066", 
    "link": "http://arxiv.org/pdf/1502.07241v2", 
    "title": "Proceedings of the DATE Friday Workshop on Heterogeneous Architectures   and Design Methods for Embedded Image Systems (HIS 2015)", 
    "arxiv-id": "1502.07241v2", 
    "author": "Anton Lokhmotov", 
    "publish": "2015-02-25T16:52:56Z", 
    "summary": "This volume contains the papers accepted at the DATE Friday Workshop on\nHeterogeneous Architectures and Design Methods for Embedded Image Systems (HIS\n2015), held in Grenoble, France, March 13, 2015. HIS 2015 was co-located with\nthe Conference on Design, Automation and Test in Europe (DATE)."
},{
    "category": "cs.ET", 
    "doi": "10.1109/ISCAS.2015.7169066", 
    "link": "http://arxiv.org/pdf/1502.07449v1", 
    "title": "Concept for a CMOS Image Sensor Suited for Analog Image Pre-Processing", 
    "arxiv-id": "1502.07449v1", 
    "author": "Thomas Ussmueller", 
    "publish": "2015-02-26T06:18:04Z", 
    "summary": "A concept for a novel CMOS image sensor suited for analog image\npre-processing is presented in this paper. As an example, an image restoration\nalgorithm for reducing image noise is applied as image pre-processing in the\nanalog domain. To supply low-latency data input for analog image preprocessing,\nthe proposed concept for a CMOS image sensor offers a new sensor signal\nacquisition method in 2D. In comparison to image pre-processing in the digital\ndomain, the proposed analog image pre-processing promises an improved image\nquality. Furthermore, the image noise at the stage of analog sensor signal\nacquisition can be used to select the most effective restoration algorithm\napplied to the analog circuit due to image processing prior to the A/D\nconverter."
},{
    "category": "cs.DC", 
    "doi": "10.1109/ISCAS.2015.7169066", 
    "link": "http://arxiv.org/pdf/1503.01416v1", 
    "title": "Disaggregated and optically interconnected memory: when will it be cost   effective?", 
    "arxiv-id": "1503.01416v1", 
    "author": "Marc A. Taubenblatt", 
    "publish": "2015-03-03T18:38:33Z", 
    "summary": "The \"Disaggregated Server\" concept has been proposed for datacenters where\nthe same type server resources are aggregated in their respective pools, for\nexample a compute pool, memory pool, network pool, and a storage pool. Each\nserver is constructed dynamically by allocating the right amount of resources\nfrom these pools according to the workload's requirements. Modularity, higher\npackaging and cooling efficiencies, and higher resource utilization are among\nthe suggested benefits. With the emergence of very large datacenters, \"clouds\"\ncontaining tens of thousands of servers, datacenter efficiency has become an\nimportant topic. Few computer chip and systems vendors are working on and\nmaking frequent announcements on silicon photonics and disaggregated memory\nsystems.\n  In this paper we study the trade-off between cost and performance of building\na disaggregated memory system where DRAM modules in the datacenter are pooled,\nfor example in memory-only chassis and racks. The compute pool and the memory\npool are interconnected by an optical interconnect to overcome the distance and\nbandwidth issues of electrical fabrics. We construct a simple cost model that\nincludes the cost of latency, cost of bandwidth and the savings expected from a\ndisaggregated memory system. We then identify the level at which a\ndisaggregated memory system becomes cost competitive with a traditional direct\nattached memory system.\n  Our analysis shows that a rack-scale disaggregated memory system will have a\nnon-trivial performance penalty, and at the datacenter scale the penalty is\nimpractically high, and the optical interconnect costs are at least a factor of\n10 more expensive than where they should be when compared to the traditional\ndirect attached memory systems."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ISCAS.2015.7169066", 
    "link": "http://arxiv.org/pdf/1503.02986v3", 
    "title": "Strategies for High-Throughput FPGA-based QC-LDPC Decoder Architecture", 
    "arxiv-id": "1503.02986v3", 
    "author": "Predrag Spasojevic", 
    "publish": "2015-03-10T16:54:39Z", 
    "summary": "We propose without loss of generality strategies to achieve a high-throughput\nFPGA-based architecture for a QC-LDPC code based on a circulant-1 identity\nmatrix construction. We present a novel representation of the parity-check\nmatrix (PCM) providing a multi-fold throughput gain. Splitting of the node\nprocessing algorithm enables us to achieve pipelining of blocks and hence\nlayers. By partitioning the PCM into not only layers but superlayers we derive\nan upper bound on the pipelining depth for the compact representation. To\nvalidate the architecture, a decoder for the IEEE 802.11n (2012) QC-LDPC is\nimplemented on the Xilinx Kintex-7 FPGA with the help of the FPGA IP compiler\n[2] available in the NI LabVIEW Communication System Design Suite (CSDS) which\noffers an automated and systematic compilation flow where an optimized hardware\nimplementation from the LDPC algorithm was generated in approximately 3\nminutes, achieving an overall throughput of 608Mb/s (at 260MHz). As per our\nknowledge this is the fastest implementation of the IEEE 802.11n QC-LDPC\ndecoder using an algorithmic compiler."
},{
    "category": "cs.IT", 
    "doi": "10.1109/ISCAS.2015.7169066", 
    "link": "http://arxiv.org/pdf/1503.03880v4", 
    "title": "Modeling and Energy Optimization of LDPC Decoder Circuits with Timing   Violations", 
    "arxiv-id": "1503.03880v4", 
    "author": "Warren J. Gross", 
    "publish": "2015-03-12T20:23:12Z", 
    "summary": "This paper proposes a \"quasi-synchronous\" design approach for signal\nprocessing circuits, in which timing violations are permitted, but without the\nneed for a hardware compensation mechanism. The case of a low-density\nparity-check (LDPC) decoder is studied, and a method for accurately modeling\nthe effect of timing violations at a high level of abstraction is presented.\nThe error-correction performance of code ensembles is then evaluated using\ndensity evolution while taking into account the effect of timing faults.\nFollowing this, several quasi-synchronous LDPC decoder circuits based on the\noffset min-sum algorithm are optimized, providing a 23%-40% reduction in energy\nconsumption or energy-delay product, while achieving the same performance and\noccupying the same area as conventional synchronous circuits."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ISCAS.2015.7169066", 
    "link": "http://arxiv.org/pdf/1503.08659v3", 
    "title": "Binary Adder Circuits of Asymptotically Minimum Depth, Linear Size, and   Fan-Out Two", 
    "arxiv-id": "1503.08659v3", 
    "author": "Sophie Theresa Spirkl", 
    "publish": "2015-03-30T13:02:53Z", 
    "summary": "We consider the problem of constructing fast and small binary adder circuits.\nAmong widely-used adders, the Kogge-Stone adder is often considered the\nfastest, because it computes the carry bits for two $n$-bit numbers (where $n$\nis a power of two) with a depth of $2\\log_2 n$ logic gates, size $4 n\\log_2 n$,\nand all fan-outs bounded by two. Fan-outs of more than two are avoided, because\nthey lead to the insertion of repeaters for repowering the signal and\nadditional depth in the physical implementation. However, the depth bound of\nthe Kogge-Stone adder is off by a factor of two from the lower bound of $\\log_2\nn$. This bound is achieved asymptotically in two separate constructions by\nBrent and Krapchenko. Brent's construction gives neither a bound on the fan-out\nnor the size, while Krapchenko's adder has linear size, but can have up to\nlinear fan-out. With a fan-out bound of two, neither construction achieves a\ndepth of less than $2 \\log_2 n$. In a further approach, Brent and Kung proposed\nan adder with linear size and fan-out two, but twice the depth of the\nKogge-Stone adder. These results are 33-43 years old and no substantial\ntheoretical improvement for has been made since then.\n  In this paper we integrate the individual advantages of all previous adder\ncircuits into a new family of full adders, the first to improve on the depth\nbound of $2\\log_2 n$ while maintaining a fan-out bound of two. Our adders\nachieve an asymptotically optimum logic gate depth of $\\log_2 n + o(\\log_2 n)$\nand linear size $\\mathcal {O}(n)$."
},{
    "category": "physics.ins-det", 
    "doi": "10.1109/ISCAS.2015.7169066", 
    "link": "http://arxiv.org/pdf/1503.08819v1", 
    "title": "FPGA based High Speed Data Acquisition System for High Energy Physics   Application", 
    "arxiv-id": "1503.08819v1", 
    "author": "Subhasis Chattopadhyay", 
    "publish": "2015-03-30T08:05:30Z", 
    "summary": "In high energy physics experiments (HEP), high speed and fault resilient data\ncommunication is needed between detectors/sensors and the host PC. Transient\nfaults can occur in the communication hardware due to various external effects\nlike presence of charged particles, noise in the environment or radiation\neffects in HEP experiments and that leads to single/multiple bit error. In\norder to keep the communication system functional in such a radiation\nenvironment where direct intervention of human is not possible, a high speed\ndata acquisition (DAQ) architecture is necessary which supports error recovery.\nThis design presents an efficient implementation of field programmable gate\narray (FPGA) based high speed DAQ system with optical communication link\nsupported by multi-bit error correcting model. The design has been implemented\non Xilinx Kintex-7 board and is tested for board to board communication as well\nas for PC communication using PCI (Peripheral Component Interconnect express).\nData communication speed up to 4.8 Gbps has been achieved in board to board and\nboard to PC communication and estimation of resource utilization and critical\npath delay are also measured."
},{
    "category": "cs.DC", 
    "doi": "10.1109/ISCAS.2015.7169066", 
    "link": "http://arxiv.org/pdf/1504.06357v1", 
    "title": "Overview of Swallow --- A Scalable 480-core System for Investigating the   Performance and Energy Efficiency of Many-core Applications and Operating   Systems", 
    "arxiv-id": "1504.06357v1", 
    "author": "Steve Kerrison", 
    "publish": "2015-04-23T22:36:46Z", 
    "summary": "We present Swallow, a scalable many-core architecture, with a current\nconfiguration of 480 x 32-bit processors.\n  Swallow is an open-source architecture, designed from the ground up to\ndeliver scalable increases in usable computational power to allow\nexperimentation with many-core applications and the operating systems that\nsupport them.\n  Scalability is enabled by the creation of a tile-able system with a\nlow-latency interconnect, featuring an attractive communication-to-computation\nratio and the use of a distributed memory configuration.\n  We analyse the energy and computational and communication performances of\nSwallow. The system provides 240GIPS with each core consuming 71--193mW,\ndependent on workload. Power consumption per instruction is lower than almost\nall systems of comparable scale.\n  We also show how the use of a distributed operating system (nOS) allows the\neasy creation of scalable software to exploit Swallow's potential. Finally, we\nshow two use case studies: modelling neurons and the overlay of shared memory\non a distributed memory system."
},{
    "category": "cs.DC", 
    "doi": "10.1109/ISCAS.2015.7169066", 
    "link": "http://arxiv.org/pdf/1507.08340v1", 
    "title": "How Data Volume Affects Spark Based Data Analytics on a Scale-up Server", 
    "arxiv-id": "1507.08340v1", 
    "author": "Eduard Ayguade", 
    "publish": "2015-07-29T22:59:49Z", 
    "summary": "Sheer increase in volume of data over the last decade has triggered research\nin cluster computing frameworks that enable web enterprises to extract big\ninsights from big data. While Apache Spark is gaining popularity for exhibiting\nsuperior scale-out performance on the commodity machines, the impact of data\nvolume on the performance of Spark based data analytics in scale-up\nconfiguration is not well understood. We present a deep-dive analysis of Spark\nbased applications on a large scale-up server machine. Our analysis reveals\nthat Spark based data analytics are DRAM bound and do not benefit by using more\nthan 12 cores for an executor. By enlarging input data size, application\nperformance degrades significantly due to substantial increase in wait time\nduring I/O operations and garbage collection, despite 10\\% better instruction\nretirement rate (due to lower L1 cache misses and higher core utilization). We\nmatch memory behaviour with the garbage collector to improve performance of\napplications between 1.6x to 3x."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ISCAS.2015.7169066", 
    "link": "http://arxiv.org/pdf/1508.06320v1", 
    "title": "Proceedings of the Second International Workshop on FPGAs for Software   Programmers (FSP 2015)", 
    "arxiv-id": "1508.06320v1", 
    "author": "Daniel Ziener", 
    "publish": "2015-08-25T22:17:22Z", 
    "summary": "This volume contains the papers accepted at the Second International Workshop\non FPGAs for Software Programmers (FSP 2015), held in London, United Kingdom,\nSeptember 1st, 2015. FSP 2015 was co-located with the International Conference\non Field Programmable Logic and Applications (FPL)."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ISCAS.2015.7169066", 
    "link": "http://arxiv.org/pdf/1508.07123v1", 
    "title": "Proposal of ROS-compliant FPGA Component for Low-Power Robotic Systems", 
    "arxiv-id": "1508.07123v1", 
    "author": "Takashi Yokota", 
    "publish": "2015-08-28T08:33:15Z", 
    "summary": "In recent years, robots are required to be autonomous and their robotic\nsoftware are sophisticated. Robots have a problem of insufficient performance,\nsince it cannot equip with a high-performance microprocessor due to\nbattery-power operation. On the other hand, FPGA devices can accelerate\nspecific functions in a robot system without increasing power consumption by\nimplementing customized circuits. But it is difficult to introduce FPGA devices\ninto a robot due to large development cost of an FPGA circuit compared to\nsoftware. Therefore, in this study, we propose an FPGA component technology for\nan easy integration of an FPGA into robots, which is compliant with ROS (Robot\nOperating System). As a case study, we designed ROS-compliant FPGA component of\nimage labeling using Xilinx Zynq platform. The developed ROS-component FPGA\ncomponent performs 1.7 times faster compared to the ordinary ROS software\ncomponent."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ISCAS.2015.7169066", 
    "link": "http://arxiv.org/pdf/1509.00040v1", 
    "title": "DSL-based Design Space Exploration for Temporal and Spatial Parallelism   of Custom Stream Computing", 
    "arxiv-id": "1509.00040v1", 
    "author": "Kentaro Sano", 
    "publish": "2015-08-27T12:23:57Z", 
    "summary": "Stream computation is one of the approaches suitable for FPGA-based custom\ncomputing due to its high throughput capability brought by pipelining with\nregular memory access. To increase performance of iterative stream computation,\nwe can exploit both temporal and spatial parallelism by deepening and\nduplicating pipelines, respectively. However, the performance is constrained by\nseveral factors including available hardware resources on FPGA, an external\nmemory bandwidth, and utilization of pipeline stages, and therefore we need to\nfind the best mix of the different parallelism to achieve the highest\nperformance per power. In this paper, we present a domain-specific language\n(DSL) based design space exploration for temporally and/or spatially parallel\nstream computation with FPGA. We define a DSL where we can easily design a\nhierarchical structure of parallel stream computation with abstract description\nof computation. For iterative stream computation of fluid dynamics simulation,\nwe design hardware structures with a different mix of the temporal and spatial\nparallelism. By measuring the performance and the power consumption, we find\nthe best among them."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICASSP.2016.7471817", 
    "link": "http://arxiv.org/pdf/1512.03128v2", 
    "title": "Partitioned Successive-Cancellation List Decoding of Polar Codes", 
    "arxiv-id": "1512.03128v2", 
    "author": "Warren J. Gross", 
    "publish": "2015-12-10T02:34:13Z", 
    "summary": "Successive-cancellation list (SCL) decoding is an algorithm that provides\nvery good error-correction performance for polar codes. However, its hardware\nimplementation requires a large amount of memory, mainly to store intermediate\nresults. In this paper, a partitioned SCL algorithm is proposed to reduce the\nlarge memory requirements of the conventional SCL algorithm. The decoder tree\nis broken into partitions that are decoded separately. We show that with\ncareful selection of list sizes and number of partitions, the proposed\nalgorithm can outperform conventional SCL while requiring less memory."
},{
    "category": "cs.CC", 
    "doi": "10.1109/ICASSP.2016.7471817", 
    "link": "http://arxiv.org/pdf/1603.02580v2", 
    "title": "On the infeasibility of analysing worst-case dynamic energy", 
    "arxiv-id": "1603.02580v2", 
    "author": "Kerstin Eder", 
    "publish": "2016-03-07T19:22:13Z", 
    "summary": "This paper examines dynamic energy consumption during the execution of\nsoftware on deeply embedded IoT microprocessors. In worst-case energy\nconsumption analysis, energy models are used to find the most costly execution\npath. Few models adequately consider dynamic energy caused by switching due to\noperand values. We find that energy contribution of operand values can be\nsignificant, prove that finding worst-case input data is NP-hard, and that\ntight bounds cannot be approximated with guaranteed safety. We conclude that\naccurate worst-case analysis of data-dependent energy is infeasible, and\nprovide recommendations to minimize the impact of this, without resorting to\nsignificant over-estimation."
},{
    "category": "cs.IT", 
    "doi": "10.1007/s11265-016-1173-y", 
    "link": "http://arxiv.org/pdf/1603.05273v2", 
    "title": "Fast Low-Complexity Decoders for Low-Rate Polar Codes", 
    "arxiv-id": "1603.05273v2", 
    "author": "Warren J. Gross", 
    "publish": "2016-03-16T20:49:30Z", 
    "summary": "Polar codes are capacity-achieving error-correcting codes with an explicit\nconstruction that can be decoded with low-complexity algorithms. In this work,\nwe show how the state-of-the-art low-complexity decoding algorithm can be\nimproved to better accommodate low-rate codes. More constituent codes are\nrecognized in the updated algorithm and dedicated hardware is added to\nefficiently decode these new constituent codes. We also alter the polar code\nconstruction to further decrease the latency and increase the throughput with\nlittle to no noticeable effect on error-correction performance. Rate-flexible\ndecoders for polar codes of length 1024 and 2048 are implemented on FPGA. Over\nthe previous work, they are shown to have from 22% to 28% lower latency and 26%\nto 34% greater throughput when decoding low-rate codes. On 65 nm ASIC CMOS\ntechnology, the proposed decoder for a (1024, 512) polar code is shown to\ncompare favorably against the state-of-the-art ASIC decoders. With a clock\nfrequency of 400 MHz and a supply voltage of 0.8 V, it has a latency of 0.41\n$\\mu$s and an area efficiency of 1.8 Gbps/mm$^2$ for an energy efficiency of 77\npJ/info. bit. At 600 MHz with a supply of 1 V, the latency is reduced to 0.27\n$\\mu$s and the area efficiency increased to 2.7 Gbps/mm$^2$ at 115 pJ/info.\nbit."
},{
    "category": "cs.IT", 
    "doi": "10.1109/TCSII.2016.2546904", 
    "link": "http://arxiv.org/pdf/1603.07055v1", 
    "title": "LLR-based Successive-Cancellation List Decoder for Polar Codes with   Multi-bit Decision", 
    "arxiv-id": "1603.07055v1", 
    "author": "Keshab K. Parhi", 
    "publish": "2016-03-23T02:48:35Z", 
    "summary": "Due to their capacity-achieving property, polar codes have become one of the\nmost attractive channel codes. To date, the successive cancellation list (SCL)\ndecoding algorithm is the primary approach that can guarantee outstanding\nerror-correcting performance of polar codes. However, the hardware designs of\nthe original SCL decoder have large silicon area and long decoding latency.\nAlthough some recent efforts can reduce either the area or latency of SCL\ndecoders, these two metrics still cannot be optimized at the same time. This\npaper, for the first time, proposes a general log-likelihood-ratio (LLR)-based\nSCL decoding algorithm with multi-bit decision. This new algorithm, referred as\nLLR-2Kb-SCL, can determine 2K bits simultaneously for arbitrary K with the use\nof LLR messages. In addition, a reduced-data-width scheme is presented to\nreduce the critical path of the sorting block. Then, based on the proposed\nalgorithm, a VLSI architecture of the new SCL decoder is developed. Synthesis\nresults show that for an example (1024, 512) polar code with list size 4, the\nproposed LLR-2Kb-SCL decoders achieve significant reduction in both area and\nlatency as compared to prior works. As a result, the hardware efficiency of the\nproposed designs with K=2 and 3 are 2.33 times and 3.32 times of that of the\nstate-of-the-art works, respectively."
},{
    "category": "cs.LG", 
    "doi": "10.1109/TCSII.2016.2546904", 
    "link": "http://arxiv.org/pdf/1603.07400v2", 
    "title": "A Reconfigurable Low Power High Throughput Architecture for Deep Network   Training", 
    "arxiv-id": "1603.07400v2", 
    "author": "Tarek Taha", 
    "publish": "2016-03-24T00:52:22Z", 
    "summary": "General purpose computing systems are used for a large variety of\napplications. Extensive supports for flexibility in these systems limit their\nenergy efficiencies. Neural networks, including deep networks, are widely used\nfor signal processing and pattern recognition applications. In this paper we\npropose a multicore architecture for deep neural network based processing.\nMemristor crossbars are utilized to provide low power high throughput execution\nof neural networks. The system has both training and recognition (evaluation of\nnew input) capabilities. The proposed system could be used for classification,\ndimensionality reduction, feature extraction, and anomaly detection\napplications. The system level area and power benefits of the specialized\narchitecture is compared with the NVIDIA Telsa K20 GPGPU. Our experimental\nevaluations show that the proposed architecture can provide up to five orders\nof magnitude more energy efficiency over GPGPUs for deep neural network\nprocessing."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TCSII.2016.2546904", 
    "link": "http://arxiv.org/pdf/1603.09062v1", 
    "title": "FPGA Impementation of Erasure-Only Reed Solomon Decoders for Hybrid-ARQ   Systems", 
    "arxiv-id": "1603.09062v1", 
    "author": "Ertugrul Kolagasioglu", 
    "publish": "2016-03-30T07:44:23Z", 
    "summary": "This paper presents the usage of the Reed Solomon Codes as the Forward Error\nCorrection (FEC) unit of the Hybrid Automatic Repeat Request (ARQ) methods.\nParametric and flexible FPGA implementation details of such Erasure-Only RS\ndecoders with high symbol lengths (e.g. GF(2^32)) have been presented. The\ndesign is based on the GF(2m) multiplier logic core operating at a single clock\ncycle, where the resource utilization and throughput are both directly\nproportional to the number of these cores. For a fixed implementation, the\nthroughput inversely decreases with the number of erasures to be corrected.\nImplementation in Zynq7020 SoC device of an example GF(2^32)-RS Decoder capable\nof correcting 64-erasures with a single multiplier resulted in 1641-LUTs and\n188-FFs achieving 15Mbps, whereas the design with 8 multipliers resulted in\n6128-LUTs and 628-FFs achieving 100Mbps."
},{
    "category": "cs.ET", 
    "doi": "10.1109/TCSII.2016.2546904", 
    "link": "http://arxiv.org/pdf/1604.05897v2", 
    "title": "CLAASIC: a Cortex-Inspired Hardware Accelerator", 
    "arxiv-id": "1604.05897v2", 
    "author": "Jos\u00e9 \u00c1ngel Gregorio", 
    "publish": "2016-04-20T11:18:06Z", 
    "summary": "This work explores the feasibility of specialized hardware implementing the\nCortical Learning Algorithm (CLA) in order to fully exploit its inherent\nadvantages. This algorithm, which is inspired in the current understanding of\nthe mammalian neo-cortex, is the basis of the Hierarchical Temporal Memory\n(HTM). In contrast to other machine learning (ML) approaches, the structure is\nnot application dependent and relies on fully unsupervised continuous learning.\nWe hypothesize that a hardware implementation will be able not only to extend\nthe already practical uses of these ideas to broader scenarios but also to\nexploit the hardware-friendly CLA characteristics. The architecture proposed\nwill enable an unfeasible scalability for software solutions and will fully\ncapitalize on one of the many CLA advantages: low computational requirements\nand reduced storage utilization. Compared to a state-of-the-art CLA software\nimplementation it could be possible to improve by 4 orders of magnitude in\nperformance and up to 8 orders of magnitude in energy efficiency. We propose to\nuse a packet-switched network to tackle this. The paper addresses the\nfundamental issues of such an approach, proposing solutions to achieve scalable\nsolutions. We will analyze cost and performance when using well-known\narchitecture techniques and tools. The results obtained suggest that even with\nCMOS technology, under constrained cost, it might be possible to implement a\nlarge-scale system. We found that the proposed solutions enable a saving of 90%\nof the original communication costs running either synthetic or realistic\nworkloads."
},{
    "category": "cs.DC", 
    "doi": "10.1109/TCSII.2016.2546904", 
    "link": "http://arxiv.org/pdf/1604.08484v1", 
    "title": "Architectural Impact on Performance of In-memory Data Analytics: Apache   Spark Case Study", 
    "arxiv-id": "1604.08484v1", 
    "author": "Eduard Ayguade", 
    "publish": "2016-04-28T16:00:38Z", 
    "summary": "While cluster computing frameworks are continuously evolving to provide\nreal-time data analysis capabilities, Apache Spark has managed to be at the\nforefront of big data analytics for being a unified framework for both, batch\nand stream data processing. However, recent studies on micro-architectural\ncharacterization of in-memory data analytics are limited to only batch\nprocessing workloads. We compare micro-architectural performance of batch\nprocessing and stream processing workloads in Apache Spark using hardware\nperformance counters on a dual socket server. In our evaluation experiments, we\nhave found that batch processing are stream processing workloads have similar\nmicro-architectural characteristics and are bounded by the latency of frequent\ndata access to DRAM. For data accesses we have found that simultaneous\nmulti-threading is effective in hiding the data latencies. We have also\nobserved that (i) data locality on NUMA nodes can improve the performance by\n10% on average and(ii) disabling next-line L1-D prefetchers can reduce the\nexecution time by up-to 14\\% and (iii) multiple small executors can provide\nup-to 36\\% speedup over single large executor."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TCSII.2016.2546904", 
    "link": "http://arxiv.org/pdf/1605.01345v1", 
    "title": "A Linearization Technique for Self-Interference Cancellation in   Full-Duplex Radios", 
    "arxiv-id": "1605.01345v1", 
    "author": "Radha Krishna Ganti", 
    "publish": "2016-05-04T17:04:37Z", 
    "summary": "The fundamental problem in the design of a full-duplex radio is the\ncancellation of the self-interference (SI) signal generated by the\ntransmitter.Current techniques for suppressing SI rely on generating a copy of\nthe SI signal and subtracting it partly in the RF (radio frequency) and digital\ndomains. A critical step in replicating the self-interference is the estimation\nof the multi-path channel through which the transmitted signal propagates to\nthe antenna. Since there is no prior model on the number of multipath\nreflections, current techniques assume a tap delay line filter (in the RF and\ndigital domain) with a large number of taps, and estimate the taps in the\nanalog and the digital domain. Assuming such a model leads to a large\nform-factor for the analog and RF circuits and increased complexity in the\ndigital domain.\n  In this paper, using a linearization technique, we show that the\nself-interference channel in an indoor environment can be effectively modelled\nas $H(f)=C_0 + C_1f$ in the frequency domain. Thus, the effective\nself-interference channel can be represented by two parameters $C_0$ and $C_1$,\nirrespective of the multipath environment. We also provide experimental\nevidence to verify the above channel model and propose novel low-complexity\ndesigns for self-interference cancellation. Linearization not only aids in the\npracticality of analog cancellation by reducing the form factor, but also\nresults in a simpler SI filter model in the digital domain due to\ndimensionality reduction of the channel parameters. Therefore this method can\nenable the widespread adoption of full-duplex techniques to portable devices in\naddition to infrastructure base-stations."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TCSII.2016.2546904", 
    "link": "http://arxiv.org/pdf/1606.04074v2", 
    "title": "ENTRA: Whole-Systems Energy Transparency", 
    "arxiv-id": "1606.04074v2", 
    "author": "Mads Rosendahl", 
    "publish": "2016-06-13T19:16:52Z", 
    "summary": "Promoting energy efficiency to a first class system design goal is an\nimportant research challenge. Although more energy-efficient hardware can be\ndesigned, it is software that controls the hardware; for a given system the\npotential for energy savings is likely to be much greater at the higher levels\nof abstraction in the system stack. Thus the greatest savings are expected from\nenergy-aware software development, which is the vision of the EU ENTRA project.\nThis article presents the concept of energy transparency as a foundation for\nenergy-aware software development. We show how energy modelling of hardware is\ncombined with static analysis to allow the programmer to understand the energy\nconsumption of a program without executing it, thus enabling exploration of the\ndesign space taking energy into consideration. The paper concludes by\nsummarising the current and future challenges identified in the ENTRA project."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TCSII.2016.2546904", 
    "link": "http://arxiv.org/pdf/1606.05487v4", 
    "title": "YodaNN: An Architecture for Ultra-Low Power Binary-Weight CNN   Acceleration", 
    "arxiv-id": "1606.05487v4", 
    "author": "Luca Benini", 
    "publish": "2016-06-17T11:48:29Z", 
    "summary": "Convolutional neural networks (CNNs) have revolutionized the world of\ncomputer vision over the last few years, pushing image classification beyond\nhuman accuracy. The computational effort of today's CNNs requires power-hungry\nparallel processors or GP-GPUs. Recent developments in CNN accelerators for\nsystem-on-chip integration have reduced energy consumption significantly.\nUnfortunately, even these highly optimized devices are above the power envelope\nimposed by mobile and deeply embedded applications and face hard limitations\ncaused by CNN weight I/O and storage. This prevents the adoption of CNNs in\nfuture ultra-low power Internet of Things end-nodes for near-sensor analytics.\nRecent algorithmic and theoretical advancements enable competitive\nclassification accuracy even when limiting CNNs to binary (+1/-1) weights\nduring training. These new findings bring major optimization opportunities in\nthe arithmetic core by removing the need for expensive multiplications, as well\nas reducing I/O bandwidth and storage. In this work, we present an accelerator\noptimized for binary-weight CNNs that achieves 1510 GOp/s at 1.2 V on a core\narea of only 1.33 MGE (Million Gate Equivalent) or 0.19 mm$^2$ and with a power\ndissipation of 895 {\\mu}W in UMC 65 nm technology at 0.6 V. Our accelerator\nsignificantly outperforms the state-of-the-art in terms of energy and area\nefficiency achieving 61.2 TOp/s/W@0.6 V and 1135 GOp/s/MGE@1.2 V, respectively."
},{
    "category": "cs.DC", 
    "doi": "10.1016/j.sysarc.2017.01.005", 
    "link": "http://arxiv.org/pdf/1607.04549v2", 
    "title": "DiaSys: Improving SoC Insight Through On-Chip Diagnosis", 
    "arxiv-id": "1607.04549v2", 
    "author": "Andreas Herkersdorf", 
    "publish": "2016-07-15T15:16:03Z", 
    "summary": "To find the cause of a functional or non-functional defect (bug) in software\nrunning on a multi-processor System-on-Chip (MPSoC), developers need insight\ninto the chip. Tracing systems provide this insight non-intrusively, at the\ncost of high off-chip bandwidth requirements. This I/O bottleneck limits the\nobservability, a problem becoming more severe as more functionality is\nintegrated on-chip. In this paper, we present DiaSys, an MPSoC diagnosis system\nwith the potential to replace today's tracing systems. Its main idea is to\npartially execute the analysis of observation data on the chip; in consequence,\nmore information and less data is sent to the attached host PC. With DiaSys,\nthe data analysis is performed by the diagnosis application. Its input are\nevents, which are generated by observation hardware at interesting points in\nthe program execution (like a function call). Its outputs are events with\nhigher information density. The event transformation is modeled as dataflow\napplication. For execution, it is mapped in part to dedicated and distributed\non-chip components, and in part to the host PC; the off-chip boundary is\ntransparent to the developer of the diagnosis application. We implement DiaSys\nas extension to an existing SoC with four tiles and a mesh network running on\nan FPGA platform. Two usage examples confirm that DiaSys is flexible enough to\nreplace a tracing system, while significantly lowering the off-chip bandwidth\nrequirements. In our examples, the debugging of a race-condition bug, and the\ncreation of a lock contention profile, we see a reduction of trace bandwidth of\nmore than three orders of magnitude, compared to a full trace created by a\ncommon tracing system."
},{
    "category": "cs.CR", 
    "doi": "10.1016/j.sysarc.2017.01.005", 
    "link": "http://arxiv.org/pdf/1608.05930v1", 
    "title": "FPGA Design for Pseudorandom Number Generator Based on Chaotic Iteration   used in Information Hiding Application", 
    "arxiv-id": "1608.05930v1", 
    "author": "Laurent Larger", 
    "publish": "2016-08-21T12:45:43Z", 
    "summary": "Lots of researches indicate that the inefficient generation of random numbers\nis a significant bottleneck for information communication applications.\nTherefore, Field Programmable Gate Array (FPGA) is developed to process a\nscalable fixed-point method for random streams generation. In our previous\nresearches, we have proposed a technique by applying some well-defined discrete\nchaotic iterations that satisfy the reputed Devaney's definition of chaos,\nnamely chaotic iterations (CI). We have formerly proven that the generator with\nCI can provide qualified chaotic random numbers. In this paper, this generator\nbased on chaotic iterations is optimally redesigned for FPGA device. By doing\nso, the generation rate can be largely improved. Analyses show that these\nhardware generators can also provide good statistical chaotic random bits and\ncan be cryptographically secure too. An application in the information hiding\nsecurity field is finally given as an illustrative example."
},{
    "category": "cs.IT", 
    "doi": "10.1016/j.sysarc.2017.01.005", 
    "link": "http://arxiv.org/pdf/1609.08192v1", 
    "title": "FPGA Implementation of High Speed Reconfigurable Filter Bank for   Multi-standard Wireless Communication Receivers", 
    "arxiv-id": "1609.08192v1", 
    "author": "S. J. Darak", 
    "publish": "2016-09-15T10:30:00Z", 
    "summary": "In next generation wireless communication system, wireless transceivers\nshould be able to handle wideband input signals compromising of multiple\ncommunication standards.Such multi-standard wireless communication receivers\n(MWCRs) need filter bank to extract the desired signal of interest from\nwideband input spectrum and bring it to the baseband for further signal\nprocessing tasks such as spectrum sensing, modulation\nclassification,demodulation etc.In MWCRs,rather any wireless receivers,\nmodulated filter banks, such as Discrete Fourier Transform Filter Banks\n(DFTFB), are preferred due to their advantages such as lower area, delay and\npower requirements. To support multi-standard operation, reconfigurable DFTFB\n(RDFTFB) was proposed by integrating DFTFB with the coefficient decimation\nmethod. In this paper, an efficient high speed implementation of RDFTFB on\nVirtex-7 field programmable gate arrays (FPGA) has been proposed.The proposed\napproach minimizes the critical path delay between clocked registers thereby\nleading to significant improvement in the maximum operating frequency of the\nRDFTFB. Numerically, the proposed implementation leads to 89.7% improvement in\nthe maximum frequency at which RDFTFB can be clocked.Furthermore,proposed\nimplementation leads to 18.5% reduction in the dynamic power consumption."
},{
    "category": "cs.AR", 
    "doi": "10.1016/j.sysarc.2017.01.005", 
    "link": "http://arxiv.org/pdf/1610.02273v2", 
    "title": "Near-Data Processing for Machine Learning", 
    "arxiv-id": "1610.02273v2", 
    "author": "Sungroh Yoon", 
    "publish": "2016-10-06T05:28:33Z", 
    "summary": "In computer architecture, near-data processing (NDP) refers to augmenting the\nmemory or the storage with processing power so that it can process the data\nstored therein. By offloading the computational burden of CPU and saving the\nneed for transferring raw data in its entirety, NDP exhibits a great potential\nfor acceleration and power reduction. Despite this potential, specific research\nactivities on NDP have witnessed only limited success until recently, often\nowing to performance mismatches between logic and memory process technologies\nthat put a limit on the processing capability of memory. Recently, there have\nbeen two major changes in the game, igniting the resurgence of NDP with renewed\ninterest. The first is the success of machine learning (ML), which often\ndemands a great deal of computation for training, requiring frequent transfers\nof big data. The second is the advent of NAND flash-based solid-state drives\n(SSDs) containing multicore processors that can accommodate extra computation\nfor data processing. Sparked by these application needs and technological\nsupport, we evaluate the potential of NDP for ML using a new SSD platform that\nallows us to simulate in-storage processing (ISP) of ML workloads. Our platform\n(named ISP-ML) is a full-fledged simulator of a realistic multi-channel SSD\nthat can execute various ML algorithms using the data stored in the SSD. For\nthorough performance analysis and in-depth comparison with alternatives, we\nfocus on a specific algorithm: stochastic gradient decent (SGD), which is the\nde facto standard for training differentiable learning machines including deep\nneural networks. We implement and compare three variants of SGD (synchronous,\nDownpour, and elastic averaging) using ISP-ML, exploiting the multiple NAND\nchannels for parallelizing SGD. In addition, we compare the performance of ISP\nand that of conventional in-host processing."
},{
    "category": "cs.AR", 
    "doi": "10.1016/j.sysarc.2017.01.005", 
    "link": "http://arxiv.org/pdf/1610.06050v1", 
    "title": "A 9.96 dB NCG FEC scheme and 164 bits/cycle low-complexity product   decoder architecture", 
    "arxiv-id": "1610.06050v1", 
    "author": "Warren J. Gross", 
    "publish": "2016-10-18T11:46:19Z", 
    "summary": "Powerful Forward Error Correction (FEC) schemes are used in optical\ncommunications to achieve bit-error rates below $10^{-15}$. These FECs follow\none of two approaches: concatenation of simpler hard-decision codes or usage of\ninherently powerful soft-decision codes. The first approach yields lower Net\nCoding Gains (NCG), but can usually work at higher code rates and have lower\ncomplexity decoders. In this work, we propose a novel FEC scheme based on a\nproduct code and a post-processing technique. It can achieve an NCG of 9.96 dB\nat a BER of $10^{-18}$ without encountering an error floor, an error-correction\nperformance that sits between that of current hard-decision and soft-decision\nFECs. A decoder architecture is designed, tested on FPGA and synthesized in 65\nnm CMOS technology: its 164 bits/cycle worst-case information throughput can\nreach 100 Gb/s at the achieved frequency of 609 MHz. Its complexity is shown to\nbe lower than that of hard-decision decoders in literature, and an order of\nmagnitude lower than the estimated complexity of soft-decision decoders."
},{
    "category": "cs.LG", 
    "doi": "10.1016/j.sysarc.2017.01.005", 
    "link": "http://arxiv.org/pdf/1610.06920v1", 
    "title": "Bit-pragmatic Deep Neural Network Computing", 
    "arxiv-id": "1610.06920v1", 
    "author": "A. Moshovos", 
    "publish": "2016-10-20T22:16:05Z", 
    "summary": "We quantify a source of ineffectual computations when processing the\nmultiplications of the convolutional layers in Deep Neural Networks (DNNs) and\npropose Pragmatic (PRA), an architecture that exploits it improving performance\nand energy efficiency. The source of these ineffectual computations is best\nunderstood in the context of conventional multipliers which generate internally\nmultiple terms, that is, products of the multiplicand and powers of two, which\nadded together produce the final product [1]. At runtime, many of these terms\nare zero as they are generated when the multiplicand is combined with the\nzero-bits of the multiplicator. While conventional bit-parallel multipliers\ncalculate all terms in parallel to reduce individual product latency, PRA\ncalculates only the non-zero terms using a) on-the-fly conversion of the\nmultiplicator representation into an explicit list of powers of two, and b)\nhybrid bit-parallel multplicand/bit-serial multiplicator processing units. PRA\nexploits two sources of ineffectual computations: 1) the aforementioned zero\nproduct terms which are the result of the lack of explicitness in the\nmultiplicator representation, and 2) the excess in the representation precision\nused for both multiplicants and multiplicators, e.g., [2]. Measurements\ndemonstrate that for the convolutional layers, a straightforward variant of PRA\nimproves performance by 2.6x over the DaDiaNao (DaDN) accelerator [3] and by\n1.4x over STR [4]. Similarly, PRA improves energy efficiency by 28% and 10% on\naverage compared to DaDN and STR. An improved cross lane synchronication scheme\nboosts performance improvements to 3.1x over DaDN. Finally, Pragmatic benefits\npersist even with an 8-bit quantized representation [5]."
},{
    "category": "physics.comp-ph", 
    "doi": "10.1016/j.sysarc.2017.01.005", 
    "link": "http://arxiv.org/pdf/1611.04474v1", 
    "title": "Revisiting FPGA Acceleration of Molecular Dynamics Simulation with   Dynamic Data Flow Behavior in High-Level Synthesis", 
    "arxiv-id": "1611.04474v1", 
    "author": "Peng Wei", 
    "publish": "2016-11-11T01:38:14Z", 
    "summary": "Molecular dynamics (MD) simulation is one of the past decade's most important\ntools for enabling biology scientists and researchers to explore human health\nand diseases. However, due to the computation complexity of the MD algorithm,\nit takes weeks or even months to simulate a comparatively simple biology entity\non conventional multicore processors. The critical path in molecular dynamics\nsimulations is the force calculation between particles inside the simulated\nenvironment, which has abundant parallelism. Among various acceleration\nplatforms, FPGA is an attractive alternative because of its low power and high\nenergy efficiency. However, due to its high programming cost using RTL, none of\nthe mainstream MD software packages has yet adopted FPGA for acceleration.\n  In this paper we revisit the FPGA acceleration of MD in high-level synthesis\n(HLS) so as to provide affordable programming cost. Our experience with the MD\nacceleration demonstrates that HLS optimizations such as loop pipelining,\nmodule duplication and memory partitioning are essential to improve the\nperformance, achieving a speedup of 9.5X compared to a 12-core CPU. More\nimportantly, we observe that even the fully optimized HLS design can still be\n2X slower than the reference RTL architecture due to the common dynamic\n(conditional) data flow behavior that is not yet supported by current HLS\ntools. To support such behavior, we further customize an array of processing\nelements together with a data-driven streaming network through a common RTL\ntemplate, and fully automate the design flow. Our final experimental results\ndemonstrate a 19.4X performance speedup and 39X energy efficiency for the\nwidely used ApoA1 MD benchmark on the Convey HC1ex FPGA compared to a 12-core\nIntel Xeon server."
},{
    "category": "cs.ET", 
    "doi": "10.1016/j.sysarc.2017.01.005", 
    "link": "http://arxiv.org/pdf/1612.02913v2", 
    "title": "Field-Programmable Crossbar Array (FPCA) for Reconfigurable Computing", 
    "arxiv-id": "1612.02913v2", 
    "author": "Wei D. Lu", 
    "publish": "2016-12-09T04:41:25Z", 
    "summary": "For decades, advances in electronics were directly related to the scaling of\nCMOS transistors according to Moore's law. However, both the CMOS scaling and\nthe classical computer architecture are approaching fundamental and practical\nlimits, and new computing architectures based on emerging devices, such as\nnon-volatile memories e.g. resistive memory (RRAM) devices, are expected to\nsustain the exponential growth of computing capability. Here we propose a novel\nmemory-centric, reconfigurable, general purpose computing platform to handle\nthe explosive amount of data in a fast and energy-efficient manner. The\nproposed computing architecture is based on a single physical resistive\nmemory-centric fabric that can be optimally reconfigured and utilized to\nperform different computing and data storage tasks in a massively parallel\napproach. The system can be tailored to achieve maximal energy efficiency based\non the data flow by dynamically allocating the basic computing fabric to\nstorage, arithmetic, and analog computing including neuromorphic computing\ntasks."
},{
    "category": "cs.DC", 
    "doi": "10.1016/j.sysarc.2017.01.005", 
    "link": "http://arxiv.org/pdf/1612.04197v1", 
    "title": "An Artificial Neural Networks based Temperature Prediction Framework for   Network-on-Chip based Multicore Platform", 
    "arxiv-id": "1612.04197v1", 
    "author": "Sandeep Aswath Narayana", 
    "publish": "2016-12-12T09:11:13Z", 
    "summary": "Continuous improvement in silicon process technologies has made possible the\nintegration of hundreds of cores on a single chip. However, power and heat have\nbecome dominant constraints in designing these massive multicore chips causing\nissues with reliability, timing variations and reduced lifetime of the chips.\nDynamic Thermal Management (DTM) is a solution to avoid high temperatures on\nthe die. Typical DTM schemes only address core level thermal issues. However,\nthe Network-on-chip (NoC) paradigm, which has emerged as an enabling\nmethodology for integrating hundreds to thousands of cores on the same die can\ncontribute significantly to the thermal issues. Moreover, the typical DTM is\ntriggered reactively based on temperature measurements from on-chip thermal\nsensor requiring long reaction times whereas predictive DTM method estimates\nfuture temperature in advance, eliminating the chance of temperature overshoot.\nArtificial Neural Networks (ANNs) have been used in various domains for\nmodeling and prediction with high accuracy due to its ability to learn and\nadapt. This thesis concentrates on designing an ANN prediction engine to\npredict the thermal profile of the cores and Network-on-Chip elements of the\nchip. This thermal profile of the chip is then used by the predictive DTM that\ncombines both core level and network level DTM techniques. On-chip wireless\ninterconnect which is recently envisioned to enable energy-efficient data\nexchange between cores in a multicore environment, will be used to provide a\nbroadcast-capable medium to efficiently distribute thermal control messages to\ntrigger and manage the DTM schemes."
},{
    "category": "cs.CV", 
    "doi": "10.1145/3020078.3021744", 
    "link": "http://arxiv.org/pdf/1612.07119v1", 
    "title": "FINN: A Framework for Fast, Scalable Binarized Neural Network Inference", 
    "arxiv-id": "1612.07119v1", 
    "author": "Kees Vissers", 
    "publish": "2016-12-01T22:19:47Z", 
    "summary": "Research has shown that convolutional neural networks contain significant\nredundancy, and high classification accuracy can be obtained even when weights\nand activations are reduced from floating point to binary values. In this\npaper, we present FINN, a framework for building fast and flexible FPGA\naccelerators using a flexible heterogeneous streaming architecture. By\nutilizing a novel set of optimizations that enable efficient mapping of\nbinarized neural networks to hardware, we implement fully connected,\nconvolutional and pooling layers, with per-layer compute resources being\ntailored to user-provided throughput requirements. On a ZC706 embedded FPGA\nplatform drawing less than 25 W total system power, we demonstrate up to 12.3\nmillion image classifications per second with 0.31 {\\mu}s latency on the MNIST\ndataset with 95.8% accuracy, and 21906 image classifications per second with\n283 {\\mu}s latency on the CIFAR-10 and SVHN datasets with respectively 80.1%\nand 94.9% accuracy. To the best of our knowledge, ours are the fastest\nclassification rates reported to date on these benchmarks."
},{
    "category": "cs.AR", 
    "doi": "10.1145/3020078.3021744", 
    "link": "http://arxiv.org/pdf/1612.08163v1", 
    "title": "Application-aware Retiming of Accelerators: A High-level Data-driven   Approach", 
    "arxiv-id": "1612.08163v1", 
    "author": "Steve Furber", 
    "publish": "2016-12-24T10:55:46Z", 
    "summary": "Flexibility at hardware level is the main driving force behind adaptive\nsystems whose aim is to realise microarhitecture deconfiguration 'online'. This\nfeature allows the software/hardware stack to tolerate drastic changes of the\nworkload in data centres. With emerge of FPGA reconfigurablity this technology\nis becoming a mainstream computing paradigm. Adaptivity is usually accompanied\nby the high-level tools to facilitate multi-dimensional space exploration. An\nessential aspect in this space is memory orchestration where on-chip and\noff-chip memory distribution significantly influences the architecture in\ncoping with the critical spatial and timing constraints, e.g. Place and Route.\nThis paper proposes a memory smart technique for a particular class of adaptive\nsystems: Elastic Circuits which enjoy slack elasticity at fine level of\ngranularity. We explore retiming of a set of popular benchmarks via\ninvestigating the memory distribution within and among accelerators. The area,\nperformance and power patterns are adopted by our high-level synthesis\nframework, with respect to the behaviour of the input descriptions, to improve\nthe quality of the synthesised elastic circuits."
},{
    "category": "cs.DC", 
    "doi": "10.1145/3020078.3021744", 
    "link": "http://arxiv.org/pdf/1701.03534v1", 
    "title": "An OpenCL(TM) Deep Learning Accelerator on Arria 10", 
    "arxiv-id": "1701.03534v1", 
    "author": "Gordon R. Chiu", 
    "publish": "2017-01-13T00:31:15Z", 
    "summary": "Convolutional neural nets (CNNs) have become a practical means to perform\nvision tasks, particularly in the area of image classification. FPGAs are well\nknown to be able to perform convolutions efficiently, however, most recent\nefforts to run CNNs on FPGAs have shown limited advantages over other devices\nsuch as GPUs. Previous approaches on FPGAs have often been memory bound due to\nthe limited external memory bandwidth on the FPGA device. We show a novel\narchitecture written in OpenCL(TM), which we refer to as a Deep Learning\nAccelerator (DLA), that maximizes data reuse and minimizes external memory\nbandwidth. Furthermore, we show how we can use the Winograd transform to\nsignificantly boost the performance of the FPGA. As a result, when running our\nDLA on Intel's Arria 10 device we can achieve a performance of 1020 img/s, or\n23 img/s/W when running the AlexNet CNN benchmark. This comes to 1382 GFLOPs\nand is 10x faster with 8.4x more GFLOPS and 5.8x better efficiency than the\nstate-of-the-art on FPGAs. Additionally, 23 img/s/W is competitive against the\nbest publicly known implementation of AlexNet on nVidia's TitanX GPU."
},{
    "category": "cs.DC", 
    "doi": "10.1145/3020078.3021744", 
    "link": "http://arxiv.org/pdf/1701.03709v1", 
    "title": "Power and Execution Time Measurement Methodology for SDF Applications on   FPGA-based MPSoCs", 
    "arxiv-id": "1701.03709v1", 
    "author": "Ralf Stemmer", 
    "publish": "2017-01-13T16:15:53Z", 
    "summary": "Timing and power consumption play an important role in the design of embedded\nsystems. Furthermore, both properties are directly related to the safety\nrequirements of many embedded systems. With regard to availability\nrequirements, power considerations are of uttermost importance for battery\noperated systems. Validation of timing and power requires observability of\nthese properties. In many cases this is difficult, because the observability is\neither not possible or requires big extra effort in the system validation\nprocess. In this paper, we present a measurement-based approach for the joint\ntiming and power analysis of Synchronous Dataflow (SDF) applications running on\na shared memory multiprocessor systems-on-chip (MPSoC) architecture. As a\nproof-of-concept, we implement an MPSoC system with configurable power and\ntiming measurement interfaces inside a Field Programmable Gate Array (FPGA).\nOur experiments demonstrate the viability of our approach being able of\naccurately analyzing different mappings of image processing applications (Sobel\nfilter and JPEG encoder) on an FPGA-based MPSoC implementation."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.jal.2017.03.001", 
    "link": "http://arxiv.org/pdf/1701.03836v2", 
    "title": "Formal Analysis of SEU Mitigation for Early Dependability and   Performability Analysis of FPGA-based Space Applications", 
    "arxiv-id": "1701.03836v2", 
    "author": "Yvon Savaria", 
    "publish": "2017-01-12T17:07:36Z", 
    "summary": "SRAM-based FPGAs are increasingly popular in the aerospace industry due to\ntheir field programmability and low cost. However, they suffer from cosmic\nradiation induced Single Event Upsets (SEUs). In safety-critical applications,\nthe dependability of the design is a prime concern since failures may have\ncatastrophic consequences. An early analysis of the relationship between\ndependability metrics, performability-area trade-off, and different mitigation\ntechniques for such applications can reduce the design effort while increasing\nthe design confidence. This paper introduces a novel methodology based on\nprobabilistic model checking, for the analysis of the reliability,\navailability, safety and performance-area tradeoffs of safety-critical systems\nfor early design decisions. Starting from the high-level description of a\nsystem, a Markov reward model is constructed from the Control Data Flow Graph\n(CDFG) and a component characterization library targeting FPGAs. The proposed\nmodel and exhaustive analysis capture all the failure states (based on the\nfault detection coverage) and repairs possible in the system. We present\nquantitative results based on an FIR filter circuit to illustrate the\napplicability of the proposed approach and to demonstrate that a wide range of\nuseful dependability and performability properties can be analyzed using the\nproposed methodology. The modeling results show the relationship between\ndifferent mitigation techniques and fault detection coverage, exposing their\ndirect impact on the design for early decisions."
},{
    "category": "hep-lat", 
    "doi": "10.1016/j.jal.2017.03.001", 
    "link": "http://arxiv.org/pdf/1702.00208v1", 
    "title": "Machines and Algorithms", 
    "arxiv-id": "1702.00208v1", 
    "author": "Peter A Boyle", 
    "publish": "2017-02-01T11:04:34Z", 
    "summary": "I discuss the evolution of computer architectures with a focus on QCD and\nwith reference to the interplay between architecture, engineering, data motion\nand algorithms. New architectures are discussed and recent performance results\nare displayed. I also review recent progress in multilevel solver and\nintegation algorithms."
},{
    "category": "cs.IT", 
    "doi": "10.1016/j.jal.2017.03.001", 
    "link": "http://arxiv.org/pdf/1702.03449v1", 
    "title": "1-bit Massive MU-MIMO Precoding in VLSI", 
    "arxiv-id": "1702.03449v1", 
    "author": "Christoph Studer", 
    "publish": "2017-02-11T19:36:49Z", 
    "summary": "Massive multiuser (MU) multiple-input multiple-output (MIMO) will be a core\ntechnology in fifth-generation (5G) wireless systems as it offers significant\nimprovements in spectral efficiency compared to existing multi-antenna\ntechnologies. The presence of hundreds of antenna elements at the base station\n(BS), however, results in excessively high hardware costs and power\nconsumption, and requires high interconnect throughput between the\nbaseband-processing unit and the radio unit. Massive MU-MIMO that uses\nlow-resolution analog-to-digital and digital-to-analog converters (DACs) has\nthe potential to address all these issues. In this paper, we focus on downlink\nprecoding for massive MU-MIMO systems with 1-bit DACs at the BS. The objective\nis to design precoders that simultaneously mitigate multi-user interference\n(MUI) and quantization artifacts. We propose two nonlinear 1-bit precoding\nalgorithms and corresponding very-large scale integration (VLSI) designs. Our\nalgorithms rely on biconvex relaxation, which enables the design of efficient\n1-bit precoding algorithms that achieve superior error-rate performance\ncompared to that of linear precoding algorithms followed by quantization. To\nshowcase the efficacy of our algorithms, we design VLSI architectures that\nenable efficient 1-bit precoding for massive MU-MIMO systems in which hundreds\nof antennas serve tens of user equipments. We present corresponding\nfield-programmable gate array (FPGA) implementations to demonstrate that 1-bit\nprecoding enables reliable and high-rate downlink data transmission in\npractical systems."
},{
    "category": "cs.DC", 
    "doi": "10.1016/j.jal.2017.03.001", 
    "link": "http://arxiv.org/pdf/1702.06392v1", 
    "title": "A 7.663-TOPS 8.2-W Energy-efficient FPGA Accelerator for Binary   Convolutional Neural Networks", 
    "arxiv-id": "1702.06392v1", 
    "author": "Fengbo Ren", 
    "publish": "2017-02-20T05:21:34Z", 
    "summary": "FPGA-based hardware accelerators for convolutional neural networks (CNNs)\nhave obtained great attentions due to their higher energy efficiency than GPUs.\nHowever, it is challenging for FPGA-based solutions to achieve a higher\nthroughput than GPU counterparts. In this paper, we demonstrate that FPGA\nacceleration can be a superior solution in terms of both throughput and energy\nefficiency when a CNN is trained with binary constraints on weights and\nactivations. Specifically, we propose an optimized accelerator architecture\ntailored for bitwise convolution and normalization that features massive\nspatial parallelism with deep pipelines stages. Experiment results show that\nthe proposed architecture is 8.3x faster and 75x more energy-efficient than a\nTitan X GPU for processing online individual requests (in small batch size).\nFor processing static data (in large batch size), the proposed solution is on a\npar with a Titan X GPU in terms of throughput while delivering 9.5x higher\nenergy efficiency."
},{
    "category": "cs.DC", 
    "doi": "10.1016/j.jal.2017.03.001", 
    "link": "http://arxiv.org/pdf/cs/9903009v1", 
    "title": "Space-Efficient Routing Tables for Almost All Networks and the   Incompressibility Method", 
    "arxiv-id": "cs/9903009v1", 
    "author": "Paul Vitanyi", 
    "publish": "1999-03-10T19:01:02Z", 
    "summary": "We use the incompressibility method based on Kolmogorov complexity to\ndetermine the total number of bits of routing information for almost all\nnetwork topologies. In most models for routing, for almost all labeled graphs\n$\\Theta (n^2)$ bits are necessary and sufficient for shortest path routing. By\n`almost all graphs' we mean the Kolmogorov random graphs which constitute a\nfraction of $1-1/n^c$ of all graphs on $n$ nodes, where $c > 0$ is an arbitrary\nfixed constant. There is a model for which the average case lower bound rises\nto $\\Omega(n^2 \\log n)$ and another model where the average case upper bound\ndrops to $O(n \\log^2 n)$. This clearly exposes the sensitivity of such bounds\nto the model under consideration. If paths have to be short, but need not be\nshortest (if the stretch factor may be larger than 1), then much less space is\nneeded on average, even in the more demanding models. Full-information routing\nrequires $\\Theta (n^3)$ bits on average. For worst-case static networks we\nprove a $\\Omega(n^2 \\log n)$ lower bound for shortest path routing and all\nstretch factors $<2$ in some networks where free relabeling is not allowed."
},{
    "category": "cs.CE", 
    "doi": "10.1016/j.jal.2017.03.001", 
    "link": "http://arxiv.org/pdf/cs/0605119v1", 
    "title": "An Internet-enabled technology to support Evolutionary Design", 
    "arxiv-id": "cs/0605119v1", 
    "author": "K. Ueda", 
    "publish": "2006-05-25T04:39:11Z", 
    "summary": "This paper discusses the systematic use of product feedback information to\nsupport life-cycle design approaches and provides guidelines for developing a\ndesign at both the product and the system levels. Design activities are\nsurveyed in the light of the product life cycle, and the design information\nflow is interpreted from a semiotic perspective. The natural evolution of a\ndesign is considered, the notion of design expectations is introduced, and the\nimportance of evaluation of these expectations in dynamic environments is\nargued. Possible strategies for reconciliation of the expectations and\nenvironmental factors are described. An Internet-enabled technology is proposed\nto monitor product functionality, usage, and operational environment and supply\nthe designer with relevant information. A pilot study of assessing design\nexpectations of a refrigerator is outlined, and conclusions are drawn."
},{
    "category": "nlin.AO", 
    "doi": "10.1063/1.2159147", 
    "link": "http://arxiv.org/pdf/nlin/0506030v2", 
    "title": "Chaos in computer performance", 
    "arxiv-id": "nlin/0506030v2", 
    "author": "Olivier Temam", 
    "publish": "2005-06-13T14:05:38Z", 
    "summary": "Modern computer microprocessors are composed of hundreds of millions of\ntransistors that interact through intricate protocols. Their performance during\nprogram execution may be highly variable and present aperiodic oscillations. In\nthis paper, we apply current nonlinear time series analysis techniques to the\nperformances of modern microprocessors during the execution of prototypical\nprograms. Our results present pieces of evidence strongly supporting that the\nhigh variability of the performance dynamics during the execution of several\nprograms display low-dimensional deterministic chaos, with sensitivity to\ninitial conditions comparable to textbook models. Taken together, these results\nshow that the instantaneous performances of modern microprocessors constitute a\ncomplex (or at least complicated) system and would benefit from analysis with\nmodern tools of nonlinear and complexity science."
},{
    "category": "cs.DC", 
    "doi": "10.12837/2013T01", 
    "link": "http://arxiv.org/pdf/1305.1459v1", 
    "title": "EURETILE 2010-2012 summary: first three years of activity of the   European Reference Tiled Experiment", 
    "arxiv-id": "1305.1459v1", 
    "author": "Piero Vicini", 
    "publish": "2013-05-07T10:22:31Z", 
    "summary": "This is the summary of first three years of activity of the EURETILE FP7\nproject 247846. EURETILE investigates and implements brain-inspired and\nfault-tolerant foundational innovations to the system architecture of massively\nparallel tiled computer architectures and the corresponding programming\nparadigm. The execution targets are a many-tile HW platform, and a many-tile\nsimulator. A set of SW process - HW tile mapping candidates is generated by the\nholistic SW tool-chain using a combination of analytic and bio-inspired\nmethods. The Hardware dependent Software is then generated, providing OS\nservices with maximum efficiency/minimal overhead. The many-tile simulator\ncollects profiling data, closing the loop of the SW tool chain. Fine-grain\nparallelism inside processes is exploited by optimized intra-tile compilation\ntechniques, but the project focus is above the level of the elementary tile.\nThe elementary HW tile is a multi-processor, which includes a fault tolerant\nDistributed Network Processor (for inter-tile communication) and ASIP\naccelerators. Furthermore, EURETILE investigates and implements the innovations\nfor equipping the elementary HW tile with high-bandwidth, low-latency\nbrain-like inter-tile communication emulating 3 levels of connection hierarchy,\nnamely neural columns, cortical areas and cortex, and develops a dedicated\ncortical simulation benchmark: DPSNN-STDP (Distributed Polychronous Spiking\nNeural Net with synaptic Spiking Time Dependent Plasticity). EURETILE leverages\non the multi-tile HW paradigm and SW tool-chain developed by the FET-ACA SHAPES\nIntegrated Project (2006-2009)."
},{
    "category": "cs.IT", 
    "doi": "10.1109/TCOMM.2013.13.130109", 
    "link": "http://arxiv.org/pdf/1310.4349v2", 
    "title": "An Improved Majority-Logic Decoder Offering Massively Parallel Decoding   for Real-Time Control in Embedded Systems", 
    "arxiv-id": "1310.4349v2", 
    "author": "Michael Huber", 
    "publish": "2013-10-16T12:31:01Z", 
    "summary": "We propose an easy-to-implement hard-decision majority-logic decoding\nalgorithm for Reed-Muller codes RM(r,m) with m >= 3, m/2 >= r >= 1. The\npresented algorithm outperforms the best known majority-logic decoding\nalgorithms and offers highly parallel decoding. The result is of special\nimportance for safety- and time-critical applications in embedded systems. A\nsimple combinational circuit can perform the proposed decoding. In particular,\nwe show how our decoder for the three-error-correcting code RM(2,5) of\ndimension 16 and length 32 can be realized on hardware level."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TCSVT.2011.2181232", 
    "link": "http://arxiv.org/pdf/1502.04221v1", 
    "title": "A Row-parallel 8$\\times$8 2-D DCT Architecture Using Algebraic Integer   Based Exact Computation", 
    "arxiv-id": "1502.04221v1", 
    "author": "A. Edirisuriya", 
    "publish": "2015-02-14T16:14:05Z", 
    "summary": "An algebraic integer (AI) based time-multiplexed row-parallel architecture\nand two final-reconstruction step (FRS) algorithms are proposed for the\nimplementation of bivariate AI-encoded 2-D discrete cosine transform (DCT). The\narchitecture directly realizes an error-free 2-D DCT without using FRSs between\nrow-column transforms, leading to an 8$\\times$8 2-D DCT which is entirely free\nof quantization errors in AI basis. As a result, the user-selectable accuracy\nfor each of the coefficients in the FRS facilitates each of the 64 coefficients\nto have its precision set independently of others, avoiding the leakage of\nquantization noise between channels as is the case for published DCT designs.\nThe proposed FRS uses two approaches based on (i) optimized Dempster-Macleod\nmultipliers and (ii) expansion factor scaling. This architecture enables\nlow-noise high-dynamic range applications in digital video processing that\nrequires full control of the finite-precision computation of the 2-D DCT. The\nproposed architectures and FRS techniques are experimentally verified and\nvalidated using hardware implementations that are physically realized and\nverified on FPGA chip. Six designs, for 4- and 8-bit input word sizes, using\nthe two proposed FRS schemes, have been designed, simulated, physically\nimplemented and measured. The maximum clock rate and block-rate achieved among\n8-bit input designs are 307.787 MHz and 38.47 MHz, respectively, implying a\npixel rate of 8$\\times$307.787$\\approx$2.462 GHz if eventually embedded in a\nreal-time video-processing system. The equivalent frame rate is about 1187.35\nHz for the image size of 1920$\\times$1080. All implementations are functional\non a Xilinx Virtex-6 XC6VLX240T FPGA device."
},{
    "category": "cs.IT", 
    "doi": "10.1007/s11045-014-0291-6", 
    "link": "http://arxiv.org/pdf/1606.05562v1", 
    "title": "An Orthogonal 16-point Approximate DCT for Image and Video Compression", 
    "arxiv-id": "1606.05562v1", 
    "author": "A. J. Kozakevicius", 
    "publish": "2016-05-27T01:19:46Z", 
    "summary": "A low-complexity orthogonal multiplierless approximation for the 16-point\ndiscrete cosine transform (DCT) was introduced. The proposed method was\ndesigned to possess a very low computational cost. A fast algorithm based on\nmatrix factorization was proposed requiring only 60~additions. The proposed\narchitecture outperforms classical and state-of-the-art algorithms when\nassessed as a tool for image and video compression. Digital VLSI hardware\nimplementations were also proposed being physically realized in FPGA technology\nand implemented in 45 nm up to synthesis and place-route levels. Additionally,\nthe proposed method was embedded into a high efficiency video coding (HEVC)\nreference software for actual proof-of-concept. Obtained results show\nnegligible video degradation when compared to Chen DCT algorithm in HEVC."
},{
    "category": "cs.NA", 
    "doi": "10.1007/s11045-014-0291-6", 
    "link": "http://arxiv.org/pdf/cs/0309018v1", 
    "title": "Using Propagation for Solving Complex Arithmetic Constraints", 
    "arxiv-id": "cs/0309018v1", 
    "author": "B. Moa", 
    "publish": "2003-09-11T18:37:09Z", 
    "summary": "Solving a system of nonlinear inequalities is an important problem for which\nconventional numerical analysis has no satisfactory method. With a\nbox-consistency algorithm one can compute a cover for the solution set to\narbitrarily close approximation. Because of difficulties in the use of\npropagation for complex arithmetic expressions, box consistency is computed\nwith interval arithmetic. In this paper we present theorems that support a\nsimple modification of propagation that allows complex arithmetic expressions\nto be handled efficiently. The version of box consistency that is obtained in\nthis way is stronger than when interval arithmetic is used."
},{
    "category": "cs.MM", 
    "doi": "10.1088/0957-0233/23/11/114010", 
    "link": "http://arxiv.org/pdf/1702.01805v1", 
    "title": "A Digital Hardware Fast Algorithm and FPGA-based Prototype for a Novel   16-point Approximate DCT for Image Compression Applications", 
    "arxiv-id": "1702.01805v1", 
    "author": "A. Madanayake", 
    "publish": "2017-02-06T22:00:34Z", 
    "summary": "The discrete cosine transform (DCT) is the key step in many image and video\ncoding standards. The 8-point DCT is an important special case, possessing\nseveral low-complexity approximations widely investigated. However, 16-point\nDCT transform has energy compaction advantages. In this sense, this paper\npresents a new 16-point DCT approximation with null multiplicative complexity.\nThe proposed transform matrix is orthogonal and contains only zeros and ones.\nThe proposed transform outperforms the well-know Walsh-Hadamard transform and\nthe current state-of-the-art 16-point approximation. A fast algorithm for the\nproposed transform is also introduced. This fast algorithm is experimentally\nvalidated using hardware implementations that are physically realized and\nverified on a 40 nm CMOS Xilinx Virtex-6 XC6VLX240T FPGA chip for a maximum\nclock rate of 342 MHz. Rapid prototypes on FPGA for 8-bit input word size shows\nsignificant improvement in compressed image quality by up to 1-2 dB at the cost\nof only eight adders compared to the state-of-art 16-point DCT approximation\nalgorithm in the literature [S. Bouguezel, M. O. Ahmad, and M. N. S. Swamy. A\nnovel transform for image compression. In {\\em Proceedings of the 53rd IEEE\nInternational Midwest Symposium on Circuits and Systems (MWSCAS)}, 2010]."
},lol]